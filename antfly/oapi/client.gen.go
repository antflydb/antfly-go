// Package oapi provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/oapi-codegen/oapi-codegen/v2 version v2.5.1 DO NOT EDIT.
package oapi

import (
	"bytes"
	"compress/gzip"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"path"
	"strings"
	"time"

	"github.com/getkin/kin-openapi/openapi3"
	"github.com/oapi-codegen/runtime"
)

const (
	BasicAuthScopes = "BasicAuth.Scopes"
)

// Defines values for AggregationType.
const (
	AggregationTypeAvg              AggregationType = "avg"
	AggregationTypeCardinality      AggregationType = "cardinality"
	AggregationTypeCount            AggregationType = "count"
	AggregationTypeDateHistogram    AggregationType = "date_histogram"
	AggregationTypeDateRange        AggregationType = "date_range"
	AggregationTypeGeoDistance      AggregationType = "geo_distance"
	AggregationTypeGeohashGrid      AggregationType = "geohash_grid"
	AggregationTypeHistogram        AggregationType = "histogram"
	AggregationTypeMax              AggregationType = "max"
	AggregationTypeMin              AggregationType = "min"
	AggregationTypeRange            AggregationType = "range"
	AggregationTypeSignificantTerms AggregationType = "significant_terms"
	AggregationTypeStats            AggregationType = "stats"
	AggregationTypeSum              AggregationType = "sum"
	AggregationTypeSumsquares       AggregationType = "sumsquares"
	AggregationTypeTerms            AggregationType = "terms"
)

// Defines values for AntflyType.
const (
	AntflyTypeBlob            AntflyType = "blob"
	AntflyTypeBoolean         AntflyType = "boolean"
	AntflyTypeDatetime        AntflyType = "datetime"
	AntflyTypeEmbedding       AntflyType = "embedding"
	AntflyTypeGeopoint        AntflyType = "geopoint"
	AntflyTypeGeoshape        AntflyType = "geoshape"
	AntflyTypeHtml            AntflyType = "html"
	AntflyTypeKeyword         AntflyType = "keyword"
	AntflyTypeLink            AntflyType = "link"
	AntflyTypeNumeric         AntflyType = "numeric"
	AntflyTypeSearchAsYouType AntflyType = "search_as_you_type"
	AntflyTypeText            AntflyType = "text"
)

// Defines values for BingSearchConfigFreshness.
const (
	BingSearchConfigFreshnessDay   BingSearchConfigFreshness = "Day"
	BingSearchConfigFreshnessMonth BingSearchConfigFreshness = "Month"
	BingSearchConfigFreshnessWeek  BingSearchConfigFreshness = "Week"
)

// Defines values for BraveSearchConfigFreshness.
const (
	BraveSearchConfigFreshnessPd BraveSearchConfigFreshness = "pd"
	BraveSearchConfigFreshnessPm BraveSearchConfigFreshness = "pm"
	BraveSearchConfigFreshnessPw BraveSearchConfigFreshness = "pw"
	BraveSearchConfigFreshnessPy BraveSearchConfigFreshness = "py"
)

// Defines values for CalendarInterval.
const (
	CalendarIntervalDay     CalendarInterval = "day"
	CalendarIntervalHour    CalendarInterval = "hour"
	CalendarIntervalMinute  CalendarInterval = "minute"
	CalendarIntervalMonth   CalendarInterval = "month"
	CalendarIntervalQuarter CalendarInterval = "quarter"
	CalendarIntervalWeek    CalendarInterval = "week"
	CalendarIntervalYear    CalendarInterval = "year"
)

// Defines values for ChainCondition.
const (
	ChainConditionAlways      ChainCondition = "always"
	ChainConditionOnError     ChainCondition = "on_error"
	ChainConditionOnRateLimit ChainCondition = "on_rate_limit"
	ChainConditionOnTimeout   ChainCondition = "on_timeout"
)

// Defines values for ChatMessageRole.
const (
	ChatMessageRoleAssistant ChatMessageRole = "assistant"
	ChatMessageRoleSystem    ChatMessageRole = "system"
	ChatMessageRoleTool      ChatMessageRole = "tool"
	ChatMessageRoleUser      ChatMessageRole = "user"
)

// Defines values for ChatToolName.
const (
	ChatToolNameAddFilter        ChatToolName = "add_filter"
	ChatToolNameAskClarification ChatToolName = "ask_clarification"
	ChatToolNameFetch            ChatToolName = "fetch"
	ChatToolNameSearch           ChatToolName = "search"
	ChatToolNameWebsearch        ChatToolName = "websearch"
)

// Defines values for ChunkerProvider.
const (
	ChunkerProviderAntfly  ChunkerProvider = "antfly"
	ChunkerProviderMock    ChunkerProvider = "mock"
	ChunkerProviderTermite ChunkerProvider = "termite"
)

// Defines values for ClusterBackupResponseStatus.
const (
	ClusterBackupResponseStatusCompleted ClusterBackupResponseStatus = "completed"
	ClusterBackupResponseStatusFailed    ClusterBackupResponseStatus = "failed"
	ClusterBackupResponseStatusPartial   ClusterBackupResponseStatus = "partial"
)

// Defines values for ClusterHealth.
const (
	ClusterHealthDegraded  ClusterHealth = "degraded"
	ClusterHealthError     ClusterHealth = "error"
	ClusterHealthHealthy   ClusterHealth = "healthy"
	ClusterHealthUnhealthy ClusterHealth = "unhealthy"
	ClusterHealthUnknown   ClusterHealth = "unknown"
)

// Defines values for ClusterRestoreRequestRestoreMode.
const (
	ClusterRestoreRequestRestoreModeFailIfExists ClusterRestoreRequestRestoreMode = "fail_if_exists"
	ClusterRestoreRequestRestoreModeOverwrite    ClusterRestoreRequestRestoreMode = "overwrite"
	ClusterRestoreRequestRestoreModeSkipIfExists ClusterRestoreRequestRestoreMode = "skip_if_exists"
)

// Defines values for ClusterRestoreResponseStatus.
const (
	ClusterRestoreResponseStatusFailed    ClusterRestoreResponseStatus = "failed"
	ClusterRestoreResponseStatusPartial   ClusterRestoreResponseStatus = "partial"
	ClusterRestoreResponseStatusTriggered ClusterRestoreResponseStatus = "triggered"
)

// Defines values for CohereEmbedderConfigInputType.
const (
	CohereEmbedderConfigInputTypeClassification CohereEmbedderConfigInputType = "classification"
	CohereEmbedderConfigInputTypeClustering     CohereEmbedderConfigInputType = "clustering"
	CohereEmbedderConfigInputTypeSearchDocument CohereEmbedderConfigInputType = "search_document"
	CohereEmbedderConfigInputTypeSearchQuery    CohereEmbedderConfigInputType = "search_query"
)

// Defines values for CohereEmbedderConfigTruncate.
const (
	CohereEmbedderConfigTruncateEND   CohereEmbedderConfigTruncate = "END"
	CohereEmbedderConfigTruncateNONE  CohereEmbedderConfigTruncate = "NONE"
	CohereEmbedderConfigTruncateSTART CohereEmbedderConfigTruncate = "START"
)

// Defines values for DistanceUnit.
const (
	DistanceUnitFt DistanceUnit = "ft"
	DistanceUnitKm DistanceUnit = "km"
	DistanceUnitM  DistanceUnit = "m"
	DistanceUnitMi DistanceUnit = "mi"
	DistanceUnitYd DistanceUnit = "yd"
)

// Defines values for DynamicTemplateMatchMappingType.
const (
	DynamicTemplateMatchMappingTypeBoolean DynamicTemplateMatchMappingType = "boolean"
	DynamicTemplateMatchMappingTypeDate    DynamicTemplateMatchMappingType = "date"
	DynamicTemplateMatchMappingTypeNumber  DynamicTemplateMatchMappingType = "number"
	DynamicTemplateMatchMappingTypeObject  DynamicTemplateMatchMappingType = "object"
	DynamicTemplateMatchMappingTypeString  DynamicTemplateMatchMappingType = "string"
)

// Defines values for EdgeDirection.
const (
	EdgeDirectionBoth EdgeDirection = "both"
	EdgeDirectionIn   EdgeDirection = "in"
	EdgeDirectionOut  EdgeDirection = "out"
)

// Defines values for EmbedderProvider.
const (
	EmbedderProviderBedrock    EmbedderProvider = "bedrock"
	EmbedderProviderCohere     EmbedderProvider = "cohere"
	EmbedderProviderGemini     EmbedderProvider = "gemini"
	EmbedderProviderMock       EmbedderProvider = "mock"
	EmbedderProviderOllama     EmbedderProvider = "ollama"
	EmbedderProviderOpenai     EmbedderProvider = "openai"
	EmbedderProviderOpenrouter EmbedderProvider = "openrouter"
	EmbedderProviderTermite    EmbedderProvider = "termite"
	EmbedderProviderVertex     EmbedderProvider = "vertex"
)

// Defines values for EvaluatorName.
const (
	EvaluatorNameCitationQuality EvaluatorName = "citation_quality"
	EvaluatorNameCoherence       EvaluatorName = "coherence"
	EvaluatorNameCompleteness    EvaluatorName = "completeness"
	EvaluatorNameCorrectness     EvaluatorName = "correctness"
	EvaluatorNameFaithfulness    EvaluatorName = "faithfulness"
	EvaluatorNameHelpfulness     EvaluatorName = "helpfulness"
	EvaluatorNameMap             EvaluatorName = "map"
	EvaluatorNameMrr             EvaluatorName = "mrr"
	EvaluatorNameNdcg            EvaluatorName = "ndcg"
	EvaluatorNamePrecision       EvaluatorName = "precision"
	EvaluatorNameRecall          EvaluatorName = "recall"
	EvaluatorNameRelevance       EvaluatorName = "relevance"
	EvaluatorNameSafety          EvaluatorName = "safety"
)

// Defines values for FailedOperationOperation.
const (
	FailedOperationOperationDelete FailedOperationOperation = "delete"
	FailedOperationOperationUpsert FailedOperationOperation = "upsert"
)

// Defines values for FilterSpecOperator.
const (
	FilterSpecOperatorContains FilterSpecOperator = "contains"
	FilterSpecOperatorEq       FilterSpecOperator = "eq"
	FilterSpecOperatorGt       FilterSpecOperator = "gt"
	FilterSpecOperatorGte      FilterSpecOperator = "gte"
	FilterSpecOperatorIn       FilterSpecOperator = "in"
	FilterSpecOperatorLt       FilterSpecOperator = "lt"
	FilterSpecOperatorLte      FilterSpecOperator = "lte"
	FilterSpecOperatorNe       FilterSpecOperator = "ne"
	FilterSpecOperatorPrefix   FilterSpecOperator = "prefix"
	FilterSpecOperatorRange    FilterSpecOperator = "range"
)

// Defines values for Fuzziness1.
const (
	Fuzziness1Auto Fuzziness1 = "auto"
)

// Defines values for GeneratorProvider.
const (
	GeneratorProviderAnthropic  GeneratorProvider = "anthropic"
	GeneratorProviderBedrock    GeneratorProvider = "bedrock"
	GeneratorProviderCohere     GeneratorProvider = "cohere"
	GeneratorProviderGemini     GeneratorProvider = "gemini"
	GeneratorProviderMock       GeneratorProvider = "mock"
	GeneratorProviderOllama     GeneratorProvider = "ollama"
	GeneratorProviderOpenai     GeneratorProvider = "openai"
	GeneratorProviderOpenrouter GeneratorProvider = "openrouter"
	GeneratorProviderTermite    GeneratorProvider = "termite"
	GeneratorProviderVertex     GeneratorProvider = "vertex"
)

// Defines values for GeoShapeGeometryRelation.
const (
	GeoShapeGeometryRelationContains   GeoShapeGeometryRelation = "contains"
	GeoShapeGeometryRelationIntersects GeoShapeGeometryRelation = "intersects"
	GeoShapeGeometryRelationWithin     GeoShapeGeometryRelation = "within"
)

// Defines values for GoogleSearchConfigSearchType.
const (
	GoogleSearchConfigSearchTypeImage GoogleSearchConfigSearchType = "image"
	GoogleSearchConfigSearchTypeWeb   GoogleSearchConfigSearchType = "web"
)

// Defines values for GraphQueryType.
const (
	GraphQueryTypeKShortestPaths GraphQueryType = "k_shortest_paths"
	GraphQueryTypeNeighbors      GraphQueryType = "neighbors"
	GraphQueryTypePattern        GraphQueryType = "pattern"
	GraphQueryTypeShortestPath   GraphQueryType = "shortest_path"
	GraphQueryTypeTraverse       GraphQueryType = "traverse"
)

// Defines values for IndexType.
const (
	IndexTypeAknnV0     IndexType = "aknn_v0"
	IndexTypeFullTextV0 IndexType = "full_text_v0"
	IndexTypeGraphV0    IndexType = "graph_v0"
)

// Defines values for LinearMergePageStatus.
const (
	LinearMergePageStatusError   LinearMergePageStatus = "error"
	LinearMergePageStatusPartial LinearMergePageStatus = "partial"
	LinearMergePageStatusSuccess LinearMergePageStatus = "success"
)

// Defines values for MatchQueryOperator.
const (
	MatchQueryOperatorAnd MatchQueryOperator = "and"
	MatchQueryOperatorOr  MatchQueryOperator = "or"
)

// Defines values for MergeStrategy.
const (
	MergeStrategyFailover MergeStrategy = "failover"
	MergeStrategyRrf      MergeStrategy = "rrf"
	MergeStrategyRsf      MergeStrategy = "rsf"
)

// Defines values for PathFindWeightMode.
const (
	PathFindWeightModeMaxWeight PathFindWeightMode = "max_weight"
	PathFindWeightModeMinHops   PathFindWeightMode = "min_hops"
	PathFindWeightModeMinWeight PathFindWeightMode = "min_weight"
)

// Defines values for PathWeightMode.
const (
	PathWeightModeMaxWeight PathWeightMode = "max_weight"
	PathWeightModeMinHops   PathWeightMode = "min_hops"
	PathWeightModeMinWeight PathWeightMode = "min_weight"
)

// Defines values for PermissionType.
const (
	PermissionTypeAdmin PermissionType = "admin"
	PermissionTypeRead  PermissionType = "read"
	PermissionTypeWrite PermissionType = "write"
)

// Defines values for QueryRequestExpandStrategy.
const (
	QueryRequestExpandStrategyIntersection QueryRequestExpandStrategy = "intersection"
	QueryRequestExpandStrategyUnion        QueryRequestExpandStrategy = "union"
)

// Defines values for QueryStrategy.
const (
	QueryStrategyDecompose QueryStrategy = "decompose"
	QueryStrategyHyde      QueryStrategy = "hyde"
	QueryStrategySimple    QueryStrategy = "simple"
	QueryStrategyStepBack  QueryStrategy = "step_back"
)

// Defines values for RerankerProvider.
const (
	RerankerProviderCohere  RerankerProvider = "cohere"
	RerankerProviderOllama  RerankerProvider = "ollama"
	RerankerProviderTermite RerankerProvider = "termite"
	RerankerProviderVertex  RerankerProvider = "vertex"
)

// Defines values for ResourceType.
const (
	ResourceTypeAsterisk ResourceType = "*"
	ResourceTypeTable    ResourceType = "table"
	ResourceTypeUser     ResourceType = "user"
)

// Defines values for RouteType.
const (
	RouteTypeQuestion RouteType = "question"
	RouteTypeSearch   RouteType = "search"
)

// Defines values for SemanticQueryMode.
const (
	SemanticQueryModeHypothetical SemanticQueryMode = "hypothetical"
	SemanticQueryModeRewrite      SemanticQueryMode = "rewrite"
)

// Defines values for SerperSearchConfigSearchType.
const (
	SerperSearchConfigSearchTypeImages   SerperSearchConfigSearchType = "images"
	SerperSearchConfigSearchTypeNews     SerperSearchConfigSearchType = "news"
	SerperSearchConfigSearchTypePlaces   SerperSearchConfigSearchType = "places"
	SerperSearchConfigSearchTypeSearch   SerperSearchConfigSearchType = "search"
	SerperSearchConfigSearchTypeShopping SerperSearchConfigSearchType = "shopping"
)

// Defines values for SerperSearchConfigTimePeriod.
const (
	SerperSearchConfigTimePeriodD SerperSearchConfigTimePeriod = "d"
	SerperSearchConfigTimePeriodM SerperSearchConfigTimePeriod = "m"
	SerperSearchConfigTimePeriodW SerperSearchConfigTimePeriod = "w"
	SerperSearchConfigTimePeriodY SerperSearchConfigTimePeriod = "y"
)

// Defines values for SignificanceAlgorithm.
const (
	SignificanceAlgorithmChiSquared        SignificanceAlgorithm = "chi_squared"
	SignificanceAlgorithmJlh               SignificanceAlgorithm = "jlh"
	SignificanceAlgorithmMutualInformation SignificanceAlgorithm = "mutual_information"
	SignificanceAlgorithmPercentage        SignificanceAlgorithm = "percentage"
)

// Defines values for SyncLevel.
const (
	SyncLevelAknn        SyncLevel = "aknn"
	SyncLevelEnrichments SyncLevel = "enrichments"
	SyncLevelFullText    SyncLevel = "full_text"
	SyncLevelPropose     SyncLevel = "propose"
	SyncLevelWrite       SyncLevel = "write"
)

// Defines values for TableBackupStatusStatus.
const (
	TableBackupStatusStatusCompleted TableBackupStatusStatus = "completed"
	TableBackupStatusStatusFailed    TableBackupStatusStatus = "failed"
	TableBackupStatusStatusSkipped   TableBackupStatusStatus = "skipped"
)

// Defines values for TableRestoreStatusStatus.
const (
	TableRestoreStatusStatusFailed    TableRestoreStatusStatus = "failed"
	TableRestoreStatusStatusSkipped   TableRestoreStatusStatus = "skipped"
	TableRestoreStatusStatusTriggered TableRestoreStatusStatus = "triggered"
)

// Defines values for TavilySearchConfigSearchDepth.
const (
	TavilySearchConfigSearchDepthAdvanced TavilySearchConfigSearchDepth = "advanced"
	TavilySearchConfigSearchDepthBasic    TavilySearchConfigSearchDepth = "basic"
)

// Defines values for TransformOpType.
const (
	TransformOpTypeAddToSet    TransformOpType = "$addToSet"
	TransformOpTypeCurrentDate TransformOpType = "$currentDate"
	TransformOpTypeInc         TransformOpType = "$inc"
	TransformOpTypeMax         TransformOpType = "$max"
	TransformOpTypeMin         TransformOpType = "$min"
	TransformOpTypeMul         TransformOpType = "$mul"
	TransformOpTypePop         TransformOpType = "$pop"
	TransformOpTypePull        TransformOpType = "$pull"
	TransformOpTypePush        TransformOpType = "$push"
	TransformOpTypeRename      TransformOpType = "$rename"
	TransformOpTypeSet         TransformOpType = "$set"
	TransformOpTypeUnset       TransformOpType = "$unset"
)

// Defines values for WebSearchProvider.
const (
	WebSearchProviderBing       WebSearchProvider = "bing"
	WebSearchProviderBrave      WebSearchProvider = "brave"
	WebSearchProviderDuckduckgo WebSearchProvider = "duckduckgo"
	WebSearchProviderGoogle     WebSearchProvider = "google"
	WebSearchProviderSerper     WebSearchProvider = "serper"
	WebSearchProviderTavily     WebSearchProvider = "tavily"
)

// Defines values for SchemasAntflyType.
const (
	SchemasAntflyTypeBlob            SchemasAntflyType = "blob"
	SchemasAntflyTypeBoolean         SchemasAntflyType = "boolean"
	SchemasAntflyTypeDatetime        SchemasAntflyType = "datetime"
	SchemasAntflyTypeEmbedding       SchemasAntflyType = "embedding"
	SchemasAntflyTypeGeopoint        SchemasAntflyType = "geopoint"
	SchemasAntflyTypeGeoshape        SchemasAntflyType = "geoshape"
	SchemasAntflyTypeHtml            SchemasAntflyType = "html"
	SchemasAntflyTypeKeyword         SchemasAntflyType = "keyword"
	SchemasAntflyTypeLink            SchemasAntflyType = "link"
	SchemasAntflyTypeNumeric         SchemasAntflyType = "numeric"
	SchemasAntflyTypeSearchAsYouType SchemasAntflyType = "search_as_you_type"
	SchemasAntflyTypeText            SchemasAntflyType = "text"
)

// AggregationBucket defines model for AggregationBucket.
type AggregationBucket struct {
	// BgCount Background count (for significant_terms)
	BgCount *int `json:"bg_count,omitempty"`

	// DocCount Number of documents in this bucket
	DocCount int `json:"doc_count"`

	// From Lower bound for range buckets
	From *float64 `json:"from,omitempty"`

	// FromAsString Formatted lower bound
	FromAsString *string `json:"from_as_string,omitempty"`

	// Key Bucket key (term, range name, date, etc.)
	Key string `json:"key"`

	// KeyAsString Formatted key for display (e.g., formatted dates)
	KeyAsString *string `json:"key_as_string,omitempty"`

	// Score Significance score (for significant_terms)
	Score *float64 `json:"score,omitempty"`

	// SubAggregations Results of nested sub-aggregations
	SubAggregations map[string]AggregationResult `json:"sub_aggregations,omitempty,omitzero"`

	// To Upper bound for range buckets
	To *float64 `json:"to,omitempty"`

	// ToAsString Formatted upper bound
	ToAsString *string `json:"to_as_string,omitempty"`
}

// AggregationDateRange defines model for AggregationDateRange.
type AggregationDateRange struct {
	// From Start date (ISO 8601 or relative like "now-7d")
	From *string `json:"from,omitempty"`

	// Name Name of the date range bucket
	Name string `json:"name"`

	// To End date (ISO 8601 or relative like "now")
	To *string `json:"to,omitempty"`
}

// AggregationRange defines model for AggregationRange.
type AggregationRange struct {
	// From Lower bound (inclusive)
	From *float64 `json:"from,omitempty"`

	// Name Name of the range bucket
	Name string `json:"name"`

	// To Upper bound (exclusive)
	To *float64 `json:"to,omitempty"`
}

// AggregationRequest defines model for AggregationRequest.
type AggregationRequest struct {
	// Algorithm Significance algorithm for significant_terms aggregations
	Algorithm *SignificanceAlgorithm `json:"algorithm,omitempty"`

	// BackgroundFilter Background filter for significant_terms aggregations
	BackgroundFilter json.RawMessage `json:"background_filter,omitempty,omitzero"`

	// CalendarInterval Calendar-aware interval for date_histogram aggregations
	CalendarInterval *CalendarInterval `json:"calendar_interval,omitempty"`

	// DateRanges Date ranges for date_range aggregations
	DateRanges []AggregationDateRange `json:"date_ranges,omitempty,omitzero"`

	// DistanceRanges Distance ranges for geo_distance aggregations
	DistanceRanges []DistanceRange `json:"distance_ranges,omitempty,omitzero"`

	// Field Field to aggregate on
	Field string `json:"field"`

	// Interval Fixed interval for histogram aggregations
	Interval *float64 `json:"interval,omitempty"`

	// MinDocCount Minimum document count for a bucket to be included
	MinDocCount *int `json:"min_doc_count,omitempty"`

	// Origin Origin for geohash_grid aggregation (format: "lat,lon")
	// Example: "37.7749,-122.4194"
	Origin *string `json:"origin,omitempty"`

	// Precision Geohash precision (1-12) for geohash_grid aggregations
	Precision *int `json:"precision,omitempty"`

	// Ranges Ranges for range aggregations
	Ranges []AggregationRange `json:"ranges,omitempty,omitzero"`

	// Size Maximum number of buckets to return (for bucketing aggregations)
	Size *int `json:"size,omitempty"`

	// SubAggregations Nested sub-aggregations
	SubAggregations map[string]AggregationRequest `json:"sub_aggregations,omitempty,omitzero"`

	// Type Type of aggregation to compute:
	// - Metrics: sum, avg, min, max, count, sumsquares, stats, cardinality
	// - Bucketing: terms, range, date_range, histogram, date_histogram
	// - Geo: geohash_grid, geo_distance
	// - Analytics: significant_terms
	Type AggregationType `json:"type"`

	// Unit Distance unit for geo_distance aggregations
	Unit *DistanceUnit `json:"unit,omitempty"`
}

// AggregationResult defines model for AggregationResult.
type AggregationResult struct {
	// Avg Average for stats aggregations
	Avg *float64 `json:"avg,omitempty"`

	// Buckets Buckets for bucketing aggregations (terms, range, histogram, etc.)
	Buckets []AggregationBucket `json:"buckets,omitempty,omitzero"`

	// Count Document count for stats aggregations
	Count *int `json:"count,omitempty"`

	// Max Maximum value for stats aggregations
	Max *float64 `json:"max,omitempty"`

	// Min Minimum value for stats aggregations
	Min *float64 `json:"min,omitempty"`

	// StdDeviation Standard deviation for stats aggregations
	StdDeviation *float64 `json:"std_deviation,omitempty"`

	// Sum Sum for stats aggregations
	Sum *float64 `json:"sum,omitempty"`

	// SumOfSquares Sum of squares for stats aggregations
	SumOfSquares *float64 `json:"sum_of_squares,omitempty"`

	// Value Single value for metric aggregations (sum, avg, min, max, count, cardinality)
	Value *float64 `json:"value,omitempty"`

	// Variance Variance for stats aggregations
	Variance *float64 `json:"variance,omitempty"`
}

// AggregationType Type of aggregation to compute:
// - Metrics: sum, avg, min, max, count, sumsquares, stats, cardinality
// - Bucketing: terms, range, date_range, histogram, date_histogram
// - Geo: geohash_grid, geo_distance
// - Analytics: significant_terms
type AggregationType string

// Analyses defines model for Analyses.
type Analyses struct {
	Pca  bool `json:"pca,omitempty,omitzero"`
	Tsne bool `json:"tsne,omitempty,omitzero"`
}

// AnalysesResult defines model for AnalysesResult.
type AnalysesResult struct {
	Pca  []float64 `json:"pca,omitempty,omitzero"`
	Tsne []float64 `json:"tsne,omitempty,omitzero"`
}

// AnswerAgentRequest defines model for AnswerAgentRequest.
type AnswerAgentRequest struct {
	// AgentKnowledge Background knowledge that guides the agent's understanding of the domain.
	// Similar to CLAUDE.md, this provides context that applies to all steps
	// (classification, retrieval, and answer generation).
	//
	// Examples:
	// - "This data contains medical records. Use clinical terminology and be precise about diagnoses."
	// - "This is a software engineering knowledge base. Assume a technical audience."
	// - "This table stores legal documents. Reference laws and regulations accurately."
	AgentKnowledge string `json:"agent_knowledge,omitempty,omitzero"`

	// Chain Default chain of generators for all pipeline steps unless overridden in `steps`.
	// Each link can specify retry configuration and a condition for trying the next generator.
	// Mutually exclusive with 'generator'. Either 'generator' or 'chain' must be provided.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Eval Configuration for inline evaluation of query results.
	// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
	Eval EvalConfig `json:"eval,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// MaxContextTokens Maximum total tokens allowed for retrieved document context.
	// When set, documents are pruned (lowest-ranked first) to fit within this budget.
	// Useful for ensuring LLM context limits are not exceeded.
	// Uses BERT tokenizer for estimation.
	MaxContextTokens int `json:"max_context_tokens,omitempty,omitzero"`

	// Queries Array of query requests to execute. The query text will be transformed for semantic search
	// and populated into the semantic_search field of each query.
	Queries []QueryRequest `json:"queries"`

	// Query User's natural language query to be classified and improved
	Query string `json:"query"`

	// ReserveTokens Tokens to reserve for system prompt, answer generation, and other overhead.
	// Subtracted from max_context_tokens to determine available context budget.
	// Defaults to 4000 if max_context_tokens is set.
	ReserveTokens int `json:"reserve_tokens,omitempty,omitzero"`

	// Steps Per-step configuration for the answer agent pipeline. Each step can have
	// its own generator (or chain of generators) and step-specific options.
	// If a step is not configured, it uses the top-level generator as default.
	Steps AnswerAgentSteps `json:"steps,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results (classification, queries, results, answer) instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`

	// WithoutGeneration When true, skip AI answer generation and return search results only.
	// Useful when you want search quality without LLM cost, such as for
	// quota management or rate limiting scenarios.
	WithoutGeneration bool `json:"without_generation,omitempty,omitzero"`
}

// AnswerAgentResult defines model for AnswerAgentResult.
type AnswerAgentResult struct {
	// Answer Generated answer in markdown format
	Answer string `json:"answer"`

	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0)
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// ClassificationTransformation Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
	ClassificationTransformation ClassificationTransformationResult `json:"classification_transformation,omitempty,omitzero"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance,omitempty,omitzero"`

	// EvalResult Complete evaluation result
	EvalResult EvalResult `json:"eval_result,omitempty,omitzero"`

	// FollowupQuestions Suggested follow-up questions
	FollowupQuestions []string `json:"followup_questions,omitempty,omitzero"`

	// QueryResults Results from each executed query
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`
}

// AnswerAgentSteps Per-step configuration for the answer agent pipeline. Each step can have
// its own generator (or chain of generators) and step-specific options.
// If a step is not configured, it uses the top-level generator as default.
type AnswerAgentSteps struct {
	// Answer Configuration for the answer generation step. This step generates the final
	// answer from retrieved documents using the reasoning as context.
	Answer AnswerStepConfig `json:"answer,omitempty,omitzero"`

	// Classification Configuration for the classification step. This step analyzes the query,
	// selects the optimal retrieval strategy, and generates semantic transformations.
	Classification ClassificationStepConfig `json:"classification,omitempty,omitzero"`

	// Confidence Configuration for confidence assessment. Evaluates answer quality and
	// resource relevance. Can use a model calibrated for scoring tasks.
	Confidence ConfidenceStepConfig `json:"confidence,omitempty,omitzero"`

	// Followup Configuration for generating follow-up questions. Uses a separate generator
	// call which can use a cheaper/faster model.
	Followup FollowupStepConfig `json:"followup,omitempty,omitzero"`
}

// AnswerConfidence Confidence assessment for the generated answer
type AnswerConfidence struct {
	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0). Considers both ability to answer from provided resources and general knowledge.
	AnswerConfidence float32 `json:"answer_confidence"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance"`
}

// AnswerResult Result from answer generation with optional confidence and follow-up questions
type AnswerResult struct {
	// Answer Generated answer in markdown format
	Answer string `json:"answer"`

	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0)
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance,omitempty,omitzero"`

	// FollowupQuestions Suggested follow-up questions
	FollowupQuestions []string `json:"followup_questions,omitempty,omitzero"`
}

// AnswerStepConfig Configuration for the answer generation step. This step generates the final
// answer from retrieved documents using the reasoning as context.
type AnswerStepConfig struct {
	// AnswerContext Custom guidance for answer tone, detail level, and style
	AnswerContext string `json:"answer_context,omitempty,omitzero"`

	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// SystemPrompt Custom system prompt for answer generation
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`
}

// AntflyChunkerConfig defines model for AntflyChunkerConfig.
type AntflyChunkerConfig struct {
	// FullText Configuration for full-text indexing of chunks in Bleve.
	// When present (even if empty), chunks will be stored with :cft: suffix and indexed in Bleve's _chunks field.
	// When absent, chunks use :c: suffix and are only used for vector embeddings.
	// This object is reserved for future options like boosting, field mapping, etc.
	FullText map[string]interface{} `json:"full_text,omitempty,omitzero"`

	// MaxChunks Maximum number of chunks to generate per document.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries. Only used by fixed-size chunkers.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs). Only used by fixed-size chunkers.
	Separator string `json:"separator,omitempty,omitzero"`

	// TargetTokens Target number of tokens per chunk.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`

	// Threshold Minimum confidence threshold for separator detection (0.0-1.0). Only used by ONNX models.
	Threshold float32 `json:"threshold,omitempty,omitzero"`
}

// AntflyType defines model for AntflyType.
type AntflyType string

// AnthropicGeneratorConfig Configuration for the Anthropic generative AI provider (Claude models).
//
// API key via `api_key` field or `ANTHROPIC_API_KEY` environment variable.
//
// **Example Models:** claude-sonnet-4-5-20250929 (default), claude-opus-4-5-20251101, claude-3-5-haiku-20241022
//
// **Docs:** https://docs.anthropic.com/en/docs/about-claude/models/overview
type AnthropicGeneratorConfig struct {
	// ApiKey The Anthropic API key. If not provided, falls back to ANTHROPIC_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The full model ID of the Anthropic model to use (e.g., 'claude-sonnet-4-5-20250929', 'claude-opus-4-5-20251101').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-1.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Anthropic API endpoint (optional, uses default if not specified).
	Url string `json:"url,omitempty,omitzero"`
}

// BackupInfo defines model for BackupInfo.
type BackupInfo struct {
	// AntflyVersion Antfly version that created the backup
	AntflyVersion string `json:"antfly_version,omitempty,omitzero"`

	// BackupId The backup identifier
	BackupId string `json:"backup_id"`

	// Location Storage location of the backup
	Location string `json:"location"`

	// Tables Tables included in the backup
	Tables []string `json:"tables"`

	// Timestamp When the backup was created
	Timestamp time.Time `json:"timestamp"`
}

// BackupListResponse defines model for BackupListResponse.
type BackupListResponse struct {
	// Backups List of available backups
	Backups []BackupInfo `json:"backups"`
}

// BackupRequest defines model for BackupRequest.
type BackupRequest struct {
	// BackupId Unique identifier for this backup. Used to reference the backup for restore operations.
	// Choose a meaningful name that includes date/version information.
	BackupId string `json:"backup_id"`

	// Location Storage location for the backup. Supports multiple backends:
	// - Local filesystem: `file:///path/to/backup`
	// - Amazon S3: `s3://bucket-name/path/to/backup`
	//
	// The backup includes all table data, indexes, and metadata for the specified table.
	Location string `json:"location"`
}

// BatchRequest Batch insert, delete, and transform operations in a single request.
//
// **Atomicity**:
// - **Single shard**: Operations are atomic within shard boundaries
// - **Multiple shards**: Uses distributed 2-phase commit (2PC) for atomic cross-shard writes
//
// **How distributed transactions work**:
// 1. Metadata server allocates HLC timestamp and selects coordinator shard
// 2. Coordinator writes transaction record, participants write intents
// 3. After all intents succeed, coordinator commits transaction
// 4. Participants are notified asynchronously to resolve intents
// 5. Recovery loop ensures notifications complete even after coordinator failure
//
// **Performance**:
// - Single-shard batches: < 5ms latency
// - Cross-shard transactions: ~20ms latency
// - Intent resolution: < 30 seconds worst-case (via recovery loop)
//
// **Guarantees**:
// - All writes succeed or all fail (atomicity across all shards)
// - Coordinator failure is recoverable (new leader resumes notifications)
// - Idempotent resolution (duplicate notifications are safe)
//
// **Benefits**:
// - Reduces network overhead compared to individual requests
// - More efficient indexing (updates are batched)
// - Automatic distributed transactions when operations span shards
//
// The inserts are upserts - existing keys are overwritten, new keys are created.
type BatchRequest struct {
	// Deletes Array of document IDs to delete. Documents are removed from all indexes.
	//
	// Notes:
	// - Non-existent keys are silently ignored
	// - Deletions are processed before inserts in the same batch
	// - Keys are permanently removed from storage and indexes
	Deletes []string `json:"deletes,omitempty,omitzero"`

	// Inserts Map of document IDs to document objects. Each key is the unique identifier for the document.
	//
	// Best practices:
	// - Use consistent key naming schemes (e.g., "user:123", "article:456")
	// - Key length affects storage and performance - keep them reasonably short
	// - Keys are sorted lexicographically, so choose prefixes that support range scans
	Inserts map[string]map[string]interface{} `json:"inserts,omitempty,omitzero"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write
	// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`

	// Transforms Array of transform operations for in-place document updates using MongoDB-style operators.
	//
	// Transform operations allow you to modify documents without read-modify-write races:
	// - Operations are applied atomically on the server
	// - Multiple operations per document are applied in sequence
	// - Supports numeric operations ($inc, $mul), array operations ($push, $pull), and more
	//
	// Common use cases:
	// - Increment counters (views, likes, votes)
	// - Update timestamps ($currentDate)
	// - Manage arrays (add/remove tags, items)
	// - Update nested fields without overwriting the entire document
	Transforms []Transform `json:"transforms,omitempty,omitzero"`
}

// BatchResponse defines model for BatchResponse.
type BatchResponse struct {
	// Deleted Number of documents successfully deleted
	Deleted int `json:"deleted,omitempty,omitzero"`

	// Inserted Number of documents successfully inserted
	Inserted int `json:"inserted,omitempty,omitzero"`

	// Transformed Number of documents successfully transformed
	Transformed int `json:"transformed,omitempty,omitzero"`
}

// BedrockEmbedderConfig Configuration for the AWS Bedrock embedding provider.
//
// Uses AWS credentials from environment or IAM roles.
//
// **Example Models:** cohere.embed-english-v4, amazon.titan-embed-text-v2:0
//
// **Docs:** https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html
type BedrockEmbedderConfig struct {
	// BatchSize The batch size for embedding requests to optimize throughput.
	BatchSize int `json:"batch_size,omitempty,omitzero"`

	// Model The Bedrock model ID to use (e.g., 'cohere.embed-english-v4', 'amazon.titan-embed-text-v2:0').
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service (e.g., 'us-east-1').
	Region string `json:"region,omitempty,omitzero"`

	// StripNewLines Whether to strip new lines from the input text before embedding.
	StripNewLines bool `json:"strip_new_lines,omitempty,omitzero"`
}

// BedrockGeneratorConfig Configuration for the AWS Bedrock generative AI provider.
//
// Provides access to models from Anthropic, Meta, Amazon, Cohere, Mistral, and others.
//
// **Example Models:** anthropic.claude-sonnet-4-5-20250929-v1:0, meta.llama3-3-70b-instruct-v1:0, amazon.nova-pro-v1:0
//
// **Docs:** https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html
type BedrockGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The Bedrock model ID to use (e.g., 'anthropic.claude-sonnet-4-5-20250929-v1:0').
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service.
	Region string `json:"region,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-1.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// BingSearchConfig defines model for BingSearchConfig.
type BingSearchConfig struct {
	// ApiKey Bing Search API key (or set BING_SEARCH_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Endpoint Bing API endpoint URL
	Endpoint string `json:"endpoint,omitempty,omitzero"`

	// Freshness Filter results by freshness
	Freshness BingSearchConfigFreshness `json:"freshness,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// BingSearchConfigFreshness Filter results by freshness
type BingSearchConfigFreshness string

// BleveIndexV2Config defines model for BleveIndexV2Config.
type BleveIndexV2Config struct {
	// MemOnly Whether to use memory-only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`
}

// BleveIndexV2Stats defines model for BleveIndexV2Stats.
type BleveIndexV2Stats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// Rebuilding Whether the index is currently rebuilding
	Rebuilding bool `json:"rebuilding,omitempty,omitzero"`

	// TotalIndexed Number of documents in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`
}

// BoolFieldQuery defines model for BoolFieldQuery.
type BoolFieldQuery struct {
	Bool bool `json:"bool"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
}

// BooleanQuery defines model for BooleanQuery.
type BooleanQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost   Boost            `json:"boost,omitzero"`
	Filter  Query            `json:"filter,omitempty,omitzero"`
	Must    ConjunctionQuery `json:"must,omitempty,omitzero"`
	MustNot DisjunctionQuery `json:"must_not,omitempty,omitzero"`
	Should  DisjunctionQuery `json:"should,omitempty,omitzero"`
}

// Boost A floating-point number used to decrease or increase the relevance scores of a query.
type Boost = float64

// BraveSearchConfig defines model for BraveSearchConfig.
type BraveSearchConfig struct {
	// ApiKey Brave Search API key (or set BRAVE_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Freshness Freshness filter: pd=day, pw=week, pm=month, py=year
	Freshness BraveSearchConfigFreshness `json:"freshness,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// Spellcheck Enable spellcheck suggestions
	Spellcheck bool `json:"spellcheck,omitempty,omitzero"`

	// TextDecorations Include text decorations (bold, italic markers)
	TextDecorations bool `json:"text_decorations,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// BraveSearchConfigFreshness Freshness filter: pd=day, pw=week, pm=month, py=year
type BraveSearchConfigFreshness string

// ByteRange defines model for ByteRange.
type ByteRange = [][]byte

// CalendarInterval Calendar-aware interval for date_histogram aggregations
type CalendarInterval string

// ChainCondition Condition for trying the next generator in chain:
// - always: Always try next regardless of outcome
// - on_error: Try next on any error (default)
// - on_timeout: Try next only on timeout errors
// - on_rate_limit: Try next only on rate limit errors
type ChainCondition string

// ChainLink A single link in a generator chain with optional retry and condition
type ChainLink struct {
	// Condition Condition for trying the next generator in chain:
	// - always: Always try next regardless of outcome
	// - on_error: Try next on any error (default)
	// - on_timeout: Try next only on timeout errors
	// - on_rate_limit: Try next only on rate limit errors
	Condition ChainCondition `json:"condition,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator"`

	// Retry Retry configuration for generator calls
	Retry RetryConfig `json:"retry,omitempty,omitzero"`
}

// ChatAgentRequest defines model for ChatAgentRequest.
type ChatAgentRequest struct {
	// AccumulatedFilters Filters accumulated from previous conversation turns.
	// These are applied to all queries automatically.
	// New filters discovered in this turn will be added to this list in the response.
	AccumulatedFilters []FilterSpec `json:"accumulated_filters,omitempty,omitzero"`

	// AgentKnowledge Background knowledge that guides the agent's understanding of the domain.
	// Similar to CLAUDE.md, this provides context that applies to all steps
	// (classification, retrieval, and answer generation).
	//
	// Example: "This is a technical documentation search. Results should be
	// filtered to only include official documentation, not community posts."
	AgentKnowledge string `json:"agent_knowledge,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator"`

	// MaxContextTokens Maximum tokens for retrieved document context
	MaxContextTokens int `json:"max_context_tokens,omitempty,omitzero"`

	// Messages Conversation history. Include all previous messages to maintain context.
	// The last message should typically be from the user.
	Messages []ChatMessage `json:"messages"`

	// Queries Base query configurations. The chat agent will modify these queries
	// based on conversation context, applying filters and transformations.
	Queries []QueryRequest `json:"queries"`

	// Steps Per-step configuration for the chat agent pipeline. Similar to AnswerAgentSteps
	// but includes tool-specific configuration.
	Steps ChatAgentSteps `json:"steps,omitempty,omitzero"`

	// SystemPrompt Optional custom system prompt for the chat agent.
	// If not provided, uses a default conversational RAG prompt.
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// ChatAgentResult defines model for ChatAgentResult.
type ChatAgentResult struct {
	// Answer Final answer text (if available)
	Answer string `json:"answer,omitempty,omitzero"`

	// AnswerConfidence Confidence in the answer
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// AppliedFilters Filters that have been applied in this conversation
	AppliedFilters []FilterSpec `json:"applied_filters,omitempty,omitzero"`

	// ClassificationTransformation Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
	ClassificationTransformation ClassificationTransformationResult `json:"classification_transformation,omitempty,omitzero"`

	// Messages Updated conversation history including the assistant's response
	Messages []ChatMessage `json:"messages"`

	// PendingClarification A request for clarification from the user
	PendingClarification ClarificationRequest `json:"pending_clarification,omitempty,omitzero"`

	// QueryResults Search results from executed queries
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`

	// ToolCallsMade Number of tool calls made in this turn
	ToolCallsMade int `json:"tool_calls_made,omitempty,omitzero"`
}

// ChatAgentSteps Per-step configuration for the chat agent pipeline. Similar to AnswerAgentSteps
// but includes tool-specific configuration.
type ChatAgentSteps struct {
	// Answer Configuration for the answer generation step. This step generates the final
	// answer from retrieved documents using the reasoning as context.
	Answer AnswerStepConfig `json:"answer,omitempty,omitzero"`

	// Classification Configuration for the classification step. This step analyzes the query,
	// selects the optimal retrieval strategy, and generates semantic transformations.
	Classification ClassificationStepConfig `json:"classification,omitempty,omitzero"`

	// Confidence Configuration for confidence assessment. Evaluates answer quality and
	// resource relevance. Can use a model calibrated for scoring tasks.
	Confidence ConfidenceStepConfig `json:"confidence,omitempty,omitzero"`

	// Tools Configuration for chat agent tools.
	//
	// If `enabled_tools` is empty/omitted, defaults to: add_filter, ask_clarification, search.
	//
	// For models that don't support native tool calling (e.g., Ollama),
	// a prompt-based fallback is used with structured output parsing.
	Tools ChatToolsConfig `json:"tools,omitempty,omitzero"`
}

// ChatMessage A message in the conversation history
type ChatMessage struct {
	// Content Text content of the message
	Content string `json:"content"`

	// Role Role of the message sender in the conversation
	Role ChatMessageRole `json:"role"`

	// ToolCalls Tool calls made by the assistant (only for assistant role)
	ToolCalls []ChatToolCall `json:"tool_calls,omitempty,omitzero"`

	// ToolResults Results from tool executions (only for tool role)
	ToolResults []ChatToolResult `json:"tool_results,omitempty,omitzero"`
}

// ChatMessageRole Role of the message sender in the conversation
type ChatMessageRole string

// ChatToolCall A tool call made by the assistant
type ChatToolCall struct {
	// Arguments Arguments passed to the tool as key-value pairs
	Arguments map[string]interface{} `json:"arguments"`

	// Id Unique identifier for this tool call
	Id string `json:"id"`

	// Name Name of the tool being called
	Name string `json:"name"`
}

// ChatToolName Available tool names for the chat agent.
// - add_filter: Add search filters (field constraints)
// - ask_clarification: Ask user for clarification
// - search: Execute semantic searches
// - websearch: Search the web (requires websearch_config)
// - fetch: Fetch URL content (subject to security controls)
type ChatToolName string

// ChatToolResult Result from executing a tool call
type ChatToolResult struct {
	// Error Error message if tool execution failed
	Error string `json:"error,omitempty,omitzero"`

	// Result Result data from the tool execution
	Result map[string]interface{} `json:"result"`

	// ToolCallId ID of the tool call this result corresponds to
	ToolCallId string `json:"tool_call_id"`
}

// ChatToolsConfig Configuration for chat agent tools.
//
// If `enabled_tools` is empty/omitted, defaults to: add_filter, ask_clarification, search.
//
// For models that don't support native tool calling (e.g., Ollama),
// a prompt-based fallback is used with structured output parsing.
type ChatToolsConfig struct {
	// EnabledTools List of tools to enable. If empty, defaults to filter, clarification, and search.
	EnabledTools []ChatToolName `json:"enabled_tools,omitempty,omitzero"`

	// FetchConfig Configuration for URL content fetching.
	//
	// Uses lib/scraping for downloading and processing. Supports:
	// - HTTP/HTTPS URLs with security validation
	// - HTML pages (extracts readable text via go-readability)
	// - PDF files (extracts text)
	// - Images (returns as data URIs)
	// - Plain text files
	// - S3 URLs (requires s3_credentials)
	//
	// Security features (from lib/scraping.ContentSecurityConfig):
	// - Allowed host whitelist
	// - Private IP blocking (SSRF prevention)
	// - Download size limits
	// - Timeout controls
	FetchConfig FetchConfig `json:"fetch_config,omitempty,omitzero"`

	// MaxToolIterations Maximum number of tool call iterations per turn.
	// Prevents infinite loops in tool execution.
	MaxToolIterations int `json:"max_tool_iterations,omitempty,omitzero"`

	// WebsearchConfig A unified configuration for web search providers.
	//
	// Each provider has specific configuration requirements. Use the appropriate
	// provider-specific config or set common options at the top level.
	//
	// **Environment Variables (fallbacks):**
	// - GOOGLE_CSE_API_KEY, GOOGLE_CSE_ID
	// - BING_SEARCH_API_KEY
	// - SERPER_API_KEY
	// - TAVILY_API_KEY
	// - BRAVE_API_KEY
	WebsearchConfig WebSearchConfig `json:"websearch_config,omitempty,omitzero"`
}

// ChunkOptions Per-request configuration for chunking. All fields are optional - zero/omitted values use chunker defaults.
type ChunkOptions struct {
	// MaxChunks Maximum number of chunks to generate per document.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries. Only used by fixed-size chunkers.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs). Only used by fixed-size chunkers.
	Separator string `json:"separator,omitempty,omitzero"`

	// TargetTokens Target number of tokens per chunk.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`

	// Threshold Minimum confidence threshold for separator detection (0.0-1.0). Only used by ONNX models.
	Threshold float32 `json:"threshold,omitempty,omitzero"`
}

// ChunkerConfig defines model for ChunkerConfig.
type ChunkerConfig struct {
	// Provider The chunking provider to use.
	Provider ChunkerProvider `json:"provider"`
	union    json.RawMessage
}

// ChunkerProvider The chunking provider to use.
type ChunkerProvider string

// ClarificationRequest A request for clarification from the user
type ClarificationRequest struct {
	// Options Optional list of suggested answers for the user to choose from
	Options []string `json:"options,omitempty,omitzero"`

	// Question The clarifying question to ask the user
	Question string `json:"question"`

	// Required Whether the clarification is required before proceeding
	Required bool `json:"required,omitempty,omitzero"`
}

// ClassificationStepConfig Configuration for the classification step. This step analyzes the query,
// selects the optimal retrieval strategy, and generates semantic transformations.
type ClassificationStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// ForceSemanticMode Mode for semantic query generation:
	// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
	// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
	ForceSemanticMode SemanticQueryMode `json:"force_semantic_mode,omitempty,omitzero"`

	// ForceStrategy Strategy for query transformation and retrieval:
	// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
	// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
	// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
	// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
	ForceStrategy QueryStrategy `json:"force_strategy,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// MultiPhraseCount Number of alternative query phrasings to generate
	MultiPhraseCount int `json:"multi_phrase_count,omitempty,omitzero"`

	// WithReasoning Include pre-retrieval reasoning explaining query analysis and strategy selection
	WithReasoning bool `json:"with_reasoning,omitempty,omitzero"`
}

// ClassificationTransformationResult Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
type ClassificationTransformationResult struct {
	// Confidence Classification confidence (0.0 to 1.0)
	Confidence float32 `json:"confidence"`

	// ImprovedQuery Clarified query with added context for answer generation (human-readable)
	ImprovedQuery string `json:"improved_query"`

	// MultiPhrases Alternative phrasings of the query for expanded retrieval coverage
	MultiPhrases []string `json:"multi_phrases,omitempty,omitzero"`

	// Reasoning Pre-retrieval reasoning explaining query analysis and strategy selection (only present when with_classification_reasoning is enabled)
	Reasoning string `json:"reasoning,omitempty,omitzero"`

	// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
	RouteType RouteType `json:"route_type"`

	// SemanticMode Mode for semantic query generation:
	// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
	// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
	SemanticMode SemanticQueryMode `json:"semantic_mode"`

	// SemanticQuery Optimized query for vector/semantic search. Content style depends on semantic_mode: keywords for 'rewrite', hypothetical answer for 'hypothetical'
	SemanticQuery string `json:"semantic_query"`

	// StepBackQuery Broader background query for context (only present when strategy is 'step_back')
	StepBackQuery string `json:"step_back_query,omitempty,omitzero"`

	// Strategy Strategy for query transformation and retrieval:
	// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
	// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
	// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
	// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
	Strategy QueryStrategy `json:"strategy"`

	// SubQuestions Decomposed sub-questions (only present when strategy is 'decompose')
	SubQuestions []string `json:"sub_questions,omitempty,omitzero"`
}

// ClusterBackupRequest defines model for ClusterBackupRequest.
type ClusterBackupRequest struct {
	// BackupId Unique identifier for this backup. Used to reference the backup for restore operations.
	// Choose a meaningful name that includes date/version information.
	BackupId string `json:"backup_id"`

	// Location Storage location for the backup. Supports multiple backends:
	// - Local filesystem: `file:///path/to/backup`
	// - Amazon S3: `s3://bucket-name/path/to/backup`
	//
	// The backup includes all table data, indexes, and metadata.
	Location string `json:"location"`

	// TableNames Optional list of tables to backup. If omitted, all tables are backed up.
	TableNames []string `json:"table_names,omitempty,omitzero"`
}

// ClusterBackupResponse defines model for ClusterBackupResponse.
type ClusterBackupResponse struct {
	// BackupId The backup identifier
	BackupId string `json:"backup_id"`

	// Status Overall backup status
	Status ClusterBackupResponseStatus `json:"status"`

	// Tables Status of each table backup
	Tables []TableBackupStatus `json:"tables"`
}

// ClusterBackupResponseStatus Overall backup status
type ClusterBackupResponseStatus string

// ClusterHealth Overall health status of the cluster
type ClusterHealth string

// ClusterRestoreRequest defines model for ClusterRestoreRequest.
type ClusterRestoreRequest struct {
	// BackupId Unique identifier of the backup to restore from.
	BackupId string `json:"backup_id"`

	// Location Storage location where the backup is stored.
	Location string `json:"location"`

	// RestoreMode How to handle existing tables:
	// - `fail_if_exists`: Abort if any table already exists (default)
	// - `skip_if_exists`: Skip existing tables, restore others
	// - `overwrite`: Drop and recreate existing tables
	RestoreMode ClusterRestoreRequestRestoreMode `json:"restore_mode,omitempty,omitzero"`

	// TableNames Optional list of tables to restore. If omitted, all tables in the backup are restored.
	TableNames []string `json:"table_names,omitempty,omitzero"`
}

// ClusterRestoreRequestRestoreMode How to handle existing tables:
// - `fail_if_exists`: Abort if any table already exists (default)
// - `skip_if_exists`: Skip existing tables, restore others
// - `overwrite`: Drop and recreate existing tables
type ClusterRestoreRequestRestoreMode string

// ClusterRestoreResponse defines model for ClusterRestoreResponse.
type ClusterRestoreResponse struct {
	// Status Overall restore status
	Status ClusterRestoreResponseStatus `json:"status"`

	// Tables Status of each table restore
	Tables []TableRestoreStatus `json:"tables"`
}

// ClusterRestoreResponseStatus Overall restore status
type ClusterRestoreResponseStatus string

// ClusterStatus defines model for ClusterStatus.
type ClusterStatus struct {
	// AuthEnabled Indicates whether authentication is enabled for the cluster
	AuthEnabled bool `json:"auth_enabled,omitempty"`

	// Health Overall health status of the cluster
	Health ClusterHealth `json:"health"`

	// Message Optional message providing details about the health status
	Message              string                 `json:"message,omitempty,omitzero"`
	AdditionalProperties map[string]interface{} `json:"-"`
}

// CohereEmbedderConfig Configuration for the Cohere embedding provider.
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** embed-english-v3.0 (default, 1024 dims), embed-multilingual-v3.0
//
// **Docs:** https://docs.cohere.com/reference/embed
type CohereEmbedderConfig struct {
	// ApiKey The Cohere API key. Can also be set via COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// InputType Specifies the type of input for optimized embeddings.
	InputType CohereEmbedderConfigInputType `json:"input_type,omitempty,omitzero"`

	// Model The name of the Cohere embedding model to use.
	Model string `json:"model"`

	// Truncate How to handle inputs longer than the max token length.
	Truncate CohereEmbedderConfigTruncate `json:"truncate,omitempty,omitzero"`
}

// CohereEmbedderConfigInputType Specifies the type of input for optimized embeddings.
type CohereEmbedderConfigInputType string

// CohereEmbedderConfigTruncate How to handle inputs longer than the max token length.
type CohereEmbedderConfigTruncate string

// CohereGeneratorConfig Configuration for the Cohere generative AI provider (Command models).
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** command-r-plus (default), command-r, command-a-03-2025
//
// **Docs:** https://docs.cohere.com/reference/chat
type CohereGeneratorConfig struct {
	// ApiKey The Cohere API key. If not provided, falls back to COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (0.0-1.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Cohere model to use.
	Model string `json:"model"`

	// PresencePenalty Penalty for token presence (0.0-1.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-1.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// CohereRerankerConfig Configuration for the Cohere reranking provider.
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** rerank-english-v3.0 (default), rerank-multilingual-v3.0
//
// **Docs:** https://docs.cohere.com/reference/rerank
type CohereRerankerConfig struct {
	// ApiKey The Cohere API key. Can also be set via COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// MaxChunksPerDoc Maximum number of chunks per document for long document handling.
	MaxChunksPerDoc int `json:"max_chunks_per_doc,omitempty,omitzero"`

	// Model The name of the Cohere reranking model to use.
	Model string `json:"model"`

	// TopN Number of most relevant documents to return. If not specified, returns all documents with scores.
	TopN int `json:"top_n,omitempty,omitzero"`
}

// ConfidenceStepConfig Configuration for confidence assessment. Evaluates answer quality and
// resource relevance. Can use a model calibrated for scoring tasks.
type ConfidenceStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Context Custom guidance for confidence assessment approach
	Context string `json:"context,omitempty,omitzero"`

	// Enabled Enable confidence scoring
	Enabled bool `json:"enabled,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`
}

// ConjunctionQuery defines model for ConjunctionQuery.
type ConjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Conjuncts []Query `json:"conjuncts"`
}

// CreateTableRequest defines model for CreateTableRequest.
type CreateTableRequest struct {
	// Description Optional human-readable description of the table and its purpose.
	// Useful for documentation and team collaboration.
	Description string `json:"description,omitempty,omitzero"`

	// Indexes Map of index name to index configuration. Indexes enable different query capabilities:
	// - Full-text indexes for BM25 search
	// - Vector indexes for semantic similarity
	// - Multimodal indexes for images/audio/video
	//
	// You can add multiple indexes to support different query patterns.
	Indexes map[string]IndexConfig `json:"indexes,omitempty,omitzero"`

	// NumShards Number of shards to create for the table. Data is partitioned across shards based on key ranges.
	//
	// **Sizing Guidelines:**
	// - Small datasets (<100K docs): 1-3 shards
	// - Medium datasets (100K-1M docs): 3-10 shards
	// - Large datasets (>1M docs): 10+ shards
	//
	// More shards enable better parallelism but increase overhead. Choose based on expected data size and query patterns.
	//
	// **When to Add More Shards:**
	//
	// Antfly supports **online shard reallocation** without downtime. Add more shards when:
	// - Individual shards exceed size thresholds (configurable)
	// - Query latency increases due to large shard size
	// - Need better parallelism for write-heavy workloads
	//
	// Use the internal `/reallocate` endpoint to trigger automatic shard splitting:
	// ```bash
	// POST /_internal/v1/reallocate
	// ```
	//
	// This enqueues a reallocation request that the leader processes asynchronously, splitting
	// large shards and redistributing data without service interruption.
	//
	// **Advantages over Elasticsearch:**
	// - Automatic shard splitting (no manual reindexing required)
	// - Online operation (no downtime)
	// - Transparent to applications (keys remain accessible during reallocation)
	NumShards uint `json:"num_shards,omitempty,omitzero"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema `json:"schema,omitempty,omitzero"`
}

// CreateUserRequest defines model for CreateUserRequest.
type CreateUserRequest struct {
	// InitialPolicies Optional list of initial permissions for the user.
	InitialPolicies []Permission `json:"initial_policies,omitzero"`
	Password        string       `json:"password"`

	// Username Username for the new user. If provided in the path, this field can be omitted or must match the path parameter.
	Username string `json:"username,omitempty,omitzero"`
}

// Credentials defines model for Credentials.
type Credentials struct {
	// AccessKeyId AWS access key ID. Supports keystore syntax for secret lookup. Falls back to AWS_ACCESS_KEY_ID environment variable if not set.
	AccessKeyId string `json:"access_key_id,omitempty,omitzero"`

	// Endpoint S3-compatible endpoint (e.g., 's3.amazonaws.com' or 'localhost:9000' for MinIO)
	Endpoint string `json:"endpoint,omitempty,omitzero"`

	// SecretAccessKey AWS secret access key. Supports keystore syntax for secret lookup. Falls back to AWS_SECRET_ACCESS_KEY environment variable if not set.
	SecretAccessKey string `json:"secret_access_key,omitempty,omitzero"`

	// SessionToken Optional AWS session token for temporary credentials. Supports keystore syntax for secret lookup.
	SessionToken string `json:"session_token,omitempty,omitzero"`

	// UseSsl Enable SSL/TLS for S3 connections (default: true for AWS, false for local MinIO)
	UseSsl bool `json:"use_ssl,omitempty,omitzero"`
}

// DateRangeStringQuery defines model for DateRangeStringQuery.
type DateRangeStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost          Boost     `json:"boost,omitzero"`
	DatetimeParser string    `json:"datetime_parser,omitempty,omitzero"`
	End            time.Time `json:"end,omitempty,omitzero"`
	Field          string    `json:"field,omitempty,omitzero"`
	InclusiveEnd   bool      `json:"inclusive_end,omitzero"`
	InclusiveStart bool      `json:"inclusive_start,omitzero"`
	Start          time.Time `json:"start,omitempty,omitzero"`
}

// DisjunctionQuery defines model for DisjunctionQuery.
type DisjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Disjuncts []Query `json:"disjuncts"`
	Min       float64 `json:"min,omitempty,omitzero"`
}

// DistanceRange defines model for DistanceRange.
type DistanceRange struct {
	// From Minimum distance (inclusive)
	From *float64 `json:"from,omitempty"`

	// Name Name of the distance range bucket
	Name string `json:"name"`

	// To Maximum distance (exclusive)
	To *float64 `json:"to,omitempty"`
}

// DistanceUnit Distance unit for geo aggregations:
// - m: meters
// - km: kilometers
// - mi: miles
// - ft: feet
// - yd: yards
type DistanceUnit string

// DocIdQuery defines model for DocIdQuery.
type DocIdQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost    `json:"boost,omitzero"`
	Ids   []string `json:"ids"`
}

// DocumentSchema Defines the structure of a document type
type DocumentSchema struct {
	// Description A description of the document type.
	Description string `json:"description,omitempty,omitzero"`

	// Schema A valid JSON Schema defining the document's structure.
	// This is used to infer indexing rules and field types.
	Schema map[string]interface{} `json:"schema,omitempty,omitzero"`
}

// DuckDuckGoSearchConfig defines model for DuckDuckGoSearchConfig.
type DuckDuckGoSearchConfig struct {
	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// NoHtml Remove HTML from results
	NoHtml bool `json:"no_html,omitempty,omitzero"`

	// NoRedirect Skip HTTP redirect for bang queries
	NoRedirect bool `json:"no_redirect,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// DynamicTemplate A rule for mapping dynamically detected fields. Templates are checked in order
// and the first matching template's mapping is used.
type DynamicTemplate struct {
	// Mapping Field mapping to apply when a dynamic template matches
	Mapping TemplateFieldMapping `json:"mapping,omitempty,omitzero"`

	// Match Glob pattern for field name (last path element).
	// Supports * and ** wildcards. Example: "*_text" matches "title_text", "body_text"
	Match string `json:"match,omitempty,omitzero"`

	// MatchMappingType Filter by detected JSON type
	MatchMappingType DynamicTemplateMatchMappingType `json:"match_mapping_type,omitempty,omitzero"`

	// Name Optional identifier for the template (useful for debugging)
	Name string `json:"name,omitempty,omitzero"`

	// PathMatch Glob pattern for the full dotted path. Supports ** for matching multiple segments.
	// Example: "metadata.**" matches "metadata.author", "metadata.tags.primary"
	PathMatch string `json:"path_match,omitempty,omitzero"`

	// PathUnmatch Path exclusion pattern. If it matches the full path, the template is skipped.
	PathUnmatch string `json:"path_unmatch,omitempty,omitzero"`

	// Unmatch Exclusion pattern for field name. If it matches, the template is skipped.
	// Example: "skip_*" would exclude fields like "skip_this"
	Unmatch string `json:"unmatch,omitempty,omitzero"`
}

// DynamicTemplateMatchMappingType Filter by detected JSON type
type DynamicTemplateMatchMappingType string

// Edge A typed, weighted connection between documents
type Edge struct {
	// CreatedAt When the edge was created
	CreatedAt time.Time `json:"created_at,omitempty,omitzero"`

	// Metadata Optional edge metadata
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`

	// Source Base64-encoded source document key
	Source []byte `json:"source"`

	// Target Base64-encoded target document key
	Target []byte `json:"target"`

	// Type Edge type (e.g., "cites", "similar_to", "authored_by")
	Type string `json:"type"`

	// UpdatedAt When the edge was last updated
	UpdatedAt time.Time `json:"updated_at,omitempty,omitzero"`

	// Weight Edge weight/confidence (0.0 to 1.0)
	Weight float64 `json:"weight"`
}

// EdgeDirection Direction of edges to query:
// - out: Outgoing edges from the node
// - in: Incoming edges to the node
// - both: Both outgoing and incoming edges
type EdgeDirection string

// EdgeTypeConfig Configuration for a specific edge type
type EdgeTypeConfig struct {
	// AllowSelfLoops Whether to allow edges from a node to itself
	AllowSelfLoops bool `json:"allow_self_loops,omitempty,omitzero"`

	// MaxWeight Maximum allowed edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum allowed edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// Name Edge type name (e.g., 'cites', 'similar_to')
	Name string `json:"name"`

	// RequiredMetadata Required metadata fields for this edge type
	RequiredMetadata []string `json:"required_metadata,omitempty,omitzero"`
}

// EdgesResponse defines model for EdgesResponse.
type EdgesResponse struct {
	// Count Total number of edges returned
	Count int    `json:"count,omitempty,omitzero"`
	Edges []Edge `json:"edges,omitempty,omitzero"`
}

// EmbedderConfig defines model for EmbedderConfig.
type EmbedderConfig struct {
	// Provider The embedding provider to use.
	Provider EmbedderProvider `json:"provider"`
	union    json.RawMessage
}

// EmbedderProvider The embedding provider to use.
type EmbedderProvider string

// EmbeddingIndexConfig defines model for EmbeddingIndexConfig.
type EmbeddingIndexConfig struct {
	// Chunker A unified configuration for a chunking provider.
	Chunker ChunkerConfig `json:"chunker,omitempty,omitzero"`

	// Dimension Vector dimension
	Dimension int `json:"dimension"`

	// Embedder A unified configuration for an embedding provider.
	//
	// Embedders can be configured with templates to customize how documents are
	// converted to text before embedding. Templates use Handlebars syntax and
	// support various built-in helpers.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full document as context
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active user{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// Document with metadata:
	// ```handlebars
	// Title: {{metadata.title}}
	// Date: {{metadata.date}}
	// Tags: {{#each metadata.tags}}{{this}}, {{/each}}
	//
	// {{content}}
	// ```
	//
	// HTML content extraction:
	// ```handlebars
	// Product: {{name}}
	// Description: {{scrubHtml description_html}}
	// Price: ${{price}}
	// ```
	//
	// Multimodal with image:
	// ```handlebars
	// Product: {{title}}
	// {{media url=image}}
	// Description: {{description}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{title}}
	// {{#if author}}By: {{author}}{{/if}}
	// {{#if (eq category "premium")}} Premium Content{{/if}}
	// {{body}}
	// ```
	//
	// **Environment Variables:**
	// - `GEMINI_API_KEY` - API key for Google AI
	// - `OPENAI_API_KEY` - API key for OpenAI
	// - `OPENAI_BASE_URL` - Base URL for OpenAI-compatible APIs
	// - `OLLAMA_HOST` - Ollama server URL (e.g., http://localhost:11434)
	//
	// **Importing Pre-computed Embeddings:**
	//
	// You can import existing embeddings (from OpenAI, Cohere, or any provider) by including
	// them directly in your documents using the `_embeddings` field. This bypasses the
	// embedding generation step and writes vectors directly to the index.
	//
	// **Steps:**
	// 1. Create the index first with the appropriate dimension
	// 2. Write documents with `_embeddings: { "<indexName>": [...<embedding>...] }`
	//
	// **Example:**
	// ```json
	// {
	//   "title": "My Document",
	//   "content": "Document text...",
	//   "_embeddings": {
	//     "my_vector_index": [0.1, 0.2, 0.3, ...]
	//   }
	// }
	// ```
	//
	// **Use Cases:**
	// - Migrating from another vector database with existing embeddings
	// - Using embeddings generated by external systems
	// - Importing pre-computed OpenAI, Cohere, or other provider embeddings
	// - Batch processing embeddings offline before ingestion
	Embedder EmbedderConfig `json:"embedder,omitempty,omitzero"`

	// Field Field to extract embeddings from
	Field string `json:"field,omitempty,omitzero"`

	// MemOnly Whether to use in-memory only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`

	// Summarizer A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Summarizer GeneratorConfig `json:"summarizer,omitempty,omitzero"`

	// Template Handlebars template for generating prompts. See https://handlebarsjs.com/guide/ for more information.
	Template string `json:"template,omitempty,omitzero"`
}

// EmbeddingIndexStats defines model for EmbeddingIndexStats.
type EmbeddingIndexStats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalIndexed Number of vectors in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`

	// TotalNodes Total number of nodes in the index
	TotalNodes uint64 `json:"total_nodes,omitempty,omitzero"`
}

// Error defines model for Error.
type Error struct {
	Error string `json:"error"`
}

// EvalConfig Configuration for inline evaluation of query results.
// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
type EvalConfig struct {
	// Evaluators List of evaluators to run
	Evaluators []EvaluatorName `json:"evaluators,omitempty,omitzero"`

	// GroundTruth Ground truth data for evaluation
	GroundTruth GroundTruth `json:"ground_truth,omitempty,omitzero"`

	// Judge A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Judge GeneratorConfig `json:"judge,omitempty,omitzero"`

	// Options Options for evaluation behavior
	Options EvalOptions `json:"options,omitempty,omitzero"`
}

// EvalOptions Options for evaluation behavior
type EvalOptions struct {
	// K K value for @K metrics (precision@k, recall@k, ndcg@k)
	K int `json:"k,omitempty,omitzero"`

	// PassThreshold Score threshold for pass/fail determination
	PassThreshold float32 `json:"pass_threshold,omitempty,omitzero"`

	// TimeoutSeconds Timeout for evaluation in seconds
	TimeoutSeconds int `json:"timeout_seconds,omitempty,omitzero"`
}

// EvalRequest Standalone evaluation request for POST /eval endpoint.
// Useful for testing evaluators without running a query.
type EvalRequest struct {
	// Context Retrieved documents/context
	Context []map[string]interface{} `json:"context,omitempty,omitzero"`

	// Evaluators List of evaluators to run
	Evaluators []EvaluatorName `json:"evaluators"`

	// GroundTruth Ground truth data for evaluation
	GroundTruth GroundTruth `json:"ground_truth,omitempty,omitzero"`

	// Judge A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Judge GeneratorConfig `json:"judge,omitempty,omitzero"`

	// Options Options for evaluation behavior
	Options EvalOptions `json:"options,omitempty,omitzero"`

	// Output Generated output to evaluate (optional for retrieval-only)
	Output string `json:"output,omitempty,omitzero"`

	// Query Original query/input to evaluate
	Query string `json:"query,omitempty,omitzero"`

	// RetrievedIds IDs of retrieved documents (for retrieval metrics)
	RetrievedIds []string `json:"retrieved_ids,omitempty,omitzero"`
}

// EvalResult Complete evaluation result
type EvalResult struct {
	// DurationMs Total evaluation duration in milliseconds
	DurationMs int `json:"duration_ms,omitempty,omitzero"`

	// Scores Scores organized by category
	Scores EvalScores `json:"scores,omitempty,omitzero"`

	// Summary Aggregate statistics across all evaluators
	Summary EvalSummary `json:"summary,omitempty,omitzero"`
}

// EvalScores Scores organized by category
type EvalScores struct {
	// Generation Generation quality scores (faithfulness, relevance, etc.)
	Generation map[string]EvaluatorScore `json:"generation,omitempty,omitzero"`

	// Retrieval Retrieval metric scores (recall, precision, ndcg, etc.)
	Retrieval map[string]EvaluatorScore `json:"retrieval,omitempty,omitzero"`
}

// EvalSummary Aggregate statistics across all evaluators
type EvalSummary struct {
	// AverageScore Average score across all evaluators
	AverageScore float32 `json:"average_score,omitempty,omitzero"`

	// Failed Number of evaluators that failed
	Failed int `json:"failed,omitempty,omitzero"`

	// Passed Number of evaluators that passed
	Passed int `json:"passed,omitempty,omitzero"`

	// Total Total number of evaluators run
	Total int `json:"total,omitempty,omitzero"`
}

// EvaluatorName Available evaluator types:
//
// **Retrieval metrics** (require ground_truth.relevant_ids):
// - recall: Recall@k - fraction of relevant docs retrieved
// - precision: Precision@k - fraction of retrieved docs that are relevant
// - ndcg: Normalized Discounted Cumulative Gain
// - mrr: Mean Reciprocal Rank
// - map: Mean Average Precision
//
// **LLM-as-judge metrics** (require judge config):
// - relevance: Is output relevant to query? (works on retrieval-only too)
// - faithfulness: Is output grounded in context?
// - completeness: Does output fully address query?
// - coherence: Is output well-structured?
// - safety: Is output safe/appropriate?
// - helpfulness: Is output useful?
// - correctness: Is output factually correct? (uses expectations)
// - citation_quality: Are citations accurate?
type EvaluatorName string

// EvaluatorScore Result from a single evaluator
type EvaluatorScore struct {
	// Metadata Additional evaluator-specific data
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`

	// Pass Whether the evaluation passed the threshold
	Pass bool `json:"pass,omitempty,omitzero"`

	// Reason Human-readable explanation of the result
	Reason string `json:"reason,omitempty,omitzero"`

	// Score Numeric score (0-1)
	Score float32 `json:"score,omitempty,omitzero"`
}

// FailedOperation defines model for FailedOperation.
type FailedOperation struct {
	Error     string                   `json:"error,omitempty,omitzero"`
	Id        string                   `json:"id,omitempty,omitzero"`
	Operation FailedOperationOperation `json:"operation,omitempty,omitzero"`
}

// FailedOperationOperation defines model for FailedOperation.Operation.
type FailedOperationOperation string

// FetchConfig Configuration for URL content fetching.
//
// Uses lib/scraping for downloading and processing. Supports:
// - HTTP/HTTPS URLs with security validation
// - HTML pages (extracts readable text via go-readability)
// - PDF files (extracts text)
// - Images (returns as data URIs)
// - Plain text files
// - S3 URLs (requires s3_credentials)
//
// Security features (from lib/scraping.ContentSecurityConfig):
// - Allowed host whitelist
// - Private IP blocking (SSRF prevention)
// - Download size limits
// - Timeout controls
type FetchConfig struct {
	// AllowedHosts Whitelist of allowed hostnames for fetching.
	// If empty, all hosts are allowed (except private IPs).
	// Example: ["docs.example.com", "api.example.com"]
	AllowedHosts []string `json:"allowed_hosts,omitempty,omitzero"`

	// BlockPrivateIps Block requests to private IP ranges (SSRF prevention).
	// Blocked: 127.0.0.0/8, 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16
	BlockPrivateIps *bool `json:"block_private_ips,omitempty"`

	// MaxContentLength Maximum content length in characters (truncated if exceeded)
	MaxContentLength int `json:"max_content_length,omitempty,omitzero"`

	// MaxDownloadSizeBytes Maximum download size in bytes (default: 100MB)
	MaxDownloadSizeBytes int         `json:"max_download_size_bytes,omitempty,omitzero"`
	S3Credentials        Credentials `json:"s3_credentials,omitempty,omitzero"`

	// TimeoutSeconds Download timeout in seconds
	TimeoutSeconds int `json:"timeout_seconds,omitempty,omitzero"`
}

// FilterSpec A filter specification to apply to search queries
type FilterSpec struct {
	// Field Field name to filter on
	Field string `json:"field"`

	// Operator Filter operator:
	// - eq: Equals
	// - ne: Not equals
	// - gt/gte: Greater than (or equal)
	// - lt/lte: Less than (or equal)
	// - contains: Contains substring
	// - prefix: Starts with
	// - range: Between two values (value should be array [min, max])
	// - in: Value in list (value should be array)
	Operator FilterSpecOperator `json:"operator"`

	// Value Filter value (string, number, boolean, or array for range/in operators)
	Value interface{} `json:"value"`
}

// FilterSpecOperator Filter operator:
// - eq: Equals
// - ne: Not equals
// - gt/gte: Greater than (or equal)
// - lt/lte: Less than (or equal)
// - contains: Contains substring
// - prefix: Starts with
// - range: Between two values (value should be array [min, max])
// - in: Value in list (value should be array)
type FilterSpecOperator string

// FollowupStepConfig Configuration for generating follow-up questions. Uses a separate generator
// call which can use a cheaper/faster model.
type FollowupStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Context Custom guidance for follow-up question focus and style
	Context string `json:"context,omitempty,omitzero"`

	// Count Number of follow-up questions to generate
	Count int `json:"count,omitempty,omitzero"`

	// Enabled Enable follow-up question generation
	Enabled bool `json:"enabled,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`
}

// Fuzziness The fuzziness of the query. Can be an integer or "auto".
type Fuzziness struct {
	union json.RawMessage
}

// Fuzziness0 defines model for .
type Fuzziness0 = int32

// Fuzziness1 defines model for Fuzziness.1.
type Fuzziness1 string

// FuzzyQuery defines model for FuzzyQuery.
type FuzzyQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness `json:"fuzziness,omitempty,omitzero"`
	PrefixLength int32     `json:"prefix_length,omitempty,omitzero"`
	Term         string    `json:"term"`
}

// GenerateResult Result of a generate operation. Formatted as markdown by default with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
type GenerateResult struct {
	// Text The generated text in markdown format with inline resource references like [resource_id res1] or [resource_id res1, res2]
	Text string `json:"text"`
}

// GeneratorConfig defines model for GeneratorConfig.
type GeneratorConfig struct {
	// Provider The generative AI provider to use.
	Provider GeneratorProvider `json:"provider"`
	union    json.RawMessage
}

// GeneratorProvider The generative AI provider to use.
type GeneratorProvider string

// GeoBoundingBoxQuery defines model for GeoBoundingBoxQuery.
type GeoBoundingBoxQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost `json:"boost,omitzero"`

	// BottomRight [lon, lat]
	BottomRight []float64 `json:"bottom_right"`
	Field       string    `json:"field,omitempty,omitzero"`

	// TopLeft [lon, lat]
	TopLeft []float64 `json:"top_left"`
}

// GeoBoundingPolygonQuery defines model for GeoBoundingPolygonQuery.
type GeoBoundingPolygonQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost         Boost      `json:"boost,omitzero"`
	Field         string     `json:"field,omitempty,omitzero"`
	PolygonPoints []GeoPoint `json:"polygon_points"`
}

// GeoDistanceQuery defines model for GeoDistanceQuery.
type GeoDistanceQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Distance string `json:"distance"`
	Field    string `json:"field,omitempty,omitzero"`

	// Location [lon, lat]
	Location []float64 `json:"location"`
}

// GeoPoint defines model for GeoPoint.
type GeoPoint struct {
	Lat float64 `json:"lat,omitempty,omitzero"`
	Lon float64 `json:"lon,omitempty,omitzero"`
}

// GeoShape A GeoJSON shape object. This is a simplified representation.
type GeoShape struct {
	Coordinates []interface{} `json:"coordinates"`
	Type        string        `json:"type"`
}

// GeoShapeGeometry defines model for GeoShapeGeometry.
type GeoShapeGeometry struct {
	Relation GeoShapeGeometryRelation `json:"relation"`

	// Shape A GeoJSON shape object. This is a simplified representation.
	Shape GeoShape `json:"shape"`
}

// GeoShapeGeometryRelation defines model for GeoShapeGeometry.Relation.
type GeoShapeGeometryRelation string

// GeoShapeQuery defines model for GeoShapeQuery.
type GeoShapeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost            `json:"boost,omitzero"`
	Field    string           `json:"field,omitempty,omitzero"`
	Geometry GeoShapeGeometry `json:"geometry"`
}

// GoogleEmbedderConfig Configuration for the Google AI (Gemini) embedding provider.
//
// API key via `api_key` field or `GEMINI_API_KEY` environment variable.
//
// **Example Models:** gemini-embedding-001 (default, 3072 dims)
//
// **Docs:** https://ai.google.dev/gemini-api/docs/embeddings
type GoogleEmbedderConfig struct {
	// ApiKey The Google API key. Can also be set via GEMINI_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimension The dimension of the embedding vector (768, 1536, or 3072 recommended).
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1'). Required for Vertex AI, optional for Gemini API.
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the embedding model to use.
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID (optional for Gemini API, required for Vertex AI).
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Url The URL of the Google API endpoint (optional, uses default if not specified).
	Url string `json:"url,omitempty,omitzero"`
}

// GoogleGeneratorConfig Configuration for the Google generative AI provider (Gemini).
//
// **Example Models:** gemini-2.5-flash (default), gemini-2.5-pro, gemini-3.0-pro
//
// **Docs:** https://ai.google.dev/gemini-api/docs/models
type GoogleGeneratorConfig struct {
	// ApiKey The Google API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1').
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the generative model to use (e.g., 'gemini-2.5-flash', 'gemini-2.5-pro', 'gemini-3.0-pro').
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Google API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// GoogleSearchConfig defines model for GoogleSearchConfig.
type GoogleSearchConfig struct {
	// ApiKey Google API key (or set GOOGLE_CSE_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// CseId Custom Search Engine ID (or set GOOGLE_CSE_ID env var)
	CseId string `json:"cse_id,omitempty,omitzero"`

	// DateRestrict Restrict results by date (e.g., 'd7' for last 7 days, 'm1' for last month)
	DateRestrict string `json:"date_restrict,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// SearchType Type of search to perform
	SearchType GoogleSearchConfigSearchType `json:"search_type,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// GoogleSearchConfigSearchType Type of search to perform
type GoogleSearchConfigSearchType string

// GraphIndexV0Config Configuration for graph_v0 index type
type GraphIndexV0Config struct {
	// EdgeTypes List of edge types with their configurations
	EdgeTypes []EdgeTypeConfig `json:"edge_types,omitempty,omitzero"`

	// MaxEdgesPerDocument Maximum number of edges per document (0 = unlimited)
	MaxEdgesPerDocument int `json:"max_edges_per_document,omitempty,omitzero"`
}

// GraphIndexV0Stats Statistics for graph_v0 index
type GraphIndexV0Stats struct {
	// EdgeTypes Count of edges per edge type
	EdgeTypes map[string]uint64 `json:"edge_types,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalEdges Total number of edges in the graph
	TotalEdges uint64 `json:"total_edges,omitempty,omitzero"`
}

// GraphNodeSelector Defines how to select start/target nodes for graph queries
type GraphNodeSelector struct {
	// Keys Explicit list of node keys
	Keys []string `json:"keys,omitempty,omitzero"`

	// Limit Maximum number of nodes to select from the referenced results
	Limit int `json:"limit,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`

	// ResultRef Reference to search results to use as nodes:
	// - "$full_text_results" - use full-text search results
	// - "$aknn_results.index_name" - use vector search results from specific index
	ResultRef string `json:"result_ref,omitempty,omitzero"`
}

// GraphQuery Declarative graph query to execute after full-text/vector searches
type GraphQuery struct {
	// Fields Which fields to return from documents
	Fields []string `json:"fields,omitempty,omitzero"`

	// IncludeDocuments Fetch full documents for graph results
	IncludeDocuments bool `json:"include_documents,omitempty,omitzero"`

	// IncludeEdges Include edge details for each node
	IncludeEdges bool `json:"include_edges,omitempty,omitzero"`

	// IndexName Graph index name (must be graph_v0 type)
	IndexName string `json:"index_name"`

	// Params Parameters for graph traversal and pathfinding
	Params GraphQueryParams `json:"params,omitempty,omitzero"`

	// Pattern Pattern steps for pattern query type
	Pattern []PatternStep `json:"pattern,omitempty,omitzero"`

	// ReturnAliases Which aliases to return from pattern query (empty = all)
	ReturnAliases []string `json:"return_aliases,omitempty,omitzero"`

	// StartNodes Defines how to select start/target nodes for graph queries
	StartNodes GraphNodeSelector `json:"start_nodes,omitempty,omitzero"`

	// TargetNodes Defines how to select start/target nodes for graph queries
	TargetNodes GraphNodeSelector `json:"target_nodes,omitempty,omitzero"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryParams Parameters for graph traversal and pathfinding
type GraphQueryParams struct {
	// Algorithm Graph algorithm to run (e.g., 'pagerank', 'betweenness')
	Algorithm string `json:"algorithm,omitempty,omitzero"`

	// AlgorithmParams Parameters for the graph algorithm
	AlgorithmParams map[string]interface{} `json:"algorithm_params,omitempty,omitzero"`

	// DeduplicateNodes Remove duplicate nodes (traversal)
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information (traversal)
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// K Number of paths to find (k-shortest-paths)
	K int `json:"k,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum number of results (traversal)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`

	// WeightMode Path weighting algorithm for pathfinding:
	// - min_hops: Minimize number of edges
	// - min_weight: Minimize sum of edge weights
	// - max_weight: Maximize product of edge weights
	WeightMode PathWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// GraphQueryResult Results of a graph query
type GraphQueryResult struct {
	// Matches Pattern matches (for pattern queries)
	Matches []PatternMatch `json:"matches,omitempty,omitzero"`

	// Nodes Result nodes
	Nodes []GraphResultNode `json:"nodes,omitempty,omitzero"`

	// Paths Result paths (for pathfinding queries)
	Paths []Path `json:"paths,omitempty,omitzero"`

	// Took Query execution time
	Took time.Duration `json:"took,omitempty,omitzero"`

	// Total Total number of results
	Total int `json:"total"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryType Type of graph query to execute
type GraphQueryType string

// GraphResultNode A node in graph query results
type GraphResultNode struct {
	// Depth Distance from start node
	Depth int `json:"depth,omitempty,omitzero"`

	// Distance Weighted distance
	Distance float64 `json:"distance,omitempty,omitzero"`

	// Document Full document (if include_documents=true)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Edges Connected edges (when include_edges=true)
	Edges []Edge `json:"edges,omitempty,omitzero"`

	// Key Document key
	Key string `json:"key"`

	// Path Keys in path from start to this node
	Path []string `json:"path,omitempty,omitzero"`

	// PathEdges Edges in path from start to this node
	PathEdges []PathEdge `json:"path_edges,omitempty,omitzero"`
}

// GroundTruth Ground truth data for evaluation
type GroundTruth struct {
	// Expectations Context for evaluators about what to expect in the response.
	// Provides guidance for LLM judges (e.g., "Should mention pricing tiers").
	Expectations string `json:"expectations,omitempty,omitzero"`

	// RelevantIds Document IDs known to be relevant (for retrieval metrics)
	RelevantIds []string `json:"relevant_ids,omitempty,omitzero"`
}

// IPRangeQuery defines model for IPRangeQuery.
type IPRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Cidr  string `json:"cidr"`
	Field string `json:"field,omitempty,omitzero"`
}

// IndexConfig Configuration for an index
type IndexConfig struct {
	// Description Optional description of the index and its purpose
	Description string `json:"description,omitempty,omitzero"`

	// Enrichments List of enrichment names to apply to documents before indexing. Enrichments must be defined at the table level.
	Enrichments []string `json:"enrichments,omitempty,omitzero"`

	// Name Name of the index
	Name string `json:"name"`

	// Type The type of the index.
	Type  IndexType `json:"type"`
	union json.RawMessage
}

// IndexStats Statistics for an index
type IndexStats struct {
	union json.RawMessage
}

// IndexStatus defines model for IndexStatus.
type IndexStatus struct {
	// Config Configuration for an index
	Config      IndexConfig           `json:"config"`
	ShardStatus map[string]IndexStats `json:"shard_status"`

	// Status Statistics for an index
	Status IndexStats `json:"status"`
}

// IndexType The type of the index.
type IndexType string

// KeyRange Key range processed in this request
type KeyRange struct {
	From string `json:"from,omitempty,omitzero"`
	To   string `json:"to,omitempty,omitzero"`
}

// LinearMergePageStatus Status of a linear merge page operation:
// - "success": All records in batch processed successfully
// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
// - "error": Fatal error occurred, no records processed successfully
type LinearMergePageStatus string

// LinearMergeRequest Linear merge operation for syncing sorted records from external sources.
// Use this to keep Antfly in sync with an external database or data source.
//
// **How it works:**
// 1. Send sorted records from your external source
// 2. Server upserts records that exist in your batch
// 3. Server deletes Antfly records in the key range that are absent from your batch
// 4. If stopped at shard boundary, use next_cursor for next request
//
// **WARNING:** Not safe for concurrent operations with overlapping key ranges.
type LinearMergeRequest struct {
	// DryRun If true, returns what would be deleted without making changes.
	//
	// Use cases:
	// - Validate sync behavior before committing
	// - Check which records will be removed
	// - Test key range boundaries
	//
	// Response includes deleted_ids array when dry_run=true.
	DryRun bool `json:"dry_run,omitempty,omitzero"`

	// LastMergedId ID of last record from previous merge request.
	// - First request: Use empty string ""
	// - Subsequent requests: Use next_cursor from previous response
	// - Defines lower bound of key range to process
	//
	// This enables pagination for large datasets.
	LastMergedId string `json:"last_merged_id,omitempty,omitzero"`

	// Records Map of resource ID to resource object: {"resource_id_1": {...}, "resource_id_2": {...}}
	//
	// Requirements:
	// - Keys must be sorted lexicographically by your client
	// - Server will process keys in sorted order
	// - Use consistent key naming (e.g., all start with same prefix)
	//
	// This format avoids duplicate IDs and matches Antfly's batch write interface.
	Records map[string]interface{} `json:"records"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write
	// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`
}

// LinearMergeResult defines model for LinearMergeResult.
type LinearMergeResult struct {
	// Deleted Records deleted or would be deleted (if dry_run=true)
	Deleted int `json:"deleted"`

	// DeletedIds IDs that were deleted (or would be deleted if dry_run=true). Only included if dry_run=true.
	DeletedIds []string          `json:"deleted_ids,omitempty,omitzero"`
	Failed     []FailedOperation `json:"failed,omitempty,omitzero"`

	// KeyRange Key range processed in this request
	KeyRange KeyRange `json:"key_range,omitempty,omitzero"`

	// KeysScanned Total number of keys scanned from Antfly during range query
	KeysScanned int `json:"keys_scanned,omitempty,omitzero"`

	// Message Additional information (e.g., "stopped at shard boundary", "dry run - no changes made")
	Message string `json:"message,omitempty,omitzero"`

	// NextCursor ID of last record in this batch (use for next request)
	NextCursor string `json:"next_cursor"`

	// Skipped Records skipped because content hash matched (unchanged)
	Skipped int `json:"skipped"`

	// Status Status of a linear merge page operation:
	// - "success": All records in batch processed successfully
	// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
	// - "error": Fatal error occurred, no records processed successfully
	Status LinearMergePageStatus `json:"status"`
	Took   time.Duration         `json:"took,omitempty,omitzero"`

	// Upserted Records inserted or updated (0 if dry_run=true)
	Upserted int `json:"upserted"`
}

// MatchAllQuery defines model for MatchAllQuery.
type MatchAllQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost                  `json:"boost,omitzero"`
	MatchAll map[string]interface{} `json:"match_all"`
}

// MatchNoneQuery defines model for MatchNoneQuery.
type MatchNoneQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost                  `json:"boost,omitzero"`
	MatchNone map[string]interface{} `json:"match_none"`
}

// MatchPhraseQuery defines model for MatchPhraseQuery.
type MatchPhraseQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness   Fuzziness `json:"fuzziness,omitempty,omitzero"`
	MatchPhrase string    `json:"match_phrase"`
}

// MatchQuery defines model for MatchQuery.
type MatchQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness          `json:"fuzziness,omitempty,omitzero"`
	Match        string             `json:"match"`
	Operator     MatchQueryOperator `json:"operator,omitempty,omitzero"`
	PrefixLength int32              `json:"prefix_length,omitempty,omitzero"`
}

// MatchQueryOperator defines model for MatchQuery.Operator.
type MatchQueryOperator string

// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
// failover: Use full_text_search if embedding generation fails
type MergeStrategy string

// MultiPhraseQuery defines model for MultiPhraseQuery.
type MultiPhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness  `json:"fuzziness,omitempty,omitzero"`
	Terms     [][]string `json:"terms"`
}

// NodeFilter Filter nodes during graph traversal using existing query primitives
type NodeFilter struct {
	// FilterPrefix Filter by key prefix
	FilterPrefix string `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query to filter nodes (same syntax as search filter_query)
	FilterQuery map[string]interface{} `json:"filter_query,omitempty,omitzero"`
}

// NumericRangeQuery defines model for NumericRangeQuery.
type NumericRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost   `json:"boost,omitzero"`
	Field        string  `json:"field,omitempty,omitzero"`
	InclusiveMax bool    `json:"inclusive_max,omitzero"`
	InclusiveMin bool    `json:"inclusive_min,omitzero"`
	Max          float64 `json:"max,omitzero"`
	Min          float64 `json:"min,omitzero"`
}

// OllamaEmbedderConfig Configuration for the Ollama embedding provider.
//
// Local embeddings for privacy and offline use. URL via `url` field or `OLLAMA_HOST` env var.
//
// **Example Models:** nomic-embed-text (768 dims), mxbai-embed-large (1024 dims), all-minilm (384 dims)
//
// **Docs:** https://ollama.com/search?c=embedding
type OllamaEmbedderConfig struct {
	// Model The name of the Ollama model to use (e.g., 'nomic-embed-text', 'mxbai-embed-large').
	Model string `json:"model"`

	// Url The URL of the Ollama API endpoint. Can also be set via OLLAMA_HOST environment variable.
	Url string `json:"url,omitempty,omitzero"`
}

// OllamaGeneratorConfig Configuration for the Ollama generative AI provider.
//
// Ollama provides local LLM inference for privacy and offline use.
//
// **Example Models:** llama3.3:70b, qwen2.5:72b, deepseek-r1:70b, mistral:7b, llava:34b
//
// **Docs:** https://ollama.com/library
type OllamaGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Ollama model to use (e.g., 'llama3.3:70b', 'qwen2.5:72b', 'deepseek-coder:33b').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OllamaRerankerConfig Configuration for the Ollama reranking provider.
type OllamaRerankerConfig struct {
	// Model The name of the Ollama model to use for reranking.
	Model string `json:"model"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIEmbedderConfig Configuration for the OpenAI embedding provider.
//
// API key via `api_key` field or `OPENAI_API_KEY` environment variable.
// Supports OpenAI-compatible APIs via `url` field.
//
// **Example Models:** text-embedding-3-small (default, 1536 dims), text-embedding-3-large (3072 dims)
//
// **Docs:** https://platform.openai.com/docs/guides/embeddings
type OpenAIEmbedderConfig struct {
	// ApiKey The OpenAI API key. Can also be set via OPENAI_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimensions Output dimension for the embedding (uses MRL for dimension reduction). Recommended: 256, 512, 1024, 1536, or 3072.
	Dimensions int `json:"dimensions,omitempty,omitzero"`

	// Model The name of the OpenAI model to use.
	Model string `json:"model"`

	// Url The URL of the OpenAI API endpoint. Defaults to OpenAI's API. Can be set via OPENAI_BASE_URL environment variable.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIGeneratorConfig Configuration for the OpenAI generative AI provider.
//
// **Example Models:** gpt-4.1 (default), gpt-4.1-mini, o3, o4-mini
//
// **Docs:** https://platform.openai.com/docs/models
type OpenAIGeneratorConfig struct {
	// ApiKey The OpenAI API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (-2.0 to 2.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the OpenAI model to use (e.g., 'gpt-4.1', 'gpt-4.1-mini', 'o4-mini').
	Model string `json:"model"`

	// PresencePenalty Penalty for token presence (-2.0 to 2.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the OpenAI API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenRouterEmbedderConfig Configuration for the OpenRouter embedding provider.
//
// OpenRouter provides a unified API for multiple embedding models from different providers.
// API key via `api_key` field or `OPENROUTER_API_KEY` environment variable.
//
// **Example Models:** openai/text-embedding-3-small (default), openai/text-embedding-3-large,
// google/gemini-embedding-001, qwen/qwen3-embedding-8b
//
// **Docs:** https://openrouter.ai/docs/api/reference/embeddings
type OpenRouterEmbedderConfig struct {
	// ApiKey The OpenRouter API key. Can also be set via OPENROUTER_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimensions Output dimension for the embedding (if supported by the model).
	Dimensions int `json:"dimensions,omitempty,omitzero"`

	// Model The OpenRouter model identifier (e.g., 'openai/text-embedding-3-small', 'google/gemini-embedding-001').
	Model string `json:"model"`
}

// OpenRouterGeneratorConfig Configuration for the OpenRouter generative AI provider.
//
// OpenRouter provides a unified API for multiple LLM providers with automatic fallback routing.
// API key via `api_key` field or `OPENROUTER_API_KEY` environment variable.
//
// **Model Selection:**
// - Use `model` for a single model (e.g., "openai/gpt-4.1", "anthropic/claude-sonnet-4-5-20250929")
// - Use `models` array for fallback routing - OpenRouter tries models in order until one succeeds
//
// **Example Models:** openai/gpt-4.1, anthropic/claude-sonnet-4-5-20250929, google/gemini-2.5-flash,
// meta-llama/llama-3.3-70b-instruct
//
// **Docs:** https://openrouter.ai/docs/api/api-reference/chat/send-chat-completion-request
type OpenRouterGeneratorConfig struct {
	// ApiKey The OpenRouter API key. Can also be set via OPENROUTER_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (-2.0 to 2.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model Single model identifier (e.g., 'openai/gpt-4.1'). Either model or models must be provided.
	Model string `json:"model,omitempty,omitzero"`

	// Models Array of model identifiers for fallback routing. OpenRouter tries each model in order
	// until one succeeds. Either model or models must be provided.
	Models []string `json:"models,omitempty,omitzero"`

	// PresencePenalty Penalty for token presence (-2.0 to 2.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// Path defines model for Path.
type Path struct {
	Edges  []PathEdge `json:"edges,omitempty,omitzero"`
	Length int        `json:"length,omitempty,omitzero"`

	// Nodes Ordered list of node keys (base64-encoded)
	Nodes       []string `json:"nodes,omitempty,omitzero"`
	TotalWeight float64  `json:"total_weight,omitempty,omitzero"`
}

// PathEdge defines model for PathEdge.
type PathEdge struct {
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`
	Source   string                 `json:"source,omitempty,omitzero"`
	Target   string                 `json:"target,omitempty,omitzero"`
	Type     string                 `json:"type,omitempty,omitzero"`
	Weight   float64                `json:"weight,omitempty,omitzero"`
}

// PathFindRequest defines model for PathFindRequest.
type PathFindRequest struct {
	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by specific edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`
	K         int      `json:"k,omitempty,omitzero"`
	MaxDepth  int      `json:"max_depth,omitempty,omitzero"`
	MaxWeight float64  `json:"max_weight,omitempty,omitzero"`
	MinWeight float64  `json:"min_weight,omitempty,omitzero"`

	// Source Source node key (base64-encoded)
	Source string `json:"source"`

	// Target Target node key (base64-encoded)
	Target string `json:"target"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindResult defines model for PathFindResult.
type PathFindResult struct {
	Paths        []Path  `json:"paths,omitempty,omitzero"`
	PathsFound   int     `json:"paths_found,omitempty,omitzero"`
	SearchTimeMs float64 `json:"search_time_ms,omitempty,omitzero"`
	Source       string  `json:"source,omitempty,omitzero"`
	Target       string  `json:"target,omitempty,omitzero"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindWeightMode Algorithm for path finding:
// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
// - max_weight: Path with maximum product of edge weights (strongest connection chain)
// - min_weight: Path with minimum sum of edge weights (lowest cost route)
type PathFindWeightMode string

// PathWeightMode Path weighting algorithm for pathfinding:
// - min_hops: Minimize number of edges
// - min_weight: Minimize sum of edge weights
// - max_weight: Maximize product of edge weights
type PathWeightMode string

// PatternEdgeStep Edge constraints in a pattern step
type PatternEdgeStep struct {
	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// MaxHops Maximum number of hops (>1 = variable-length path)
	MaxHops int `json:"max_hops,omitempty,omitzero"`

	// MaxWeight Maximum edge weight filter
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinHops Minimum number of hops (1 = direct edge)
	MinHops int `json:"min_hops,omitempty,omitzero"`

	// MinWeight Minimum edge weight filter
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// Types Edge types to traverse (empty = any)
	Types []string `json:"types,omitempty,omitzero"`
}

// PatternMatch A single match from a pattern query
type PatternMatch struct {
	// Bindings Map of alias to matched node
	Bindings map[string]GraphResultNode `json:"bindings,omitempty,omitzero"`

	// Path Edges traversed in this match
	Path []PathEdge `json:"path,omitempty,omitzero"`
}

// PatternStep A step in a graph pattern query
type PatternStep struct {
	// Alias Name for this node (reuse alias for cycle detection)
	Alias string `json:"alias,omitempty,omitzero"`

	// Edge Edge constraints in a pattern step
	Edge PatternEdgeStep `json:"edge,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`
}

// Permission defines model for Permission.
type Permission struct {
	// Resource Resource name (e.g., table name, target username, or '*' for global).
	Resource string `json:"resource"`

	// ResourceType Type of the resource, e.g., table, user, or global ('*').
	ResourceType ResourceType `json:"resource_type"`

	// Type Type of permission.
	Type PermissionType `json:"type"`
}

// PermissionType Type of permission.
type PermissionType string

// PhraseQuery defines model for PhraseQuery.
type PhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness `json:"fuzziness,omitempty,omitzero"`
	Terms     []string  `json:"terms"`
}

// PrefixQuery defines model for PrefixQuery.
type PrefixQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Prefix string `json:"prefix"`
}

// Pruner Configuration for pruning search results based on score quality.
// Helps filter out low-relevance results in RAG pipelines by detecting
// score gaps or deviations from top results.
type Pruner struct {
	// MaxScoreGapPercent Stop returning results when score drops more than this percentage
	// from the previous result. Detects "elbows" in score distribution.
	// For example, 30.0 stops when score drops 30% from previous result.
	MaxScoreGapPercent float64 `json:"max_score_gap_percent,omitempty,omitzero"`

	// MinAbsoluteScore Hard minimum score threshold. Results with scores below this value
	// are excluded regardless of other pruning settings.
	MinAbsoluteScore float64 `json:"min_absolute_score,omitempty,omitzero"`

	// MinScoreRatio Keep only results with score >= max_score * min_score_ratio.
	// For example, 0.5 keeps results scoring at least half of the top result.
	// Applied after fusion scoring.
	MinScoreRatio float64 `json:"min_score_ratio,omitempty,omitzero"`

	// RequireMultiIndex Only keep results that appear in multiple indexes (both full-text
	// and vector search). Useful for increasing precision by requiring
	// agreement between different retrieval methods.
	RequireMultiIndex bool `json:"require_multi_index,omitempty,omitzero"`

	// StdDevThreshold Keep results within N standard deviations below the mean score.
	// For example, 1.0 keeps results with score >= mean - 1*stddev.
	// Useful for statistical outlier detection in result sets.
	StdDevThreshold float64 `json:"std_dev_threshold,omitempty,omitzero"`
}

// Query defines model for Query.
type Query struct {
	union json.RawMessage
}

// QueryBuilderRequest defines model for QueryBuilderRequest.
type QueryBuilderRequest struct {
	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// Intent Natural language description of the search intent
	Intent string `json:"intent"`

	// SchemaFields List of searchable field names to consider. Overrides table schema if provided.
	SchemaFields []string `json:"schema_fields,omitempty,omitzero"`

	// Table Name of the table to build query for. If provided, uses table schema for field context.
	Table string `json:"table,omitempty,omitzero"`
}

// QueryBuilderResult defines model for QueryBuilderResult.
type QueryBuilderResult struct {
	// Confidence Model's confidence in the generated query (0.0-1.0)
	Confidence float64 `json:"confidence,omitempty,omitzero"`

	// Explanation Human-readable explanation of what the query does and why it was structured this way
	Explanation string `json:"explanation,omitempty,omitzero"`

	// Query Generated search query in simplified DSL format.
	// Can be used directly in QueryRequest.full_text_search or filter_query.
	Query map[string]interface{} `json:"query"`

	// Warnings Any issues, limitations, or assumptions made when generating the query
	Warnings []string `json:"warnings,omitempty,omitzero"`
}

// QueryHit A single query result hit
type QueryHit struct {
	// ID ID of the record.
	ID string `json:"_id"`

	// IndexScores Scores partitioned by index when using RRF search.
	IndexScores map[string]interface{} `json:"_index_scores,omitempty,omitzero"`

	// Score Relevance score of the hit.
	Score  float64                `json:"_score"`
	Source map[string]interface{} `json:"_source,omitempty,omitzero"`
}

// QueryHits A list of query hits.
type QueryHits struct {
	Hits []QueryHit `json:"hits"`

	// MaxScore Maximum score of the results.
	MaxScore float64 `json:"max_score,omitempty,omitzero"`

	// Total Total number of hits available.
	Total uint64 `json:"total,omitempty"`
}

// QueryRequest defines model for QueryRequest.
type QueryRequest struct {
	// Aggregations Aggregation requests for computing metrics and bucketing results.
	// Each key is a user-defined name for the aggregation, and the value specifies the aggregation configuration.
	//
	// Supports metric aggregations (sum, avg, min, max, count, stats, cardinality),
	// bucketing aggregations (terms, range, date_range, histogram, date_histogram),
	// geo aggregations (geohash_grid, geo_distance), and analytics (significant_terms).
	//
	// Example:
	// ```json
	// {
	//   "price_stats": {
	//     "type": "stats",
	//     "field": "price"
	//   },
	//   "categories": {
	//     "type": "terms",
	//     "field": "category",
	//     "size": 10
	//   }
	// }
	// ```
	Aggregations map[string]AggregationRequest `json:"aggregations,omitempty,omitzero"`
	Analyses     *Analyses                     `json:"analyses,omitempty"`

	// Count If true, returns only the total count of matching documents without retrieving the actual documents.
	// Useful for pagination and displaying result counts.
	Count bool `json:"count,omitempty,omitzero"`

	// DistanceOver Minimum distance threshold for semantic similarity search. Results with distance
	// less than this value are excluded.
	//
	// Useful for excluding near-exact duplicates or finding dissimilar documents.
	DistanceOver *float32 `json:"distance_over,omitempty"`

	// DistanceUnder Maximum distance threshold for semantic similarity search. Results with distance
	// greater than this value are excluded. Lower distances indicate higher similarity.
	//
	// Useful for filtering out low-confidence matches.
	DistanceUnder *float32 `json:"distance_under,omitempty"`

	// DocumentRenderer Optional Handlebars template string for rendering document content in RAG queries.
	// Template has access to document fields via `{{this.fields.fieldName}}`.
	//
	// **Default**: Uses TOON (Token-Oriented Object Notation) format for 30-60% token reduction:
	// ```handlebars
	// {{encodeToon this.fields}}
	// ```
	//
	// **Available Helpers**:
	// - `encodeToon` - Renders fields in compact TOON format with configurable options:
	//   - `lengthMarker` (bool): Add # prefix to array counts (default: true)
	//   - `indent` (int): Indentation spacing (default: 2)
	//   - `delimiter` (string): Field separator for tabular arrays
	// - `scrubHtml` - Removes HTML tags and extracts text
	// - `media` - Wraps data URIs for GenKit multimodal support
	// - `eq` - Equality comparison for conditionals
	//
	// **Examples**:
	// - Basic TOON: `{{encodeToon this.fields}}`
	// - Compact TOON: `{{encodeToon this.fields lengthMarker=false indent=0}}`
	// - Tabular data: `{{encodeToon this.fields delimiter="\t"}}`
	// - Custom template: `Title: {{this.fields.title}}\nBody: {{this.fields.body}}`
	// - Traditional format: `{{#each this.fields}}{{@key}}: {{this}}\n{{/each}}`
	//
	// TOON format produces compact, LLM-optimized output like:
	// ```
	// title: Introduction to Vector Search
	// author: Jane Doe
	// tags[#3]: ai,search,ml
	// ```
	//
	// **References**:
	// - TOON Specification: https://github.com/toon-format/toon
	// - Go Implementation: https://github.com/alpkeskin/gotoon
	DocumentRenderer string `json:"document_renderer,omitempty,omitzero"`

	// EmbeddingTemplate Optional Handlebars template for multimodal embedding of the semantic_search query.
	// The template has access to `this` which contains the semantic_search string value.
	//
	// Use this when you want to embed multimodal content (images, PDFs, etc.) instead of
	// just text. The template is rendered using dotprompt with access to remote content helpers.
	//
	// **Available Helpers**:
	// - `remoteMedia url=<url>` - Fetches and embeds remote images/media
	// - `remotePDF url=<url>` - Fetches and extracts content from PDFs
	// - `remoteText url=<url>` - Fetches and includes remote text content
	//
	// **Examples**:
	// - PDF search: `{{remotePDF url=this}}`
	// - Image search: `{{remoteMedia url=this}}`
	// - Mixed: `Search for: {{this}} {{#if this}}{{remoteMedia url=this}}{{/if}}`
	//
	// When not specified, the semantic_search string is embedded as plain text.
	EmbeddingTemplate string `json:"embedding_template,omitempty,omitzero"`

	// Embeddings Pre-computed embeddings to use for semantic searches instead of embedding the semantic_search string.
	// The keys are the index names, and values are the embedding vectors.
	//
	// Use when you've already generated embeddings on the client side to avoid redundant embedding calls.
	Embeddings map[string][]float32 `json:"embeddings,omitempty,omitzero"`

	// ExclusionQuery Bleve query applied as a NOT condition. Documents matching this query are excluded
	// from results. Applied before scoring.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Excluding drafts: `"status:draft"`
	// - Removing deprecated content: `"deprecated:true"`
	// - Filtering out archived items: `"status:archived"`
	ExclusionQuery json.RawMessage `json:"exclusion_query,omitempty,omitzero"`

	// ExpandStrategy Strategy for merging graph results with search results:
	// - union: Include nodes from both search and graph results
	// - intersection: Only include nodes appearing in both
	ExpandStrategy QueryRequestExpandStrategy `json:"expand_strategy,omitempty,omitzero"`

	// Fields List of fields to include in the results. If not specified, all fields are returned.
	// Use to reduce response size and improve performance.
	Fields []string `json:"fields,omitempty,omitzero"`

	// FilterPrefix Filter results by key prefix. Only returns documents whose keys start with this string.
	// Applied before scoring to improve performance.
	//
	// Common use cases:
	// - Multi-tenant filtering: `"tenant:acme:"`
	// - User-specific data: `"user:123:"`
	// - Document type filtering: `"article:"`
	FilterPrefix []byte `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query applied as an AND condition. Documents must match both the main query
	// and this filter. Applied before scoring for better performance.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Status filtering: `"status:published"`
	// - Date ranges: `"created_at:>2023-01-01"`
	// - Category filtering: `"category:technology AND language:en"`
	FilterQuery json.RawMessage `json:"filter_query,omitempty,omitzero"`

	// FullTextSearch Bleve query for full-text search. Supports all Bleve query types.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Examples:
	// - Simple: `{"query": "computer"}`
	// - Field-specific: `{"query": "body:computer"}`
	// - Boolean: `{"query": "artificial AND intelligence"}`
	// - Range: `{"query": "year:>2020"}`
	// - Phrase: `{"query": "\"exact phrase\""}`
	FullTextSearch json.RawMessage `json:"full_text_search,omitempty,omitzero"`

	// GraphSearches Declarative graph queries to execute after full-text/vector searches.
	// Results can reference search results using node selectors like $full_text_results.
	GraphSearches map[string]GraphQuery `json:"graph_searches,omitempty,omitzero"`

	// Indexes List of vector index names to use for semantic search. Required when using semantic_search.
	// Multiple indexes can be specified, and their results will be merged using RRF.
	Indexes []string `json:"indexes,omitempty,omitzero"`

	// Limit Maximum number of results to return. For semantic_search, this is the topk parameter.
	// Default varies by query type (typically 10).
	Limit int `json:"limit,omitempty,omitzero"`

	// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
	// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
	// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
	// failover: Use full_text_search if embedding generation fails
	MergeStrategy MergeStrategy `json:"merge_strategy,omitempty,omitzero"`

	// Offset Number of results to skip for pagination. Only available for full_text_search queries.
	// Not supported for semantic_search due to vector index limitations.
	Offset int `json:"offset,omitempty,omitzero"`

	// OrderBy Sort order for results. Map of field names to boolean (true = descending, false = ascending).
	// Only applicable for full_text_search queries. Semantic searches are always sorted by similarity score.
	OrderBy map[string]bool `json:"order_by,omitempty,omitzero"`

	// Pruner Configuration for pruning search results based on score quality.
	// Helps filter out low-relevance results in RAG pipelines by detecting
	// score gaps or deviations from top results.
	Pruner Pruner `json:"pruner,omitempty,omitzero"`

	// Reranker A unified configuration for a reranking provider.
	Reranker *RerankerConfig `json:"reranker,omitempty"`

	// SemanticSearch Natural language query for vector similarity search. Results are ranked by semantic similarity
	// to the query and can be combined with full_text_search using Reciprocal Rank Fusion (RRF).
	//
	// The semantic_search string is automatically embedded using the configured embedding model
	// for the specified indexes. Use `embedding_template` for multimodal queries.
	SemanticSearch string `json:"semantic_search,omitempty,omitzero"`

	// Table Name of the table to query. Optional for global queries.
	Table string `json:"table,omitempty,omitzero"`
}

// QueryRequestExpandStrategy Strategy for merging graph results with search results:
// - union: Include nodes from both search and graph results
// - intersection: Only include nodes appearing in both
type QueryRequestExpandStrategy string

// QueryResponses Responses from multiple query operations.
type QueryResponses struct {
	Responses []QueryResult `json:"responses,omitempty,omitzero"`
}

// QueryResult Result of a query operation as an array of results and a count.
type QueryResult struct {
	// Aggregations Aggregation results keyed by the user-defined aggregation names from the request.
	// Contains computed metrics or buckets depending on the aggregation type.
	Aggregations map[string]AggregationResult `json:"aggregations,omitempty,omitzero"`

	// Analyses Analysis results like PCA and t-SNE per index embeddings.
	Analyses map[string]AnalysesResult `json:"analyses,omitempty,omitzero"`

	// Error Error message if the query failed.
	Error string `json:"error,omitempty,omitzero"`

	// GraphResults Results from declarative graph queries.
	GraphResults map[string]GraphQueryResult `json:"graph_results,omitempty,omitzero"`

	// Hits A list of query hits.
	Hits QueryHits `json:"hits"`

	// Status HTTP status code of the query operation.
	Status int32 `json:"status"`

	// Table Which table this result came from
	Table string `json:"table,omitempty,omitzero"`

	// Took Duration of the query in milliseconds.
	Took time.Duration `json:"took"`
}

// QueryStrategy Strategy for query transformation and retrieval:
// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
type QueryStrategy string

// QueryStringQuery defines model for QueryStringQuery.
type QueryStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Query string `json:"query"`
}

// RAGRequest defines model for RAGRequest.
type RAGRequest struct {
	// Chain Chain of generators with retry/fallback semantics. Mutually exclusive with 'generator'.
	// Each link can specify retry configuration and a condition for trying the next generator.
	// Either 'generator' or 'chain' must be provided.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Eval Configuration for inline evaluation of query results.
	// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
	Eval EvalConfig `json:"eval,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// Prompt Optional custom user prompt template for the LLM. If not provided, a default prompt is used.
	// The prompt can reference the following variables:
	// - {{documents}}: Array of retrieved documents with id and fields
	// - {{semantic_search}}: The user's semantic search query (if provided)
	// You can use Handlebars template syntax to customize the prompt, including loops and conditionals.
	// To generate a comma-separated list of document IDs, use: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	Prompt string `json:"prompt,omitempty,omitzero"`

	// Queries Array of retrieval queries to execute. Each query must specify a table and can specify its own limit and document_renderer.
	// Results from all queries are concatenated together (respecting each query's limit).
	// For single table: [{"table": "papers", "semantic_search": "...", "limit": 10}]
	// For broadcast: [{"table": "images", "limit": 5, ...}, {"table": "products", "limit": 5, ...}]
	// For mixed: [{"table": "papers", "semantic_search": "...", "limit": 10}, {"table": "books", "full_text_search": {...}, "limit": 5}]
	Queries []QueryRequest `json:"queries"`

	// SystemPrompt Optional system prompt to guide the summarization
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// RAGResult RAG result with individual query results and generation/evaluation outcome
type RAGResult struct {
	// EvalResult Complete evaluation result
	EvalResult EvalResult `json:"eval_result,omitempty,omitzero"`

	// GenerateResult Result of a generate operation. Formatted as markdown by default with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
	GenerateResult GenerateResult `json:"generate_result,omitempty,omitzero"`

	// QueryResults Results from each query. Check each result's status and error fields for failures.
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`
}

// RegexpQuery defines model for RegexpQuery.
type RegexpQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Regexp string `json:"regexp"`
}

// RerankerConfig defines model for RerankerConfig.
type RerankerConfig struct {
	// Field Field name to extract from documents for reranking.
	Field string `json:"field,omitempty,omitzero"`

	// Provider The reranking provider to use.
	Provider RerankerProvider `json:"provider"`

	// Template Handlebars template to render document text for reranking.
	Template string `json:"template,omitempty,omitzero"`
	union    json.RawMessage
}

// RerankerProvider The reranking provider to use.
type RerankerProvider string

// ResourceType Type of the resource, e.g., table, user, or global ('*').
type ResourceType string

// RestoreRequest defines model for RestoreRequest.
type RestoreRequest = BackupRequest

// RetryConfig Retry configuration for generator calls
type RetryConfig struct {
	// BackoffMultiplier Multiplier for exponential backoff
	BackoffMultiplier float32 `json:"backoff_multiplier,omitempty,omitzero"`

	// InitialBackoffMs Initial backoff delay in milliseconds
	InitialBackoffMs int `json:"initial_backoff_ms,omitempty,omitzero"`

	// MaxAttempts Maximum number of retry attempts
	MaxAttempts int `json:"max_attempts,omitempty,omitzero"`

	// MaxBackoffMs Maximum backoff delay in milliseconds
	MaxBackoffMs int `json:"max_backoff_ms,omitempty,omitzero"`
}

// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
type RouteType string

// ScanKeysRequest Request to scan keys in a table within a key range.
// If no range is specified, scans all keys in the table.
type ScanKeysRequest struct {
	// ExclusiveTo If true, exclude keys matching 'to' from the results.
	// Default: false (inclusive upper bound).
	ExclusiveTo bool `json:"exclusive_to,omitempty,omitzero"`

	// Fields List of fields to include in each result. If not specified,
	// only returns the key. Supports:
	// - Simple fields: "title", "author"
	// - Nested paths: "user.address.city"
	// - Wildcards: "_chunks.*"
	// - Exclusions: "-_chunks.*._embedding"
	// - Special fields: "_embeddings", "_summaries", "_chunks"
	Fields []string `json:"fields,omitempty,omitzero"`

	// FilterQuery Bleve query to filter documents. Only documents matching this query
	// are included in results. Uses the sear library for efficient per-document
	// matching without requiring a full index.
	//
	// Examples:
	// - Status filtering: `{"query": "status:published"}`
	// - Date ranges: `{"query": "created_at:>2023-01-01"}`
	// - Field matching: `{"query": "category:technology"}`
	FilterQuery json.RawMessage `json:"filter_query,omitempty,omitzero"`

	// From Start of the key range to scan (exclusive by default).
	// Can be a full key or a prefix. If not specified, starts from
	// the beginning of the table.
	From string `json:"from,omitempty,omitzero"`

	// InclusiveFrom If true, include keys matching 'from' in the results.
	// Default: false (exclusive lower bound for pagination).
	InclusiveFrom bool `json:"inclusive_from,omitempty,omitzero"`

	// Limit Maximum number of results to return. If not specified, returns all
	// matching keys in the range. Useful for pagination or sampling.
	Limit int `json:"limit,omitempty,omitzero"`

	// To End of the key range to scan (inclusive by default).
	// Can be a full key or a prefix. If not specified, scans to
	// the end of the table.
	To string `json:"to,omitempty,omitzero"`
}

// SemanticQueryMode Mode for semantic query generation:
// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
type SemanticQueryMode string

// SerperSearchConfig defines model for SerperSearchConfig.
type SerperSearchConfig struct {
	// ApiKey Serper API key (or set SERPER_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// SearchType Type of search to perform
	SearchType SerperSearchConfigSearchType `json:"search_type,omitempty,omitzero"`

	// TimePeriod Time period filter: d=day, w=week, m=month, y=year
	TimePeriod SerperSearchConfigTimePeriod `json:"time_period,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// SerperSearchConfigSearchType Type of search to perform
type SerperSearchConfigSearchType string

// SerperSearchConfigTimePeriod Time period filter: d=day, w=week, m=month, y=year
type SerperSearchConfigTimePeriod string

// ShardConfig defines model for ShardConfig.
type ShardConfig struct {
	ByteRange ByteRange `json:"byte_range"`
}

// SignificanceAlgorithm Algorithm for computing term significance:
// - jlh: JLH algorithm (default)
// - mutual_information: Mutual Information
// - chi_squared: Chi-squared test
// - percentage: Simple percentage comparison
type SignificanceAlgorithm string

// StorageStatus defines model for StorageStatus.
type StorageStatus struct {
	// DiskUsage Disk usage in bytes.
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Empty Whether the table has received data.
	Empty bool `json:"empty,omitempty,omitzero"`
}

// SuccessMessage defines model for SuccessMessage.
type SuccessMessage struct {
	Message string `json:"message,omitempty,omitzero"`
}

// SyncLevel Synchronization level for batch operations:
// - "propose": Wait for Raft proposal acceptance (fastest, default)
// - "write": Wait for Pebble KV write
// - "full_text": Wait for full-text index WAL write
// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
type SyncLevel string

// Table defines model for Table.
type Table struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema            `json:"schema,omitempty,omitzero"`
	Shards map[string]ShardConfig `json:"shards"`
}

// TableBackupStatus defines model for TableBackupStatus.
type TableBackupStatus struct {
	// Error Error message if backup failed
	Error string `json:"error,omitempty,omitzero"`

	// Name Table name
	Name string `json:"name"`

	// Status Backup status for this table
	Status TableBackupStatusStatus `json:"status"`
}

// TableBackupStatusStatus Backup status for this table
type TableBackupStatusStatus string

// TableRestoreStatus defines model for TableRestoreStatus.
type TableRestoreStatus struct {
	// Error Error message if restore failed
	Error string `json:"error,omitempty,omitzero"`

	// Name Table name
	Name string `json:"name"`

	// Status Restore status for this table
	Status TableRestoreStatusStatus `json:"status"`
}

// TableRestoreStatusStatus Restore status for this table
type TableRestoreStatusStatus string

// TableSchema Schema definition for a table with multiple document types
type TableSchema struct {
	// DefaultType Default type to use from the document_types.
	DefaultType string `json:"default_type,omitempty,omitzero"`

	// DocumentSchemas A map of type names to their document json schemas.
	DocumentSchemas map[string]DocumentSchema `json:"document_schemas,omitempty,omitzero"`

	// DynamicTemplates Rules for mapping dynamically detected fields. When a document contains fields
	// that don't have explicit mappings and dynamic mapping is enabled, templates are
	// evaluated in order to determine how those fields should be indexed.
	DynamicTemplates []DynamicTemplate `json:"dynamic_templates,omitempty,omitzero"`

	// EnforceTypes Whether to enforce that documents must match one of the provided document types.
	// If false, documents not matching any type will be accepted but not indexed.
	EnforceTypes bool `json:"enforce_types,omitempty,omitzero"`

	// TtlDuration The duration after which documents should expire, based on the ttl_field timestamp (optional).
	// Uses Go duration format (e.g., '24h', '7d', '168h').
	TtlDuration string `json:"ttl_duration,omitempty,omitzero"`

	// TtlField The field containing the timestamp for TTL expiration (optional).
	// Defaults to "_timestamp" if ttl_duration is specified but ttl_field is not.
	TtlField string `json:"ttl_field,omitempty,omitzero"`

	// Version Version of the schema. Used for migrations.
	Version uint32 `json:"version,omitempty,omitzero"`
}

// TableStatus defines model for TableStatus.
type TableStatus struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema        TableSchema            `json:"schema,omitempty,omitzero"`
	Shards        map[string]ShardConfig `json:"shards"`
	StorageStatus StorageStatus          `json:"storage_status"`
}

// TavilySearchConfig defines model for TavilySearchConfig.
type TavilySearchConfig struct {
	// ApiKey Tavily API key (or set TAVILY_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// ExcludeDomains Exclude results from these domains
	ExcludeDomains []string `json:"exclude_domains,omitempty,omitzero"`

	// IncludeAnswer Include AI-generated answer summary
	IncludeAnswer bool `json:"include_answer,omitempty,omitzero"`

	// IncludeDomains Only include results from these domains
	IncludeDomains []string `json:"include_domains,omitempty,omitzero"`

	// IncludeRawContent Include raw HTML content of pages
	IncludeRawContent bool `json:"include_raw_content,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// SearchDepth Search depth:
	// - basic: Fast search with standard results
	// - advanced: Deeper search with more comprehensive results
	SearchDepth TavilySearchConfigSearchDepth `json:"search_depth,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// TavilySearchConfigSearchDepth Search depth:
// - basic: Fast search with standard results
// - advanced: Deeper search with more comprehensive results
type TavilySearchConfigSearchDepth string

// TemplateFieldMapping Field mapping to apply when a dynamic template matches
type TemplateFieldMapping struct {
	// Analyzer Analyzer name (e.g., "standard", "keyword", "en", "html_analyzer").
	// Used for text fields to control tokenization and normalization.
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// DocValues Whether to enable doc values for sorting/faceting
	DocValues bool `json:"doc_values,omitempty,omitzero"`

	// IncludeInAll Whether to include in the _all field for cross-field search
	IncludeInAll bool `json:"include_in_all,omitempty,omitzero"`

	// Index Whether to index the field (default true)
	Index bool `json:"index,omitempty,omitzero"`

	// Store Whether to store the field value (default false)
	Store bool `json:"store,omitempty,omitzero"`

	// Type Field type annotations for schema fields
	Type SchemasAntflyType `json:"type,omitempty,omitzero"`
}

// TermQuery defines model for TermQuery.
type TermQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
	Term  string `json:"term"`
}

// TermRangeQuery defines model for TermRangeQuery.
type TermRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost  `json:"boost,omitzero"`
	Field        string `json:"field,omitempty,omitzero"`
	InclusiveMax bool   `json:"inclusive_max,omitzero"`
	InclusiveMin bool   `json:"inclusive_min,omitzero"`
	Max          string `json:"max,omitzero"`
	Min          string `json:"min,omitzero"`
}

// TermiteChunkerConfig defines model for TermiteChunkerConfig.
type TermiteChunkerConfig struct {
	// ApiUrl The URL of the Termite API endpoint (e.g., 'http://localhost:8080'). Can also be set via ANTFLY_TERMITE_URL environment variable.
	ApiUrl string `json:"api_url,omitempty,omitzero"`

	// FullText Configuration for full-text indexing of chunks in Bleve.
	// When present (even if empty), chunks will be stored with :cft: suffix and indexed in Bleve's _chunks field.
	// When absent, chunks use :c: suffix and are only used for vector embeddings.
	// This object is reserved for future options like boosting, field mapping, etc.
	FullText map[string]interface{} `json:"full_text,omitempty,omitzero"`

	// MaxChunks Maximum number of chunks to generate per document.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// Model The chunking model to use. Either 'fixed' for simple token-based chunking, or a model name from models/chunkers/{name}/.
	Model string `json:"model"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries. Only used by fixed-size chunkers.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs). Only used by fixed-size chunkers.
	Separator string `json:"separator,omitempty,omitzero"`

	// TargetTokens Target number of tokens per chunk.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`

	// Threshold Minimum confidence threshold for separator detection (0.0-1.0). Only used by ONNX models.
	Threshold float32 `json:"threshold,omitempty,omitzero"`
}

// TermiteEmbedderConfig Configuration for the Termite embedding provider.
//
// Termite is Antfly's built-in ML service for local embeddings using ONNX models.
// It provides embedding generation with multi-tier caching (memory + persistent).
//
// **Features:**
// - Local ONNX-based embedding generation
// - L1 memory cache with configurable TTL
// - L2 persistent Pebble database cache
// - Singleflight deduplication for concurrent identical requests
//
// **Example Models:** bge-base-en-v1.5 (768 dims), all-MiniLM-L6-v2 (384 dims)
//
// Models are loaded from the `models/embedders/{name}/` directory.
type TermiteEmbedderConfig struct {
	// ApiUrl The URL of the Termite API endpoint. Can also be set via ANTFLY_TERMITE_URL environment variable.
	ApiUrl string `json:"api_url,omitempty,omitzero"`

	// Model The embedding model name (maps to models/embedders/{name}/ directory).
	Model string `json:"model"`
}

// TermiteGeneratorConfig Configuration for the Termite generative AI provider.
//
// Termite is Antfly's built-in ML service for local LLM inference using
// ONNX Runtime GenAI models. It provides text generation with automatic
// model discovery from the `models/generators/` directory.
//
// **Example Models:** onnxruntime/Gemma-3-ONNX (from HuggingFace)
//
// **Features:**
// - Local inference with no external API dependencies
// - ONNX Runtime GenAI for efficient CPU/GPU execution
// - Auto-discovery of models from `models/generators/` directory
// - OpenAI-compatible chat format
type TermiteGeneratorConfig struct {
	// ApiUrl The URL of the Termite API endpoint.
	ApiUrl string `json:"api_url,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the generator model (maps to models/generators/{name}/ directory).
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// TermiteRerankerConfig Configuration for the Termite reranking provider.
type TermiteRerankerConfig struct {
	// Model The name of the reranking model (e.g., cross-encoder model name).
	Model string `json:"model"`

	// Url The URL of the Termite API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// Transform In-place document transformation using MongoDB-style operators. Transforms are applied atomically
// at the storage layer, eliminating read-modify-write races.
//
// **Important:** Transform results are NOT validated against the table schema. This improves performance
// but means it's possible to create invalid documents. Use with care and ensure your operations maintain
// schema compliance.
type Transform struct {
	// Key Document key (must be a string, not an object like inserts)
	Key string `json:"key"`

	// Operations List of operations to apply in sequence
	Operations []TransformOp `json:"operations"`

	// Upsert If true, create document if it doesn't exist (like MongoDB upsert)
	Upsert bool `json:"upsert,omitempty,omitzero"`
}

// TransformOp defines model for TransformOp.
type TransformOp struct {
	// Op MongoDB-style update operator
	Op TransformOpType `json:"op"`

	// Path JSONPath to field (e.g., "$.user.name", "$.tags", or "user.name")
	Path string `json:"path"`

	// Value Value for operation (not required for $unset, $currentDate). Type depends on operator (number for $inc/$mul, any for $set, etc.)
	Value interface{} `json:"value,omitempty,omitzero"`
}

// TransformOpType MongoDB-style update operator
type TransformOpType string

// TraversalResult A single result from graph traversal
type TraversalResult struct {
	// Depth Distance from start node (0 = start node)
	Depth int `json:"depth"`

	// Document Document data (if loaded)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Key Base64-encoded document key
	Key []byte `json:"key"`

	// Path Sequence of keys from start to this node (if include_paths=true)
	Path [][]byte `json:"path,omitempty,omitzero"`

	// PathEdges Sequence of edges from start to this node (if include_paths=true)
	PathEdges []Edge `json:"path_edges,omitempty,omitzero"`

	// TotalWeight Product of edge weights along the path
	TotalWeight float64 `json:"total_weight,omitempty,omitzero"`
}

// TraversalRules Rules for graph traversal
type TraversalRules struct {
	// DeduplicateNodes Visit each node only once
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter edges by type (empty = all types)
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information in results
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth (0 = unlimited)
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum results to return (0 = unlimited)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight filter
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight filter
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`
}

// TraverseResponse defines model for TraverseResponse.
type TraverseResponse struct {
	// Count Total number of results
	Count   int               `json:"count,omitempty,omitzero"`
	Results []TraversalResult `json:"results,omitempty,omitzero"`
}

// UpdatePasswordRequest defines model for UpdatePasswordRequest.
type UpdatePasswordRequest struct {
	NewPassword string `json:"new_password"`
}

// User defines model for User.
type User struct {
	// PasswordHash Base64 encoded password hash. Exposing this is a security risk.
	PasswordHash []byte `json:"password_hash"`
	Username     string `json:"username"`
}

// VertexEmbedderConfig Configuration for Google Cloud Vertex AI embedding models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication. Requires IAM role `roles/aiplatform.user`.
//
// **Example Models:** gemini-embedding-001 (default, 3072 dims), multimodalembedding (images/audio/video)
//
// **Docs:** https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings
type VertexEmbedderConfig struct {
	// CredentialsPath Path to service account JSON key file. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Dimension The dimension of the embedding vector (768, 1536, or 3072 for gemini-embedding-001; 128-1408 for multimodalembedding).
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the Vertex AI embedding model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`
}

// VertexGeneratorConfig Configuration for Google Cloud Vertex AI generative models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication. In GCP environments
// (Cloud Run, GKE, Compute Engine) this is automatic. For local dev, run
// `gcloud auth application-default login`. Requires IAM role `roles/aiplatform.user`.
//
// **Example Models:** gemini-2.5-flash (default), gemini-2.5-pro, gemini-3.0-pro
//
// **Docs:** https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models
type VertexGeneratorConfig struct {
	// CredentialsPath Path to service account JSON key file. Sets GOOGLE_APPLICATION_CREDENTIALS environment variable. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Vertex AI model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// VertexRerankerConfig Configuration for the Google Vertex AI Ranking API.
//
// Uses Application Default Credentials (ADC) or explicit credentials path.
//
// **Prerequisites:**
// - Enable Discovery Engine API: `gcloud services enable discoveryengine.googleapis.com`
// - Grant IAM role: `roles/discoveryengine.admin` (includes `discoveryengine.rankingConfigs.rank` permission)
//
// **Models:** semantic-ranker-default@latest (default), semantic-ranker-fast-004
//
// **Docs:** https://cloud.google.com/generative-ai-app-builder/docs/ranking
//
// **IAM:** https://cloud.google.com/generative-ai-app-builder/docs/access-control
type VertexRerankerConfig struct {
	// CredentialsPath Path to service account JSON file. Falls back to GOOGLE_APPLICATION_CREDENTIALS environment variable.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Model The ranking model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Falls back to GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// TopN Maximum number of records to return. If not specified, returns all documents with scores.
	TopN int `json:"top_n,omitempty,omitzero"`
}

// WebSearchConfig A unified configuration for web search providers.
//
// Each provider has specific configuration requirements. Use the appropriate
// provider-specific config or set common options at the top level.
//
// **Environment Variables (fallbacks):**
// - GOOGLE_CSE_API_KEY, GOOGLE_CSE_ID
// - BING_SEARCH_API_KEY
// - SERPER_API_KEY
// - TAVILY_API_KEY
// - BRAVE_API_KEY
type WebSearchConfig struct {
	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// WebSearchProvider The web search provider to use.
//
// - **google**: Google Custom Search API (requires CSE setup)
// - **bing**: Microsoft Bing Web Search API
// - **serper**: Serper.dev Google Search API (simpler setup)
// - **tavily**: Tavily AI Search API (optimized for RAG)
// - **brave**: Brave Search API
// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
type WebSearchProvider string

// WildcardQuery defines model for WildcardQuery.
type WildcardQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Field    string `json:"field,omitempty,omitzero"`
	Wildcard string `json:"wildcard"`
}

// SchemasAntflyType Field type annotations for schema fields
type SchemasAntflyType string

// SchemasChatAgentResult Result from the chat agent. Contains the assistant's response,
// any pending clarifications, applied filters, and conversation state.
type SchemasChatAgentResult struct {
	// Answer Final answer text (if available)
	Answer string `json:"answer,omitempty,omitzero"`

	// AnswerConfidence Confidence in the answer
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// AppliedFilters Filters that have been applied in this conversation
	AppliedFilters []FilterSpec `json:"applied_filters,omitempty,omitzero"`

	// Messages Updated conversation history including the assistant's response
	Messages []ChatMessage `json:"messages"`

	// PendingClarification A request for clarification from the user
	PendingClarification ClarificationRequest `json:"pending_clarification,omitempty,omitzero"`

	// QueryResults Search results from executed queries
	QueryResults []map[string]interface{} `json:"query_results,omitempty,omitzero"`

	// ToolCallsMade Number of tool calls made in this turn
	ToolCallsMade int `json:"tool_calls_made,omitempty,omitzero"`
}

// UserNamePathParameter defines model for UserNamePathParameter.
type UserNamePathParameter = string

// BadRequest defines model for BadRequest.
type BadRequest = Error

// InternalServerError defines model for InternalServerError.
type InternalServerError = Error

// NotFound defines model for NotFound.
type NotFound = Error

// ListBackupsParams defines parameters for ListBackups.
type ListBackupsParams struct {
	// Location Storage location to search for backups.
	// - Local filesystem: `file:///path/to/backup`
	// - Amazon S3: `s3://bucket-name/path/to/backup`
	Location string `form:"location" json:"location"`
}

// ListTablesParams defines parameters for ListTables.
type ListTablesParams struct {
	// Prefix Filter tables by name prefix (e.g., "prod_")
	Prefix string `form:"prefix,omitempty" json:"prefix,omitempty,omitzero"`

	// Pattern Filter tables by regex pattern (e.g., "^prod_.*_v[0-9]+$")
	Pattern string `form:"pattern,omitempty" json:"pattern,omitempty,omitzero"`
}

// LookupKeyParams defines parameters for LookupKey.
type LookupKeyParams struct {
	// Fields Comma-separated list of fields to include in the response.
	// If not specified, returns the full document. Supports:
	// - Simple fields: "title,author"
	// - Nested paths: "user.address.city"
	// - Wildcards: "_chunks.*"
	// - Exclusions: "-_chunks.*._embedding"
	// - Special fields: "_embeddings,_summaries,_chunks"
	Fields string `form:"fields,omitempty" json:"fields,omitempty,omitzero"`
}

// RemovePermissionFromUserParams defines parameters for RemovePermissionFromUser.
type RemovePermissionFromUserParams struct {
	// Resource The name of the resource for the permission to be removed.
	Resource string `form:"resource" json:"resource"`

	// ResourceType The type of the resource for the permission to be removed.
	ResourceType ResourceType `form:"resourceType" json:"resourceType"`
}

// AnswerAgentJSONRequestBody defines body for AnswerAgent for application/json ContentType.
type AnswerAgentJSONRequestBody = AnswerAgentRequest

// ChatAgentJSONRequestBody defines body for ChatAgent for application/json ContentType.
type ChatAgentJSONRequestBody = ChatAgentRequest

// QueryBuilderAgentJSONRequestBody defines body for QueryBuilderAgent for application/json ContentType.
type QueryBuilderAgentJSONRequestBody = QueryBuilderRequest

// BackupJSONRequestBody defines body for Backup for application/json ContentType.
type BackupJSONRequestBody = ClusterBackupRequest

// EvaluateJSONRequestBody defines body for Evaluate for application/json ContentType.
type EvaluateJSONRequestBody = EvalRequest

// GlobalQueryJSONRequestBody defines body for GlobalQuery for application/json ContentType.
type GlobalQueryJSONRequestBody = QueryRequest

// RagQueryJSONRequestBody defines body for RagQuery for application/json ContentType.
type RagQueryJSONRequestBody = RAGRequest

// RestoreJSONRequestBody defines body for Restore for application/json ContentType.
type RestoreJSONRequestBody = ClusterRestoreRequest

// CreateTableJSONRequestBody defines body for CreateTable for application/json ContentType.
type CreateTableJSONRequestBody = CreateTableRequest

// BackupTableJSONRequestBody defines body for BackupTable for application/json ContentType.
type BackupTableJSONRequestBody = BackupRequest

// BatchWriteJSONRequestBody defines body for BatchWrite for application/json ContentType.
type BatchWriteJSONRequestBody = BatchRequest

// CreateIndexJSONRequestBody defines body for CreateIndex for application/json ContentType.
type CreateIndexJSONRequestBody = IndexConfig

// ScanKeysJSONRequestBody defines body for ScanKeys for application/json ContentType.
type ScanKeysJSONRequestBody = ScanKeysRequest

// LinearMergeJSONRequestBody defines body for LinearMerge for application/json ContentType.
type LinearMergeJSONRequestBody = LinearMergeRequest

// QueryTableJSONRequestBody defines body for QueryTable for application/json ContentType.
type QueryTableJSONRequestBody = QueryRequest

// TableRagQueryJSONRequestBody defines body for TableRagQuery for application/json ContentType.
type TableRagQueryJSONRequestBody = RAGRequest

// RestoreTableJSONRequestBody defines body for RestoreTable for application/json ContentType.
type RestoreTableJSONRequestBody = RestoreRequest

// UpdateSchemaJSONRequestBody defines body for UpdateSchema for application/json ContentType.
type UpdateSchemaJSONRequestBody = TableSchema

// CreateUserJSONRequestBody defines body for CreateUser for application/json ContentType.
type CreateUserJSONRequestBody = CreateUserRequest

// UpdateUserPasswordJSONRequestBody defines body for UpdateUserPassword for application/json ContentType.
type UpdateUserPasswordJSONRequestBody = UpdatePasswordRequest

// AddPermissionToUserJSONRequestBody defines body for AddPermissionToUser for application/json ContentType.
type AddPermissionToUserJSONRequestBody = Permission

// Getter for additional properties for ClusterStatus. Returns the specified
// element and whether it was found
func (a ClusterStatus) Get(fieldName string) (value interface{}, found bool) {
	if a.AdditionalProperties != nil {
		value, found = a.AdditionalProperties[fieldName]
	}
	return
}

// Setter for additional properties for ClusterStatus
func (a *ClusterStatus) Set(fieldName string, value interface{}) {
	if a.AdditionalProperties == nil {
		a.AdditionalProperties = make(map[string]interface{})
	}
	a.AdditionalProperties[fieldName] = value
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a *ClusterStatus) UnmarshalJSON(b []byte) error {
	object := make(map[string]json.RawMessage)
	err := json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["auth_enabled"]; found {
		err = json.Unmarshal(raw, &a.AuthEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'auth_enabled': %w", err)
		}
		delete(object, "auth_enabled")
	}

	if raw, found := object["health"]; found {
		err = json.Unmarshal(raw, &a.Health)
		if err != nil {
			return fmt.Errorf("error reading 'health': %w", err)
		}
		delete(object, "health")
	}

	if raw, found := object["message"]; found {
		err = json.Unmarshal(raw, &a.Message)
		if err != nil {
			return fmt.Errorf("error reading 'message': %w", err)
		}
		delete(object, "message")
	}

	if len(object) != 0 {
		a.AdditionalProperties = make(map[string]interface{})
		for fieldName, fieldBuf := range object {
			var fieldVal interface{}
			err := json.Unmarshal(fieldBuf, &fieldVal)
			if err != nil {
				return fmt.Errorf("error unmarshaling field %s: %w", fieldName, err)
			}
			a.AdditionalProperties[fieldName] = fieldVal
		}
	}
	return nil
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a ClusterStatus) MarshalJSON() ([]byte, error) {
	var err error
	object := make(map[string]json.RawMessage)

	object["auth_enabled"], err = json.Marshal(a.AuthEnabled)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'auth_enabled': %w", err)
	}

	object["health"], err = json.Marshal(a.Health)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'health': %w", err)
	}

	object["message"], err = json.Marshal(a.Message)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'message': %w", err)
	}

	for fieldName, field := range a.AdditionalProperties {
		object[fieldName], err = json.Marshal(field)
		if err != nil {
			return nil, fmt.Errorf("error marshaling '%s': %w", fieldName, err)
		}
	}
	return json.Marshal(object)
}

// AsTermiteChunkerConfig returns the union data inside the ChunkerConfig as a TermiteChunkerConfig
func (t ChunkerConfig) AsTermiteChunkerConfig() (TermiteChunkerConfig, error) {
	var body TermiteChunkerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteChunkerConfig overwrites any union data inside the ChunkerConfig as the provided TermiteChunkerConfig
func (t *ChunkerConfig) FromTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteChunkerConfig performs a merge with any union data inside the ChunkerConfig, using the provided TermiteChunkerConfig
func (t *ChunkerConfig) MergeTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAntflyChunkerConfig returns the union data inside the ChunkerConfig as a AntflyChunkerConfig
func (t ChunkerConfig) AsAntflyChunkerConfig() (AntflyChunkerConfig, error) {
	var body AntflyChunkerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAntflyChunkerConfig overwrites any union data inside the ChunkerConfig as the provided AntflyChunkerConfig
func (t *ChunkerConfig) FromAntflyChunkerConfig(v AntflyChunkerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAntflyChunkerConfig performs a merge with any union data inside the ChunkerConfig, using the provided AntflyChunkerConfig
func (t *ChunkerConfig) MergeAntflyChunkerConfig(v AntflyChunkerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t ChunkerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *ChunkerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsGoogleEmbedderConfig returns the union data inside the EmbedderConfig as a GoogleEmbedderConfig
func (t EmbedderConfig) AsGoogleEmbedderConfig() (GoogleEmbedderConfig, error) {
	var body GoogleEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided GoogleEmbedderConfig
func (t *EmbedderConfig) FromGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided GoogleEmbedderConfig
func (t *EmbedderConfig) MergeGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexEmbedderConfig returns the union data inside the EmbedderConfig as a VertexEmbedderConfig
func (t EmbedderConfig) AsVertexEmbedderConfig() (VertexEmbedderConfig, error) {
	var body VertexEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided VertexEmbedderConfig
func (t *EmbedderConfig) FromVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided VertexEmbedderConfig
func (t *EmbedderConfig) MergeVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaEmbedderConfig returns the union data inside the EmbedderConfig as a OllamaEmbedderConfig
func (t EmbedderConfig) AsOllamaEmbedderConfig() (OllamaEmbedderConfig, error) {
	var body OllamaEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OllamaEmbedderConfig
func (t *EmbedderConfig) FromOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OllamaEmbedderConfig
func (t *EmbedderConfig) MergeOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIEmbedderConfig returns the union data inside the EmbedderConfig as a OpenAIEmbedderConfig
func (t EmbedderConfig) AsOpenAIEmbedderConfig() (OpenAIEmbedderConfig, error) {
	var body OpenAIEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) FromOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) MergeOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenRouterEmbedderConfig returns the union data inside the EmbedderConfig as a OpenRouterEmbedderConfig
func (t EmbedderConfig) AsOpenRouterEmbedderConfig() (OpenRouterEmbedderConfig, error) {
	var body OpenRouterEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenRouterEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OpenRouterEmbedderConfig
func (t *EmbedderConfig) FromOpenRouterEmbedderConfig(v OpenRouterEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenRouterEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OpenRouterEmbedderConfig
func (t *EmbedderConfig) MergeOpenRouterEmbedderConfig(v OpenRouterEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockEmbedderConfig returns the union data inside the EmbedderConfig as a BedrockEmbedderConfig
func (t EmbedderConfig) AsBedrockEmbedderConfig() (BedrockEmbedderConfig, error) {
	var body BedrockEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided BedrockEmbedderConfig
func (t *EmbedderConfig) FromBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided BedrockEmbedderConfig
func (t *EmbedderConfig) MergeBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereEmbedderConfig returns the union data inside the EmbedderConfig as a CohereEmbedderConfig
func (t EmbedderConfig) AsCohereEmbedderConfig() (CohereEmbedderConfig, error) {
	var body CohereEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided CohereEmbedderConfig
func (t *EmbedderConfig) FromCohereEmbedderConfig(v CohereEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided CohereEmbedderConfig
func (t *EmbedderConfig) MergeCohereEmbedderConfig(v CohereEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermiteEmbedderConfig returns the union data inside the EmbedderConfig as a TermiteEmbedderConfig
func (t EmbedderConfig) AsTermiteEmbedderConfig() (TermiteEmbedderConfig, error) {
	var body TermiteEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided TermiteEmbedderConfig
func (t *EmbedderConfig) FromTermiteEmbedderConfig(v TermiteEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided TermiteEmbedderConfig
func (t *EmbedderConfig) MergeTermiteEmbedderConfig(v TermiteEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t EmbedderConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *EmbedderConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsFuzziness0 returns the union data inside the Fuzziness as a Fuzziness0
func (t Fuzziness) AsFuzziness0() (Fuzziness0, error) {
	var body Fuzziness0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness0 overwrites any union data inside the Fuzziness as the provided Fuzziness0
func (t *Fuzziness) FromFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness0 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness0
func (t *Fuzziness) MergeFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzziness1 returns the union data inside the Fuzziness as a Fuzziness1
func (t Fuzziness) AsFuzziness1() (Fuzziness1, error) {
	var body Fuzziness1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness1 overwrites any union data inside the Fuzziness as the provided Fuzziness1
func (t *Fuzziness) FromFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness1 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness1
func (t *Fuzziness) MergeFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Fuzziness) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Fuzziness) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsGoogleGeneratorConfig returns the union data inside the GeneratorConfig as a GoogleGeneratorConfig
func (t GeneratorConfig) AsGoogleGeneratorConfig() (GoogleGeneratorConfig, error) {
	var body GoogleGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided GoogleGeneratorConfig
func (t *GeneratorConfig) FromGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided GoogleGeneratorConfig
func (t *GeneratorConfig) MergeGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexGeneratorConfig returns the union data inside the GeneratorConfig as a VertexGeneratorConfig
func (t GeneratorConfig) AsVertexGeneratorConfig() (VertexGeneratorConfig, error) {
	var body VertexGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided VertexGeneratorConfig
func (t *GeneratorConfig) FromVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided VertexGeneratorConfig
func (t *GeneratorConfig) MergeVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaGeneratorConfig returns the union data inside the GeneratorConfig as a OllamaGeneratorConfig
func (t GeneratorConfig) AsOllamaGeneratorConfig() (OllamaGeneratorConfig, error) {
	var body OllamaGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OllamaGeneratorConfig
func (t *GeneratorConfig) FromOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OllamaGeneratorConfig
func (t *GeneratorConfig) MergeOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermiteGeneratorConfig returns the union data inside the GeneratorConfig as a TermiteGeneratorConfig
func (t GeneratorConfig) AsTermiteGeneratorConfig() (TermiteGeneratorConfig, error) {
	var body TermiteGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided TermiteGeneratorConfig
func (t *GeneratorConfig) FromTermiteGeneratorConfig(v TermiteGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided TermiteGeneratorConfig
func (t *GeneratorConfig) MergeTermiteGeneratorConfig(v TermiteGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIGeneratorConfig returns the union data inside the GeneratorConfig as a OpenAIGeneratorConfig
func (t GeneratorConfig) AsOpenAIGeneratorConfig() (OpenAIGeneratorConfig, error) {
	var body OpenAIGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) FromOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) MergeOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenRouterGeneratorConfig returns the union data inside the GeneratorConfig as a OpenRouterGeneratorConfig
func (t GeneratorConfig) AsOpenRouterGeneratorConfig() (OpenRouterGeneratorConfig, error) {
	var body OpenRouterGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenRouterGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OpenRouterGeneratorConfig
func (t *GeneratorConfig) FromOpenRouterGeneratorConfig(v OpenRouterGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenRouterGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OpenRouterGeneratorConfig
func (t *GeneratorConfig) MergeOpenRouterGeneratorConfig(v OpenRouterGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockGeneratorConfig returns the union data inside the GeneratorConfig as a BedrockGeneratorConfig
func (t GeneratorConfig) AsBedrockGeneratorConfig() (BedrockGeneratorConfig, error) {
	var body BedrockGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided BedrockGeneratorConfig
func (t *GeneratorConfig) FromBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided BedrockGeneratorConfig
func (t *GeneratorConfig) MergeBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAnthropicGeneratorConfig returns the union data inside the GeneratorConfig as a AnthropicGeneratorConfig
func (t GeneratorConfig) AsAnthropicGeneratorConfig() (AnthropicGeneratorConfig, error) {
	var body AnthropicGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAnthropicGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) FromAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAnthropicGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) MergeAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereGeneratorConfig returns the union data inside the GeneratorConfig as a CohereGeneratorConfig
func (t GeneratorConfig) AsCohereGeneratorConfig() (CohereGeneratorConfig, error) {
	var body CohereGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided CohereGeneratorConfig
func (t *GeneratorConfig) FromCohereGeneratorConfig(v CohereGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided CohereGeneratorConfig
func (t *GeneratorConfig) MergeCohereGeneratorConfig(v CohereGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t GeneratorConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *GeneratorConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Config returns the union data inside the IndexConfig as a BleveIndexV2Config
func (t IndexConfig) AsBleveIndexV2Config() (BleveIndexV2Config, error) {
	var body BleveIndexV2Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Config overwrites any union data inside the IndexConfig as the provided BleveIndexV2Config
func (t *IndexConfig) FromBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Config performs a merge with any union data inside the IndexConfig, using the provided BleveIndexV2Config
func (t *IndexConfig) MergeBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexConfig returns the union data inside the IndexConfig as a EmbeddingIndexConfig
func (t IndexConfig) AsEmbeddingIndexConfig() (EmbeddingIndexConfig, error) {
	var body EmbeddingIndexConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexConfig overwrites any union data inside the IndexConfig as the provided EmbeddingIndexConfig
func (t *IndexConfig) FromEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexConfig performs a merge with any union data inside the IndexConfig, using the provided EmbeddingIndexConfig
func (t *IndexConfig) MergeEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Config returns the union data inside the IndexConfig as a GraphIndexV0Config
func (t IndexConfig) AsGraphIndexV0Config() (GraphIndexV0Config, error) {
	var body GraphIndexV0Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Config overwrites any union data inside the IndexConfig as the provided GraphIndexV0Config
func (t *IndexConfig) FromGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Config performs a merge with any union data inside the IndexConfig, using the provided GraphIndexV0Config
func (t *IndexConfig) MergeGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["description"], err = json.Marshal(t.Description)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'description': %w", err)
	}

	if t.Enrichments != nil {
		object["enrichments"], err = json.Marshal(t.Enrichments)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'enrichments': %w", err)
		}
	}

	object["name"], err = json.Marshal(t.Name)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'name': %w", err)
	}

	object["type"], err = json.Marshal(t.Type)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'type': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *IndexConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["description"]; found {
		err = json.Unmarshal(raw, &t.Description)
		if err != nil {
			return fmt.Errorf("error reading 'description': %w", err)
		}
	}

	if raw, found := object["enrichments"]; found {
		err = json.Unmarshal(raw, &t.Enrichments)
		if err != nil {
			return fmt.Errorf("error reading 'enrichments': %w", err)
		}
	}

	if raw, found := object["name"]; found {
		err = json.Unmarshal(raw, &t.Name)
		if err != nil {
			return fmt.Errorf("error reading 'name': %w", err)
		}
	}

	if raw, found := object["type"]; found {
		err = json.Unmarshal(raw, &t.Type)
		if err != nil {
			return fmt.Errorf("error reading 'type': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Stats returns the union data inside the IndexStats as a BleveIndexV2Stats
func (t IndexStats) AsBleveIndexV2Stats() (BleveIndexV2Stats, error) {
	var body BleveIndexV2Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Stats overwrites any union data inside the IndexStats as the provided BleveIndexV2Stats
func (t *IndexStats) FromBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Stats performs a merge with any union data inside the IndexStats, using the provided BleveIndexV2Stats
func (t *IndexStats) MergeBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexStats returns the union data inside the IndexStats as a EmbeddingIndexStats
func (t IndexStats) AsEmbeddingIndexStats() (EmbeddingIndexStats, error) {
	var body EmbeddingIndexStats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexStats overwrites any union data inside the IndexStats as the provided EmbeddingIndexStats
func (t *IndexStats) FromEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexStats performs a merge with any union data inside the IndexStats, using the provided EmbeddingIndexStats
func (t *IndexStats) MergeEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Stats returns the union data inside the IndexStats as a GraphIndexV0Stats
func (t IndexStats) AsGraphIndexV0Stats() (GraphIndexV0Stats, error) {
	var body GraphIndexV0Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Stats overwrites any union data inside the IndexStats as the provided GraphIndexV0Stats
func (t *IndexStats) FromGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Stats performs a merge with any union data inside the IndexStats, using the provided GraphIndexV0Stats
func (t *IndexStats) MergeGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexStats) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *IndexStats) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsTermQuery returns the union data inside the Query as a TermQuery
func (t Query) AsTermQuery() (TermQuery, error) {
	var body TermQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermQuery overwrites any union data inside the Query as the provided TermQuery
func (t *Query) FromTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermQuery performs a merge with any union data inside the Query, using the provided TermQuery
func (t *Query) MergeTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchQuery returns the union data inside the Query as a MatchQuery
func (t Query) AsMatchQuery() (MatchQuery, error) {
	var body MatchQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchQuery overwrites any union data inside the Query as the provided MatchQuery
func (t *Query) FromMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchQuery performs a merge with any union data inside the Query, using the provided MatchQuery
func (t *Query) MergeMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchPhraseQuery returns the union data inside the Query as a MatchPhraseQuery
func (t Query) AsMatchPhraseQuery() (MatchPhraseQuery, error) {
	var body MatchPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchPhraseQuery overwrites any union data inside the Query as the provided MatchPhraseQuery
func (t *Query) FromMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchPhraseQuery performs a merge with any union data inside the Query, using the provided MatchPhraseQuery
func (t *Query) MergeMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPhraseQuery returns the union data inside the Query as a PhraseQuery
func (t Query) AsPhraseQuery() (PhraseQuery, error) {
	var body PhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPhraseQuery overwrites any union data inside the Query as the provided PhraseQuery
func (t *Query) FromPhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePhraseQuery performs a merge with any union data inside the Query, using the provided PhraseQuery
func (t *Query) MergePhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMultiPhraseQuery returns the union data inside the Query as a MultiPhraseQuery
func (t Query) AsMultiPhraseQuery() (MultiPhraseQuery, error) {
	var body MultiPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMultiPhraseQuery overwrites any union data inside the Query as the provided MultiPhraseQuery
func (t *Query) FromMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMultiPhraseQuery performs a merge with any union data inside the Query, using the provided MultiPhraseQuery
func (t *Query) MergeMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzzyQuery returns the union data inside the Query as a FuzzyQuery
func (t Query) AsFuzzyQuery() (FuzzyQuery, error) {
	var body FuzzyQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzzyQuery overwrites any union data inside the Query as the provided FuzzyQuery
func (t *Query) FromFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzzyQuery performs a merge with any union data inside the Query, using the provided FuzzyQuery
func (t *Query) MergeFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPrefixQuery returns the union data inside the Query as a PrefixQuery
func (t Query) AsPrefixQuery() (PrefixQuery, error) {
	var body PrefixQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPrefixQuery overwrites any union data inside the Query as the provided PrefixQuery
func (t *Query) FromPrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePrefixQuery performs a merge with any union data inside the Query, using the provided PrefixQuery
func (t *Query) MergePrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsRegexpQuery returns the union data inside the Query as a RegexpQuery
func (t Query) AsRegexpQuery() (RegexpQuery, error) {
	var body RegexpQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromRegexpQuery overwrites any union data inside the Query as the provided RegexpQuery
func (t *Query) FromRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeRegexpQuery performs a merge with any union data inside the Query, using the provided RegexpQuery
func (t *Query) MergeRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsWildcardQuery returns the union data inside the Query as a WildcardQuery
func (t Query) AsWildcardQuery() (WildcardQuery, error) {
	var body WildcardQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromWildcardQuery overwrites any union data inside the Query as the provided WildcardQuery
func (t *Query) FromWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeWildcardQuery performs a merge with any union data inside the Query, using the provided WildcardQuery
func (t *Query) MergeWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsQueryStringQuery returns the union data inside the Query as a QueryStringQuery
func (t Query) AsQueryStringQuery() (QueryStringQuery, error) {
	var body QueryStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromQueryStringQuery overwrites any union data inside the Query as the provided QueryStringQuery
func (t *Query) FromQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeQueryStringQuery performs a merge with any union data inside the Query, using the provided QueryStringQuery
func (t *Query) MergeQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsNumericRangeQuery returns the union data inside the Query as a NumericRangeQuery
func (t Query) AsNumericRangeQuery() (NumericRangeQuery, error) {
	var body NumericRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromNumericRangeQuery overwrites any union data inside the Query as the provided NumericRangeQuery
func (t *Query) FromNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeNumericRangeQuery performs a merge with any union data inside the Query, using the provided NumericRangeQuery
func (t *Query) MergeNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermRangeQuery returns the union data inside the Query as a TermRangeQuery
func (t Query) AsTermRangeQuery() (TermRangeQuery, error) {
	var body TermRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermRangeQuery overwrites any union data inside the Query as the provided TermRangeQuery
func (t *Query) FromTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermRangeQuery performs a merge with any union data inside the Query, using the provided TermRangeQuery
func (t *Query) MergeTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDateRangeStringQuery returns the union data inside the Query as a DateRangeStringQuery
func (t Query) AsDateRangeStringQuery() (DateRangeStringQuery, error) {
	var body DateRangeStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDateRangeStringQuery overwrites any union data inside the Query as the provided DateRangeStringQuery
func (t *Query) FromDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDateRangeStringQuery performs a merge with any union data inside the Query, using the provided DateRangeStringQuery
func (t *Query) MergeDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBooleanQuery returns the union data inside the Query as a BooleanQuery
func (t Query) AsBooleanQuery() (BooleanQuery, error) {
	var body BooleanQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBooleanQuery overwrites any union data inside the Query as the provided BooleanQuery
func (t *Query) FromBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBooleanQuery performs a merge with any union data inside the Query, using the provided BooleanQuery
func (t *Query) MergeBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsConjunctionQuery returns the union data inside the Query as a ConjunctionQuery
func (t Query) AsConjunctionQuery() (ConjunctionQuery, error) {
	var body ConjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromConjunctionQuery overwrites any union data inside the Query as the provided ConjunctionQuery
func (t *Query) FromConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeConjunctionQuery performs a merge with any union data inside the Query, using the provided ConjunctionQuery
func (t *Query) MergeConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDisjunctionQuery returns the union data inside the Query as a DisjunctionQuery
func (t Query) AsDisjunctionQuery() (DisjunctionQuery, error) {
	var body DisjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDisjunctionQuery overwrites any union data inside the Query as the provided DisjunctionQuery
func (t *Query) FromDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDisjunctionQuery performs a merge with any union data inside the Query, using the provided DisjunctionQuery
func (t *Query) MergeDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchAllQuery returns the union data inside the Query as a MatchAllQuery
func (t Query) AsMatchAllQuery() (MatchAllQuery, error) {
	var body MatchAllQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchAllQuery overwrites any union data inside the Query as the provided MatchAllQuery
func (t *Query) FromMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchAllQuery performs a merge with any union data inside the Query, using the provided MatchAllQuery
func (t *Query) MergeMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchNoneQuery returns the union data inside the Query as a MatchNoneQuery
func (t Query) AsMatchNoneQuery() (MatchNoneQuery, error) {
	var body MatchNoneQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchNoneQuery overwrites any union data inside the Query as the provided MatchNoneQuery
func (t *Query) FromMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchNoneQuery performs a merge with any union data inside the Query, using the provided MatchNoneQuery
func (t *Query) MergeMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDocIdQuery returns the union data inside the Query as a DocIdQuery
func (t Query) AsDocIdQuery() (DocIdQuery, error) {
	var body DocIdQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDocIdQuery overwrites any union data inside the Query as the provided DocIdQuery
func (t *Query) FromDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDocIdQuery performs a merge with any union data inside the Query, using the provided DocIdQuery
func (t *Query) MergeDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBoolFieldQuery returns the union data inside the Query as a BoolFieldQuery
func (t Query) AsBoolFieldQuery() (BoolFieldQuery, error) {
	var body BoolFieldQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBoolFieldQuery overwrites any union data inside the Query as the provided BoolFieldQuery
func (t *Query) FromBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBoolFieldQuery performs a merge with any union data inside the Query, using the provided BoolFieldQuery
func (t *Query) MergeBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsIPRangeQuery returns the union data inside the Query as a IPRangeQuery
func (t Query) AsIPRangeQuery() (IPRangeQuery, error) {
	var body IPRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromIPRangeQuery overwrites any union data inside the Query as the provided IPRangeQuery
func (t *Query) FromIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeIPRangeQuery performs a merge with any union data inside the Query, using the provided IPRangeQuery
func (t *Query) MergeIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingBoxQuery returns the union data inside the Query as a GeoBoundingBoxQuery
func (t Query) AsGeoBoundingBoxQuery() (GeoBoundingBoxQuery, error) {
	var body GeoBoundingBoxQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingBoxQuery overwrites any union data inside the Query as the provided GeoBoundingBoxQuery
func (t *Query) FromGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingBoxQuery performs a merge with any union data inside the Query, using the provided GeoBoundingBoxQuery
func (t *Query) MergeGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoDistanceQuery returns the union data inside the Query as a GeoDistanceQuery
func (t Query) AsGeoDistanceQuery() (GeoDistanceQuery, error) {
	var body GeoDistanceQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoDistanceQuery overwrites any union data inside the Query as the provided GeoDistanceQuery
func (t *Query) FromGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoDistanceQuery performs a merge with any union data inside the Query, using the provided GeoDistanceQuery
func (t *Query) MergeGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingPolygonQuery returns the union data inside the Query as a GeoBoundingPolygonQuery
func (t Query) AsGeoBoundingPolygonQuery() (GeoBoundingPolygonQuery, error) {
	var body GeoBoundingPolygonQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingPolygonQuery overwrites any union data inside the Query as the provided GeoBoundingPolygonQuery
func (t *Query) FromGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingPolygonQuery performs a merge with any union data inside the Query, using the provided GeoBoundingPolygonQuery
func (t *Query) MergeGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoShapeQuery returns the union data inside the Query as a GeoShapeQuery
func (t Query) AsGeoShapeQuery() (GeoShapeQuery, error) {
	var body GeoShapeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoShapeQuery overwrites any union data inside the Query as the provided GeoShapeQuery
func (t *Query) FromGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoShapeQuery performs a merge with any union data inside the Query, using the provided GeoShapeQuery
func (t *Query) MergeGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Query) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Query) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsOllamaRerankerConfig returns the union data inside the RerankerConfig as a OllamaRerankerConfig
func (t RerankerConfig) AsOllamaRerankerConfig() (OllamaRerankerConfig, error) {
	var body OllamaRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaRerankerConfig overwrites any union data inside the RerankerConfig as the provided OllamaRerankerConfig
func (t *RerankerConfig) FromOllamaRerankerConfig(v OllamaRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided OllamaRerankerConfig
func (t *RerankerConfig) MergeOllamaRerankerConfig(v OllamaRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermiteRerankerConfig returns the union data inside the RerankerConfig as a TermiteRerankerConfig
func (t RerankerConfig) AsTermiteRerankerConfig() (TermiteRerankerConfig, error) {
	var body TermiteRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteRerankerConfig overwrites any union data inside the RerankerConfig as the provided TermiteRerankerConfig
func (t *RerankerConfig) FromTermiteRerankerConfig(v TermiteRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided TermiteRerankerConfig
func (t *RerankerConfig) MergeTermiteRerankerConfig(v TermiteRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereRerankerConfig returns the union data inside the RerankerConfig as a CohereRerankerConfig
func (t RerankerConfig) AsCohereRerankerConfig() (CohereRerankerConfig, error) {
	var body CohereRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereRerankerConfig overwrites any union data inside the RerankerConfig as the provided CohereRerankerConfig
func (t *RerankerConfig) FromCohereRerankerConfig(v CohereRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided CohereRerankerConfig
func (t *RerankerConfig) MergeCohereRerankerConfig(v CohereRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexRerankerConfig returns the union data inside the RerankerConfig as a VertexRerankerConfig
func (t RerankerConfig) AsVertexRerankerConfig() (VertexRerankerConfig, error) {
	var body VertexRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexRerankerConfig overwrites any union data inside the RerankerConfig as the provided VertexRerankerConfig
func (t *RerankerConfig) FromVertexRerankerConfig(v VertexRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided VertexRerankerConfig
func (t *RerankerConfig) MergeVertexRerankerConfig(v VertexRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t RerankerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["field"], err = json.Marshal(t.Field)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'field': %w", err)
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	object["template"], err = json.Marshal(t.Template)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'template': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *RerankerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["field"]; found {
		err = json.Unmarshal(raw, &t.Field)
		if err != nil {
			return fmt.Errorf("error reading 'field': %w", err)
		}
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	if raw, found := object["template"]; found {
		err = json.Unmarshal(raw, &t.Template)
		if err != nil {
			return fmt.Errorf("error reading 'template': %w", err)
		}
	}

	return err
}

// RequestEditorFn  is the function signature for the RequestEditor callback function
type RequestEditorFn func(ctx context.Context, req *http.Request) error

// Doer performs HTTP requests.
//
// The standard http.Client implements this interface.
type HttpRequestDoer interface {
	Do(req *http.Request) (*http.Response, error)
}

// Client which conforms to the OpenAPI3 specification for this service.
type Client struct {
	// The endpoint of the server conforming to this interface, with scheme,
	// https://api.deepmap.com for example. This can contain a path relative
	// to the server, such as https://api.deepmap.com/dev-test, and all the
	// paths in the swagger spec will be appended to the server.
	Server string

	// Doer for performing requests, typically a *http.Client with any
	// customized settings, such as certificate chains.
	Client HttpRequestDoer

	// A list of callbacks for modifying requests which are generated before sending over
	// the network.
	RequestEditors []RequestEditorFn
}

// ClientOption allows setting custom parameters during construction
type ClientOption func(*Client) error

// Creates a new Client, with reasonable defaults
func NewClient(server string, opts ...ClientOption) (*Client, error) {
	// create a client with sane default values
	client := Client{
		Server: server,
	}
	// mutate client and add all optional params
	for _, o := range opts {
		if err := o(&client); err != nil {
			return nil, err
		}
	}
	// ensure the server URL always has a trailing slash
	if !strings.HasSuffix(client.Server, "/") {
		client.Server += "/"
	}
	// create httpClient, if not already present
	if client.Client == nil {
		client.Client = &http.Client{}
	}
	return &client, nil
}

// WithHTTPClient allows overriding the default Doer, which is
// automatically created using http.Client. This is useful for tests.
func WithHTTPClient(doer HttpRequestDoer) ClientOption {
	return func(c *Client) error {
		c.Client = doer
		return nil
	}
}

// WithRequestEditorFn allows setting up a callback function, which will be
// called right before sending the request. This can be used to mutate the request.
func WithRequestEditorFn(fn RequestEditorFn) ClientOption {
	return func(c *Client) error {
		c.RequestEditors = append(c.RequestEditors, fn)
		return nil
	}
}

// The interface specification for the client above.
type ClientInterface interface {
	// AnswerAgentWithBody request with any body
	AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ChatAgentWithBody request with any body
	ChatAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	ChatAgent(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// QueryBuilderAgentWithBody request with any body
	QueryBuilderAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	QueryBuilderAgent(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BackupWithBody request with any body
	BackupWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Backup(ctx context.Context, body BackupJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListBackups request
	ListBackups(ctx context.Context, params *ListBackupsParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// EvaluateWithBody request with any body
	EvaluateWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Evaluate(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GlobalQueryWithBody request with any body
	GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RagQueryWithBody request with any body
	RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RestoreWithBody request with any body
	RestoreWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Restore(ctx context.Context, body RestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetStatus request
	GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListTables request
	ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropTable request
	DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetTable request
	GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateTableWithBody request with any body
	CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BackupTableWithBody request with any body
	BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BatchWriteWithBody request with any body
	BatchWriteWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	BatchWrite(ctx context.Context, tableName string, body BatchWriteJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListIndexes request
	ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropIndex request
	DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetIndex request
	GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateIndexWithBody request with any body
	CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ScanKeysWithBody request with any body
	ScanKeysWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	ScanKeys(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LookupKey request
	LookupKey(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LinearMergeWithBody request with any body
	LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// QueryTableWithBody request with any body
	QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// TableRagQueryWithBody request with any body
	TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RestoreTableWithBody request with any body
	RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateSchemaWithBody request with any body
	UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListUsers request
	ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetCurrentUser request
	GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteUser request
	DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserByName request
	GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateUserWithBody request with any body
	CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateUserPasswordWithBody request with any body
	UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RemovePermissionFromUser request
	RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserPermissions request
	GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// AddPermissionToUserWithBody request with any body
	AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)
}

func (c *Client) AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ChatAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewChatAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ChatAgent(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewChatAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryBuilderAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryBuilderAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryBuilderAgent(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryBuilderAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Backup(ctx context.Context, body BackupJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListBackups(ctx context.Context, params *ListBackupsParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListBackupsRequest(c.Server, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) EvaluateWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewEvaluateRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Evaluate(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewEvaluateRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Restore(ctx context.Context, body RestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetStatusRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListTablesRequest(c.Server, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BatchWriteWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchWriteRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BatchWrite(ctx context.Context, tableName string, body BatchWriteJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchWriteRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListIndexesRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequestWithBody(c.Server, tableName, indexName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequest(c.Server, tableName, indexName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ScanKeysWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewScanKeysRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ScanKeys(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewScanKeysRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LookupKey(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLookupKeyRequest(c.Server, tableName, key, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListUsersRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetCurrentUserRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteUserRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserByNameRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRemovePermissionFromUserRequest(c.Server, userName, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserPermissionsRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

// NewAnswerAgentRequest calls the generic AnswerAgent builder with application/json body
func NewAnswerAgentRequest(server string, body AnswerAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAnswerAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewAnswerAgentRequestWithBody generates requests for AnswerAgent with any type of body
func NewAnswerAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/answer")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewChatAgentRequest calls the generic ChatAgent builder with application/json body
func NewChatAgentRequest(server string, body ChatAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewChatAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewChatAgentRequestWithBody generates requests for ChatAgent with any type of body
func NewChatAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/chat")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewQueryBuilderAgentRequest calls the generic QueryBuilderAgent builder with application/json body
func NewQueryBuilderAgentRequest(server string, body QueryBuilderAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewQueryBuilderAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewQueryBuilderAgentRequestWithBody generates requests for QueryBuilderAgent with any type of body
func NewQueryBuilderAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/query-builder")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBackupRequest calls the generic Backup builder with application/json body
func NewBackupRequest(server string, body BackupJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBackupRequestWithBody(server, "application/json", bodyReader)
}

// NewBackupRequestWithBody generates requests for Backup with any type of body
func NewBackupRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backup")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListBackupsRequest generates requests for ListBackups
func NewListBackupsRequest(server string, params *ListBackupsParams) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backups")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "location", runtime.ParamLocationQuery, params.Location); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewEvaluateRequest calls the generic Evaluate builder with application/json body
func NewEvaluateRequest(server string, body EvaluateJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewEvaluateRequestWithBody(server, "application/json", bodyReader)
}

// NewEvaluateRequestWithBody generates requests for Evaluate with any type of body
func NewEvaluateRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/eval")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGlobalQueryRequest calls the generic GlobalQuery builder with application/json body
func NewGlobalQueryRequest(server string, body GlobalQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewGlobalQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewGlobalQueryRequestWithBody generates requests for GlobalQuery with any type of body
func NewGlobalQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/query")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRagQueryRequest calls the generic RagQuery builder with application/json body
func NewRagQueryRequest(server string, body RagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRagQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewRagQueryRequestWithBody generates requests for RagQuery with any type of body
func NewRagQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/rag")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRestoreRequest calls the generic Restore builder with application/json body
func NewRestoreRequest(server string, body RestoreJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRestoreRequestWithBody(server, "application/json", bodyReader)
}

// NewRestoreRequestWithBody generates requests for Restore with any type of body
func NewRestoreRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/restore")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetStatusRequest generates requests for GetStatus
func NewGetStatusRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/status")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListTablesRequest generates requests for ListTables
func NewListTablesRequest(server string, params *ListTablesParams) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "prefix", runtime.ParamLocationQuery, params.Prefix); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "pattern", runtime.ParamLocationQuery, params.Pattern); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropTableRequest generates requests for DropTable
func NewDropTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetTableRequest generates requests for GetTable
func NewGetTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateTableRequest calls the generic CreateTable builder with application/json body
func NewCreateTableRequest(server string, tableName string, body CreateTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewCreateTableRequestWithBody generates requests for CreateTable with any type of body
func NewCreateTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBackupTableRequest calls the generic BackupTable builder with application/json body
func NewBackupTableRequest(server string, tableName string, body BackupTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBackupTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBackupTableRequestWithBody generates requests for BackupTable with any type of body
func NewBackupTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/backup", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBatchWriteRequest calls the generic BatchWrite builder with application/json body
func NewBatchWriteRequest(server string, tableName string, body BatchWriteJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBatchWriteRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBatchWriteRequestWithBody generates requests for BatchWrite with any type of body
func NewBatchWriteRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/batch", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListIndexesRequest generates requests for ListIndexes
func NewListIndexesRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropIndexRequest generates requests for DropIndex
func NewDropIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetIndexRequest generates requests for GetIndex
func NewGetIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateIndexRequest calls the generic CreateIndex builder with application/json body
func NewCreateIndexRequest(server string, tableName string, indexName string, body CreateIndexJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateIndexRequestWithBody(server, tableName, indexName, "application/json", bodyReader)
}

// NewCreateIndexRequestWithBody generates requests for CreateIndex with any type of body
func NewCreateIndexRequestWithBody(server string, tableName string, indexName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewScanKeysRequest calls the generic ScanKeys builder with application/json body
func NewScanKeysRequest(server string, tableName string, body ScanKeysJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewScanKeysRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewScanKeysRequestWithBody generates requests for ScanKeys with any type of body
func NewScanKeysRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/lookup", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewLookupKeyRequest generates requests for LookupKey
func NewLookupKeyRequest(server string, tableName string, key string, params *LookupKeyParams) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "key", runtime.ParamLocationPath, key)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/lookup/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "fields", runtime.ParamLocationQuery, params.Fields); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewLinearMergeRequest calls the generic LinearMerge builder with application/json body
func NewLinearMergeRequest(server string, tableName string, body LinearMergeJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewLinearMergeRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewLinearMergeRequestWithBody generates requests for LinearMerge with any type of body
func NewLinearMergeRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/merge", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewQueryTableRequest calls the generic QueryTable builder with application/json body
func NewQueryTableRequest(server string, tableName string, body QueryTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewQueryTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewQueryTableRequestWithBody generates requests for QueryTable with any type of body
func NewQueryTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/query", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewTableRagQueryRequest calls the generic TableRagQuery builder with application/json body
func NewTableRagQueryRequest(server string, tableName string, body TableRagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewTableRagQueryRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewTableRagQueryRequestWithBody generates requests for TableRagQuery with any type of body
func NewTableRagQueryRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/rag", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRestoreTableRequest calls the generic RestoreTable builder with application/json body
func NewRestoreTableRequest(server string, tableName string, body RestoreTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRestoreTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewRestoreTableRequestWithBody generates requests for RestoreTable with any type of body
func NewRestoreTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/restore", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateSchemaRequest calls the generic UpdateSchema builder with application/json body
func NewUpdateSchemaRequest(server string, tableName string, body UpdateSchemaJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateSchemaRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewUpdateSchemaRequestWithBody generates requests for UpdateSchema with any type of body
func NewUpdateSchemaRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/schema", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListUsersRequest generates requests for ListUsers
func NewListUsersRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetCurrentUserRequest generates requests for GetCurrentUser
func NewGetCurrentUserRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/me")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDeleteUserRequest generates requests for DeleteUser
func NewDeleteUserRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserByNameRequest generates requests for GetUserByName
func NewGetUserByNameRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateUserRequest calls the generic CreateUser builder with application/json body
func NewCreateUserRequest(server string, userName UserNamePathParameter, body CreateUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewCreateUserRequestWithBody generates requests for CreateUser with any type of body
func NewCreateUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateUserPasswordRequest calls the generic UpdateUserPassword builder with application/json body
func NewUpdateUserPasswordRequest(server string, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateUserPasswordRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewUpdateUserPasswordRequestWithBody generates requests for UpdateUserPassword with any type of body
func NewUpdateUserPasswordRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/password", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRemovePermissionFromUserRequest generates requests for RemovePermissionFromUser
func NewRemovePermissionFromUserRequest(server string, userName UserNamePathParameter, params *RemovePermissionFromUserParams) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resource", runtime.ParamLocationQuery, params.Resource); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resourceType", runtime.ParamLocationQuery, params.ResourceType); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserPermissionsRequest generates requests for GetUserPermissions
func NewGetUserPermissionsRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewAddPermissionToUserRequest calls the generic AddPermissionToUser builder with application/json body
func NewAddPermissionToUserRequest(server string, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAddPermissionToUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewAddPermissionToUserRequestWithBody generates requests for AddPermissionToUser with any type of body
func NewAddPermissionToUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

func (c *Client) applyEditors(ctx context.Context, req *http.Request, additionalEditors []RequestEditorFn) error {
	for _, r := range c.RequestEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	for _, r := range additionalEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	return nil
}

// ClientWithResponses builds on ClientInterface to offer response payloads
type ClientWithResponses struct {
	ClientInterface
}

// NewClientWithResponses creates a new ClientWithResponses, which wraps
// Client with return type handling
func NewClientWithResponses(server string, opts ...ClientOption) (*ClientWithResponses, error) {
	client, err := NewClient(server, opts...)
	if err != nil {
		return nil, err
	}
	return &ClientWithResponses{client}, nil
}

// WithBaseURL overrides the baseURL.
func WithBaseURL(baseURL string) ClientOption {
	return func(c *Client) error {
		newBaseURL, err := url.Parse(baseURL)
		if err != nil {
			return err
		}
		c.Server = newBaseURL.String()
		return nil
	}
}

// ClientWithResponsesInterface is the interface specification for the client with responses above.
type ClientWithResponsesInterface interface {
	// AnswerAgentWithBodyWithResponse request with any body
	AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	// ChatAgentWithBodyWithResponse request with any body
	ChatAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error)

	ChatAgentWithResponse(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error)

	// QueryBuilderAgentWithBodyWithResponse request with any body
	QueryBuilderAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error)

	QueryBuilderAgentWithResponse(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error)

	// BackupWithBodyWithResponse request with any body
	BackupWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupResponse, error)

	BackupWithResponse(ctx context.Context, body BackupJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupResponse, error)

	// ListBackupsWithResponse request
	ListBackupsWithResponse(ctx context.Context, params *ListBackupsParams, reqEditors ...RequestEditorFn) (*ListBackupsResponse, error)

	// EvaluateWithBodyWithResponse request with any body
	EvaluateWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*EvaluateResponse, error)

	EvaluateWithResponse(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*EvaluateResponse, error)

	// GlobalQueryWithBodyWithResponse request with any body
	GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	// RagQueryWithBodyWithResponse request with any body
	RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	// RestoreWithBodyWithResponse request with any body
	RestoreWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreResponse, error)

	RestoreWithResponse(ctx context.Context, body RestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreResponse, error)

	// GetStatusWithResponse request
	GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error)

	// ListTablesWithResponse request
	ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error)

	// DropTableWithResponse request
	DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error)

	// GetTableWithResponse request
	GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error)

	// CreateTableWithBodyWithResponse request with any body
	CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	// BackupTableWithBodyWithResponse request with any body
	BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	// BatchWriteWithBodyWithResponse request with any body
	BatchWriteWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchWriteResponse, error)

	BatchWriteWithResponse(ctx context.Context, tableName string, body BatchWriteJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchWriteResponse, error)

	// ListIndexesWithResponse request
	ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error)

	// DropIndexWithResponse request
	DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error)

	// GetIndexWithResponse request
	GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error)

	// CreateIndexWithBodyWithResponse request with any body
	CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	// ScanKeysWithBodyWithResponse request with any body
	ScanKeysWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error)

	ScanKeysWithResponse(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error)

	// LookupKeyWithResponse request
	LookupKeyWithResponse(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error)

	// LinearMergeWithBodyWithResponse request with any body
	LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	// QueryTableWithBodyWithResponse request with any body
	QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	// TableRagQueryWithBodyWithResponse request with any body
	TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	// RestoreTableWithBodyWithResponse request with any body
	RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	// UpdateSchemaWithBodyWithResponse request with any body
	UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	// ListUsersWithResponse request
	ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error)

	// GetCurrentUserWithResponse request
	GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error)

	// DeleteUserWithResponse request
	DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error)

	// GetUserByNameWithResponse request
	GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error)

	// CreateUserWithBodyWithResponse request with any body
	CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	// UpdateUserPasswordWithBodyWithResponse request with any body
	UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	// RemovePermissionFromUserWithResponse request
	RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error)

	// GetUserPermissionsWithResponse request
	GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error)

	// AddPermissionToUserWithBodyWithResponse request with any body
	AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)

	AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)
}

type AnswerAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *AnswerAgentResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AnswerAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AnswerAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ChatAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ChatAgentResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ChatAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ChatAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type QueryBuilderAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryBuilderResult
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r QueryBuilderAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r QueryBuilderAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BackupResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ClusterBackupResponse
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BackupResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BackupResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListBackupsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *BackupListResponse
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListBackupsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListBackupsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type EvaluateResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *EvalResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r EvaluateResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r EvaluateResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GlobalQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GlobalQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GlobalQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RestoreResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON202      *ClusterRestoreResponse
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r RestoreResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RestoreResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetStatusResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ClusterStatus
	JSON401      *Error
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetStatusResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetStatusResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListTablesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]TableStatus
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListTablesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListTablesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *TableStatus
	JSON404      *NotFound
}

// Status returns HTTPResponse.Status
func (r GetTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
}

// Status returns HTTPResponse.Status
func (r CreateTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BackupTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *struct {
		Backup string `json:"backup,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON404 *NotFound
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BackupTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BackupTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BatchWriteResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *BatchResponse
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BatchWriteResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BatchWriteResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListIndexesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListIndexesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListIndexesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r CreateIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ScanKeysResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ScanKeysResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ScanKeysResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LookupKeyResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *map[string]interface{}
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LookupKeyResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LookupKeyResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LinearMergeResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *LinearMergeResult
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LinearMergeResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LinearMergeResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type QueryTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r QueryTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r QueryTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type TableRagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON404      *NotFound
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r TableRagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r TableRagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RestoreTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON202      *struct {
		Restore string `json:"restore,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r RestoreTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RestoreTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateSchemaResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r UpdateSchemaResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateSchemaResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListUsersResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]struct {
		Username string `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON403 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r ListUsersResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListUsersResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetCurrentUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *struct {
		Permissions []Permission `json:"permissions,omitempty,omitzero"`
		Username    string       `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r GetCurrentUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetCurrentUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserByNameResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *User
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserByNameResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserByNameResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *User
	JSON400      *Error
	JSON409      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateUserPasswordResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateUserPasswordResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateUserPasswordResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RemovePermissionFromUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RemovePermissionFromUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RemovePermissionFromUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserPermissionsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]Permission
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserPermissionsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserPermissionsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type AddPermissionToUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AddPermissionToUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AddPermissionToUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

// AnswerAgentWithBodyWithResponse request with arbitrary body returning *AnswerAgentResponse
func (c *ClientWithResponses) AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

func (c *ClientWithResponses) AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

// ChatAgentWithBodyWithResponse request with arbitrary body returning *ChatAgentResponse
func (c *ClientWithResponses) ChatAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error) {
	rsp, err := c.ChatAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseChatAgentResponse(rsp)
}

func (c *ClientWithResponses) ChatAgentWithResponse(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error) {
	rsp, err := c.ChatAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseChatAgentResponse(rsp)
}

// QueryBuilderAgentWithBodyWithResponse request with arbitrary body returning *QueryBuilderAgentResponse
func (c *ClientWithResponses) QueryBuilderAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error) {
	rsp, err := c.QueryBuilderAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryBuilderAgentResponse(rsp)
}

func (c *ClientWithResponses) QueryBuilderAgentWithResponse(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error) {
	rsp, err := c.QueryBuilderAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryBuilderAgentResponse(rsp)
}

// BackupWithBodyWithResponse request with arbitrary body returning *BackupResponse
func (c *ClientWithResponses) BackupWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupResponse, error) {
	rsp, err := c.BackupWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupResponse(rsp)
}

func (c *ClientWithResponses) BackupWithResponse(ctx context.Context, body BackupJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupResponse, error) {
	rsp, err := c.Backup(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupResponse(rsp)
}

// ListBackupsWithResponse request returning *ListBackupsResponse
func (c *ClientWithResponses) ListBackupsWithResponse(ctx context.Context, params *ListBackupsParams, reqEditors ...RequestEditorFn) (*ListBackupsResponse, error) {
	rsp, err := c.ListBackups(ctx, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListBackupsResponse(rsp)
}

// EvaluateWithBodyWithResponse request with arbitrary body returning *EvaluateResponse
func (c *ClientWithResponses) EvaluateWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*EvaluateResponse, error) {
	rsp, err := c.EvaluateWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseEvaluateResponse(rsp)
}

func (c *ClientWithResponses) EvaluateWithResponse(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*EvaluateResponse, error) {
	rsp, err := c.Evaluate(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseEvaluateResponse(rsp)
}

// GlobalQueryWithBodyWithResponse request with arbitrary body returning *GlobalQueryResponse
func (c *ClientWithResponses) GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

func (c *ClientWithResponses) GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

// RagQueryWithBodyWithResponse request with arbitrary body returning *RagQueryResponse
func (c *ClientWithResponses) RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

func (c *ClientWithResponses) RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

// RestoreWithBodyWithResponse request with arbitrary body returning *RestoreResponse
func (c *ClientWithResponses) RestoreWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreResponse, error) {
	rsp, err := c.RestoreWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreResponse(rsp)
}

func (c *ClientWithResponses) RestoreWithResponse(ctx context.Context, body RestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreResponse, error) {
	rsp, err := c.Restore(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreResponse(rsp)
}

// GetStatusWithResponse request returning *GetStatusResponse
func (c *ClientWithResponses) GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error) {
	rsp, err := c.GetStatus(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetStatusResponse(rsp)
}

// ListTablesWithResponse request returning *ListTablesResponse
func (c *ClientWithResponses) ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error) {
	rsp, err := c.ListTables(ctx, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListTablesResponse(rsp)
}

// DropTableWithResponse request returning *DropTableResponse
func (c *ClientWithResponses) DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error) {
	rsp, err := c.DropTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropTableResponse(rsp)
}

// GetTableWithResponse request returning *GetTableResponse
func (c *ClientWithResponses) GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error) {
	rsp, err := c.GetTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetTableResponse(rsp)
}

// CreateTableWithBodyWithResponse request with arbitrary body returning *CreateTableResponse
func (c *ClientWithResponses) CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

func (c *ClientWithResponses) CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

// BackupTableWithBodyWithResponse request with arbitrary body returning *BackupTableResponse
func (c *ClientWithResponses) BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

func (c *ClientWithResponses) BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

// BatchWriteWithBodyWithResponse request with arbitrary body returning *BatchWriteResponse
func (c *ClientWithResponses) BatchWriteWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchWriteResponse, error) {
	rsp, err := c.BatchWriteWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchWriteResponse(rsp)
}

func (c *ClientWithResponses) BatchWriteWithResponse(ctx context.Context, tableName string, body BatchWriteJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchWriteResponse, error) {
	rsp, err := c.BatchWrite(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchWriteResponse(rsp)
}

// ListIndexesWithResponse request returning *ListIndexesResponse
func (c *ClientWithResponses) ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error) {
	rsp, err := c.ListIndexes(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListIndexesResponse(rsp)
}

// DropIndexWithResponse request returning *DropIndexResponse
func (c *ClientWithResponses) DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error) {
	rsp, err := c.DropIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropIndexResponse(rsp)
}

// GetIndexWithResponse request returning *GetIndexResponse
func (c *ClientWithResponses) GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error) {
	rsp, err := c.GetIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetIndexResponse(rsp)
}

// CreateIndexWithBodyWithResponse request with arbitrary body returning *CreateIndexResponse
func (c *ClientWithResponses) CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndexWithBody(ctx, tableName, indexName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

func (c *ClientWithResponses) CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndex(ctx, tableName, indexName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

// ScanKeysWithBodyWithResponse request with arbitrary body returning *ScanKeysResponse
func (c *ClientWithResponses) ScanKeysWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error) {
	rsp, err := c.ScanKeysWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseScanKeysResponse(rsp)
}

func (c *ClientWithResponses) ScanKeysWithResponse(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error) {
	rsp, err := c.ScanKeys(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseScanKeysResponse(rsp)
}

// LookupKeyWithResponse request returning *LookupKeyResponse
func (c *ClientWithResponses) LookupKeyWithResponse(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error) {
	rsp, err := c.LookupKey(ctx, tableName, key, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLookupKeyResponse(rsp)
}

// LinearMergeWithBodyWithResponse request with arbitrary body returning *LinearMergeResponse
func (c *ClientWithResponses) LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMergeWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

func (c *ClientWithResponses) LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMerge(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

// QueryTableWithBodyWithResponse request with arbitrary body returning *QueryTableResponse
func (c *ClientWithResponses) QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

func (c *ClientWithResponses) QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

// TableRagQueryWithBodyWithResponse request with arbitrary body returning *TableRagQueryResponse
func (c *ClientWithResponses) TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQueryWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

func (c *ClientWithResponses) TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQuery(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

// RestoreTableWithBodyWithResponse request with arbitrary body returning *RestoreTableResponse
func (c *ClientWithResponses) RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

func (c *ClientWithResponses) RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

// UpdateSchemaWithBodyWithResponse request with arbitrary body returning *UpdateSchemaResponse
func (c *ClientWithResponses) UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchemaWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

func (c *ClientWithResponses) UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchema(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

// ListUsersWithResponse request returning *ListUsersResponse
func (c *ClientWithResponses) ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error) {
	rsp, err := c.ListUsers(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListUsersResponse(rsp)
}

// GetCurrentUserWithResponse request returning *GetCurrentUserResponse
func (c *ClientWithResponses) GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error) {
	rsp, err := c.GetCurrentUser(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetCurrentUserResponse(rsp)
}

// DeleteUserWithResponse request returning *DeleteUserResponse
func (c *ClientWithResponses) DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error) {
	rsp, err := c.DeleteUser(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteUserResponse(rsp)
}

// GetUserByNameWithResponse request returning *GetUserByNameResponse
func (c *ClientWithResponses) GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error) {
	rsp, err := c.GetUserByName(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserByNameResponse(rsp)
}

// CreateUserWithBodyWithResponse request with arbitrary body returning *CreateUserResponse
func (c *ClientWithResponses) CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

func (c *ClientWithResponses) CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

// UpdateUserPasswordWithBodyWithResponse request with arbitrary body returning *UpdateUserPasswordResponse
func (c *ClientWithResponses) UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPasswordWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

func (c *ClientWithResponses) UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPassword(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

// RemovePermissionFromUserWithResponse request returning *RemovePermissionFromUserResponse
func (c *ClientWithResponses) RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error) {
	rsp, err := c.RemovePermissionFromUser(ctx, userName, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRemovePermissionFromUserResponse(rsp)
}

// GetUserPermissionsWithResponse request returning *GetUserPermissionsResponse
func (c *ClientWithResponses) GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error) {
	rsp, err := c.GetUserPermissions(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserPermissionsResponse(rsp)
}

// AddPermissionToUserWithBodyWithResponse request with arbitrary body returning *AddPermissionToUserResponse
func (c *ClientWithResponses) AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

func (c *ClientWithResponses) AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

// ParseAnswerAgentResponse parses an HTTP response from a AnswerAgentWithResponse call
func ParseAnswerAgentResponse(rsp *http.Response) (*AnswerAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AnswerAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest AnswerAgentResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseChatAgentResponse parses an HTTP response from a ChatAgentWithResponse call
func ParseChatAgentResponse(rsp *http.Response) (*ChatAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ChatAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ChatAgentResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseQueryBuilderAgentResponse parses an HTTP response from a QueryBuilderAgentWithResponse call
func ParseQueryBuilderAgentResponse(rsp *http.Response) (*QueryBuilderAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &QueryBuilderAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryBuilderResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseBackupResponse parses an HTTP response from a BackupWithResponse call
func ParseBackupResponse(rsp *http.Response) (*BackupResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BackupResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ClusterBackupResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListBackupsResponse parses an HTTP response from a ListBackupsWithResponse call
func ParseListBackupsResponse(rsp *http.Response) (*ListBackupsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListBackupsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest BackupListResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseEvaluateResponse parses an HTTP response from a EvaluateWithResponse call
func ParseEvaluateResponse(rsp *http.Response) (*EvaluateResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &EvaluateResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest EvalResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGlobalQueryResponse parses an HTTP response from a GlobalQueryWithResponse call
func ParseGlobalQueryResponse(rsp *http.Response) (*GlobalQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GlobalQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRagQueryResponse parses an HTTP response from a RagQueryWithResponse call
func ParseRagQueryResponse(rsp *http.Response) (*RagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseRestoreResponse parses an HTTP response from a RestoreWithResponse call
func ParseRestoreResponse(rsp *http.Response) (*RestoreResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RestoreResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest ClusterRestoreResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetStatusResponse parses an HTTP response from a GetStatusWithResponse call
func ParseGetStatusResponse(rsp *http.Response) (*GetStatusResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetStatusResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ClusterStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListTablesResponse parses an HTTP response from a ListTablesWithResponse call
func ParseListTablesResponse(rsp *http.Response) (*ListTablesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListTablesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropTableResponse parses an HTTP response from a DropTableWithResponse call
func ParseDropTableResponse(rsp *http.Response) (*DropTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetTableResponse parses an HTTP response from a GetTableWithResponse call
func ParseGetTableResponse(rsp *http.Response) (*GetTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	}

	return response, nil
}

// ParseCreateTableResponse parses an HTTP response from a CreateTableWithResponse call
func ParseCreateTableResponse(rsp *http.Response) (*CreateTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	}

	return response, nil
}

// ParseBackupTableResponse parses an HTTP response from a BackupTableWithResponse call
func ParseBackupTableResponse(rsp *http.Response) (*BackupTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BackupTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest struct {
			Backup string `json:"backup,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseBatchWriteResponse parses an HTTP response from a BatchWriteWithResponse call
func ParseBatchWriteResponse(rsp *http.Response) (*BatchWriteResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BatchWriteResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest BatchResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListIndexesResponse parses an HTTP response from a ListIndexesWithResponse call
func ParseListIndexesResponse(rsp *http.Response) (*ListIndexesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListIndexesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropIndexResponse parses an HTTP response from a DropIndexWithResponse call
func ParseDropIndexResponse(rsp *http.Response) (*DropIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetIndexResponse parses an HTTP response from a GetIndexWithResponse call
func ParseGetIndexResponse(rsp *http.Response) (*GetIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateIndexResponse parses an HTTP response from a CreateIndexWithResponse call
func ParseCreateIndexResponse(rsp *http.Response) (*CreateIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseScanKeysResponse parses an HTTP response from a ScanKeysWithResponse call
func ParseScanKeysResponse(rsp *http.Response) (*ScanKeysResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ScanKeysResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLookupKeyResponse parses an HTTP response from a LookupKeyWithResponse call
func ParseLookupKeyResponse(rsp *http.Response) (*LookupKeyResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LookupKeyResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest map[string]interface{}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLinearMergeResponse parses an HTTP response from a LinearMergeWithResponse call
func ParseLinearMergeResponse(rsp *http.Response) (*LinearMergeResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LinearMergeResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest LinearMergeResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseQueryTableResponse parses an HTTP response from a QueryTableWithResponse call
func ParseQueryTableResponse(rsp *http.Response) (*QueryTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &QueryTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseTableRagQueryResponse parses an HTTP response from a TableRagQueryWithResponse call
func ParseTableRagQueryResponse(rsp *http.Response) (*TableRagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &TableRagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseRestoreTableResponse parses an HTTP response from a RestoreTableWithResponse call
func ParseRestoreTableResponse(rsp *http.Response) (*RestoreTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RestoreTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest struct {
			Restore string `json:"restore,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateSchemaResponse parses an HTTP response from a UpdateSchemaWithResponse call
func ParseUpdateSchemaResponse(rsp *http.Response) (*UpdateSchemaResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateSchemaResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListUsersResponse parses an HTTP response from a ListUsersWithResponse call
func ParseListUsersResponse(rsp *http.Response) (*ListUsersResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListUsersResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []struct {
			Username string `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 403:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON403 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetCurrentUserResponse parses an HTTP response from a GetCurrentUserWithResponse call
func ParseGetCurrentUserResponse(rsp *http.Response) (*GetCurrentUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetCurrentUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest struct {
			Permissions []Permission `json:"permissions,omitempty,omitzero"`
			Username    string       `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteUserResponse parses an HTTP response from a DeleteUserWithResponse call
func ParseDeleteUserResponse(rsp *http.Response) (*DeleteUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserByNameResponse parses an HTTP response from a GetUserByNameWithResponse call
func ParseGetUserByNameResponse(rsp *http.Response) (*GetUserByNameResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserByNameResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateUserResponse parses an HTTP response from a CreateUserWithResponse call
func ParseCreateUserResponse(rsp *http.Response) (*CreateUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 409:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON409 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateUserPasswordResponse parses an HTTP response from a UpdateUserPasswordWithResponse call
func ParseUpdateUserPasswordResponse(rsp *http.Response) (*UpdateUserPasswordResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateUserPasswordResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRemovePermissionFromUserResponse parses an HTTP response from a RemovePermissionFromUserWithResponse call
func ParseRemovePermissionFromUserResponse(rsp *http.Response) (*RemovePermissionFromUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RemovePermissionFromUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserPermissionsResponse parses an HTTP response from a GetUserPermissionsWithResponse call
func ParseGetUserPermissionsResponse(rsp *http.Response) (*GetUserPermissionsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserPermissionsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []Permission
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseAddPermissionToUserResponse parses an HTTP response from a AddPermissionToUserWithResponse call
func ParseAddPermissionToUserResponse(rsp *http.Response) (*AddPermissionToUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AddPermissionToUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// Base64 encoded, gzipped, json marshaled Swagger object
var swaggerSpec = []string{

	"H4sIAAAAAAAC/+z9iXYjN7YuCL8Kfp76V0rZJDWl7TLvqlWlHJzWcU5Hyizf01YuCowASZQigDCAkETn",
	"Uj9Dv0i/VD9JL+wNIBAMcNCQ9jn3+t51XCkG5mFjj9/+0stkWUnBhNG90ZdeRRUtmWEK/vqkmXpHS/aB",
	"mvkH/8V+yJnOFK8Ml6I36n2cM1JrpgQt2bDX73H7Y0XNvNfv2d96o17tWur1e4r9WnPF8t7IqJr1ezqb",
	"s5LaVtkNLavCFv+XnItc2tJmUdkftFFczHq3t7e2AV1JoRkM8TnNT9mvNdPG/pVJYZiAf9KqKnhG7RD3",
	"/qXtOL9EXf1FsWlv1Pu3vWb6e/hV771SSirsqj3P5zQnynV22++dCGPnXJwxdcUU1vrqY/CdEg29EoYF",
	"+7130vwga5F//SGcMi1rlTEipCFT6NMWcvVss8ezmWIz6PR5nV0yGEmlZMWU4bhvk9k4kzWOcXmVs8uZ",
	"ss0SKEF2plIRzWeCT3lGhRkbpkq92xwOLgybMdXr924GMzmwvw70Ja8GEtqkxaCStozqjaa00MzOSGar",
	"+n9XlxOmiJySXGZ1adeEcEHMnGsywdl0er7t96ZKlt3G3shrpsgEZmOnoaiYMdeM7vV7U6lKanqj3rSQ",
	"NGpYwCDiGfky3z67yzztqMZUj9396YzvB+jfsJwUzUg71+4OHV6yRWJLYb7kki3Ijt28vlsHSxz6JKeG",
	"9Qkz2XC3e+Ghxe1mYJu3a5xzXRV0QXbYcDbsk2koYDvSuw+Znc6kYt0xnIXDmTECZdYc2q+95bqejGlz",
	"AeG20TznWP5D6xauu//RJT5lui6A5nUoQV0Ybe+KYNousa4ng1bnYXpy8i+WQRtGdlfwU1X9offEyO3O",
	"WN2M8/7n6DZ+BH+BKxNTpM+JNYs24yU17NQuT5eopmnQmaHKwOEnOydn78lfv90/IHaNWUENv2Kk4JeM",
	"nPeEvB58l5/3HnRD8L3v0FRaMntKzJzhQOL9TV361Bl5JfLtZvGgKSxtDsxnw47caTfiF2GHi6yoNb9i",
	"vwdh2Lw199mV+ObusJvfbT732aeGUWzvFC1mUnEzL/GP4v20N/plPXWMSf5xqH77ub/uaQj9kOTrQJYo",
	"59Y7Owks03jKC8ejbzeP/6iZWvRu+19au2E5xeEpvX7LtKYz1hoLLyupcBEtiz/qMZHJnIsZ8pe33TWI",
	"ODoc3jbTv+33MlowkVM1hule0WL7ab1wVU98ze6ofJEBvaaKEd8HshDUsPGcayNnipb33hdoBi6V7l6c",
	"l4EO6qZPvIFL/XHDyrs8180LcRsuBFWKLuAF59rYw7h6XK5APLYZk2Nf8V6j842uHNaUsyJPvLz2Z2Jk",
	"6JQRKVKkKT4iy03csLy9vSt39muT4JKL8RrR4y0XvKzLIHg4AcgOmTqybNdiYk9rVtQ5s0xIkJoPHiIQ",
	"ScVnXHSH9B5+94dgTvV8PFM8jxcOeN2SmhE57xXU9Aspznu75+IVDsz+fPTd8Lvvnn3fHxwcHg6fHXz/",
	"7Lx3Lh7CZlSKZVxzmRjxaxwmCUXIzsHg4HB37Rz0g6TJVVfptLlBj3KxV94ezX9LPO1v6Q0cJxEkWsdQ",
	"20OkmKkV7p37mYtZa4C7rcO1/5AF+ioySVDELDE0d5BE4Ietu/xoi9/2e7XgZvunyJO+T7ZW9xkK5Na2",
	"upHY3o85gnl6GruRSQJZr8sjXSUEo+MrpuiM4XtuqNG/N0H1EuIKlQPevfTxRlWEdrqIfvMoNLqIu95P",
	"p+xKXNAVBP9ll9Anl/H+N6+kN6sJwxUt6j9w88rUg+PfwD94bNrk45xdcWqSj8yZoZZ3zEko8wcOtU4J",
	"/XX5h45oLKdj/WtNVepdtIOTU+K+/3HjhDOWUueJWcGiE1gyo3i2RD10XfYJvZr1SclFn5T0po/XuE8y",
	"qnIuaMHNYvd3mYbi9rHozuSf7ssftcS369+aj+79XTInLSrQSMQsppHEkt7asNG5GJC3sCF6RNZsgq5L",
	"d8D6OPXWvthWnvt3YUTaT0EjirWehbZUaFt4zeSoxVP2W6+3LXIsaLEwONhliRd4YCbs/f0FrnEfnlmk",
	"jEi7/dMBl8pfKEueKOhFoxnZvbON9hw/2ovlz16/FwbuP8Q/xHPAP8MkbG/LA4+YiEYEg5k6s1ybd6gy",
	"sDa5GhMpC0YFPJNasNSXzrm5w23ww1jFyLjBhLf9Xjcg8cT7uTxyww9bCn3N1PGMCbNa92W/ji+FvC5Y",
	"PmNr7XGhFDFzasis5jnToDmEVp5oUoucKXtucstueY2vLCkXw3NxxkteUGVv84s3x59evhqWeR8ta5WS",
	"V9Aa2C5vDPYA1ksG8gotCqINq/S52MkKqjUcSDvGvpVlFGdXtOgTKnJCYdpkxgRTUGJ3eC6CPKqBgpz3",
	"Ptpuc2oodEm50KRkOc9oQRTLpMr1kHzSjGQFF/CrPflcyELOFtDNhDkZkxE6kbUhOaczITXTQyvehj64",
	"JpRoOTWgZ2JixgVj9tJE6zmhmg3JsdZ1yQglhmVz7JTWOWciY+0mDZ0UjGgj7fNZsBktGmPlkJyyKVO2",
	"EinotYaxKjarC/dy0SyrFTWsWAyTYrhlV+c0xZu9ZFNaF4bAZ7u7bomlwkfc7lHFK1ZwwXCzSC0KpjWR",
	"V0wpnudMEC7IBXy7GJ6LVzSbk4KLS5JRQXTFMj5dwH4u7LZM+azGLcSNtb+h1Aj9GbWwy2jPmLBnJgxn",
	"eC7e1qamRbEgQSdNrrmZkyeh0JMhecXNnKn4NyIVeQLze0LKWhvcZTib+RAWayuh4IVt4Q0XlylKwZye",
	"aq31/YoWL2ABbI0wvk3VXvuCTd2S3ozdpRobecmEXi0QGGnsQYdSdjflNXP2OLxhLI91U9Dm8Fz8PGeC",
	"aGb6kcXcHvVK1YLlZMc2o81AUXFpm+NKm117pafcwJ401vV8xmyDnzSb1qiqY0LXcFfevHkbaEPBS+76",
	"ENLYHWYM9+eTZpo8f3X6ESfBf3PKZqYNL+Eg4SZGeg37/+DFtSuQ0qLd9nu/1kzxFCd7bPfU3gRbYuG9",
	"Q4BgsRuW1YYNycc5c59h8Ne8KOypMooKbd8It8SalVQYnhHNqMrm58Ke+EpW9t6iAlPCSfflxliOgFRv",
	"h8DsXYKOhvEMf/nS4yJnN3b4v/RYOWG5Jc5jnt/YZxzW0ul3LFXpjewDkdeZ0WAW2KLuN01Vxa44u9ag",
	"59jqooD9IdLllFycYL2D7sWBySVMUJqpJ5oIampFC1JQMavpLCw6KEz9k8FyoCS8tJe6rT/t/QxPjmKw",
	"zBOmDZnR0p69glZGVu51I3853N/f/3uKbCoGXjmtawYUszd6BqdsidHFewbKOKiI52ChDSst0Skr0+8+",
	"ZvjGSSBclqzOGbUn/6yeGEUze1SmSpake+1tRznDV4wRekV5Ac+Iv1Xh+jkyDxXsuAmfpprj2l76pfv0",
	"rH2b9lO3Caj/RrVKw7ucQfnbfs8Si7E2isG2tNYXfcmWDcYwv7OzVyRUshdFObeFDh/hrnnfl/Crv0u4",
	"0IZRuGb/fvb+HfE+aM0piLhaO0xZm3GzZ62hAne2PFagoTAJYpk6cnzS3Xn3koPe1l1+PxUp7GvuCee1",
	"bWwha3JNhfFFf61BTCBudI6gapCUsjmh8ISfi19raSgpqaAzBnQelNeGIdG1K6gzJqjiUg9j5iHm3WPd",
	"I97ZhoQm1Y8xn+q59u20q1g1OKh06DOuIbCnbrGQDVjBQkYPnMaL5pafebYSWElL0tstjAM5x60KPGWl",
	"2CDwp0QxqqWwq7jDp4TBAc3JFafnAm7FsN3qEE58qLRrHxOuo1Ysb1kbaTvNgNupqNYsJ0aeC+DLO2fI",
	"dgN0xo6Qi9oeCeDTZT2bu9vclhDWTnQjI9Sq/LFVt3ErsmszVmHrNzFGTUU4Xa5mygDjrgdQRHgf3auc",
	"E38u7/JK+V43SGi3n9tn+szTu/bgPjA1gN1oM7rA2DZbh0fXc9VDAhwzVqOCzOkVOxeWGZLXouF/yY7d",
	"4C6XvgtH2tYeIK/NM4Lio73MJ1MrqNimuQbGyg+M5X3CDam1k/aMrAYFu2JF1CPVxFG41BnCyWxH8+1y",
	"Nexr+/Td7bgttWT/lTOnKFvbSijZbmEqLUtcV5vq/+DKxbVvV9K9F61xLTkphG/EXmytgST7I7JMm1Ys",
	"+zhb08P7K6as3NaUQW/XcAB39of7lhM4GO7vDskLKTS3Mj6ZSDMndMLhUbECOhaHq+YlJktywVdYR7S0",
	"aOTeYUoDWaIwAhxggpFw6hPcUOBHFCvYVVoBeuo/eV1EYmSOrwYWFMzF0YQfML6ld7C7FakJrH4dm4cx",
	"ReJw2bvUHt46ryCK95iCo6U9poO6CnPXay7uspW9ffTsoSmpuswtHXJLdg/7vuWAbvuPfm7vv43bj/m/",
	"9Gncfhqexo2bM5Gw38xmaGVPH6HwpnY9COOXc9tBJW/SmqsSkd00QV311i6xSY7bghfRk1p8AKdc0MJK",
	"6A3JSzCQpNZePdVwbFRHmpM1BNuWSAy/1kaWoHkNdh03CiMF61sBj/KCwOvcd6/9omAtOfc5yHyouBR5",
	"o2wckhN0KyKZzBlxFbQVJ5SdAhxeM7yDwvBFQlFoD7ha2MsqVc7UkGyjqXsUvdtDtGgolY9RKl+5Ly3Z",
	"Pd6cSBTsxjQlD7KZFosX81pcMtWc5S2dH22195X3o+z4JddFMfbHK+2Fk5KmuzfHNjQA1QEoiZx0ndne",
	"IWTmuT2FXj9YKaYt77LDrpggVvgpK7PY7fvyXi0GSu0cT8Aom5oR0fV0ym9QbQPKqDw0/kSTsasPajDf",
	"GZ3YvkLbtWZklLVaooqB0Gy/of7timWWjw1KLssRw/3HXSEgd4GaJnezN7VtBNcZ3c8nUmorI/edVq6k",
	"VQV/MpMtKUq+dLc9IUj0tyJfhcxoQfDM4JztXrjHxUusjZFFEVUL3RTMuWKZKRaNMha3gc4YEZYSVEpm",
	"TOv+ufDKA6THQM8EYTcuJu0jUyU3DGLTeMaG5MQJDZrbSZMpv2H5QPPf2LkI+tnBhNotCKOBnReSZDSb",
	"w5FqdFzn4unTT5qhtvh6zsTo6dNzMSCntQDaqsFwP4Ax56wq5ALp8I6+pqokpczZri3/n7ImuRRPDBGM",
	"5c2W78EgQs80U1JrWALtq4FGBd5ZiMEzdQWG6YLdgFHZj9CvhNcbJQZb1oXhOFZL9ozlqZHS+v4Vy+sM",
	"TGLahAHAiN+/e/c/BzTLWOGYsLB6do5Fe7QVU5prAzp7W2wvzBd6YnrpYKLFAG5Ob/TNfr9nd6CgVVBr",
	"2t/8UbL0Fc5dr9/TrKKOvvbsUlhSR9WMmajm/m2gbt76HwzgoKcaUz1eyHrsfNYu2eJaKgi2sRSr35ub",
	"suj1LV/DFM+cLdtwCC31Oqh+r7BPANixgZXAf+o5hTbD/G2VQk5WWLPNXMmKZ8uPwZYsRagfaP8VI8cn",
	"zR3ceVFQ+9bijqGJ8vjDCYSxXXFKLmjFx5dsceE1/IpcHL/7+OPp+w8nL8bHH07GP736zwvCxBVXUoBc",
	"CI4gk4K5q+IMnuQt9DB6+pRk0OVASyGYGTwbfDM43D/8Zv/7w+/JjpPeLUXGUrKqdShzcLB/EL4cDb4Z",
	"zCm/rO2nZwf7h4fY4UuZQTdzYyo92tvLZaaH1C/EMJPlHhPw6x5YTAfY3h4uwZ49Z1ecXafOoz9Bz/a/",
	"/7bfgwq9UW/1fHrLRxTHAOeorOx+1Ir1RvvD7247PBiuezrOudlWt1dDcjIFZYnn5ftkSotCkwnNLi2z",
	"09mz9JaluKp44pudexstv2dWvUTktdXDZOSqW8xIQ71+XbuLYhkBPMfk5KWXbZqVwi9GwjvsojKfrO7i",
	"SfO1cwSf7LZsW+sH2pU+4q1PXGOjZKGJoiKXpWAamJhIJrCi2ADVID/y2ZwpdBHTpKSXjMjaVLUhpVTM",
	"NfEw7YaR1fgycQhlNbgk2i4APPI+LH9I3lt2RuOVB5HEqerIT4FJAVMoKBDriWa/1vYEwrFJnww7hCoV",
	"IZ0VrNaJQcRLdFwAVwB0z/L8zdo/bF1qVaSv5qfTN92zZ28pEzm8AmTHC5h9ZEvcgbfcqL3BTiXK8t3W",
	"CGvFk0x7LJPiHUqJpM9pdllXJ2IqE7438A6Or+wDnfIydRyd+44uMZli8OKDjRLabl2Iq4Ph/nA/dfix",
	"8Jjn6dXDz4TnTBi7CGrpngGHMsBScMkG+weDg29SPVl2dJXbLHKVvoTfr8RE9NFob69coO/2Hq6U617v",
	"ueHsrR8HGKUTpPMj/B5iaDyV7A7iF8CtcEoxNIl/3lq7Yf/mJdOGlok7hPa+Zt2vqfZb21qGZoYfD/ZH",
	"R/uj/f3/Mz6clvsZOPZn/RFt9j8eWFilaNtWH+M3XJtTb/rsYjrg7iRiXrk24NEZbM6+6JZifXSJUuaX",
	"7jT1mkmsdIVbc0M+Cf5rzaLb4fg8rt1UwFcsR1u+976Kthd9aEC2JbJyD4qVMF/MpdSMUFIyasWCaV0A",
	"LAJedndEwU+N7Xk6wEUwoS0Jlb3O/RxcHT7winqG1s/zrK4qqYxGAaZym8lEjo51b0AWnfKCoTJkRC7s",
	"H6O9vb2KmvmekXvY0gV4x5b0NynI2dGIXMCNx/s+sEvQLY+GV0+p/NrQonAOcTk1tO+UBM58WzJDwcnP",
	"TyMQeayzvIBryQ5QgwHUW0t61ty8DZfMZPPoeC47YppsbiVKpkyf5KxghuEkg0k2OluWqlEnEXu/JCcX",
	"HBtZ8oybxdOnsGVPnzqPdz2nKn/6dETeN81QxQiFCl49AKUw4psqjqLx06dv/WmAz9q2As5YOberMgGb",
	"6+GgmlPNrMRcckN2Dj+8wLA81wHI2wNs/1pxY9u2A/5RXrfagfnSDAd4LdUlTORgSN763XboOLSA9Waa",
	"/PjmBQlUD/WirGCZsdK1BB9qIxWO/VwcDsmL6FccStyr8xDtW87H8IxXVBiN5SDSVFh5/WhIjqcGR+F/",
	"JbrOMmaFhLhbXI9WD+fi2ZB8iFt33m7Oh0kvRDZXUshaFwvnQiSLq6j7b4bklGVWplqQQsoKXemYdo1k",
	"bn9Re2EYAb0chQHHY5tSXtSK4UZ8YApIj8iYOzt4ctyeTewJZXpEzuv9/aOMfFNqUlDDRAb+9i+i7Y23",
	"cET+r8P9dtETmAVOqraFQptH+0SzTIocdl6bQWZP1I6VmFU83V0c8euaKioMY9oN+Lgo/Ia6vSDOc9XO",
	"lOxQfzm8+gccj+FMg+7oRXdtUDUIfQMZ2hHsmhSMgqaN6bpcXnRo6CRnZSWXpkl28hoBm9jSPtnt13TK",
	"3LyeM8Gm3PhZnTpVkWDG3oegNIPtpQpfJi5yfsXzGvxQ0FERginso8SmU55xO5igy92pK0DMga5xa3MY",
	"+bH3OFlzKS17ExEjXVFHOLQn40jIsPW6wn8PCLvhoEG1ojV+s1OxG2aY6BO7suGL45eWFas9JI3a82+j",
	"7/5qpUH4pyzyMc0Czoobg60Enw8Oj5xPfG90tN/vsZLywuGR/cP1MMxk2QCb/bucC/ISocroDPrMwBbg",
	"rPGs5HXZ+3zr+n/2zbehg8Nvog6oYCs6oIKRs5IDmlqni8+Az9VmY8L0VzqrBh/ek5fOK9DWGJKXLfdd",
	"xUp55d0JkYbBwwqvyDtpnCf9OykGsGu2wbA3mhdMmGJB+ExIxXJb8qXtJhxmp1RmOZmwqVTNgfAaaMsF",
	"wbGzdX/yDVfM0h9suzVCr7Fu7ARLis3Np2Frxj46N6vCmFcEejpjAii5qZpwo6haoIZPk9LO1h7+hayV",
	"d/IHFniYCl9eVghVyb1t96ydB9ElW1iyZRe6XsHbslAXdvw504ZUyt7wzG09hEdIoZvNt7wr+gjOmSV7",
	"TttzHq7Xec/+Be9awex1AKgA2F9SMDGzyzKdwsMcb2jVPDxkQC4Zq+wAS2dXpZNiQfRcKtM6KloqQDZj",
	"NzyTM0WrOTrJ9YmWJEPGu1Jsym/ArEsN0cjbumh9nVHRUY7/t6UTiQNkmYgxmIo3CWBnC5G9gYK2Hc9u",
	"rqMxSZ7UHiwuBlVBs+Z0Ef/OoLn8rRQz+fL5AOzWrrJUSHU+phqFOAVwdzWSlDLn00Vkg28sVjQf4NcB",
	"MmqK+nO8zO5C1FHuuFIwTUtHk4CthEfTs7vRQCqmmknFDVmmGbRtGBIYJChnxIjb2PkLF1mf/KWsi90+",
	"obia8eeq1vM++UtVF1DAijgS2bMXsiylACWr5YlwaiciU6wJMWdKW16JXes+WCx1n1xZSg538BPsQ8Mm",
	"2+6yWikmzEtq0HT2FhyDcWCa7NA830MqTOyZ6xOgoXFrDhjOUTi/G/5R9/4RlvSo5kgsEe4vCCsYyIa9",
	"fv1esyxQRFa9Uc+unr1PiEz0lyFGI4RI34Pbvi8YTSyuUFBt/snZNcvBjdP3HC7lim7trsTNwAUM3fau",
	"eGWb2zYoIhzzbZxNg9i4Si2Dr3u+HdIl8MRaT2t76n3NlG4Yn8B7NRuqJnXOTVjMPZqOa3dbTy4ey5XM",
	"Ll+BTZDd1cj38xlxDTRW5LbhHYRgWy5TDF5YWnh/5MgMJBU5OX5LlCwcf5W03sk5U2wIHQ2YmBVczwdX",
	"z/qEghZlaLihYoCfDbsxg6vD0f46y9y1HrqqmSz3JjiRPSuGaQPKDojwdOa5gXscWT50NtjYROcNcukh",
	"tq1xriPAAp7h8tZ6wKg2g4Neh50FFnDcINw4G9VBP6nENtmc2LJo6ghbEgdmycrw0hYxcyXr2byqzUbD",
	"2HJHftOD0WvZupVehyd98mTdZnXMWyuXMxF7NEvq8z66Y4rfw8n1E3CuGmHgYSOWh9LsUKJz+69qLNj1",
	"uOCC6a3CXSCAyUgCdUGwg7qN6YqLqjYYM+ckhLCfw81xJ2ssMjj1+9r1oyuftuzD/f3g45kpUCfHmjB/",
	"94OBqg86q75ThPbJC9jxPnlrJWsf0AzBXqvpQmRhX2kOHVwdjPb7oA4dFgUt6dHgaPDd/mTAhTaqzowr",
	"4E6nkFd0UCkJv34tEpLwf3yoxfvRL/LWa7t8X7au+PiXefhVbd+/q1H7cczSw8dz419DVriYnYEL0139",
	"NX9mk1bFrsvmSpcU2ynByt4hBWJ/NDPk+cm71+OzV8enL36MXU/IFVVJoG1vJm+7gvjrTis+nFjSW/JM",
	"SS2nBm781XfD/T303Oq4hsDgWgb4T6dvNlrW+72pYnpuz2AKzBHwQ33Y42RBmsINlMpLcC7/mTHLY7yV",
	"wswTLl738rZ86ydPYHI/s0m0+o5AnzFTV+DsdzAkL0BHSY5/q608iLomQk2gopYc0mJI7Xe7oGh8wEqU",
	"xNvrQwTAsPCambDfzv3cgfJfsoVeQ7Dbu8fEoNZ7dlvdHg5oxfGHwTWbDPDHtmNW9+AX7IqdiJzd/POw",
	"OfpLdJ2VYymKRdIQ7jkBS3dLVkq1GIBrrlMAdd/6OwQOrB3tGaDodAUmri/HNQDfJrChfgvRG6BltHRy",
	"sjCsBaZUc4E4SXcHbnNhGMynk1gKabY/kxJheQmfOlCnTNZFDj4sE9ZEIjwgAEexSc2LPImGHnasWQJN",
	"nDgNStlQ9d4bZ2m8ocXY+XvfIUmDG9JjbkbyFElZADbtf3hIgiWhRcoiDXkELuIb/R2gUAyLu8HCbLv7",
	"vGKcjIrVo7zTWDy09DaA0r2y3tz2Cyn+VQuwGbXqjYU0W0AKd+rqub0Id6+5You1WS9yHhNgJiy1xPfN",
	"saa1cwXJWaYY1YyA2tP9Gx0yfSAYZIuADAq0we5ovHtkPYHgHVEXBUJsYGhGh7F6rugV+/3ZD9vrSv7j",
	"9Pifr7biPNY9+P6Tgw4fkSr/W04XfVJd/+2ascs+qcq/lfaN75Nq8bcFoyriBCpLBKtr+5/S/meR9PXW",
	"FSuKbM6yy20xJZoaRGMwXBupM8Y4YzdmnLNMKhqF060Tjn0UFoi+UU2yM5EFhGLTgmcQbslUnNBkNX7a",
	"NrzN8mai1Sf+MYB0VYpf0WwxmMoMzrqDmACrlg9Gt3S4YiIPNuUUe3TGZ4LUVcwRTWyPwJ047oNWfA/Y",
	"og7Tk1M9n0hw2UgxPJZlxTaGTaO0qvb8m0HR0yLJ1CyiLBtdSDf74q/w2HbwNYcxls1h14TYQajvCmX3",
	"Bqj3p7/kooZxzmWtIFTC8sXXyBfDnQFgDqoMPIdwd1L3A6LqXnjorbZ8IMUYeZXEAdsGqss+2xA9COYK",
	"WlzThR6RY/hfCBSE4nZ2KkcosSmRtclkCbYU3/2IfPRlAShlgZmxmrAGV9jwksnatIo7+w5+wXraFVd2",
	"nQH5JFGjgUUJlaLFx6n0+vEKNQPAP5rmV687RDN27WzetQvA08DXq1lSRH5ox34jphqFrFp+IztIH/EW",
	"bwyzbA7EA2MrYWib6p3aQhGYQsz+NJ2neKAXc2o2YCBmWV0izpZLoLFS9ET4PFfYgx2wKy5riOu9Yko7",
	"xNJaCQwhZJq1rIEOzNAB4rTxW4bn4h27dm8dOM+BW5F3UuYa2g3BkjTPsUH4VHBtOiEf22PW4QTPKpal",
	"XB7+t8OJHLXwGxtExtbj4V6+IfFIM8iBkgk7F7iJuD9AMpzHKpHga7XcVN9BrpRlLbhZkEpqo1ciNP5+",
	"iICgYl2PAXh3QD0nweqkKrK5RPDCqUUTmA4Ik/6++UZAuU45AC5FwfUf54wUVJsgLru9MYvKWfUnUaBM",
	"rUFzv2R3DpkUez9w8CYmzgatHeZnCbGajBSMKoEyr5KFT3kJvHTTxgmmSySaAXjFpraG5GcY8ELWGF5c",
	"MoRNBB3YZEGqeuKTOwJH8Pemd3vw7f0yS0P4T6b7eBrDzGGNHN/cGvvn7YPujc8UdJtG7Us6RT234hCC",
	"9LUgkDRiJmZwswH+COidc+0wQFBdo+cCo4cRcas5OO4U9IEyAOfhSWrLXzq44a8GTHRLN26CRtOgiX4v",
	"vxL04VaYeeGlC4h5G2AL3gdkmFX4Baa1EQgS1Y52hEgqGmKp4m2gBTk9fu2aG6YJ2eNi+m1hF/SUJ6ah",
	"6+HpIgbibuB07n8Hyw10cepeNGe9hVIXn2ltIFGmkbIgln65CIfA4S3h03kOgEwLeU1QFtP2olw7/V1W",
	"UBUeR4D8AhRV9KQ/mZILW4OL2bhV8ILAK8wQYAGORwF+w466+uybMYjNuSAExnpNXY4TS2CcgdfZdkt6",
	"iXACiGzZRCwc4mBwdonel5ku0EY6p/YhKMsvHOflebsLO9Zr9OwOZCEDM26I6omb/YNA8TZg2521ESDR",
	"pSRGt+NMf0V8uyVac1d0u4i4N9h2Ed+3DJ93LiZ1FA9lL0EDYdfq4n9d+Dk76a3egI+24DrgufjFToiW",
	"wb4gulfMsWQp2dHnnF6y7Vou3X31nH4Z8gp2Td+yYHdgOE5tcbc2Y6CKKeuyp5ikpDmznBPIIp5FIjvI",
	"EAGKof/NjmP3DrBDsOgvaFEkA0Ht6LZDqQTyjvcYdX5hbPDlXsNac7PjpxGWvh928vP6g3MqixTEmSzY",
	"0i4TzQA3OXGaInUJsJz9iG/1zEsPl2+VgqRZ98RBDm9leuO7dELN0Jh0N2ikY1+tgV91wfeyIFSTS7YY",
	"YDaZinKVTEV2x6DTMLHUFdqc6BWqTxhCwBRFwlS4fDYgeFFgBv9mlVYdEbsn75KjOA4hwDAG26JOM5oD",
	"QnP/ZI/IcR60zP7J3kFclEwKbZQV/9DvmOrLNscyIsf6EjkOwL2Nv9kK2OyIvMLHcxmIHQMcr9nEl3MP",
	"rx3wNZuQHbdMuimDwIUzGM6UGVvpB/s/AFHgSeGOrjEWxEiiWVYrK/RnzhFnt61KDAsBN2RpfoC84xww",
	"whB6/R70vPbabIMp6UiRZc1ap659cbY1V7epGwTQpQ4fQKl7Vnvra+iGjeG+DQBG3GM6H7l7OpKR3w2g",
	"SUNMDIIwa5R3FHLaub2VG+9Rq7MwzXX3SG/vnxgxVcArgCxgmWcHND2GX4GHBvS1PVlyY6wQlzeQ76Po",
	"3vW7t6nvVV627R/s7qJbI+jhEFTLR9EE8A+3bhBUiH5178EHcbd/LqgTDx0M2JQWBSDncI1mVJCD0EWx",
	"VlbSR5iViirNxSzF7LUmuxqMAD5DogYoD1IGrEprNYhfiKVFwAhitxDtKLPWbU3czM93fL2BkKZS5tr7",
	"7UjNRt2uLdvWAMJJ5IalzJLf9LfwvfS3oWkDImCsDDY8Fx8Uu3JuGVMuuGEQlYteGq0riesXvPEON+oO",
	"l8nsprl37NtpjjjCTEwKM04iTcgzHnxtCMHFLtKFBmxAWpAB+Y0p6a+bhw2CSB2EeAxHbph0ifVobJtd",
	"Yh3iYQwCFYclpR0qlwHeVnvbNB63rg6ZMHPNGGjcNOzolZuUHpIfWVHpjmrWB1Yj2F6DI+AQjODWTxYR",
	"WKBfJJ0efQQ715WR3SeC5BgTbFQFNyYiRk/Oz8X5uXgCX20FiBXUu3caUAw708K866LP2M9dL2a7TdDu",
	"CqfXuWJ6LlNJsn3KzAgKOZR2qWX8MuTMsGwZzKo1y/fv3v1PR9OHm/MDrr5LadhSKdgWejOHnthu57a/",
	"SXrvQqZiCNdS/rcQiLIFiipTH3zx5Zc8tPO561xxTGqBQA1dakETCJ3pYBo4cL2N+IsGV2sl2uLyRJJe",
	"5Z0xOYfMYexOgEE7TX8O+THJYsbP5UpIk2Ov5+ty5m3LTIcqylWkOqi0C/fO6wBWjVqgRtwAkcCEUGDb",
	"Ye8uUeBevbliRWE2YHsIYN5GWoYqnlWC8fVHbOsYmtBZpMv1zXj1KkTbs7RXZiJli16JUbNSxbVl/Exb",
	"odbB2aaCFovfnLUYNKD9c+GhWuxvEL3l/Bkwp4qV/gybLdr5WnQjxyXNPUvaq/8O+NVTqTI2Dvm/LJnY",
	"GLftCoOC962t0LTjlm0r3fCZL/xQ03NdGD6u5opqNo6SYrtzftRfyXnQCE4QbYbQChezFrfTCuzYzEq2",
	"0uts75m3KqkPu6kKyoW78+BvQ4uF5tohseMiOuihlji6xnVv+c4l7QWdo/sfaFdt37au8bMRY8sJDtz7",
	"piwIE3MqMua9q+3UAduhMw0nDbnr5uIr6SoXo9XJTtqDjdiZ3zsJgk8PN16Rcc69bj6NkIPzAGccz+Qm",
	"wd/JzrwuqRgoRnMrdO4+wEU/vkopIIbovjQ3xakycNQQIntTUYEZKPxxRiAj0M4/ciIH+8y07lpLxnqk",
	"O+U05h5vHpCI4J4vmexaSbSczuAh+6FkbRjCVm9yZbMlAf0apJeHkvPQworD+t7FO+fRtiPY/d6SqhPS",
	"+4ByEsE3IqNxa5gj4mC5kZd6ohggajzpk/mikmbODOaudekxbJH4w5MHrLJlEsYTml2umu1zJQF4a9K4",
	"ozXT9pczcUTCQeKaPAm9PNl90Fjv+cLqerIu/cpLBo2A43U9GYSSG6eV+4pPdr96lpboOnToaefMLl+D",
	"aO1ahtM0QwpYsP/rY3t+LQze/zUAPu8E5HkH/OAxmKi2kDMRRxfSzbqFPJmSoGAPc/Bwetkly0ldDVMY",
	"ZfdFHL4v7ujSFVqP7/t7IEhrQ02tVyf9cl25Yo2Gwvv9QNQPVYbTwrKLaGX63EbWaEpuDRx9Bv2FXMsm",
	"gjLeVsAD7GlcaGztTrsYsJrdzNds5o+MFma+egnn8N0toecL3SbFZnlxKeS1PaNYwRLkWjT/ztlM0RxB",
	"q8EGmFYGQbOnSCQfh0a3kMMdACqQ4KmS5e9FOjFfSzQOrl0Co69AjtwEA6PYxODYAz7m0zHAMOpOJM6P",
	"8tou0JyKvGANwiYeJqDpF+0WLkbkeCIVAONTsXAHnRZWbFlgA7odWXNhOYNWA2eXvFruq9+8k4BoAjU9",
	"FBi7GJGXSlYuyzGCey630DKLd6bdHoTTnELb7cvfKfdopN/NbyXtb0HNO5TN5IH5Qx+CcFFXvQSb6LPf",
	"5g6BNorPZkxtQaDjkg8j0G4wd6LQbgW2JNF3IMtnYeXW+TUseSXVZj52EmrCQUHkHDGuvWOvLW/pZKMN",
	"9ommGyWsp/OJAH17bn9jSjod2K0n/ZudH+OHpwnyWHOBvGcIGh0gFxnkL/QREXasrYdqo3+FG2pyBwBa",
	"6X5Ab1h3FcbbprRNL97/+Or01T1zNi2Bfx0N9wPp7ZOD/cNnJOel3u27gsC0F1zMalpA6TVgIA5eLJPl",
	"XpBsMDtY2yAFjtpjv/Boe/cW5V6Tjak70jbuG3bXu1vCJbfyIdvSCyoILbSEXIHMwJq313f7/ErxvOL3",
	"tDvFJTLjcgi4bNiLChzr0J3dnhgZNC5RNsGICnbbd794aXjJ67jvGRgXftINO+6mcEpuRnd5ReQV2Dnk",
	"ceKmNrpVsvUumVa1sKSpPbJX715uYFFgJTUppJiBfYviq1nSGzSWO6TgeEnfvX/3qtfvnX08Pv3Y60Mf",
	"n++ftAdX4p4IcW4ZV6Z9k2WJsK3b5317EAHJsMOBGlRFrVuJ3vyX5p90sH8E/PFdyUY2p+YOidtaY0qS",
	"iYdmalsmHBvStN2XhkwVIvsuxhUTtDCLlPcQfHBO3Pb8hkqPhav2x2WKW97IrUjMasLSaa+z4KjezNhd",
	"1tvXeTQYuz8Tyf13TyR3x7fglCnadmq6w1OgoPLvyzZin2m+cbfvPz+YW8R20v5LiSH8F2cIG1/LccWU",
	"ZdDu4HPZgn+3J8DyL80vwNu0sWvXk9b08m1FX5sDt5rSppvv8nCyGot1LqGl1CYkh4/g2EAbAs7A/ukN",
	"qbf67guq9ttY/Q4Ra5iG7972yiYC6Lbxn288DqjWTGtwmSWvLHXGTDho0fy1pgVkCBL5uQjIiwHUC89k",
	"jaYfWP+MFnyCmZrBHzOTCnVa+vK/rzuSB39YlQx/VvMcMM5WLi2hVaUkBf/45mA+x6QiTF0hzR8gXsHM",
	"/nvOZ/O4LT4NyJe6yWNO81wB6HIUg5xGPI10Kuv8flzUedSx28Ik4tf9HaRu04e5jVb3QBi/zLWnW8hW",
	"W0H6rVWCNe0mrySoc51ubYX+v7XmK3VGbQ8aEpUKgTqorhY5YJFVtaokAOF80mxaO/ysFogLuEUxWpJM",
	"FgWdSJW0v37STNkHHEyfeKca8d75WbfcKZAZeQOyKnjjJlUQDmlidSahdVsDQKaNe10yIxBidKLhWbq/",
	"2hHT5ARH4fSEJOdTeN+NR+egFZ3wgtsRgb3gh7ooALXe22IRQO7t4Tdu6rbQP8HHpFWiWSCM9Iac+S6Z",
	"SilzWrRK85LOmN6jdc7lnuUZpOVO/lPWJLNvfp43FmpfzcgQfbQ8iYoay0fqTrqwsIkIN4oIsCUTmJP3",
	"6K/PfMZ49J323A0tioHlL4uyzdRICG2Kr8ulEOOrfXTVATVP6MeVmNZFMQY4HlssRQREXY4xfdq6pxhL",
	"gEszWk88H4qpLslLaigAKFBl4Kix3AdjuKoBTcXypZAFycPOn/Hf7JP1uuY5ROtrgPAbkLMS3nBqqGZG",
	"kx1M03ewv/+TvWR6d0QOBkch9duAvGU5r8uogi06OHjrSx8NDvaj4m+omrHl5llT/GD//4jyykEqOzcV",
	"d5YnzG47SBZFwQquS+KQBBw0p8uUNyTOXSMsAbupWGafbMwoyX9DmtI5TXZ1MJ2vhDBVGMQZDALW6Fy4",
	"PM7aO1Y8fSqFXUOXSlMxl6eSS/H0aciRk8trYXjJhtBqGU3tes6Ey+4TMvr5Wd9ASkPt8ltgEIgmO+HC",
	"TwpM5IP+oS7lYlgOTfIayEQB647js41BpjcG/uSd9Zz6HJmDOaNXC8jIWUiKW/LJQZ6Cq5Cl3xd7Yb7s",
	"ooEGBz4GTD4NIprv3wfsjM7FxcXFhOr5ufjw/uwj2Rv7ZveuDqJ2oRy6k4D149ea1YBSEy91iD0AdxxA",
	"QsKcjT4znV5Ks9lvRnIuogXSzmQZsiGCIcMeGr+VPssGjFbVlXteIBlrbvlmgLGyR5G8Kqg2PHPBxnjH",
	"jlctCNkRkpRUYErHkLnRP8uw0e/xqAXPJKjjzxaUAIfiiioU4hFMzaed3IGMfoqVlvPEXBYcnohaYU/N",
	"eu62CevREgRzOnYL3rGtTHJnWDTNIwG5sw/0SuaCC244LcaVLHjGtzLruiqQcpBrHRQfAS5sWzb6Q2gA",
	"aXkSyzfw1RXV+loqYEtjB4JMHZkP/9D6+r3KY8VHKJ9gL+ww03AAn9yXMCPBrnFWVlzzWlKvF6yomTsE",
	"Phd1T4UVuH1Eo1SkrLXBDIahRjsDQzOXf8m5yOXmlOVhZis4Sp9PKYnoyLQeX7JF0p3k+Oczn5jFPnQn",
	"LyOvN3vg0Xi9EIbeOL4lU8yQQkpw7PqhpTk+/vlsfPzixauzs/FPr/5zfPIyqW+wogoIwcy0F2MhazXA",
	"wQwu2WLA883JGVrGqKMBJHk1cC8DPfWxjfrIJWih13qYyfKJ3asn9s4Wc6nN6Pv9/f0nLreBOHm/u+S1",
	"0q7cA5Wa52gPUp5bsFLjZv3Ti+8WtNmDh27A2asXp68+Rvtwj03ATqK9SLqmMbjIqG1fQ0RwllDWK/3t",
	"RWNlJSHlZ5QO7E5zTw0behngiNJEYKx1sT222pu9j2/OoO+zIysqCObS+noF4ojY+lDi+OczMKVo5nRe",
	"GS2ao7RNdMtL6qCWz2DEjyLk5tQw+76NK6o08u2pK9XCdLZ1BrZS0syzAojfSnBOzTJ2Da6g75GCoKmi",
	"DVVmu0qh6DYDTq7zMuz9Q9fYtfdgRQIQlfbMPO79eqV9M4LP6fkaKrIGxrs9WQj3XBlLnbvKZCds1u7m",
	"cOjIV96XgcwTGz3ovafNZuieMDDMUYsOhWnF7WrddTO7oCT8+rNb2jyY6rp9+yR44rnzX0ktHJbgjMkW",
	"ADpIRuWIAOMBQuRlOSKXvJDNLyUfkZIXiO0zNSMyZQySBy/yEVmgOBlHPvf6vUt8/ewy2aVZ5ElPjJcy",
	"O8kf5XrxvH2x7ubyZ2snF9cpvs4C470cWzKFLHyQ7dajrmB6imDJcEEdd1DeHafUdK32kuaYRjq4AxYX",
	"uaIFz8m/n71/R3CWJLeT8vDzvtsnupng0EmKHnQG9GRTpppk+KoG133hMtnCmPUwlTsgSXrr7NL+32v5",
	"tVJ0CDmGrJyb3vhTTNb748e3b0LiqBXAqX3bqJVqlZ3FpobB3/fHjx8/EF8FLueEurg9RKN8lEQVzWqS",
	"E4FofQjdGLJWRCUCYDhg9gJmO2NxwgpMDm1vDuKPBsuiS3kOLBgH66qbx/8gJV0AH4lmrAaDUyrEH3fA",
	"YU7EfycNGz19ilHuAJdrz2F36OR6zrM5mVM32BBI9IMEpUReY4BjrVkf867nTKErdTAs+z47Ftw6u7T/",
	"N5MuCwZP5714uRC05NlHVlZF8NxagmyoC+T1SlpVoOrAOhRTBhtUmiEMzpD4ljDuBVKmoFgJ5qpzAbr3",
	"OSNTrrz8CDfVVXuiQzfucg6TaSOhyEY9gmsUMje9dXXA7GuyRKjE60JOvKIPJoxXH6TmHUDNBiGXFRAi",
	"vTs8F4GPfwqkApR5RZ7Z92RIIlz5p6DtPe/hfJkm5z3DTcHcz31y3pvIfOH+TAMnQ9Wxm3nkxJhIlzeJ",
	"9gXooqPgwR/RRzaGh77xB84xqN6dkM9bww0GQagTV8fC5pKdOjLJsEk9m3ExS6YIsis93naf4DzVYFoG",
	"7YStHAlZT5+64+vOWrAiaDYDQ/SwlQQgRJg9fdrasfA7rc1cKty28KOhMz2sFC+pWqzaQphULVZM6wMc",
	"LuTPpPATBPUMN2EcYa5eRRMtL9fEcmQVy5PP68qeXy13unT6l8awutfWOkLUhV3CawCKhpnlzONlAcC9",
	"K2TmXKfXLPW4vsrTKLa2YN4n14zP5gYj850gG0CrgutB1wIPGsV8TE0yAR5qxSDFxTXVztzS0sqtFs7u",
	"EOLvDtPdOKBw82B4oY3llbtDHDPY19P4/d8+GzCRyZzlxLlBBLYOFSjrUybdISEgYBttHAQW+2qDSFLZ",
	"V5DpZFGFrMHnvYwbppEiOFPn2Ej8G6kFy8eTxXnvIeHldZXf4YjCe+WqPPY5xSu2YmHw494WaB4rpP57",
	"BqC7UxtOjms2jPbz/S+EnddL4HG76bDqbrhAKAqBSbnLWAJ2RJBVIR/V+9rMJOBdQIHgdylkDsY3Lkbk",
	"RGSybMo4lGFfYiLNfESeSzO3LWJj4ATRqtWSa3G0XMCLn8qSe7c1+bio2PbeVpQEAHfmb1AXkbko5PVY",
	"s2I6BvzIjXJIlE8W6sbrSWGtQLoztsmHJCgt6c04PverckR6lQsMhuXuQmLFxzv7oEJLjWe/v0LB9bXH",
	"k+YKG1KJXLQzUgC5fNInTxpi+WR3HTraOH4alyVch3zmi3gOI6A6xKftnuqVlcorO0G9OnAygrxq+2Ib",
	"WkQepXhmUbqMIyAjyykU2VrzCjzSFpkd+r1ufNxd0RtfSzkrluPsNqE3/pMpw27uWAlRhO9aqWLi+OQe",
	"lQC2R92xokvNf8dayVDFTZUcauZyrQdAYPqmHh8DU6wKpfRdam9h9pU9FLQJ+gQjXdoi/hsjc3kdORJT",
	"xc4FJhowDo6f3YRUM6HrWDtRa0Z+hPCzCVXa29/Aw9d7lF1RBXnHJjUvzIALMmdF1ahcfFvkDHFR0Hfj",
	"6dMzaOrp01HcvpsG+HB4Hc08fP4XWFv3IHHe3i428wKyg81sO22dSiuBIMloNvdrFTv9kI8f30T2u28I",
	"JgfVvnV05m23rljGIOqikacdW01DAj6c+3O/JD/ikjjHp4MhefpUZ6qe/GjK4ulTMiBOAYknZQ9xpqys",
	"DKwKuzGKZoZk9jHGPYOH+8ePb99AEqGLi4tmleCXL19C+2RuymLs8PVvb30F+F/fsSYX6KGGA0B3sgvo",
	"3H+wQ/K/25G5+sd5rolg1+D8RugUFCuFzC69AkiTnapPcn7VJ/ODwfzbPil4nzCTDXfDENDrHQDNcHqw",
	"TxCepK4AhY3m6Gq5sOt3aNeP/QoL98p7nYO1X3HdOK17yVCvXKN/41Oyw371cB/nPcx3dN7bvb09xtRH",
	"tWbqy5c9PnUr11T6xyVbWEHGcmu0gDpn+G98WuNazu/qyA68ZDmnMPbXTPzErVRmXGox+OQctn3epbLx",
	"AnV7uHI6WL1Wxd/AR/QlNfTT6UkYePPZvvdDKDOuVZEocN7zt89Z1eHiQY3hv6rZeS9ZB9A8vKuFgzRy",
	"lSqxqtIySlK3E7d4hFiqgUSH5ZA0AgwZzucSjtKF5WxGF2RAUAAmXgAGjufT6Yn2zBWWhM72/lWx2f+Y",
	"QIX+cDi88Afzwi7CaG/vguzhvzX8MSA/s4nt37k7N455PokFsHIBVNq35mZqG1hGiwI1lb9SiAhli7Wd",
	"WLTDWdlBdtRDRy0v+CVb2Bm4BWuc5DyI3Qf04+Ni1qzb06cn4FVsCd1LeS0KSXMMSNEQsL3Dpy4PGsTH",
	"Ri9IWNjQ0oeXP2gkmDfGky70hUJldmXnoCD5DcstyYRNCNUtUbPVT70ru2m3U9uRk7fyN14U1JUKlAHP",
	"iE8b4kMO/Tz9zPCBqJR0yt/JIuxcSDmiGbgSarKjGSNtMe3Ux3ntjjwVdGLDXGpDrufcsIJr4z5+UPzK",
	"PoAnH5AywutW+UQAZ2enPxBqDM0utT94fqDosApWj9jL5GB//+3zTlmXQjkueLQfmoT9JcGDu9vo4f6z",
	"v1Y3fTjNA7fv/hidMTZq8oeD2+6QS4h/22uxMf/m128wyCDz87l4BsQaruFHCZ68A/IK/sSzwwX5+P79",
	"O4KHmux8lJdMDN4rzoTdm/eYDeadNN6bcgXxa7oAcWaI4k0gOenPLmT+LeSM/xv663BIzv63Z5uq5gxt",
	"Z+pv573zc5MkVz8DpJ2GGf7dnUKYLWTPhbudmf5y8IZbipxpPhMuOKqicGXjnB+wfEaSN2/eWmaLEHJi",
	"GsPe06dH+4Nv9///zs1KMWcnw9D3iroUvGD4uJ7zgoWMBLYbiCh68+YtNGvLKzZ3J4dmWa1othiGWf7E",
	"FuQHBrGnES1+gbPzPCPe24vRBUxnKfeTv0ZWAHN74hP5j8iFZTd++bejzyNCeR+tiP2y8BzMRzqpC6r8",
	"qkEeRcHtX85F3a+Y76VB/rRl37x569OmAL/TysHsarx1K6Nxp5b5EViE50ywKTc6JqpvpLdhZlIb7Ti9",
	"vM5g7e221AD0UjIqNCmgtB1PqBFa+oFqA/kfUYTGpt5ANFeIWncO2qEOeNxnnoMlA/IDd/HT7dhC7l3x",
	"kCaEGbm8H9HrGt+WC7IzkbLYxSRU/2a5tSm/AQUT7CLI9M6AcWF372LJTy68snjhLsgOF2Z3BFE3IY90",
	"RTOfoEIgXD3K5C3KFVoKV/KC7KDKYndEwKwZJXsAhYc7MzDUuC0hBYPkreTC3eoLX0E3j6qPK8aYdL9A",
	"nqkGm6Wdh2mM00b6wJ8zFwlECEGd94j8OxWMvJT4BqYPO3zyqht8dQhhyOGOyKH7wT6tekSefbPfoUQv",
	"XSJaLsjp8Wuwuzs6BN4f7mt0h4JQg081mJqhrrf3N/c/vIfRWYHWHSKMTzjmX5AZN/N6AiylkVIMsFf4",
	"t6v9WpITu8IhGC1ZmRbVJdOXXOzNJFZuCZxul7zU5X18kGmL1nLpNfmI22e5VG+0tL9Y6v6SmvaXnBr4",
	"8JHOtP3wbxD937J23t5++WKfjdvbPvnyZc8WsDXOxZcvkUzmtgocUDwv4ngeO/vOID/g0bJ9Clri4Bo9",
	"w6gl/0UKCPCGsYU/KJ6xEfnLly+V/Vc0hCjqDBYKuLO1AwjL05FAEsOKBhN1+qKR1twZbAJb4l5bnVlB",
	"DK/Q7e3zhW3c/xVEr0Zay6hhM6msxFYpVvK6BInt//1//m/yAf/2DHJUeSLzRTTKp09fRd7T/3Te0z7k",
	"6+L1q7cn704aYIKB95mB+4T6P3J8AmXff3j17nhlWVTGxQWfH5+9Gn86feNFGxB/mqKxmHD84QQhBN+/",
	"eXP89nj84/uzj7YaqgUh6IYpqO9EISflNM7vBwfPjp7t4oxPSitv2dv/QTHoBjLpvgohnu52+fhDDuUb",
	"gMIoFnQHlBY44L6Lye8T0Hstgrpr13LjAVX/XJg5K5sQZi7IQtYqesCQrbA07KJJRq4dXoRLoTFZQAJK",
	"IHXnolGxRdgjLstGjhFb2iGBR8HTzqoEnm8+9s+wCqd/MCQYa9OUccIOKufmDGO6K8VtocCFgyrjZ9vj",
	"crh/PJkR+ULOe6iGgbbf0dKpYs57I/LLcDjEj6EKfhwOh5/J7UULCgOGe3Fx8S9te/9iya1zsrFNnffe",
	"Loink+e9Pn72agcoEKio5Spsz75UNGBb8gs+See9cjHGxcT4Thjx/vCgT/aHh/Y/R31iB2qL356L+LJ9",
	"0oy8oDpcsLd8plA3iGYrlxMbWwdez8rwLgS5e/5sE5/00pn0SD8gBLIbF4yHQjnUaM5/FZ//xClue5wt",
	"dfwcIoCqIHrHY5DTKcSiOT0sF7MQm5+AD7HrPgi1B0cDXYbUkyHYtmKCctBLd5TVSfSQrto5kehoxkou",
	"eK/fA+n/ptf3Qb193yH+AzDOwV0KtfwAVu7Aq5aSJaUcpwJpiaO4uyYjTN+0ZbqqKBa8iWFeXgjHoDUl",
	"NuVJieOftzEYNKMIcRPLjmngRCuDxjeOpMc8TPd3minHUhSLpFOENw3XIP4OSlbalxLwJZzS6SE2YV2X",
	"JVX8N3af1Dhmpctl12zAnOM7UnU8zGVl9JCcMUY22BNQ2YoXsAGbb8UV/ciKQvYjFTBEIJz3/l3OBXAT",
	"9h/UzKn48oWBb/+XL++AO3M8xf+P2GeSKka+fDm27BFZMDt+WSRc0e7p4NEc388r7Zj+cp0ZahJhgjnX",
	"l+M6DVJ6xn8LQRf40HFBJgsDfsytyFYIgli6NNsfmm1T52o7BStsFjn4Hk+Yz9mSwMi9g0uTNLTAFyuF",
	"LtuAC3hGwUWEIobBo64EDkXInOnNJnIo9tUGk7SM+41akfq4uT7HgrB4+zYGui5Dp0edXtFie5cajrHe",
	"DAGLnMcRAhY4H/XhuTjOgfKeHr92wdJ9BAMIf0nlnNKPZ0wY93My0y72I9WaNLtNGUCEqsW2QdOvfMVV",
	"+W8xu8vYqHozNvFrKPsRit72e/+qnc/oHWl0lHVw09B9LtnuUbqDT1XUzgoHawfF12z4hM3pFZfdjImX",
	"bT+ljmPQTwhCCO394ycr2iueadDfZ9yS2X9c9oliGS0K+y+RZ7N/XO62861tTLhmxZPxUipT76k07GQd",
	"PsukWs5lalvYm1JegNlJlVx4jNwHICSiQWGsWSZF3vYxO+os1EcsvbzwXBBfP+r6aNOa3K649CtzZp4Z",
	"KnJayPY9j/NoIjQGpNHyJrM2+pFhTmRo7maIhKkFZoFDspEEJ1uF+3Xqn6NGxtvzhbueVlEC9qWL/SdZ",
	"2YKs9Huok02EQwRJzyGJWjbbQdiRnZCTGtMWuXxrA8sCJz3uViUVU3zGbTPwfQ+xr6OO0s577nyMeQrH",
	"6OQlIPer7ikCQ3CUoc7Rpt37++9FR+zzw+jzqvyLL1yCmfYlhbKd0En3hI/LlXxP1IgvbQlOyYuCN1Qn",
	"ha8iFdvqYJ1hySDFLLaq5IqupGJnof8EZddEqhkVYKCaLILisrM+jfbqvjBp4dJDv12ktNeNfsx72eDK",
	"kZ0p5WY+rQvBNOQvcRiPzrEnFUIXzunXGu3p0kUIY8XXuU/Ck43P9Mqxrty15gQs+fS5MGvM7MEBqMgj",
	"iNGiiKhy15Ebk0qOYayJlvEzTmVlk5uykYdUImvkmPjlmFNDXI1V3MrdGnM10hjIhhZbuP42LeKrti3D",
	"0DxqicWlHNAlmtYxgHmE+sflA6WfPrWHCcglid/Docd5tRR8F4IX8MyNyKnjDMmATJ0xB6l5AwyrG9pu",
	"a4ZTOiIfGh6zUz96DdwiY9ocbNc2ZM/4iLyzZ6MAYvKSazDKspy8qMu6QBzR15QLiP1XakTeMirsmHml",
	"wEPplIpL+Egr99GfyDA2XKs3b94OqB7AU59aLvyAviJ+hRzNGJET7d/ksC4+EuTvZOdaqktIttl+lomR",
	"Erw0Y1IUt4U7hFG1jt/6uy3vc5xh+ZeShRrTuohgUrF/rDFH+2bc/DUrikHjjQEFNZ0ys4hL2V/2It0/",
	"FJuzokoMGKM+XY9Kscwsl5jSzKHYugJ/h1hR7UD5MDIaFiVzcdJjR7hH5Fix8Kt2ThwwnkjDi6cWiJTb",
	"3V6/Z8+R5d2VAg6+6lla7vYOsxSF5QdNb7O6QfGLJXF1IGdamD8UCXO1fy0NPK0ibj8FCZYbsje76BbN",
	"xSy+5N046XsFFB6Hkk3TgxC7kwwudMRzjQ523uKMkG5iHGmQDlOQBJi1N6EjbTsWQdJgQWO4icB8JWAm",
	"kmv7ri5ZeF3Jzv7gYPdhePOdJfoBnp73VcTdrNAtdVGH0mBEMm4r5PCrNFMYlmYPbDoxSndwzMRAFZtU",
	"T59OG3v+lGFk9dABQGpS8MmezhStvI9L7pz5vDNSYzBqArWBev748eOHPfufs8gRNTgvAtYHRd/TAaJa",
	"gGsI2XGGBU1Uy73yilMyk4PIrwmoyIeXP6CTalTRlt9Fyxg2GUDLdeMMirUbf+6pB5U5O8Lx+odBE300",
	"jkC/wOocHDinzqnMmY7j5Ro6a70v+yJ6WlZ5Y65wxQQPTOePiS6GaQ9MAIV0Wo7MuZYmFAEuhGxse09e",
	"dTceTN/fjBTS6mFIeXNQTqaElZVZYLo8aBKjG1zFHXaTscqQKkwMcueE+PJfznuQpSBy43bxthVv//j5",
	"XNxBcOz3YP3Grt8x3yIG8TmEBTiVjPNYC9uBqLrdzRieC6jH8hE5OPxuuG///95f++RgP/r3d4fDg2/h",
	"r4PDPjn43v75V/z72zhg/g7GK489BckP8KyNCwfxF030m/39/f1V0Y3+5juPRsuIzCn4MStNdnweqJzw",
	"qUOobeVaj/Mg0Juxpw1jeyTHaHJp6y6f/fWb775dPZq8daa92abjV5yWmFu3dKPVNSp6Z0XiskNzW4W4",
	"Dd+P+B5nFctSAAhTRP/QsW+aB3gFPw+HgtPA8ywhpK2z3Xo8cddJGmAfn6OUecshk/gCQM3YryOMcgEC",
	"JJjl6Q1h4ZeZ2ZsZNiKvwQPFJQbbkQqLADUrzF5hi6DDaPe7PaeUCz0CHyhwdNX1BAfsZJIpvxmRM0OV",
	"81ABFt7e2RF57mAjzLX0GXt2UGmu52CXmzDnE/pLyUWflPTm864P3v4nFOQC4WXT9XZbTCr71TKllqGc",
	"GfiP/SewMAX8008G2dgpv7EMK4DdQUx3ip+EXlfuBo7JOZT2nVDaJ46WoAcTTA/UcbanPS7CHurdjpoN",
	"T1B0DvwIUqauH6Ql9XV1t5wdkRF8Cg0M6iokfdCQul1b1hi9YlmTOuNcWBHAYS5lIWFHNme0Ympvin7I",
	"4Izyv0eKju7ykanMaozMg6i4lo/AD/BNgiNc5L/aZPAULrg8o5olM3lFwdCeRvZXaloSmxsnMGvboTb6",
	"s9wx8UdiaSKl5NfPAfJD/dtvHORGy3aJhYvCDrIIF+boMPWcNUIArY1MkITPqYxCU9+dl53QFgRpbSyp",
	"EsT1YCkCIJrI897QD3TxKPCHqwFXp/FirGurWbVbTyEjxmbz4oHzVmIIy9l/bakUQfOGmFUmAie8A7hi",
	"SMQXJLgh+QH9gzF2rKTq0vI1COaFTuzotow2/ygNkfdRdy6jv/hPY54T51yZo+PkZ7uBye8HWKAffjj0",
	"NXDdhh2CmCY09jg1rocuZUgzGeeGv2kiEFvRGqdi+qA7evsrxPIdft7ocwHjXbNt8sEQCF1L3zYYCHet",
	"hd7Od63lwALu3Bl4g96nFqIn3LWmg0+4a7VjYeZKVjy7a8V04teHYCiEth4fRGFFilnQurxu2I8VQAqI",
	"neA9B717uY/9X4JGOBdJbASyCRrBMRY+zgHqgO6kpIJXoJkPmTD+N8BPcPwYLoHXeaK/fcSX/gmo8JUA",
	"FaBO5AcDq2KP0DWbBBWGc073vrxOufi7YjE8EgyDn659cS+gndvbC1xivTxcUsgZz+KAVgV4x4tY2J16",
	"WdqFg/6J8vAnysOfKA9/ojz8ifLwJ8rDnygPf6I8/Iny8CfKw58oD78TyoMdektIQe4tmmeYRQdd4LnP",
	"cWrmTEf3p+/praPmjkpeeXFoMUI8B0R/CNUA/cD3iyAQQ57f3o5s2UaahN8jadJ+jWAi/gl5W8L4T15G",
	"QBNRV1H7X778Wy0KSzX+UVBtHPAE/gShiL7xO4MvWJkLWdkxyjK3t04rYeXj9ocgd4Gvi8JgKlsOtOZ+",
	"orZFR7zsT05fMGpWM/o4IB5Jo7VEoaMugIUTuBoci8SmHwtaLCAtLNcB7KIjZXkJ6lx4A4+dChiCxlQx",
	"GvV/tvR2A2ORXFBYlw+YOhs6jXiQWjM1dqwTcCqHbS4G4/Fsfx8KyNhL43m4fNzDKJr+hSxLKchyUP3T",
	"p/bG7ARf18FxDdkeWE4a9+9dy6qj3j0ZiIBqIe9c6PRT8SW09V+AsqWFcIImNJ9OyV1b5hrAVLwvCssS",
	"eeoSjcPRpzaaCybXwVy8WasmttmcDdvSicBcC92M2pYIOhUgVoQc0T+EywHzQQEpxau1nKuc5oppK5TR",
	"zPAsLP5PjFURdKvLp+NdVG9Q+0AmrJBWRuEiTkJLMgdwbnc0KxhV/Qbp5YpFeSl05AEL/mBwBAnkXrWv",
	"LjK6M0Uzhh6wO6aF/3rec0Uv2eJvvzElz3uRuQVz5ULC4FAL9kQx0DcBab9yYoDTIrWz9izhHNAbzCKp",
	"eyMrrfQD8sGsMoNnw4Mk1AEGitvjWivWG+0Pv7uNbRbr0Q/SCuPHRUCgXvceoyF4GASHi5ByTXjN5HNZ",
	"A5v6XN48ig1xIo2R5VilsxP8UkjRJwU1n2Nb+8YchGBoPsHih2Bobv5Ytr+vNmIaWY0LNv0jhrVsB/Mj",
	"WVqvtGks7NEHWSxmj5RJcvUyVdjLGDRC28Odv2byA2TL3RQHttT+ijn7nIOPlTYTGmuHjB/sX5Z3yzvq",
	"027/8ScojCSa3IqV/OBzGLdXsKBmyyEWcutMoan+z+a0SiYLes0kqA60LeCEMgeqBLoNeLHQEheTewTO",
	"WI6PlSrngjq3xWWa4HPIbLBOY3qCuK3Pa6b0msmSmdThVKzoOISD46e2Ymfbiwyl5yR11n7hNlw7XOBO",
	"Lhb4td8MZt1cvjJJmUVLtc1kwtIuTyo0lJxMKgnCFu5sVnoNAGpk5zW8w7ur0PI9lNoVp+SCVnx8yRYO",
	"EYxI1QVqS+XEHrZgs8hby4NA6kDkASIEpv39g6Ba6JOj/e8OSc5LvZvOOEj5cAYTGebsas81RiuOatYG",
	"76fNFLlJhLzoFXeJuCM4I9tzxCwlhtnmnBwzc9vxX/d9pVglvwkuGST4PtFCSzJhRDMMJGgvb3p1U0R9",
	"CZopOAjbaXVH0ii5nTdWcxgcItjOd9/+tU8Ovjn6Fnw0YWcUy2RZMpGzfHeY9G5a/YBE839RyDonvmhI",
	"2FLrQcaEUbQ4eLI7JCHnij3C6MZCjk/6pBVsjmcZcnQm8xnifsbJlFZsbXewIkqQ3KwOtBgzt+G1XdFw",
	"l/1Q0l7oMc+3WCRXmJy8XIqybybeJyq5Urvp/HyqSHf76fSNn210TJvU/773PmYb9down/wetVjuXDSQ",
	"OYpv9JnCPVpN7xKuU3cgeCukE08ENxGqw+E3g2lB9TwQqd1+/K1SMvx9NNy3f9+HcsEaJMNh7kBOUtv9",
	"ePcxnS60kTZXpQVvopAbLbx33kvTkNWXNuzGxgsbbXt8Y8Pclht80v6tUjL6xW0sLkLnwseDeqzLnlzt",
	"loyeuARgxyWKilyW4GjLY49iyJA3OBzut29oJ+LwcBOujazGl6mQ82pwSbRdG+AoqKKQGX24Im69Glep",
	"6MisYLVe0cz9sXjuSfQenZR9rUTdK6lEm0JA3IrlM16/f//6zavxi7NXMZ9h+YskXEumWfIAO4d/HBx5",
	"JWZcMHypOt2cvFzbQ04NGytmf8jSTs3wJSTFnixIDsgz7jrn3z0Bwg8JKb8jOV3oPnlSHkS/llKY+W7r",
	"ApfJ9xntSVHyY0+ErtmkS3cWFdAcF/VkJKmYsmcm0nthPVCTbhUmu0W2ck82WhvgE5Wf+uBQSpI7tPPi",
	"7NWuHWrbgZOLNjV6IYWWgZU/Y6auluB6aaBY1ISHLnPVMtuIf/MyWYKzmwt96Iwb3L5Cq8lRx11o1mr4",
	"2ZC8Ziaccipy8uLsFTl5uSJtObtihYQkW00re+i6OsCN3Ls62JNXTF1xdp3Oaf5a0WoOMJD/3L9DYJGt",
	"Nb7ad+CPyeyULJ8xOH3rkKp8tkEdMJK5arvz6q3Bq9pJNhMRP/aZh9SA44qpsTdcbPPkY87BikWm0p19",
	"8jdSC5c5f/dx4RTjXQnwnB2oMw8y092RDZuxCnhnI0TkbfdK18K0VyjOINmZ2H8JQM+QHnKbRJMORRPW",
	"92ujaMK2v5M5O2MFSK/dQb5kU3AJnstrjFK1Be1yKbPn8jsj+mc4FCtDWC/ZQqfym1cFz7ghPjod0sJC",
	"2a0Dw7ffELg+29xAnFQz45ADOJjyc/+qPgRm1XYzxrDdTfTG7hPGhiL2hu17DOW7z74bYhRX7DkAx89T",
	"jTOEWN/z3l+mdVGMDbuxLULB8x4ZQEn7ZQB+ku2WXEV6KYSvMwRaMLbyRKjutCJLo4DVDKglCNEuHoJF",
	"fF/UOLgB/5GG1XvJsoI6Yag52QtEymZZbd9ccJQPS7TXmu2qKO40PEM29zZRMOWaWglcpjgv/qPfB8x5",
	"wMZNJ914ZGbs2OKUk/Ft71yCu0N1+0GsoJPeYA6E3ke0gvs7zeZwjB/WuT+zCTEAZog8B+ZILmsNj0N4",
	"/mwPD0kcD5LaZhtaOKYfsDzUNIaphIbiA36A7BLaOXjiL+78LmVbXtexa+vMsOoBpwyP85gWHMKPVxx/",
	"93n5/LcHvwPAJORvhBbF7te4EfC0NcDXG3el9Xze+gz3D2lgsYVxJ5wHy4GuMlhFR/vzY5DID+GsLh84",
	"p22I6YJR9IopTQuEFKJmPuVgrE5A18yk4mZerrqAoYCDlw3ia0VnTFFx+aRPnkwQD0IwrZ885EKGzsbN",
	"1dwenmtpKQIn18yhd/+dyFleoycOW4XM7gLQQjnHx+yE3dh9CK100UOoFt0kG70MhV2G9FXCmQO8mCwi",
	"8exrvnUQD7P6mbGf42wMj7V4l+uwK2FMCOEicrJzOdBzqQzTZgBfdh/CYwKMD6s8hFCK720uKxZ8YG+e",
	"J9iCz/YcYXKR79f7NUv7GPnO4ZS5Qv2N3gt36JuL1X2jmvWr9X1vOQLHMi4tF7WZF5j/DMXf2tKPw3av",
	"x2PQDpCh4b67MIrUAKu9kg1yBRC3OmYmOGujVm/BB721bT2ABK2k2gA+gV+3HBEsIVZ8B9tx70GtoIdu",
	"UEiZ/OL5R/w+C/iQhTNSJugnOuuiMAaRELxk8bXarDLpjQAnbPiyDvgxd9LtbNbqPIKS4PE4QhzzozCD",
	"Hxcp5y2v10/Ly5Fy35F7BqhafDafIKi0f/bgke71e5fj1i8gUTu55/P9ebzlu5PwQQMtFBetiTRbuYQZ",
	"n35cvaei03ZYuWJJWr37UYgdFpdkKKDMLCehyGO+L7Hyentu+IdYaQCBvh19A4QU7D6AKV6hNHghhcAI",
	"XFSr7lzPmSAtTUPoemt1/wMIWNLMGOJ00K3q/jqE1PH7iS1Amwz8bHQEAeOCa38UH53Ntv2tUuW88iru",
	"bQe16Ul50K4s0Ui7CQ8ijU3+kYQgaz8SAG4nIWakAV3uGlAibO201wLghzSNSKUJncjakOs5xfQf0IQ3",
	"KPjwziFk0cU43hbk3Js3bxEwPeAYnPfOEBKxRFhUUikOIZOGM6XPe7vDc5HOLdIA06859CcvNbkU8lo4",
	"m2qAYX+UDCMdY8fJh1MqZo/j0ZrxPA0FvcrVdemoQf2Uv8NS9slNdlFAf0P723ZgWM8LdsXQ0He4JQxT",
	"MjPmpkoJM+/t5+67Gc0unVKLthJJt1MAUpETbjSpalVJncxyw4Ti2XyFYjsYhUMhF7gUw7I2Ku+QKDVn",
	"NwCN/appnHi9cA7mspzYGzhnxIDZ3q550fKB+qWnWUmF4dkYUooC6+MSfXz+CjQ5rd5+Fzl++WO0osf1",
	"uw0bneQ7oWPXyMrzvp3F+UFnHbu421Hfrk7XdH67dqJ1IvVlFi78xlVuvA30nKp8rEOT98lu05pnd9BN",
	"49s2skzncLShpaVRr1yoFcLFHLWDrTMbR8o1Vsyr/V6/B7ZJ+Jc31yTDKX5iC3gZkiwUQut6/AN09wFO",
	"xSGKd018SpYroszS70JnBd5wwah6y9SMfaAz1hya7vWonYKkgCqktHUQBCdAVzoLr64zAHDojchxUYBH",
	"usqBFZvESaJZTlxJCMrEuhVVBlCuRhHAD9FGVhWSOthUMrEsDlWLPskKDoA3yD3Yl3yB/jbC7k1WKy0V",
	"Ng3+GbbhHyik1gK/DJlltVIs7xMhw0hXDTDafvcBZEQYca/fyebZ7Ee0zCvz+72J1zUsKZAjvRDAC2mE",
	"jPLDBJ62SekNaJgaM/7huTGSXDJWkWOAugGY8YXIHNqTaKqGzOIuy7hry7mV/SivCTcEstR477IzJvLk",
	"cCB5/dKYwK3sDLPyY04KHSpBYh/IZR5S38MhAW8zVwfTV2g/jeg82Zt5GS5OSBJEJxrSUYQBuSafDcnJ",
	"dN1hqjWLz43D67gx/gbigvx8fPru5B2AT7yTmAHHw6rBYRKm2T/n/CWvmCpoBWkwwoB1Cl86V4uxqsVm",
	"iOKTKcCP9IlPTwG8+LXHFcdFy0OCx5ICYFM29z3jOQGQZri3/8SUGgzPiE8n6lmRTJYlh8hwW/bFnGWX",
	"DkLbb8c1LwpkrUvpMj1B0HSzP26dIf79XJw6IcELytoP2bLyDnwFBGm3IiBC44oF3sYtTBeGuaDajOEq",
	"5Um32JOXlpiB0ymO39l/FbsCPEu8hSqkwB2QHwD0y/0ygph0NA/jLSfnvfMe5P+oJ9oWEqGwxtKtc9Xq",
	"zItLkJbD+UAhiA6smB1pdMgjgJxzAYGKiGqtLTF2WVGdS62dg73Pmhm9tHI9F6E+2t8/SstVsKt308G8",
	"pZVTQyKS78lLNLC7P/HZGZEv570IvHd8YGnyl+FweGvFwPjLYfhyGznNAhc8QnSBRcMOO2pUsBueSXiE",
	"HbLnZIFEAF8K2COkK3Bi3WKCFxhQSGwGENsD+IAUmmvjtCeWcwfsM5RcaVE4xQKmqLGMLoII7YYdcng0",
	"9Eras91YTK1YakULbzdACvdEu4fyWnHDAHNbTWm2fPi/RHt4YP9Ezrv3hlZGVkBYeMZ6o++//374/fcY",
	"6OCKH0bF30pEKHClDzuFj6LCP7HFRFKVN+W/g/JJjm4hsjHII5u4urOFyN5AwWWmzh/Dz+t5l8aysyz1",
	"AUVJGRyQaHkqKVWXcu7waYv27K7wGQ1EK53aFF6la6aihlO9LXc2JO8FvNlAHDvfh3dKZdNkR9xK27Wc",
	"nyrR4iVbjJXnZNe1FTherKTHOqNCpPZk2ZoBN9KVRorpGIC8BoqL9NBb6hIxSi4Je1fj3uQ1a9nevSZq",
	"JYOAiYVytQDPkIFlGd17Skqas/NeMnAiIvzbPESe6UcSsAN+kUtsSLIbK5VX6866K0AmLKO1ZgGjZk71",
	"3FGgnOzUAqe0Ik/PdmJaWqyIbGsPMZvd9l1ms3WT5QJL2JtdVzmg0O/sky2u9HIIu5cmQ5/hzveaRW/v",
	"copagTn3uCgeRScIuzWmRZHIq70c7xSKrhzVOynYIw5LSMG2HReUXTmwD3NF9aqhOTiotG70j805gXOr",
	"YPSbFbSt0ivX4r/pKqzJVojk0AvUkCSIijwpP989iUdqjdOLa4nUmVHUsNmiHUym1LQTTAbFLc8P5Z3Y",
	"V04QbbTlcm5l06B5dT7pltdrFEf44/BcKDUdLSelJT/UEPs/cO0z7dM9IwKpaoorW9yuSF3Qc6E0NOaS",
	"30L+0KYt4ZPlhtYmC1JysVfSGw+iSck1F7m8htGGzq+9zRfrnQvLU1ixFqWb5VlBxrcQkR+FuNpqup2T",
	"FZZZ6SnmWoVGk6cAsM3W0oQ/9sAbpso2VtH2HNp6qCZoOHV6IwerVb6O6JXpeKZlf1k8S6B/8Z42C1Ip",
	"XnJ7elJBBbbNsUs7tsa90spJITnZfY3Nrrdf/WZvL4mCPr7xCZnGS7EDIppPZqF9vEjc2f2dBB7gqOby",
	"zj6e5XD1+QapQvMrNi4pbKOoC0gU7lezq1GJqmD+s81VXNtdz5AVVSNAKi7uVTMlhmKenPsh8mDdVSg8",
	"iH7fINpg/IPiVzTDCFc5nUJqo1qzIcSxA15PrYoYq+f9mzfHb4/HP74/+3jhA7BXQl4IWfIM8UswUGrn",
	"u2//img8fVLeTKgDNxmg8mfnYP/wmf9Mi2JQcsGLkuwc/fXZOgwfBP2DmFu8HX/P/hbmuYRm6OB4lke2",
	"BGLoUQQhzL/nEhIUdgHnUpvRwcGzo2ddpJ4IZmIdkoTbpiSKxPK4nvTJk85CLcNGJCazGqXFswsrJtVf",
	"j2ngxt7CNEiCDkXnZCXiUDODlYN5JLCEdPapu12rNWmMXImAAg/zALcRLnzA4brbtur+QLNHw6PRd/uT",
	"Pvn1monD4Tej7w4nfZIzVmnGLgfqAL+W3LJ5xei7Sd/Wu6Kjo2eTjfel4BNF1SKh2f/qSCz3vSLxotjr",
	"ES2L/TMsTCZzpkZHR5Pl6xI38Ccqyu+NipKiII990U8h9umez6eCyq3ns/eIlB49uFwX9wbU+sqrCPnz",
	"7smEQN37QgG+//Dq3fFmKECfe9/1FufrOf5wopc5l5UE1r6WEb7a0UCXtCgi+MCDb46+9RxJp7DjWjZB",
	"DFYFNXZjhohJDHQXMLog8ds2IIP6cjAcDnsNmmB63Ekk5rvhCbrdW4sn2N6je+AJJl6U95DTIQIR9Mep",
	"OUc7gBL39vQNJkoIJUOOFUD4C3CCI3L4zbd98g0koN8/fLaEPLg1UNjKpd5w9XEhV4P7rWx3O9YNEOAq",
	"Hp2pjaxbs7UN6+YSVMDLjQWeaID98Vl0lzb9+fHZq7FtdDueLjnKRyVS9+XpcDHW8HRJCD9EPG8h9+FP",
	"IKr0iTzqE/kM/rgjLbgfXt/SdU1CM4MVRmSLse2xMImWPuAHXBzISRMqkR3LytjTcTeOZnCYBm7+ncD9",
	"AjL9nS9pg+eHbTxp/gnbav92O9xB7wu9pjTC2koBd9kDX+dRt+C/Dm/7X40tTVDHx6VVmFr4/kwV1l/F",
	"WEUlghhKQ1peO62Q1tLStCX4WWcEyPkUxNWQ0Ezp4XY82+n7Tx9fnd4Twhlp4d4GZmy3v7IgMGL9c4Hg",
	"a3sp3FwUn/fsf46iL39dJSKHrBFD6hBVacX3AsTRdkybVEt829qZdtk3l7fi7iycOwkb2bj2tv1+rByf",
	"+pzMmAjSfoY12t2axm9ayrULgxSf50wYe0FUoPprW4W3YPURW34PNo3w4cTkAcyPW4h1Sq27URTI6Oep",
	"xnKK1iktignNLok90VbufXSqAtSEIFoMl8Il9PmkGbmAlbxwycg1F7PCQ/gGHxq3Ve4FR8eZkCFmLyto",
	"nbOBlkIwM3g2+GZwuH/4zf73h9+f93bb3egL5wsKGcWXZg1ZEMOiGkiX5Mjv/8fe+y63kSP5oq+CYM8J",
	"S16Skux2z4xudJyVZdmtadnWkdTduzvsQ4JVIIlREagpoCSxHdo4n+4D3NiP9+n2SW4gM4FCFYt/ZFvu",
	"7rnzYaatIv4jkUjkn19KhT58rFRWZkwrgc7cIjUbuCaNucu2GW+X1ek3IA13B2ouLO+BWmEP/r/3vP+8",
	"98f9cU8qTKn0IE7Jc9mruGUy43bPCJX23L96mE/J7VMvuCqvzjr09f6fv1lioSuTD4VcP0sJiH5zXPQf",
	"SDRfiqV8iPb3Mj6Tq5myl8h3++xE2llg47rwp8g71xJJpK38eI2Yjs20uODBkdaTpSGa1nPeXz7mAMhG",
	"tZV3110+69vPrH5g/ro8uW3YQafbWcEPHhBr9w/5vGHfyanbB0opP+fXPu8o5nLFJr7wKwjHdwDjO8og",
	"aAVubqtZNPFPeSu1WaTPKYZ+GcZ2+0xXnxyQ3u1U3lSfBCnaJrAWmBR9CWaV7WB6+h7ls38UVD0Ewq3Q",
	"kT4XMsUnuHaE3VradZ/XcZN7y8f2jMEUy8v7gOUEkMFPaqE189X29X9zW/laqjSK42vEHDwycF2Asn1c",
	"BLvr2uPwIGZ4+/sRyzv4fGhxvq/9qLMXn7Ovz09ITSS2z9dudXAboh3GUnmW2sZRP/2kN6T3Cnv7c3f5",
	"QEg4d/AasHA1X31cszCTnz/HMW+PLApAZl8CkQw6G050qdJPuq592gw5F8PtkkP+vi6aT6emTyWXqLma",
	"bs1xiZnOzZIa7SjgzXrUO0awdxDh6OsdskvCJsMy4wWb6ZwlkKJgZ1wIntpZbwIxqpRsn8mpAg9vXBUD",
	"epWKCx4yN2ZKLk3vUYr5C9krqCbbMbbQaup6TxDrCtIzz7hUu36ULa0SDqUp58stZvoWmzMWHnkQiuM9",
	"wqPVith2jdd+AiJbA1uyDcxxRgN1jwW+tEPtGwSwm/IX0cyy0FygUK5lXZpbBIoCV3bFztT86ONVqxaq",
	"toSftmrufeSEFkDobsXbgkhZW3CpLGbzDiCYxtXpfjZRyc0J5toQUjbpWVwdtjMo9/efiwP2bdAm9fAx",
	"BNu723kUkWMjQCx5oH92nNgt1olOanOd3ArhHsE4P9/CPAy99jEWZoWYfVIl7bHax0mICAleLR7hzfpp",
	"F08FFtuCLem18xBMCiZJXke5XzqUY+RuH43z0wIW24oSABD8bpV96Gkdr/LBK9GOTIgogH4jq+haDAj7",
	"guh/n7jB7Tz3CPgqcloM7Vm/t7DmK8C50JZFuIhspxCQuwU2CaLcFkkGKTGQCX+K0C/SqdgSBDlcNx+P",
	"O/0pay+KuTQ+YW8zv/aqF9qFx7vANB6ockd0NvfF/RveU6URBX7QBXvyFPPgTTM95lnT7lmkojBDaKMd",
	"rIMwM7YBUPPDQwy17UDXqoVoRV4La9Ecyho0tkaTK9F981AuRt9yAm+n2wGAjE63w9M55i+v1oxKLK3V",
	"7yp+cDP05HZhgucQiffIk66CAtfb4alc+zhL1RbKuGx1z4sSQm4byZ7G3DF5rTBKlf295Jm0i/5AfSey",
	"3Pg4QF1alunbHqGAJiLUl4pdHL1hucxFBmGv44XneWo6UNjqlOcGoLLEjSSQJ4z41blvqL8i/gMaGE55",
	"PsxFkbRm6LvEZmxZ1GKKAQoJ+08LJ52B1cTOOF1o1B6fioEK8ccxxFCZgXeqm4thg47IxvrWDDqAeYPN",
	"SrdhY4A37w/Ua10wOk5d9ny/vw/AWS0Deb7/P5YBjVxvdYva8/3PLdjysdFZaQWu6vJKfseLtHqFJrhe",
	"hTAznaV95lH/EbWHgqFFpm9xPcFONVC8EEzcEQZLIaa8SDNhAApPg12xIkRAx2riLO339w8+97yRiOAw",
	"tOEIipxplS0qygkTZPjw+ZYFUmRPWaPF5s7v918AiJwJ7bnC8DC2LBPcWDbj2cR7/VVnoD9QR3meSZGG",
	"1GXgvETVl9bpxedcJuI3Q3CmGSKW50ZENQDcAcC8kMEOEOXyXPDCnZPgmgMNCsN2xtrOqpxsA8VVWk9D",
	"t9tnPxgxKTEjvFRJIbhBX0ORSFiQ8YKywwOL4dNCAMQVoyxDkQ9hDad4plNTA0V+eJoYY9NhKm6G4VSs",
	"IKeYkqRi75ixXKXudEUs0J8dweaCE4doEtNBf79BTG3E6ar32MFTY9NU3CCgoV9B44FaeebYeCYBH5CE",
	"UrdH2DBrgTw7+Jwk1mbXDffrdpixV6KYY5VNuK8RAMhWRWMZZ1OFh5RdAmDYVMGJN4stxxGJKJvKXoip",
	"uMu3K/uTzNKEF+l2paHUJcgt21VYDtrfVMNt+wOKv+JWQPGHjOolsoLtCh9r9bdSwQHackjSPKxCHfto",
	"q9IVJtHG0ejkNN1+WV47+XW74jUU943YzEK/1CWoTl7qu63r+MQdD+7kXGeL6bYb8EboyxnPfS8/e2b1",
	"spRZKoqVtuypd4fdqPRp+M0CYIRtlW/fcVsWPGMZV9OSQ5rNJdB1jyGDTcTPutdSpQC5mJfjTJqZky4K",
	"K5NM+JQEc57MpBJONkEJOkjDgLK2ELxohU+DmQxXZU31AO44MnjMo2dtgHEHkMhUFH32/kYUBXj34qsf",
	"m2Zy0u5G99eOlRauIkJkizGswzSH3D7MhQy1BWuB2HF4VrOxowOCS5noAmBy/VgBFbcxFfDRg+knmB2i",
	"rq/wO7LRJZs2+OdVl2mgz3YjLEB+p6I1Rw249T4xrCoT0l2Th6WfcPABq8ujf2qVFrYOkRF3ecYRjbXl",
	"ZVLOueoVgqewqlFZtzWYVGPm8WtSLRAl9Ha2ACBmbhj6D5eFSPG1cgvKyGoHLikrMOzUk+aReOKWwsP/",
	"4T4evXtFUqgwDKmPUmWIO57YbMGeBFJ80nZ+PgKk503YCDrvOF/3IJXzPEO3+FeXZwSf2h8oCqEsDeQe",
	"KgQMTCpG6d0QrXcJigqItQL3WYJR5SoFYY1UG9ExJAizTnMBgeH64uGsWlHMO4fVkUVGu0TZt9hGm1es",
	"WjBpTClMl0H2cBStQUHIjSnnOYrac54KfId7V0s1rQimzlvgvmNPEm7FVBeLJ5ByHlwJ8OXvznOXcKDq",
	"JCGVsYKnD+E6jeONw1l5ur9rS48eTBZxHiw2k8vo92uAndFxOtFF2l+lpyZA29NXbjj4QsRn8AMxjy9R",
	"cwAo8O4Tht9g1hDYIlzai4vXROX9VTYOGhFUxVZhaCuUGxdBd4WvJ5r1TNpWd9XWVw71iD3UITeh3jdf",
	"4wiCovvBHoq+B2yhSR9uB8MM15FJ21kJ3qVIKDNpzTKsxIzqbmXmCUTZZubRc9dGbhdBeYDffhGFpk9k",
	"8l2xYd7iW9sury7cesuWt2fL3IBuJRi/4TLz0RNVJOYaENbmFFutKdutTcykW4Asp9NCTKskVB9jejyq",
	"2vD9LFkfozIBoN3DOOYYVERJoODOHZfJtbCRIrY/UCc8mYEjnIT4LSOKns/FoypLmmDRlLrQmPsIekXv",
	"xOnkqnpBlFe8qhtCsQI0B44rLm3YjinnXcZvpl02l6rL5vyui25BXbjGTZe5169UoAjf7Q5UNaN6Q2A9",
	"6CKqcpel3Ioh/XsmjdXTgs/pc/jbNTcVutHQVOgZN7PhtJBpl02FHvo0gbu4DIBZCrl2doycKjmRCVd2",
	"CAPYhSlTbNbhQI1Go78ZrQbqw0AxNkDUccjpAvlF4Kv77ojSfRh06Leu/wUuM/wJKg867pf7LrZH96IU",
	"q5qDUbU35+/U6Fcjf4F6B/vQyUDdwxRiNV3F3WAdzBZk7cvduydC2faoWkoGARpgVMg6PoCOYnqCdm+3",
	"+VWyKZ8hgrSLXpbgiS15lVLR1PVwUa4Bt6WpNHnGF9U5wR7NtvkaPIUMAfxzpVOIL1bp8VEpSDCrTm6U",
	"GS+kXfjLtq7m9/UHCpT4lfUET2Ws7PcZMvyE8buboBK86IFUXCH5GxQyMV9tKg0NpLZ69efFwUM4/ipV",
	"pGetYflKlbauH909n2/9poXgEIy1bgnZGWSx8LWME4sw8cEMg4Gq/prLjQK7W01vrIsecpQuYa0J4dPX",
	"lLZuWAi3qG3LGvLGfcdVmokxLwzEDWWQRgXzgiA6lWshPnVB1CaDI6U47g/Ula8/44ZxSDIU54ZD2Zzw",
	"mD58cCvfx0/4H/e8v78fUQwvgdE8fQogvYZdvX//ju1c6Wuheu8LKZR7fL0HhsTeaXxu7PpsFRMA9ul9",
	"s/8/KMAs4AIhX56FSQ/Uhw/oDH6lNZIDDere8z83miMvfbDvRJaLwjx9Cj6Uo6ruiPXYBayW8TOFp+o8",
	"d8cNhk+jA3oMl6VrFLfSHDrO22Mj9Oh7y4trUYzYjmM2u4fsKE3ZV4RMC8n3IBARmVUARjgEZrpLDTmB",
	"XNkR25HK7h6yU/gTWZ/JOSRmqio+87VSAS846BtJYfeQ4WPMiJyDsgwlBT4uHauAkYAH6MgkRTn+zs4z",
	"XI65vhGGfXf19oxZPkW5RNzZgifWMLQ79dhoLlLJXYWfCp4bzOP0w8UpCjdvhPpeWjRgzXXKM48WgOv/",
	"d1fvhKzluNyFNGRqT7Tyolg9dNrv30tuZAKbc+hochUljCBzULSVa0qzePe+hSPJcB++3aeWrmjd3ETX",
	"tRQ24ttBZzCwg44fSWmsnofzeshGV9Jm4pDVTxXo5u7vBwP1UqeL5q9jnS78eAoe0kogjcKovoJA1dpC",
	"fPjwr9dicX/vG4PWP3zYcyWhsYGKKR19f4Xxx6DLzs7eAuOay19E6qMoM3lNAtNAWZzJqbLoNwwJyzX7",
	"ES2TqBwaKF7amS4O2V+4EuyVFgPlyOuvXz3/+ZBx2SU/8nkWHeELH4Du9x4GekkhSZgELgSyT6WdlWNA",
	"ZLJaqx7OB/7tqr7R7NSR0dwfp9aaPMuvhbmWam+qsWZN0bWa3FpzdHrQiKHf9gcy9QDQgIeoAuAIius6",
	"4LtXOEE6wXbOPnKjHlEyLXctcKlMa2N0o8BFGxJ4ofpvJiB5GrvlCvPxuoHFI/X3zY6c86kwXXb+6rXp",
	"MmGT/q7X9DA9Gai/lcYCU+mz2qAhDaHCuE5UaaTa5oWe58SLqxkVYq5tlF8EmX1/wyWAtd46LsbKIvsW",
	"zMFJWWRoF3Yc6rXANEnAAN0Mje8LZ7UHPDBq7fzV663a8sw0KMAKPYcVitq6End2m8ZCOjMaGsA0U8Ot",
	"7NMNEncYGEZ95MgfgMGcujkul6xWLCr7Vt6J9JCNLgnb3B1zz2zYhw9fyQnDP1a18uHDnpwQM/rJUZfS",
	"Nrxa0+46+pSGzoVIGTcsz7hUSFFLZ7dtrmvP7VrVQFDybBACW4wljQiQQvRQHSDSGN87AhytRGavaa8O",
	"UcQWVi8TMQWIiubgmeRzDYNFCV/KFCzvf6/aRR+TKo2fZwBPbgTjWSF4uojsHNEUNNpAfNZMmYL9BxKT",
	"gXynUsdBqo4SnmV1N5Pq/QpyvpFaRQj9WbaF50NltIx1Wu6d37/gt28pb1Msq8u5E1Z84F3nsANcX6rp",
	"nqvVub//eV0GAO79kAzj7N37q0qk6bNX4R0cnsbAUqlm9JwhvzqvB2Leu4kyJFZ+TQN1KQQbuwH0oJke",
	"YEnksr/g8ywomzJhKccsaI9gPNWOuiPrTvJJeHemBZ9Yc8hGAzI5HMKXQQdOPIiJUEzkhUhg34nrQJXq",
	"M+hrqdbr2jPLkae8ESmDkxT35H+BanXrCbmPHgQTUNCLHEZDeX/BGk2BNljc5VylQ1PLv1L3howyrcxF",
	"Ma2yWNRdiGp+oLBypQKZ4hT5MSV/gC0Er60oJUutPVcVnoKGgI9qidioGfQJA26noLlaJBb03EETuG+m",
	"NaPJJmszibBWh+4rVBgkwtNJkzPzLPP1HPWiQgj0GSAuaHzGVcAyzMhfBN5c87zQN4LlogAOqpZSDlam",
	"6rLIojzi3U4C+oCHW6m3SygS3HvjxCKUIc9rvCKF1kwb4qxRYkY41YH3th9eWOnWVRioYz2fawUXQJU0",
	"FTyielYormyls4CTgx8PeTIXh3TafjCi6IX4fXq4DDqlEcXhwbPnvphnScgc6q2Saf3QH8Rw1Y0XtjU2",
	"YCmHym+eQyswRrezaCecYiwTnGHwNnTiBbSC7pewzzjrVTwamMlYWEBia2zzZ2TdlDW7voHEBYOR2O+5",
	"k7ExKzAUq87TIYqZz/afPe/tH/T2D6jGMXHZRvuB+VqRzJTO9HQB6+ndbQ6FehgTb7SzELyohrQPXLxp",
	"cf8YOvso8JNHpUlQQ3rX3qAPDdYYx2draYYWOeVV/kQS8s8DpCEJhhA2+jDArSHTA0qnxaBzT/e4yNLA",
	"WpaKj3W6OGzWISfBpcKOxUxkInkGG+4usSyTU/fq91XBL26pYoM0fGF0GF0qPRgMOqhFx9R37m+ssok0",
	"a7NBZrFMrECYmIvfi+ifFNHoKbVBMK9EknHCe0QxglS58Aq/E0lpRfB/J1raq3mIA9F4LXvCFQsgf83g",
	"Fnx2Q3ieAVhGXRhQ+7A/VCewFoCyJLKT4/pqiYOGFr1E1rx6+oxSMqexq0PjvdMfqLdNv/mEoNAjqQXN",
	"o7KIxDrMJ45ZvCs3inaRZOiIYgh5e+oYC8Mqb9GDBBNQGm4D3RdiBTSJIn32OlqqoYdjgHtJGh8lcR1h",
	"MQ8UKeohHh2jjiqmwnbsIqdc1gf7u435P9tvz31bTEVNrF7rcVvLgXjf7ejJxLQhwbxrm7W5lnnDJkii",
	"WXA3CLy05pdVGT0gjX6Ar50sLx9LS5Bda+QZuUg1TUFtawJRlMPxYh0baLFMNtB3Cku4omjYITGcYpob",
	"LqHUDNtx1xj7FjxdBdgIuwx12t8y7j+5jcVVy8GouHHZ2OWSDsIJ/Dy75U7yDVDAsVGPgjLqHDaS3enC",
	"JReWGn5XxEXyEKa33qMfSoHPD2aP2RyaWssyA4g1NTLYwpu4urs9l11t0+SIO3hN67RsBR0oqyNPTEiI",
	"iayL8mKm+LZY2iPiVu0pPXcuLl6jn8PVWi1aQPuFox90atg2aHHI/BWreBDfcqC8E0rgsZ759hFcd1kV",
	"Pmpqt6vzueTdS/JBLBtQIvuG8zURM7r1tKWGeoCXMirTWVDQV/HSYai1gd7Ka5mLVPJWP+R2Z7MLehWb",
	"1rhu/AmVCCEYDGlD+2zpLV5oRdzo9q5o5Pbc5mW5cvDkJ700cne56AnjzdHSi4t7PFbP18FPB+2iy/P5",
	"7L5afp7rXLVwXNdiUQGc11yvYicq5MDB8Z/8vPruEU/2laDe9c5e7kUInlGGpSJHluy1pXHTbuX7m/15",
	"PmpJqP7K9YDfZRU8B7Lf+fERSk+9y3cn7jlLt2Ol9O23Km+Loi0f/Yn7zCh1PpOTiPtNuMxE2oq7jHI2",
	"DevTxexVC3AR51dOV0nerdP1jqDb+H+aeqL7huv+1dW5d5BPnCiu4zUK56rmYLkqSfVK9vcTGAOJ8c3C",
	"jrME3AsLSPqzzEopt37jgeKj5mvjlIrNZZZJIxKtUtMc7YNT8jeRCNxQwhqu9Oy93E7tS6JwwZXBQXqv",
	"sxAPC09lQ09lBIqiWohEBlo6fGYyUDkDngR7KYylqNKCy+nMTnRxy4uUTcj5rboBe47eHMm4l+zLQvBr",
	"esXfhQefdMKCKcc9YDbouE8jRElOcCd8hE5pVLyAsRovx/YA02U45sn1IfMhEmxcaO6kTvd5WoD7Pp1K",
	"WRgL9jhVQYPSTRm6Cu0zJUQaXP3BJNdjs0Uqoq5mi1zbmcAYW64MuHCRCq5LlmUIjEYJmLYg6o2PDdhT",
	"9xKtEpH7lTSxpE6actwzeLHR6gLZ0Pw73Y4bW6vqfClS8xNxLYKCdH3E0uqQhoujNyudmwEqrwXWwn12",
	"BzPE2ZE1w63qYi+goHsR0T00SrecThy8o3zMWONJaOKJ91DOpLoGcRXJYoGt1h2Mwz1Pylb0SCoWXsJU",
	"4s5Wo3MtI5p61B2g18AEn6wAVd9K4oG1OJPquu0x7ghsI0bcDc+qh8OnRC6iV8Maz5AEXYec+MHIBaLm",
	"IeJW7uzsbbDOVKF0nJGnmK8nDUQzkTWYPta1QK61ic4yfYveH4hYh+rBDx+C2eP+/pAdVWIc8p204efL",
	"ZApbjgYibKHxAHHtXJFw9cQ0VT4+Zi4KZtwdqH/XJQy6NKLdFxKTrVtNSyd/EYRP4ubbJeuWm16mdY7S",
	"Z+x25pYnSo3gCHY+5z1ypIuQxoOb5OkrA4GLh8y7YEULRT5cMnX//KpEZ+B/zbix9/dd9uHDHn4CLwh0",
	"ymo8gV56mBk7E0ZUTXf9osBGWxCY0N3dSLdhA9UymoF6pRMWjanhZOZKRAMZqB95JlM3w880uVXhfFKs",
	"y9xQgVEsazz7DDgQ0gowBc+DOEk1/intv0trmL5VqNNBl/Km/22kJkUgu6zq2r3k3W3DrVBAEFZPBXCq",
	"Hff4QvwezBkBg3pisKddQqigmDMY2yH764cBSmYUNsBzURjMYdM4LFig3+/jr9Am+v/f/4wtw8WdcGOX",
	"mkWfpUbFF13W7/fdRtWHgH58K0pTV3N0+vkso28OYKz1NTXSVHZA4AQOOh6aG9W2zL8WGoQoN6dY72D5",
	"MjALY8V8uJFLY7nAoDWD7LCoFAG7tfwFpdf4ZDtOBlo0cFublBk7OmXcGHBht312STWbbLmhqne0KI3I",
	"2jNIOk48NLYQfO6+LD/CFJyRy8sTFkrFj/PI1egvl+/fBVP+MhZMm/jijvVKAWaFAuHojX+C4C2iUnkj",
	"Uy8iL2pqgyr9x55jDyU9P0qb6LlY0iW4IvRy3OaGr56G/jbYsrIXb6sGYOTxo3XNY7PiHH12PBPJNX7B",
	"yk9CxDQ4E8ILmjwwMJmNzMoC36WPo/yJ8VAeDd6tgE42S8hUrpXClrKIV1bi+qDDMJruIF6/jpcNPDNI",
	"HRDknM35wKsEV9vpo899eUqI0+443Cb4gFHIXV+VZALW5E1jXILMowG0rOq2cEOtidy3AauR7tA8qNax",
	"nonioZV+FIUVd81KPy/b6I9CyrxkCRZwVbL5yNrREuVPidBSoaYJ13v/C1Ja+pH09vvfvDx8ffBNIzMa",
	"LKejiK0jipbIqTVP2vIE4mzX9G6m3hFzADEwE1j0TrdzAwvZ+miuYX+uhNwkBzMo2WURfilI1AXAEZDe",
	"fefJU0rSSAPzGKWuYKfbeVoH5VyJYHohjNWOZMIDejv/kZc8uS7zIDn8DE3ZYrEqfeNFyxMYzAj+FYgO",
	"r8ugyDy51pPJkJT+0m8ewck9W8I4DuUoeBAHLnnGqKm1OaVetAJtV+7L4C/Cs2EYVgPge39/vzmiU6zi",
	"u2epyPiSHrAG8L3fblnmd0NuIdy73unz7hamcrf6oXYtp8xaaHHqd8V0n++3zNf3vmm+zZ5a71dd2hVn",
	"5jhzwqGPfangCFwbh0HrxXaCai5WLS52WXADYTviLs80ECFZ/+OUCL6ljs/i0Xq+LxOuvhcLE52jJv3D",
	"D2C2d88vcJIE+Gh8lhHCHwc3S3BH6w8UaDHwLyZN7LXh2kBPKN9QMNi1IaAGndXQ6s1wjCGmmRywsY/g",
	"pf3E6iexice7vbzyoXhoYd8B3QIoyso8FwUb61Klu63IiR/rkRvJgi0euQOlYz9Vi17/lSdZ5OdFzUPc",
	"ubTu7QV5UyFOa9Bx5d4J4563kBHGFXN8ts/TtBDG9BNpF1jMo95BmWEyK9W16T/F30682z782Au/9itX",
	"GSwIYV08iwZVlaC34JBeUv4dS425+u1+wzgXd/Qp8Vnf8qn5KJ/h37hLq9UebrgKAke3mHRdyAFCzhJx",
	"pRWiJdrtTYBHY5kcF5xcHcRkIhOI6MhF0fPtD1Rov4rxJ6BRxsFpAW2FLW6Hy66rde+9ZTfW+xY/1obT",
	"4jqf1siPMSzLcgvLfn7kMgjJX/W8zZLEC+ulmsDVAgPcqfToAPWMidErqClaJlcRxEvver7sdw+u5vhc",
	"HCjX2VhMpVJRcGDEFyuRCJ2/9/fbpKLAuobV3LbimJ43NTima+VJM4RgmWNWS5JB/D5wzIaH10oG+il+",
	"c8uL6pkmz7KImuPLBi8p1g5N4W5XSvrZBIPd3yhxWN2mmUnX0FJ11XwqLcG9ajUSkqg6XU1Cz9pIqE2Y",
	"8V5jwA/bMyC5r3V/T2RplWYHmEQhAH//kF1502ywLsPrPOfKsbBrsbjVRWq8OdCwKnY59tMiMehM3IiM",
	"PfOFkNrQTFnZJSNzJW81WIKB8laXWRrhNxPeu4048M53i1cnrMew1+fNXmspB3y2gbi/djFMFLkoMPay",
	"TdexFq9WjGsV3YW1ZZZt7NZn12Y7sKiWXZ5cnNeTabMbXuy2gmBSgrgg6vr8ZSRzdle8GGnvrPbhFLGJ",
	"11dV4hYyVYLa28mGGU/gH2am85wcdJcvfzkXw1wUUrfog67kHAJ1pE7prjpk6bcpX3TZ7be3Qlx32fzb",
	"uVZ21mWLbwn60w8MEkg4SaTT7Sxa+l4+PEv3/XJeAtyDfipu2BtIBE3R9m5XKDgANone9gYS6LtzXDBe",
	"T0BM1QmmgFpx9/hAObIRVkLJvJAAQQGqR24WbsvLnIKtL92/IXP/QZ9dyqliZc64DXH2Jox2oJ712Rth",
	"A/WgUo2b2VjzIm3PVF9VhzT17V5RlzNepNUpaLyrFx5maqOGckE4yEvKsaiNNqXjZYCYSkTIttdi16ql",
	"eavAwKwo5sxEbQDr+1s2O2R/Ofsuyg7nMUAwIx6Y6YdSBYeVQzLds9PqmyuZzOTQ/L3khUgP2fFM9ugP",
	"ZiGJfy9K7HDoXwnVpwiro8as/pa5E7c8ik63E3XoDmFoqp2TWV3wqbgMzlDNBG7meliC4LzseCTNNSvR",
	"jUwxt0lmK9Q5CPfO21Ke/zRDk17lFDrjhhUiERC0Cq+JdhPIMlGUgFbgpf6WtMzhh+qefR+cJn0AT4p5",
	"5o1xF/tiy/t3oRK4beoc1vWP7i8Npr5QyazQiu4klsFFBQFsEAdX+Z0CYQ58Q05g/olLVDVf8Al4HOTa",
	"uCsycdcw4EDtTLhxhNZlMfUOMLFOrYlzMXYr/v2PDH+DYsEUWCtaBU2hJ+JPR2dxJaEKmczg+nXVomB7",
	"Fv3kQ/bqQ98xtBy6NFHpSDKhCfBrpWqDqkUOwGjQlDUWxvbEZKILy2qNB4fqnQnPMgOKJIiVd6XA9i/n",
	"Qpe2ywwms+yyuTaWpQhHVBceqt31QkRYOigVpu2eyNeqPVr4yjsLNg5hTC8rraEtKNvWI0FWJH4Vwg7A",
	"uQUyk4Pu7YySxb+ItILxQyWEFX2M5+epq1753ywdGUQR/bAKtHtT8zCpSyzqKrkL6aPHGl9ny2NtXE0w",
	"8NBjtU5t9xSMEvXZq9jttj67Y2iFHHbb5Dy/oM08zz5H2dLzotV3f5WLLE7C20RDXjmv/PdnIjBRdxr8",
	"UM21zHOR1s0Gccn1hjK/4KsdT2GSZG741HUusJlfbaFpGhtX2hZyOhVFbYHDmtcNNFHJz7LSl+GENmGT",
	"AUi+in0l812lhq4CLNI4Hn7ZNkM3V/RqqQdoor8dRNL5UEavNQ4+Rhi827b2oQgxgI/lGz6IveJDTavm",
	"HGPIYKAhhAxjIsMK/M1oD9rd7ueeLhSfyyQE9bRRTZkRMPycw7uLUSXwK8VkOsK7CPYZoP/wOnIhhFB4",
	"H0J4aqdaPbFsxm8QzV4m0vrm0S2C+gh9Snd/u81Ou8FcDn5cA0VeI6j9xGA7q2FgxVwqwWaQZ0gbry5n",
	"ZgYP/bEPMH2I3+krHJeHXWz1PnXyM6U0NGvEUs2oJKMlaYEt0CqYWL3/ZIO+0eCC+r2oDaVtpcnjikJD",
	"fZAsinQiZePSQtHaQixr6azNhqn33m81Q6fBQxiClxGerBoOLbm4y2UhulXePZArbIZ5NEBEMpbPc7bj",
	"zeK7CERi2Btd9UFId5Qr88mzr2dPuuzJH1P3/wff/Gn2pK5ujLQDvqv2SVQ5KrhU3qe5GpQ7A1dXZzgL",
	"HEltnMQ74CAOOsNQcdCByJhoDWt2MdiEahEgpapdMYEbUZjWPfgRfwjAckCuoOdErdlcTqN4s9qrqjXW",
	"5H4lhw6Xy3YKKpRCl9VSBp+Kw+qyWitG1R6Wzcul0dby7fIzjP5GZosvrmXDbpe0bFdHP56e/ftWWjay",
	"Zw5TPXeMtEXQIINnEbugeVdjrPMQexlZA4aoGq09O9syGnjApKPTXgUhRmrVCvBnmaf4blZOq4aj9Jnn",
	"VvDboffo2Wwn8WPgtwir6nH/9ITlpJ1cnh8pR1OR+0TT/u0+5qYJOxBysDAoD29zKHbIXnPj4UQIu8pn",
	"04sQqHgKyR3SQ/ZKiFwUtQqQ+tNRdSFmQoHBIVSNxD4/LN/W59Jx+hNw2tRt0g+yqeG/OHoDMsDRaS0e",
	"2HvLQ97DvBC9vNCJMEakDWwvb2OmoK848YVHXNus67QwuH6i5x+l60x1YvpxG23Sl5ciwIz5FiWdVV6M",
	"XhCyGhZlgRAaPAhKwYeQ0K6Xo3AVzxa/tLmRHdEvtQzUYLMFOkNTPZll8A+h8L8zO8+GvuFBhy5r3EV0",
	"XAz+D+7MFDpDbGivnXIbpNxdlNGXFddeqpMhghtuPq01+QqeB6lOPDQiWKl0YaWa7k14AokN1nInqYY8",
	"yx7UawN7bRgQ1lBVXGhjehNCdiZbR1v/zRykbby31msq7tDLHNr2+mXEpm7nUDZkHtlyavh+rDpBEPfQ",
	"FVRv72ubtOH0396RspNsEVKHtxwbnwnz0byXMTfTJt9lKPXzihFGyQAfbZiVxX/OgVpUmWWo9qtBYTUJ",
	"G6tgjOHmKuvbrkazvsF1Sm7yGz6elav8vdfHApbqGjWXZoVoVhZZu8j/w8WZl5lpEMDmhUrBHze8MRxf",
	"P9zby3TCs5k29vBP+3/af7LbZ8dcMZ4ZyH3mBLsbydnRu6vXZ/8+vDq5eHt6dTJ0fQh1Iwut4N3mY/Lq",
	"utTWHmqyeiFbEfuCZvhBiaiW7+mGHp48UdBDyzEz8FbqE75vXggDANHiRij3vAEjzG7Xl/cvTeAYBHty",
	"mEzsITPlZCLvCPsYXp2h8SeGkUcY8hffGR8bCCam30oj2GFSa4kXAnOYlKbuJhDBGgzU1czJGpi/AKPk",
	"RXFD5SelLYuQFQCxEuCYIvxOfAcjDnYDFqeNrMlTPJb9JvIOtGXLlAiTC4gs3omb+QhaqPgELzA068FN",
	"2sOntK+Mud+oCeXD//Fvs5fg+TJ7H9xP93t1AvRDW8/zcE4/f4wgGB+yMNvgdg8SIf0KmZISoWzhJAOR",
	"MoRREMWN9OqSYBEPLUWx+1aKgiUALuORk6MlmfMcRJL37979G33H7IC6WJAqbcdnZLEa9EcYDcFudXFN",
	"OYeePj32HUPuSAOyZI9NMKouOGjeibQHkKlhnOMFJcjALDs741JmtidVlykak19vME4dqQXljofBw8Ei",
	"n2g3ukzzdO0mV3OjYeOy0HDPDg7ZWzF3M3frRbrUZ725VKUV7OrqDEo9O2TnojDSwLuHjHspt9yRHzqk",
	"qmkmJpmczixLhc90I6ukEElZQFZymQqFvjc+n9ZSgkXPsFfzxIjnkbM38obO4Yv9KkLDU7S+EUXG8yEs",
	"O5WJYjOqoIiQaqNz2BmgidzyYipsVHX/vrqwThBkqVgVP7D+DFQ2w1WHACWhJ4Z5GmFvz8IxcM3BysSA",
	"3Yj2VFE26Aej01L1WdlAV50ctjNHyvgXlofN99T/WnDHMD3Zn8FAXL/Ekdo6QoJj8yV6qyVmCTQX9dok",
	"Oaz86YQX4etXx5iNpwJm0ROqd3PQf8F2/vjNn1gq52YXAJN7b6WSZ297Z9/0bp6xned/+hp/dO1hK3Ah",
	"uaMp0sp8MKITStBc1REdVWe0/5Cj8CyKRmqOudNK4vfdzygcPbLw82wL4Se6YZuDb0Cc0ePW8/5VW1Ht",
	"xG59hC3r+3EXZWAeTSiJB3IPf6xuBDs6/VQOcnb2lknlISSAiQwUcJGLUlk5F+yNUEennqewmKXYCPQj",
	"cJMARjdQ/oY1iePDi+XzUMGZ1E7CqtOplborcFR7b8R8znvPezDUHWj5u3I6lWr6mididw2rqmYL41UQ",
	"HyoKxTOgcQT1EiqRAhRsLWtR96Q/Pv9h7835DwRpQMzuqLS6V81cT2gBcQ3Wzx96zV1P4O/CrXQMMCEk",
	"nTm3LREzn3Satzlu/C7chJtdtrEkhNKTYrjf6r+15hCrCNivCrpDimqe5WgZNx3mVSTUajMSc/CZKtuy",
	"tB6jVsuwgqtUz5Uw8FSKTgOkC3/W39/trw3he7YhP7jV+fC6LW1r3rsOTusRRmw7fJjOh3kbTGuSidKs",
	"aGb1mNfnNH8oO1yO9n4IN2yP42146W1HZ1VTRGeoAkDFHaaPKqI7ZbfVD+DxTuH26+rd7Fvyf6oeuFNH",
	"tuQ6XBqKkW+1mupXL3vGLiBhHh2vfuXBTxiyHo7favILGCjKSU+mOZbxhSi6DJKrKU4Zcnnam+tUThY9",
	"9LAreCJ84qdTiKbiyjqWX0UMFBEW67v3V+yGZzJFk9OUS2Vs5O7pjaDw7Kc8DSZG8B+ocWnZXHBlmLRP",
	"DMu1MZLgQzH8iEkFXcRRWZBBB8RWmLxKmVCmLARb6LKIPCwh14DlUg0UDgUdQWVLpowPHTAehnwNB8+e",
	"u3dLaAp0YDrvHHb+IFXiKBtDzP7Qv5HoJw+q2M7hAUT4Q0GSe19xeNqEChk39kcpbn3C+foZabVhhgwT",
	"YMH0qF2csGe74EHAldesgOpEKiMKa1oNmvG0VgVORqsYLB5SMeMkd5WIbd01AuG8z9vMgWXuRvmASCki",
	"inBs5IRJy1ItjHpimbhzo9+BBaCzw7CL3c1YK27la2uz9ky/z5e1yjp/wHKget3TRXMb/nL5/t05tzMM",
	"SwR7gjcL/aEPQaSO9aER6A8Qk+n+rQsfYoq/7tYu3YpWl90akHiXnBrAvOBYfQVAu+OIza8b/PaHUhlh",
	"uywm+N0+u8JkCU6MgzxWnn2xHZJQoK5Uyd4f5mXWBScZ+ASNQaa7pT3SuT9JGzanPfq7zk/L3DGuMK7I",
	"EuuG0Ol2cGLuH3jm/5CXZob/zTL3X56mV/oSi+QwNjcV+I9U8B9+5/5T5wR/KAR447X6DBf8RhQmAOe0",
	"5NEn7CvC9wFBFvFUra/b4nKXtxHZK59eGBrB3DuQrmBnn30b/b27Fl10FYwGoZH7o/ow7XjgeJAXdUdO",
	"6DG/21mTXmTDSFpZ60tuxDdfk1gR+XYhN1ifrmf7rtsP+SUxU8dvIUYy2gfwJQRXJLcfjs2RQRRCyb/1",
	"RsXlHHqrEgvVWO/DRj4U6bTNky4ePxT5lAmsRZJKp+IT5gA51Ye3Qk5nLSfqHLHa/CQYljOMZ5o80GD3",
	"ImJIdVnDRdk+WTUMqPXewSP688dTd8U5ymy9G+lmbhHypA8hfdpGM/iP0kiLsAqw3WAJ0igmNG7dBzAO",
	"eDuSs90m6ngVCt93O24bV3l/UoYyJNexz9gBxjP2LUBjQMXd7b2atp9R7QRs7/bkirMoKCwCGfiU9Z3z",
	"uxbnqJWwMIFe0EMK74hSYbLm9JOuCDeSGq5bhYuzajRL0eifezwxt/DDWTWYiG1QWOtn5Bbwxm8bzvLa",
	"oC7gcYdz/8kcSvjEDC24y7pUtk3JYnm2DEXQqmKJ6GjbB0pN4NoKwO8HkBzPuTG3ukhXwkgrcTvMqVA9",
	"NFGJ28vnSfHcnv+rMbfvizTeoVBlY0xH3H6bQPyDQXez+rB8leGMm9kqiYh5iciXZq50n53c5doECBSw",
	"ExuRlJCvpZDmuq7n+8ub14v/ePbn8u283+9vk/7QPV58EE7VzN/0TKVabFyQULvbmGTb4iCA3cMtiD7Q",
	"O9NlyrARdnTaNHcYtiMc9eeFNKI3LXgqdn3GQYN5DslK5iNejguRIuaYYTtHr453McSmtDM0m2GiJsrg",
	"Zdjp0VtW6Eywkft/s8dlnnHrFhjeh6OV6vupmEsle2G8vf39g+BC1mXP9//4zJvaquQyUXgl5e7mZSr1",
	"3o1Mhd5td8FM3Ar1p7BckBseke56XO5VthP3V6oTbwmSamr2psKCH0wvgi9qaGtSORcKPfHdgLudTCcU",
	"HdEpTY9cFw4i+1zbtFH0cQQxlGnnsDNf9KZJ3qNvdQsewfQtKWySatuG7WK+f8d7qw9P0PEAsGDBn1Vm",
	"os+O6ngCR6+OgQCUVr03x+exDW9F5FO1JDWwtT8+a/N2CaW9MrSZrBpsrl128OL5N6BYALpA7L3lhfy/",
	"2MGzP/UOvt7/UyMpUSi1264Rr7YtdtKp72B98LXjV4ipP5bVSTw6Pw1uY1FLT7rsiSjd3vVuhbEHq5zH",
	"3rx//+bsZHh89v6HV8Oz98dHV6fv3/VZHFxSa7a/wS7qJ7WCANfrwlfylxhkMvDJFV20AaoGov+wbn2p",
	"IDt9tcVanV+8/8vJ8dVKa/PH6tFxDT7CWruCU0eG20dl1aeKNQ/uQO3gaC5K1WVvvj/psmOKpT9RU6nE",
	"bnWvegMu5idEM3EqbrqsKNVAjabAXqHT2Eu/532BMz2VavQZL4xn/Re9ScbNrILO6Ma/5YUOfz/v77u/",
	"P8e9AKnJ9nCjmrfAaqYf2Um/3v/zN0vXQJjMR1wBDZPkfv+Pj3cpXApr/Ck7Oj8/O0V2NDy+OHl18u7q",
	"9Ojssv28ffJ18g/LmT/RhB7hscErZqNJvcH/Y8rblvdv5Phxo79Nbv8Z7fjsOzmdicKHlMz5tWC6tHlp",
	"MdIKm/iy5n5EijTIOoODjdU5+z64NPucUsyUY7SjWaSvz+QsgEt0AEvUOP3R2n8Rl4JWcPAtPQqIJCvq",
	"vyBvAB+29oBrGbGcMbw94smgUqP77rwQMCcjbfBQooQOr4LjEF7ObgSHzN+8xLlNiHLypQUUpguO59K4",
	"Sw7gMt8UXNlwER/6m7hZk6dzqUaET5gKw0bNEuQggQto4M8Ry0Uxl8YgqI6bWnWFe2DAHmGkE1f6V4ji",
	"t/GF3iw54cb29ve/3vIqr13gPZ7nvXEps1QUeJnTuMnD4Ojtp7TFAcmpR3FtdcHA3/br5/0beP7hLf+6",
	"hlj0Mdf9lm+QjevRgm/PW6IianfQxkY/z43UukgfexfpfKi2Qz1NdJFuj3razN8FmZlNvz3Afzte2ox9",
	"bzEJr06wcCvGPhTZEzM6+EDCp5CxYMZNlY2w3goNMnK9gRSruTsGheRWDJRvptdoglGsfaLnc3AAwHuQ",
	"PJPc5QjoaP7hEW3ejz5rGqJ5uU03u8Sc/c5fnvjo/W787fSVK/Ty9N2b4eXJ0cXxd74UOKvXsDXdlzoO",
	"AFS9OPrxpPrgDoV0yw1+U4gzNK9Chcfw3xUBhFJNa1vX7YwLfiNWlnc/NiqkZXLt/jfVKxFRyuTa/e+N",
	"blRFVroywQ782qiCCJErQSCWcVK7HYyxXo0+sQT6ULHQxTvQ9FZsdom7+jThbVZbMRFFIdIqlXiU4T28",
	"MoSCx4Vx/z8pntQdYoRa9UBos0a92JwwoZFVKjCNmuS5Ech423Q3gTHE+W7w3bVuvaKXWXO1Slin8tr9",
	"fyoaq1W2Y13xiahle19jJiaxylXxSxUQyz/KkukztRC0X1tejf3uqpQKWGe7FBPbJvfpLO9JqxNqC1v2",
	"V+sAHNefPsXT+/TpYTuyLDylC6/bOb48QSDZXazsuJKr+lYmhTZ6YpnjRewnMY7qY1E88q7wOixcCMgD",
	"2Nu4Gzz7rm4bxgSC89RgJfzwHKNz1YDjLQ2p4nmuTMXf2KmCtG7sCNFNoA8y+ELwHgFE1LEciQ12kVUH",
	"Hhc4l2fKNV7b5pvlkzQ8ckz5LXWzOfw9lGyjxJZg/hXIFuACwZXSllcPVXKYpfwaETYdQmDO7NyJ3ARK",
	"0em6J6IoAL6kOr8pt8IdM3cXCQ2nFv9pZjwHwDuvqHbVMj3udDuZVNchacqQm+FClwgV17YlfpLHM26P",
	"pkLZDSn1w8scwji4q9FnIck8CDY+d+ATE1Q83YHiasF8lvkk40VIIWO6wfsaeZn7gOlQwa4MMpSx3LZm",
	"WIkhfuoboyJsdHFnwYOK33AJkf2tXr1YegiiVwo+uu0PbvjNa7FoAB+vEuh2aPpDmv4qlxuDYcMAOTcW",
	"QoVlg5FIU1uxbR3DsOnLXCRt3sUE/dgyJDTgN3ZpJg1EIFfZbVcRxAOSJFuPWdwyPiKoYY2gNrYZF45y",
	"cG5Ij3hZF00wSyJmf019WtZ4WutcNZd4TXNiVutsCJm5hnPelrHgXaRg1Rkm8WKuaKAGEps2vZr8Dv/c",
	"Bu3qHRMAwxHJ4CU3Mjkq8Z0OSyoiQChqYmZt3rm/B4+tiUbHFGV5AnwFvRM6yFY7FGjS8UqMqbSzcgzq",
	"Cw4l0jH9owVCEr6jD0Uq3UEew25ci0UPgV0Q7sWxk3rSBdQCYUgh04px9vQphg8D/HLiaFSZ0jBXWlqR",
	"2LIQT59iKHKi52OpKDXNWKC7vy243+8Q42s8elUqCuWu9oTnfCwzaSl7cCoyeeNej4txIT2ajnvemYRn",
	"KMl89RX7yR37t/xa+GBI9oOSfy8F/vwV+w5rI4GiAPDy7bMX7F/YjzjpS4QCkBYkjdcBJSOG2FpCm6AI",
	"mguRyLwA29kFV9fsNWRSYjsXF69JFnkbbNWudYA2hhX3ORLEne0y9HnoMnB6QAYPng/YxEkwzXqpz7i2",
	"ELOgS0GEXXb00yV7KdJCJ9ddL2G9Af19163MrNC5TLDF73iR3vJCsKMkERmpwEFGO337qpb0wrCdox//",
	"7dne0Y//1ntx8MxRw92fvumydyfv37k/ji7e7sJ4L9+esJ3LhMMFwt5yW8g7dnJn0QsALZhHF2/9rryK",
	"CPLY01O0Ykhpr4SRUxwY5faOiG9a6DIn5FLKHuXESPBeT7LSWFHg0HyM0o5WAJbPAICZ9uc7Xchf3PHL",
	"GGA5k2T7yrUWbKQAhZrzwgINi5RxiBbDhkxLjHshgvoYu4nnC3EEHNxJYSOPIKyKAtCgSUQk90SWaO3G",
	"xa0uKPj+2fmxz7xrhbL0NdMJaj9dh6+lEr03BZduuK/csNzJAhInYwjBnrsFhSD8ZEE6pYVKUHNi2A4h",
	"lXexcJcFZIZujM7eZfxaoVrYbe7Rae8d2gZ8aC6O6eLoDexlSGIckob3eDl1LYl0KdL4UhQ3ouhdCmXZ",
	"yQ1auV1jXkh3QhYeLSuyTLo/fRZijTkb6gHLS8lraIO8Z76H/UCqo4Q3AdzDa1l3KLhvdxW4Ag0SFvMk",
	"rBQ8Snhy7WhXxSAKQKdxGmpsNxM8FUUPHJ4JDi+0XXEWdiHm2grHHqgEkFWYcapvVaZ52o3a6BIXIt+6",
	"xBvI3HHy7Oj81WsSNwEWES71Hy7ODNtx99EeXEp75vneRGZ+IS4vL16zvBBuozwCnIdTpFg+WHLiAo7K",
	"3PXPTu5yJyNA0J6b3HEGUddnkNVMCuMnFGFQXr763pAfRheigS7h8sMBny/sTCscMjDI81PQQGLroBsn",
	"zOnAo6APegWP7np4rfaejpbeLh4+ibaBgn4uIeinipxEmqQ4TIwFMmznD1IlXYpBgnif3SgZWyNeEts/",
	"k0rwgr0VxVTg6eFWQBZ/TEgHiiFdWFC9oDaZpC8Kd8fMrXRqPCQhu4A8xEQqLbmKcaoJLkcIWyl8LWzt",
	"Dbj6h0QYMOdXwsmbePx9Pn4gjeDhjcCNObeziVRpaOzq6swnQayTb4TH68YUZWuCONAe8Cpk9eh3v4Mh",
	"CLBP9KunuGqsbFDu7z/7huGdBcwRx/FeZU76gduAXeaZtHbpRBWCZ96DAQ+SLwfbUV0LbmPd8XPvVGz+",
	"+3IsCiXcCr+n0DC4zQFpgGdsRITn48ZGFf9yco9nFpmciGSRZILNueJTgRn+XAfnhZ4LOxOlYW8df01g",
	"W156fIi5VtICUmYISsa91mPH3GpL8R+i0L1XNHz2Qw7OS9Dchc5gKCV98zdiQ0DEO9ov/utM3EH47Wnt",
	"BKFQ5E4wND0Kd8zwZn/Edpy0tttlI3fF4BeSxmBdLvhLaf+X+x02HQsUIsNNnsm8oju68ZEbkxA1CixY",
	"0OdRl408Jxbxx1zmwlFG+MZ2MPnHuGLoFX+lzkCZ4xmzpj4JwmnEdkJGtXDCAiG5KeVFqaCcj8bz6kz3",
	"Y0Hmb5wvgaAWokc4qK3y548S5FM0tv0L8/AoTBeMrPmVb2Us7e6gIEltnmfldApyzlHtAXDITriBVJc8",
	"TT3vIOBKt7vg5VGIqZOFnDxlHYcCtUUmE0Eu+/4BlGXsAiOlLgjHbek1hCelL/VeJqY8w/xgNqveT+y8",
	"HGcyYUfnp50IXLtzc8CzfMYPKFpZ8Vx2DjvP+/v95xQACq+5PdDgmL1KjZLrtjS64DFwdvYWwsoxA/AC",
	"AfAwKB2eQiB2dKtAfEaZaEDadmzakwK+DLr++VwHh69z1Jmo2oMcUXd0/QVvIq5IB9Mnscv4EZJ42iV5",
	"KOCadP0jHlsiJRE37PLyhMG9DvbGELF7msJyu1Igi3XwCS2MfanThX/d+gjNyq0Cs6b6Z/LGrC1RD0Er",
	"UX+uUxiIV6LADj7b33+cEWAwB7gd3dk9WJaegQWuN7iUkq8hyzKshPsJzeBROVzapjqCQ5fNpDVDiIWE",
	"f9MHocBgzI0GgPsKv75LO9llE51l+nZY5sMqH3VULNVKdBnmPFl2qm3RMiB9gNxdpb/q0sTgmsGZ6gJ9",
	"EoKW677b+foz7g/kY2kb4ilBPPB4qEWl2nrxZQbhxTGgAVrgWI0EGBCRAumvP9//3O14iPWw0kCArPfx",
	"7x0wTUwNpREvFsMYk8ANyLO9ZMbtaqZ3HOk23RPk6A2tLOhhPTSGCQlyvPoTXzqY6xrer4V7Ct+Igaor",
	"vqEgpUwuxEQqgUAms0KX01ml2Ksgv78XC9bAgnr6NB4m+w7HAKarMEDY9zvrJZiQZwacLkg0dZ0dY2dQ",
	"Gf26EVkK702aEtsJ6hivcumSFmYXk82UKsGkcdicf+7EUw9dsIQrlnNXD1KNXZNxYOG22Z/ekBsNL47Q",
	"JqUyYaQfBwE2Scp5SeI9qc1p2jVVdTT11+QfAQNqzN0Jt7APfvJuoHmh57lXSRhblCAcpORCSeDslyfI",
	"/1Dqo80a1Qhg6Dn7yC+GEiI1mIlMqry0bCcknwmczBENOYKAsDKi7OBkDRgd0nLguIOGeidKYwM/u7ci",
	"NkCmIl90dOjtiatawGT9UHcm7QiUfvJGpiUc/khNDkWQKY0OvdERSBEERPjZceMRqGzquxNyDkIpYCaj",
	"Q4YpqXQCgBCEXF+r+jrTtx4Un57YBgA0vKabgZI9aLSWrBcAln868fhIsCO1bavclUat9ocRhRfDFTBQ",
	"z8M4UmnyjC8azYWd7bKpsLT7uGYD9XVjEkrcer5OTJA4fg5gbymAidFEB+pF38vlrBC54K51ZWWwi0kT",
	"xKgUhNS6yBNsgo8k8EQ2x19F3GnaPB9T2Gnw/nD0u6x+fLuscRq7AwWyj5dtIuGlLdPA8rV8HAy1gShb",
	"iB8MrF9cXknisf3epBVYWC+rtMgK+ICJLnFUFdbuwa0lFfjVu+9ueKdx5Z9qIFGDMkw5oYFnla8X8WlU",
	"r2MCcx5fZgBnjpye8KcrvSTKWwkmeQe8coSaQIQr92YDpQAd636l7aBOdeGpHluizGsA/DmDPGmEXS+B",
	"HVKee0gp89KtAMkG8EwETSDm7qxWAm52incD+ZxCskKlKvXeE0OeGoB2OYXws0pr7+bj9tJrRkwLm4S5",
	"vsSdeUx2GffzK3HM+hCIaS4dLdQIoW21li74S7MXf1OSdx5ilBDFQ0Yxg4H46BECo/v68UdHyTC1ZRNd",
	"qvTX5Xh+bRzDSCDPCyTJ3H0QJwSKABwDON50qN3BbLKdzfwOU7mueZQBfp1h3Cd91RMEnUFvZ11Eaenw",
	"W5+Bq7Y/7VTNh4YAV8EtiWyssJZdSu9guqjvrvt1I7R9ltFvWBFzVEFGJ2D/vxib7iJfE77nJMyAbLio",
	"wGdzruQEHCvdxWILnlyjRzwN1c9noNw9gnkyZSV4U+teZ+9RKCnvHGAGY9bsGEN4IjNhFsaK+SE8JMTh",
	"3t5ezu1sz2raCoi7OZrzX7Ril88P2cg8P9zbG5fJtbA9xediubzrl3LiXvobBbodjUYD9cEP8X5voP77",
	"v/7f//6v//Pf//V/2AesPpTpfc8vjN+RPqQBZWyHfghrtVtrAdbn4L4XN9VoAg0qYatr9WEjewe9tnb6",
	"lhf9X4xdLv9s6/JY7tma8bnS/0Wl+/0+LdjSjYNr+1hSOS4x9vFrSeb1MXht2jJPIypbkZ6+um/aOguj",
	"33vJ04sl8XN9Fc9M8Qlw8mDhkQbe4Fwiw1S0+ClilkT3w8oSVmOXsAFTYdvRSJGL1JkN1as8In1QScU9",
	"/THtD9QFPXgDh+RjXRJeWY2fhpSjOCfPuboDFXKJotKdrBdksOi3ELkb+UuaXbcTYjQRSLbxDvMQvd5e",
	"CcFi6B6vCz/X/mOzvXpMlys+X2AFsuP0aCR7kBm9c4h3YMdnza4ixptnLU783nzw/fyI5xDX3+3EukPo",
	"EW8rWvJU+Rs+gDDo5RFvceTcu2C1fHJRKkb5nHUBsK1V2mN3crxWkaxR7lUYXlk/hLcOs8LgyyU01fX/",
	"BocpnsyqrJEALzOGdMu+DJwpdw9fhKfM3JvKQ9gDQ5vu0BalnfXJxGqHMvWJJ6GqSN2XXRCUCuGExC7L",
	"C5GAobXLVJpMu2xeFF025zl2enb2tsdN729lOhVt/eIPKE75hsm+23USqJ1NykwJY7qBtfu/ZpjzoAtB",
	"MHbRZTOR5VHpwj1E6Q+JPi3Dv5ccLf5LTOaEMm8/0l3qmv+VrlDsetUT7SSQyea788u81SrCbT7b/DOt",
	"gkwGdcHub+fhhOT8MS+nS8hQmmkl4gXw+o/Nr6W/h0iaVmZ0gkpE43mMN4U4ecAfd39Xg9UK3Xpqyc1J",
	"2YMr7F2S8YlPSDeUhajpV+wlfhRsPwwUY4MOdDboHLJB51Zey1ykkg86XfyxqShy5T4McO5YZ6zTxWGC",
	"gD/FoHNPFSGEyZU42B+oexKbMUduzeVg05AIvN6EEXmXhWhAWIpcmWQwUSailuo3tEBPSFfzrwN03hi6",
	"WQyD78mg83NzGs8a0/iu5h8OvtebppIjKK95wOJmPLc6Z1OwaVeL27oGMzmdxYkIqBbze7NqAWhYbbOP",
	"VYLLg8sLmYjDQbm//zx5tr+/z47evWJSDY3VyTVw02rEyCCoxwrmHZrAf0bHpGX5D17Ul/8n95QPnkmb",
	"Vr408fRpVnkhJvIOC1ihuLKHPJmLwwdsDxqRG1OF1OoGL7nWdcOM8oepAB7fcmReNGjt3SvEVQA/DJjr",
	"ayddlNm1V592wRhVmZG9VpUbRpVB9zE6Rp7Ru1rk4jA+HXt3PZW65Rv1KY4e/BEhLYNrGasPBmp06HUG",
	"1Qoj43Dr1kKZg87RKfxUUd1fBx0xH8Muh0m/uG80meoEtqxtG6L1HHRsaXUheQYLGdo72L9f9VZ/k+kx",
	"z/4XCfqPpheupIxup22l6821GI2+sBL5IrS+UoFciSNfXBghb5PfnUnqHBky42wKZMf8A3ODGFHw6UOE",
	"CIg4QVc7Tj79iyr3EMbHlcbrAiqNQnA6LfrsKkIAY9IbTkUKfnjLdtWdy8uTXQq551kPvHXJ5XzZV++C",
	"Tx/zwF0cvfmVhHro+XPbqvWEzXlxnepbFTYz5ECGCBzgzgB/4OQcs43V+eLoDVFLu8dcoJqGyxyZpqWN",
	"XKT8acTAzC/NC9xMfr+cwI1+J+gAekchCOlN8Jbb3ZpLiJBvf4XuAwsY/6QAE1Awc5COBZHxqK2GApQj",
	"spsNugss9FanlQuVe2YN5WQIqYrM6JAdjXUBeYy4WjBMdkvps3hWCJ4uMKuRqUC60OvpWua1di6vZY5F",
	"g1HQ60FwGMTe0KtJ34gCYlhGh+xVodfXhIXA6XtjkP9JOrlpoZJZoZUuDeth9G4wgdtCTqcY/F1VIid8",
	"tAR5byQ5n7vXlBXZAtkrT2xJ0ahUkxydwFsIfdXtTAxUIRKtEplJ/D3TOndsmF6DvBCYkUSkbXpa2qTH",
	"tUZQJw9iu88ebRCrVaGeYmnXfkcGCT/yyjm0dobH3uS0UT2KD46VBglvSgAMCcprPBM8A1+2lGFtb9Ql",
	"dhKpJsi/hHpflraFvcT+H986RR21uVwRw6PJBD1qCzEcPP5l8oPipZ3pAmBkeg2Q5aBV+2KE9kbYcCMY",
	"v1cbqYosYhVVLRuLrrzRbK2tyDvHInWPMV0+w+d5lSIuL3Q6bKZ/g48rTDfYQCc21Mz53ZlQU7cGz168",
	"aEHv3ji0QkzFnY8iqgb3v2Eg/afDm7/u9/7887/8oTnQ/10aUQz7T1eNFRtcNdgX+/vdz25l2i6ViJu5",
	"P1ZLaUSWAzNYRpYnoo7fvLkpCDsRycOHVQS/hz4D7/hc3CMvzYQVy/TvJBBYvWW+93ULgBbCrRY6z39H",
	"NxRIWeS1t379uu1M4o2wK9bo890NNRJe5fuVCstlZiKPs/Ur907b1+gq9kA+a2vdbViztWzzXQSr7XcA",
	"eAuldiPWEqh1rQl7E2f8ubvR+UuJW5odPBh9dJdH3UrFRCqJXvXBiYsi9SsXLm/N+MEIdsyNN2RcAlAb",
	"NT/RBStV5BjrxOlWFbAq50OUUkCHXNeqXlVjnWxjJ6k39tyr4tFTFZS8ijH3yYfVDokCox9ZZdGofW1t",
	"yf/g9gI1x4gDRArqqkCFv7VUG9T9acvnesO4z42GsVAAJQCvedLgE0baoPNzvcJ9t9k5mFc+e/9ur9Bs",
	"sP1IxjpdPNJAmn3Hf943Nis0Q544Pal6PMtiaxTODMcbNR2apX/4lgceHXJYzSMQmStyv2z3CcRKsQ0y",
	"vWuQadVWHBqPDdIQ7lceKA/tFFCOtj9YL2iwNXuQG4bPaZlwyzNNEYeNAObKSvjgY0lmsC93LL3d7Vc9",
	"nmiK+w2czsZ2f4FD2l3eEDBGbugcQQK375xAJD8nk6jsp3Wj6cexikD4m1kF2fbWMQsCzIjWh4y/+HNt",
	"wFERDwqxdPw8lCydNIAfqy3+AGHGqfcs682lktm8UaYsqMTM2vxwbw9SD820sYcHB18//9qztWrBlvjb",
	"V1+xl8JYdg6hwwlKJj32CqKEA7SoLlgC6kWwdzOrAxxDZJkH1G5IKIzSh7j1+GCEUzoH1HVuuRHWsJ2D",
	"3nNQkDqhaC64kmo6KendAo9lU38mk5NBZPiuOVJAW8daGYDo5YgFNdY1OSjC5yNSgJHVUPHa4hNBGqxE",
	"+kfQPlY9/EoWH5zdypcExhLU33AUGJplQdgFjFBY14963z0kJg7GE8vnH/PSjYNAHvQocUcgaCo/+nmy",
	"5jnS5of/mAT4EV74D9MoNhCYw7pHjsyVGb4tA10TNHSViz6ZLBg8y/hnctV/4Ov5C/v2Lx0Ax2SXzWqt",
	"9G8RDf6B5D8JfsChly90EGwy+6mQ9vHOgU1mj3gMtuh7XRBKbcXbHVd+/2TtTcpIYFIZUVi0zaBW0iCQ",
	"7kcTvb+i1un4T6nMl9BGQ18fo42OZZhKX/ab3degmo7HvbyP8OuvpzNc4kXrqWjvA/xjK8U5bHSnnYM0",
	"/TJScfc7VZwrwqkjg+5W27tKjb5ixT6f2Fs7e23+MbAPH61G/4KmTlkb6m/2OHXX9SZpu1t6C6fs8wgS",
	"+H6oyOvzSxLQtk+ktLUg0UZ+PE1/R0zgKE0rHgBgH1twgBU8NtP6o55njySLNhwdE64MuxYLcBbhkZXI",
	"/akqU9G1WLCCq6lgsReVnYk542aglLjNpBK9VFCCHHRU3EEX911CFQDXyACMxbEMPoagz4Fys3ddVbhd",
	"iLWOiflEWgGjEgwKu6IE1hX0yUBJ67FMPDycu7Gbs4xc6NzCw89+5jjXNg8ut2Lfi4V5pBPnm4/E94dp",
	"TNp92Bu01rpbXQxRhk2SbdvDOOqNBx1c/W1cW91cELqD7cRey0QY/1Ayv9u7lWepOkEfI+4jE9n7cC0W",
	"96tlfij0vVhscus51vM57xnKoZAGWTxSjaJyeyn79ECtzkfpCjrOHs5o3+N3I24IWYqxk0NvgOyiv9Wg",
	"44q8E8aNBxB3fXRQn6dpIYzpJ9IusJhPjQVlhuh+3X+Kv534GB/4sRd+7cdRVDAcNwMIb/fjqUqY7pDc",
	"74XpUhOuVs1xKB5+NyBTwNa2uxKF7FaPF5/+gDw6bf6YiS7SCmjnH+Zg4sGgMyi3e3f/puTL70UUMgKb",
	"ZDUjwaK132ux+CwPxLkoMB3mb1F2IUdw+QsKJddC5B4qQyrMW4LQgj71ATh3U/4DlslrwS5nOpeTRXeg",
	"zrWx00KYLrt8DhABXC3qiRSoZp8dZUaza6VvFePmkFoNg0HYy4HyeY3gp67jqJjWlmf0RfQSPZ+LIsEi",
	"4F/zUtsZ9UPKImOlQk0ZRPyNhR/UeIEBQ27tr8Wiz0jl5BhxIUTvli8YbB8w31PSQCEmZpQXAjsDGxYl",
	"pUhm7pYK6SPQlIY6K1pd3wAfGxDFqnZYzqfCYyn5xBSUWeE0FfNcW0p78k7jDgGWIhsLeyuEguqmzy75",
	"RGA+U/ClHyh8h6sFFGBygkjBRZmjn73rL/glQVYM1zQZ3NzahSRTtWU/Oj81bMfTAPtJ62P6aZc2kGX8",
	"WjBxB7cYkMUtL8RMAwQvup5a7ZdloguW6dtexjF9Ts0kR6P86eji3em7N7gCFpOTomlSeQdv2DQKJ9I3",
	"osgw/S8KD6Y/UJeQ1KiXENapm+rR+SnTKlu0Y8MowQtIGPJIQmvUw69k+auNYBWOA/z8eeGPfqOCaMQZ",
	"gYpbM8BElB8zv12KRuTwEuAF0uPHCK0V3sKD7ZJecnp8awzEPj6mVfL/VxHHv/+zg5PjVX76pqi4It6v",
	"hf59oPDDzZIhIPSLCFJRzHIViQrmqfoi/NZimRl8xMdnhaQQwmGXQ53RN+Wf8c7/jHd+pHjnj2Vpv6cA",
	"6ZXs4eN4ZBQm/WApIYQFK6u/iLBAcZ+PKS48fvBu3Ysp2oBIteUjcj/Oi+miHnn9Ow7w9VrcKCb9YyTh",
	"aPF/VT1K2ULT+OzH7JePRNMY54VFfysuoZTus6TU7P+wb0Hc3iUA/82epuCgvC4yHcK0DbwTCdI0yyC5",
	"QAg8R9TYPrvA7TaMp3OpWC4KgCnUqt8KZPsD9Py5vJbq7M6ND49RzO/+pmcq1WIbbrfZt+kykFLkWPhr",
	"xK9jp88fv9PXuhjLNBWK9XyI/PJef3lxB48M+wQnr5Io0R8VR5nx8dhDQtpwQsifJbi4kaIvW8TwAiKF",
	"3vptKA3HWAF6/8RjUT8N1e6YrT39zms7Wj8M3U8/X7/x8/Q7oWDAjSB98jKRraPoD+4/LZ6A9RF6g0D0",
	"BminXizYTrlft6bkKchD9leC2H3JU3ZRx9T1NM2kCQggXy4DCizJr5gA5aNpELee8RUk130I29xIZ28E",
	"sMeXiyAXP5JACaN/EJf6J9H+zhgnJchqOqEGum284dpGWhUBgnFEec7t7Nx/7mwL2wBjCdmdp/JGqGpr",
	"MW++Mbe6SPvsh7DjCjxomOXXwgD6vEiFSkR/RVBg4M6PFRPoOqgpNFqIBYLzwFQbFv7LRa2sOtTVyH5D",
	"15Ek3SMkPa0O+p6nBDaXZs5tMqPj/ufHH+WxVpNMJjXm0wAU3P0dMYFaYOb2AlPYgRZFz8czibItcyEZ",
	"QCAXvN/2re5JrOm6O/eDfZyTjx35Ttac/nfitprD9of/8xES3dxvMRNs2xD9LDZpi744K1Dx2kHGvuji",
	"/+et/1AlGbCtvDoXW535+hN61YPpQsz1Tf3BVNVkRel1zCgtV0klCkGOVeHCd+/lFhRnaL96m78u9Jzu",
	"9bUq56sZNV1ZcbE/r6yIRmk1G7sSrqe0v8LJ1TewVjddaQZ0kYrCDIMBaZMnpBuvK/TZx3vlel435g1G",
	"m6qRNi/elqfuebT9OMTfDFvxSWTQ1FfRTyV7xKv2G2I5TBfsQscJQwNdoOgcqPP3w5vwZMd0HbL4Riwq",
	"0spt8bTmWRY1+LAn9nnE8L5EZPE6feM/n+H/6M/wvEZtK6j9cR/kR2nqX+P1y2XjiTlK02qkV/oR39nx",
	"IWmRX6the6WaG36aftFH9hZydjXOtfGiv5Un9z9P9MNCauvHZ90Nhi27rtqE1rdcKnB5xyKdbqcsss5h",
	"Z4/ncu/mAM4yNfthyXdVJtdMKlvFBsBQvM8iufIfnZ96vNNjdLM/k+MC4sHcZypFCGiG8dLqXpXy//LV",
	"9xRd4Zp8nwsFgyVmARtziBhlT5++0U+fHrLRVNpZOe4nek7pT9Mx/cOnQ51q+tcIKzrR6xJmBg38a6Na",
	"z5oR21H5fBeLny/sTCsoSgVy+DJiO+eL81PIu32UZTh2XqCU3YP4BAyuyW09qgZW6/w0hNgmOhVsGhJl",
	"wPK9dnJFkcykFQnmNtc3oriR4rbLJoLbskB/fF5IoxWhzpZGsIQbwaalTDHLpRGYUOKvc7fzPr4Q+vl5",
	"Z2Ztbg73aN59qfdSnZhdiIQgIX8qrJVqOqTMDJ1u566XSpNnHO0FcOFAwPBlXEInhk96wAnwfffXzk8z",
	"mczcIjEz02WWslMYrxOg5iFO+X92up3v9C1LNTutmd9qK+dK/TQTbgm4YqdsIgFyNxWMnkfmf7rbbYn4",
	"tZIW4pNShk4bbKHLwlMugcI/McuJAiqKRkD576CAz7HhYeapWsipEYi88r/dkHfgECkOG1o4knOEpXRa",
	"z04Q7kqeYYVUTAueihQCeLTrBwuWKko9W1aA+JNSJXH9UkVdHhfSrTnm6C9hgJOJSDCJLDYnMc+pqwou",
	"kVCNEj/fylSEqrRutPJSTfHw4vqxZCaS67Beh2z05uSK7eFQfoHDel7oubAzURqf39WXoj9HkPpWF5Z9",
	"/Wx/37X+gwGKNyI0THG51i2Sp6R5GBH52uAC80wUMFGpJgUPcMz9+Ei0JA9YPhWeUt42CrUcjEDvuBxy",
	"4s6D3ynpqXGBRM+tK+vOQSon4Dkc8logbQkDcIq1g1TNnUgdlqBa2/bTgickpNhuOyt9htkQkJKxhOcx",
	"RLEYx1zl+yDgHH+i0JnM/YH/MoipjUwrrH9Q38DRgcAcPyAaH95DT5+C1zM29fQpeT2Xxuq5H7m4s0KB",
	"VNwfqJ9mMhMBLqFLeN4QwkPgl+EMG3EjHBseCyUmEgKzq9sEwu4snJ4TZeDMwCATrYw0GNNGOVHD8mDt",
	"97mVc0iZAWgfUk1dI6/LLGNX4s7iVwbbCsobqTBjIrxmHS/L80LnhXSb+zITN4LNMeiN2n8prCOjS4ik",
	"c0274fb4LS9oK4DYEc7T+MyfIUsy2snqIJ9Pn2KgB40choITp6g+uP28eE8+z8HTk7Y92iZ26Xc5kg9g",
	"wgay1hZprXS8pdVewm40MZjXgCO3I5avAEbeAIu8FhR5NVj4FuC/HwlF3ATeXQES/vEDmNl5tqFPJ0Ru",
	"6BM0ES1dgm6DMowuj/B+uyFutzIee2DDSFuxsDeiYQOVEUTDqsmsg0+OkI9r1NaGVOCanfDMiFrJj4Vl",
	"v1+Nh/5qofhcJhG3YjujthGNMOH6aMN4R6zH3iuIOwfUMMTRwDvAvRrZqFrjEdspBIQgK/fEdewv4k27",
	"G7pzj3TXG6EqZVnoDKcEcDk7k0zcSS8umUzfigIaXgbvoGoRFzUslcYxwZRS3CImx3ugHvP06aHHOx61",
	"EdcIWZvCSrVpA35yPTVEhPmBDbibRT1xL42ZKKRloxWbP8LnVc6d6OBaOXLHEO5VauhweYx0VEc+Ze6K",
	"MxrOCev3+/ceYZpY+klg1vj9q2iIcHJHAwVjcUOhOnDl4WExtPYLt9QzfYsyHWwlbmSfvQ05xUBSQO+D",
	"SvKAUuF6DPc3xoRDHXjjrcdbdxTk/UzC/QTo0ggIDk3WB7K51Torj7sYQatOphyxHVd4F67k6vNwSBXp",
	"bfsTJhBw13iPm95Cl73tZtat8iZwM1zoktDUHzqcZ9OCz33yBLd9x3o+9kAMF2Um/EEYufojrO8ulBG8",
	"neelLeEkUsbpG8F2kpnWRjCtBOOG5YWEEDc3vF18I1QfDNvBdrvU6C48EcfwWB4DT8FcDryQHIIkR379",
	"umy0PP8RJXFc/oH9CwtVHTfRt9S2Lm1tjGwHdBw8TQ3NeXf5AAAljwbqpdaZ4KBZIV5S8Rc0NcBSH9aE",
	"nbZ7vM79U3EXOG6M/v7VajbhBfKeEyozxv3JxFOEAO3LcEeGoIFGQ2Q1UBhQGpzw28O/KW3GssD2wPuq",
	"LVmAnx3cKW61e2gQbiWOLtuw+102yqS6Hu0ylJdhVCkqWzT0MBNhs3FyO+6aGFXHkunC/YnHItDdbr/O",
	"HK/gPNKegOBPX8I56cGjIE7oU2UmsfpaePwUfMYqni2MNODahoRDSPnujRNWDFKsh6ZID9qHTvFEruv0",
	"u6u3Z8zyKfBn4KlVb/Bbrb2wHD12cscT2wM/q8DbYdVg1L+IdLdq6PSV6bpOTJcl3IqpxsTwmO3e9Fce",
	"zh47SaeCqZ5bdt9wgStRWu2RLPotnC3sFd0U2AmQAeuxHy7O9ty//W7TvEIXfmO/Yu8wRwbshz/W1aZS",
	"Bg3X5DtIvmHYDjzT3b9clUmmuaOTsBSJLpU1XQYZPdzOJboQtARjbN+1dlWUYg8OOrvhWRle2l+xV9yK",
	"vSs5F9EwUm6FlXNYMfeTsXyeB4TA0DX68e15Jx5woeoyiJGu2n8jtMm5dce/6mAqNOhgXAdn3EpbpmIv",
	"02oK/2LwW9VRplHH67Zb6yJ194af41RoM+O4ucewf3dsKvS04PlMJgx+q1oa69LdzUAthZjSex8H6vHL",
	"qlEG+DLX+I+YIqKCNEPqRMUFyKTw0I62ZiklEO1KpseuwZdSOf4AGoG4qagFOedTImz3nzHWqE4Q8Aq4",
	"Tk8VxYu7j6eTJSHKiaENSRV5H3KwiSicCAkyYPysHsG58SL78oUyYv/9f/8/bBQJQktFfRIZZHmDDpFz",
	"XLfKG7NcnWg4Lh4+/RxkydLqObcyYa+BRiOVAfc/gfgA1y2qAStsPh5B7JGCx6tcR0PryX/khKVXdDCi",
	"KyzUDCWNrxsg76AuCvyeQ8x5HtC6q3vTB+qjEOWaPzqN7CChQZo3zJa9wyD/Y63cyfOi9E8zoaJ8umGz",
	"IwrwWjvvIB2eSA2hmPJPlZOJvBN+ac7j+w3ee3gjuV1GGQteDIbpQk5l1Shk9IEWvicmSbcfCKMrJdjL",
	"duG1VcQ8QXX/g+TrNYIurQ+Jp07cIDG3Yu/VT9EVv3wLxMXoOtkRLTfS7posPPAKw6UGJrN0U0fiC5QQ",
	"7mJlcLGCpr1HsrcnClcmvG9BMSfV9DA61M13iCCVXkseHezL58zpsaM0bb+Jm1duZHsgGwLME+UNkJeb",
	"AgQcFydjgCDA0rJABT2KxQGQcrJY9+YFHpvrwnJVE2UmgY189ZXHgQPNp88lVKkt254sxFtm/EawmZzO",
	"RFHJ64k2lqUl4C1URGSkqQtE1IQ7sRMOOv/wsh2Xll71Xo2eOzmOZ7jJdHm1rTqwv5jgwqj0jShmgqfN",
	"ew8mhTdWNKI6U4U3WeqvD5hTvA2N93fuBC7gBIDgxw29ZZjxuINhUI6j0h688lz26uqM7TiZpHele2fy",
	"RuxGzJ7Ww1QDZOIul0UlAoM7qftDT2KTxMQtMI8AdtIqSeerqtjS1L2j4XhBWcqnBTjJJe6CKnP2Nz1m",
	"RanAeKDxLXTBJ5ZlgqeiCKIHmPnZcZwd1P3kPwiY9a1j6BjVAaYIBFJAC8fI2mzoxzxqVXv79HeOzaH/",
	"T8ggGFfGIs++rvILrtWXU1uPry+HpNI+f+BGBfCgU+lvW7q9X5M+rkW7+Z2+ZdKyW11cG0jr2GMVUQCB",
	"CSKhOkqTX9PguiCLSkogHmdYLGPQyRgvGCWvQzVBTYARKeOWMqBIreBSeblMekWpjJPFiwV7vs+MSLRK",
	"TQsRIsavm0ManwhI7OaeU/5cu5tBCsPkfC5Sya3IFmxnLCa6EL7P3QBtiWhChcB0LSJlOwf7+/tx+9ZR",
	"sJwLVBVNdXB7gKElWhmhTBkev8do2nHn4MJDI6H444273Jt/bP3B4lbKCp66Ex8v9YZDgq+YNUfkj2nt",
	"xyjxH72Lhtxud4agq8c/QfGwVhwid9OjIZFSGHIrwENh+XzBoENqxU1mjLqpwnt5kTQWD2wbYwOhXwAh",
	"0XGMyINEV8J2zQsBkKpS1cR8gxcTlpGKXbw+fv78+Z8ZTt57qY2e7T970ds/6O0fXB08O9zfP9zf/w/U",
	"/VXn3yv3AK0b+r6VGXpJMHByC+wcXtueJbzGZVYD5QbtSQtg99kbHbEOKIey5/N94x6O1XGGry/m7uML",
	"NpeqtHT5P/t65j4++5rNdFngtz+CmuWPLOULw3YsBeFxww6++dMMRVP3L1fogN0Kce3H3ExQjSw/8mFo",
	"TXW7fGIOZqtOTMaNHXJwTXRUUW039RW47AHMh5jtqFZt1CfAXUT7CUxAK4Thx3JOigL7cIq8GtsnLNkr",
	"4WRB96g55iAsbzkxuC2rQbvKggllgV/SyP1W0NgD+6auz/SUXWj0wNqy1+f7taU609M2CcXH/mO3z/dh",
	"+4PgURNtZ9y9NEQhjZUJbXbliHBpdcGngg6cI9rqwYuOHinzCPjuahgd2hG9GQHDH5+z73cOdgloG6jy",
	"nUZ9QyqMKCTPvLpSCZHiDQoyM91pJuEKqv3nwf5+z10pd0E6nnEFv4OsVYPNZ2OdSjwYb6WSc44uVnwq",
	"gtjLdv7z+T4bLywJqL7qLq4Cuja8hvvQk0WPkYnoWixoRo64yHmpkjp3/nMuk0LTid2lSct57l5KWpEr",
	"BEEcQ7MJJxjkucwyoP5YWMURHdOKvBQzfiN1QUO6aL30d0Le+XGGxpEzuPp7oKyuUsft5AVeeywt0eNV",
	"gNADVV70sDk2LXgC4RNSp0yQX8ttIS0pGDANaCGohRTlExQD0iAcBIHA7DLqFnbjdiayeQC8BB8sT6x1",
	"dzFHgZUDCfSc6enUm3I8yXj/MDolp+9ev2folOg6cY3Esnp8yr599nVoZgjw2Dc8+/b5vvGtwB6IlJU5",
	"HfJYgAK97LdfP2NRcy/mblstz4ZU/tuD58//WDO8vNUpGTPd0JZeBE+fHmEOWzh/GkOBYbXc1hIREBs0",
	"kWdM/X1QGSWP8jyT4IpoC80TK2/c2W3oxEz9wqvCkHHOYJ/jxTXZ3oN8GDbb39pzfUND9wdI2ObI3Jzm",
	"uV2QCQDGmGXxeSIMPHDRsxq5yHkhbqQuTbZo2YlCzLmkQRzPuJq6qr7H1UumxG1jcGhcv63uZk6rF4vE",
	"bWt3Uo2+EAnPkjIj6Bg3lGoPIwUiUsOZnHtsTm+XPs50ct1Exw9+80+fopn+3dU56EcWKmGJq2G8o5n3",
	"IATvUd8kHgDiQeC1tbSK/h6h9Cv/WWMv1IA/JOQhDU6AZChMYkoGh7Ors7B+zTXzZkMgamqrEupBIHJN",
	"ePnNC2+68P98x5WOfTOXENmWPTMxo/EWfpmvNDuF6wmsseiVGPwC6T1Et7ujMz+nugtz6s2dLOE5Os76",
	"hcBZe7fOJ6bm1ZlUyP5B5+a1jKBeafXZ9GijYGqIeCaqwyAldpxVc48yanZrgOWYZGGgELTR44x2vcZG",
	"3si0pLxWdL97AwVmKH1fc/Y7mUxkIhG0C7t124cdV1rrGkXw/4+8b21uHDfW/isob1KRHFGSLzPZo9TW",
	"OR7bM+usb7E8m5w62rJgEZa4pgguCdmjnfL7299CXwDwItszc5Iv58vuWCRBAmh0NxrdzyNKNLhU74PI",
	"x/Dlk8xlV1s3LzcUnGSaUI6236t1BMdfIpdJUXYr/KEdd5gN7gp//VFiVdHtygr/dSGzUs5cLxplC0Yv",
	"kxmdakOyNRpGYYIHHRy8O8vSBR5HT7LdKF/IEtISlokRnd3LQ2setdEznfYFxPRlnWRXlLnMSj9qmOXN",
	"4f1JVo/WETh1YqzzL0UcdDD4zv6G2MdOX5xRfhzj38oUTuhUKX48PQxcb8j0VSmkIQWdxQ+cZLt9cRj8",
	"Si5E8AnEi9HD+OYsySE3A0c0gSBwOcn2+uIAw3dAImoQbHk1mykV9yqvxUGtvGGS7ffFZdi6tWaZNhjA",
	"kaxn0bYgQq5OH4LXv+mLKzXT4HKlWufOI8JG6ODSkSTA6Sg54+G3UWY8jvl7rOTgze32tjvfYqIPOqo8",
	"uDxxql9E4lerEFeY6E5CwuuC2gH55AIC9tnQMEDlAdYHkPTpQshbXRhh9FyZBYaKrCGH7lotBQn+zV7g",
	"KC5kFqcqFg+JhIl0Q0Rmx6kA28r/2x0uS7ZAQWoILiJTW3fb28HGpeKN0wMYdipHQJWyNxNvfOMQLtjQ",
	"du07kOcFDhtg3lfgMXCbgQV81EVpIqix6TS6S3uIDytZyMwoN63BFJC4wohz7KCDyiQx6y6e2TSGGUtg",
	"3WSIjnVZMKgH+N3LuhRiyqJjjQk6JTre468KLhwZyjvVrZHChI4TkKko9GkclQ1KFUlUCGOTF/ouSZX4",
	"s/X7GeW8604KIkP5Tai6zUIajObwIIXS+G6V3tMJDpcDg25N00gXUaatrzIXpVrKjPe04FaBWUP6ks6R",
	"1WTjdTaDLv5fIEGi7nwD/1HSZD/qORaBGt9Rz1nYzTRHzxgb3HvXuFZwCnI55xTCju/EvbIrZrcvxsra",
	"H/wdaI6Mrno0XjlaI0KDAmRBI7HKsYccQGx05hnqJuRs2reWIVfSgDrLrLsGXxGJrELV5BR4hbOpbbnR",
	"wTvJ1OBsPf77KZyCj49Pjw+vxbZ4f3VxxjRNpbi4Ojq+Eu/+WySxOD05O7kWsOm+eP9+fHwthtNJJkTU",
	"oHY6elejYKrQLuEzV6uMIgCcIb3QqyJdD2KZpOsuns1Kt2JcUi0uDGu34LuhZAtwbaHSdHe4ux8Ndwbc",
	"gf6vpc7+ExBNfkhiZL0Cgs0fdt9Uvj4Q+pk0MtVzLggpSl0EcoLPUN9u1UwvXXkLaB16Mx5Buq/eE6Aj",
	"TuW9wlK6whGyQmaO6EztuhwMh8Md+OZpT7hfdvmXfr/fxfejQ4xqCyUGVrtnwiJ+LLz7kkDf8VVJJmBA",
	"eqJUUN5IHg+I1u3a8YXZD7dffVsks/uyRUpilRqJODFeUKz37iWlMsa1T6yTdeGdWO1TIe2ifY61UsHj",
	"mKxuRfwdV06xs+N4zsjZwUkEchIIrlHxXsRkZqLCZYZtVKnRPPtZVKyyGttZizMyRqoOX0jbs0u2kFls",
	"X4RxZAxQ/rs4yGgfNQPWxSwWBKcPh8SYz47bMpiQB1kkelW6IKe9pDIqI51aMRoNBoNcmsXA6AE+CIl4",
	"Gso7rZhR3C0S03JvNBjcrmb3ysAj9saDpfxdZ2K8Z9/PyP7BvrJQt6skjVlGAqx/UWYyLxfa5QeKn6zE",
	"cTx4kh0lhZqZYKNGe0kirAG8Fcrz4B2n3ySiBUsKscqS31ZoxcIwQJ1eoBkFgHV+Ubtjc3Hmhq0TOIT3",
	"dqni2qjs/Uu3mGBcWJtb8Sb1+PLev7YBxNTQ0LRV3njr5aao0jC0RguIvcgd+JInV6movKvl//bEA6ZH",
	"NnIee5PMmxAoS5TWM6fEe4g9WO8EFsaVmiV5AVJ4JbN78R54Z0Xn6uq9246jO1BJjIZkZMiOHpOJgnN1",
	"rHskWpx1ZuQnrA3Sj6q4W6Ui+Pwkm8PigAPlapViYp2B6a2O1yOrD1ZGFRAI5NxdnARd2LsOzo+s5r+4",
	"sv89v7iGG6+A5Ns3tVayGMEWQu0Od4dYz7worE/nb5psYSZVDhcmWy4+PCZX1nX1XCIOQCqz+Ur6N9FE",
	"NaYFmYPhYT+3PmXBpf5wRS50gTih2I8Gi09NViOdzE/sgxG+waWOVeom7UeUCPwSnOJJRolpZS2rjN/L",
	"tgS71i4tLfUDtrEb29gNuTB4YA2SwUmmwfTyWfdki98bPIcVotZWSIw2pGkyh7xbPtrkcQuqE25s+zeZ",
	"3c5VqhEoh5NOlaCrjm0ZVesdckEhERj6vCy+d+40yq0D+EVcFuou+US1DkjnFejIx4UuFZJqo/UkInIn",
	"9Bh4r5WS4Mtucmx6i6mkR3DID31hGYEjJWgetkJ0387uHmYXwF/7b95OtmpfDet6kh3keboWsrJ4pdVv",
	"4uD8yBpUTFFt/zw3o9XZpRKB9cio2SLTqZ6vobXaSpxsPXFn/GEH7JGwKAH0lFXIgJlBn5bFNBH4gztY",
	"dfPIHTvGJLlgJjgjs9bbzvnFte9ot9ZTxe2+2NlY5YVCiPqLK0IBGIGye1Bx0NdaNMV6MIojRFRQgcfK",
	"EKyPOcRdzrQT2kJm90k271HFeIB059tl/X118EF0CDhNptHBam5HQ8Xig0M66WIOb80KZTGDoSifB02q",
	"4PT0jCjRG/qn4FdxS3Abce7xynqGKS/UfzXitkRVOdtm/qzG5dj6d4C19/nYYE1dtU/5qApxMIfay0l2",
	"4vSKYTo2vYIoCy5Wl9yIFz1GDIzBYSrL0mrz0g9eKUBISswesL4GZzsjdzsNvnVDcoMn5KhqW52AcEx8",
	"crqEXpSiY62s85a6IsyRPzmi6yVZoG44HTP6cow99fhko+zxZ/TYibEjSoN34mSObMkVwxS0RegZrwFU",
	"gXUSsVwNkQ480IF9gfhtBcnITr/u9OtWixOpvQfyZ2ehu5iWBlpjWjdBlFhbMzBTF9vqiysWzUKhS0fH",
	"hVbTbvaSAKJTprCQ+VzI65mKKXUegdNZu/attJa9JsY4rMpmOlYFGnHaS0GpkZNvh7AKQhm5KXeoEX37",
	"6bZ51ihL8ERns1WBWTsya3gLQb11T5Sag9tLYdUhHURHLk+RP4WijUbn4g2kiaD3WPcLWs37HIspUpnD",
	"4TJbdQg72Dt2hkP6qaDOVHL5SNAKStJLU7mULklvsgW9otw6lc1nUg/+/qiyvYhHJhr2374bvd95GzwU",
	"JEpV6hobqXF2EvdYdMRlscpgJsnC6pWBjTmJtZ+4tYiVISQfnNO5zGFDUhKI0zLJkuVqCYHAcqHTuB1Z",
	"o3VAl5BKpUSqZJF5NAk7VKusNnrLJLuBL7gBfWavDftv/OjJT3R5LvObXBUzSpzcG/aHjdGIxLTW3nQk",
	"flIqRx+Fu+8MGSTElkb884+OMk7ndBu21vb66UiM7X2QnY3FdyIudI7SDUL9zz+6jRvktc5WJnlQVTX2",
	"ndjvU0B6bOx6mIOpOsQa54V+3OQSF4Ge4GJm3OgXxd1UdCiPuDvatLuKWGHEPQy8ikcFJ2liqUsDwGGY",
	"P1iUd1PbSirh88cgKa6RzNr5NPmdTPWjSuYLGl07IoxKlK4xCCGTVD+oYorpCr5vyV2gA7xhgyMPN1Rv",
	"OCrsfGfUtdPQD5xyDXrguUJ+SV4oUhk1XybwXyYZ6O3AfyHLwwg4t5T7Dzulgn43gXenZEGRm+3tShkP",
	"nplRAY63QtYosu2lOR1B/HvsvfRKIFZ0/Kj92ckDRr5Rd7P3ZrTIZFHoRwwnaEyH2cMyQ9ZikBnu5L2E",
	"8DU2g+sUdT4g5+qVSRNVlGFopUFQ2oytMD7Qi8GV52Mfz24NfdxDlbXhwgjD1XsQ8ioOVt360yS/HIex",
	"ziweqHgHrjWmwgQIHmKOtolYffX6aAo2Yb3IpY5lWq8FRRQTFx2pl8WYR+3q0rHoBpJGnIcT+CkPQ1fn",
	"HYRW8AWT7N3Z7hsqoa9/PLnksKXp+8pMiBkgfhOmytQhq6olh7RyDmtpQy15sS7tPPx2Z2TCqheoh0ri",
	"T+7iUi1vrC1wIAjVPPMLrIZnYAq+eyo6DA3WHYmTO4CQ6TFqHw6r1Z5qqYHXN12LzqpUsGfXhTAKsr26",
	"1aN+eokdV95OCZnOdZGYxXJzaEp0sJzQx6a6rcEp0WkGp7qN6JToNKJT3WZ4SnSa4amuq2bB2f1T2axA",
	"9pPMZY60kbCdMuULZXpNpAgntPI+y0heqUh77NcNCexBnhf6U7K0q/A+ypQsrE7OrJW6hfE5+On8vMtw",
	"Q+D6NBzlqoA/1OvB+829dG12f5RF/CgLFcnZTKW0bYqT0sDNnBgY5AiNT86OoH6lWM3czvLT928HB2dH",
	"I3Hw8z93Uf38/M/ozc4u2g86K0bNQh8ZAq1F4uDqbCTOjy/O4eHx2bHojGcypQQ4UySfPCpPV7hvhaCU",
	"lZh3ifm73RxlhtMPMTgfr2YqZrm/09rkBWRkZTEnafvC0HMtPlx+DJNXtMs0t60dXn4k/RKrPNXrIPW5",
	"pVjuBc1AAtKiFNzsVfRCnCyx9+Bbfr9PP+PNX+3wyzSNrCOdLoPrq4KuLozJR4NBav2zhS7NaGdnf2+/",
	"xcl39S8xFbuzfuLPm47EMf2zmnYJA8s+lZPgMlR2Mq016oZiOuLF5X4SnSpwAH+AdeIqWANdOnhSaTwd",
	"UdE6JPreuiTYv40vzi+lWXCknitwalueKfzE+Gx9sn78+x/6ABt+a3cOBNFj1DJPpVHTkfgR8pFupfWI",
	"6FfULFg7lBd6mZvA58TjL4z0/A7D+nNiuz0IzC9uh+FYwaclI2rDQK7iRA+scOiq/YAdAwMt1kwF2XE3",
	"gZckXq3mvCXIzuJYQtqVdVu8XFSlwRn9C5BZ0cHjvzPYd3eby+kZQX9ezF8l5CzflzpfpZLiDOVITH1z",
	"do4hhh5BjyLG7Fl+upUJ/ZbKYq7cXhiAok9e7EquMpm0dQWAgtzYRntRuQTcIbpT5snNvaK4a3kf9fv9",
	"sCtn3IX2Zqais/Nm723c7bXcgf0Qnb3hX3bb7pCxjIbDXdeGA1vRep4q8UHZIXup43O86+WOD4f7wa4d",
	"EJmpFHeytVxH9JOPlRBcC58TRHafXMh0p13B/uXt90HBV0W2cZGFkCu03cEl5lF1Dv4xFu9UXOjZ/Uu9",
	"vqXb2kQXzrX7JjEyC4QsevBfjqAxrmdKlibaaZ31zY1Zod14dddenemFKlQff1fZPE3KRfSw17gEg5Qm",
	"2XwlU3udcZX92J24QvxJRvqbdx4z6YopHNAM6CzcZIDiYl+nXfH5OjLAlxs7XSk61486Ghs5V12uzsU2",
	"fADRBfNhSqvwU2ahKBaIO6/gYmvgabOp/9ebcjDQfGDoRuArG05T+SBbjX6YGre9zbaIhrMzhQenXTeq",
	"ZWNYAT7H2ZVOqFi7DgIGXQKq88SlqGJ+F4o2eQbb22g3ILMI396jf0T5IgFZvZX3tSvwyN6UQY6teka0",
	"/txE+9reB/+KzKq49X9q+FB6CnUbPgX/jHb7w+guleUiUp9yeAh/3+m/sbqp9gvcSW0dZGZR6BxToqez",
	"VNpdx170Jip1likT7Q5393eGu7gm+arOVyVcGe7u/seU8ZRBqTAbADba39xg9LA7Gjo7dY4RtWDZdigd",
	"iJcQoLdTSJxBP2JMlWlVlN+ySnaGu1+wTCpG5LVm5CVD0pB/nPQ/lc0DAqvFcCTwmAeLfDk8hHrN1WhL",
	"V6FaUUcOddxJ/JmKE0k12h5NCZVhMOCkSnth3Z/MhEtrFlAXBi4eu2qPcu3jLSdLTPUEEZKlersv8KAl",
	"Fh1IEfp4ddIFobJ/jaA3g19zNf/rLdzdw1R0/AN37Zx6SDfn2evvfVS3+TM342d+vDrFbELy5RA1EQkj",
	"AC5xj/5BeWZOyA+saRGYxCl+Zq/4KxskhCd/sIjnsLYbbTtBxtqebF1SguflQhvtczbsgw7yoG2gk5/f",
	"XVw9Dn/6MNcHBwcH5+OPi+OP84Oay4d4bLS5iN7B/vUS9hUgRIhSkPyOAf0q2MZMZw8KZI9xgSg47SUe",
	"xa9lG/O/ZBQ3nTNxzT69rTKQI/H5Mwzv09Nkkh1y8oH4/JkTEeDCkW/PXguaf3pyL/jfNspVA8rTIsaQ",
	"3OjTTWHDaSWwObJ2vB0dysJd/rUEXpn5KonVgIodCTEASht5WlrK8WcS6qAxOzmoykZcIzqsGXk0B27d",
	"bnQ/mWrrhZopazcAeaJS8C5LDAx/MmHIBHtKHZ9+/uyw056epiNxglV4GGGD3Eu67buE4F2fnvr9/ufP",
	"g+QOHjjkHBWZilTPkxnfj3ALRSHX/IT9BV9i0OeDqyU/sMpSq7Vd0gs/hr/T1z2oAgrj3Evp6f8CJfz0",
	"ZFXE58//da/W7t93SVEa91cq4Y+RONU6R9A5zsHY3n63SlITJZn4UaW5KjjffqcvtrfLWbG6/dEs0+1t",
	"EQmiD0QBHpRmDdkc85Lwz0whZwbLxgkAutBLAC4DkZ1Op16O4JfPn137YmGW6Q0FNZ6e+AH4P7+4FFPU",
	"zfgBpJvxrIsu2E/i3wFwH58H2rVMPaaQloIlaLdQTaxSBFMRnbwn4uShJxY70eJtT6RJTygzw7x14ZM+",
	"8lQm1D1MSisUlALGolAydkQwcBa1va1+g4E75oNnn1fNWdI8peXGMbJC2FG/MVPOZAuL1Sdb3aenA/gn",
	"CWbtfisP1jHHgjm4nXE+QabDp0hV7NlvBsMNn/1BZT8lRsTaUIQIbTr6HHb5AVVR40RmY0/w8VWR/gBW",
	"5kga+fHqxH24v2wWSdmHe25WRdpyA8ZTrGoifiPQSvBE/9d8jjlejWfAnnLlC2d240N5tumhetJ48yU0",
	"eEKIcOfw8eoUoUSpggWkCH0OgECt+jzs8rgMjk1uT7/fn7JMOr9BDALHQUTiH+rWvr+sJ005/MB1rjjz",
	"AStDhE+Pb8uHF7b3vJrILxGRGO9FINEGABQ56b5DwD10Y33A79UaAb9hwDx+6SF93KULJ/px295GfxGA",
	"SPVjlmoJsNOFKiFu3knuqCyh26v6E25gXUuXR+9LtCafDGstLEAEpYnlJIXKYkiskRQhcI9bfWYfv4Ll",
	"ntIm3reDrsqZ/j1JU0l3OaWAMkI0d9DjQqdOPrhnaD3zQtsJwsounjmmyOP8FOv/oIojwPWFLo14XCRG",
	"pUlp6OJlkTxY23NyiWoPjLtDPBmPr94LaYyc3ZcsWvwpCE0IKUBlYKR3hsOzd417TbJUelW5cW/omoQZ",
	"DELojUZ3h/vf5596yIBHM8uCMlZqJNrZ2QaV2O53PEJRNKMI/z5oYlho11pnqJHhT0ecdH1xce4QsK71",
	"vcqiiyLB7EwCrz0niKLuRvXmXyFAgSFqpFMq7ZdFqrK5WZzJ4l4VPyBMtTXrmflh/6VHYwVjqIofJluT",
	"iWlVSNCz9wQc4ZMBt7f3htHb4R8RKR1PsPA4iWwUrp6/jS/OWcIONQL30DEFoS+O8IyyBi/AQgmwAthD",
	"BEqBYgFrmf/nu71fRkImPTrdX6Zs7K/lLcTBaTps66ss8SgOjveD33JROT47PT0TuSxKivwJIS5c+AzV",
	"VzjiU9G51TrtjgCv9TuByTKARgHfjhjjgZCaYqWc/sWJmgJQeXcEEUeiEhRlLmewzLx4u8fcvE1FB3PO",
	"u3w2RJt0jcjshoYCfUY4SxdTmusp31HyGuGdoV6ZfGVGFR8Kj8rFSY2skg+NXX2jQH6ekfibzJQ40qj3",
	"2iesIWsOnjCweCB/4wpdpVvHAVGl0TqLcMbh3/T0By1ObJ8cRWPrwzLN71V5n2SDucaHJ9k/XNyDN289",
	"PBPCszh080UCqHOxC6NAobJBCLOkCDbZSSkYpUvF/QoG9TGqfjuiYG75PI/JEPmNjjbYn2LVj/4Qsxib",
	"y+YEV49uNLHgeLButwq+cAccbHXdYWLbnre6Jd20Gd28D63tQV1XSUrdMauLUQDivs4JNcfhNE2xcoKO",
	"NoUj+SEwcTAWeaFylcWlmP6hP+UzWCpfZhakP/Rbzk6BfCFPk1lignmj+4HS53+Gv/Tx0HzqFFoSnCzY",
	"GfbGH6WKq8slVZT0GbmaDmTJ90fEfiiec/lAWOvpCsSqVD2edbNyts0j6gqlElAD4N8ccwjlK0XEDdW/",
	"PFBxro0ahafuds3pZWIwwZ6wJW/rkP2wpoOAPh8L7H2/78/IgvAyLFHGzOSwztcGkP7y9vvWCJELDH1T",
	"xOer48vNM8YvPKd57s3184QNydiX3s7gYYcYK7PKvz40/2bvbVM8ifbm9bIZHnh/yZF349D7D58vLo/P",
	"D05uDi5Pbn46/u+n1nFohbHf3qbcZu8LPyalSgF+7EfETHeXSpejieUCszUUBjgAcdp0DSgLDjDWKawO",
	"vK8uZNZCmRbm49Y0jUgyo4E3Ncnmd6uUckTKgM4L11OJKdtrhl8zjzoqDWwDvaiJP7sMmW4Aug/boh5h",
	"W9FTxB6COpkYdXE3+lCKw1SvAOiNEjeAhMKaC51bozjI7T5ntu6Jmb0xyAihNBWSyEE5k4yuRm5X6KBA",
	"HTwD6JPxfnTHsjGxoSIg1x1n9MgHncTicaFT5QtAKsCevmgH/RnbzkHIAzB2uX3XUJeDt1W4AgZNIrMq",
	"fcAIre1OXxxhBWWI69fExYdIQCvo6rOwzTSU/3rgZk5X+xcwhbYyXmyim3wFNPMuUyeFKf3WUWgd3qBU",
	"NgCU92m6lYHdlOi7+WP2uEzAmkci3CCitLavaS8Tps8KKiwzzzYySmXeovLA4W3jXwBpc3QrWZOKwbt0",
	"xLZCRwWOKqw7yRARCQGuHPNDkuUriPtbNxHZdvt2x8vU5z1AWc4nW+5J+NvoHAUhlbk1ARju5VJN5ZgY",
	"jgiuA5imFzLPVVaiOljrlUNDLPCB/2SAFQwOlPw7oroiyjsgqwmVFclsYVdYrw5TRxgSQSU6o0J6moW+",
	"+FEV6k/2S6RBONRczQx+mH8poiaJDrE8sPLK1COl4AGyCAGDVuIoXXdSe8BPnatHyrI3WhwzdOc1IlW6",
	"FL2Wnle7t2kcvOqyW3Hb3cryubW+RnZ5Mb4WA6zFHHyG/8MxzoBGavAZ/gG/vcLFqLgM/X6/uaaP3fe5",
	"ya90h86U3HBUjzaxd8iRVZ1ARlQN0IP9zR5UtY5YHORabkAshjpY5E1HbhE8NrDWnNj+80LPC1WWTlWc",
	"1S5UhxyQil474jR0p1rfC2nEFEDQbvAbiJPHDyi/D3Cn4U5fRF4UusBjSWZ6PAB58fPhchNaq6aqb4Ia",
	"ql59cQJTf4mozgDdPOIsY1Os6/jS72WSqjhotJ0UxRQJay71KdeZNfQyhYnXd3fPTKcHT6xNKCOBY9uI",
	"qut7ZjdoSebKqMxChYTzALmY3IlSLxUMAnbQw0lDtwLAxRbJ6UybElCf/acp+nUwohQ0Q3RiZtRnNGoY",
	"lVLVJ2dVKAHJW8FQ13GMQ7Sqh0TW7SwcArAOo8jx9vahXi51xt0U45nKZJHoyimn2yQD7tDHTD7IJEWQ",
	"R4pDBQNO01CbeKyBVMVDMlOMTFi6+HitH2zvOpyc47OXuq1VUdQQRBHsKriBGMkoFEaixPKgncGy6ID4",
	"M3poWGYIF7ruuPLKyhwgL8N5Pkdx3RENSTEVBJpi7ULDSA1FQWFIcmYf3fnGcPqNQX8O3BZ+H2NH/reV",
	"NuSqNtO63fkk5OKhggCKSGCaQC+gFx5XdF0HTgNw9KAeHzG7swdVmmQug5OwK5ri0uicTouX8pOQxu6m",
	"TH1aaVbRSDs2UJjWiq7a3n4v09QOIde5rkkI30ORTwKyBEseDoF6Ds/U14wyHjE9bwf3TqaoXuCPhuA8",
	"btSQMPetwcOXUWOoHMioYvkCZkzlTld8VszVDXeCPFvqYjWn6HqRlE4zOkCG9FGuS8Z34SpgVnVByrTV",
	"zyu/mp1xcVDo6M00oOavNQE5kmKpFw/Y3VWhcwwUs+FHZ0VMj45Pj6+PX9SXsOKuFFFyO9h1fNVITFsc",
	"nbZG9vqB6wGHWWXDJEXsWBAJuzZ2yxcQ2bKX2akWQXbZh6ugvGtm4mJm3fBtk4wB0KgoHDafOJiEfCBj",
	"1Re1fOyOK2Tr0qKp4w83HWBPIAYQX+8wZexM/qqLwH3n5QVVBTBCpTJlj4HBKNHM+6qj1/ia+LBbLvin",
	"y+bENiNqMyIinQ0lAnBCvlzT0Tgh2TkUyEaC3YdC5lSJStXmwOp7fX0KqaJw1Q8qMMHyqIJmAqjaRGfl",
	"IskxUsroGKaQ1mR5sJi+OE3uA9CenoDmYONWTjJOxW2lm2MXP1cFcm0j20S4jDxJru+SuHiwFlQ9NjuD",
	"2G14TGO9MPsRrhY5+EboJ6PwJIRKSwBnWUwAufZLMkV4dQih6NoAhhccCxeAjxY65wyIKECtCkcTIfjs",
	"RiNIO5v7PrQz27iNCU9VW/WuniUyvYE76gLxnZv/5yj0gjmyd4eMEqoIP/L1lHqv+vJCzVRmkECEIayf",
	"ZxV7kXzuGCb+C4nnnL6qMNB9K3GcnOFiEAvAkvfY7/eqygHUtYsLky5AK9ouyZI5pEMSOhTrJgFdY3HW",
	"t4jPMc9Ro1/IOufk6qGsMFDizIS/bG+LjvF8F11EYnJ+OLjqNaoT5ylRyDCgY3mREKNJHOgLGaeOXIsk",
	"iHthvxHV8Zd8Y7gyUHmFX4p095rGFz5TGg8mFzzsPhvEpSmNokMkUkkmQG4QxzkSR4wdErZG9UvAsOrA",
	"RUSFSu0ZyjU3rwBI4FCvm7xrQpbeWb6+Pv138LA9S7oGBqH8ej2KaZM3r6AA3ano2Wu7eAU+jTDu3MRf",
	"ae4r6oh42oDgGh5inCmgD7CDeUC/ivdKxV/fn2/Rrh4LyEpAKksDtHf2q6GHYaN/FTq1ezvSI20Uaw0S",
	"uSsFqNQZMgB+w6SZQoHZvglM9kvkrfWp4zZcEl3Q1l9Foe4KVS4EwHdbI54S8pNO48r88iSGe+RvkMY8",
	"ubFj+KVyaPfJ8BzYbjtZz0khxATSJEYAvSzWj8E2PMnmr2XDc1qDLWVVe3gAA4a5bdEeNU494qsjuw6I",
	"ncBxh0qyYk3LqjklEAXXfJ1Az3Fs2nY7O10YKWiVeEIKBTmWVXfgVbx60IoH8P5ycryq/xXy8jFouKfH",
	"a1j9zRR55JR/OT0eTB+TV9UnbTNf3mZWPMTDwPgl3biJAQ/F1k4OOCzddrI7J3rtjHcB7yLCyVeFro35",
	"TtWF+Vd9y6b1xu7Eb4xJf9j7UgI87A6S3+3s/sWz333/Hw3yuzf7e7vO0T2jyCh4iSquO+VgeK/t45WF",
	"HosysauVWE9u1cxOJdUG2HmzSp176PQKSlBmP/2hrHy6i9rW2fjCHeZGEr76TicShwj/DhEIWI8IDpc7",
	"5FTlCL3dWY/38ImLKCivQNcZwxHUFC7xy1RmQs5mQBIzJ+KGgNShgaLSQscH4Zzgqzjyw5G8JhveQZq6",
	"XehML0H+lzJzsb5NdHvPvWkD8Z4L8Kj2oXmGMu/SbcAbLHSwfwk9XLuNSUwp9GMG00sZ5kQSEM+Zz85z",
	"9VHOR5tfKzr2E91i9M9QVde5huCAcv75KBhRYDwLP61cyEJ5cxP6ukR6ALexSNVYAQ9lZj9mCRKNqiRr",
	"ldxnaAYx45/k+Pz6EoTMAXiGTPutXIMUqmokA1nvlqpyQ1S0iltfvjqBwIngTSUysTGbwLsnlEngUp3I",
	"t2T/9RUt9ILLG5zP+itkasXihunGv+0VO4vN+RB2Q+Hym6o7qepBvh/3MEai02SWNGYGskqs7a2Mdb9y",
	"wOb0b6rnHMH4ByBqA7lMMl+EqjdgcaLnQNHE4LOEMi+SO9cyM7lIcauNSVWmZve0ucUjmXKhC6BcqzFV",
	"Yn/sDER255/w9oZhL9GhL10xrteo1JGfVWHXUz2kdEt+h8u2wMwEj8EFjfLXhDCToAILRXm7CAxQsUyR",
	"OIajgJZ4CKFa1m1xgWndIVwjzPzzhJioTV5BiPkyXCMH0zFUjkFuFj4EWUxmbadddtpWaSxO7JRUIRsp",
	"Ig/V/bZVPPOFcJC98VBmRLPJMu7DZMQv5mJPrYCNFyGbCTKbGY3JNX4UP5aqaBk5+Pm1TVp1leBO2jd8",
	"6X5saT64+PSLvWzk/EOhV7mdjc/cBJ3yX65u0wSoZLZ6W0bOYcbmaNRugABAxVu9LdLUVYloYU1tMqi0",
	"AH82hAvGNxizQKpqX0YjGnTxl6dfnv5/AAAA///eCXytP7kDAA==",
}

// GetSwagger returns the content of the embedded swagger specification file
// or error if failed to decode
func decodeSpec() ([]byte, error) {
	zipped, err := base64.StdEncoding.DecodeString(strings.Join(swaggerSpec, ""))
	if err != nil {
		return nil, fmt.Errorf("error base64 decoding spec: %w", err)
	}
	zr, err := gzip.NewReader(bytes.NewReader(zipped))
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}
	var buf bytes.Buffer
	_, err = buf.ReadFrom(zr)
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}

	return buf.Bytes(), nil
}

var rawSpec = decodeSpecCached()

// a naive cached of a decoded swagger spec
func decodeSpecCached() func() ([]byte, error) {
	data, err := decodeSpec()
	return func() ([]byte, error) {
		return data, err
	}
}

// Constructs a synthetic filesystem for resolving external references when loading openapi specifications.
func PathToRawSpec(pathToFile string) map[string]func() ([]byte, error) {
	res := make(map[string]func() ([]byte, error))
	if len(pathToFile) > 0 {
		res[pathToFile] = rawSpec
	}

	return res
}

// GetSwagger returns the Swagger specification corresponding to the generated code
// in this file. The external references of Swagger specification are resolved.
// The logic of resolving external references is tightly connected to "import-mapping" feature.
// Externally referenced files must be embedded in the corresponding golang packages.
// Urls can be supported but this task was out of the scope.
func GetSwagger() (swagger *openapi3.T, err error) {
	resolvePath := PathToRawSpec("")

	loader := openapi3.NewLoader()
	loader.IsExternalRefsAllowed = true
	loader.ReadFromURIFunc = func(loader *openapi3.Loader, url *url.URL) ([]byte, error) {
		pathToFile := url.String()
		pathToFile = path.Clean(pathToFile)
		getSpec, ok := resolvePath[pathToFile]
		if !ok {
			err1 := fmt.Errorf("path not found: %s", pathToFile)
			return nil, err1
		}
		return getSpec()
	}
	var specData []byte
	specData, err = rawSpec()
	if err != nil {
		return
	}
	swagger, err = loader.LoadFromData(specData)
	if err != nil {
		return
	}
	return
}
