// Package oapi provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/oapi-codegen/oapi-codegen/v2 version v2.5.0 DO NOT EDIT.
package oapi

import (
	"bytes"
	"compress/gzip"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"path"
	"strings"
	"time"

	"github.com/getkin/kin-openapi/openapi3"
	"github.com/oapi-codegen/runtime"
)

const (
	BasicAuthScopes = "BasicAuth.Scopes"
)

// Defines values for AntflyType.
const (
	AntflyTypeBlob            AntflyType = "blob"
	AntflyTypeBoolean         AntflyType = "boolean"
	AntflyTypeDatetime        AntflyType = "datetime"
	AntflyTypeEmbedding       AntflyType = "embedding"
	AntflyTypeGeopoint        AntflyType = "geopoint"
	AntflyTypeGeoshape        AntflyType = "geoshape"
	AntflyTypeHtml            AntflyType = "html"
	AntflyTypeKeyword         AntflyType = "keyword"
	AntflyTypeLink            AntflyType = "link"
	AntflyTypeNumeric         AntflyType = "numeric"
	AntflyTypeSearchAsYouType AntflyType = "search_as_you_type"
	AntflyTypeText            AntflyType = "text"
)

// Defines values for ChunkerProvider.
const (
	ChunkerProviderMock    ChunkerProvider = "mock"
	ChunkerProviderTermite ChunkerProvider = "termite"
)

// Defines values for ChunkingStrategy.
const (
	ChunkingStrategyFixed ChunkingStrategy = "fixed"
	ChunkingStrategyHugot ChunkingStrategy = "hugot"
)

// Defines values for ClusterHealth.
const (
	ClusterHealthDegraded  ClusterHealth = "degraded"
	ClusterHealthError     ClusterHealth = "error"
	ClusterHealthHealthy   ClusterHealth = "healthy"
	ClusterHealthUnhealthy ClusterHealth = "unhealthy"
	ClusterHealthUnknown   ClusterHealth = "unknown"
)

// Defines values for EdgeDirection.
const (
	EdgeDirectionBoth EdgeDirection = "both"
	EdgeDirectionIn   EdgeDirection = "in"
	EdgeDirectionOut  EdgeDirection = "out"
)

// Defines values for EmbedderProvider.
const (
	EmbedderProviderBedrock EmbedderProvider = "bedrock"
	EmbedderProviderGemini  EmbedderProvider = "gemini"
	EmbedderProviderMock    EmbedderProvider = "mock"
	EmbedderProviderOllama  EmbedderProvider = "ollama"
	EmbedderProviderOpenai  EmbedderProvider = "openai"
	EmbedderProviderVertex  EmbedderProvider = "vertex"
)

// Defines values for FailedOperationOperation.
const (
	FailedOperationOperationDelete FailedOperationOperation = "delete"
	FailedOperationOperationUpsert FailedOperationOperation = "upsert"
)

// Defines values for Fuzziness1.
const (
	Fuzziness1Auto Fuzziness1 = "auto"
)

// Defines values for GeneratorProvider.
const (
	GeneratorProviderAnthropic GeneratorProvider = "anthropic"
	GeneratorProviderBedrock   GeneratorProvider = "bedrock"
	GeneratorProviderGemini    GeneratorProvider = "gemini"
	GeneratorProviderMock      GeneratorProvider = "mock"
	GeneratorProviderOllama    GeneratorProvider = "ollama"
	GeneratorProviderOpenai    GeneratorProvider = "openai"
	GeneratorProviderVertex    GeneratorProvider = "vertex"
)

// Defines values for GeoShapeGeometryRelation.
const (
	GeoShapeGeometryRelationContains   GeoShapeGeometryRelation = "contains"
	GeoShapeGeometryRelationIntersects GeoShapeGeometryRelation = "intersects"
	GeoShapeGeometryRelationWithin     GeoShapeGeometryRelation = "within"
)

// Defines values for GraphQueryType.
const (
	GraphQueryTypeKShortestPaths GraphQueryType = "k_shortest_paths"
	GraphQueryTypeNeighbors      GraphQueryType = "neighbors"
	GraphQueryTypeShortestPath   GraphQueryType = "shortest_path"
	GraphQueryTypeTraverse       GraphQueryType = "traverse"
)

// Defines values for IndexType.
const (
	IndexTypeAknnV0     IndexType = "aknn_v0"
	IndexTypeFullTextV0 IndexType = "full_text_v0"
	IndexTypeGraphV0    IndexType = "graph_v0"
)

// Defines values for LinearMergePageStatus.
const (
	LinearMergePageStatusError   LinearMergePageStatus = "error"
	LinearMergePageStatusPartial LinearMergePageStatus = "partial"
	LinearMergePageStatusSuccess LinearMergePageStatus = "success"
)

// Defines values for MatchQueryOperator.
const (
	MatchQueryOperatorAnd MatchQueryOperator = "and"
	MatchQueryOperatorOr  MatchQueryOperator = "or"
)

// Defines values for MergeStrategy.
const (
	MergeStrategyFailover MergeStrategy = "failover"
	MergeStrategyRrf      MergeStrategy = "rrf"
	MergeStrategyRsf      MergeStrategy = "rsf"
)

// Defines values for PathFindWeightMode.
const (
	PathFindWeightModeMaxWeight PathFindWeightMode = "max_weight"
	PathFindWeightModeMinHops   PathFindWeightMode = "min_hops"
	PathFindWeightModeMinWeight PathFindWeightMode = "min_weight"
)

// Defines values for PathWeightMode.
const (
	PathWeightModeMaxWeight PathWeightMode = "max_weight"
	PathWeightModeMinHops   PathWeightMode = "min_hops"
	PathWeightModeMinWeight PathWeightMode = "min_weight"
)

// Defines values for PermissionType.
const (
	PermissionTypeAdmin PermissionType = "admin"
	PermissionTypeRead  PermissionType = "read"
	PermissionTypeWrite PermissionType = "write"
)

// Defines values for QueryRequestExpandStrategy.
const (
	QueryRequestExpandStrategyIntersection QueryRequestExpandStrategy = "intersection"
	QueryRequestExpandStrategyUnion        QueryRequestExpandStrategy = "union"
)

// Defines values for ResourceType.
const (
	ResourceTypeAsterisk ResourceType = "*"
	ResourceTypeTable    ResourceType = "table"
	ResourceTypeUser     ResourceType = "user"
)

// Defines values for RouteType.
const (
	RouteTypeQuestion RouteType = "question"
	RouteTypeSearch   RouteType = "search"
)

// Defines values for SyncLevel.
const (
	SyncLevelAknn     SyncLevel = "aknn"
	SyncLevelFullText SyncLevel = "full_text"
	SyncLevelPropose  SyncLevel = "propose"
	SyncLevelWrite    SyncLevel = "write"
)

// Defines values for TransformOpType.
const (
	TransformOpTypeAddToSet    TransformOpType = "$addToSet"
	TransformOpTypeCurrentDate TransformOpType = "$currentDate"
	TransformOpTypeInc         TransformOpType = "$inc"
	TransformOpTypeMax         TransformOpType = "$max"
	TransformOpTypeMin         TransformOpType = "$min"
	TransformOpTypeMul         TransformOpType = "$mul"
	TransformOpTypePop         TransformOpType = "$pop"
	TransformOpTypePull        TransformOpType = "$pull"
	TransformOpTypePush        TransformOpType = "$push"
	TransformOpTypeRename      TransformOpType = "$rename"
	TransformOpTypeSet         TransformOpType = "$set"
	TransformOpTypeUnset       TransformOpType = "$unset"
)

// Analyses defines model for Analyses.
type Analyses struct {
	Pca  bool `json:"pca,omitempty,omitzero"`
	Tsne bool `json:"tsne,omitempty,omitzero"`
}

// AnalysesResult defines model for AnalysesResult.
type AnalysesResult struct {
	Pca  []float64 `json:"pca,omitempty,omitzero"`
	Tsne []float64 `json:"tsne,omitempty,omitzero"`
}

// AnswerAgentRequest defines model for AnswerAgentRequest.
type AnswerAgentRequest struct {
	// Queries Array of query requests to execute. The query text will be transformed for semantic search
	// and populated into the semantic_search field of each query.
	Queries []QueryRequest `json:"queries"`

	// Query User's natural language query to be classified and improved
	Query string `json:"query"`

	// Summarizer A unified configuration for a generative AI provider.
	Summarizer GeneratorConfig `json:"summarizer"`

	// SystemPrompt Optional system prompt to guide classification and answer generation
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`

	// UserContext Optional user context to customize the content guidance for each section of the answer agent response.
	//
	// **What you can customize**: Style, tone, length, detail level, and focus of content for each section independently.
	//
	// **What is fixed**: The response format is always markdown with consistent structure (## Reasoning, ## Answer, ## Follow-up Questions).
	// Markdown formatting (headings, bullets, code blocks, etc.) is always applied and cannot be disabled.
	//
	// **Architecture**: These contexts are passed as template variables to the prompt template. Defaults are set
	// at the application layer, and users can override them via this API to customize content guidance.
	UserContext UserContext `json:"user_context,omitempty,omitzero"`

	// WithFollowup Include suggested follow-up questions as separate events after the answer
	WithFollowup bool `json:"with_followup,omitempty,omitzero"`

	// WithReasoning Include the LLM's reasoning process as separate events before the answer
	WithReasoning bool `json:"with_reasoning,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results (classification, queries, results, answer) instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// AnswerAgentResult Answer agent result with classification and generated answer with inline resource references
type AnswerAgentResult struct {
	// Answer Generated answer (markdown format with inline resource references)
	Answer string `json:"answer,omitempty,omitzero"`

	// ClassificationTransformation Query classification and transformation result combining all query enhancements
	ClassificationTransformation ClassificationTransformationResult `json:"classification_transformation,omitempty,omitzero"`

	// FollowupQuestions Suggested follow-up questions (if with_followup was enabled)
	FollowupQuestions []string `json:"followup_questions,omitempty,omitzero"`

	// QueryResults Results from each executed query
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`

	// Reasoning LLM's reasoning process (if with_reasoning was enabled)
	Reasoning string `json:"reasoning,omitempty,omitzero"`
}

// AntflyType defines model for AntflyType.
type AntflyType string

// AnthropicGeneratorConfig Configuration for the Anthropic generative AI provider (Claude models).
// Uses the firebase/genkit compat_oai/anthropic plugin with OpenAI-compatible API.
//
// Defaults to claude-3-7-sonnet-20250219 if no model is specified.
//
// API key can be provided via the 'api_key' field or the ANTHROPIC_API_KEY environment variable.
//
// Supported models:
// - claude-3-7-sonnet-20250219 (latest, most capable)
// - claude-3-5-haiku-20241022 (fast and efficient)
// - claude-3-5-sonnet-20240620 (balanced performance)
// - claude-3-opus-20240229 (highly capable)
// - claude-3-haiku-20240307 (fastest)
type AnthropicGeneratorConfig struct {
	// ApiKey The Anthropic API key. If not provided, falls back to ANTHROPIC_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The full model ID of the Anthropic model to use (e.g., 'claude-3-7-sonnet-20250219', 'claude-3-5-haiku-20241022').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-1.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Anthropic API endpoint (optional, uses default if not specified).
	Url string `json:"url,omitempty,omitzero"`
}

// BackupRequest defines model for BackupRequest.
type BackupRequest struct {
	// BackupId Unique identifier for this backup. Used to reference the backup for restore operations.
	// Choose a meaningful name that includes date/version information.
	BackupId string `json:"backup_id"`

	// Location Storage location for the backup. Supports multiple backends:
	// - Local filesystem: `file:///path/to/backup`
	// - Amazon S3: `s3://bucket-name/path/to/backup`
	//
	// The backup includes all table data, indexes, and metadata for the specified table.
	Location string `json:"location"`
}

// BatchRequest Batch insert, delete, and transform operations in a single request. All operations are processed atomically within each shard.
//
// Benefits:
// - Reduces network overhead compared to individual requests
// - More efficient indexing (updates are batched)
// - Atomic within shard boundaries
//
// The inserts are upserts - existing keys are overwritten, new keys are created.
type BatchRequest struct {
	// Deletes Array of document IDs to delete. Documents are removed from all indexes.
	//
	// Notes:
	// - Non-existent keys are silently ignored
	// - Deletions are processed before inserts in the same batch
	// - Keys are permanently removed from storage and indexes
	Deletes []string `json:"deletes,omitempty,omitzero"`

	// Inserts Map of document IDs to document objects. Each key is the unique identifier for the document.
	//
	// Best practices:
	// - Use consistent key naming schemes (e.g., "user:123", "article:456")
	// - Key length affects storage and performance - keep them reasonably short
	// - Keys are sorted lexicographically, so choose prefixes that support range scans
	Inserts map[string]map[string]interface{} `json:"inserts,omitempty,omitzero"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write (slowest, most durable)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`

	// Transforms Array of transform operations for in-place document updates using MongoDB-style operators.
	//
	// Transform operations allow you to modify documents without read-modify-write races:
	// - Operations are applied atomically on the server
	// - Multiple operations per document are applied in sequence
	// - Supports numeric operations ($inc, $mul), array operations ($push, $pull), and more
	//
	// Common use cases:
	// - Increment counters (views, likes, votes)
	// - Update timestamps ($currentDate)
	// - Manage arrays (add/remove tags, items)
	// - Update nested fields without overwriting the entire document
	Transforms []Transform `json:"transforms,omitempty,omitzero"`
}

// BedrockEmbedderConfig Configuration for the Bedrock embedding provider.
type BedrockEmbedderConfig struct {
	// BatchSize The batch size for embedding requests.
	BatchSize int `json:"batch_size,omitempty,omitzero"`

	// Model The name of the Bedrock model to use.
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service.
	Region string `json:"region,omitempty,omitzero"`

	// StripNewLines Whether to strip new lines from the input text.
	StripNewLines bool `json:"strip_new_lines,omitempty,omitzero"`
}

// BedrockGeneratorConfig Configuration for the AWS Bedrock generative AI provider.
type BedrockGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Bedrock model to use.
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service.
	Region string `json:"region,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-1.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// BleveIndexV2Config defines model for BleveIndexV2Config.
type BleveIndexV2Config struct {
	// MemOnly Whether to use memory-only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`
}

// BleveIndexV2Stats defines model for BleveIndexV2Stats.
type BleveIndexV2Stats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// Rebuilding Whether the index is currently rebuilding
	Rebuilding bool `json:"rebuilding,omitempty,omitzero"`

	// TotalIndexed Number of documents in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`
}

// BoolFieldQuery defines model for BoolFieldQuery.
type BoolFieldQuery struct {
	Bool bool `json:"bool"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
}

// BooleanQuery defines model for BooleanQuery.
type BooleanQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost   Boost            `json:"boost,omitzero"`
	Filter  Query            `json:"filter,omitempty,omitzero"`
	Must    ConjunctionQuery `json:"must,omitempty,omitzero"`
	MustNot DisjunctionQuery `json:"must_not,omitempty,omitzero"`
	Should  DisjunctionQuery `json:"should,omitempty,omitzero"`
}

// Boost A floating-point number used to decrease or increase the relevance scores of a query.
type Boost = float64

// ByteRange defines model for ByteRange.
type ByteRange = [][]byte

// ChunkerConfig defines model for ChunkerConfig.
type ChunkerConfig struct {
	// Provider The chunking provider to use.
	Provider ChunkerProvider `json:"provider"`
	union    json.RawMessage
}

// ChunkerProvider The chunking provider to use.
type ChunkerProvider string

// ChunkingStrategy Document chunking strategy.
// - hugot: ONNX-accelerated chunking using sentence boundary detection
// - fixed: Simple fixed-size chunking by token count
type ChunkingStrategy string

// ClassificationTransformationResult Query classification and transformation result combining all query enhancements
type ClassificationTransformationResult struct {
	// Confidence Classification confidence (0.0 to 1.0)
	Confidence float32 `json:"confidence"`

	// ImprovedQuery Clarified query with added context for answer generation (human-readable)
	ImprovedQuery string `json:"improved_query"`

	// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
	RouteType RouteType `json:"route_type"`

	// SemanticQuery Optimized query for vector/semantic search (concept extraction with synonyms)
	SemanticQuery string `json:"semantic_query"`
}

// ClusterHealth Overall health status of the cluster
type ClusterHealth string

// ClusterStatus defines model for ClusterStatus.
type ClusterStatus struct {
	// AuthEnabled Indicates whether authentication is enabled for the cluster
	AuthEnabled bool `json:"auth_enabled,omitempty"`

	// Health Overall health status of the cluster
	Health ClusterHealth `json:"health"`

	// Message Optional message providing details about the health status
	Message              string                 `json:"message,omitempty,omitzero"`
	AdditionalProperties map[string]interface{} `json:"-"`
}

// ConjunctionQuery defines model for ConjunctionQuery.
type ConjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Conjuncts []Query `json:"conjuncts"`
}

// CreateTableRequest defines model for CreateTableRequest.
type CreateTableRequest struct {
	// Description Optional human-readable description of the table and its purpose.
	// Useful for documentation and team collaboration.
	Description string `json:"description,omitempty,omitzero"`

	// Indexes Map of index name to index configuration. Indexes enable different query capabilities:
	// - Full-text indexes for BM25 search
	// - Vector indexes for semantic similarity
	// - Multimodal indexes for images/audio/video
	//
	// You can add multiple indexes to support different query patterns.
	Indexes map[string]IndexConfig `json:"indexes,omitempty,omitzero"`

	// NumShards Number of shards to create for the table. Data is partitioned across shards based on key ranges.
	//
	// Guidelines:
	// - Small datasets (<100K docs): 1-3 shards
	// - Medium datasets (100K-1M docs): 3-10 shards
	// - Large datasets (>1M docs): 10+ shards
	//
	// More shards enable better parallelism but increase overhead. Choose based on expected data size and query patterns.
	NumShards uint `json:"num_shards,omitempty,omitzero"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema `json:"schema,omitempty,omitzero"`
}

// CreateUserRequest defines model for CreateUserRequest.
type CreateUserRequest struct {
	// InitialPolicies Optional list of initial permissions for the user.
	InitialPolicies []Permission `json:"initial_policies,omitzero"`
	Password        string       `json:"password"`

	// Username Username for the new user. If provided in the path, this field can be omitted or must match the path parameter.
	Username string `json:"username,omitempty,omitzero"`
}

// DateRange defines model for DateRange.
type DateRange struct {
	From *string `json:"from,omitempty"`
	Name string  `json:"name"`
	To   *string `json:"to,omitempty"`
}

// DateRangeResult defines model for DateRangeResult.
type DateRangeResult struct {
	Count int     `json:"count"`
	From  *string `json:"from,omitempty"`
	Name  string  `json:"name"`
	To    *string `json:"to,omitempty"`
}

// DateRangeStringQuery defines model for DateRangeStringQuery.
type DateRangeStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost          Boost     `json:"boost,omitzero"`
	DatetimeParser string    `json:"datetime_parser,omitempty,omitzero"`
	End            time.Time `json:"end,omitempty,omitzero"`
	Field          string    `json:"field,omitempty,omitzero"`
	InclusiveEnd   bool      `json:"inclusive_end,omitzero"`
	InclusiveStart bool      `json:"inclusive_start,omitzero"`
	Start          time.Time `json:"start,omitempty,omitzero"`
}

// DisjunctionQuery defines model for DisjunctionQuery.
type DisjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Disjuncts []Query `json:"disjuncts"`
	Min       float64 `json:"min,omitempty,omitzero"`
}

// DocIdQuery defines model for DocIdQuery.
type DocIdQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost    `json:"boost,omitzero"`
	Ids   []string `json:"ids"`
}

// DocumentSchema Defines the structure of a document type
type DocumentSchema struct {
	// Description A description of the document type.
	Description string `json:"description,omitempty,omitzero"`

	// Schema A valid JSON Schema defining the document's structure.
	// This is used to infer indexing rules and field types.
	Schema map[string]interface{} `json:"schema,omitempty,omitzero"`
}

// Edge A typed, weighted connection between documents
type Edge struct {
	// CreatedAt When the edge was created
	CreatedAt time.Time `json:"created_at,omitempty,omitzero"`

	// Metadata Optional edge metadata
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`

	// Source Base64-encoded source document key
	Source []byte `json:"source"`

	// Target Base64-encoded target document key
	Target []byte `json:"target"`

	// Type Edge type (e.g., "cites", "similar_to", "authored_by")
	Type string `json:"type"`

	// UpdatedAt When the edge was last updated
	UpdatedAt time.Time `json:"updated_at,omitempty,omitzero"`

	// Weight Edge weight/confidence (0.0 to 1.0)
	Weight float64 `json:"weight"`
}

// EdgeDirection Direction of edges to query:
// - out: Outgoing edges from the node
// - in: Incoming edges to the node
// - both: Both outgoing and incoming edges
type EdgeDirection string

// EdgeTypeConfig Configuration for a specific edge type
type EdgeTypeConfig struct {
	// AllowSelfLoops Whether to allow edges from a node to itself
	AllowSelfLoops bool `json:"allow_self_loops,omitempty,omitzero"`

	// MaxWeight Maximum allowed edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum allowed edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// Name Edge type name (e.g., 'cites', 'similar_to')
	Name string `json:"name"`

	// RequiredMetadata Required metadata fields for this edge type
	RequiredMetadata []string `json:"required_metadata,omitempty,omitzero"`
}

// EdgesResponse defines model for EdgesResponse.
type EdgesResponse struct {
	// Count Total number of edges returned
	Count int    `json:"count,omitempty,omitzero"`
	Edges []Edge `json:"edges,omitempty,omitzero"`
}

// EmbedderConfig defines model for EmbedderConfig.
type EmbedderConfig struct {
	// Provider The embedding provider to use.
	Provider EmbedderProvider `json:"provider"`
	union    json.RawMessage
}

// EmbedderProvider The embedding provider to use.
type EmbedderProvider string

// EmbeddingIndexConfig defines model for EmbeddingIndexConfig.
type EmbeddingIndexConfig struct {
	// Chunker A unified configuration for a chunking provider.
	Chunker ChunkerConfig `json:"chunker,omitempty,omitzero"`

	// Dimension Vector dimension
	Dimension int `json:"dimension"`

	// Embedder A unified configuration for an embedding provider.
	Embedder EmbedderConfig `json:"embedder,omitempty,omitzero"`

	// Field Field to extract embeddings from
	Field string `json:"field,omitempty,omitzero"`

	// MemOnly Whether to use in-memory only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`

	// Summarizer A unified configuration for a generative AI provider.
	Summarizer GeneratorConfig `json:"summarizer,omitempty,omitzero"`

	// Template Handlebars template for generating prompts. See https://handlebarsjs.com/guide/ for more information.
	Template string `json:"template,omitempty,omitzero"`
}

// EmbeddingIndexStats defines model for EmbeddingIndexStats.
type EmbeddingIndexStats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalIndexed Number of vectors in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`

	// TotalNodes Total number of nodes in the index
	TotalNodes uint64 `json:"total_nodes,omitempty,omitzero"`
}

// Error defines model for Error.
type Error struct {
	Error string `json:"error"`
}

// FacetOption defines model for FacetOption.
type FacetOption struct {
	DateRanges    []DateRange    `json:"date_ranges,omitempty,omitzero"`
	Field         string         `json:"field,omitempty,omitzero"`
	NumericRanges []NumericRange `json:"numeric_ranges,omitempty,omitzero"`
	Size          int            `json:"size,omitempty,omitzero"`
}

// FacetResult defines model for FacetResult.
type FacetResult struct {
	DateRanges    []DateRangeResult    `json:"date_ranges,omitempty,omitzero"`
	Field         string               `json:"field,omitempty,omitzero"`
	Missing       int                  `json:"missing,omitempty,omitzero"`
	NumericRanges []NumericRangeResult `json:"numeric_ranges,omitempty,omitzero"`
	Terms         []TermFacetResult    `json:"terms,omitempty,omitzero"`
	Total         int                  `json:"total,omitempty,omitzero"`
}

// FailedOperation defines model for FailedOperation.
type FailedOperation struct {
	Error     string                   `json:"error,omitempty,omitzero"`
	Id        string                   `json:"id,omitempty,omitzero"`
	Operation FailedOperationOperation `json:"operation,omitempty,omitzero"`
}

// FailedOperationOperation defines model for FailedOperation.Operation.
type FailedOperationOperation string

// Fuzziness The fuzziness of the query. Can be an integer or "auto".
type Fuzziness struct {
	union json.RawMessage
}

// Fuzziness0 defines model for .
type Fuzziness0 = int32

// Fuzziness1 defines model for Fuzziness.1.
type Fuzziness1 string

// FuzzyQuery defines model for FuzzyQuery.
type FuzzyQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness `json:"fuzziness,omitempty,omitzero"`
	PrefixLength int32     `json:"prefix_length,omitempty,omitzero"`
	Term         string    `json:"term"`
}

// GeneratorConfig defines model for GeneratorConfig.
type GeneratorConfig struct {
	// Provider The generative AI provider to use.
	Provider GeneratorProvider `json:"provider"`
	union    json.RawMessage
}

// GeneratorProvider The generative AI provider to use.
type GeneratorProvider string

// GeoBoundingBoxQuery defines model for GeoBoundingBoxQuery.
type GeoBoundingBoxQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost `json:"boost,omitzero"`

	// BottomRight [lon, lat]
	BottomRight []float64 `json:"bottom_right"`
	Field       string    `json:"field,omitempty,omitzero"`

	// TopLeft [lon, lat]
	TopLeft []float64 `json:"top_left"`
}

// GeoBoundingPolygonQuery defines model for GeoBoundingPolygonQuery.
type GeoBoundingPolygonQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost         Boost      `json:"boost,omitzero"`
	Field         string     `json:"field,omitempty,omitzero"`
	PolygonPoints []GeoPoint `json:"polygon_points"`
}

// GeoDistanceQuery defines model for GeoDistanceQuery.
type GeoDistanceQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Distance string `json:"distance"`
	Field    string `json:"field,omitempty,omitzero"`

	// Location [lon, lat]
	Location []float64 `json:"location"`
}

// GeoPoint defines model for GeoPoint.
type GeoPoint struct {
	Lat float64 `json:"lat,omitempty,omitzero"`
	Lon float64 `json:"lon,omitempty,omitzero"`
}

// GeoShape A GeoJSON shape object. This is a simplified representation.
type GeoShape struct {
	Coordinates []interface{} `json:"coordinates"`
	Type        string        `json:"type"`
}

// GeoShapeGeometry defines model for GeoShapeGeometry.
type GeoShapeGeometry struct {
	Relation GeoShapeGeometryRelation `json:"relation"`

	// Shape A GeoJSON shape object. This is a simplified representation.
	Shape GeoShape `json:"shape"`
}

// GeoShapeGeometryRelation defines model for GeoShapeGeometry.Relation.
type GeoShapeGeometryRelation string

// GeoShapeQuery defines model for GeoShapeQuery.
type GeoShapeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost            `json:"boost,omitzero"`
	Field    string           `json:"field,omitempty,omitzero"`
	Geometry GeoShapeGeometry `json:"geometry"`
}

// GoogleEmbedderConfig Configuration for the Google embedding provider.
type GoogleEmbedderConfig struct {
	// ApiKey The Google API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimension The dimension of the embedding.
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1').
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the embedding model to use (e.g., 'text-embedding-004').
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Url The URL of the Google API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// GoogleGeneratorConfig Configuration for the Google generative AI provider (Gemini). Defaults to gemini-2.5-flash if no model is specified.
type GoogleGeneratorConfig struct {
	// ApiKey The Google API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1').
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the generative model to use (e.g., 'gemini-2.5-flash', 'gemini-1.5-pro').
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Google API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// GraphIndexV0Config Configuration for graph_v0 index type
type GraphIndexV0Config struct {
	// EdgeTypes List of edge types with their configurations
	EdgeTypes []EdgeTypeConfig `json:"edge_types,omitempty,omitzero"`

	// MaxEdgesPerDocument Maximum number of edges per document (0 = unlimited)
	MaxEdgesPerDocument int `json:"max_edges_per_document,omitempty,omitzero"`
}

// GraphIndexV0Stats Statistics for graph_v0 index
type GraphIndexV0Stats struct {
	// EdgeTypes Count of edges per edge type
	EdgeTypes map[string]uint64 `json:"edge_types,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalEdges Total number of edges in the graph
	TotalEdges uint64 `json:"total_edges,omitempty,omitzero"`
}

// GraphNodeSelector Defines how to select start/target nodes for graph queries
type GraphNodeSelector struct {
	// Keys Explicit list of node keys
	Keys []string `json:"keys,omitempty,omitzero"`

	// Limit Maximum number of nodes to select from the referenced results
	Limit int `json:"limit,omitempty,omitzero"`

	// ResultRef Reference to search results to use as nodes:
	// - "$full_text_results" - use full-text search results
	// - "$aknn_results.index_name" - use vector search results from specific index
	ResultRef string `json:"result_ref,omitempty,omitzero"`
}

// GraphQuery Declarative graph query to execute after full-text/vector searches
type GraphQuery struct {
	// Fields Which fields to return from documents
	Fields []string `json:"fields,omitempty,omitzero"`

	// IncludeDocuments Fetch full documents for graph results
	IncludeDocuments bool `json:"include_documents,omitempty,omitzero"`

	// IncludeEdges Include edge details for each node
	IncludeEdges bool `json:"include_edges,omitempty,omitzero"`

	// IndexName Graph index name (must be graph_v0 type)
	IndexName string `json:"index_name"`

	// Params Parameters for graph traversal and pathfinding
	Params GraphQueryParams `json:"params"`

	// StartNodes Defines how to select start/target nodes for graph queries
	StartNodes GraphNodeSelector `json:"start_nodes"`

	// TargetNodes Defines how to select start/target nodes for graph queries
	TargetNodes GraphNodeSelector `json:"target_nodes,omitempty,omitzero"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryParams Parameters for graph traversal and pathfinding
type GraphQueryParams struct {
	// Algorithm Graph algorithm to run (e.g., 'pagerank', 'betweenness')
	Algorithm string `json:"algorithm,omitempty,omitzero"`

	// AlgorithmParams Parameters for the graph algorithm
	AlgorithmParams map[string]interface{} `json:"algorithm_params,omitempty,omitzero"`

	// DeduplicateNodes Remove duplicate nodes (traversal)
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information (traversal)
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// K Number of paths to find (k-shortest-paths)
	K int `json:"k,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum number of results (traversal)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// WeightMode Path weighting algorithm for pathfinding:
	// - min_hops: Minimize number of edges
	// - min_weight: Minimize sum of edge weights
	// - max_weight: Maximize product of edge weights
	WeightMode PathWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// GraphQueryResult Results of a graph query
type GraphQueryResult struct {
	// Nodes Result nodes
	Nodes []GraphResultNode `json:"nodes,omitempty,omitzero"`

	// Paths Result paths (for pathfinding queries)
	Paths []Path `json:"paths,omitempty,omitzero"`

	// Took Query execution time
	Took time.Duration `json:"took,omitempty,omitzero"`

	// Total Total number of results
	Total int `json:"total"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryType Type of graph query to execute
type GraphQueryType string

// GraphResultNode A node in graph query results
type GraphResultNode struct {
	// Depth Distance from start node
	Depth int `json:"depth,omitempty,omitzero"`

	// Distance Weighted distance
	Distance float64 `json:"distance,omitempty,omitzero"`

	// Document Full document (if include_documents=true)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Edges Connected edges (when include_edges=true)
	Edges []Edge `json:"edges,omitempty,omitzero"`

	// Key Document key
	Key string `json:"key"`

	// Path Keys in path from start to this node
	Path []string `json:"path,omitempty,omitzero"`

	// PathEdges Edges in path from start to this node
	PathEdges []PathEdge `json:"path_edges,omitempty,omitzero"`
}

// IPRangeQuery defines model for IPRangeQuery.
type IPRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Cidr  string `json:"cidr"`
	Field string `json:"field,omitempty,omitzero"`
}

// IndexConfig Configuration for an index
type IndexConfig struct {
	// Description Optional description of the index and its purpose
	Description string `json:"description,omitempty,omitzero"`

	// Enrichments List of enrichment names to apply to documents before indexing. Enrichments must be defined at the table level.
	Enrichments []string `json:"enrichments,omitempty,omitzero"`

	// Name Name of the index
	Name string `json:"name"`

	// Type The type of the index.
	Type  IndexType `json:"type"`
	union json.RawMessage
}

// IndexStats Statistics for an index
type IndexStats struct {
	union json.RawMessage
}

// IndexStatus defines model for IndexStatus.
type IndexStatus struct {
	// Config Configuration for an index
	Config      IndexConfig           `json:"config"`
	ShardStatus map[string]IndexStats `json:"shard_status"`

	// Status Statistics for an index
	Status IndexStats `json:"status"`
}

// IndexType The type of the index.
type IndexType string

// KeyRange Key range processed in this request
type KeyRange struct {
	From string `json:"from,omitempty,omitzero"`
	To   string `json:"to,omitempty,omitzero"`
}

// LinearMergePageStatus Status of a linear merge page operation:
// - "success": All records in batch processed successfully
// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
// - "error": Fatal error occurred, no records processed successfully
type LinearMergePageStatus string

// LinearMergeRequest Linear merge operation for syncing sorted records from external sources.
// Use this to keep Antfly in sync with an external database or data source.
//
// **How it works:**
// 1. Send sorted records from your external source
// 2. Server upserts records that exist in your batch
// 3. Server deletes Antfly records in the key range that are absent from your batch
// 4. If stopped at shard boundary, use next_cursor for next request
//
// **WARNING:** Not safe for concurrent operations with overlapping key ranges.
type LinearMergeRequest struct {
	// DryRun If true, returns what would be deleted without making changes.
	//
	// Use cases:
	// - Validate sync behavior before committing
	// - Check which records will be removed
	// - Test key range boundaries
	//
	// Response includes deleted_ids array when dry_run=true.
	DryRun bool `json:"dry_run,omitempty,omitzero"`

	// LastMergedId ID of last record from previous merge request.
	// - First request: Use empty string ""
	// - Subsequent requests: Use next_cursor from previous response
	// - Defines lower bound of key range to process
	//
	// This enables pagination for large datasets.
	LastMergedId string `json:"last_merged_id,omitempty,omitzero"`

	// Records Map of resource ID to resource object: {"resource_id_1": {...}, "resource_id_2": {...}}
	//
	// Requirements:
	// - Keys must be sorted lexicographically by your client
	// - Server will process keys in sorted order
	// - Use consistent key naming (e.g., all start with same prefix)
	//
	// This format avoids duplicate IDs and matches Antfly's batch write interface.
	Records map[string]interface{} `json:"records"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write (slowest, most durable)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`
}

// LinearMergeResult defines model for LinearMergeResult.
type LinearMergeResult struct {
	// Deleted Records deleted or would be deleted (if dry_run=true)
	Deleted int `json:"deleted"`

	// DeletedIds IDs that were deleted (or would be deleted if dry_run=true). Only included if dry_run=true.
	DeletedIds []string          `json:"deleted_ids,omitempty,omitzero"`
	Failed     []FailedOperation `json:"failed,omitempty,omitzero"`

	// KeyRange Key range processed in this request
	KeyRange KeyRange `json:"key_range,omitempty,omitzero"`

	// KeysScanned Total number of keys scanned from Antfly during range query
	KeysScanned int `json:"keys_scanned,omitempty,omitzero"`

	// Message Additional information (e.g., "stopped at shard boundary", "dry run - no changes made")
	Message string `json:"message,omitempty,omitzero"`

	// NextCursor ID of last record in this batch (use for next request)
	NextCursor string `json:"next_cursor"`

	// Skipped Records skipped because content hash matched (unchanged)
	Skipped int `json:"skipped"`

	// Status Status of a linear merge page operation:
	// - "success": All records in batch processed successfully
	// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
	// - "error": Fatal error occurred, no records processed successfully
	Status LinearMergePageStatus `json:"status"`
	Took   time.Duration         `json:"took,omitempty,omitzero"`

	// Upserted Records inserted or updated (0 if dry_run=true)
	Upserted int `json:"upserted"`
}

// MatchAllQuery defines model for MatchAllQuery.
type MatchAllQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost                  `json:"boost,omitzero"`
	MatchAll map[string]interface{} `json:"match_all"`
}

// MatchNoneQuery defines model for MatchNoneQuery.
type MatchNoneQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost                  `json:"boost,omitzero"`
	MatchNone map[string]interface{} `json:"match_none"`
}

// MatchPhraseQuery defines model for MatchPhraseQuery.
type MatchPhraseQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness   Fuzziness `json:"fuzziness,omitempty,omitzero"`
	MatchPhrase string    `json:"match_phrase"`
}

// MatchQuery defines model for MatchQuery.
type MatchQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness          `json:"fuzziness,omitempty,omitzero"`
	Match        string             `json:"match"`
	Operator     MatchQueryOperator `json:"operator,omitempty,omitzero"`
	PrefixLength int32              `json:"prefix_length,omitempty,omitzero"`
}

// MatchQueryOperator defines model for MatchQuery.Operator.
type MatchQueryOperator string

// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
// failover: Use full_text_search if embedding generation fails
type MergeStrategy string

// MultiPhraseQuery defines model for MultiPhraseQuery.
type MultiPhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness  `json:"fuzziness,omitempty,omitzero"`
	Terms     [][]string `json:"terms"`
}

// NumericRange defines model for NumericRange.
type NumericRange struct {
	From *float64 `json:"from,omitempty"`
	Name string   `json:"name"`
	To   *float64 `json:"to,omitempty"`
}

// NumericRangeQuery defines model for NumericRangeQuery.
type NumericRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost   `json:"boost,omitzero"`
	Field        string  `json:"field,omitempty,omitzero"`
	InclusiveMax bool    `json:"inclusive_max,omitzero"`
	InclusiveMin bool    `json:"inclusive_min,omitzero"`
	Max          float64 `json:"max,omitzero"`
	Min          float64 `json:"min,omitzero"`
}

// NumericRangeResult defines model for NumericRangeResult.
type NumericRangeResult struct {
	Count int      `json:"count"`
	From  *float64 `json:"from,omitempty"`
	Name  string   `json:"name"`
	To    *float64 `json:"to,omitempty"`
}

// OllamaEmbedderConfig Configuration for the Ollama embedding provider.
type OllamaEmbedderConfig struct {
	// Model The name of the Ollama model to use.
	Model string `json:"model"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OllamaGeneratorConfig Configuration for the Ollama generative AI provider.
type OllamaGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Ollama model to use (e.g., 'llama3.2', 'llava').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIEmbedderConfig Configuration for the OpenAI embedding provider.
type OpenAIEmbedderConfig struct {
	// ApiKey The OpenAI API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Model The name of the OpenAI model to use.
	Model string `json:"model"`

	// Url The URL of the OpenAI API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIGeneratorConfig Configuration for the OpenAI generative AI provider.
type OpenAIGeneratorConfig struct {
	// ApiKey The OpenAI API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (-2.0 to 2.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the OpenAI model to use (e.g., 'gpt-4o', 'gpt-4-turbo').
	Model string `json:"model"`

	// PresencePenalty Penalty for token presence (-2.0 to 2.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the OpenAI API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// Path defines model for Path.
type Path struct {
	Edges  []PathEdge `json:"edges,omitempty,omitzero"`
	Length int        `json:"length,omitempty,omitzero"`

	// Nodes Ordered list of node keys (base64-encoded)
	Nodes       []string `json:"nodes,omitempty,omitzero"`
	TotalWeight float64  `json:"total_weight,omitempty,omitzero"`
}

// PathEdge defines model for PathEdge.
type PathEdge struct {
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`
	Source   string                 `json:"source,omitempty,omitzero"`
	Target   string                 `json:"target,omitempty,omitzero"`
	Type     string                 `json:"type,omitempty,omitzero"`
	Weight   float64                `json:"weight,omitempty,omitzero"`
}

// PathFindRequest defines model for PathFindRequest.
type PathFindRequest struct {
	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by specific edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`
	K         int      `json:"k,omitempty,omitzero"`
	MaxDepth  int      `json:"max_depth,omitempty,omitzero"`
	MaxWeight float64  `json:"max_weight,omitempty,omitzero"`
	MinWeight float64  `json:"min_weight,omitempty,omitzero"`

	// Source Source node key (base64-encoded)
	Source string `json:"source"`

	// Target Target node key (base64-encoded)
	Target string `json:"target"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindResult defines model for PathFindResult.
type PathFindResult struct {
	Paths        []Path  `json:"paths,omitempty,omitzero"`
	PathsFound   int     `json:"paths_found,omitempty,omitzero"`
	SearchTimeMs float64 `json:"search_time_ms,omitempty,omitzero"`
	Source       string  `json:"source,omitempty,omitzero"`
	Target       string  `json:"target,omitempty,omitzero"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindWeightMode Algorithm for path finding:
// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
// - max_weight: Path with maximum product of edge weights (strongest connection chain)
// - min_weight: Path with minimum sum of edge weights (lowest cost route)
type PathFindWeightMode string

// PathWeightMode Path weighting algorithm for pathfinding:
// - min_hops: Minimize number of edges
// - min_weight: Minimize sum of edge weights
// - max_weight: Maximize product of edge weights
type PathWeightMode string

// Permission defines model for Permission.
type Permission struct {
	// Resource Resource name (e.g., table name, target username, or '*' for global).
	Resource string `json:"resource"`

	// ResourceType Type of the resource, e.g., table, user, or global ('*').
	ResourceType ResourceType `json:"resource_type"`

	// Type Type of permission.
	Type PermissionType `json:"type"`
}

// PermissionType Type of permission.
type PermissionType string

// PhraseQuery defines model for PhraseQuery.
type PhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness `json:"fuzziness,omitempty,omitzero"`
	Terms     []string  `json:"terms"`
}

// PrefixQuery defines model for PrefixQuery.
type PrefixQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Prefix string `json:"prefix"`
}

// Query defines model for Query.
type Query struct {
	union json.RawMessage
}

// QueryHit A single query result hit
type QueryHit struct {
	// ID ID of the record.
	ID string `json:"_id"`

	// IndexScores Scores partitioned by index when using RRF search.
	IndexScores map[string]interface{} `json:"_index_scores,omitempty,omitzero"`

	// Score Relevance score of the hit.
	Score  float64                `json:"_score"`
	Source map[string]interface{} `json:"_source,omitempty,omitzero"`
}

// QueryHits A list of query hits.
type QueryHits struct {
	Hits []QueryHit `json:"hits"`

	// MaxScore Maximum score of the results.
	MaxScore float64 `json:"max_score,omitempty,omitzero"`

	// Total Total number of hits available.
	Total uint64 `json:"total,omitempty"`
}

// QueryRequest defines model for QueryRequest.
type QueryRequest struct {
	Analyses *Analyses `json:"analyses,omitempty"`

	// Count If true, returns only the total count of matching documents without retrieving the actual documents.
	// Useful for pagination and displaying result counts.
	Count bool `json:"count,omitempty,omitzero"`

	// DistanceOver Minimum distance threshold for semantic similarity search. Results with distance
	// less than this value are excluded.
	//
	// Useful for excluding near-exact duplicates or finding dissimilar documents.
	DistanceOver *float32 `json:"distance_over,omitempty"`

	// DistanceUnder Maximum distance threshold for semantic similarity search. Results with distance
	// greater than this value are excluded. Lower distances indicate higher similarity.
	//
	// Useful for filtering out low-confidence matches.
	DistanceUnder *float32 `json:"distance_under,omitempty"`

	// DocumentRenderer Optional Handlebars template string for rendering document content in RAG queries.
	// Template has access to document fields via `{{this.fields.fieldName}}`.
	//
	// Useful for customizing how documents are presented to LLMs in RAG pipelines.
	DocumentRenderer string `json:"document_renderer,omitempty,omitzero"`

	// Embeddings Pre-computed embeddings to use for semantic searches instead of embedding the semantic_search string.
	// The keys are the index names, and values are the embedding vectors.
	//
	// Use when you've already generated embeddings on the client side to avoid redundant embedding calls.
	Embeddings map[string][]float32 `json:"embeddings,omitempty,omitzero"`

	// ExclusionQuery Bleve query applied as a NOT condition. Documents matching this query are excluded
	// from results. Applied before scoring.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Excluding drafts: `"status:draft"`
	// - Removing deprecated content: `"deprecated:true"`
	// - Filtering out archived items: `"status:archived"`
	ExclusionQuery json.RawMessage `json:"exclusion_query,omitempty,omitzero"`

	// ExpandStrategy Strategy for merging graph results with search results:
	// - union: Include nodes from both search and graph results
	// - intersection: Only include nodes appearing in both
	ExpandStrategy QueryRequestExpandStrategy `json:"expand_strategy,omitempty,omitzero"`

	// Facets Faceting configuration for aggregating results by field values.
	// Useful for building faceted navigation and filters.
	Facets map[string]FacetOption `json:"facets,omitempty,omitzero"`

	// Fields List of fields to include in the results. If not specified, all fields are returned.
	// Use to reduce response size and improve performance.
	Fields []string `json:"fields,omitempty,omitzero"`

	// FilterPrefix Filter results by key prefix. Only returns documents whose keys start with this string.
	// Applied before scoring to improve performance.
	//
	// Common use cases:
	// - Multi-tenant filtering: `"tenant:acme:"`
	// - User-specific data: `"user:123:"`
	// - Document type filtering: `"article:"`
	FilterPrefix []byte `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query applied as an AND condition. Documents must match both the main query
	// and this filter. Applied before scoring for better performance.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Status filtering: `"status:published"`
	// - Date ranges: `"created_at:>2023-01-01"`
	// - Category filtering: `"category:technology AND language:en"`
	FilterQuery json.RawMessage `json:"filter_query,omitempty,omitzero"`

	// FullTextSearch Bleve query for full-text search. Supports all Bleve query types.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Examples:
	// - Simple: `{"query": "computer"}`
	// - Field-specific: `{"query": "body:computer"}`
	// - Boolean: `{"query": "artificial AND intelligence"}`
	// - Range: `{"query": "year:>2020"}`
	// - Phrase: `{"query": "\"exact phrase\""}`
	FullTextSearch json.RawMessage `json:"full_text_search,omitempty,omitzero"`

	// GraphSearches Declarative graph queries to execute after full-text/vector searches.
	// Results can reference search results using node selectors like $full_text_results.
	GraphSearches map[string]GraphQuery `json:"graph_searches,omitempty,omitzero"`

	// Indexes List of vector index names to use for semantic search. Required when using semantic_search.
	// Multiple indexes can be specified, and their results will be merged using RRF.
	Indexes []string `json:"indexes,omitempty,omitzero"`

	// Limit Maximum number of results to return. For semantic_search, this is the topk parameter.
	// Default varies by query type (typically 10).
	Limit int `json:"limit,omitempty,omitzero"`

	// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
	// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
	// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
	// failover: Use full_text_search if embedding generation fails
	MergeStrategy MergeStrategy `json:"merge_strategy,omitempty,omitzero"`

	// Offset Number of results to skip for pagination. Only available for full_text_search queries.
	// Not supported for semantic_search due to vector index limitations.
	Offset int `json:"offset,omitempty,omitzero"`

	// OrderBy Sort order for results. Map of field names to boolean (true = descending, false = ascending).
	// Only applicable for full_text_search queries. Semantic searches are always sorted by similarity score.
	OrderBy map[string]bool `json:"order_by,omitempty,omitzero"`

	// Reranker A unified configuration for an embedding provider.
	Reranker *RerankerConfig `json:"reranker,omitempty"`

	// ReturnChunks Controls whether to search and return chunk documents in addition to original documents.
	// When true (default): Searches both original documents and chunks, returns chunks in results.
	// When false: Only searches original documents, excludes chunks from results.
	//
	// Use false when you want to search only the original full documents without their chunked versions.
	ReturnChunks *bool `json:"return_chunks,omitempty"`

	// SemanticSearch Natural language query for vector similarity search. Results are ranked by semantic similarity
	// to the query and can be combined with full_text_search using Reciprocal Rank Fusion (RRF).
	//
	// The semantic_search string is automatically embedded using the configured embedding model
	// for the specified indexes.
	SemanticSearch string `json:"semantic_search,omitempty,omitzero"`

	// Table Name of the table to query. Optional for global queries.
	Table string `json:"table,omitempty,omitzero"`
}

// QueryRequestExpandStrategy Strategy for merging graph results with search results:
// - union: Include nodes from both search and graph results
// - intersection: Only include nodes appearing in both
type QueryRequestExpandStrategy string

// QueryResponses Responses from multiple query operations.
type QueryResponses struct {
	Responses []QueryResult `json:"responses,omitempty,omitzero"`
}

// QueryResult Result of a query operation as an array of results and a count.
type QueryResult struct {
	// Analyses Analysis results like PCA and t-SNE per index embeddings.
	Analyses map[string]AnalysesResult `json:"analyses,omitempty,omitzero"`

	// Error Error message if the query failed.
	Error  string                 `json:"error,omitempty,omitzero"`
	Facets map[string]FacetResult `json:"facets,omitempty,omitzero"`

	// GraphResults Results from declarative graph queries.
	GraphResults map[string]GraphQueryResult `json:"graph_results,omitempty,omitzero"`

	// Hits A list of query hits.
	Hits QueryHits `json:"hits"`

	// Status HTTP status code of the query operation.
	Status int32 `json:"status"`

	// Table Which table this result came from
	Table string `json:"table,omitempty,omitzero"`

	// Took Duration of the query in milliseconds.
	Took time.Duration `json:"took"`
}

// QueryStringQuery defines model for QueryStringQuery.
type QueryStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Query string `json:"query"`
}

// RAGRequest defines model for RAGRequest.
type RAGRequest struct {
	// Prompt Optional custom user prompt template for the LLM. If not provided, a default prompt is used.
	// The prompt can reference the following variables:
	// - {{documents}}: Array of retrieved documents with id and fields
	// - {{semantic_search}}: The user's semantic search query (if provided)
	// You can use Handlebars template syntax to customize the prompt, including loops and conditionals.
	// To generate a comma-separated list of document IDs, use: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	Prompt string `json:"prompt,omitempty,omitzero"`

	// Queries Array of retrieval queries to execute. Each query must specify a table and can specify its own limit and document_renderer.
	// Results from all queries are concatenated together (respecting each query's limit).
	// For single table: [{"table": "papers", "semantic_search": "...", "limit": 10}]
	// For broadcast: [{"table": "images", "limit": 5, ...}, {"table": "products", "limit": 5, ...}]
	// For mixed: [{"table": "papers", "semantic_search": "...", "limit": 10}, {"table": "books", "full_text_search": {...}, "limit": 5}]
	Queries []QueryRequest `json:"queries"`

	// Summarizer A unified configuration for a generative AI provider.
	Summarizer GeneratorConfig `json:"summarizer"`

	// SystemPrompt Optional system prompt to guide the summarization
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// RAGResult RAG result with individual query results and summary
type RAGResult struct {
	// QueryResults Results from each query. Check each result's status and error fields for failures.
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`

	// SummaryResult Result of a summarization operation. The summary is formatted as markdown with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
	SummaryResult SummarizeResult `json:"summary_result,omitempty,omitzero"`
}

// RegexpQuery defines model for RegexpQuery.
type RegexpQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Regexp string `json:"regexp"`
}

// RerankerConfig defines model for RerankerConfig.
type RerankerConfig struct {
	Field string `json:"field,omitempty,omitzero"`

	// Provider The embedding provider to use.
	Provider EmbedderProvider `json:"provider"`
	Template string           `json:"template,omitempty,omitzero"`
	union    json.RawMessage
}

// ResourceType Type of the resource, e.g., table, user, or global ('*').
type ResourceType string

// RestoreRequest defines model for RestoreRequest.
type RestoreRequest = BackupRequest

// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
type RouteType string

// ShardConfig defines model for ShardConfig.
type ShardConfig struct {
	ByteRange ByteRange `json:"byte_range"`
}

// StorageStatus defines model for StorageStatus.
type StorageStatus struct {
	// DiskUsage Disk usage in bytes.
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Empty Whether the table has received data.
	Empty bool `json:"empty,omitempty,omitzero"`
}

// SuccessMessage defines model for SuccessMessage.
type SuccessMessage struct {
	Message string `json:"message,omitempty,omitzero"`
}

// SummarizeResult Result of a summarization operation. The summary is formatted as markdown with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
type SummarizeResult struct {
	// Summary The generated summary text in markdown format with inline resource references like [resource_id res1] or [resource_id res1, res2]
	Summary string `json:"summary"`
}

// SyncLevel Synchronization level for batch operations:
// - "propose": Wait for Raft proposal acceptance (fastest, default)
// - "write": Wait for Pebble KV write
// - "full_text": Wait for full-text index WAL write (slowest, most durable)
// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout)
type SyncLevel string

// Table defines model for Table.
type Table struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema            `json:"schema,omitempty,omitzero"`
	Shards map[string]ShardConfig `json:"shards"`
}

// TableSchema Schema definition for a table with multiple document types
type TableSchema struct {
	// DefaultType Default type to use from the document_types.
	DefaultType string `json:"default_type,omitempty,omitzero"`

	// DocumentSchemas A map of type names to their document json schemas.
	DocumentSchemas map[string]DocumentSchema `json:"document_schemas,omitempty,omitzero"`

	// EnforceTypes Whether to enforce that documents must match one of the provided document types.
	// If false, documents not matching any type will be accepted but not indexed.
	EnforceTypes bool `json:"enforce_types,omitempty,omitzero"`

	// TtlDuration The duration after which documents should expire, based on the ttl_field timestamp (optional).
	// Uses Go duration format (e.g., '24h', '7d', '168h').
	TtlDuration string `json:"ttl_duration,omitempty,omitzero"`

	// TtlField The field containing the timestamp for TTL expiration (optional).
	// Defaults to "_timestamp" if ttl_duration is specified but ttl_field is not.
	TtlField string `json:"ttl_field,omitempty,omitzero"`

	// Version Version of the schema. Used for migrations.
	Version uint32 `json:"version,omitempty,omitzero"`
}

// TableStatus defines model for TableStatus.
type TableStatus struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema        TableSchema            `json:"schema,omitempty,omitzero"`
	Shards        map[string]ShardConfig `json:"shards"`
	StorageStatus StorageStatus          `json:"storage_status"`
}

// TermFacetResult defines model for TermFacetResult.
type TermFacetResult struct {
	Count int    `json:"count"`
	Term  string `json:"term"`
}

// TermQuery defines model for TermQuery.
type TermQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
	Term  string `json:"term"`
}

// TermRangeQuery defines model for TermRangeQuery.
type TermRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost  `json:"boost,omitzero"`
	Field        string `json:"field,omitempty,omitzero"`
	InclusiveMax bool   `json:"inclusive_max,omitzero"`
	InclusiveMin bool   `json:"inclusive_min,omitzero"`
	Max          string `json:"max,omitzero"`
	Min          string `json:"min,omitzero"`
}

// TermiteChunkerConfig Configuration for the Termite chunking provider.
//
// Termite is a centralized HTTP service that provides chunking with multi-tier caching.
// It supports multiple chunking strategies similar to how generators support different models.
//
// **Chunking Strategies:**
// - hugot: ONNX-accelerated chunking using sentence boundary detection
// - fixed: Simple fixed-size chunking by token count (default, no ONNX required)
//
// **Caching:**
// - L1: Memory cache with 2-minute TTL
// - L2: Persistent Pebble database
// - Singleflight deduplication for concurrent identical requests
type TermiteChunkerConfig struct {
	// ApiUrl The URL of the Termite API endpoint (e.g., 'http://localhost:8080'). Can also be set via ANTFLY_TERMITE_URL environment variable.
	ApiUrl string `json:"api_url,omitempty,omitzero"`

	// FullText Configuration for full-text indexing of chunks in Bleve.
	// When present (even if empty), chunks will be stored with :cft: suffix and indexed in Bleve's _chunks field.
	// When absent, chunks use :c: suffix and are only used for vector embeddings.
	// This object is reserved for future options like boosting, field mapping, etc.
	FullText map[string]interface{} `json:"full_text,omitempty,omitzero"`

	// MaxChunks Maximum number of chunks to generate per document. Prevents excessive chunking of very large documents.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs). Only used with fixed strategy.
	Separator string `json:"separator,omitempty,omitzero"`

	// Strategy Document chunking strategy.
	// - hugot: ONNX-accelerated chunking using sentence boundary detection
	// - fixed: Simple fixed-size chunking by token count
	Strategy ChunkingStrategy `json:"strategy"`

	// TargetTokens Target number of tokens per chunk. Chunker will aim for chunks around this size.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`

	// Threshold Minimum confidence threshold for separator detection. Only used with hugot strategy.
	Threshold float32 `json:"threshold,omitempty,omitzero"`
}

// Transform In-place document transformation using MongoDB-style operators. Transforms are applied atomically
// at the storage layer, eliminating read-modify-write races.
//
// **Important:** Transform results are NOT validated against the table schema. This improves performance
// but means it's possible to create invalid documents. Use with care and ensure your operations maintain
// schema compliance.
type Transform struct {
	// Key Document key (must be a string, not an object like inserts)
	Key string `json:"key"`

	// Operations List of operations to apply in sequence
	Operations []TransformOp `json:"operations"`

	// Upsert If true, create document if it doesn't exist (like MongoDB upsert)
	Upsert bool `json:"upsert,omitempty,omitzero"`
}

// TransformOp defines model for TransformOp.
type TransformOp struct {
	// Op MongoDB-style update operator
	Op TransformOpType `json:"op"`

	// Path JSONPath to field (e.g., "$.user.name", "$.tags", or "user.name")
	Path string `json:"path"`

	// Value Value for operation (not required for $unset, $currentDate). Type depends on operator (number for $inc/$mul, any for $set, etc.)
	Value interface{} `json:"value,omitempty,omitzero"`
}

// TransformOpType MongoDB-style update operator
type TransformOpType string

// TraversalResult A single result from graph traversal
type TraversalResult struct {
	// Depth Distance from start node (0 = start node)
	Depth int `json:"depth"`

	// Document Document data (if loaded)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Key Base64-encoded document key
	Key []byte `json:"key"`

	// Path Sequence of keys from start to this node (if include_paths=true)
	Path [][]byte `json:"path,omitempty,omitzero"`

	// PathEdges Sequence of edges from start to this node (if include_paths=true)
	PathEdges []Edge `json:"path_edges,omitempty,omitzero"`

	// TotalWeight Product of edge weights along the path
	TotalWeight float64 `json:"total_weight,omitempty,omitzero"`
}

// TraversalRules Rules for graph traversal
type TraversalRules struct {
	// DeduplicateNodes Visit each node only once
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter edges by type (empty = all types)
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information in results
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth (0 = unlimited)
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum results to return (0 = unlimited)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight filter
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight filter
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`
}

// TraverseResponse defines model for TraverseResponse.
type TraverseResponse struct {
	// Count Total number of results
	Count   int               `json:"count,omitempty,omitzero"`
	Results []TraversalResult `json:"results,omitempty,omitzero"`
}

// UpdatePasswordRequest defines model for UpdatePasswordRequest.
type UpdatePasswordRequest struct {
	NewPassword string `json:"new_password"`
}

// User defines model for User.
type User struct {
	// PasswordHash Base64 encoded password hash. Exposing this is a security risk.
	PasswordHash []byte `json:"password_hash"`
	Username     string `json:"username"`
}

// UserContext Optional user context to customize the content guidance for each section of the answer agent response.
//
// **What you can customize**: Style, tone, length, detail level, and focus of content for each section independently.
//
// **What is fixed**: The response format is always markdown with consistent structure (## Reasoning, ## Answer, ## Follow-up Questions).
// Markdown formatting (headings, bullets, code blocks, etc.) is always applied and cannot be disabled.
//
// **Architecture**: These contexts are passed as template variables to the prompt template. Defaults are set
// at the application layer, and users can override them via this API to customize content guidance.
type UserContext struct {
	// AnswerContext Custom content guidance for the answer section. Controls the tone, content depth, level of detail,
	// and what information to emphasize. Does not control markdown formatting (which is always applied).
	AnswerContext string `json:"answer_context,omitempty,omitzero"`

	// FollowupContext Custom content guidance for follow-up questions. Controls the quantity, focus area, tone,
	// and style of follow-up questions. Does not control markdown formatting.
	FollowupContext string `json:"followup_context,omitempty,omitzero"`

	// ReasoningContext Custom content guidance for the reasoning section. Controls what information to include,
	// the level of detail, and the focus of the reasoning process. Does not control markdown formatting.
	ReasoningContext string `json:"reasoning_context,omitempty,omitzero"`
}

// VertexEmbedderConfig Configuration for Google Cloud Vertex AI embedding models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication by default.
// Suitable for production deployments on Google Cloud Platform.
//
// **Authentication Priority:**
// 1. credentials_path (path to service account key file)
// 2. GOOGLE_APPLICATION_CREDENTIALS environment variable
// 3. Application Default Credentials (ADC) - RECOMMENDED
//   - In GCP: automatic (Cloud Run, GKE, Compute Engine)
//   - Local dev: `gcloud auth application-default login`
//
// **Required IAM Permission:** `roles/aiplatform.user`
//
// **Supported Models:**
// - text-embedding-004 (latest, 768 dimensions)
// - textembedding-gecko@003, @002, @001 (legacy)
// - textembedding-gecko-multilingual@001 (multilingual support)
// - text-multilingual-embedding-002 (multilingual, 768 dimensions)
// - multimodalembedding (images, audio, video - 128/256/512/1408 dimensions)
type VertexEmbedderConfig struct {
	// CredentialsPath Path to service account JSON key file. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Dimension The dimension of the embedding vector. Model-specific (e.g., 768 for text-embedding-004, 128-1408 for multimodalembedding).
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the Vertex AI embedding model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`
}

// VertexGeneratorConfig Configuration for Google Cloud Vertex AI generative models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication by default.
// Suitable for production deployments on Google Cloud Platform.
//
// **Authentication Priority:**
// 1. credentials_path (path to service account key file)
// 2. GOOGLE_APPLICATION_CREDENTIALS environment variable
// 3. Application Default Credentials (ADC) - RECOMMENDED
//   - In GCP: automatic (Cloud Run, GKE, Compute Engine)
//   - Local dev: `gcloud auth application-default login`
//
// **Note:** credentials_json is not supported by the genkit VertexAI plugin.
// Use credentials_path or ADC instead.
//
// **Required IAM Permission:** `roles/aiplatform.user`
//
// **Supported Models:**
// - gemini-2.5-flash (default, fast and efficient)
// - gemini-1.5-pro (balanced performance)
// - gemini-1.5-flash (cost-effective)
// - gemini-2.0-pro (advanced reasoning)
//
// Defaults to gemini-2.5-flash if no model is specified.
type VertexGeneratorConfig struct {
	// CredentialsPath Path to service account JSON key file. Sets GOOGLE_APPLICATION_CREDENTIALS environment variable. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Vertex AI model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// WildcardQuery defines model for WildcardQuery.
type WildcardQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Field    string `json:"field,omitempty,omitzero"`
	Wildcard string `json:"wildcard"`
}

// UserNamePathParameter defines model for UserNamePathParameter.
type UserNamePathParameter = string

// BadRequest defines model for BadRequest.
type BadRequest = Error

// InternalServerError defines model for InternalServerError.
type InternalServerError = Error

// NotFound defines model for NotFound.
type NotFound = Error

// ListTablesParams defines parameters for ListTables.
type ListTablesParams struct {
	// Prefix Filter tables by name prefix (e.g., "prod_")
	Prefix string `form:"prefix,omitempty" json:"prefix,omitempty,omitzero"`

	// Pattern Filter tables by regex pattern (e.g., "^prod_.*_v[0-9]+$")
	Pattern string `form:"pattern,omitempty" json:"pattern,omitempty,omitzero"`
}

// RemovePermissionFromUserParams defines parameters for RemovePermissionFromUser.
type RemovePermissionFromUserParams struct {
	// Resource The name of the resource for the permission to be removed.
	Resource string `form:"resource" json:"resource"`

	// ResourceType The type of the resource for the permission to be removed.
	ResourceType ResourceType `form:"resourceType" json:"resourceType"`
}

// AnswerAgentJSONRequestBody defines body for AnswerAgent for application/json ContentType.
type AnswerAgentJSONRequestBody = AnswerAgentRequest

// GlobalQueryJSONRequestBody defines body for GlobalQuery for application/json ContentType.
type GlobalQueryJSONRequestBody = QueryRequest

// RagQueryJSONRequestBody defines body for RagQuery for application/json ContentType.
type RagQueryJSONRequestBody = RAGRequest

// CreateTableJSONRequestBody defines body for CreateTable for application/json ContentType.
type CreateTableJSONRequestBody = CreateTableRequest

// BackupTableJSONRequestBody defines body for BackupTable for application/json ContentType.
type BackupTableJSONRequestBody = BackupRequest

// BatchJSONRequestBody defines body for Batch for application/json ContentType.
type BatchJSONRequestBody = BatchRequest

// CreateIndexJSONRequestBody defines body for CreateIndex for application/json ContentType.
type CreateIndexJSONRequestBody = IndexConfig

// LinearMergeJSONRequestBody defines body for LinearMerge for application/json ContentType.
type LinearMergeJSONRequestBody = LinearMergeRequest

// QueryTableJSONRequestBody defines body for QueryTable for application/json ContentType.
type QueryTableJSONRequestBody = QueryRequest

// TableRagQueryJSONRequestBody defines body for TableRagQuery for application/json ContentType.
type TableRagQueryJSONRequestBody = RAGRequest

// RestoreTableJSONRequestBody defines body for RestoreTable for application/json ContentType.
type RestoreTableJSONRequestBody = RestoreRequest

// UpdateSchemaJSONRequestBody defines body for UpdateSchema for application/json ContentType.
type UpdateSchemaJSONRequestBody = TableSchema

// CreateUserJSONRequestBody defines body for CreateUser for application/json ContentType.
type CreateUserJSONRequestBody = CreateUserRequest

// UpdateUserPasswordJSONRequestBody defines body for UpdateUserPassword for application/json ContentType.
type UpdateUserPasswordJSONRequestBody = UpdatePasswordRequest

// AddPermissionToUserJSONRequestBody defines body for AddPermissionToUser for application/json ContentType.
type AddPermissionToUserJSONRequestBody = Permission

// Getter for additional properties for ClusterStatus. Returns the specified
// element and whether it was found
func (a ClusterStatus) Get(fieldName string) (value interface{}, found bool) {
	if a.AdditionalProperties != nil {
		value, found = a.AdditionalProperties[fieldName]
	}
	return
}

// Setter for additional properties for ClusterStatus
func (a *ClusterStatus) Set(fieldName string, value interface{}) {
	if a.AdditionalProperties == nil {
		a.AdditionalProperties = make(map[string]interface{})
	}
	a.AdditionalProperties[fieldName] = value
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a *ClusterStatus) UnmarshalJSON(b []byte) error {
	object := make(map[string]json.RawMessage)
	err := json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["auth_enabled"]; found {
		err = json.Unmarshal(raw, &a.AuthEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'auth_enabled': %w", err)
		}
		delete(object, "auth_enabled")
	}

	if raw, found := object["health"]; found {
		err = json.Unmarshal(raw, &a.Health)
		if err != nil {
			return fmt.Errorf("error reading 'health': %w", err)
		}
		delete(object, "health")
	}

	if raw, found := object["message"]; found {
		err = json.Unmarshal(raw, &a.Message)
		if err != nil {
			return fmt.Errorf("error reading 'message': %w", err)
		}
		delete(object, "message")
	}

	if len(object) != 0 {
		a.AdditionalProperties = make(map[string]interface{})
		for fieldName, fieldBuf := range object {
			var fieldVal interface{}
			err := json.Unmarshal(fieldBuf, &fieldVal)
			if err != nil {
				return fmt.Errorf("error unmarshaling field %s: %w", fieldName, err)
			}
			a.AdditionalProperties[fieldName] = fieldVal
		}
	}
	return nil
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a ClusterStatus) MarshalJSON() ([]byte, error) {
	var err error
	object := make(map[string]json.RawMessage)

	object["auth_enabled"], err = json.Marshal(a.AuthEnabled)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'auth_enabled': %w", err)
	}

	object["health"], err = json.Marshal(a.Health)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'health': %w", err)
	}

	object["message"], err = json.Marshal(a.Message)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'message': %w", err)
	}

	for fieldName, field := range a.AdditionalProperties {
		object[fieldName], err = json.Marshal(field)
		if err != nil {
			return nil, fmt.Errorf("error marshaling '%s': %w", fieldName, err)
		}
	}
	return json.Marshal(object)
}

// AsTermiteChunkerConfig returns the union data inside the ChunkerConfig as a TermiteChunkerConfig
func (t ChunkerConfig) AsTermiteChunkerConfig() (TermiteChunkerConfig, error) {
	var body TermiteChunkerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteChunkerConfig overwrites any union data inside the ChunkerConfig as the provided TermiteChunkerConfig
func (t *ChunkerConfig) FromTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteChunkerConfig performs a merge with any union data inside the ChunkerConfig, using the provided TermiteChunkerConfig
func (t *ChunkerConfig) MergeTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t ChunkerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *ChunkerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsGoogleEmbedderConfig returns the union data inside the EmbedderConfig as a GoogleEmbedderConfig
func (t EmbedderConfig) AsGoogleEmbedderConfig() (GoogleEmbedderConfig, error) {
	var body GoogleEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided GoogleEmbedderConfig
func (t *EmbedderConfig) FromGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided GoogleEmbedderConfig
func (t *EmbedderConfig) MergeGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexEmbedderConfig returns the union data inside the EmbedderConfig as a VertexEmbedderConfig
func (t EmbedderConfig) AsVertexEmbedderConfig() (VertexEmbedderConfig, error) {
	var body VertexEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided VertexEmbedderConfig
func (t *EmbedderConfig) FromVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided VertexEmbedderConfig
func (t *EmbedderConfig) MergeVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaEmbedderConfig returns the union data inside the EmbedderConfig as a OllamaEmbedderConfig
func (t EmbedderConfig) AsOllamaEmbedderConfig() (OllamaEmbedderConfig, error) {
	var body OllamaEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OllamaEmbedderConfig
func (t *EmbedderConfig) FromOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OllamaEmbedderConfig
func (t *EmbedderConfig) MergeOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIEmbedderConfig returns the union data inside the EmbedderConfig as a OpenAIEmbedderConfig
func (t EmbedderConfig) AsOpenAIEmbedderConfig() (OpenAIEmbedderConfig, error) {
	var body OpenAIEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) FromOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) MergeOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockEmbedderConfig returns the union data inside the EmbedderConfig as a BedrockEmbedderConfig
func (t EmbedderConfig) AsBedrockEmbedderConfig() (BedrockEmbedderConfig, error) {
	var body BedrockEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided BedrockEmbedderConfig
func (t *EmbedderConfig) FromBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided BedrockEmbedderConfig
func (t *EmbedderConfig) MergeBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t EmbedderConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *EmbedderConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsFuzziness0 returns the union data inside the Fuzziness as a Fuzziness0
func (t Fuzziness) AsFuzziness0() (Fuzziness0, error) {
	var body Fuzziness0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness0 overwrites any union data inside the Fuzziness as the provided Fuzziness0
func (t *Fuzziness) FromFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness0 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness0
func (t *Fuzziness) MergeFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzziness1 returns the union data inside the Fuzziness as a Fuzziness1
func (t Fuzziness) AsFuzziness1() (Fuzziness1, error) {
	var body Fuzziness1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness1 overwrites any union data inside the Fuzziness as the provided Fuzziness1
func (t *Fuzziness) FromFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness1 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness1
func (t *Fuzziness) MergeFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Fuzziness) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Fuzziness) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsGoogleGeneratorConfig returns the union data inside the GeneratorConfig as a GoogleGeneratorConfig
func (t GeneratorConfig) AsGoogleGeneratorConfig() (GoogleGeneratorConfig, error) {
	var body GoogleGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided GoogleGeneratorConfig
func (t *GeneratorConfig) FromGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided GoogleGeneratorConfig
func (t *GeneratorConfig) MergeGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexGeneratorConfig returns the union data inside the GeneratorConfig as a VertexGeneratorConfig
func (t GeneratorConfig) AsVertexGeneratorConfig() (VertexGeneratorConfig, error) {
	var body VertexGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided VertexGeneratorConfig
func (t *GeneratorConfig) FromVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided VertexGeneratorConfig
func (t *GeneratorConfig) MergeVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaGeneratorConfig returns the union data inside the GeneratorConfig as a OllamaGeneratorConfig
func (t GeneratorConfig) AsOllamaGeneratorConfig() (OllamaGeneratorConfig, error) {
	var body OllamaGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OllamaGeneratorConfig
func (t *GeneratorConfig) FromOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OllamaGeneratorConfig
func (t *GeneratorConfig) MergeOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIGeneratorConfig returns the union data inside the GeneratorConfig as a OpenAIGeneratorConfig
func (t GeneratorConfig) AsOpenAIGeneratorConfig() (OpenAIGeneratorConfig, error) {
	var body OpenAIGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) FromOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) MergeOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockGeneratorConfig returns the union data inside the GeneratorConfig as a BedrockGeneratorConfig
func (t GeneratorConfig) AsBedrockGeneratorConfig() (BedrockGeneratorConfig, error) {
	var body BedrockGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided BedrockGeneratorConfig
func (t *GeneratorConfig) FromBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided BedrockGeneratorConfig
func (t *GeneratorConfig) MergeBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAnthropicGeneratorConfig returns the union data inside the GeneratorConfig as a AnthropicGeneratorConfig
func (t GeneratorConfig) AsAnthropicGeneratorConfig() (AnthropicGeneratorConfig, error) {
	var body AnthropicGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAnthropicGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) FromAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAnthropicGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) MergeAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t GeneratorConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *GeneratorConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Config returns the union data inside the IndexConfig as a BleveIndexV2Config
func (t IndexConfig) AsBleveIndexV2Config() (BleveIndexV2Config, error) {
	var body BleveIndexV2Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Config overwrites any union data inside the IndexConfig as the provided BleveIndexV2Config
func (t *IndexConfig) FromBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Config performs a merge with any union data inside the IndexConfig, using the provided BleveIndexV2Config
func (t *IndexConfig) MergeBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexConfig returns the union data inside the IndexConfig as a EmbeddingIndexConfig
func (t IndexConfig) AsEmbeddingIndexConfig() (EmbeddingIndexConfig, error) {
	var body EmbeddingIndexConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexConfig overwrites any union data inside the IndexConfig as the provided EmbeddingIndexConfig
func (t *IndexConfig) FromEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexConfig performs a merge with any union data inside the IndexConfig, using the provided EmbeddingIndexConfig
func (t *IndexConfig) MergeEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Config returns the union data inside the IndexConfig as a GraphIndexV0Config
func (t IndexConfig) AsGraphIndexV0Config() (GraphIndexV0Config, error) {
	var body GraphIndexV0Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Config overwrites any union data inside the IndexConfig as the provided GraphIndexV0Config
func (t *IndexConfig) FromGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Config performs a merge with any union data inside the IndexConfig, using the provided GraphIndexV0Config
func (t *IndexConfig) MergeGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["description"], err = json.Marshal(t.Description)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'description': %w", err)
	}

	object["enrichments"], err = json.Marshal(t.Enrichments)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'enrichments': %w", err)
	}

	object["name"], err = json.Marshal(t.Name)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'name': %w", err)
	}

	object["type"], err = json.Marshal(t.Type)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'type': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *IndexConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["description"]; found {
		err = json.Unmarshal(raw, &t.Description)
		if err != nil {
			return fmt.Errorf("error reading 'description': %w", err)
		}
	}

	if raw, found := object["enrichments"]; found {
		err = json.Unmarshal(raw, &t.Enrichments)
		if err != nil {
			return fmt.Errorf("error reading 'enrichments': %w", err)
		}
	}

	if raw, found := object["name"]; found {
		err = json.Unmarshal(raw, &t.Name)
		if err != nil {
			return fmt.Errorf("error reading 'name': %w", err)
		}
	}

	if raw, found := object["type"]; found {
		err = json.Unmarshal(raw, &t.Type)
		if err != nil {
			return fmt.Errorf("error reading 'type': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Stats returns the union data inside the IndexStats as a BleveIndexV2Stats
func (t IndexStats) AsBleveIndexV2Stats() (BleveIndexV2Stats, error) {
	var body BleveIndexV2Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Stats overwrites any union data inside the IndexStats as the provided BleveIndexV2Stats
func (t *IndexStats) FromBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Stats performs a merge with any union data inside the IndexStats, using the provided BleveIndexV2Stats
func (t *IndexStats) MergeBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexStats returns the union data inside the IndexStats as a EmbeddingIndexStats
func (t IndexStats) AsEmbeddingIndexStats() (EmbeddingIndexStats, error) {
	var body EmbeddingIndexStats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexStats overwrites any union data inside the IndexStats as the provided EmbeddingIndexStats
func (t *IndexStats) FromEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexStats performs a merge with any union data inside the IndexStats, using the provided EmbeddingIndexStats
func (t *IndexStats) MergeEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Stats returns the union data inside the IndexStats as a GraphIndexV0Stats
func (t IndexStats) AsGraphIndexV0Stats() (GraphIndexV0Stats, error) {
	var body GraphIndexV0Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Stats overwrites any union data inside the IndexStats as the provided GraphIndexV0Stats
func (t *IndexStats) FromGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Stats performs a merge with any union data inside the IndexStats, using the provided GraphIndexV0Stats
func (t *IndexStats) MergeGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexStats) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *IndexStats) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsTermQuery returns the union data inside the Query as a TermQuery
func (t Query) AsTermQuery() (TermQuery, error) {
	var body TermQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermQuery overwrites any union data inside the Query as the provided TermQuery
func (t *Query) FromTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermQuery performs a merge with any union data inside the Query, using the provided TermQuery
func (t *Query) MergeTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchQuery returns the union data inside the Query as a MatchQuery
func (t Query) AsMatchQuery() (MatchQuery, error) {
	var body MatchQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchQuery overwrites any union data inside the Query as the provided MatchQuery
func (t *Query) FromMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchQuery performs a merge with any union data inside the Query, using the provided MatchQuery
func (t *Query) MergeMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchPhraseQuery returns the union data inside the Query as a MatchPhraseQuery
func (t Query) AsMatchPhraseQuery() (MatchPhraseQuery, error) {
	var body MatchPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchPhraseQuery overwrites any union data inside the Query as the provided MatchPhraseQuery
func (t *Query) FromMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchPhraseQuery performs a merge with any union data inside the Query, using the provided MatchPhraseQuery
func (t *Query) MergeMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPhraseQuery returns the union data inside the Query as a PhraseQuery
func (t Query) AsPhraseQuery() (PhraseQuery, error) {
	var body PhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPhraseQuery overwrites any union data inside the Query as the provided PhraseQuery
func (t *Query) FromPhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePhraseQuery performs a merge with any union data inside the Query, using the provided PhraseQuery
func (t *Query) MergePhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMultiPhraseQuery returns the union data inside the Query as a MultiPhraseQuery
func (t Query) AsMultiPhraseQuery() (MultiPhraseQuery, error) {
	var body MultiPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMultiPhraseQuery overwrites any union data inside the Query as the provided MultiPhraseQuery
func (t *Query) FromMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMultiPhraseQuery performs a merge with any union data inside the Query, using the provided MultiPhraseQuery
func (t *Query) MergeMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzzyQuery returns the union data inside the Query as a FuzzyQuery
func (t Query) AsFuzzyQuery() (FuzzyQuery, error) {
	var body FuzzyQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzzyQuery overwrites any union data inside the Query as the provided FuzzyQuery
func (t *Query) FromFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzzyQuery performs a merge with any union data inside the Query, using the provided FuzzyQuery
func (t *Query) MergeFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPrefixQuery returns the union data inside the Query as a PrefixQuery
func (t Query) AsPrefixQuery() (PrefixQuery, error) {
	var body PrefixQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPrefixQuery overwrites any union data inside the Query as the provided PrefixQuery
func (t *Query) FromPrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePrefixQuery performs a merge with any union data inside the Query, using the provided PrefixQuery
func (t *Query) MergePrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsRegexpQuery returns the union data inside the Query as a RegexpQuery
func (t Query) AsRegexpQuery() (RegexpQuery, error) {
	var body RegexpQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromRegexpQuery overwrites any union data inside the Query as the provided RegexpQuery
func (t *Query) FromRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeRegexpQuery performs a merge with any union data inside the Query, using the provided RegexpQuery
func (t *Query) MergeRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsWildcardQuery returns the union data inside the Query as a WildcardQuery
func (t Query) AsWildcardQuery() (WildcardQuery, error) {
	var body WildcardQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromWildcardQuery overwrites any union data inside the Query as the provided WildcardQuery
func (t *Query) FromWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeWildcardQuery performs a merge with any union data inside the Query, using the provided WildcardQuery
func (t *Query) MergeWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsQueryStringQuery returns the union data inside the Query as a QueryStringQuery
func (t Query) AsQueryStringQuery() (QueryStringQuery, error) {
	var body QueryStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromQueryStringQuery overwrites any union data inside the Query as the provided QueryStringQuery
func (t *Query) FromQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeQueryStringQuery performs a merge with any union data inside the Query, using the provided QueryStringQuery
func (t *Query) MergeQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsNumericRangeQuery returns the union data inside the Query as a NumericRangeQuery
func (t Query) AsNumericRangeQuery() (NumericRangeQuery, error) {
	var body NumericRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromNumericRangeQuery overwrites any union data inside the Query as the provided NumericRangeQuery
func (t *Query) FromNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeNumericRangeQuery performs a merge with any union data inside the Query, using the provided NumericRangeQuery
func (t *Query) MergeNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermRangeQuery returns the union data inside the Query as a TermRangeQuery
func (t Query) AsTermRangeQuery() (TermRangeQuery, error) {
	var body TermRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermRangeQuery overwrites any union data inside the Query as the provided TermRangeQuery
func (t *Query) FromTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermRangeQuery performs a merge with any union data inside the Query, using the provided TermRangeQuery
func (t *Query) MergeTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDateRangeStringQuery returns the union data inside the Query as a DateRangeStringQuery
func (t Query) AsDateRangeStringQuery() (DateRangeStringQuery, error) {
	var body DateRangeStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDateRangeStringQuery overwrites any union data inside the Query as the provided DateRangeStringQuery
func (t *Query) FromDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDateRangeStringQuery performs a merge with any union data inside the Query, using the provided DateRangeStringQuery
func (t *Query) MergeDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBooleanQuery returns the union data inside the Query as a BooleanQuery
func (t Query) AsBooleanQuery() (BooleanQuery, error) {
	var body BooleanQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBooleanQuery overwrites any union data inside the Query as the provided BooleanQuery
func (t *Query) FromBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBooleanQuery performs a merge with any union data inside the Query, using the provided BooleanQuery
func (t *Query) MergeBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsConjunctionQuery returns the union data inside the Query as a ConjunctionQuery
func (t Query) AsConjunctionQuery() (ConjunctionQuery, error) {
	var body ConjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromConjunctionQuery overwrites any union data inside the Query as the provided ConjunctionQuery
func (t *Query) FromConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeConjunctionQuery performs a merge with any union data inside the Query, using the provided ConjunctionQuery
func (t *Query) MergeConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDisjunctionQuery returns the union data inside the Query as a DisjunctionQuery
func (t Query) AsDisjunctionQuery() (DisjunctionQuery, error) {
	var body DisjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDisjunctionQuery overwrites any union data inside the Query as the provided DisjunctionQuery
func (t *Query) FromDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDisjunctionQuery performs a merge with any union data inside the Query, using the provided DisjunctionQuery
func (t *Query) MergeDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchAllQuery returns the union data inside the Query as a MatchAllQuery
func (t Query) AsMatchAllQuery() (MatchAllQuery, error) {
	var body MatchAllQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchAllQuery overwrites any union data inside the Query as the provided MatchAllQuery
func (t *Query) FromMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchAllQuery performs a merge with any union data inside the Query, using the provided MatchAllQuery
func (t *Query) MergeMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchNoneQuery returns the union data inside the Query as a MatchNoneQuery
func (t Query) AsMatchNoneQuery() (MatchNoneQuery, error) {
	var body MatchNoneQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchNoneQuery overwrites any union data inside the Query as the provided MatchNoneQuery
func (t *Query) FromMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchNoneQuery performs a merge with any union data inside the Query, using the provided MatchNoneQuery
func (t *Query) MergeMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDocIdQuery returns the union data inside the Query as a DocIdQuery
func (t Query) AsDocIdQuery() (DocIdQuery, error) {
	var body DocIdQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDocIdQuery overwrites any union data inside the Query as the provided DocIdQuery
func (t *Query) FromDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDocIdQuery performs a merge with any union data inside the Query, using the provided DocIdQuery
func (t *Query) MergeDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBoolFieldQuery returns the union data inside the Query as a BoolFieldQuery
func (t Query) AsBoolFieldQuery() (BoolFieldQuery, error) {
	var body BoolFieldQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBoolFieldQuery overwrites any union data inside the Query as the provided BoolFieldQuery
func (t *Query) FromBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBoolFieldQuery performs a merge with any union data inside the Query, using the provided BoolFieldQuery
func (t *Query) MergeBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsIPRangeQuery returns the union data inside the Query as a IPRangeQuery
func (t Query) AsIPRangeQuery() (IPRangeQuery, error) {
	var body IPRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromIPRangeQuery overwrites any union data inside the Query as the provided IPRangeQuery
func (t *Query) FromIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeIPRangeQuery performs a merge with any union data inside the Query, using the provided IPRangeQuery
func (t *Query) MergeIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingBoxQuery returns the union data inside the Query as a GeoBoundingBoxQuery
func (t Query) AsGeoBoundingBoxQuery() (GeoBoundingBoxQuery, error) {
	var body GeoBoundingBoxQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingBoxQuery overwrites any union data inside the Query as the provided GeoBoundingBoxQuery
func (t *Query) FromGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingBoxQuery performs a merge with any union data inside the Query, using the provided GeoBoundingBoxQuery
func (t *Query) MergeGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoDistanceQuery returns the union data inside the Query as a GeoDistanceQuery
func (t Query) AsGeoDistanceQuery() (GeoDistanceQuery, error) {
	var body GeoDistanceQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoDistanceQuery overwrites any union data inside the Query as the provided GeoDistanceQuery
func (t *Query) FromGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoDistanceQuery performs a merge with any union data inside the Query, using the provided GeoDistanceQuery
func (t *Query) MergeGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingPolygonQuery returns the union data inside the Query as a GeoBoundingPolygonQuery
func (t Query) AsGeoBoundingPolygonQuery() (GeoBoundingPolygonQuery, error) {
	var body GeoBoundingPolygonQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingPolygonQuery overwrites any union data inside the Query as the provided GeoBoundingPolygonQuery
func (t *Query) FromGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingPolygonQuery performs a merge with any union data inside the Query, using the provided GeoBoundingPolygonQuery
func (t *Query) MergeGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoShapeQuery returns the union data inside the Query as a GeoShapeQuery
func (t Query) AsGeoShapeQuery() (GeoShapeQuery, error) {
	var body GeoShapeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoShapeQuery overwrites any union data inside the Query as the provided GeoShapeQuery
func (t *Query) FromGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoShapeQuery performs a merge with any union data inside the Query, using the provided GeoShapeQuery
func (t *Query) MergeGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Query) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Query) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsGoogleEmbedderConfig returns the union data inside the RerankerConfig as a GoogleEmbedderConfig
func (t RerankerConfig) AsGoogleEmbedderConfig() (GoogleEmbedderConfig, error) {
	var body GoogleEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleEmbedderConfig overwrites any union data inside the RerankerConfig as the provided GoogleEmbedderConfig
func (t *RerankerConfig) FromGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleEmbedderConfig performs a merge with any union data inside the RerankerConfig, using the provided GoogleEmbedderConfig
func (t *RerankerConfig) MergeGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexEmbedderConfig returns the union data inside the RerankerConfig as a VertexEmbedderConfig
func (t RerankerConfig) AsVertexEmbedderConfig() (VertexEmbedderConfig, error) {
	var body VertexEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexEmbedderConfig overwrites any union data inside the RerankerConfig as the provided VertexEmbedderConfig
func (t *RerankerConfig) FromVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexEmbedderConfig performs a merge with any union data inside the RerankerConfig, using the provided VertexEmbedderConfig
func (t *RerankerConfig) MergeVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaEmbedderConfig returns the union data inside the RerankerConfig as a OllamaEmbedderConfig
func (t RerankerConfig) AsOllamaEmbedderConfig() (OllamaEmbedderConfig, error) {
	var body OllamaEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaEmbedderConfig overwrites any union data inside the RerankerConfig as the provided OllamaEmbedderConfig
func (t *RerankerConfig) FromOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaEmbedderConfig performs a merge with any union data inside the RerankerConfig, using the provided OllamaEmbedderConfig
func (t *RerankerConfig) MergeOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIEmbedderConfig returns the union data inside the RerankerConfig as a OpenAIEmbedderConfig
func (t RerankerConfig) AsOpenAIEmbedderConfig() (OpenAIEmbedderConfig, error) {
	var body OpenAIEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIEmbedderConfig overwrites any union data inside the RerankerConfig as the provided OpenAIEmbedderConfig
func (t *RerankerConfig) FromOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIEmbedderConfig performs a merge with any union data inside the RerankerConfig, using the provided OpenAIEmbedderConfig
func (t *RerankerConfig) MergeOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockEmbedderConfig returns the union data inside the RerankerConfig as a BedrockEmbedderConfig
func (t RerankerConfig) AsBedrockEmbedderConfig() (BedrockEmbedderConfig, error) {
	var body BedrockEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockEmbedderConfig overwrites any union data inside the RerankerConfig as the provided BedrockEmbedderConfig
func (t *RerankerConfig) FromBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockEmbedderConfig performs a merge with any union data inside the RerankerConfig, using the provided BedrockEmbedderConfig
func (t *RerankerConfig) MergeBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t RerankerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["field"], err = json.Marshal(t.Field)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'field': %w", err)
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	object["template"], err = json.Marshal(t.Template)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'template': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *RerankerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["field"]; found {
		err = json.Unmarshal(raw, &t.Field)
		if err != nil {
			return fmt.Errorf("error reading 'field': %w", err)
		}
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	if raw, found := object["template"]; found {
		err = json.Unmarshal(raw, &t.Template)
		if err != nil {
			return fmt.Errorf("error reading 'template': %w", err)
		}
	}

	return err
}

// RequestEditorFn  is the function signature for the RequestEditor callback function
type RequestEditorFn func(ctx context.Context, req *http.Request) error

// Doer performs HTTP requests.
//
// The standard http.Client implements this interface.
type HttpRequestDoer interface {
	Do(req *http.Request) (*http.Response, error)
}

// Client which conforms to the OpenAPI3 specification for this service.
type Client struct {
	// The endpoint of the server conforming to this interface, with scheme,
	// https://api.deepmap.com for example. This can contain a path relative
	// to the server, such as https://api.deepmap.com/dev-test, and all the
	// paths in the swagger spec will be appended to the server.
	Server string

	// Doer for performing requests, typically a *http.Client with any
	// customized settings, such as certificate chains.
	Client HttpRequestDoer

	// A list of callbacks for modifying requests which are generated before sending over
	// the network.
	RequestEditors []RequestEditorFn
}

// ClientOption allows setting custom parameters during construction
type ClientOption func(*Client) error

// Creates a new Client, with reasonable defaults
func NewClient(server string, opts ...ClientOption) (*Client, error) {
	// create a client with sane default values
	client := Client{
		Server: server,
	}
	// mutate client and add all optional params
	for _, o := range opts {
		if err := o(&client); err != nil {
			return nil, err
		}
	}
	// ensure the server URL always has a trailing slash
	if !strings.HasSuffix(client.Server, "/") {
		client.Server += "/"
	}
	// create httpClient, if not already present
	if client.Client == nil {
		client.Client = &http.Client{}
	}
	return &client, nil
}

// WithHTTPClient allows overriding the default Doer, which is
// automatically created using http.Client. This is useful for tests.
func WithHTTPClient(doer HttpRequestDoer) ClientOption {
	return func(c *Client) error {
		c.Client = doer
		return nil
	}
}

// WithRequestEditorFn allows setting up a callback function, which will be
// called right before sending the request. This can be used to mutate the request.
func WithRequestEditorFn(fn RequestEditorFn) ClientOption {
	return func(c *Client) error {
		c.RequestEditors = append(c.RequestEditors, fn)
		return nil
	}
}

// The interface specification for the client above.
type ClientInterface interface {
	// AnswerAgentWithBody request with any body
	AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GlobalQueryWithBody request with any body
	GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RagQueryWithBody request with any body
	RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetStatus request
	GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListTables request
	ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropTable request
	DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetTable request
	GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateTableWithBody request with any body
	CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BackupTableWithBody request with any body
	BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BatchWithBody request with any body
	BatchWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Batch(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListIndexes request
	ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropIndex request
	DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetIndex request
	GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateIndexWithBody request with any body
	CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LookupKey request
	LookupKey(ctx context.Context, tableName string, key string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LinearMergeWithBody request with any body
	LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// QueryTableWithBody request with any body
	QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// TableRagQueryWithBody request with any body
	TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RestoreTableWithBody request with any body
	RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateSchemaWithBody request with any body
	UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListUsers request
	ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetCurrentUser request
	GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteUser request
	DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserByName request
	GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateUserWithBody request with any body
	CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateUserPasswordWithBody request with any body
	UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RemovePermissionFromUser request
	RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserPermissions request
	GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// AddPermissionToUserWithBody request with any body
	AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)
}

func (c *Client) AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetStatusRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListTablesRequest(c.Server, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BatchWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Batch(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListIndexesRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequestWithBody(c.Server, tableName, indexName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequest(c.Server, tableName, indexName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LookupKey(ctx context.Context, tableName string, key string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLookupKeyRequest(c.Server, tableName, key)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListUsersRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetCurrentUserRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteUserRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserByNameRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRemovePermissionFromUserRequest(c.Server, userName, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserPermissionsRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

// NewAnswerAgentRequest calls the generic AnswerAgent builder with application/json body
func NewAnswerAgentRequest(server string, body AnswerAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAnswerAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewAnswerAgentRequestWithBody generates requests for AnswerAgent with any type of body
func NewAnswerAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/answer")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGlobalQueryRequest calls the generic GlobalQuery builder with application/json body
func NewGlobalQueryRequest(server string, body GlobalQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewGlobalQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewGlobalQueryRequestWithBody generates requests for GlobalQuery with any type of body
func NewGlobalQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/query")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRagQueryRequest calls the generic RagQuery builder with application/json body
func NewRagQueryRequest(server string, body RagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRagQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewRagQueryRequestWithBody generates requests for RagQuery with any type of body
func NewRagQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/rag")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetStatusRequest generates requests for GetStatus
func NewGetStatusRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/status")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListTablesRequest generates requests for ListTables
func NewListTablesRequest(server string, params *ListTablesParams) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "prefix", runtime.ParamLocationQuery, params.Prefix); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "pattern", runtime.ParamLocationQuery, params.Pattern); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropTableRequest generates requests for DropTable
func NewDropTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetTableRequest generates requests for GetTable
func NewGetTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateTableRequest calls the generic CreateTable builder with application/json body
func NewCreateTableRequest(server string, tableName string, body CreateTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewCreateTableRequestWithBody generates requests for CreateTable with any type of body
func NewCreateTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBackupTableRequest calls the generic BackupTable builder with application/json body
func NewBackupTableRequest(server string, tableName string, body BackupTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBackupTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBackupTableRequestWithBody generates requests for BackupTable with any type of body
func NewBackupTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/backup", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBatchRequest calls the generic Batch builder with application/json body
func NewBatchRequest(server string, tableName string, body BatchJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBatchRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBatchRequestWithBody generates requests for Batch with any type of body
func NewBatchRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/batch", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListIndexesRequest generates requests for ListIndexes
func NewListIndexesRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropIndexRequest generates requests for DropIndex
func NewDropIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetIndexRequest generates requests for GetIndex
func NewGetIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateIndexRequest calls the generic CreateIndex builder with application/json body
func NewCreateIndexRequest(server string, tableName string, indexName string, body CreateIndexJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateIndexRequestWithBody(server, tableName, indexName, "application/json", bodyReader)
}

// NewCreateIndexRequestWithBody generates requests for CreateIndex with any type of body
func NewCreateIndexRequestWithBody(server string, tableName string, indexName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewLookupKeyRequest generates requests for LookupKey
func NewLookupKeyRequest(server string, tableName string, key string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "key", runtime.ParamLocationPath, key)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/lookup/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewLinearMergeRequest calls the generic LinearMerge builder with application/json body
func NewLinearMergeRequest(server string, tableName string, body LinearMergeJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewLinearMergeRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewLinearMergeRequestWithBody generates requests for LinearMerge with any type of body
func NewLinearMergeRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/merge", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewQueryTableRequest calls the generic QueryTable builder with application/json body
func NewQueryTableRequest(server string, tableName string, body QueryTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewQueryTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewQueryTableRequestWithBody generates requests for QueryTable with any type of body
func NewQueryTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/query", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewTableRagQueryRequest calls the generic TableRagQuery builder with application/json body
func NewTableRagQueryRequest(server string, tableName string, body TableRagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewTableRagQueryRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewTableRagQueryRequestWithBody generates requests for TableRagQuery with any type of body
func NewTableRagQueryRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/rag", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRestoreTableRequest calls the generic RestoreTable builder with application/json body
func NewRestoreTableRequest(server string, tableName string, body RestoreTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRestoreTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewRestoreTableRequestWithBody generates requests for RestoreTable with any type of body
func NewRestoreTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/restore", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateSchemaRequest calls the generic UpdateSchema builder with application/json body
func NewUpdateSchemaRequest(server string, tableName string, body UpdateSchemaJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateSchemaRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewUpdateSchemaRequestWithBody generates requests for UpdateSchema with any type of body
func NewUpdateSchemaRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/schema", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListUsersRequest generates requests for ListUsers
func NewListUsersRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetCurrentUserRequest generates requests for GetCurrentUser
func NewGetCurrentUserRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/me")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDeleteUserRequest generates requests for DeleteUser
func NewDeleteUserRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserByNameRequest generates requests for GetUserByName
func NewGetUserByNameRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateUserRequest calls the generic CreateUser builder with application/json body
func NewCreateUserRequest(server string, userName UserNamePathParameter, body CreateUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewCreateUserRequestWithBody generates requests for CreateUser with any type of body
func NewCreateUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateUserPasswordRequest calls the generic UpdateUserPassword builder with application/json body
func NewUpdateUserPasswordRequest(server string, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateUserPasswordRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewUpdateUserPasswordRequestWithBody generates requests for UpdateUserPassword with any type of body
func NewUpdateUserPasswordRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/password", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRemovePermissionFromUserRequest generates requests for RemovePermissionFromUser
func NewRemovePermissionFromUserRequest(server string, userName UserNamePathParameter, params *RemovePermissionFromUserParams) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resource", runtime.ParamLocationQuery, params.Resource); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resourceType", runtime.ParamLocationQuery, params.ResourceType); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserPermissionsRequest generates requests for GetUserPermissions
func NewGetUserPermissionsRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewAddPermissionToUserRequest calls the generic AddPermissionToUser builder with application/json body
func NewAddPermissionToUserRequest(server string, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAddPermissionToUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewAddPermissionToUserRequestWithBody generates requests for AddPermissionToUser with any type of body
func NewAddPermissionToUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

func (c *Client) applyEditors(ctx context.Context, req *http.Request, additionalEditors []RequestEditorFn) error {
	for _, r := range c.RequestEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	for _, r := range additionalEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	return nil
}

// ClientWithResponses builds on ClientInterface to offer response payloads
type ClientWithResponses struct {
	ClientInterface
}

// NewClientWithResponses creates a new ClientWithResponses, which wraps
// Client with return type handling
func NewClientWithResponses(server string, opts ...ClientOption) (*ClientWithResponses, error) {
	client, err := NewClient(server, opts...)
	if err != nil {
		return nil, err
	}
	return &ClientWithResponses{client}, nil
}

// WithBaseURL overrides the baseURL.
func WithBaseURL(baseURL string) ClientOption {
	return func(c *Client) error {
		newBaseURL, err := url.Parse(baseURL)
		if err != nil {
			return err
		}
		c.Server = newBaseURL.String()
		return nil
	}
}

// ClientWithResponsesInterface is the interface specification for the client with responses above.
type ClientWithResponsesInterface interface {
	// AnswerAgentWithBodyWithResponse request with any body
	AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	// GlobalQueryWithBodyWithResponse request with any body
	GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	// RagQueryWithBodyWithResponse request with any body
	RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	// GetStatusWithResponse request
	GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error)

	// ListTablesWithResponse request
	ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error)

	// DropTableWithResponse request
	DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error)

	// GetTableWithResponse request
	GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error)

	// CreateTableWithBodyWithResponse request with any body
	CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	// BackupTableWithBodyWithResponse request with any body
	BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	// BatchWithBodyWithResponse request with any body
	BatchWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchResponse, error)

	BatchWithResponse(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchResponse, error)

	// ListIndexesWithResponse request
	ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error)

	// DropIndexWithResponse request
	DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error)

	// GetIndexWithResponse request
	GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error)

	// CreateIndexWithBodyWithResponse request with any body
	CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	// LookupKeyWithResponse request
	LookupKeyWithResponse(ctx context.Context, tableName string, key string, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error)

	// LinearMergeWithBodyWithResponse request with any body
	LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	// QueryTableWithBodyWithResponse request with any body
	QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	// TableRagQueryWithBodyWithResponse request with any body
	TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	// RestoreTableWithBodyWithResponse request with any body
	RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	// UpdateSchemaWithBodyWithResponse request with any body
	UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	// ListUsersWithResponse request
	ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error)

	// GetCurrentUserWithResponse request
	GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error)

	// DeleteUserWithResponse request
	DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error)

	// GetUserByNameWithResponse request
	GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error)

	// CreateUserWithBodyWithResponse request with any body
	CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	// UpdateUserPasswordWithBodyWithResponse request with any body
	UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	// RemovePermissionFromUserWithResponse request
	RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error)

	// GetUserPermissionsWithResponse request
	GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error)

	// AddPermissionToUserWithBodyWithResponse request with any body
	AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)

	AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)
}

type AnswerAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *AnswerAgentResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AnswerAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AnswerAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GlobalQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GlobalQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GlobalQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetStatusResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ClusterStatus
	JSON401      *Error
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetStatusResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetStatusResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListTablesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]TableStatus
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListTablesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListTablesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *TableStatus
	JSON404      *NotFound
}

// Status returns HTTPResponse.Status
func (r GetTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
}

// Status returns HTTPResponse.Status
func (r CreateTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BackupTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *struct {
		Backup string `json:"backup,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON404 *NotFound
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BackupTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BackupTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BatchResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *struct {
		// Deleted Number of documents successfully deleted
		Deleted int `json:"deleted,omitempty,omitzero"`

		// Failed List of failed operations with error details
		Failed []struct {
			// Error Error message for this failure
			Error string `json:"error,omitempty,omitzero"`

			// Id The document ID that failed
			Id string `json:"id,omitempty,omitzero"`
		} `json:"failed,omitempty,omitzero"`

		// Inserted Number of documents successfully inserted
		Inserted int `json:"inserted,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON404 *NotFound
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BatchResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BatchResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListIndexesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListIndexesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListIndexesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r CreateIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LookupKeyResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *map[string]interface{}
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LookupKeyResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LookupKeyResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LinearMergeResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *LinearMergeResult
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LinearMergeResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LinearMergeResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type QueryTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r QueryTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r QueryTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type TableRagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON404      *NotFound
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r TableRagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r TableRagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RestoreTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON202      *struct {
		Restore string `json:"restore,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r RestoreTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RestoreTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateSchemaResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r UpdateSchemaResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateSchemaResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListUsersResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]struct {
		Username string `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON403 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r ListUsersResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListUsersResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetCurrentUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *struct {
		Permissions []Permission `json:"permissions,omitempty,omitzero"`
		Username    string       `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r GetCurrentUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetCurrentUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserByNameResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *User
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserByNameResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserByNameResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *User
	JSON400      *Error
	JSON409      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateUserPasswordResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateUserPasswordResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateUserPasswordResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RemovePermissionFromUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RemovePermissionFromUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RemovePermissionFromUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserPermissionsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]Permission
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserPermissionsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserPermissionsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type AddPermissionToUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AddPermissionToUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AddPermissionToUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

// AnswerAgentWithBodyWithResponse request with arbitrary body returning *AnswerAgentResponse
func (c *ClientWithResponses) AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

func (c *ClientWithResponses) AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

// GlobalQueryWithBodyWithResponse request with arbitrary body returning *GlobalQueryResponse
func (c *ClientWithResponses) GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

func (c *ClientWithResponses) GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

// RagQueryWithBodyWithResponse request with arbitrary body returning *RagQueryResponse
func (c *ClientWithResponses) RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

func (c *ClientWithResponses) RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

// GetStatusWithResponse request returning *GetStatusResponse
func (c *ClientWithResponses) GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error) {
	rsp, err := c.GetStatus(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetStatusResponse(rsp)
}

// ListTablesWithResponse request returning *ListTablesResponse
func (c *ClientWithResponses) ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error) {
	rsp, err := c.ListTables(ctx, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListTablesResponse(rsp)
}

// DropTableWithResponse request returning *DropTableResponse
func (c *ClientWithResponses) DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error) {
	rsp, err := c.DropTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropTableResponse(rsp)
}

// GetTableWithResponse request returning *GetTableResponse
func (c *ClientWithResponses) GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error) {
	rsp, err := c.GetTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetTableResponse(rsp)
}

// CreateTableWithBodyWithResponse request with arbitrary body returning *CreateTableResponse
func (c *ClientWithResponses) CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

func (c *ClientWithResponses) CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

// BackupTableWithBodyWithResponse request with arbitrary body returning *BackupTableResponse
func (c *ClientWithResponses) BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

func (c *ClientWithResponses) BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

// BatchWithBodyWithResponse request with arbitrary body returning *BatchResponse
func (c *ClientWithResponses) BatchWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchResponse, error) {
	rsp, err := c.BatchWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchResponse(rsp)
}

func (c *ClientWithResponses) BatchWithResponse(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchResponse, error) {
	rsp, err := c.Batch(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchResponse(rsp)
}

// ListIndexesWithResponse request returning *ListIndexesResponse
func (c *ClientWithResponses) ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error) {
	rsp, err := c.ListIndexes(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListIndexesResponse(rsp)
}

// DropIndexWithResponse request returning *DropIndexResponse
func (c *ClientWithResponses) DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error) {
	rsp, err := c.DropIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropIndexResponse(rsp)
}

// GetIndexWithResponse request returning *GetIndexResponse
func (c *ClientWithResponses) GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error) {
	rsp, err := c.GetIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetIndexResponse(rsp)
}

// CreateIndexWithBodyWithResponse request with arbitrary body returning *CreateIndexResponse
func (c *ClientWithResponses) CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndexWithBody(ctx, tableName, indexName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

func (c *ClientWithResponses) CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndex(ctx, tableName, indexName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

// LookupKeyWithResponse request returning *LookupKeyResponse
func (c *ClientWithResponses) LookupKeyWithResponse(ctx context.Context, tableName string, key string, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error) {
	rsp, err := c.LookupKey(ctx, tableName, key, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLookupKeyResponse(rsp)
}

// LinearMergeWithBodyWithResponse request with arbitrary body returning *LinearMergeResponse
func (c *ClientWithResponses) LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMergeWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

func (c *ClientWithResponses) LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMerge(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

// QueryTableWithBodyWithResponse request with arbitrary body returning *QueryTableResponse
func (c *ClientWithResponses) QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

func (c *ClientWithResponses) QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

// TableRagQueryWithBodyWithResponse request with arbitrary body returning *TableRagQueryResponse
func (c *ClientWithResponses) TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQueryWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

func (c *ClientWithResponses) TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQuery(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

// RestoreTableWithBodyWithResponse request with arbitrary body returning *RestoreTableResponse
func (c *ClientWithResponses) RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

func (c *ClientWithResponses) RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

// UpdateSchemaWithBodyWithResponse request with arbitrary body returning *UpdateSchemaResponse
func (c *ClientWithResponses) UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchemaWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

func (c *ClientWithResponses) UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchema(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

// ListUsersWithResponse request returning *ListUsersResponse
func (c *ClientWithResponses) ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error) {
	rsp, err := c.ListUsers(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListUsersResponse(rsp)
}

// GetCurrentUserWithResponse request returning *GetCurrentUserResponse
func (c *ClientWithResponses) GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error) {
	rsp, err := c.GetCurrentUser(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetCurrentUserResponse(rsp)
}

// DeleteUserWithResponse request returning *DeleteUserResponse
func (c *ClientWithResponses) DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error) {
	rsp, err := c.DeleteUser(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteUserResponse(rsp)
}

// GetUserByNameWithResponse request returning *GetUserByNameResponse
func (c *ClientWithResponses) GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error) {
	rsp, err := c.GetUserByName(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserByNameResponse(rsp)
}

// CreateUserWithBodyWithResponse request with arbitrary body returning *CreateUserResponse
func (c *ClientWithResponses) CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

func (c *ClientWithResponses) CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

// UpdateUserPasswordWithBodyWithResponse request with arbitrary body returning *UpdateUserPasswordResponse
func (c *ClientWithResponses) UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPasswordWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

func (c *ClientWithResponses) UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPassword(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

// RemovePermissionFromUserWithResponse request returning *RemovePermissionFromUserResponse
func (c *ClientWithResponses) RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error) {
	rsp, err := c.RemovePermissionFromUser(ctx, userName, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRemovePermissionFromUserResponse(rsp)
}

// GetUserPermissionsWithResponse request returning *GetUserPermissionsResponse
func (c *ClientWithResponses) GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error) {
	rsp, err := c.GetUserPermissions(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserPermissionsResponse(rsp)
}

// AddPermissionToUserWithBodyWithResponse request with arbitrary body returning *AddPermissionToUserResponse
func (c *ClientWithResponses) AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

func (c *ClientWithResponses) AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

// ParseAnswerAgentResponse parses an HTTP response from a AnswerAgentWithResponse call
func ParseAnswerAgentResponse(rsp *http.Response) (*AnswerAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AnswerAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest AnswerAgentResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseGlobalQueryResponse parses an HTTP response from a GlobalQueryWithResponse call
func ParseGlobalQueryResponse(rsp *http.Response) (*GlobalQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GlobalQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRagQueryResponse parses an HTTP response from a RagQueryWithResponse call
func ParseRagQueryResponse(rsp *http.Response) (*RagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseGetStatusResponse parses an HTTP response from a GetStatusWithResponse call
func ParseGetStatusResponse(rsp *http.Response) (*GetStatusResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetStatusResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ClusterStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListTablesResponse parses an HTTP response from a ListTablesWithResponse call
func ParseListTablesResponse(rsp *http.Response) (*ListTablesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListTablesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropTableResponse parses an HTTP response from a DropTableWithResponse call
func ParseDropTableResponse(rsp *http.Response) (*DropTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetTableResponse parses an HTTP response from a GetTableWithResponse call
func ParseGetTableResponse(rsp *http.Response) (*GetTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	}

	return response, nil
}

// ParseCreateTableResponse parses an HTTP response from a CreateTableWithResponse call
func ParseCreateTableResponse(rsp *http.Response) (*CreateTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	}

	return response, nil
}

// ParseBackupTableResponse parses an HTTP response from a BackupTableWithResponse call
func ParseBackupTableResponse(rsp *http.Response) (*BackupTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BackupTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest struct {
			Backup string `json:"backup,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseBatchResponse parses an HTTP response from a BatchWithResponse call
func ParseBatchResponse(rsp *http.Response) (*BatchResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BatchResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest struct {
			// Deleted Number of documents successfully deleted
			Deleted int `json:"deleted,omitempty,omitzero"`

			// Failed List of failed operations with error details
			Failed []struct {
				// Error Error message for this failure
				Error string `json:"error,omitempty,omitzero"`

				// Id The document ID that failed
				Id string `json:"id,omitempty,omitzero"`
			} `json:"failed,omitempty,omitzero"`

			// Inserted Number of documents successfully inserted
			Inserted int `json:"inserted,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListIndexesResponse parses an HTTP response from a ListIndexesWithResponse call
func ParseListIndexesResponse(rsp *http.Response) (*ListIndexesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListIndexesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropIndexResponse parses an HTTP response from a DropIndexWithResponse call
func ParseDropIndexResponse(rsp *http.Response) (*DropIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetIndexResponse parses an HTTP response from a GetIndexWithResponse call
func ParseGetIndexResponse(rsp *http.Response) (*GetIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateIndexResponse parses an HTTP response from a CreateIndexWithResponse call
func ParseCreateIndexResponse(rsp *http.Response) (*CreateIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLookupKeyResponse parses an HTTP response from a LookupKeyWithResponse call
func ParseLookupKeyResponse(rsp *http.Response) (*LookupKeyResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LookupKeyResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest map[string]interface{}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLinearMergeResponse parses an HTTP response from a LinearMergeWithResponse call
func ParseLinearMergeResponse(rsp *http.Response) (*LinearMergeResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LinearMergeResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest LinearMergeResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseQueryTableResponse parses an HTTP response from a QueryTableWithResponse call
func ParseQueryTableResponse(rsp *http.Response) (*QueryTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &QueryTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseTableRagQueryResponse parses an HTTP response from a TableRagQueryWithResponse call
func ParseTableRagQueryResponse(rsp *http.Response) (*TableRagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &TableRagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseRestoreTableResponse parses an HTTP response from a RestoreTableWithResponse call
func ParseRestoreTableResponse(rsp *http.Response) (*RestoreTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RestoreTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest struct {
			Restore string `json:"restore,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateSchemaResponse parses an HTTP response from a UpdateSchemaWithResponse call
func ParseUpdateSchemaResponse(rsp *http.Response) (*UpdateSchemaResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateSchemaResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListUsersResponse parses an HTTP response from a ListUsersWithResponse call
func ParseListUsersResponse(rsp *http.Response) (*ListUsersResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListUsersResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []struct {
			Username string `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 403:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON403 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetCurrentUserResponse parses an HTTP response from a GetCurrentUserWithResponse call
func ParseGetCurrentUserResponse(rsp *http.Response) (*GetCurrentUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetCurrentUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest struct {
			Permissions []Permission `json:"permissions,omitempty,omitzero"`
			Username    string       `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteUserResponse parses an HTTP response from a DeleteUserWithResponse call
func ParseDeleteUserResponse(rsp *http.Response) (*DeleteUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserByNameResponse parses an HTTP response from a GetUserByNameWithResponse call
func ParseGetUserByNameResponse(rsp *http.Response) (*GetUserByNameResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserByNameResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateUserResponse parses an HTTP response from a CreateUserWithResponse call
func ParseCreateUserResponse(rsp *http.Response) (*CreateUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 409:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON409 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateUserPasswordResponse parses an HTTP response from a UpdateUserPasswordWithResponse call
func ParseUpdateUserPasswordResponse(rsp *http.Response) (*UpdateUserPasswordResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateUserPasswordResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRemovePermissionFromUserResponse parses an HTTP response from a RemovePermissionFromUserWithResponse call
func ParseRemovePermissionFromUserResponse(rsp *http.Response) (*RemovePermissionFromUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RemovePermissionFromUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserPermissionsResponse parses an HTTP response from a GetUserPermissionsWithResponse call
func ParseGetUserPermissionsResponse(rsp *http.Response) (*GetUserPermissionsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserPermissionsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []Permission
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseAddPermissionToUserResponse parses an HTTP response from a AddPermissionToUserWithResponse call
func ParseAddPermissionToUserResponse(rsp *http.Response) (*AddPermissionToUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AddPermissionToUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// Base64 encoded, gzipped, json marshaled Swagger object
var swaggerSpec = []string{

	"H4sIAAAAAAAC/+z963IbObIoCr8KPnZHWPIiqYvtuTBixbdk2e3WtC9aknt6rzP0psAqkMSoCNQUUJLY",
	"Dv09D3Ae8TzJCWQCKFQViqRunu7Z86dbZuGSSCQSmYm8fO0lcplLwYRWvdHXXk4LumSaFfCvnxUrPtIl",
	"O6V6ceq+mA8pU0nBc82l6I16nxeMlIoVgi7ZsNfvcfNjTvWi1++Z33qjXmlH6vV7BftHyQuW9ka6KFm/",
	"p5IFW1IzKruhyzwzzf8uFyKVprVe5eYHpQsu5r3b21szgMqlUAxAfE3TM/aPkilt/pVIoZmAP2meZzyh",
	"BsS9vysD59dgqu8LNuuNet/tVcvfw69q721RyAKnqq/zNU1JYSe77fdOhDZrzs5ZccUK7PXkMLhJiYJZ",
	"CcOG/d5HqX+QpUifHoQzpmRZJIwIqckM5jSNbD8z7JGg2cpuUF7InBWa238lMK/d1amUGaPCgK+VYLEv",
	"t54E5PTvLNG9fu9mMJcD8+NAXfJ8IAEumg1yyQXQ54xmit32PRhnTJWZ7gSGa7aEf89ksaS6N+rNMkl1",
	"RXyiXE5ZEc7s2vzhZa8CkBYFXYVreeSBH4YKdc2KozkTOjgudXT8o2SF/bO+4UdmfiJnxLRYuSOgiJaE",
	"3bCk1GxIDA/Az5rdaHLNs4xMGdEFFcosn6VkJgui2JIKzROiGC2SxVhQkZJc5mVGNUsJF1oSvWC+3QTb",
	"kRlnWWpAYDRZ4ESG03iO8bevPS5SdmPA/1uPLacsTbmYT3h60/vS72V8yXVvdLDf72k6BRaTFzItE616",
	"t/2t+r6quhbsirNr1bv90q/2eN1R+m8D71nFOZZcnGC/gzb1wOLam2B48TNFBNVlQTOSUTEv6dwjXRps",
	"JxlVis84S4nBK1/mhbxiaYio3i8LqgktGKB5ypQmc7rkYk4ymmuZK1KKlBXk+8P9/f3/f5sB93uqXC5p",
	"wX/Fm2Ddst8xwQqqZXEsxYxj55XSbDnJC7nMdXuRnywBE2xHsJ1Z3bzkabVAZGiwSAqUTeY4lxkmXO3/",
	"yBIWS8mCZfmszIhayDw36zUjKU2FHsZWaS6sCfDRG71pnWZrjm3T237vmuvFZCazTF6XOa5xRoEBwWls",
	"c/QkK1NGVDmfM6XhoJi+gzInQDFcCkWoIoqZ21kzwq7M9ITONCtgGxEH1TICvgrAFIwqKczKtobGDPv+",
	"/YdnivjOZjcSpqKwTNlMWpraBIzSBQOKqwGDskAdlrfCHDhyfv6W+E6GBxTAzxXZqZNDn1gO1nct+haY",
	"XcKF0owCB/nL+aePxMkQETBvQxHlb/Y41si+71nllyZLbrJad/E0GCrSLDVtLKzE4CZG35awmad0aMhF",
	"xgUzffEqLtiMFUwkTPX6DbZu96MFxLvmwDtLWlym8loQvK82zbQbOzf1FUw8/8ejueEgHdc6f671tbi8",
	"7ffc0Zr409Fe3Pnaw7TDZ6R2Ssk1VYQBuaVmWZ6rt9YX5dYTS29tOM4sqc4KucS7y96YKXGEdZcbxKGg",
	"CUXjgIcQdB1ij4PqUwMJTdE7Sut6lq0+w89fe0yUS3Nk8M6eUDVZyXICnfq9S7a6loW5i4BP9nsLvcyM",
	"glAuWcGTXr+XUs00Bx3BHUZz+4rLXr83ZxJkGvxTLSiM6e9q0yWT0+A8Vjt2JPSikDlPmtdRC1X4e4nX",
	"CIgrhp/5/v6OuWLk6MQg8oqbq3LnOKOGZS5lyjK1OxyLnxVT0HfGCzaliu3NmbjkmpidpXoiKd+jftg8",
	"K+dc4Gn7lDNxdDLAdtxwv6PTk+FYjMUb5JQgdSUw4eDF4I8DJYVgenC4f/hq//Dgz4TPiJAICuGKqJwl",
	"IBDAGEenJ+SSrUhChREX7ApScsUpgPuM5nxyyVbPnLxlMfDx849nn05PjidHpyeTn97+D2HiihdSLA3/",
	"uqIFNzQDM5yXeS4LQ96IjdFYDNaBu2PkPqX7ZCmVJgnNzUi7tU6vBgvKL0vT5+XB/uEh2ZlRpYE3stmM",
	"J5wJ3exRTfNy/w+H+2RnSjMqEpaSnBXAUkTSmEbmpcIOh4d/JjsLPl9kqzhEFTz7L/b/iPAwZYAIZY+v",
	"vSW9mWh5yQyDern/5z/0e4CU3qjXjRFk30BY5oA7IoFjs8wN+ZUF6432h3+8bTF63Ly4fl5RsSWCITmZ",
	"gQbnqKBPZjTLFJnS5NIQ2Za7HrsEwoU3gflAb/iyXBLUfcyFjC1ByLNXEuECCM/d0sEkRq+ZM9B4LTID",
	"IWI9XttImZVZZs/KyRsApYYp/KIlKRUjO2w4H/bJs+4pnoVfm1T7bLemr6yHtH3rhHsfYVu6kJkiBRWp",
	"XArD3bkIJGKysz/cHxwM93eH5Ec+X7CCXNGsZIos6SUjstR5qcnSCHA4hAG1pbMuceNAZ1lygX/vN3VZ",
	"A6zMJ5cRKpT54JIogwC4h5w9aUg+iWyFHxhelGYbtMzJTwQ1WgXMGK5PVU6VUaSERrqJk4YBIW+D8LFM",
	"MlaqCBAhio4yMLEAnzfqaIX7h+GlLLL42fz57H2b+MwxZSKFW4/sOM2+b2hREUvxyO11xeV3axCWBY9e",
	"46F4i4coJse+psllmXdaC6bwecLTiKoq+D9KRnjKhDZgFfYu5chcynxIflYsNcj10iSqo/AVWhdMaUOQ",
	"MrdErIZjcbyQUhllbsmokViMPifo0nSmmnBUXRQxgsTeFSuUoX0uvAg5rDNouwQ4eIP9g8HBq8HVYez0",
	"ZTLx4mtDzNSyMEq4a+GFBrdOex8qsiwzzQ2Bmy9MpHgzvpcJzciMZwwV3hG5MP8Y7e3t5VQv9rTcw5Eu",
	"TOujJf1VCnL+YkQu1IvR3t60TC6ZHhgUtNuPxecKpR43NMsI2DEMlmifWMtHH+7TJdPU/OyX4QkL+zQR",
	"CEAsVwiGkWhm2WqAM6o9o0GrAfTbq1C8kSArugoQH6dPnSwC8mzaanVilBfFCt0nKcuYZrhIr5IEtGX4",
	"JSWKi3nGnH3LMIIsbEML5qRnozRpueQJzbIVSG5cWP60oAUKW6+ZYDOucaPPWFomTBHB9LUsLom8YsXC",
	"KKQg6RV4GLhI+RVPS5p5G5vp+8GcAy/q4I4Z5rVT5obSEbCpWS9LQVA5AtAcWAARmcpSpNQorY4yEDfY",
	"u8zx7wFhN1xpM/olW+E3A+p1wbVmok8Eu66+JAUz+uOwKfcgtsGaZohg9Mc/mUsN/pRZOqFJIkuhzaZa",
	"GEwn+Hxw+AIkmTnrjV7sGwGf8sy+B/yXnWGYyGX1sPAXuRDkDT4V0DnMmZRKyyXo6XnBlrxc9r5Yi87o",
	"5as/+AkOXwUTUME6JqCCkfMlh9eM1hRfwD5e54x++Z121FQmJUhRJ29A7sEeQ/LG/o7oLdhSXhkN1lyJ",
	"5tzaswrU9VFqhqT1UYoB7JoZ0O+N4hkTOlsRPheyYKlp+cZMEyFla7xxBGGFL2UYK5CV6fuTGzhnRnrG",
	"sWsQKssLwfKIkNYJYzM1bK11B3RD05Tj3Xja2IUQ9Q6zBPkHKlu0mHJd0GKF6o4Rh3SyMMS/kmVh2SRq",
	"4IGYUXGgpmCbR/e2PrMakreGTxg1jKOSWHZcl8z3tfxEGWGdJpondut/VowkUqhq8811aBYAUDPlpNax",
	"P17jnvkXLTRPMmaOw7i3a/eXZEzMDVpmMwNobUMDtYkMyCVjuQFwae0KdGoEuIUsdI1UFGqCGbvhiZwX",
	"NF8gw+wTJUmCd3lesBm/AXWZaqLwujRi6NygngrVZC6/Wz4RISC1EskkY1eoxqyz/5yvRPIeGppx3A22",
	"jsdErzlDWFwM8owmFXURd4+U5gIkH6SYyzevB0qvMid/yQK5zufYoDTL5LU5MobclzLls5UfW8FJk6U2",
	"lJIO8OvAXCdG13B0/Kl+ycKbZf2KlZYnwaMnXIpOngoAyVlRLSocyNyCoDQkzPT1Qpm1PYVj7HzPRdIn",
	"3y/LbLdPKGIz/JyXatEn3+dlBg2M1CQLZpBzLJdLKUBZTKiySzsRScEAIGBzrFBkB16P+iTjl0bwujKc",
	"HM7gz7APRPMlU5ouczNdUhYFE/oN1WiE+EAFnEkDmCI7NE33kAsTQ3N9Ajw0HE1YMyhyOLcb7lI3G24Q",
	"a1hPUZFEg3F/7YFdwbMNc/z6vQot0ETmvVHPYM+cJ6oX5l9DfCjr90Df7I0ObvuuYbCwsENGlf4rZ9cs",
	"7d1+Ma1xZn8oO6Y1uxIOAwfQT9u74rkZbtv3Ok/mWzzCGkmUpYVMLt+CNZLd0bxoOxNvy/SGxWHLlA+3",
	"8UTxX1lckYTvxHxHhdkP6cTJjYaU5oigXVnd1EEamkXqRg0KCspQc03FAGYfaHajB1cHMbWqYPOoUgXm",
	"ql/OCX5vIcrwAJ7EDU/mr3wi2PUk4yImB/yyYHrBCgM9tAWBFtpWlgcu8lLDM/Zw8/PQGv0Z4b2v1fmX",
	"c7/iuN25TR4PNbs9NXU428Ywbqk92D88HFwdjva/EbE8mlHtm1rLHsfe9RCYtz8BRrQ5MarAXw8r6m/Q",
	"LFtOpMhWa4+quVKXbCmL1UCCrRAl0/bp3MIjRhcli3PxANpzTXXEeynl6nJSKpAKW6Ygw3XtWQD1x5DL",
	"dKXhRbYyyXGh//CyvYfbAt7vMedn1ngrNz+TJVMGOsJnRJklGKEjS8FGODUKpS44Q4eQ+mnYfvqCTUue",
	"pdGnRr9jFQoUsfc8aIu+6703zpC6ptkEFcw0RvKOv1UiqFVooc9jbkaUiqTMfjCy1n87N57GFS5lFveA",
	"m0qpNrqavIZGt/0eyHMRXblpTTPTfemAk1HRDeWdYMn0Zm8gnMpcKOXmsY+l+HspEoP2Wr+JkBv7vuGq",
	"1VctzEG4e8+OLXYWR/vudNC0BRwR4KlczJFk3LVbWrN3yhKjOTMC+pj9G1+8MnYFWrZKZMGUIWRa+bt5",
	"0k1lOc0YPJ9nGbqloQdN6355vdLszKjTcY9Ew6E6nvCsi9ph6K922LbFHC9KcRlKvTTLPs1QNhfM/rVW",
	"2mbFkmtWHweF/4a/pn8Y3UA8ONKpa948FH4c0AiaO1cKtHgnLbmMksSM3JTRA+OEUasymnsp7NV+7TlX",
	"40p7IKhSzeZGtZnxG+TItJgzHXTdv62wexosvS0AtcAK5S/rlLGUySW8IiMIMU+JYzvMuQeu04zmZ3QL",
	"GRqVc1HOpR6RTx8//q8BTRKWWQcj3xotDIoJDW8+1ii9IinTDI6dGQUQMiLnHB8Ezb8GoNP4YaYrlF5R",
	"p0Zl1S4TQDAnBbAaXeVmJ6PWuoEbxLyz6v5NzpcrkcspB5cammXWQ5OJhTnXcCO1JHegtdTgJCKJ1met",
	"moIEanbaCKEPkkGdo+ikw/f0OKMFHgpcC1pP0xRPCTj8wvloumKSnUW5pGJQMJqCG0VUspelZugltOFc",
	"n5mW4GxkOLrzEO6A+VOu+ZL/6mE2AF6xRMtir+GETHYSKRKWa8JuNNhXpfXGUSshxWqpdje+WgWLaKGz",
	"BWs/3O/Y5XyclUqz4kdGM72ILO2KFYawFvAdJL1SOdkzwb7BkSjFpZDX5pBgBwNAKaq/UzYvaIpuwiBc",
	"xk8NDHsOc3Xb3fESavillHoxsX5l7cWciNSQNlPk2oqPpj0z6EIa4t4pzWt31RojYqRccv0rK2Tl/L7w",
	"eFzvfBgi3VyBKEyv8VJ24jayXXPeU6YpzxShU1lqgLW2SRvpyIIaJYqmSPRAqS2x46maYLCVBNcyiYVL",
	"qMaNrgLeDD+b/ex0LahhuxP5ddZCglbuKOADDrxHaUXyssilYuieNyszoCanJAQcndElSaSRqmQRdRv4",
	"WbHCbDk82yOj8JY2FYtyQFb8Hl5X4GKPnC8fgdD9orVua0Bvrdzsoy9TqJKhv4S0/6oJOUNyglDYA0dS",
	"PgP3DG15KHjD8YwbiMC6/UOZZWDicy9+sPzXHw5f+QCPAfkrcN1aiwpBfMnN5aJX3qi/lCnNaq35ks6Z",
	"2qNlyuWekW/kWIzF/8gSHBlpmlbeFa6blv4tqbmInGrNCvAnqQtvQeQHaIqg8C+ZUIDFF3966RxOUQxz",
	"vnw0ywbmds2Wdd89Q0JLGh6XSyEmV/t4eYGHrJ/Hhf6UWTYx6IRmMd1DlMsJPOirdaovtgBPUThunnGi",
	"Fwd5QzU1fDWnhQZSYymhSSGVcl2n1GgqUsCbIrzG4QPQu5KnDOylsP/nS3MPpVRTxbQiO+Nyf/9FcrC/",
	"/5M5WWp3RA4GL+yYsMEs5eUy6GCaDg4+uNYvBgf7QfP3RiRuDs+q5gf7/+FbjwX4SVj4LQFPmdlrMHtl",
	"Gcu4WpJpqSuVy7lhDIl1LfLrZjc5S4zsCv4wIH4a7rCWhF40bAtRU912wXfAIM+xaZQQkI8aVtTJRrng",
	"mtNsksuMJ9FXcc9LM640sgjoAo/8XCn/ZqhthOdwW3/1Uz8AUm1USfUqZE6VAufwWhCoepEUL/Tpfyl1",
	"/Qkcxz1yffuOwB18ko1FUAH3cysS7BpXRU5mlTO0tRblVC/66LSGztDWadqIF4YuZEGWpdLoM+B71C2s",
	"2wS0NlRTt7LY3fmGBqp8fa9nhVy2rUF3CBB0KGtbyeUDxm2sDiZZu7JKAausCGstNh4lbXMB+pVUwPtD",
	"2BJYrP9JA6wvIWDnsPJHEbxcnMMkp4XCu6SFdYaBvJW9h2o2sMERrcZdtkAjVRhRmV+xiR2w4yQGZsiq",
	"i9K00Nt18k23ATjGzlqWt4fi2I73YOEWNOf6ypzpbf2zSAVBlOBlcpI+ykp5Wl/jBt+pBpSmdwd8IBef",
	"+9uqYQhiM3g0BacMXZSJLguGxkrvgWG14TvI9kcxKb42XvzV1wO5TiltTnVFM55iNCCukqRmUc4jwk37",
	"TFULHI7FZ3MhcOUtuVzMWFH5ZBal0QmMpICXhoHVigkNHMdOwds0pm4ewShpn1wzPl9oNLoItJcZCeea",
	"MVG9drRtS+ilOaE6+mKDtx1L5wziv2zrmq258yhv/2rjPIvvtklePgHw/Bj3iIO3YGAMY8xbWLE/vBww",
	"kUgjAthQR095l2wVIiRqM7/DCxYYejcCgc2eDAhrb2u8Iho8m0+V42DCNVPoNWiVtYmW1ouw1AtZsHQy",
	"XY17uw8ABh3QtiXRjCrns/bodIpHrAMx+HFvCwtsxx1xh4fFkElbqvWUY4f10H65/4Ew63rDC2Qm9Vgq",
	"WepW0JRvCqkY0jlq2qAUgT4oSz0in0o9l4YZYgPvVyNkCu53XIzIiUjksmpjsz64FlOpFyPyWuqFGREH",
	"Q7fisFfN7o/QcgHBozUL2p1pwODk8ypn2zvsUBcokSCVRm8+cJOcKJbNJpmUudoY/h44QKCLZYBPCriC",
	"C0ibIR/yor6kN5OQ7rseNZ0LEQDDUnsgsePj0T4IXDF49lvw4JPGk8MT1yYrVgk6pQ8PNOzyWZ88q5jl",
	"s/izhz3gk/BqbAaPY5MgLge9OH04VUht95QAO3Uys0B15vIkjDq1q6bfkqZZ4GWGNFswXRYidDwJLCLQ",
	"ZGs5HWSkrdwy2/6Yd32ZfiflPGONcYyiua7TX1mh2c0dO30CY+FdO0Gw+B07xZ1VH/Lc7oZ6/Pd20eEV",
	"G8ZYWyss+Jn61oP9/ZcNa2zOBOUAWgve6Jt6e+bIo/qcLbngvX7vCja913dW376bsN+bIsJ7fXyCjz2u",
	"vXVzhWb89olDV4AtvR+Cx4DKiN1cqDXNVy2Ch+KD6FkNDODb0EQFhTdS1CH4AdUk6d5ea08pBQRY3F/n",
	"2NK1kIsBeheSx/EufGCOJM2WeUZ15M75kYo0Y1NaKOIawUFxL+5IrMtcqyE5Z4wstM7VaG9v4fv9XQ0T",
	"udyDbEp70HeJoV9VkGzNbvkjyzLZJ1+/fsdnZIf9g3w0l90YwmnGvd3bW/MH1Qsqvn5lYPH7+tU0Mf/f",
	"47Pb2/8fcSmYvn49mrPbW7JiBn6ZpcN7723L1OLI90vnNeAO1789Ox/sWIleFE/nVulAMRKu2ixhQLNv",
	"6uPpUz3WacjvX3V8jgQmaHTbt9H+33TAqCb9gSZMf/KGswb5Us0m+Ey3tSAVms5bRs9uk7KNmbrrbB+x",
	"W+eELqglYquPo6IrqeODUNGdYakbIfDOhe7Q7fvyEbDVDZNmNgRwu6AmVixDzMUGNEdr+13gGUt96N6a",
	"89B+lohjUoZjee8lCE0HS0TGoo6LUeDKX3/lgimbAW1lhX3PFrjQLw5j2kg1MS21jMz2JZ5Ixk7n7gn0",
	"2CXH+GZIBbEzEFmg4UyOe0MH6OqRvLC7KHQWImPdWBXWIKidzfjNJLNuK9sgDyhys1M6tIrxuEis1P1U",
	"trZUtY3OdtdeqLTduRdobXft1RFNtqlbZ/Kzhyh8fqwn8LDujnXrSKx1uP/yT1VirXmuBy9lVPWLZNAK",
	"SW69NtiR+u2hGmGY36tTO3zH5GtZCiPCvpY3j8IrplJruZwUcWP33zIp+iSj+ktoVtr4AHqXoIFuZqVl",
	"PsnY7J8BVpNNOUga+IpzLr9HpzJbzaV4Yp6e4ywTkFa3FwLeMXkKeRQ3mQUb43es+Q1k0E3YY73Zw2B1",
	"Efpg/3J5N6eH7nRN35qCPCTB4jowibvSwmBG9ZYgZnJrN4XY/OeQUjPy9vyOSXgjh5ybNonJkLhncEoU",
	"X+YZ8vOC5QVTzpt2GIlykEXKBbXJcVrSp32S3CA8oLU7HOvLmiW9Y3LJdIw4C5a1hE3Q/BRL4Bk9kUJT",
	"LsyfmEopyp2VQ9yGY4cIbj3t2UymHph1a3liljIPULXNYjxqm4vyA0UXE7OpbxkUj323SpWwNhmmHcdl",
	"woyxl4bR1L2J7R++jMn/vrWT/z2I8XjtbhYVgHecyTKtUsu5F6ZSDRImdEGzA0wq2dZI24kxo+bx9QH9",
	"FZajeTDbI3ZAkxfS7H00U2BrtbYxOXkTz8q+RQrFYHNd/sRHzIoY1y/uRr9deYTfgey4OyRhrl8UKAeH",
	"w1eDWUbVojvD76OfgSem0qfOVuFov4nBjZQf7E+U9JsDPqt+Oxi+GuSF/AZH4TGyVxxuzF5x+C+XveI3",
	"wUQKmi8w1cT+9hwEMqhNrvbtI0TUyYSlcwxDjByq99bJ3zsN2OAlvWC8qCvjals//4avTMx9lt5M4IV/",
	"krNi4rzZtjny6DpQS+q1s0/+k5QCSrLUktQ/hlk/3BX/TNTM90o1V5onKrIjGzajK6xr41NFK57rWJZC",
	"1zEUOoK0FvabeFjyXh7b+IvY1xzA71O/5sC2f5QpO2cZvGx1ezsv5DVElkFDAk7ve9ZNE1+hPFG4UiQt",
	"mrhkqwgW3t7kGU+49oE44N0Fbbd27Nl+Q2xFo80nEBdVrdi78vm0zakrtfKQ5z4cYgJspu0D5RNESxev",
	"7eq/2GuZKgQUPBDHve+rKDrbcNwjA2g58+GK9ZFsRwjQsz8N4UhPjFjgu+PDZxMKTH7q/P+gW+jvffen",
	"7fv6cgIh/3c8Gv4NSzJqZZqKQFdBCS9bTsijaK+22ggloy9azLmCu4JdClN867IQiKbQS/3RydrmuJ5U",
	"k7S9TZg2sJVZFqQHqg5ti5bv7vnhgOhgd668EvBrFyzuk9sbMn7Y5I5mI+V+YIVBDPAOhK9NWXWLmRke",
	"4sYN8tlmE6Qn01Ns7+KHqgf/jd1r7Nq71D9kgC3ST1SAYw6KuGEq2IP6ujx+vjzGET/1uK5vsy/TGdK1",
	"LugVKxTNMJcv1YsZFzYRV9NJeS4LrhfLLgLyDeBol5XCl9M5K6i4NMqQDUoxasezhxCUn2xSkdb20SMN",
	"VHiBolrDAyJJUpaWWFmTdTmqnGFeVt/OXqc7fjd2H3LW09Brf5OIXrn4W3/bLh3hB0jlRaarQEt4Sl5t",
	"aHENm4SQ2sA57bGQd7nOvwlgMuRtDgnZuRxAZmum9AC+7D5E1DHaUMryWFYXJ35VhxUbPnC2ztJkbXHP",
	"19WLIfl+s3fF07jJv1UMQSxu4KnmxiEnRv3fGCZP9eIXaP7BtH4c6a8riZWrRQdRmoEQ2LoEOvkZJLdy",
	"t9l2741mGuz4EVZ4b47RwSksUHhmdwyfD643p4Xtbp22gGLqn3vCqKW87EoehmK24WE2RC10p9mg0/ZG",
	"PdNp+Kb0JU7vpHxvVrsfQYt7PBEKYX4UMelzNMzR/GpWHdeEAm8Oywgh0aI5plNZGBy5C2Fii5xfTmq/",
	"qIdEnzVPTORJFowDXNTArzawGW8dvWzcw70r3UEL3dA+7k4A4ft9QyV0gcu+yWPy29CmuL10+EOoBEI1",
	"zJb++J+m3+4DhMQOJfAYw7dtyJoiO9cLJkhNc/RT3z8m6g7SEFuX6hHjju+vE8bID0qEcIHyXUCCEAfK",
	"lSPFRxc7zXxdqvlbZ3ncFqhNF8mDdqXBGc0mPIAhnpyCK/Hj5I3jadyrd8uUxNA/9irSCH7aGHQrvNl9",
	"O9fQSDryTe6T0cCsTZ0irzu3X/r3ynEXSYeBFpxGUrvYAyETBU8WHYYw/xbkG4FRCNQemufZKixdpKoK",
	"UZjmYkjeVoMTZ0eC9BlQtiXIvgfVbeql+qt0mBDRpnxx7dUdikA9NHz3Y/De68ioY8YtMu9FpRlrA4JB",
	"Oul9u4emB9E6TnE3Ut+uT/vF7HbtQksViyN2B/4O+Q0hy9tEbUhGusWQbp2R2kx+8G0HaefBNND6kRpQ",
	"dyKqQ2Rd2GjzkGZDx+Na7sC+TzbY7znzbtR77Se28hnFWle0LcNVFYqDZzmuXDmZ9pNANAtZRxKx6GPc",
	"ey4YLT6wYs5O6ZxVRNM+HqXVZDPoQpamD8npPCgJZV+EVJmYBYx7IyjpWLBEFilc9Vgwp1qgbWlwucK+",
	"kCKRZqbvKTbDrNcyz5HV1corrvokyaBKIyach/dTmy9ZmL1JykLJAoeGZ1kz8A/UKGMYKCYTKJiQ9omQ",
	"HtIuAIPttx/QymwgXpvNN0BzZwXN9yFePUoxfedKJIAGLPDmwMQi9zdQPTezSXQU5ltFutESS8dh2Xgo",
	"y7USiU0nLaquKdV0atPjY/5FGAsyUD5//qO8JlyTa1lcqtHz52NxMCTnTKRRcKCSXwOmsTg0PYorVvjK",
	"l64TlKGDcooGPOhtayC+8H1sgUe3jICezMn0GTNxLKhDNlWGJiqA7JAvIfPgGmIqFQvpBpBv/u1OICLk",
	"l6Ozjycf342ePycfpSaKzjAsOJHCVt8IS5gBtm2i+txW+qxSfLYVyGI1Kcq6GyQk92sqVCczAnqWffBT",
	"5Nos/xqOAUgHBmmpr0C2pJDKPVlUyUV/rlVO+yvNOFQwAxqZsgW94rJwokgil0uuNRdz0/Z4wZJLcg0v",
	"j247rnmWoQsDFKk0zT4zpYP9qddEdakugjrCCPKEp8pWggNFzWIEVLRGBlCLmHaCvIwqPYGjlEa9v7D8",
	"OGQ2QviRWPKCXXFZKnsKXWVaSL3LC+XpYASlINky1yuCp5yMe+MeFrvzBbNdFTBsXaOr2mSu7DrWDEXX",
	"h0xeswIxZiANiFw69oSFZX26bmWYMRcV18hq2VybWZXzQqZlokf7+y/i6VJgV++m49vExwWzCb1O3uCD",
	"tP0nXjsj8nXcc79NeDo5MDz563A4vO2T+pdD/+UWKQZue5CCR77ypROHu6pfkukKmQDeFLBHyFeAYi0y",
	"sZKr4ZA4jCxSLHzYXfPTvsTRLLOKK+awN4IuxvLt+h1C4wuhV9LQdvVCdfIGk9dBUlPP4Z4pe1Fi3UYQ",
	"r2c0Ya0MytUeHoAdGStjvqe5ljkwFp6w3ujPf/7z8M9/RndI2/wwaP5BlopVrQ9bjV8EjX9iq6mkkAnW",
	"tv8jtH+0apvNPP+WDL+sl106g5ORo8TM2Mi0HJeURZtz7vBZjffsdriKeaYVYzP2hrtmRTBwbLbmZLZM",
	"v2WOre/D3l3q984gdnjrqKVmqHFkxEu2wiDrTWN5iRc7qYlKqBCxPWnayOFE2tbIMa0AkJbAcZEfuieV",
	"iGtyVz2BI8/Q6m+dLgVfp4CAafjSYgUv8QMjMtr7lCxpymJJ+YxCXDH+bS4iJ/QjC9gBP6qGGBKdxmjl",
	"+Tpatw3IlCW0RK4GLG1B1cJyoJTslAKXlMbJfTs1La5WBC82D3mMgQSGRopct1isWI0n2+YuJDv7ZIsj",
	"3YwYctqkn9Of+V6F9Poux7jVB4Pgoyx7FJsg7NaEZmHygCDRac0r2jfthOqjFOwRwRJSsG3hgradgJ0u",
	"Cqq6QKOCZqtfO/I5/3ND+XFtOUC/2UBba92Ji98pFtYknrDJW1xCyQLis+M1pO6eGyGG4zhyDZOqV+By",
	"gSxFMWvFrkBzX4XLqn2u+lTNRRXrZ1vLq/VhhUTF3nCEPw7HoihmI3LGEm6EUZqRMyouyQ8lBLgN7PhM",
	"uRJ1WNSrqJoXprnBSJnRsSgUDJah8+m56VONJQzeMv5rNdp0RZZc7C3pDcGoS0LJNRepvAZo/eQ+GTL2",
	"GwsjUxi1FrWb5qoMp60i2oJAGNOtnkoU0Vwo8183aJQKoFzJWp7wzyX4dn6Y7SW09ZHxMHCMemtpfjqr",
	"FLRidzqffl0buJMfq5jB006/bX7NEFVPTD5VTv8lvblrGQCb/35zFzv2PWpUdqbY39DzdgNa71pNopGk",
	"6ikKSkQTfW4ZPop9twp/3rJotx2xWbP7XnG3dqwnCpmL59q5G+J+F3XUI1vifazh04vh4TP8+4p2xJn+",
	"Ozb0KWNDn5jQY0l9t6Vz6Pvw/Ah2nHWx4dtSM470OAymgurJ8H5fBoOgbctgHor8GdhdRLKa5EzQTEdG",
	"OsUPCCHUyvWdyI453GY37nbGB4fxzDj/RF7Zpq4qSB8ygT1zfw10WUy74/KZYiJhd0Gn6/Oo2PztMO7f",
	"Gs990rN/ap0U2+Hb22fWerDHX79XmRPu7YPb4br/qUhZwdJ2eDHZmdaqzuw+hdclBoBX4RiPWCblvg6R",
	"frdau75tpaKHlyB6eP2ghxb/eXiVnN/IVv7ARdpdTviJI+XatV+eJGTuslmdpWKw+/tr8/bfOzzNZ70K",
	"Jnv1mHM9PiE1Q78eb9yu2mHn6EzgWGqMoz52pbDPVc6Jx57yjsFr5uA1AtjWVa768hjHPP607uPDvkWg",
	"F0w2mclSpA+6rm0daKgGul0yyt/XRfNwanoouQTD1d5SDJdYyFy1HlSOfIC7CyYkNpoQXHxcvxE5tyFf",
	"2Ga6IguZEzD9kZ1pwWiqF4MZOGnhLvcJnwt44kCsqF0Yz3PBETEwo9OO5bbEOr34rE22J9lRupBibmYP",
	"akEmC8rFroMyMqoNfFXlsj1iJq9xOKVJIUsNb9HuSSTAVsC2a7z2ASFvjSjYSE4DswJoAJXgWjsU3yCI",
	"8+W/smZ2oSaCfLsIXppbBCqtaduxM7WHpBBrFaJqKHwI1qoS25Hcpl231ZlzfgurlmGohvml78pOujLa",
	"fSIL8uz5M8wmkckpzXbrJWLAM01NYIy45551oNsmmsKBhwEV20VgVIiIhmF4XDRBWROa0RiyM4C0qpMe",
	"uuKbw9/r98Bbrtfv0XSJuWMrnNkWLVz9rh4T71ZnrvvN8BQe0586XzZMstn5wbaLwekh3C4E5zMrlq6o",
	"9PqWgT/FVk1DKtnU4S5tW+/ZmzoExSs2whFs8qa2Z2zObvLt2v7CszShRbpda2gVlnLf1KH9SLuph9n2",
	"OzSPFpjfWAwCH123a3wsRb20+kaQmrXYtyJK70q2VevKxWsjNFWl9G3QAvXktmteC4rdGOoWKcKwRZ96",
	"gvw7TFKrIrBFvyBBOLwzw58/xtL8HRHFxTxjtcQBZMHb4VxrIhUwCWAii+4qbtZD++SN4Z1YV2yCvjp3",
	"c+I/R78gCGsyP7HUCNsYBgvxGOh/dHb2gxW0h10R+xYi6IqjAmgAVExSytgV5EiABm7VC66j5u6ommZn",
	"xBnifiUAgRfW7mxxdDPgCM3bzOygX2HnnfYjj4WgHnlrMRLKgmvVfspa8DtUn/BEGdO85dKMkeuVD6PB",
	"335lhaxce4zs3LFh7rmptl0unePWW9beni1TqBhMEHpFOXisDLdNW9pcYlTn3Q43NvtPhxkUPDPV5rjY",
	"I9futt9V5LcV6gV1MyHoG5CSuAS14OZoTmcVSu7iv2xmWfPRdKSJLmmQlRHDBmdlZpU8H0lEBaQRyTO6",
	"qlwccUa1bTSWS0MyAde+zgRRrhnRi4KphcxSjH60TpTElnjmeuU4D3E5lkDfdv3HImMKAi+sK/0VzUoG",
	"kYHsBsMpXPybWzD+bhYoGC0G7IYmuorTUUYpczmOUqOAACA17IWI2B8e3IX8N7nXefSVIlowyR3Ex8Pf",
	"vGBUs2I9Csl7iFFzvZS5IzCsacHnC1YE8zXRPQNjvsGmIc1MXg+CIv82GKqF01ePilO7dZOCGaTG0Oqz",
	"QsTKwNqoP7MYHCE8dT60ggtydvTOpcUajsVn139BFaEQQhxmfnBpXK84JRdfvxrMD/En/B+Wer1oojMp",
	"lZZL/quBYSGvg9NvNswWiWFQ9vf9+w/KgZXznGVG4WzGBn7mOmMjUgdAmx9vb8fitUxXzY9Tma7Mt5/P",
	"3jc/lUV2extNmOErD69LKdAuGxTf+4hPbcOqVbCBYb8lJAKqqh5bP4b6SbFJeAkXSjMKIZiVl0/MsxuX",
	"ZXZ4YV96DeqrBCKQ7aMP3BSOUvW9GtcWevWxuSBtrWT57IoRmhWMpivvx1FbgsRIaBcKz1MIE4VoQ1Kw",
	"tBQpFUGlZ5LQLLOb3k5efgOOqFJM/uH07+2cOSvRObzX/66kGJ7R6w++IGt1RPkyl4V2jwm9UQ/eU7iY",
	"75levdt2LTtIs2HlI5rnGWcpMQeJfPz02Rw6JKEheeMPgL8RgYvZngEXGwtw1ndiCzmyo9qwZyPb4L6O",
	"xTljZGoAGMAwA6gvl/Phii4zFwiQZ0zbxBGQngXgqXZ0Jgswmr71101a0JlWI3IxtpFGI/hl3Lsw7SCl",
	"KTRjecES2HfLW6BL9TPIrLbXDzXuasiTX7GUwEkKZ3JfoFs9stSagQ76PUsFPTPLXBarUQDKpzPSGAok",
	"YnaTU5FOVC2oop5OIgifWLJiDjECYUpoG0tby/wNmCsFl2JEXMJSmwbebOFUVj3MMauNZ7r6YlMwQhhd",
	"aYehec4o4I0LGK5mXYaZIeFwNUw0TGFGE6bvnSYlrDvc4mHwEU5wOz3TfF6wORYld0icrvBCsSynLuNN",
	"S54BCQK8LCWCXvF5JfThHd3FJrqykbtER1U+codjm67Bn7STGRQ98PV0MJLa9jNHFIVdkNUgo4UEXpYw",
	"Hy9PFP+VYWqmZV7IK0ZyVsA1IVrB0n/rwf3VQ/enKgNSv5eArJNOqL5DOiTAgMHPpDJ0Rv0Vgq24ZCsb",
	"GG5je500HwjrC6ns9RGElAPr8hdMnEMBpqNYGItjuVxKAbdcle4BjI8DzQQFscNyDGAP+OOIJks2sizl",
	"Z8WKgXe8SKmm0LJUrBgdHL5wzXwSO+CA9VFpoXmS2RFDbW260ixecRAQ/Du6hgQ5+vim4x4qlcbLCBmV",
	"OQpLygWOMhaGimGfcdVdFxGeXKYNaTW3+RHvJ5vvp76BltXn5TTjamGvjQF5Y8RZzGcCzarzNBqX+/sv",
	"2OH+4YvB/sFg/8D2OLZXSWN8f8NoliyEzOR8BfjMqJiXdM5GTNztpmqMs2K0qEDah6uqGbZ2Hzq7l9fa",
	"k9IkqFiN2htDcl7mZlAFfDZsDi5Uj0FCb3FbkMGcc/P3iFx8HePWjHsjMu5ZEbwY926tsMKy1LOWVnOj",
	"WIyafaw9vtXYsJgZTzjNYMPNTZ1lfG60StcVTNCtjg3ScI3xbabVejwe99BCgEG75t/YZRNp1laDzKJN",
	"rECYmEXMFwO5pzARlChpyRLxEiUccxJuWaRkCGl84IJLqKjK1DRrtqDJGPynlK0CoUjGLxlpV4/pEDhA",
	"jVpXZsuCFqhba1S7IbHJZNLQpt1Q6oZjAbdknlktjuEyp6wmtQDnZrwIZFfMhIT5hyp7eVwkmRiimAi5",
	"hKrUwdomXmG7m2CydbmhoK4PiiJD8kOAqonzo9G2+CwaHPPLwBF9LGztRHIFiZ2MnFMxFbKjV7nNwnOw",
	"v9tY/+F+PGtHMWc13WHt41Ytevu235OzmYq58H2MrVpd8rxh77Simbcre15aC26uDDqQAAwZK6ub21zb",
	"tATZtUaesEXUMc6amSuGE3D5mExX69hAxOracJssNGY1skYrK4bbnE2oJ/hjY4chO+YaI/8JiVEZ2D/7",
	"BExo5D8JdT+ZjUWs5WAw3Yg2ct4ytEDatuyaGskXcTld1QyWiSzaCZAC2d1euPatouZ4HXCRAmqmbC65",
	"f2bbVSkw8YS4FKrdwSLXC6YXWKo+UEZtUSboHcj7XBC3n6aDLLihw7pZ/hfDn2Abdqw73e6InDu8gTDZ",
	"7oex+wBr9WqA/zaTVqwWRocdtSqx35H2oH1nNfFD1WwnXogE+nDGK3JtFIwKG/7pwo/fKA/lHixsmUQz",
	"EUvJFStU5LhEY6PvYAZuHNZY3lpdFjTzQmggYbm7sNuqDlosBfgNNbft8GMBya69LmE2DS8Ym3cB8/e1",
	"T5K9U+IpI3bOzn7YHWLysS5LJRQTL7VcUm0ZNN42/r4Cg6K1MoTWRoz+GgsXiudvQndFNo3JgVAWCmQ2",
	"71my4IKRjNECMmhYDuJqYrbvOoxOX5ddGJ3rtEScDok341cedZ4R1QC95pc8Zymn0cim+FOuS2IYr5SB",
	"n/CULJ0kgVtdJYhsv/EW4aDbP/RaT+2YY1gn8GsKl2C21wa0Vs3F7IzBZWo2k+KrYCT8MngJvY8U615I",
	"qwU2Xs7hO+TJRWhAsjw9PkLZbHD+8S0U7cS7t7KbDx9SvLM6tZhcLR44+nBTYGtXK1BRRwgKDj1MRehC",
	"71mY1Sbt0hqiyHTeCts4Kah6erE6DD9+/nxqbc0kMWqEDHfAk+ewUeclmhqok4tgJUXLPxaenkhiuAvk",
	"UolxpGgNGpesrA4nF2TJs4wrlkiRquEDq9K0XD4NKB6Hne4noefbA/0/vW1uvZMnNosBdHb0rtOBIi/k",
	"Mtdr3mXx2RNcpwk2rt5n3fX0/v0Hb2q2AeJGZyNWlHL9uNFRwdRsrkz7Y12lNaPNZJbJa3irowWHrKtg",
	"6/j61csvt7cjclSxR1vOtyHfEJ5aGzvLUoUjNO5pM46BxazumWrqr5agdvjMr2p3LP5HlgC0UXqjj9Yr",
	"oemNuRvdizEuC9fbt6Z6s7xMytwKkc6aSeHJ8HMVSg4Mf7mkA8WMQqiDeFf/nn3yRkFW5RH5+vU7qLkZ",
	"IMq+E/PU/PldiV4b/5VRpW9v++Tr1z38yXzdM31vbxuixWuqWGpfPxULBVWLFNhoDfyZUHtLjIxgFIFm",
	"LN7IhAQwNR6yTYsAkLGAhMlmhY+0uBh3cWWN295iDRKrhJrAfDMkb6mnFbBAo7S2ItSyOSdxut+5VkRe",
	"C1RQ0fen6SgR2HzgRqBZNTWFTNEioZoJih4Hc1SHdoxQwxJ4nmIeqGcKZzLSKpge0FMSYBuRv30dI6tG",
	"s1tOc1YozMHZOCzYYDgc4lcY0/x2sH/7BUeeFpKmCVW6NSxf0jlTjY6v+gQTEjdAwCiUjtZ2qiW/Yekj",
	"Qd8EYCrlpR2kqRPUsihXoBmotq2iU3Now9DOE+x30DYz4Qsa/3WzMt1M8gG5gZVmy8lGFo/tPHeXZF6C",
	"d8MCoodgflehrWILhg2CPYEsWJbPyowcnRCqFDgq6SE5d5A3eHrDaGkImSuWxXOCGDY+UbpgkAw6IjBC",
	"Um5yfv6W+FahxBx4lvzl/NNH/6jZLrMZu02x1HmwBZ2Xa4eIf/TOSTd4H4mUX/G0tGxkVRPsq7fS+gUN",
	"LbsLXta4RHXmhzZ7PPyCnZ8pJ9uZ6bAwg30IBjsS5VlZoIj5cHXIv/1ayDcmp3ZIdgPGRPEwhOLJYmoK",
	"mGSzuGXbRUmibteqvXZFyo13hPZgnp2N4f02p9Kpa28TrhhRZJvAINsrsoxtQ4LeSTnPWCO30ybn/r+y",
	"QrObO3aKppnb2CmWempj0AVLC5lcNnt9ab8IHpFSoGUmiRXzimetCoyrlgJ61uGo59ME9cytM/D9B/v7",
	"L3shWfTg2ZCb/d7aEFcLROyM/7MOJNCyT4JgShAyCwietCaenWfPMfuQry1pAyZNw16/97weIdgZTnnG",
	"lJZFWLZlu/fh1zS5LHN/mX4xQ8lSdyzwODP308yavqogAAPOiMAYYNnzLhgz68ANzXaJf5MjO+wmzyRc",
	"t/YpJgwsdiP1XCx81IPpfEGLtGIRDW620my71O+vVzbWqnW4gzFiXOpcy6JWjaiZYERdTsp4bvc3XF2S",
	"Eo00gph51FahAeCPmsdSUf3iDPretrigUL+GgVddSjUdxi/t9rqwaNCHKjF9MxeO/1BRpk/D7x/f62WJ",
	"trNWNm+xtUa/mmgVWFdAIbW3J/FlLTR6vyxpcZka3cEKFBkX1WGt9Gj3GPy3oNAHgaf3hKf4BP/FkHP0",
	"+wE26PsfDl0PBKVte3SySzThVeVM6xYFDhNcVIuxlTs2rQksjjWQC6YO2gsxv/bNfw+/bMyfFRTpa2+n",
	"r5hRy7Jg1o7lCRuPfyuRLAop3JZCVQ70JQKXpMoabUt42YGMBvEL5RqantEZ2EtyqWgGzus5hhvszKjS",
	"TOm+s6rs4iAQkF0b4pRNzQH66a9Y2gSbeUWm1rTyX0Gz7S9H7209lB2FuRP6ZCmVJmlZmFNp56SXQtTG",
	"qb274gCwmVOm9IDNZrLQUPHIoEeWKrgWd2Y0yxSZ0uQS3KmhLpKtJy1Ls8iAsVaYd2Hoflm2OlyU0352",
	"lshHqlapXSxU4Mzv32PBUAa5tiCu671Nf/Zqf78fy2Hs/S3uXe2v0vdaBNyZMhoH2DQ8LOocm7r6hPeG",
	"Nbzu2rDGq0zaGSs8xU5pCGXbCRp+D3yoUDCzdwwmEHFvRmnoVxkrOg3Hzmd8aDr6oKkTPDKcS4zLUO/N",
	"O+gEFpOAfBOLr/ui2TlDVtvWlFeX6IsAgHpXBHwH9hj4u5KC2CHjDzhiJl3OCbXmOpfEtsQKPWnMVVMK",
	"L3Y6M2tjL4ZjcTLDJ+9+MIaQugo9oMK6wzjHIOSdLCXTUkNTJKK05voUeHJonU1SZ/WP3mTuq3XYwsps",
	"FTi2OiK7yXnB+mQa2E2JGRy9PwxjU5ouc7LjBPVddL5W5J2s5rB3osv8efhy8axPnv0xNf89+MOfFs92",
	"awsJ3krcVPFFIBRG3aBYTwHA80CZ4/H583tchU3AGcJp6RyIZtyb+I7jHrzXBTg0skv1bm02oUICFJ7W",
	"HQuwXght8P+KHxyxIH0Oyc/KOgUt+Tx47q1Jo13lKzq4SVWDdSs1BC+Ydm51hSL2ZLt6PnWBvF0ipzZW",
	"PBH7Z1YswwfN0dbZ3jEXymaLAbTqd2aDRxCe2ERzB0i7IPyXK1DQ0TDIbb12wHVajcEX1+wYnITumEPa",
	"9kUPo5oZBDxn7FeuCCUJE7qAsikpwZdoVlxxd3PYfqoaqbq8B5qzgiTg5jI3d4X3FlTV7e77Wa9HzpTz",
	"ETK8bCGvnaYiC+X6k5TPQP3Q6JGjbLXWYzfYuR8MirYOyKKcSz0inz5+/F8DcwNlVvfx0zsnWKHhwdNV",
	"PSMp0xjuZEaZ4esGenfjvwYQh+OHma5symabnM1KJ1Bh10xO3FHYtRAjdiyU7w9G5ANbymIFaLOS0OFg",
	"yUWpmbkAoNXhiJwanotVGa1e4erYovu5mGdslvH5QpOUuVhuRwFBrVaeMgFOUL5gZ9PNkOZ8AlmTewut",
	"89HeXiYTmi2k0qM/7f9pvybsj77arAnOU/DVfr9ny7/6zN3mt8BeppHYwCgDT6nS/GqwA8/5zhW2B9j2",
	"2R2D0fZvYynPt0n07Og8zPTsb/boap/tDskxFYRmSoIrNNMQr3z08fMP7/9n8vnt2YeTz28nZg4mrngh",
	"BUhL7sG8rpx04nNtouk6vu+Q26TNCRpqpn2kqTwlIU7C+UnaSGqyw66YwApHuV7t9l17J9+BxdC67o2S",
	"mR4RVc5m/AZj1VDW84M/U2Ti3CkNw3aTYRFjP7aR2kdJbSRaMHSnLJ2YYZXdwMXJFiBFlknQp4UVV7b9",
	"rNSlGSTHUsVgxYA7Bh19QSBaYtniPmE6aTrgxnhySPuBbcKQ/CaHdLvUIF09+G05OXZITguDea0Iu4HS",
	"4FcB24EQgGLlyt56D9re2vy5t+3DuRboj5Hc+nYAMmX6mgHfE4olpfbgqSH5kWW5gogvI9xiEO+NJjQp",
	"pLI3R1AfuQZ01CU8YBShAcjyjIam6dqGWQtUnmE9Z3/ax2MxHotn1iG+oODepVwhUqAxdEY1XMiXQIuq",
	"jNu677vLKvTgbzC32m60tsNl5m3uiiEbQOqQWOEADyflmMXSUhotoMAyBljyX9lmYvGpNWqQQXKKeFKT",
	"ILFFMy2H2xV/v7ZQDVd2DdX3TfvfEtktwqNSaEGFMhNFMtGIQZ7RJLRIuMbIU1GG+CDFXL55PVB6lbli",
	"9rJQQ+KHth7/LnhSyyW6IY8F1ahCoVJBMrpiRZ+wjC8hRAPCm2k6WMqUz1YDtOgVNGFOADqB0Dkq9Oj5",
	"82q+6kG7YJAt4MqWO08JnVMulA4M/E59A9Zpo2pVGG85FkZpXDIqFOH6mSK5VIpbv2MMSiBcwBQBJ4JC",
	"ebCvCSxepIQJZRgw1KcOasY7PjEWCAqa/nkkrvlrDwqb+Ojag8MXPVdgEZyojYIo896o9z0XSa/v4gm/",
	"H15xdq16/R7EhvdGB/CsCg2tYPSGgkjiO2RU6b9yds1S1OjqAke0voqPB4as2a5SN7V8qA+2Dyrc7QTX",
	"DxZuVdESt+GyusLAAixqCQQGfpdYkx2ykm7lQuAJ51MecyHAYrB3KNJvicIfGz4jXJNUMiWeacJuDPQ7",
	"gAB7dghOsbvZH8RgvoabtWf6U95WK2V+B3S4VLE51ZF4ib+cf/oI+YO1tPKDL6v8/bBUrBgKumTowfT9",
	"UNM5eDPJgmAwuf26WxMSK1ptG2SQeFvmGMhWZLhs5bm+Y4jN4Q2+fV8KxXSfhAS/OySfMbQ1ZyKF1CqO",
	"fZEde81AXy6Sve+XZdYH8x78BIMZKWm3tUdYj91gbMPmxJ+H6/wU6xl7uIJXCANCr9/DhZk/8Mx/n5dq",
	"gf/PMvN/mqaf5Tk2yQE2sxT4HxfwP3pj/lfnBN8XrFFdMXjIKOgVKxTNut4XfRpE63YEFmj0INeub8Sw",
	"nceIzGV5xEEwUwIEl+7sk/8M/r3be0C9BHdU76ZheI5ndFHwz80krdcIuHNu9ShrfV0rQVAxFuQG65Mr",
	"3C3xfuTpwjJTX6U92Aew2IMR1eyHYXOY/2MCOfx91e12WqeuNBAPKBkw8SWFuuGHJg9ZwKYKJ49YyKeZ",
	"0CqerJ5m0trOYff6j1k0pn3v4BF9QKGJinOUWTSOyvyMwVsbuYXP2DcJCjPZ+zl2Wv/KFdfoiQjbDdq0",
	"RDHh7kGFjnE8Zf0bJNepi68GAwT5T3DCho5PUlCqdgK2EHpsxh8o1MBFpRxUkacPwW+8aM6LLvOCpxcC",
	"nfCOKAV4SNf48v1K6tTcX30Bn05jRyvm/rHhCblFVbsoDkzANmwulkfkFs3KQJWy3KUqPyk4tw/mUMxF",
	"dK55u1qfsrZF/IFhIaCjbRWUmsC1VdjnzyA5nlKlrmXRXcFLsOtJbhvVndEEuz5/kRQv9Ol/KXX9qUjD",
	"HfJdNnk21caPCcQ/K3QvbpYcwi6TBVWLLomIOInItSam9ZC8vcml8okA4VlHsaSEuO2Cq8u6Xfov735Y",
	"/V+Hfy4/LIfD4TbJqlz9jjq6/i4XIpVsI0J8735jkV3IOUb74RrnIHD2cWbGVsSXS1A6L3mKkrQs8B60",
	"me3c+wAV6poVhM5NaxejYC0tvyyohhD/hIpq/OfPR+Tc6Cl9oqVgfYJlFvs2Egt9zzBtykwmpQLDrwWn",
	"BQUXqIgxobNVOC1kyrphqZnt8yLICWedE8wGYzqJul9iIoV7NFK6KBOwf+989x05Y1RJAVaJ774jR7Bs",
	"+PMHiA8ZlDn5b+s8q3aHY/Gh7iGIltQFo2B275NpmWVMqz5Gq04zmVwqqxwGsHn7F4ZhGQ11ykjKFZ1m",
	"Nknx8+dHRbLgmgGodrmKua21KV6pUuiF6WP9fICi9aFpRkgOifeXMCMopr3pLQjCd+Y3A6ChKEyAI69Y",
	"Udg4nCU8/sChOjo9qVNak8rQdtUMDjeYniRdBH2MQZ5Rgg0IVDkLqk/EgdlqDAG6vnD/963zo5xZguxj",
	"8rVroKpAWNGSsGW+oGAXJm8kQ6+eBMdveoji/qPfTWt/m5lveqc+PNFw9oItmIDHDLsYzPrHkoWAZ0mE",
	"0wbH2BRb0UcxoNQyvx8yZ57OnZO4amDzHyUVmutV3x5cWjBqDzni0Jp7Z/GxtkFhE1Hv3DvQq9iYCId1",
	"ZfLocj7y1gpoAMsLnqDiGwmqsef+/iToh4hQYYysrDjdHwvTu0mOLqFUxR3rc+SFTJi6Jz5/YiwPxpoW",
	"nM365GBw6J/9lSuGtp1feTRaZgsPDAzNIceZLFOCg5BaKXV0aiA7BqwiL7hig3lBU7br8swoTJFo+ZRz",
	"cjwuGDznU9P36M3xLnpVlnqBj/zQeLpynsrDsTgvufYusjbA0zRKWZ7JFfrPSVEH+DSj2iDZcej68KcF",
	"l0auAI+GgyFJKphAhSI7ubWQOj8SmqCvxCWDpIhsdywOh+Tdp0/v3r+dHJ2evj85Pvp88unj5Pjs7Zu3",
	"Hz+fHL0/j76uj8WL4ZZ4GZCzt8efPnx4+/HN2zdjQQgZkBNB3h2fjqrMMGQHF3xWij5599PbPjnG7HXk",
	"rZhzYQCFju8lMqqrEbmYJ9DF4Dy8SgYu5D6Tcy4uEHM+C9vJ0QdSVQEbPX9OLgqZMbVHee6QbS4g2+/c",
	"p9z6AHRinUfagUlkx1x2SvfJH//wJ5LypeG05gp3zavWc5Zcyv/a33/RJ/+1v38I/z0gOxmb02TV1X4A",
	"XjwZF/OSZtgh/MV56/jutfY1UA/rPaMAQ4OlTGkWuKljAHOf0DLlsk/MxSLJgBwc/mnv8NUf9l4dHO4d",
	"vNxvjFV/Q/KfeqM//uFP/V4mE+ts2ivVwLo/HWwRAWbYApSx6S1Xg3mSD+xv9fiwKzjvvdYbUvOgdJQm",
	"jBwcCKF1p2dIjozyKDBLiZbk6M0xnG4hxeDd8Wl4cjpcnit8BIoroCbie+saO17dzOg+RCKt8ufaJxGz",
	"wXCHtJDZN7s3gF0D79H2tu/GC/lXGxd6BdT3sL6CGl8r2Nwx6IonG7HO+QgEIz3rk2esNPs3uGZKH3T5",
	"BVkudvz+089vJu8/ISMLpE8t68NGN8TSXcyZSQS5nzovEuv3XlfyokQcC3f1VP11HfJsQ3LyZgtEnJ59",
	"+svb48+dLlL3La2PGGhG3N//QraOOOYg/ftG/j/hRv4oNTPXb4giiLlAx/gg2eUU8/jNmbjk2pLM0QnJ",
	"s3LOhU3a3kK0LIAb2+wHwyeRAuZsyQUfHA5fDWYZVYvABXVGFaY1YbMZTzgTeDPbHgfDV+bCIjtTmhkJ",
	"Pw19PpoN7dCJxDgyI/lf1RodDvdxNJpe4Whe8AbP15ADtkDmMyKk5V1htELL/aP7qqY33onq5f6f/1Bd",
	"3s3J7nF1YyS/4QxlAcV5/vh0l/k50+o+J+/hYsC/7G0akMbmNMGVo6P3yqxqOaA9MCqLBHe2Q12E8ra9",
	"0Luv8cigv81LvHFoOlPIFlSkcimYAg9kdwNLQXb2h/uGrewOyY9YYsvWElrSS0ZkqfNSk6XErKOpXK53",
	"GDxc6zDY72mZTy5jjxr54JIog30wR/hc0DZ/LMXAABdgqGVOfvIexpWBt5yiS5ZG+oqTkAEhjyVzTjJW",
	"qggQiKIDQFHj9Ae4f0RHym5JrF4p98lCea7tNJujjnzLL7EYV/cYAtGZCOJrqnhiJCkIGIPfe6Pe1Pxa",
	"7dZC67x3ewuvxDOJj2FC0wTWZqtlHgk9g0QFVRCFGu3tzblelNNhIpd7FFqkU/tHJDj09ARVISro3MUG",
	"4rhQga7gUyjsdclWA6xVB074mL8IM2MwkI/M3mc8YfYdz0GYZeQM3SfOrIN8C1wEbcjlXsbmNAP6hJoy",
	"boHktJxmPDEsvhfECvauDmiWL+iBdWEUNOe9Ue/FcH/4wnqFAbr34JFF7aERGCjGkkgdFSBpv3//AWzt",
	"mDdkVauC4xNO9ivvXGLD4c1BXNKsmU+w7zP+12JdXV43W4aGVeOxFNRWtFZWGQGFNWEPyTkkvVIOQity",
	"9m1eE5wNfrAPnziSe25SkDgLnf2HoXfjSQroNq2O5piVxkbtvJbpypGfc9uqZF2sm+HomG5OOetn8Clc",
	"6ufJvg3XcvUe7u8/DQRV4il2o/cALQPMKlYfsOnmVFyxYnBumOxbjJvATrifMAx6jYxa21R36+5DtdUJ",
	"OEjB3/YHJtJ+YE6uwnH7dif71mw/KfNJlcUmaJbCCw0m3W1rvZFUv8FzZJUFpR/kWLMRIrJo5FW77fde",
	"PuL+QELgGIgn1u+78XLqk+q9+jZAwN2XgWzNCovgkM+DY3jA4f8GGaR8uhSHaSBA0ENd6m7tMsTJUvtg",
	"x0o9xY+V0ALhanPl08BOQkdlA9CeTyIbZ3dvkTEpn4zaxszQLCMF1ozW6Ldvs9VBZoZ6jDt2tCgHpfO7",
	"7whczMTVrEGN8odG1RzQKC8uLsy2jMVXo1vX8jH6nOHjXh8/RtMyri1pYzsGaR/H4hZmtVpunVVvAslG",
	"AigPUTTbZGdW9iABux/B5rgwPf82DquWeOPZuPeluYzDxjJ+XE0L7i9jyFG/aSlBus1tkZvR3Eicc+AF",
	"FXKjOFjw+SLU8G0v4vamCwEWrNjqw5plbeDygicM6wwlh/v7+7ZK0URpmVzaCo63fiRIDYwzVj7zMAT+",
	"GRyTCPoPXtXR/wuGbrmCWxswD2/9FdrDUnfYoF4jbuvtoWAlaSy1UXK03ctVxmSQ/SpyZF41aO3jG+D9",
	"eH/BWiEHbJldOpGmTxQTaT0rP2SwVcR2Br52cYw8Y/AZErGFnPpmIFKDvovhWECaXUgOBTEuZmTsPh6L",
	"i5EFLMjkiozD4C1CmePe0Ql8qqjub+MeW05hl/2iX902hkxlAlsW24YAn+OeLrUsOM0AkX68g32HwZa8",
	"9Q5S6qEi8zTyVj3z7G2/F8N0fbiIrPDtpLNG8YfIDYy3SyWifHP5w+Vx/b0JHqfIkAkNi3WsNosRBZ3f",
	"RYgAdxVUUahP/1almAzKltWrnFQ5d4d1xzPupGt0xIoI3zvn5293bfUlmg00X7pYnoiOc0bnT3nggsT7",
	"3/joVFmJH1GhkbPK+8Vtpg/KD1P3uYx92ygbrnT7qkPT8FTTUDWsp6Gr8AW0Vsuq/M15AaZ7/r1yAgP9",
	"zpnLcz84KudLrGf/zmsZu9tyiSrf0ZxFs2BiqSzwkbX5QRaMZnphOQZkqZYz0D7AwlRTOrgrxF4q9F5v",
	"3KNM2xRKT3i+jnFyn6uptTG2gVtMVaOillUUSPTg6cnkZ0FLvZAFJNcZNN+FPVuqqDY2i0fmnqM6ZBVv",
	"70xz75h222cRFNCU/TABIySD4ECkKlQ/A6qq7/t7rvRnbNLveVs1xmZHo3ysOjtd4WMICt5VJK1RQCbN",
	"KFn4ERIS9kY9dxqsedMWqQ6zKwYJIA9fvYo4HGwEDdKMk5xqg/EKuP8NgAyfT67+tj/485f/+L4J6P82",
	"ysVk+LwLVhywC9hYtkqzhQ86T9tFXAT519rRFpF0hq4aiqWOiumvJ+HXND1r8eqnpXoInocYMkeljuTh",
	"hy6C3/sK//9Il+wWealR0Nr0/6aQ+WebYLuxTy8jD0zg+5EWMs+jTOm3iUKzRpe9cz3++nEm8Y7pDhw9",
	"3t1QI+E2yVrMo7s5IvvlZsx9lPoHWYr0znxW16bbgLO1bLNV/8/xFhsBa1mLp9ZeU+C9C2f80u9QMo4h",
	"x4PRJwS7DvO4Sl/OpJnzte+qJvZdsaXKLcvZKX9WjBxT5UyUNvNa5SFVCh/JgunIo8YdUS4nKKWAdahu",
	"L/lcwTrbxgJaH+yFM7LB6tB8IwgxPzVzxwYfSWWrrP0aHcl9MHuBNiF8urSmp6pB9cja6g2GvDTyc31g",
	"3OfGwNjoZoBvgBA06Gxzl2x1LYt03PtS73Dbb04OhtNHnx8zZ5ubd3tIpjJdPREgzbnDf942NssPYyMi",
	"BlwMaJaFdmZcGcIbDO2HtX+4kce1XMg1g/i4Z5rcti26nliR4Cc8vWmQaTVWZVq72scBLQi3nQeqq0zs",
	"FgfrlQW2Zuk1YLjQ/4Rqmkn7BtN40q3s/3c+ltbA/e2OpbOo/1OPJxrZfwOns7Hd3+CQ9tsbAs8MGyZH",
	"n5jtJxflkhU8eUwmUb2M1J9D7scqPOFvZhXWar+OWdBLIYBP9Kuv8KyDn2sAB01sIeaidfycG6Y9aVBy",
	"qIb8Mboj2dmzbLDkgmfLRpuysC1ayTcPDl6+eOnYWoWwFn/77jvymilNTguaaJ6gZDIgb4xY47Kn2Syr",
	"BXOVvLT0Diq1TGoDcg55V1D6YBDMidYUyJK3NGqJkWoU04rsHAxegI+tEYqWjAou5rPS6i02Z3xNTa6q",
	"9bknrdoTKYx1LIUyeIVa7GKONdUrOcgIZmEVCZuNZBG+Z0YeTVAarET6x7fhBjP8k2y5Nrt4lyZhy/PX",
	"dDjrL5BlYXVxV0ThPvrdHZQORFgon99H092bQmknzEhwF6XEHAHb9wHqyRp1pE6AWIHqKQmwUeNqG9q7",
	"m0Wx4TLp8V4Zk4IHti3iVduEiktwQbUE1LIWzd7T7nBH7fkbGSrsitumCsNk2wbzKP3rZHEP8o/UG/pG",
	"B8HA+1RHQCeLb3YCrAdEzCPaeesHRT9Crut6xryssYB9d0pN/B5m1kT/QajTWZlvvBG1DvNWBfUxlJ4r",
	"V+sz5jzPO8qGBMWmMSG/Xc9W8evNxJ6YfvReKPZdtynnEeNEtZMRdx34/bMf96iHjMBme8VK00CiENr3",
	"AOYU1K3qfIs5sW2+xasBzHWfV4NQ1qzsmr/ZffVPCCHc7X2Er/88227rzlhPRXtf4Y+tHjhgo3txdt98",
	"GU/Zze/0gUPYSnpY+n277e167ujA2OOpJ7WzF/NQgH2493PHN3yS5jVQf7PHqb9uNm63OzKbP2WPI/Ch",
	"nleR1+OLfbXyhltLfTHyo2n6O2ICR2la8QAtt+MAHTw2k/KyzPe+XrLVbfd1DY1+YquH8ol1KZw3ymZn",
	"LJFFSmbu3P/LSGOIXkIh3JpvJ3j9phjMTyzw2oRN0pIgZcXnvWSrR5EQlqywJZz/ecJL10O0lbHBs1VT",
	"zTKmFLinU6NxFXMASWHmBMSazYBNBWE3zm0PihYPx+LMtqAFs0UJWOqi9VYuBtMNYz3gDDlBfW/UyKDc",
	"BdQzGgsfGcxFXuInq5wOybmrjZYXcl7YCj85nUPlDxtKb+v7WIswPJL/cnT28eTjuxH5KDVRdMaaJb7s",
	"ohsKrK3bk0NNEQOsgiqSis8F+vBSqAy8x6GiCHEhqJjHfpBk3AxdKpvWsKlmGGx/ACJ5misomOGfZP2t",
	"QWA9elusEz53lS7/l2Kl4fmKHa7GybqPcluFyt3Z8Oy87J7e3AZu609pdv4/Kljk938wcHHU5+VsiRgd",
	"rtoR+ncxHne3O3tf/m9yAQfhJlUQAdi16kj4rYWhEPgRXeCrIDgfydCOUsHHx3+Hqvw7VOWJQlXuy9J+",
	"T7EtnezhfjySQVzK/aQE25lwoeU3ERbOcMKnFBfsFHfiIYcPeKQLNiDINVnw+ZwV2z1LxQwQuC/undoP",
	"97uxHLkVUHcpG5HYe0PcWRIOkP9P1b/LCE1jlY1z7Pc0NI2O/Nj0t+Lzg+BYUeJfWNHD7XWE/ExZh7fN",
	"rkTggbYu9BDi8Iwg6N4AaZbZsgvWrqJWSrPlkNiMmYrQdMkFyX3OzGHEEqH0zzDzYz131tnd3SufbHiE",
	"j1CWJ6XAc+SfEaCIk754+kl/kMWUpykTZOBiINt7/e3FHTwy5AGvw6WlRHdUoNJPcDz2kJA2nBBXEcO9",
	"jVs7X7YK40cZliwZxsJwj7EDzP7AY9GoUeR3Z/tSTqe1HW2Vmn3o+fqNn6ffCQVDYLA1J7eJbB1FfzX/",
	"i7gQNAqHWu+XQAeIUy82jFPuy2i2wMIZ2Lvu5KfF/WuaEnupO99sR9OEKx/ivRvc+E9MgQYlQurqPe93",
	"QoO49YR2kFz/LmxzI529Y8AeX6+8XPxEAiVAfycu9W+i/Z0xzhKZUNN7xdNtQ4eLQVo1AYIxRHlK9eLU",
	"/dzbNi4XYPEJTef8iolqa6FYlK3AB/X67Y4LLGaq6SVTJC9YwlImEjbsiPrw3Pmpgj7MBDWDRoRYIPoC",
	"6yY4xD+ub/J9DnUF2W/oOuLW9ggv0tVB3/MlJJdcLalOFva4//npoTyWYpbxpMZ8CM0KRtMVYTdcabX7",
	"O2ICtcib7QWmvbAK6aMxiTKWVNk+gGDZbLvtW92T2NNMd1rVP32Kkx8v3hrZro/sulrD9of/8QjJ3twf",
	"0Lk/BqJbxSZr0TdnBSLEHVTXDi7+f9/6dzWSAdsK6wJvc+brKnSXwnTGlvKqrjBVPUlROhszSstVPuCC",
	"of8F8Re+0ZcjCfhg/Eo3/6GQS3uvrzU5N0tY+PmcsSKAUkNtiQJmSocdCZHcAGtt05VlQBYpK9TEPyBt",
	"8qAz8EIx+ceG97OZeR3MGx5tqkFiCZ5eRt3e/PYjiL8ZtgJwibl96qvop5I9Qqz9hlgOkQU5kxkLfnF0",
	"gaKzp87fD2/Ckx3SNTCKhlgSWOW2UK1plgUD3k3FPg0Y3rcISVpnb/y3Gv6vrobnNWrroPanVciP0tRp",
	"4/XLZeOJOUrTCtLP8gn17PCQROTXCmxnVDPgp+k3VbK3kLMrONcGmvxWVO5/n+i7xeLUj8+6GwxHNlPF",
	"hNYPlAtwcMcmvvbRHs353tUBnGU7bKurFFyb206kWJ2JkZUsCxcYYHOmPlPtPLouwZ1LSPsjNDA/fq6S",
	"6LpuTKS55EK74kQq8F7ckJZ3NBYD8vw5DrR6/nxEjrKMCJnWk/d6TkMz7JAyqG+amh7n0syDDUtBryjP",
	"wI1lWlb5YmelSML+pQimPC64hvL0NsJdEYpFI8Wc2OF4xvUKu4JDGXTDsQfXPGW+q8WbxTwXc8y/g/gj",
	"yYIllx5fI3Lx7u1nsoeg/HphGp4Wcsn0gpWKLI0EkyjXyv7zwihKEPTw8nB/35Z3NUKfYn5gzOgjtEGS",
	"to6ESw+R9VRABNOMFbBQLmYF9dkKMW7Cag2R3Lr93s0g5SrPKL5BVKmLP1SN2goNfnSJarmIkeOQYD5e",
	"WyUMWlRh/UAUGIpSVYiwIcGOaNHbxfwD/1KY1RELaPklev0SqDOlmnqALHzo3Pv8Obhl4lDPn1u3zFJp",
	"uXSQsxtty3cPx+KXBc+YzyvZtxklDSm59Ev+mCh2xQqakSkTbMa1OQ1IY0bTIOd0xjQQ6FuhgCwByEQK",
	"xZVmIvH1djx6sPenXPMlJG2GOEYu5maQH8osI5/ZjcZfDUdSqF1y4atJoXCc54XMC25o53XGrhhZYiiO",
	"Hf8102anzyG9khnagDug17SwWwH0hAmllKsqY+sBJdaQX08z9fw5eqJbyAEUXDjuhAGzqtFtnTK9K5rd",
	"9mCbyLnbZfPN7hIsWGkqUlqktdbhllZ7CbvRzAK4Jj1fPGdmR2q+DYn51qbl605XuUX6uXsmw2umfutI",
	"U3l/ABZ6mW2Y09xyG+YEVSkyJShftnpNG8Lb7UDcDjNLpqk5qBsgjWZj3JiPEagMfDS6F7MugV+Qe69G",
	"bbEQXDPsjGaK1VreNzHobXdGzjcrQZc8CbgV2bmIQXSxC/LCxQZ4L8gAC57afAiY5A7vACPWkosKxxdk",
	"p2CJXC6ZMDI4lDVvFJZeM53RIi6gBBvEi2eZnwyXRLNsRXZmGbvhTiJRmbxmBQx8MsOy3S5ypO+6BVxU",
	"kZQrwwRTWz6JKc1S8gmoRz1/PnIZ9y5ixHWBrE1gp9qyIVyynpzYDGXHxwHMzSKeacLFghVck4uOzb9A",
	"K01OCwgjHZAjcwzhXrUDjdow2qN64coxdZxRf07IcDi8dTkOLUt/65k1/v5dACKc3IuxAFgMKLYPXHl4",
	"WFzx7pVB9UJeo9gEW4kbOSQfnIyBkgI+j1aSB7Ty16O/v88hDhX6mGvsYn3GT0NB7iHc30+Q3xBTUsKQ",
	"dUA2j1pn5eEUFzCqEdsuyI5pvAtXcvXzZGI7XuDUv2AKW3OND6garGQ52G5l/SpzL1WTlSxtPs+7gnM4",
	"L+jSpe8123csl1MXeHxWZswdhAvT/wL7mwvlAmKYl6Uu4STaamZXjOwkCykVI1IwQhXJCw4xOAa8XRTD",
	"qx8U2cFx+3bQXZJQQaYQOjsFnoLZhGnBKURxXTj89clFe/0XyFUiH8h/EN/VcBN5bceWpa7BSHZoqeWA",
	"pqmya95tHwCg5IuxeC1lxihooZaXVPwFbaGA6lFN2Ind43Xun7Ibz3HD/KPfdbMJJ5APjFCZEepOJp4i",
	"TBEKRxB6ecdqc0ZpRi4myGqgMUSRG+F3gP+2iZvbAtsd76tYulq3OrhTDLYH+GIVJY4+2bD7fXKRcXF5",
	"sUtQXgaobNS+hBmgzC9uNi5ux1wTF9WxJLIw/8Rj4elud1hnjp/hPNo9AcHf/uLPyYA0i2pWubGh9LcV",
	"xW1GAZqtFFfge4OEY3O1Gh3HYwzK9/mhqrqeA3ci10364+cP74mmc+DPwFOr2eBbbTyPjgF5e0MTPQBH",
	"EM/bAWsA9a8s3a0GOnmj+mYS1ScJ1WwuseggVlJUw87DOSBv0zkjYmDQ7gYuEBOlli6OfhjhbH6v7E2B",
	"kwAZkAH5+ez9nvnb7bZdl5/Cbex35CNmaYb9cMe62lSbw9kMiRnxFNmxee5QcYZ66ipARSJLoVWfQE5p",
	"s3OJLJhFwRTHN6N9Lkq2BwfdVrX3AL2hmu195ksWgJFSzTRfAsbMJ6XpMreCUTA1OhrtOS8D8PHou7rS",
	"bvx3TKqcanP8qwnmTIKZw0zwnmquy5TtZVLM4S8C36qJMmlrpvZJImWRmnvDrXHOpFpQ3Nxj2L8bMmdy",
	"XtB8wRMC36qRprI0dzNQS8HmVt9HQM8tk6qg9CVIzeB/xSTF/jdLnWi4AJkUFO1ga1pJ6e2uZHJqBnzN",
	"heEPYBEIhwpG4Es6t4Rt/jfFHo1Ku3Cdnggb0Gp+PJm1hCgjhjYkVeR9yMFmrDAiJMiAoVp9AefGiezt",
	"C+WC/L//9/9DLgJBqNXUpTFHljd2aRvDvlXm8nZ3S8Nhc//TFy9L+gLJP2Bh18pk4Gsng/gA1y1a2qrE",
	"2ZAD26W5tEYBa9W8mGhH/hdGWHpjD0ZwhfmevqVyfW0YOVPQFwV+xyGWNPd5CKt700USoxBlhj86GbgC",
	"8D4u3dsoYbXkI0YhH0thTp4TpX9ZMFFJudVmBxTgrHbOg9OrSA2h2FZAKGczfsMcak7D+w30PbyRzC6j",
	"jAUagyKy4HNeDQo55WGEnyyTtLcfCKOdEux5XHiNipi26vSd5Os1gq7FjxVPjbhhxdyKvVefgiu+fQuE",
	"zex1ssMiN9LumjzwoIUhqoHJtG7qQHyBFsxcrAQuVjBmD6zs7YjCtPH6LRjmuJiPgkPd1EOYNelFMrnj",
	"XC5r+4AcpWn8Jm5euYF535rpYZ0ob4C83BQg4LgYGQMEAZKWBdrAUSyGzPeoGa7TeYHH5rLQVNREmZln",
	"I999R06DItYum31ltoypLJa3LOgVIws+X7CiktcTqTRJSwgIr4hIcVUXiOwQ5sTOKJjlvWY7LbXV6p0Z",
	"PTdyHM1wk+3lFcM6sL+Q4DxU8ooVC0bT5r0Hi8IbK4CozlRBJ0vd9QFrCrehoX/nRuACTsCFOVnK6jJE",
	"8V/RsuyBMhw1fMVoRX623zAwNf7aFwyXHAAu3iBrFRIHlCgIs+fu2cy5/XqOL7USSX8sMMbapQXoO/j5",
	"FU9LmkGmLsyX5p82MBPxp5rp++1sxhOOMXY4LZEurqji4dUTCuSSw0xZLp0DJioByMfCP+fRJGG5tkfV",
	"pQN2d88lWw1AGCQ55YXareUJ3vGq3SVbVYqJzcMEeafgeSaeAQ0400ok8Fa1OVuTGhKbB20s4onQDBBO",
	"m4ymPsNx21nPxuKeac+eP7eJz8w9809LfWZJBpPKi5TYQH/zwXp9IwWC9GAuUlnisxud4ycm7BPthREi",
	"R3t7eznViz0tbaEFkMAlPJ0aIRPeFZF/vBjt7U3L5JJp6GIaHi3pr1KQ8xdmfpdzIFh9waYlz1L3+hZk",
	"ISBK0FwtpFcMyE9sRTBBIhyBN7ww0lFFk/bY2FQ64AlmGbw7XNV5mILKzQtSCv6PEhLk1Z4/m4kP2nzj",
	"jWEG1aGMsA2bdaiqZY8Pd7WHxmZ5t35nfar+WFRVTuC1jhrObe1Rvk4KkNMZS3hewB6dUXFJfoBy/mTn",
	"7OwHfy7x8a1mLwAdHYwG5/Y+BnEMnwNtOpuV0PQGTebymhVQ7KUC38gBhhZAzKw/3nGmRkbBTFcjc4WX",
	"mhUgqDmVFpEtC9Pq6OObiz65+HRm/vvx02doeAaHuBpqxWgxGpf7+y/Y4f7hPr6kLwpzPVSNxj0UMHL4",
	"MO55e9W5q87llvqR6rKgGcmomJe0msluVGtbYJ3YudrbKiGUvxHdQzUsweZycuWK4DK0Q9YfdD0L8ry8",
	"GhCKCvlN+xEpAiHBLR4LK6+phrDVKElmlxanlohZraq25kqagd0eKMPpXsH2uje2oDxT1Q8fTs0lRjNw",
	"W8gyPgd1tNeu8+SMdhMz/kTIpS1aVSuBhAVx4dFdpOQtmn0N9IbxzDCHEybwgjPiyXfm+o38OcDSuqdQ",
	"pdeaADENV8BBrhdSMbxlVFUwKfCYQ423YWHFySZYABjxUCpWjOAJD9biaATMgjB8xi+Za3dw+KIqnzR6",
	"+eoP414DajjXY3GU50Z7rR1ec48IcvTxjbmQUHOLg+d3tL671nK2GmmWLITM5Pz/o+1ae9vGlfZfIfoW",
	"WDtrOY6Tpn39zU2zbU7bxGi2PTg4KSpaZmxuZFEQZbtZw//9gDPDiy657u43W6RIcTic60PyFlqrrcSr",
	"Fzs7mHeOXMuVJpcC5ZRRy0sus+D+f+wcH7gYi5tHO7BTtB2DmbCOSm20nfOL3/1Au7WRCtvug4OdibwQ",
	"uLX84gthm0Yg7NZiFozVGACh4X+uSmHBTRRnROsjz1MjIabi2ihDnSjHtAXPbmQ27xGQIkCo+3at/H7M",
	"Lezo2ta0UDZjNj7gwwMkCj59+oy6vyl/CtuVbQmvCsOz8uzKuueEu1D+1Q5cM/2HZ625888C19P3ATaC",
	"D1OANnVBcL0RBRvPISV5lZ05uVLaY9TUCpBPuFhdEAgL545yQIOTlGttpLn2xNMMmERjnsDY3DYIYBZi",
	"ZIkvNICBlnAkGYjaViMgpImP2XAYhWYdo2VtZ7rLwtDR2Tsq16SBuuF0JPTlGATtMfIRdc9+BprJRNHQ",
	"7mmca9Y0fCxq5x7Lx24v9BDE8BaKJ9g82ISZ66Wa8bQeyMQUvLNhKDqlLe+WG+WSKnREuqnq5HwcXh/q",
	"khSBAYQdXGVvPw9fUf6n/vG0cEDw9H1YETQ7go8wLlrHW1XjZeQ/nIT3DUN6s66C77r6lHSmvTOzenkq",
	"FS7F8ofRKi6DV0VkXGAqx2ZVbe2YdSyurTtiZ9eAf+hZVCeSVWZsKZYKTs1Lb1lnpQVoVlWw0rBvNu9i",
	"H78JY2W51K2hqxV6jKdzVchysbzbgGQdjIV5C7LbakKyTtOE7DZsSNZp2JDdphHJOk0j0l55aGf3F90M",
	"n/tJtjE6Wu5mUKV+IMbUTHM6pqVrLIMMw6VfN8SwY+Mf/JRLswpvIuNmC12yTMj5Ygr0GX88P+9arAyI",
	"EWsZ1tdg1f71yQxiWQBEs6cwbvUazpBnXeMVtp3JJeI94G7rN0f0uOVazgeu5HzoOs5HXsVZAzLR0V8z",
	"SiTY5WM/Lx6xU/pZvU4cyG41jiOwDtciT2uNOlLEIzv37hHrVJMy9gOYrCGOuuTbi3QWjyghUCqsT5P9",
	"r8uL8wkvF9bdo00CcS1NHsMji33rk3C2z1/2Yc/IVCq7YuJSLPOUlyIesQ88m6ViygvN7FNkfERk5oVa",
	"5mWgkTHC4E7ZNQSQZtj7gXaA6UXfFM9lREwqnwu9z1czqfYNc6iqeBuxSzpisynJSM24CZwQe7VqmxZP",
	"zbKjZmvJweT1fFHlBqeTLoBnWQcjLJ/B1es2l9M9jH4/mz+KyS1/T1S+Mq4pepwjFvvmzByDIxbBiCKL",
	"h1j+nHJJzyBG5jzui1xk47MHh5KLjMu2oQAIw9E2OozgLlpXk+fyx40g413fRP1+PxzKZzuE9mZi1jl4",
	"dXg86/ZaauA4WOdw8HrYVoPPeDQYDF0bLpGt1DwV7L0wJHto4HOs9fDAB4MjVysv1B/CXdR99WJ5G9Ej",
	"V8Wmwq2zGSUiKwueHrQL2NfHbzzRql4ALrIwnQ120K+0xDxiYfzvS/ZWzAqV3Dw06ilVa2NdCB32S1ny",
	"LGCyaO2/HBPybmSC6zI6aJ31uxszTHtn6dCUJmohCtHH5yKbp1IvovVhowiIlMpsvuKpKbfbQjztzlyS",
	"4yr7Vr3COOGZv/WUkvggs9AGBsFlVXG74PO4BMDuXTpZyTq/b1R0WfK56OLOEU5tkMQslfcIYUqr0J5y",
	"ITJSD0aEhYWtcPm7Vf0/r8rDi8K9tnhmw2nK17xV6X9QGyZLtlHFDcAyv4Xk7MTwYtx1VNUNsgI0wemV",
	"TihYuy69jiYB9khLUcxsX8jaZBns7aHegAw39t6jH1G+kMCrU35TK4FXDmO7gcSIZ2hgnpfRkTL14FdU",
	"roqp/6vgQ+ktlG34FvyMhv1BdJ1yvYjEzxxewucH/VdGNtWeQE1qa5yVi0LlMoHmkpQbo/gwehVplWWi",
	"jIaD4dHBYIhr0paqfKWhZDAc/n9s96qAUIFmuG20f3eD0Xo4Gjg9dc5LuRbhsu0gtNctIdh8hmvOJVRn",
	"mI1oFZR/ZZUcDIZPWCYVJfJYNfKQImnwP076L7oRkwYphpRIb/3h2Db8jHLNgVs50yLnIHVCceR2dDmO",
	"/yxmkrPfwH/2SBUUhgHBSZT2gtCg+R53cj9bQjsyALls+K0PB5zB5xELcS2Oj5jIEkU7DuM/8vlofx+c",
	"xWQKxeg4GnbMs7vLNmKatxdiV1+/fEJoN9ljiCotc02/Ia1mflA6zjHq2KgHZtoaHrNv1rJ9ZoOEgPER",
	"JgzIGZK0eXN2L9LViwne6s8mC1UqH7w3L2IFpJv89vbiy2bw8f1cjcfj8fnl18Xp1/m4ZqUhPI38gegt",
	"RFwm4ArAvJ+AcyD/FADcDzYIFoBlWUMK2MEkKMDqmRQ5psXz+Jv0GCL34Y2Kn0TFtrcK3UZsuwVq7nZX",
	"V9mJDTqz7dYGoKHgnW/PlAXN73aug79bj1Z1np0WdglO4d4e63hS0iad7dbBq3a7eMTOEJqAcQzI0lK1",
	"/5OEAN/t+v3+drsvr+GFExuv5ylL1Vwmtr7gyQLB4/YN8wQ7KdF0gVKUD07CWJr30PtCrxe/hEnNVobB",
	"rMDqMTpJRWSlLIKlIDXTopA8lX8CPiBA0p3+LAFspTJcMNZztrumbY/udAbvL9adbEReYXPGygPQLfry",
	"tJfHQw7tHp6nMm7Aoc5tb2PVKifdxUN3s0+NddxQScq4gIaTJIAbVjltEnBbYGJMdFEQgbmtSgSJhA0R",
	"eSFykc00i1/2YxvtyAuhRVbavVwv+y1RCoCQ56lMZBnMG9WHjUn/HXzvY3gKsAyAb5GBDW9mmKZMEH9j",
	"omsq4K6/woHZfeiDACGIOy4LnmkXGIb7fnw+v7rhyG/Pr0SRLEVdXluCGIcg9qmVfM9kEUeqf1y+nKtS",
	"jML4lllzailLzIfM2EamqaFqNcYFazowna0BfvjmyHujgSEHSxSViNMyz5b7r4/ftAp2J8//kqB+tiXX",
	"9Oaf6BHd13Pdcm9RFIbkpNsMf6JbwS5FucqfbwS/Ojxusidt3nk8b4ahpacElxrhpZfbi8np+fjsx3hy",
	"9uPj6X92rXRoBePu7Z3gLjQfuN1ILVLY8/8BkZ+uSNsd9YwnyargyS1AOR0MkmBb+5QOAaQoGbBwQIQ1",
	"b9o2fsJpFgTrrUkauG6ILQU3Yuh6lVI0VgebEnE96dIo3jl8O3S4UZE2ThLreFZjv7pYdDeADsPpGj0L",
	"YcO3aA8EymQ6egMDoWvNTlK1AkucQqQApTfqQuVGKe7nhVzz5LbHElMxiL1SQJg4cl8nPCU8Oepwm2Vy",
	"JxA4GDAp740LgMzoTAcEUl7b2DlfKzljm4VKReSVNJkMFL6u3a59PygVE5v3glIvQhBdysnwtfc5UFd0",
	"IFO9eTwN+JFNVg+oooaDs2yazYdnNX03xSWfvy/UKsfzaqgJip9PVtNUJmw8OQuOymk9faQFzNuE6bUk",
	"sNsuZd+GFAoIXfsOol/l5J7vu/8FAAD//4iS/r025AEA",
}

// GetSwagger returns the content of the embedded swagger specification file
// or error if failed to decode
func decodeSpec() ([]byte, error) {
	zipped, err := base64.StdEncoding.DecodeString(strings.Join(swaggerSpec, ""))
	if err != nil {
		return nil, fmt.Errorf("error base64 decoding spec: %w", err)
	}
	zr, err := gzip.NewReader(bytes.NewReader(zipped))
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}
	var buf bytes.Buffer
	_, err = buf.ReadFrom(zr)
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}

	return buf.Bytes(), nil
}

var rawSpec = decodeSpecCached()

// a naive cached of a decoded swagger spec
func decodeSpecCached() func() ([]byte, error) {
	data, err := decodeSpec()
	return func() ([]byte, error) {
		return data, err
	}
}

// Constructs a synthetic filesystem for resolving external references when loading openapi specifications.
func PathToRawSpec(pathToFile string) map[string]func() ([]byte, error) {
	res := make(map[string]func() ([]byte, error))
	if len(pathToFile) > 0 {
		res[pathToFile] = rawSpec
	}

	return res
}

// GetSwagger returns the Swagger specification corresponding to the generated code
// in this file. The external references of Swagger specification are resolved.
// The logic of resolving external references is tightly connected to "import-mapping" feature.
// Externally referenced files must be embedded in the corresponding golang packages.
// Urls can be supported but this task was out of the scope.
func GetSwagger() (swagger *openapi3.T, err error) {
	resolvePath := PathToRawSpec("")

	loader := openapi3.NewLoader()
	loader.IsExternalRefsAllowed = true
	loader.ReadFromURIFunc = func(loader *openapi3.Loader, url *url.URL) ([]byte, error) {
		pathToFile := url.String()
		pathToFile = path.Clean(pathToFile)
		getSpec, ok := resolvePath[pathToFile]
		if !ok {
			err1 := fmt.Errorf("path not found: %s", pathToFile)
			return nil, err1
		}
		return getSpec()
	}
	var specData []byte
	specData, err = rawSpec()
	if err != nil {
		return
	}
	swagger, err = loader.LoadFromData(specData)
	if err != nil {
		return
	}
	return
}
