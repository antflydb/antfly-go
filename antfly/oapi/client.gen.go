// Package oapi provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/oapi-codegen/oapi-codegen/v2 version v2.5.0 DO NOT EDIT.
package oapi

import (
	"bytes"
	"compress/gzip"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"path"
	"strings"
	"time"

	"github.com/getkin/kin-openapi/openapi3"
	"github.com/oapi-codegen/runtime"
)

const (
	BasicAuthScopes = "BasicAuth.Scopes"
)

// Defines values for AntflyType.
const (
	AntflyTypeBlob            AntflyType = "blob"
	AntflyTypeBoolean         AntflyType = "boolean"
	AntflyTypeDatetime        AntflyType = "datetime"
	AntflyTypeEmbedding       AntflyType = "embedding"
	AntflyTypeGeopoint        AntflyType = "geopoint"
	AntflyTypeGeoshape        AntflyType = "geoshape"
	AntflyTypeHtml            AntflyType = "html"
	AntflyTypeKeyword         AntflyType = "keyword"
	AntflyTypeLink            AntflyType = "link"
	AntflyTypeNumeric         AntflyType = "numeric"
	AntflyTypeSearchAsYouType AntflyType = "search_as_you_type"
	AntflyTypeText            AntflyType = "text"
)

// Defines values for ChainCondition.
const (
	ChainConditionAlways      ChainCondition = "always"
	ChainConditionOnError     ChainCondition = "on_error"
	ChainConditionOnRateLimit ChainCondition = "on_rate_limit"
	ChainConditionOnTimeout   ChainCondition = "on_timeout"
)

// Defines values for ChunkerProvider.
const (
	ChunkerProviderAntfly  ChunkerProvider = "antfly"
	ChunkerProviderMock    ChunkerProvider = "mock"
	ChunkerProviderTermite ChunkerProvider = "termite"
)

// Defines values for ClusterHealth.
const (
	ClusterHealthDegraded  ClusterHealth = "degraded"
	ClusterHealthError     ClusterHealth = "error"
	ClusterHealthHealthy   ClusterHealth = "healthy"
	ClusterHealthUnhealthy ClusterHealth = "unhealthy"
	ClusterHealthUnknown   ClusterHealth = "unknown"
)

// Defines values for CohereEmbedderConfigInputType.
const (
	CohereEmbedderConfigInputTypeClassification CohereEmbedderConfigInputType = "classification"
	CohereEmbedderConfigInputTypeClustering     CohereEmbedderConfigInputType = "clustering"
	CohereEmbedderConfigInputTypeSearchDocument CohereEmbedderConfigInputType = "search_document"
	CohereEmbedderConfigInputTypeSearchQuery    CohereEmbedderConfigInputType = "search_query"
)

// Defines values for CohereEmbedderConfigTruncate.
const (
	CohereEmbedderConfigTruncateEND   CohereEmbedderConfigTruncate = "END"
	CohereEmbedderConfigTruncateNONE  CohereEmbedderConfigTruncate = "NONE"
	CohereEmbedderConfigTruncateSTART CohereEmbedderConfigTruncate = "START"
)

// Defines values for EdgeDirection.
const (
	EdgeDirectionBoth EdgeDirection = "both"
	EdgeDirectionIn   EdgeDirection = "in"
	EdgeDirectionOut  EdgeDirection = "out"
)

// Defines values for EmbedderProvider.
const (
	EmbedderProviderBedrock EmbedderProvider = "bedrock"
	EmbedderProviderCohere  EmbedderProvider = "cohere"
	EmbedderProviderGemini  EmbedderProvider = "gemini"
	EmbedderProviderMock    EmbedderProvider = "mock"
	EmbedderProviderOllama  EmbedderProvider = "ollama"
	EmbedderProviderOpenai  EmbedderProvider = "openai"
	EmbedderProviderVertex  EmbedderProvider = "vertex"
)

// Defines values for EvaluatorName.
const (
	EvaluatorNameCitationQuality EvaluatorName = "citation_quality"
	EvaluatorNameCoherence       EvaluatorName = "coherence"
	EvaluatorNameCompleteness    EvaluatorName = "completeness"
	EvaluatorNameCorrectness     EvaluatorName = "correctness"
	EvaluatorNameFaithfulness    EvaluatorName = "faithfulness"
	EvaluatorNameHelpfulness     EvaluatorName = "helpfulness"
	EvaluatorNameMap             EvaluatorName = "map"
	EvaluatorNameMrr             EvaluatorName = "mrr"
	EvaluatorNameNdcg            EvaluatorName = "ndcg"
	EvaluatorNamePrecision       EvaluatorName = "precision"
	EvaluatorNameRecall          EvaluatorName = "recall"
	EvaluatorNameRelevance       EvaluatorName = "relevance"
	EvaluatorNameSafety          EvaluatorName = "safety"
)

// Defines values for FailedOperationOperation.
const (
	FailedOperationOperationDelete FailedOperationOperation = "delete"
	FailedOperationOperationUpsert FailedOperationOperation = "upsert"
)

// Defines values for Fuzziness1.
const (
	Fuzziness1Auto Fuzziness1 = "auto"
)

// Defines values for GeneratorProvider.
const (
	GeneratorProviderAnthropic GeneratorProvider = "anthropic"
	GeneratorProviderBedrock   GeneratorProvider = "bedrock"
	GeneratorProviderCohere    GeneratorProvider = "cohere"
	GeneratorProviderGemini    GeneratorProvider = "gemini"
	GeneratorProviderMock      GeneratorProvider = "mock"
	GeneratorProviderOllama    GeneratorProvider = "ollama"
	GeneratorProviderOpenai    GeneratorProvider = "openai"
	GeneratorProviderVertex    GeneratorProvider = "vertex"
)

// Defines values for GeoShapeGeometryRelation.
const (
	GeoShapeGeometryRelationContains   GeoShapeGeometryRelation = "contains"
	GeoShapeGeometryRelationIntersects GeoShapeGeometryRelation = "intersects"
	GeoShapeGeometryRelationWithin     GeoShapeGeometryRelation = "within"
)

// Defines values for GraphQueryType.
const (
	GraphQueryTypeKShortestPaths GraphQueryType = "k_shortest_paths"
	GraphQueryTypeNeighbors      GraphQueryType = "neighbors"
	GraphQueryTypePattern        GraphQueryType = "pattern"
	GraphQueryTypeShortestPath   GraphQueryType = "shortest_path"
	GraphQueryTypeTraverse       GraphQueryType = "traverse"
)

// Defines values for IndexType.
const (
	IndexTypeAknnV0     IndexType = "aknn_v0"
	IndexTypeFullTextV0 IndexType = "full_text_v0"
	IndexTypeGraphV0    IndexType = "graph_v0"
)

// Defines values for LinearMergePageStatus.
const (
	LinearMergePageStatusError   LinearMergePageStatus = "error"
	LinearMergePageStatusPartial LinearMergePageStatus = "partial"
	LinearMergePageStatusSuccess LinearMergePageStatus = "success"
)

// Defines values for MatchQueryOperator.
const (
	MatchQueryOperatorAnd MatchQueryOperator = "and"
	MatchQueryOperatorOr  MatchQueryOperator = "or"
)

// Defines values for MergeStrategy.
const (
	MergeStrategyFailover MergeStrategy = "failover"
	MergeStrategyRrf      MergeStrategy = "rrf"
	MergeStrategyRsf      MergeStrategy = "rsf"
)

// Defines values for PathFindWeightMode.
const (
	PathFindWeightModeMaxWeight PathFindWeightMode = "max_weight"
	PathFindWeightModeMinHops   PathFindWeightMode = "min_hops"
	PathFindWeightModeMinWeight PathFindWeightMode = "min_weight"
)

// Defines values for PathWeightMode.
const (
	PathWeightModeMaxWeight PathWeightMode = "max_weight"
	PathWeightModeMinHops   PathWeightMode = "min_hops"
	PathWeightModeMinWeight PathWeightMode = "min_weight"
)

// Defines values for PermissionType.
const (
	PermissionTypeAdmin PermissionType = "admin"
	PermissionTypeRead  PermissionType = "read"
	PermissionTypeWrite PermissionType = "write"
)

// Defines values for QueryRequestExpandStrategy.
const (
	QueryRequestExpandStrategyIntersection QueryRequestExpandStrategy = "intersection"
	QueryRequestExpandStrategyUnion        QueryRequestExpandStrategy = "union"
)

// Defines values for QueryStrategy.
const (
	QueryStrategyDecompose QueryStrategy = "decompose"
	QueryStrategyHyde      QueryStrategy = "hyde"
	QueryStrategySimple    QueryStrategy = "simple"
	QueryStrategyStepBack  QueryStrategy = "step_back"
)

// Defines values for RerankerProvider.
const (
	RerankerProviderCohere  RerankerProvider = "cohere"
	RerankerProviderOllama  RerankerProvider = "ollama"
	RerankerProviderTermite RerankerProvider = "termite"
	RerankerProviderVertex  RerankerProvider = "vertex"
)

// Defines values for ResourceType.
const (
	ResourceTypeAsterisk ResourceType = "*"
	ResourceTypeTable    ResourceType = "table"
	ResourceTypeUser     ResourceType = "user"
)

// Defines values for RouteType.
const (
	RouteTypeQuestion RouteType = "question"
	RouteTypeSearch   RouteType = "search"
)

// Defines values for SemanticQueryMode.
const (
	SemanticQueryModeHypothetical SemanticQueryMode = "hypothetical"
	SemanticQueryModeRewrite      SemanticQueryMode = "rewrite"
)

// Defines values for SyncLevel.
const (
	SyncLevelAknn        SyncLevel = "aknn"
	SyncLevelEnrichments SyncLevel = "enrichments"
	SyncLevelFullText    SyncLevel = "full_text"
	SyncLevelPropose     SyncLevel = "propose"
	SyncLevelWrite       SyncLevel = "write"
)

// Defines values for TransformOpType.
const (
	TransformOpTypeAddToSet    TransformOpType = "$addToSet"
	TransformOpTypeCurrentDate TransformOpType = "$currentDate"
	TransformOpTypeInc         TransformOpType = "$inc"
	TransformOpTypeMax         TransformOpType = "$max"
	TransformOpTypeMin         TransformOpType = "$min"
	TransformOpTypeMul         TransformOpType = "$mul"
	TransformOpTypePop         TransformOpType = "$pop"
	TransformOpTypePull        TransformOpType = "$pull"
	TransformOpTypePush        TransformOpType = "$push"
	TransformOpTypeRename      TransformOpType = "$rename"
	TransformOpTypeSet         TransformOpType = "$set"
	TransformOpTypeUnset       TransformOpType = "$unset"
)

// Analyses defines model for Analyses.
type Analyses struct {
	Pca  bool `json:"pca,omitempty,omitzero"`
	Tsne bool `json:"tsne,omitempty,omitzero"`
}

// AnalysesResult defines model for AnalysesResult.
type AnalysesResult struct {
	Pca  []float64 `json:"pca,omitempty,omitzero"`
	Tsne []float64 `json:"tsne,omitempty,omitzero"`
}

// AnswerAgentRequest defines model for AnswerAgentRequest.
type AnswerAgentRequest struct {
	// Chain Default chain of generators for all pipeline steps unless overridden in `steps`.
	// Each link can specify retry configuration and a condition for trying the next generator.
	// Mutually exclusive with 'generator'. Either 'generator' or 'chain' must be provided.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Eval Configuration for inline evaluation of query results.
	// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
	Eval EvalConfig `json:"eval,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// MaxContextTokens Maximum total tokens allowed for retrieved document context.
	// When set, documents are pruned (lowest-ranked first) to fit within this budget.
	// Useful for ensuring LLM context limits are not exceeded.
	// Uses BERT tokenizer for estimation.
	MaxContextTokens int `json:"max_context_tokens,omitempty,omitzero"`

	// Queries Array of query requests to execute. The query text will be transformed for semantic search
	// and populated into the semantic_search field of each query.
	Queries []QueryRequest `json:"queries"`

	// Query User's natural language query to be classified and improved
	Query string `json:"query"`

	// ReserveTokens Tokens to reserve for system prompt, answer generation, and other overhead.
	// Subtracted from max_context_tokens to determine available context budget.
	// Defaults to 4000 if max_context_tokens is set.
	ReserveTokens int `json:"reserve_tokens,omitempty,omitzero"`

	// Steps Per-step configuration for the answer agent pipeline. Each step can have
	// its own generator (or chain of generators) and step-specific options.
	// If a step is not configured, it uses the top-level generator as default.
	Steps AnswerAgentSteps `json:"steps,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results (classification, queries, results, answer) instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// AnswerAgentResult defines model for AnswerAgentResult.
type AnswerAgentResult struct {
	// Answer Generated answer in markdown format
	Answer string `json:"answer"`

	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0)
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// ClassificationTransformation Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
	ClassificationTransformation ClassificationTransformationResult `json:"classification_transformation,omitempty,omitzero"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance,omitempty,omitzero"`

	// EvalResult Complete evaluation result
	EvalResult EvalResult `json:"eval_result,omitempty,omitzero"`

	// FollowupQuestions Suggested follow-up questions
	FollowupQuestions []string `json:"followup_questions,omitempty,omitzero"`

	// QueryResults Results from each executed query
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`
}

// AnswerAgentSteps Per-step configuration for the answer agent pipeline. Each step can have
// its own generator (or chain of generators) and step-specific options.
// If a step is not configured, it uses the top-level generator as default.
type AnswerAgentSteps struct {
	// Answer Configuration for the answer generation step. This step generates the final
	// answer from retrieved documents using the reasoning as context.
	Answer AnswerStepConfig `json:"answer,omitempty,omitzero"`

	// Classification Configuration for the classification step. This step analyzes the query,
	// selects the optimal retrieval strategy, and generates semantic transformations.
	Classification ClassificationStepConfig `json:"classification,omitempty,omitzero"`

	// Confidence Configuration for confidence assessment. Evaluates answer quality and
	// resource relevance. Can use a model calibrated for scoring tasks.
	Confidence ConfidenceStepConfig `json:"confidence,omitempty,omitzero"`

	// Followup Configuration for generating follow-up questions. Uses a separate generator
	// call which can use a cheaper/faster model.
	Followup FollowupStepConfig `json:"followup,omitempty,omitzero"`
}

// AnswerConfidence Confidence assessment for the generated answer
type AnswerConfidence struct {
	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0). Considers both ability to answer from provided resources and general knowledge.
	AnswerConfidence float32 `json:"answer_confidence"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance"`
}

// AnswerResult Result from answer generation with optional confidence and follow-up questions
type AnswerResult struct {
	// Answer Generated answer in markdown format
	Answer string `json:"answer"`

	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0)
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance,omitempty,omitzero"`

	// FollowupQuestions Suggested follow-up questions
	FollowupQuestions []string `json:"followup_questions,omitempty,omitzero"`
}

// AnswerStepConfig Configuration for the answer generation step. This step generates the final
// answer from retrieved documents using the reasoning as context.
type AnswerStepConfig struct {
	// AnswerContext Custom guidance for answer tone, detail level, and style
	AnswerContext string `json:"answer_context,omitempty,omitzero"`

	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// SystemPrompt Custom system prompt for answer generation
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`
}

// AntflyChunkerConfig Configuration for the local Antfly chunking provider.
//
// This provider runs chunking directly within the storage node process,
// without requiring an external Termite service. It uses simple fixed-size
// tokenizer-based chunking with no caching overhead.
//
// **Use this when:**
// - Running single-node deployments (swarm mode)
// - You don't need embedding/chunk caching across nodes
// - You want minimal setup complexity
//
// **Use Termite instead when:**
// - Running multi-node clusters where caching reduces costs
// - You need ONNX-accelerated chunking models
// - You want persistent chunk/embedding caches
type AntflyChunkerConfig struct {
	// FullText Configuration for full-text indexing of chunks in Bleve.
	// When present (even if empty), chunks will be stored with :cft: suffix and indexed in Bleve's _chunks field.
	// When absent, chunks use :c: suffix and are only used for vector embeddings.
	// This object is reserved for future options like boosting, field mapping, etc.
	FullText map[string]interface{} `json:"full_text,omitempty,omitzero"`

	// MaxChunks Maximum number of chunks to generate per document. Prevents excessive chunking of very large documents.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs).
	Separator string `json:"separator,omitempty,omitzero"`

	// TargetTokens Target number of tokens per chunk. Chunker will aim for chunks around this size.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`
}

// AntflyType defines model for AntflyType.
type AntflyType string

// AnthropicGeneratorConfig Configuration for the Anthropic generative AI provider (Claude models).
//
// API key via `api_key` field or `ANTHROPIC_API_KEY` environment variable.
//
// **Example Models:** claude-sonnet-4-5-20250929 (default), claude-opus-4-5-20251101, claude-3-5-haiku-20241022
//
// **Docs:** https://docs.anthropic.com/en/docs/about-claude/models/overview
type AnthropicGeneratorConfig struct {
	// ApiKey The Anthropic API key. If not provided, falls back to ANTHROPIC_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The full model ID of the Anthropic model to use (e.g., 'claude-sonnet-4-5-20250929', 'claude-opus-4-5-20251101').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-1.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Anthropic API endpoint (optional, uses default if not specified).
	Url string `json:"url,omitempty,omitzero"`
}

// BackupRequest defines model for BackupRequest.
type BackupRequest struct {
	// BackupId Unique identifier for this backup. Used to reference the backup for restore operations.
	// Choose a meaningful name that includes date/version information.
	BackupId string `json:"backup_id"`

	// Location Storage location for the backup. Supports multiple backends:
	// - Local filesystem: `file:///path/to/backup`
	// - Amazon S3: `s3://bucket-name/path/to/backup`
	//
	// The backup includes all table data, indexes, and metadata for the specified table.
	Location string `json:"location"`
}

// BatchRequest Batch insert, delete, and transform operations in a single request.
//
// **Atomicity**:
// - **Single shard**: Operations are atomic within shard boundaries
// - **Multiple shards**: Uses distributed 2-phase commit (2PC) for atomic cross-shard writes
//
// **How distributed transactions work**:
// 1. Metadata server allocates HLC timestamp and selects coordinator shard
// 2. Coordinator writes transaction record, participants write intents
// 3. After all intents succeed, coordinator commits transaction
// 4. Participants are notified asynchronously to resolve intents
// 5. Recovery loop ensures notifications complete even after coordinator failure
//
// **Performance**:
// - Single-shard batches: < 5ms latency
// - Cross-shard transactions: ~20ms latency
// - Intent resolution: < 30 seconds worst-case (via recovery loop)
//
// **Guarantees**:
// - All writes succeed or all fail (atomicity across all shards)
// - Coordinator failure is recoverable (new leader resumes notifications)
// - Idempotent resolution (duplicate notifications are safe)
//
// **Benefits**:
// - Reduces network overhead compared to individual requests
// - More efficient indexing (updates are batched)
// - Automatic distributed transactions when operations span shards
//
// The inserts are upserts - existing keys are overwritten, new keys are created.
type BatchRequest struct {
	// Deletes Array of document IDs to delete. Documents are removed from all indexes.
	//
	// Notes:
	// - Non-existent keys are silently ignored
	// - Deletions are processed before inserts in the same batch
	// - Keys are permanently removed from storage and indexes
	Deletes []string `json:"deletes,omitempty,omitzero"`

	// Inserts Map of document IDs to document objects. Each key is the unique identifier for the document.
	//
	// Best practices:
	// - Use consistent key naming schemes (e.g., "user:123", "article:456")
	// - Key length affects storage and performance - keep them reasonably short
	// - Keys are sorted lexicographically, so choose prefixes that support range scans
	Inserts map[string]map[string]interface{} `json:"inserts,omitempty,omitzero"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write
	// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`

	// Transforms Array of transform operations for in-place document updates using MongoDB-style operators.
	//
	// Transform operations allow you to modify documents without read-modify-write races:
	// - Operations are applied atomically on the server
	// - Multiple operations per document are applied in sequence
	// - Supports numeric operations ($inc, $mul), array operations ($push, $pull), and more
	//
	// Common use cases:
	// - Increment counters (views, likes, votes)
	// - Update timestamps ($currentDate)
	// - Manage arrays (add/remove tags, items)
	// - Update nested fields without overwriting the entire document
	Transforms []Transform `json:"transforms,omitempty,omitzero"`
}

// BedrockEmbedderConfig Configuration for the AWS Bedrock embedding provider.
//
// Uses AWS credentials from environment or IAM roles.
//
// **Example Models:** cohere.embed-english-v4, amazon.titan-embed-text-v2:0
//
// **Docs:** https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html
type BedrockEmbedderConfig struct {
	// BatchSize The batch size for embedding requests to optimize throughput.
	BatchSize int `json:"batch_size,omitempty,omitzero"`

	// Model The Bedrock model ID to use (e.g., 'cohere.embed-english-v4', 'amazon.titan-embed-text-v2:0').
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service (e.g., 'us-east-1').
	Region string `json:"region,omitempty,omitzero"`

	// StripNewLines Whether to strip new lines from the input text before embedding.
	StripNewLines bool `json:"strip_new_lines,omitempty,omitzero"`
}

// BedrockGeneratorConfig Configuration for the AWS Bedrock generative AI provider.
//
// Provides access to models from Anthropic, Meta, Amazon, Cohere, Mistral, and others.
//
// **Example Models:** anthropic.claude-sonnet-4-5-20250929-v1:0, meta.llama3-3-70b-instruct-v1:0, amazon.nova-pro-v1:0
//
// **Docs:** https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html
type BedrockGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The Bedrock model ID to use (e.g., 'anthropic.claude-sonnet-4-5-20250929-v1:0').
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service.
	Region string `json:"region,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-1.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// BleveIndexV2Config defines model for BleveIndexV2Config.
type BleveIndexV2Config struct {
	// MemOnly Whether to use memory-only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`
}

// BleveIndexV2Stats defines model for BleveIndexV2Stats.
type BleveIndexV2Stats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// Rebuilding Whether the index is currently rebuilding
	Rebuilding bool `json:"rebuilding,omitempty,omitzero"`

	// TotalIndexed Number of documents in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`
}

// BoolFieldQuery defines model for BoolFieldQuery.
type BoolFieldQuery struct {
	Bool bool `json:"bool"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
}

// BooleanQuery defines model for BooleanQuery.
type BooleanQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost   Boost            `json:"boost,omitzero"`
	Filter  Query            `json:"filter,omitempty,omitzero"`
	Must    ConjunctionQuery `json:"must,omitempty,omitzero"`
	MustNot DisjunctionQuery `json:"must_not,omitempty,omitzero"`
	Should  DisjunctionQuery `json:"should,omitempty,omitzero"`
}

// Boost A floating-point number used to decrease or increase the relevance scores of a query.
type Boost = float64

// ByteRange defines model for ByteRange.
type ByteRange = [][]byte

// ChainCondition Condition for trying the next generator in chain:
// - always: Always try next regardless of outcome
// - on_error: Try next on any error (default)
// - on_timeout: Try next only on timeout errors
// - on_rate_limit: Try next only on rate limit errors
type ChainCondition string

// ChainLink A single link in a generator chain with optional retry and condition
type ChainLink struct {
	// Condition Condition for trying the next generator in chain:
	// - always: Always try next regardless of outcome
	// - on_error: Try next on any error (default)
	// - on_timeout: Try next only on timeout errors
	// - on_rate_limit: Try next only on rate limit errors
	Condition ChainCondition `json:"condition,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator"`

	// Retry Retry configuration for generator calls
	Retry RetryConfig `json:"retry,omitempty,omitzero"`
}

// ChunkerConfig defines model for ChunkerConfig.
type ChunkerConfig struct {
	// Provider The chunking provider to use.
	Provider ChunkerProvider `json:"provider"`
	union    json.RawMessage
}

// ChunkerProvider The chunking provider to use.
type ChunkerProvider string

// ClassificationStepConfig Configuration for the classification step. This step analyzes the query,
// selects the optimal retrieval strategy, and generates semantic transformations.
type ClassificationStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// ForceSemanticMode Mode for semantic query generation:
	// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
	// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
	ForceSemanticMode SemanticQueryMode `json:"force_semantic_mode,omitempty,omitzero"`

	// ForceStrategy Strategy for query transformation and retrieval:
	// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
	// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
	// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
	// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
	ForceStrategy QueryStrategy `json:"force_strategy,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// MultiPhraseCount Number of alternative query phrasings to generate
	MultiPhraseCount int `json:"multi_phrase_count,omitempty,omitzero"`

	// WithReasoning Include pre-retrieval reasoning explaining query analysis and strategy selection
	WithReasoning bool `json:"with_reasoning,omitempty,omitzero"`
}

// ClassificationTransformationResult Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
type ClassificationTransformationResult struct {
	// Confidence Classification confidence (0.0 to 1.0)
	Confidence float32 `json:"confidence"`

	// ImprovedQuery Clarified query with added context for answer generation (human-readable)
	ImprovedQuery string `json:"improved_query"`

	// MultiPhrases Alternative phrasings of the query for expanded retrieval coverage
	MultiPhrases []string `json:"multi_phrases,omitempty,omitzero"`

	// Reasoning Pre-retrieval reasoning explaining query analysis and strategy selection (only present when with_classification_reasoning is enabled)
	Reasoning string `json:"reasoning,omitempty,omitzero"`

	// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
	RouteType RouteType `json:"route_type"`

	// SemanticMode Mode for semantic query generation:
	// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
	// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
	SemanticMode SemanticQueryMode `json:"semantic_mode"`

	// SemanticQuery Optimized query for vector/semantic search. Content style depends on semantic_mode: keywords for 'rewrite', hypothetical answer for 'hypothetical'
	SemanticQuery string `json:"semantic_query"`

	// StepBackQuery Broader background query for context (only present when strategy is 'step_back')
	StepBackQuery string `json:"step_back_query,omitempty,omitzero"`

	// Strategy Strategy for query transformation and retrieval:
	// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
	// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
	// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
	// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
	Strategy QueryStrategy `json:"strategy"`

	// SubQuestions Decomposed sub-questions (only present when strategy is 'decompose')
	SubQuestions []string `json:"sub_questions,omitempty,omitzero"`
}

// ClusterHealth Overall health status of the cluster
type ClusterHealth string

// ClusterStatus defines model for ClusterStatus.
type ClusterStatus struct {
	// AuthEnabled Indicates whether authentication is enabled for the cluster
	AuthEnabled bool `json:"auth_enabled,omitempty"`

	// Health Overall health status of the cluster
	Health ClusterHealth `json:"health"`

	// Message Optional message providing details about the health status
	Message              string                 `json:"message,omitempty,omitzero"`
	AdditionalProperties map[string]interface{} `json:"-"`
}

// CohereEmbedderConfig Configuration for the Cohere embedding provider.
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** embed-english-v3.0 (default, 1024 dims), embed-multilingual-v3.0
//
// **Docs:** https://docs.cohere.com/reference/embed
type CohereEmbedderConfig struct {
	// ApiKey The Cohere API key. Can also be set via COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// InputType Specifies the type of input for optimized embeddings.
	InputType CohereEmbedderConfigInputType `json:"input_type,omitempty,omitzero"`

	// Model The name of the Cohere embedding model to use.
	Model string `json:"model"`

	// Truncate How to handle inputs longer than the max token length.
	Truncate CohereEmbedderConfigTruncate `json:"truncate,omitempty,omitzero"`
}

// CohereEmbedderConfigInputType Specifies the type of input for optimized embeddings.
type CohereEmbedderConfigInputType string

// CohereEmbedderConfigTruncate How to handle inputs longer than the max token length.
type CohereEmbedderConfigTruncate string

// CohereGeneratorConfig Configuration for the Cohere generative AI provider (Command models).
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** command-r-plus (default), command-r, command-a-03-2025
//
// **Docs:** https://docs.cohere.com/reference/chat
type CohereGeneratorConfig struct {
	// ApiKey The Cohere API key. If not provided, falls back to COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (0.0-1.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Cohere model to use.
	Model string `json:"model"`

	// PresencePenalty Penalty for token presence (0.0-1.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-1.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// CohereRerankerConfig Configuration for the Cohere reranking provider.
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** rerank-english-v3.0 (default), rerank-multilingual-v3.0
//
// **Docs:** https://docs.cohere.com/reference/rerank
type CohereRerankerConfig struct {
	// ApiKey The Cohere API key. Can also be set via COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// MaxChunksPerDoc Maximum number of chunks per document for long document handling.
	MaxChunksPerDoc int `json:"max_chunks_per_doc,omitempty,omitzero"`

	// Model The name of the Cohere reranking model to use.
	Model string `json:"model"`

	// TopN Number of most relevant documents to return. If not specified, returns all documents with scores.
	TopN int `json:"top_n,omitempty,omitzero"`
}

// ConfidenceStepConfig Configuration for confidence assessment. Evaluates answer quality and
// resource relevance. Can use a model calibrated for scoring tasks.
type ConfidenceStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Context Custom guidance for confidence assessment approach
	Context string `json:"context,omitempty,omitzero"`

	// Enabled Enable confidence scoring
	Enabled bool `json:"enabled,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`
}

// ConjunctionQuery defines model for ConjunctionQuery.
type ConjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Conjuncts []Query `json:"conjuncts"`
}

// CreateTableRequest defines model for CreateTableRequest.
type CreateTableRequest struct {
	// Description Optional human-readable description of the table and its purpose.
	// Useful for documentation and team collaboration.
	Description string `json:"description,omitempty,omitzero"`

	// Indexes Map of index name to index configuration. Indexes enable different query capabilities:
	// - Full-text indexes for BM25 search
	// - Vector indexes for semantic similarity
	// - Multimodal indexes for images/audio/video
	//
	// You can add multiple indexes to support different query patterns.
	Indexes map[string]IndexConfig `json:"indexes,omitempty,omitzero"`

	// NumShards Number of shards to create for the table. Data is partitioned across shards based on key ranges.
	//
	// **Sizing Guidelines:**
	// - Small datasets (<100K docs): 1-3 shards
	// - Medium datasets (100K-1M docs): 3-10 shards
	// - Large datasets (>1M docs): 10+ shards
	//
	// More shards enable better parallelism but increase overhead. Choose based on expected data size and query patterns.
	//
	// **When to Add More Shards:**
	//
	// Antfly supports **online shard reallocation** without downtime. Add more shards when:
	// - Individual shards exceed size thresholds (configurable)
	// - Query latency increases due to large shard size
	// - Need better parallelism for write-heavy workloads
	//
	// Use the internal `/reallocate` endpoint to trigger automatic shard splitting:
	// ```bash
	// POST /_internal/v1/reallocate
	// ```
	//
	// This enqueues a reallocation request that the leader processes asynchronously, splitting
	// large shards and redistributing data without service interruption.
	//
	// **Advantages over Elasticsearch:**
	// - Automatic shard splitting (no manual reindexing required)
	// - Online operation (no downtime)
	// - Transparent to applications (keys remain accessible during reallocation)
	NumShards uint `json:"num_shards,omitempty,omitzero"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema `json:"schema,omitempty,omitzero"`
}

// CreateUserRequest defines model for CreateUserRequest.
type CreateUserRequest struct {
	// InitialPolicies Optional list of initial permissions for the user.
	InitialPolicies []Permission `json:"initial_policies,omitzero"`
	Password        string       `json:"password"`

	// Username Username for the new user. If provided in the path, this field can be omitted or must match the path parameter.
	Username string `json:"username,omitempty,omitzero"`
}

// DateRange defines model for DateRange.
type DateRange struct {
	From *string `json:"from,omitempty"`
	Name string  `json:"name"`
	To   *string `json:"to,omitempty"`
}

// DateRangeResult defines model for DateRangeResult.
type DateRangeResult struct {
	Count int     `json:"count"`
	From  *string `json:"from,omitempty"`
	Name  string  `json:"name"`
	To    *string `json:"to,omitempty"`
}

// DateRangeStringQuery defines model for DateRangeStringQuery.
type DateRangeStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost          Boost     `json:"boost,omitzero"`
	DatetimeParser string    `json:"datetime_parser,omitempty,omitzero"`
	End            time.Time `json:"end,omitempty,omitzero"`
	Field          string    `json:"field,omitempty,omitzero"`
	InclusiveEnd   bool      `json:"inclusive_end,omitzero"`
	InclusiveStart bool      `json:"inclusive_start,omitzero"`
	Start          time.Time `json:"start,omitempty,omitzero"`
}

// DisjunctionQuery defines model for DisjunctionQuery.
type DisjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Disjuncts []Query `json:"disjuncts"`
	Min       float64 `json:"min,omitempty,omitzero"`
}

// DocIdQuery defines model for DocIdQuery.
type DocIdQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost    `json:"boost,omitzero"`
	Ids   []string `json:"ids"`
}

// DocumentSchema Defines the structure of a document type
type DocumentSchema struct {
	// Description A description of the document type.
	Description string `json:"description,omitempty,omitzero"`

	// Schema A valid JSON Schema defining the document's structure.
	// This is used to infer indexing rules and field types.
	Schema map[string]interface{} `json:"schema,omitempty,omitzero"`
}

// Edge A typed, weighted connection between documents
type Edge struct {
	// CreatedAt When the edge was created
	CreatedAt time.Time `json:"created_at,omitempty,omitzero"`

	// Metadata Optional edge metadata
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`

	// Source Base64-encoded source document key
	Source []byte `json:"source"`

	// Target Base64-encoded target document key
	Target []byte `json:"target"`

	// Type Edge type (e.g., "cites", "similar_to", "authored_by")
	Type string `json:"type"`

	// UpdatedAt When the edge was last updated
	UpdatedAt time.Time `json:"updated_at,omitempty,omitzero"`

	// Weight Edge weight/confidence (0.0 to 1.0)
	Weight float64 `json:"weight"`
}

// EdgeDirection Direction of edges to query:
// - out: Outgoing edges from the node
// - in: Incoming edges to the node
// - both: Both outgoing and incoming edges
type EdgeDirection string

// EdgeTypeConfig Configuration for a specific edge type
type EdgeTypeConfig struct {
	// AllowSelfLoops Whether to allow edges from a node to itself
	AllowSelfLoops bool `json:"allow_self_loops,omitempty,omitzero"`

	// MaxWeight Maximum allowed edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum allowed edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// Name Edge type name (e.g., 'cites', 'similar_to')
	Name string `json:"name"`

	// RequiredMetadata Required metadata fields for this edge type
	RequiredMetadata []string `json:"required_metadata,omitempty,omitzero"`
}

// EdgesResponse defines model for EdgesResponse.
type EdgesResponse struct {
	// Count Total number of edges returned
	Count int    `json:"count,omitempty,omitzero"`
	Edges []Edge `json:"edges,omitempty,omitzero"`
}

// EmbedderConfig defines model for EmbedderConfig.
type EmbedderConfig struct {
	// Provider The embedding provider to use.
	Provider EmbedderProvider `json:"provider"`
	union    json.RawMessage
}

// EmbedderProvider The embedding provider to use.
type EmbedderProvider string

// EmbeddingIndexConfig defines model for EmbeddingIndexConfig.
type EmbeddingIndexConfig struct {
	// Chunker A unified configuration for a chunking provider.
	Chunker ChunkerConfig `json:"chunker,omitempty,omitzero"`

	// Dimension Vector dimension
	Dimension int `json:"dimension"`

	// Embedder A unified configuration for an embedding provider.
	//
	// Embedders can be configured with templates to customize how documents are
	// converted to text before embedding. Templates use Handlebars syntax and
	// support various built-in helpers.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full document as context
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active user{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// Document with metadata:
	// ```handlebars
	// Title: {{metadata.title}}
	// Date: {{metadata.date}}
	// Tags: {{#each metadata.tags}}{{this}}, {{/each}}
	//
	// {{content}}
	// ```
	//
	// HTML content extraction:
	// ```handlebars
	// Product: {{name}}
	// Description: {{scrubHtml description_html}}
	// Price: ${{price}}
	// ```
	//
	// Multimodal with image:
	// ```handlebars
	// Product: {{title}}
	// {{media url=image}}
	// Description: {{description}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{title}}
	// {{#if author}}By: {{author}}{{/if}}
	// {{#if (eq category "premium")}} Premium Content{{/if}}
	// {{body}}
	// ```
	//
	// **Environment Variables:**
	// - `GEMINI_API_KEY` - API key for Google AI
	// - `OPENAI_API_KEY` - API key for OpenAI
	// - `OPENAI_BASE_URL` - Base URL for OpenAI-compatible APIs
	// - `OLLAMA_HOST` - Ollama server URL (e.g., http://localhost:11434)
	//
	// **Importing Pre-computed Embeddings:**
	//
	// You can import existing embeddings (from OpenAI, Cohere, or any provider) by including
	// them directly in your documents using the `_embeddings` field. This bypasses the
	// embedding generation step and writes vectors directly to the index.
	//
	// **Steps:**
	// 1. Create the index first with the appropriate dimension
	// 2. Write documents with `_embeddings: { "<indexName>": [...<embedding>...] }`
	//
	// **Example:**
	// ```json
	// {
	//   "title": "My Document",
	//   "content": "Document text...",
	//   "_embeddings": {
	//     "my_vector_index": [0.1, 0.2, 0.3, ...]
	//   }
	// }
	// ```
	//
	// **Use Cases:**
	// - Migrating from another vector database with existing embeddings
	// - Using embeddings generated by external systems
	// - Importing pre-computed OpenAI, Cohere, or other provider embeddings
	// - Batch processing embeddings offline before ingestion
	Embedder EmbedderConfig `json:"embedder,omitempty,omitzero"`

	// Field Field to extract embeddings from
	Field string `json:"field,omitempty,omitzero"`

	// MemOnly Whether to use in-memory only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`

	// Summarizer A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Summarizer GeneratorConfig `json:"summarizer,omitempty,omitzero"`

	// Template Handlebars template for generating prompts. See https://handlebarsjs.com/guide/ for more information.
	Template string `json:"template,omitempty,omitzero"`
}

// EmbeddingIndexStats defines model for EmbeddingIndexStats.
type EmbeddingIndexStats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalIndexed Number of vectors in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`

	// TotalNodes Total number of nodes in the index
	TotalNodes uint64 `json:"total_nodes,omitempty,omitzero"`
}

// Error defines model for Error.
type Error struct {
	Error string `json:"error"`
}

// EvalConfig Configuration for inline evaluation of query results.
// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
type EvalConfig struct {
	// Evaluators List of evaluators to run
	Evaluators []EvaluatorName `json:"evaluators,omitempty,omitzero"`

	// GroundTruth Ground truth data for evaluation
	GroundTruth GroundTruth `json:"ground_truth,omitempty,omitzero"`

	// Judge A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Judge GeneratorConfig `json:"judge,omitempty,omitzero"`

	// Options Options for evaluation behavior
	Options EvalOptions `json:"options,omitempty,omitzero"`
}

// EvalOptions Options for evaluation behavior
type EvalOptions struct {
	// K K value for @K metrics (precision@k, recall@k, ndcg@k)
	K int `json:"k,omitempty,omitzero"`

	// PassThreshold Score threshold for pass/fail determination
	PassThreshold float32 `json:"pass_threshold,omitempty,omitzero"`

	// TimeoutSeconds Timeout for evaluation in seconds
	TimeoutSeconds int `json:"timeout_seconds,omitempty,omitzero"`
}

// EvalRequest Standalone evaluation request for POST /eval endpoint.
// Useful for testing evaluators without running a query.
type EvalRequest struct {
	// Context Retrieved documents/context
	Context []map[string]interface{} `json:"context,omitempty,omitzero"`

	// Evaluators List of evaluators to run
	Evaluators []EvaluatorName `json:"evaluators"`

	// GroundTruth Ground truth data for evaluation
	GroundTruth GroundTruth `json:"ground_truth,omitempty,omitzero"`

	// Judge A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Judge GeneratorConfig `json:"judge,omitempty,omitzero"`

	// Options Options for evaluation behavior
	Options EvalOptions `json:"options,omitempty,omitzero"`

	// Output Generated output to evaluate (optional for retrieval-only)
	Output string `json:"output,omitempty,omitzero"`

	// Query Original query/input to evaluate
	Query string `json:"query,omitempty,omitzero"`

	// RetrievedIds IDs of retrieved documents (for retrieval metrics)
	RetrievedIds []string `json:"retrieved_ids,omitempty,omitzero"`
}

// EvalResult Complete evaluation result
type EvalResult struct {
	// DurationMs Total evaluation duration in milliseconds
	DurationMs int `json:"duration_ms,omitempty,omitzero"`

	// Scores Scores organized by category
	Scores EvalScores `json:"scores,omitempty,omitzero"`

	// Summary Aggregate statistics across all evaluators
	Summary EvalSummary `json:"summary,omitempty,omitzero"`
}

// EvalScores Scores organized by category
type EvalScores struct {
	// Generation Generation quality scores (faithfulness, relevance, etc.)
	Generation map[string]EvaluatorScore `json:"generation,omitempty,omitzero"`

	// Retrieval Retrieval metric scores (recall, precision, ndcg, etc.)
	Retrieval map[string]EvaluatorScore `json:"retrieval,omitempty,omitzero"`
}

// EvalSummary Aggregate statistics across all evaluators
type EvalSummary struct {
	// AverageScore Average score across all evaluators
	AverageScore float32 `json:"average_score,omitempty,omitzero"`

	// Failed Number of evaluators that failed
	Failed int `json:"failed,omitempty,omitzero"`

	// Passed Number of evaluators that passed
	Passed int `json:"passed,omitempty,omitzero"`

	// Total Total number of evaluators run
	Total int `json:"total,omitempty,omitzero"`
}

// EvaluatorName Available evaluator types:
//
// **Retrieval metrics** (require ground_truth.relevant_ids):
// - recall: Recall@k - fraction of relevant docs retrieved
// - precision: Precision@k - fraction of retrieved docs that are relevant
// - ndcg: Normalized Discounted Cumulative Gain
// - mrr: Mean Reciprocal Rank
// - map: Mean Average Precision
//
// **LLM-as-judge metrics** (require judge config):
// - relevance: Is output relevant to query? (works on retrieval-only too)
// - faithfulness: Is output grounded in context?
// - completeness: Does output fully address query?
// - coherence: Is output well-structured?
// - safety: Is output safe/appropriate?
// - helpfulness: Is output useful?
// - correctness: Is output factually correct? (uses expectations)
// - citation_quality: Are citations accurate?
type EvaluatorName string

// EvaluatorScore Result from a single evaluator
type EvaluatorScore struct {
	// Metadata Additional evaluator-specific data
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`

	// Pass Whether the evaluation passed the threshold
	Pass bool `json:"pass,omitempty,omitzero"`

	// Reason Human-readable explanation of the result
	Reason string `json:"reason,omitempty,omitzero"`

	// Score Numeric score (0-1)
	Score float32 `json:"score,omitempty,omitzero"`
}

// FacetOption defines model for FacetOption.
type FacetOption struct {
	DateRanges    []DateRange    `json:"date_ranges,omitempty,omitzero"`
	Field         string         `json:"field,omitempty,omitzero"`
	NumericRanges []NumericRange `json:"numeric_ranges,omitempty,omitzero"`
	Size          int            `json:"size,omitempty,omitzero"`
}

// FacetResult defines model for FacetResult.
type FacetResult struct {
	DateRanges    []DateRangeResult    `json:"date_ranges,omitempty,omitzero"`
	Field         string               `json:"field,omitempty,omitzero"`
	Missing       int                  `json:"missing,omitempty,omitzero"`
	NumericRanges []NumericRangeResult `json:"numeric_ranges,omitempty,omitzero"`
	Terms         []TermFacetResult    `json:"terms,omitempty,omitzero"`
	Total         int                  `json:"total,omitempty,omitzero"`
}

// FailedOperation defines model for FailedOperation.
type FailedOperation struct {
	Error     string                   `json:"error,omitempty,omitzero"`
	Id        string                   `json:"id,omitempty,omitzero"`
	Operation FailedOperationOperation `json:"operation,omitempty,omitzero"`
}

// FailedOperationOperation defines model for FailedOperation.Operation.
type FailedOperationOperation string

// FollowupStepConfig Configuration for generating follow-up questions. Uses a separate generator
// call which can use a cheaper/faster model.
type FollowupStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Context Custom guidance for follow-up question focus and style
	Context string `json:"context,omitempty,omitzero"`

	// Count Number of follow-up questions to generate
	Count int `json:"count,omitempty,omitzero"`

	// Enabled Enable follow-up question generation
	Enabled bool `json:"enabled,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`
}

// Fuzziness The fuzziness of the query. Can be an integer or "auto".
type Fuzziness struct {
	union json.RawMessage
}

// Fuzziness0 defines model for .
type Fuzziness0 = int32

// Fuzziness1 defines model for Fuzziness.1.
type Fuzziness1 string

// FuzzyQuery defines model for FuzzyQuery.
type FuzzyQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness `json:"fuzziness,omitempty,omitzero"`
	PrefixLength int32     `json:"prefix_length,omitempty,omitzero"`
	Term         string    `json:"term"`
}

// GeneratorConfig defines model for GeneratorConfig.
type GeneratorConfig struct {
	// Provider The generative AI provider to use.
	Provider GeneratorProvider `json:"provider"`
	union    json.RawMessage
}

// GeneratorProvider The generative AI provider to use.
type GeneratorProvider string

// GeoBoundingBoxQuery defines model for GeoBoundingBoxQuery.
type GeoBoundingBoxQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost `json:"boost,omitzero"`

	// BottomRight [lon, lat]
	BottomRight []float64 `json:"bottom_right"`
	Field       string    `json:"field,omitempty,omitzero"`

	// TopLeft [lon, lat]
	TopLeft []float64 `json:"top_left"`
}

// GeoBoundingPolygonQuery defines model for GeoBoundingPolygonQuery.
type GeoBoundingPolygonQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost         Boost      `json:"boost,omitzero"`
	Field         string     `json:"field,omitempty,omitzero"`
	PolygonPoints []GeoPoint `json:"polygon_points"`
}

// GeoDistanceQuery defines model for GeoDistanceQuery.
type GeoDistanceQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Distance string `json:"distance"`
	Field    string `json:"field,omitempty,omitzero"`

	// Location [lon, lat]
	Location []float64 `json:"location"`
}

// GeoPoint defines model for GeoPoint.
type GeoPoint struct {
	Lat float64 `json:"lat,omitempty,omitzero"`
	Lon float64 `json:"lon,omitempty,omitzero"`
}

// GeoShape A GeoJSON shape object. This is a simplified representation.
type GeoShape struct {
	Coordinates []interface{} `json:"coordinates"`
	Type        string        `json:"type"`
}

// GeoShapeGeometry defines model for GeoShapeGeometry.
type GeoShapeGeometry struct {
	Relation GeoShapeGeometryRelation `json:"relation"`

	// Shape A GeoJSON shape object. This is a simplified representation.
	Shape GeoShape `json:"shape"`
}

// GeoShapeGeometryRelation defines model for GeoShapeGeometry.Relation.
type GeoShapeGeometryRelation string

// GeoShapeQuery defines model for GeoShapeQuery.
type GeoShapeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost            `json:"boost,omitzero"`
	Field    string           `json:"field,omitempty,omitzero"`
	Geometry GeoShapeGeometry `json:"geometry"`
}

// GoogleEmbedderConfig Configuration for the Google AI (Gemini) embedding provider.
//
// API key via `api_key` field or `GEMINI_API_KEY` environment variable.
//
// **Example Models:** gemini-embedding-001 (default, 3072 dims)
//
// **Docs:** https://ai.google.dev/gemini-api/docs/embeddings
type GoogleEmbedderConfig struct {
	// ApiKey The Google API key. Can also be set via GEMINI_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimension The dimension of the embedding vector (768, 1536, or 3072 recommended).
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1'). Required for Vertex AI, optional for Gemini API.
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the embedding model to use.
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID (optional for Gemini API, required for Vertex AI).
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Url The URL of the Google API endpoint (optional, uses default if not specified).
	Url string `json:"url,omitempty,omitzero"`
}

// GoogleGeneratorConfig Configuration for the Google generative AI provider (Gemini).
//
// **Example Models:** gemini-2.5-flash (default), gemini-2.5-pro, gemini-3.0-pro
//
// **Docs:** https://ai.google.dev/gemini-api/docs/models
type GoogleGeneratorConfig struct {
	// ApiKey The Google API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1').
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the generative model to use (e.g., 'gemini-2.5-flash', 'gemini-2.5-pro', 'gemini-3.0-pro').
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Google API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// GraphIndexV0Config Configuration for graph_v0 index type
type GraphIndexV0Config struct {
	// EdgeTypes List of edge types with their configurations
	EdgeTypes []EdgeTypeConfig `json:"edge_types,omitempty,omitzero"`

	// MaxEdgesPerDocument Maximum number of edges per document (0 = unlimited)
	MaxEdgesPerDocument int `json:"max_edges_per_document,omitempty,omitzero"`
}

// GraphIndexV0Stats Statistics for graph_v0 index
type GraphIndexV0Stats struct {
	// EdgeTypes Count of edges per edge type
	EdgeTypes map[string]uint64 `json:"edge_types,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalEdges Total number of edges in the graph
	TotalEdges uint64 `json:"total_edges,omitempty,omitzero"`
}

// GraphNodeSelector Defines how to select start/target nodes for graph queries
type GraphNodeSelector struct {
	// Keys Explicit list of node keys
	Keys []string `json:"keys,omitempty,omitzero"`

	// Limit Maximum number of nodes to select from the referenced results
	Limit int `json:"limit,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`

	// ResultRef Reference to search results to use as nodes:
	// - "$full_text_results" - use full-text search results
	// - "$aknn_results.index_name" - use vector search results from specific index
	ResultRef string `json:"result_ref,omitempty,omitzero"`
}

// GraphQuery Declarative graph query to execute after full-text/vector searches
type GraphQuery struct {
	// Fields Which fields to return from documents
	Fields []string `json:"fields,omitempty,omitzero"`

	// IncludeDocuments Fetch full documents for graph results
	IncludeDocuments bool `json:"include_documents,omitempty,omitzero"`

	// IncludeEdges Include edge details for each node
	IncludeEdges bool `json:"include_edges,omitempty,omitzero"`

	// IndexName Graph index name (must be graph_v0 type)
	IndexName string `json:"index_name"`

	// Params Parameters for graph traversal and pathfinding
	Params GraphQueryParams `json:"params,omitempty,omitzero"`

	// Pattern Pattern steps for pattern query type
	Pattern []PatternStep `json:"pattern,omitempty,omitzero"`

	// ReturnAliases Which aliases to return from pattern query (empty = all)
	ReturnAliases []string `json:"return_aliases,omitempty,omitzero"`

	// StartNodes Defines how to select start/target nodes for graph queries
	StartNodes GraphNodeSelector `json:"start_nodes,omitempty,omitzero"`

	// TargetNodes Defines how to select start/target nodes for graph queries
	TargetNodes GraphNodeSelector `json:"target_nodes,omitempty,omitzero"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryParams Parameters for graph traversal and pathfinding
type GraphQueryParams struct {
	// Algorithm Graph algorithm to run (e.g., 'pagerank', 'betweenness')
	Algorithm string `json:"algorithm,omitempty,omitzero"`

	// AlgorithmParams Parameters for the graph algorithm
	AlgorithmParams map[string]interface{} `json:"algorithm_params,omitempty,omitzero"`

	// DeduplicateNodes Remove duplicate nodes (traversal)
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information (traversal)
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// K Number of paths to find (k-shortest-paths)
	K int `json:"k,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum number of results (traversal)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`

	// WeightMode Path weighting algorithm for pathfinding:
	// - min_hops: Minimize number of edges
	// - min_weight: Minimize sum of edge weights
	// - max_weight: Maximize product of edge weights
	WeightMode PathWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// GraphQueryResult Results of a graph query
type GraphQueryResult struct {
	// Matches Pattern matches (for pattern queries)
	Matches []PatternMatch `json:"matches,omitempty,omitzero"`

	// Nodes Result nodes
	Nodes []GraphResultNode `json:"nodes,omitempty,omitzero"`

	// Paths Result paths (for pathfinding queries)
	Paths []Path `json:"paths,omitempty,omitzero"`

	// Took Query execution time
	Took time.Duration `json:"took,omitempty,omitzero"`

	// Total Total number of results
	Total int `json:"total"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryType Type of graph query to execute
type GraphQueryType string

// GraphResultNode A node in graph query results
type GraphResultNode struct {
	// Depth Distance from start node
	Depth int `json:"depth,omitempty,omitzero"`

	// Distance Weighted distance
	Distance float64 `json:"distance,omitempty,omitzero"`

	// Document Full document (if include_documents=true)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Edges Connected edges (when include_edges=true)
	Edges []Edge `json:"edges,omitempty,omitzero"`

	// Key Document key
	Key string `json:"key"`

	// Path Keys in path from start to this node
	Path []string `json:"path,omitempty,omitzero"`

	// PathEdges Edges in path from start to this node
	PathEdges []PathEdge `json:"path_edges,omitempty,omitzero"`
}

// GroundTruth Ground truth data for evaluation
type GroundTruth struct {
	// Expectations Context for evaluators about what to expect in the response.
	// Provides guidance for LLM judges (e.g., "Should mention pricing tiers").
	Expectations string `json:"expectations,omitempty,omitzero"`

	// RelevantIds Document IDs known to be relevant (for retrieval metrics)
	RelevantIds []string `json:"relevant_ids,omitempty,omitzero"`
}

// IPRangeQuery defines model for IPRangeQuery.
type IPRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Cidr  string `json:"cidr"`
	Field string `json:"field,omitempty,omitzero"`
}

// IndexConfig Configuration for an index
type IndexConfig struct {
	// Description Optional description of the index and its purpose
	Description string `json:"description,omitempty,omitzero"`

	// Enrichments List of enrichment names to apply to documents before indexing. Enrichments must be defined at the table level.
	Enrichments []string `json:"enrichments,omitempty,omitzero"`

	// Name Name of the index
	Name string `json:"name"`

	// Type The type of the index.
	Type  IndexType `json:"type"`
	union json.RawMessage
}

// IndexStats Statistics for an index
type IndexStats struct {
	union json.RawMessage
}

// IndexStatus defines model for IndexStatus.
type IndexStatus struct {
	// Config Configuration for an index
	Config      IndexConfig           `json:"config"`
	ShardStatus map[string]IndexStats `json:"shard_status"`

	// Status Statistics for an index
	Status IndexStats `json:"status"`
}

// IndexType The type of the index.
type IndexType string

// KeyRange Key range processed in this request
type KeyRange struct {
	From string `json:"from,omitempty,omitzero"`
	To   string `json:"to,omitempty,omitzero"`
}

// LinearMergePageStatus Status of a linear merge page operation:
// - "success": All records in batch processed successfully
// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
// - "error": Fatal error occurred, no records processed successfully
type LinearMergePageStatus string

// LinearMergeRequest Linear merge operation for syncing sorted records from external sources.
// Use this to keep Antfly in sync with an external database or data source.
//
// **How it works:**
// 1. Send sorted records from your external source
// 2. Server upserts records that exist in your batch
// 3. Server deletes Antfly records in the key range that are absent from your batch
// 4. If stopped at shard boundary, use next_cursor for next request
//
// **WARNING:** Not safe for concurrent operations with overlapping key ranges.
type LinearMergeRequest struct {
	// DryRun If true, returns what would be deleted without making changes.
	//
	// Use cases:
	// - Validate sync behavior before committing
	// - Check which records will be removed
	// - Test key range boundaries
	//
	// Response includes deleted_ids array when dry_run=true.
	DryRun bool `json:"dry_run,omitempty,omitzero"`

	// LastMergedId ID of last record from previous merge request.
	// - First request: Use empty string ""
	// - Subsequent requests: Use next_cursor from previous response
	// - Defines lower bound of key range to process
	//
	// This enables pagination for large datasets.
	LastMergedId string `json:"last_merged_id,omitempty,omitzero"`

	// Records Map of resource ID to resource object: {"resource_id_1": {...}, "resource_id_2": {...}}
	//
	// Requirements:
	// - Keys must be sorted lexicographically by your client
	// - Server will process keys in sorted order
	// - Use consistent key naming (e.g., all start with same prefix)
	//
	// This format avoids duplicate IDs and matches Antfly's batch write interface.
	Records map[string]interface{} `json:"records"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write
	// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`
}

// LinearMergeResult defines model for LinearMergeResult.
type LinearMergeResult struct {
	// Deleted Records deleted or would be deleted (if dry_run=true)
	Deleted int `json:"deleted"`

	// DeletedIds IDs that were deleted (or would be deleted if dry_run=true). Only included if dry_run=true.
	DeletedIds []string          `json:"deleted_ids,omitempty,omitzero"`
	Failed     []FailedOperation `json:"failed,omitempty,omitzero"`

	// KeyRange Key range processed in this request
	KeyRange KeyRange `json:"key_range,omitempty,omitzero"`

	// KeysScanned Total number of keys scanned from Antfly during range query
	KeysScanned int `json:"keys_scanned,omitempty,omitzero"`

	// Message Additional information (e.g., "stopped at shard boundary", "dry run - no changes made")
	Message string `json:"message,omitempty,omitzero"`

	// NextCursor ID of last record in this batch (use for next request)
	NextCursor string `json:"next_cursor"`

	// Skipped Records skipped because content hash matched (unchanged)
	Skipped int `json:"skipped"`

	// Status Status of a linear merge page operation:
	// - "success": All records in batch processed successfully
	// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
	// - "error": Fatal error occurred, no records processed successfully
	Status LinearMergePageStatus `json:"status"`
	Took   time.Duration         `json:"took,omitempty,omitzero"`

	// Upserted Records inserted or updated (0 if dry_run=true)
	Upserted int `json:"upserted"`
}

// MatchAllQuery defines model for MatchAllQuery.
type MatchAllQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost                  `json:"boost,omitzero"`
	MatchAll map[string]interface{} `json:"match_all"`
}

// MatchNoneQuery defines model for MatchNoneQuery.
type MatchNoneQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost                  `json:"boost,omitzero"`
	MatchNone map[string]interface{} `json:"match_none"`
}

// MatchPhraseQuery defines model for MatchPhraseQuery.
type MatchPhraseQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness   Fuzziness `json:"fuzziness,omitempty,omitzero"`
	MatchPhrase string    `json:"match_phrase"`
}

// MatchQuery defines model for MatchQuery.
type MatchQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness          `json:"fuzziness,omitempty,omitzero"`
	Match        string             `json:"match"`
	Operator     MatchQueryOperator `json:"operator,omitempty,omitzero"`
	PrefixLength int32              `json:"prefix_length,omitempty,omitzero"`
}

// MatchQueryOperator defines model for MatchQuery.Operator.
type MatchQueryOperator string

// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
// failover: Use full_text_search if embedding generation fails
type MergeStrategy string

// MultiPhraseQuery defines model for MultiPhraseQuery.
type MultiPhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness  `json:"fuzziness,omitempty,omitzero"`
	Terms     [][]string `json:"terms"`
}

// NodeFilter Filter nodes during graph traversal using existing query primitives
type NodeFilter struct {
	// FilterPrefix Filter by key prefix
	FilterPrefix string `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query to filter nodes (same syntax as search filter_query)
	FilterQuery map[string]interface{} `json:"filter_query,omitempty,omitzero"`
}

// NumericRange defines model for NumericRange.
type NumericRange struct {
	From *float64 `json:"from,omitempty"`
	Name string   `json:"name"`
	To   *float64 `json:"to,omitempty"`
}

// NumericRangeQuery defines model for NumericRangeQuery.
type NumericRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost   `json:"boost,omitzero"`
	Field        string  `json:"field,omitempty,omitzero"`
	InclusiveMax bool    `json:"inclusive_max,omitzero"`
	InclusiveMin bool    `json:"inclusive_min,omitzero"`
	Max          float64 `json:"max,omitzero"`
	Min          float64 `json:"min,omitzero"`
}

// NumericRangeResult defines model for NumericRangeResult.
type NumericRangeResult struct {
	Count int      `json:"count"`
	From  *float64 `json:"from,omitempty"`
	Name  string   `json:"name"`
	To    *float64 `json:"to,omitempty"`
}

// OllamaEmbedderConfig Configuration for the Ollama embedding provider.
//
// Local embeddings for privacy and offline use. URL via `url` field or `OLLAMA_HOST` env var.
//
// **Example Models:** nomic-embed-text (768 dims), mxbai-embed-large (1024 dims), all-minilm (384 dims)
//
// **Docs:** https://ollama.com/search?c=embedding
type OllamaEmbedderConfig struct {
	// Model The name of the Ollama model to use (e.g., 'nomic-embed-text', 'mxbai-embed-large').
	Model string `json:"model"`

	// Url The URL of the Ollama API endpoint. Can also be set via OLLAMA_HOST environment variable.
	Url string `json:"url,omitempty,omitzero"`
}

// OllamaGeneratorConfig Configuration for the Ollama generative AI provider.
//
// Ollama provides local LLM inference for privacy and offline use.
//
// **Example Models:** llama3.3:70b, qwen2.5:72b, deepseek-r1:70b, mistral:7b, llava:34b
//
// **Docs:** https://ollama.com/library
type OllamaGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Ollama model to use (e.g., 'llama3.3:70b', 'qwen2.5:72b', 'deepseek-coder:33b').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OllamaRerankerConfig Configuration for the Ollama reranking provider.
type OllamaRerankerConfig struct {
	// Model The name of the Ollama model to use for reranking.
	Model string `json:"model"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIEmbedderConfig Configuration for the OpenAI embedding provider.
//
// API key via `api_key` field or `OPENAI_API_KEY` environment variable.
// Supports OpenAI-compatible APIs via `url` field.
//
// **Example Models:** text-embedding-3-small (default, 1536 dims), text-embedding-3-large (3072 dims)
//
// **Docs:** https://platform.openai.com/docs/guides/embeddings
type OpenAIEmbedderConfig struct {
	// ApiKey The OpenAI API key. Can also be set via OPENAI_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimensions Output dimension for the embedding (uses MRL for dimension reduction). Recommended: 256, 512, 1024, 1536, or 3072.
	Dimensions int `json:"dimensions,omitempty,omitzero"`

	// Model The name of the OpenAI model to use.
	Model string `json:"model"`

	// Url The URL of the OpenAI API endpoint. Defaults to OpenAI's API. Can be set via OPENAI_BASE_URL environment variable.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIGeneratorConfig Configuration for the OpenAI generative AI provider.
//
// **Example Models:** gpt-4.1 (default), gpt-4.1-mini, o3, o4-mini
//
// **Docs:** https://platform.openai.com/docs/models
type OpenAIGeneratorConfig struct {
	// ApiKey The OpenAI API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (-2.0 to 2.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the OpenAI model to use (e.g., 'gpt-4.1', 'gpt-4.1-mini', 'o4-mini').
	Model string `json:"model"`

	// PresencePenalty Penalty for token presence (-2.0 to 2.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the OpenAI API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// Path defines model for Path.
type Path struct {
	Edges  []PathEdge `json:"edges,omitempty,omitzero"`
	Length int        `json:"length,omitempty,omitzero"`

	// Nodes Ordered list of node keys (base64-encoded)
	Nodes       []string `json:"nodes,omitempty,omitzero"`
	TotalWeight float64  `json:"total_weight,omitempty,omitzero"`
}

// PathEdge defines model for PathEdge.
type PathEdge struct {
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`
	Source   string                 `json:"source,omitempty,omitzero"`
	Target   string                 `json:"target,omitempty,omitzero"`
	Type     string                 `json:"type,omitempty,omitzero"`
	Weight   float64                `json:"weight,omitempty,omitzero"`
}

// PathFindRequest defines model for PathFindRequest.
type PathFindRequest struct {
	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by specific edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`
	K         int      `json:"k,omitempty,omitzero"`
	MaxDepth  int      `json:"max_depth,omitempty,omitzero"`
	MaxWeight float64  `json:"max_weight,omitempty,omitzero"`
	MinWeight float64  `json:"min_weight,omitempty,omitzero"`

	// Source Source node key (base64-encoded)
	Source string `json:"source"`

	// Target Target node key (base64-encoded)
	Target string `json:"target"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindResult defines model for PathFindResult.
type PathFindResult struct {
	Paths        []Path  `json:"paths,omitempty,omitzero"`
	PathsFound   int     `json:"paths_found,omitempty,omitzero"`
	SearchTimeMs float64 `json:"search_time_ms,omitempty,omitzero"`
	Source       string  `json:"source,omitempty,omitzero"`
	Target       string  `json:"target,omitempty,omitzero"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindWeightMode Algorithm for path finding:
// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
// - max_weight: Path with maximum product of edge weights (strongest connection chain)
// - min_weight: Path with minimum sum of edge weights (lowest cost route)
type PathFindWeightMode string

// PathWeightMode Path weighting algorithm for pathfinding:
// - min_hops: Minimize number of edges
// - min_weight: Minimize sum of edge weights
// - max_weight: Maximize product of edge weights
type PathWeightMode string

// PatternEdgeStep Edge constraints in a pattern step
type PatternEdgeStep struct {
	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// MaxHops Maximum number of hops (>1 = variable-length path)
	MaxHops int `json:"max_hops,omitempty,omitzero"`

	// MaxWeight Maximum edge weight filter
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinHops Minimum number of hops (1 = direct edge)
	MinHops int `json:"min_hops,omitempty,omitzero"`

	// MinWeight Minimum edge weight filter
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// Types Edge types to traverse (empty = any)
	Types []string `json:"types,omitempty,omitzero"`
}

// PatternMatch A single match from a pattern query
type PatternMatch struct {
	// Bindings Map of alias to matched node
	Bindings map[string]GraphResultNode `json:"bindings,omitempty,omitzero"`

	// Path Edges traversed in this match
	Path []PathEdge `json:"path,omitempty,omitzero"`
}

// PatternStep A step in a graph pattern query
type PatternStep struct {
	// Alias Name for this node (reuse alias for cycle detection)
	Alias string `json:"alias,omitempty,omitzero"`

	// Edge Edge constraints in a pattern step
	Edge PatternEdgeStep `json:"edge,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`
}

// Permission defines model for Permission.
type Permission struct {
	// Resource Resource name (e.g., table name, target username, or '*' for global).
	Resource string `json:"resource"`

	// ResourceType Type of the resource, e.g., table, user, or global ('*').
	ResourceType ResourceType `json:"resource_type"`

	// Type Type of permission.
	Type PermissionType `json:"type"`
}

// PermissionType Type of permission.
type PermissionType string

// PhraseQuery defines model for PhraseQuery.
type PhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness `json:"fuzziness,omitempty,omitzero"`
	Terms     []string  `json:"terms"`
}

// PrefixQuery defines model for PrefixQuery.
type PrefixQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Prefix string `json:"prefix"`
}

// Pruner Configuration for pruning search results based on score quality.
// Helps filter out low-relevance results in RAG pipelines by detecting
// score gaps or deviations from top results.
type Pruner struct {
	// MaxScoreGapPercent Stop returning results when score drops more than this percentage
	// from the previous result. Detects "elbows" in score distribution.
	// For example, 30.0 stops when score drops 30% from previous result.
	MaxScoreGapPercent float64 `json:"max_score_gap_percent,omitempty,omitzero"`

	// MinAbsoluteScore Hard minimum score threshold. Results with scores below this value
	// are excluded regardless of other pruning settings.
	MinAbsoluteScore float64 `json:"min_absolute_score,omitempty,omitzero"`

	// MinScoreRatio Keep only results with score >= max_score * min_score_ratio.
	// For example, 0.5 keeps results scoring at least half of the top result.
	// Applied after fusion scoring.
	MinScoreRatio float64 `json:"min_score_ratio,omitempty,omitzero"`

	// RequireMultiIndex Only keep results that appear in multiple indexes (both full-text
	// and vector search). Useful for increasing precision by requiring
	// agreement between different retrieval methods.
	RequireMultiIndex bool `json:"require_multi_index,omitempty,omitzero"`

	// StdDevThreshold Keep results within N standard deviations below the mean score.
	// For example, 1.0 keeps results with score >= mean - 1*stddev.
	// Useful for statistical outlier detection in result sets.
	StdDevThreshold float64 `json:"std_dev_threshold,omitempty,omitzero"`
}

// Query defines model for Query.
type Query struct {
	union json.RawMessage
}

// QueryBuilderRequest defines model for QueryBuilderRequest.
type QueryBuilderRequest struct {
	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// Intent Natural language description of the search intent
	Intent string `json:"intent"`

	// SchemaFields List of searchable field names to consider. Overrides table schema if provided.
	SchemaFields []string `json:"schema_fields,omitempty,omitzero"`

	// Table Name of the table to build query for. If provided, uses table schema for field context.
	Table string `json:"table,omitempty,omitzero"`
}

// QueryBuilderResult defines model for QueryBuilderResult.
type QueryBuilderResult struct {
	// Confidence Model's confidence in the generated query (0.0-1.0)
	Confidence float64 `json:"confidence,omitempty,omitzero"`

	// Explanation Human-readable explanation of what the query does and why it was structured this way
	Explanation string `json:"explanation,omitempty,omitzero"`

	// Query Generated search query in simplified DSL format.
	// Can be used directly in QueryRequest.full_text_search or filter_query.
	Query map[string]interface{} `json:"query"`

	// Warnings Any issues, limitations, or assumptions made when generating the query
	Warnings []string `json:"warnings,omitempty,omitzero"`
}

// QueryHit A single query result hit
type QueryHit struct {
	// ID ID of the record.
	ID string `json:"_id"`

	// IndexScores Scores partitioned by index when using RRF search.
	IndexScores map[string]interface{} `json:"_index_scores,omitempty,omitzero"`

	// Score Relevance score of the hit.
	Score  float64                `json:"_score"`
	Source map[string]interface{} `json:"_source,omitempty,omitzero"`
}

// QueryHits A list of query hits.
type QueryHits struct {
	Hits []QueryHit `json:"hits"`

	// MaxScore Maximum score of the results.
	MaxScore float64 `json:"max_score,omitempty,omitzero"`

	// Total Total number of hits available.
	Total uint64 `json:"total,omitempty"`
}

// QueryRequest defines model for QueryRequest.
type QueryRequest struct {
	Analyses *Analyses `json:"analyses,omitempty"`

	// Count If true, returns only the total count of matching documents without retrieving the actual documents.
	// Useful for pagination and displaying result counts.
	Count bool `json:"count,omitempty,omitzero"`

	// DistanceOver Minimum distance threshold for semantic similarity search. Results with distance
	// less than this value are excluded.
	//
	// Useful for excluding near-exact duplicates or finding dissimilar documents.
	DistanceOver *float32 `json:"distance_over,omitempty"`

	// DistanceUnder Maximum distance threshold for semantic similarity search. Results with distance
	// greater than this value are excluded. Lower distances indicate higher similarity.
	//
	// Useful for filtering out low-confidence matches.
	DistanceUnder *float32 `json:"distance_under,omitempty"`

	// DocumentRenderer Optional Handlebars template string for rendering document content in RAG queries.
	// Template has access to document fields via `{{this.fields.fieldName}}`.
	//
	// **Default**: Uses TOON (Token-Oriented Object Notation) format for 30-60% token reduction:
	// ```handlebars
	// {{encodeToon this.fields}}
	// ```
	//
	// **Available Helpers**:
	// - `encodeToon` - Renders fields in compact TOON format with configurable options:
	//   - `lengthMarker` (bool): Add # prefix to array counts (default: true)
	//   - `indent` (int): Indentation spacing (default: 2)
	//   - `delimiter` (string): Field separator for tabular arrays
	// - `scrubHtml` - Removes HTML tags and extracts text
	// - `media` - Wraps data URIs for GenKit multimodal support
	// - `eq` - Equality comparison for conditionals
	//
	// **Examples**:
	// - Basic TOON: `{{encodeToon this.fields}}`
	// - Compact TOON: `{{encodeToon this.fields lengthMarker=false indent=0}}`
	// - Tabular data: `{{encodeToon this.fields delimiter="\t"}}`
	// - Custom template: `Title: {{this.fields.title}}\nBody: {{this.fields.body}}`
	// - Traditional format: `{{#each this.fields}}{{@key}}: {{this}}\n{{/each}}`
	//
	// TOON format produces compact, LLM-optimized output like:
	// ```
	// title: Introduction to Vector Search
	// author: Jane Doe
	// tags[#3]: ai,search,ml
	// ```
	//
	// **References**:
	// - TOON Specification: https://github.com/toon-format/toon
	// - Go Implementation: https://github.com/alpkeskin/gotoon
	DocumentRenderer string `json:"document_renderer,omitempty,omitzero"`

	// EmbeddingTemplate Optional Handlebars template for multimodal embedding of the semantic_search query.
	// The template has access to `this` which contains the semantic_search string value.
	//
	// Use this when you want to embed multimodal content (images, PDFs, etc.) instead of
	// just text. The template is rendered using dotprompt with access to remote content helpers.
	//
	// **Available Helpers**:
	// - `remoteMedia url=<url>` - Fetches and embeds remote images/media
	// - `remotePDF url=<url>` - Fetches and extracts content from PDFs
	// - `remoteText url=<url>` - Fetches and includes remote text content
	//
	// **Examples**:
	// - PDF search: `{{remotePDF url=this}}`
	// - Image search: `{{remoteMedia url=this}}`
	// - Mixed: `Search for: {{this}} {{#if this}}{{remoteMedia url=this}}{{/if}}`
	//
	// When not specified, the semantic_search string is embedded as plain text.
	EmbeddingTemplate string `json:"embedding_template,omitempty,omitzero"`

	// Embeddings Pre-computed embeddings to use for semantic searches instead of embedding the semantic_search string.
	// The keys are the index names, and values are the embedding vectors.
	//
	// Use when you've already generated embeddings on the client side to avoid redundant embedding calls.
	Embeddings map[string][]float32 `json:"embeddings,omitempty,omitzero"`

	// ExclusionQuery Bleve query applied as a NOT condition. Documents matching this query are excluded
	// from results. Applied before scoring.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Excluding drafts: `"status:draft"`
	// - Removing deprecated content: `"deprecated:true"`
	// - Filtering out archived items: `"status:archived"`
	ExclusionQuery json.RawMessage `json:"exclusion_query,omitempty,omitzero"`

	// ExpandStrategy Strategy for merging graph results with search results:
	// - union: Include nodes from both search and graph results
	// - intersection: Only include nodes appearing in both
	ExpandStrategy QueryRequestExpandStrategy `json:"expand_strategy,omitempty,omitzero"`

	// Facets Faceting configuration for aggregating results by field values.
	// Useful for building faceted navigation and filters.
	Facets map[string]FacetOption `json:"facets,omitempty,omitzero"`

	// Fields List of fields to include in the results. If not specified, all fields are returned.
	// Use to reduce response size and improve performance.
	Fields []string `json:"fields,omitempty,omitzero"`

	// FilterPrefix Filter results by key prefix. Only returns documents whose keys start with this string.
	// Applied before scoring to improve performance.
	//
	// Common use cases:
	// - Multi-tenant filtering: `"tenant:acme:"`
	// - User-specific data: `"user:123:"`
	// - Document type filtering: `"article:"`
	FilterPrefix []byte `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query applied as an AND condition. Documents must match both the main query
	// and this filter. Applied before scoring for better performance.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Status filtering: `"status:published"`
	// - Date ranges: `"created_at:>2023-01-01"`
	// - Category filtering: `"category:technology AND language:en"`
	FilterQuery json.RawMessage `json:"filter_query,omitempty,omitzero"`

	// FullTextSearch Bleve query for full-text search. Supports all Bleve query types.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Examples:
	// - Simple: `{"query": "computer"}`
	// - Field-specific: `{"query": "body:computer"}`
	// - Boolean: `{"query": "artificial AND intelligence"}`
	// - Range: `{"query": "year:>2020"}`
	// - Phrase: `{"query": "\"exact phrase\""}`
	FullTextSearch json.RawMessage `json:"full_text_search,omitempty,omitzero"`

	// GraphSearches Declarative graph queries to execute after full-text/vector searches.
	// Results can reference search results using node selectors like $full_text_results.
	GraphSearches map[string]GraphQuery `json:"graph_searches,omitempty,omitzero"`

	// Indexes List of vector index names to use for semantic search. Required when using semantic_search.
	// Multiple indexes can be specified, and their results will be merged using RRF.
	Indexes []string `json:"indexes,omitempty,omitzero"`

	// Limit Maximum number of results to return. For semantic_search, this is the topk parameter.
	// Default varies by query type (typically 10).
	Limit int `json:"limit,omitempty,omitzero"`

	// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
	// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
	// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
	// failover: Use full_text_search if embedding generation fails
	MergeStrategy MergeStrategy `json:"merge_strategy,omitempty,omitzero"`

	// Offset Number of results to skip for pagination. Only available for full_text_search queries.
	// Not supported for semantic_search due to vector index limitations.
	Offset int `json:"offset,omitempty,omitzero"`

	// OrderBy Sort order for results. Map of field names to boolean (true = descending, false = ascending).
	// Only applicable for full_text_search queries. Semantic searches are always sorted by similarity score.
	OrderBy map[string]bool `json:"order_by,omitempty,omitzero"`

	// Pruner Configuration for pruning search results based on score quality.
	// Helps filter out low-relevance results in RAG pipelines by detecting
	// score gaps or deviations from top results.
	Pruner Pruner `json:"pruner,omitempty,omitzero"`

	// Reranker A unified configuration for a reranking provider.
	Reranker *RerankerConfig `json:"reranker,omitempty"`

	// SemanticSearch Natural language query for vector similarity search. Results are ranked by semantic similarity
	// to the query and can be combined with full_text_search using Reciprocal Rank Fusion (RRF).
	//
	// The semantic_search string is automatically embedded using the configured embedding model
	// for the specified indexes. Use `embedding_template` for multimodal queries.
	SemanticSearch string `json:"semantic_search,omitempty,omitzero"`

	// Table Name of the table to query. Optional for global queries.
	Table string `json:"table,omitempty,omitzero"`
}

// QueryRequestExpandStrategy Strategy for merging graph results with search results:
// - union: Include nodes from both search and graph results
// - intersection: Only include nodes appearing in both
type QueryRequestExpandStrategy string

// QueryResponses Responses from multiple query operations.
type QueryResponses struct {
	Responses []QueryResult `json:"responses,omitempty,omitzero"`
}

// QueryResult Result of a query operation as an array of results and a count.
type QueryResult struct {
	// Analyses Analysis results like PCA and t-SNE per index embeddings.
	Analyses map[string]AnalysesResult `json:"analyses,omitempty,omitzero"`

	// Error Error message if the query failed.
	Error  string                 `json:"error,omitempty,omitzero"`
	Facets map[string]FacetResult `json:"facets,omitempty,omitzero"`

	// GraphResults Results from declarative graph queries.
	GraphResults map[string]GraphQueryResult `json:"graph_results,omitempty,omitzero"`

	// Hits A list of query hits.
	Hits QueryHits `json:"hits"`

	// Status HTTP status code of the query operation.
	Status int32 `json:"status"`

	// Table Which table this result came from
	Table string `json:"table,omitempty,omitzero"`

	// Took Duration of the query in milliseconds.
	Took time.Duration `json:"took"`
}

// QueryStrategy Strategy for query transformation and retrieval:
// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
type QueryStrategy string

// QueryStringQuery defines model for QueryStringQuery.
type QueryStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Query string `json:"query"`
}

// RAGRequest defines model for RAGRequest.
type RAGRequest struct {
	// Chain Chain of generators with retry/fallback semantics. Mutually exclusive with 'generator'.
	// Each link can specify retry configuration and a condition for trying the next generator.
	// Either 'generator' or 'chain' must be provided.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Eval Configuration for inline evaluation of query results.
	// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
	Eval EvalConfig `json:"eval,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// Prompt Optional custom user prompt template for the LLM. If not provided, a default prompt is used.
	// The prompt can reference the following variables:
	// - {{documents}}: Array of retrieved documents with id and fields
	// - {{semantic_search}}: The user's semantic search query (if provided)
	// You can use Handlebars template syntax to customize the prompt, including loops and conditionals.
	// To generate a comma-separated list of document IDs, use: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	Prompt string `json:"prompt,omitempty,omitzero"`

	// Queries Array of retrieval queries to execute. Each query must specify a table and can specify its own limit and document_renderer.
	// Results from all queries are concatenated together (respecting each query's limit).
	// For single table: [{"table": "papers", "semantic_search": "...", "limit": 10}]
	// For broadcast: [{"table": "images", "limit": 5, ...}, {"table": "products", "limit": 5, ...}]
	// For mixed: [{"table": "papers", "semantic_search": "...", "limit": 10}, {"table": "books", "full_text_search": {...}, "limit": 5}]
	Queries []QueryRequest `json:"queries"`

	// SystemPrompt Optional system prompt to guide the summarization
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// RAGResult RAG result with individual query results and summary
type RAGResult struct {
	// EvalResult Complete evaluation result
	EvalResult EvalResult `json:"eval_result,omitempty,omitzero"`

	// QueryResults Results from each query. Check each result's status and error fields for failures.
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`

	// SummaryResult Result of a summarization operation. The summary is formatted as markdown with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
	SummaryResult SummarizeResult `json:"summary_result,omitempty,omitzero"`
}

// RegexpQuery defines model for RegexpQuery.
type RegexpQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Regexp string `json:"regexp"`
}

// RerankerConfig defines model for RerankerConfig.
type RerankerConfig struct {
	// Field Field name to extract from documents for reranking.
	Field string `json:"field,omitempty,omitzero"`

	// Provider The reranking provider to use.
	Provider RerankerProvider `json:"provider"`

	// Template Handlebars template to render document text for reranking.
	Template string `json:"template,omitempty,omitzero"`
	union    json.RawMessage
}

// RerankerProvider The reranking provider to use.
type RerankerProvider string

// ResourceType Type of the resource, e.g., table, user, or global ('*').
type ResourceType string

// RestoreRequest defines model for RestoreRequest.
type RestoreRequest = BackupRequest

// RetryConfig Retry configuration for generator calls
type RetryConfig struct {
	// BackoffMultiplier Multiplier for exponential backoff
	BackoffMultiplier float32 `json:"backoff_multiplier,omitempty,omitzero"`

	// InitialBackoffMs Initial backoff delay in milliseconds
	InitialBackoffMs int `json:"initial_backoff_ms,omitempty,omitzero"`

	// MaxAttempts Maximum number of retry attempts
	MaxAttempts int `json:"max_attempts,omitempty,omitzero"`

	// MaxBackoffMs Maximum backoff delay in milliseconds
	MaxBackoffMs int `json:"max_backoff_ms,omitempty,omitzero"`
}

// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
type RouteType string

// ScanKeysRequest Request to scan keys in a table within a key range.
// If no range is specified, scans all keys in the table.
type ScanKeysRequest struct {
	// ExclusiveTo If true, exclude keys matching 'to' from the results.
	// Default: false (inclusive upper bound).
	ExclusiveTo bool `json:"exclusive_to,omitempty,omitzero"`

	// Fields List of fields to include in each result. If not specified,
	// only returns the key. Supports:
	// - Simple fields: "title", "author"
	// - Nested paths: "user.address.city"
	// - Wildcards: "_chunks.*"
	// - Exclusions: "-_chunks.*._embedding"
	// - Special fields: "_embeddings", "_summaries", "_chunks"
	Fields []string `json:"fields,omitempty,omitzero"`

	// FilterQuery Bleve query to filter documents. Only documents matching this query
	// are included in results. Uses the sear library for efficient per-document
	// matching without requiring a full index.
	//
	// Examples:
	// - Status filtering: `{"query": "status:published"}`
	// - Date ranges: `{"query": "created_at:>2023-01-01"}`
	// - Field matching: `{"query": "category:technology"}`
	FilterQuery json.RawMessage `json:"filter_query,omitempty,omitzero"`

	// From Start of the key range to scan (exclusive by default).
	// Can be a full key or a prefix. If not specified, starts from
	// the beginning of the table.
	From string `json:"from,omitempty,omitzero"`

	// InclusiveFrom If true, include keys matching 'from' in the results.
	// Default: false (exclusive lower bound for pagination).
	InclusiveFrom bool `json:"inclusive_from,omitempty,omitzero"`

	// Limit Maximum number of results to return. If not specified, returns all
	// matching keys in the range. Useful for pagination or sampling.
	Limit int `json:"limit,omitempty,omitzero"`

	// To End of the key range to scan (inclusive by default).
	// Can be a full key or a prefix. If not specified, scans to
	// the end of the table.
	To string `json:"to,omitempty,omitzero"`
}

// SemanticQueryMode Mode for semantic query generation:
// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
type SemanticQueryMode string

// ShardConfig defines model for ShardConfig.
type ShardConfig struct {
	ByteRange ByteRange `json:"byte_range"`
}

// StorageStatus defines model for StorageStatus.
type StorageStatus struct {
	// DiskUsage Disk usage in bytes.
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Empty Whether the table has received data.
	Empty bool `json:"empty,omitempty,omitzero"`
}

// SuccessMessage defines model for SuccessMessage.
type SuccessMessage struct {
	Message string `json:"message,omitempty,omitzero"`
}

// SummarizeResult Result of a summarization operation. The summary is formatted as markdown with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
type SummarizeResult struct {
	// Summary The generated summary text in markdown format with inline resource references like [resource_id res1] or [resource_id res1, res2]
	Summary string `json:"summary"`
}

// SyncLevel Synchronization level for batch operations:
// - "propose": Wait for Raft proposal acceptance (fastest, default)
// - "write": Wait for Pebble KV write
// - "full_text": Wait for full-text index WAL write
// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
type SyncLevel string

// Table defines model for Table.
type Table struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema            `json:"schema,omitempty,omitzero"`
	Shards map[string]ShardConfig `json:"shards"`
}

// TableSchema Schema definition for a table with multiple document types
type TableSchema struct {
	// DefaultType Default type to use from the document_types.
	DefaultType string `json:"default_type,omitempty,omitzero"`

	// DocumentSchemas A map of type names to their document json schemas.
	DocumentSchemas map[string]DocumentSchema `json:"document_schemas,omitempty,omitzero"`

	// EnforceTypes Whether to enforce that documents must match one of the provided document types.
	// If false, documents not matching any type will be accepted but not indexed.
	EnforceTypes bool `json:"enforce_types,omitempty,omitzero"`

	// TtlDuration The duration after which documents should expire, based on the ttl_field timestamp (optional).
	// Uses Go duration format (e.g., '24h', '7d', '168h').
	TtlDuration string `json:"ttl_duration,omitempty,omitzero"`

	// TtlField The field containing the timestamp for TTL expiration (optional).
	// Defaults to "_timestamp" if ttl_duration is specified but ttl_field is not.
	TtlField string `json:"ttl_field,omitempty,omitzero"`

	// Version Version of the schema. Used for migrations.
	Version uint32 `json:"version,omitempty,omitzero"`
}

// TableStatus defines model for TableStatus.
type TableStatus struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema        TableSchema            `json:"schema,omitempty,omitzero"`
	Shards        map[string]ShardConfig `json:"shards"`
	StorageStatus StorageStatus          `json:"storage_status"`
}

// TermFacetResult defines model for TermFacetResult.
type TermFacetResult struct {
	Count int    `json:"count"`
	Term  string `json:"term"`
}

// TermQuery defines model for TermQuery.
type TermQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
	Term  string `json:"term"`
}

// TermRangeQuery defines model for TermRangeQuery.
type TermRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost  `json:"boost,omitzero"`
	Field        string `json:"field,omitempty,omitzero"`
	InclusiveMax bool   `json:"inclusive_max,omitzero"`
	InclusiveMin bool   `json:"inclusive_min,omitzero"`
	Max          string `json:"max,omitzero"`
	Min          string `json:"min,omitzero"`
}

// TermiteChunkerConfig Configuration for the Termite chunking provider.
//
// Termite is a centralized HTTP service that provides chunking with multi-tier caching.
// The model name maps to ONNX model directory names (similar to how Ollama works).
//
// **Chunking Models:**
// - fixed: Simple fixed-size chunking by token count (built-in, no ONNX required)
// - Any other name will attempt to load from models/chunkers/{name}/ directory
//
// **Caching:**
// - L1: Memory cache with 2-minute TTL
// - L2: Persistent Pebble database
// - Singleflight deduplication for concurrent identical requests
type TermiteChunkerConfig struct {
	// ApiUrl The URL of the Termite API endpoint (e.g., 'http://localhost:8080'). Can also be set via ANTFLY_TERMITE_URL environment variable.
	ApiUrl string `json:"api_url,omitempty,omitzero"`

	// FullText Configuration for full-text indexing of chunks in Bleve.
	// When present (even if empty), chunks will be stored with :cft: suffix and indexed in Bleve's _chunks field.
	// When absent, chunks use :c: suffix and are only used for vector embeddings.
	// This object is reserved for future options like boosting, field mapping, etc.
	FullText map[string]interface{} `json:"full_text,omitempty,omitzero"`

	// MaxChunks Maximum number of chunks to generate per document. Prevents excessive chunking of very large documents.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// Model The chunking model to use. Either 'fixed' for simple token-based chunking, or a model name from models/chunkers/{name}/.
	Model string `json:"model"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs). Only used with fixed strategy.
	Separator string `json:"separator,omitempty,omitzero"`

	// TargetTokens Target number of tokens per chunk. Chunker will aim for chunks around this size.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`

	// Threshold Minimum confidence threshold for separator detection. Only used with ONNX-based models.
	Threshold float32 `json:"threshold,omitempty,omitzero"`
}

// TermiteRerankerConfig Configuration for the Termite reranking provider.
type TermiteRerankerConfig struct {
	// Model The name of the reranking model (e.g., cross-encoder model name).
	Model string `json:"model"`

	// Url The URL of the Termite API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// Transform In-place document transformation using MongoDB-style operators. Transforms are applied atomically
// at the storage layer, eliminating read-modify-write races.
//
// **Important:** Transform results are NOT validated against the table schema. This improves performance
// but means it's possible to create invalid documents. Use with care and ensure your operations maintain
// schema compliance.
type Transform struct {
	// Key Document key (must be a string, not an object like inserts)
	Key string `json:"key"`

	// Operations List of operations to apply in sequence
	Operations []TransformOp `json:"operations"`

	// Upsert If true, create document if it doesn't exist (like MongoDB upsert)
	Upsert bool `json:"upsert,omitempty,omitzero"`
}

// TransformOp defines model for TransformOp.
type TransformOp struct {
	// Op MongoDB-style update operator
	Op TransformOpType `json:"op"`

	// Path JSONPath to field (e.g., "$.user.name", "$.tags", or "user.name")
	Path string `json:"path"`

	// Value Value for operation (not required for $unset, $currentDate). Type depends on operator (number for $inc/$mul, any for $set, etc.)
	Value interface{} `json:"value,omitempty,omitzero"`
}

// TransformOpType MongoDB-style update operator
type TransformOpType string

// TraversalResult A single result from graph traversal
type TraversalResult struct {
	// Depth Distance from start node (0 = start node)
	Depth int `json:"depth"`

	// Document Document data (if loaded)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Key Base64-encoded document key
	Key []byte `json:"key"`

	// Path Sequence of keys from start to this node (if include_paths=true)
	Path [][]byte `json:"path,omitempty,omitzero"`

	// PathEdges Sequence of edges from start to this node (if include_paths=true)
	PathEdges []Edge `json:"path_edges,omitempty,omitzero"`

	// TotalWeight Product of edge weights along the path
	TotalWeight float64 `json:"total_weight,omitempty,omitzero"`
}

// TraversalRules Rules for graph traversal
type TraversalRules struct {
	// DeduplicateNodes Visit each node only once
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter edges by type (empty = all types)
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information in results
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth (0 = unlimited)
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum results to return (0 = unlimited)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight filter
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight filter
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`
}

// TraverseResponse defines model for TraverseResponse.
type TraverseResponse struct {
	// Count Total number of results
	Count   int               `json:"count,omitempty,omitzero"`
	Results []TraversalResult `json:"results,omitempty,omitzero"`
}

// UpdatePasswordRequest defines model for UpdatePasswordRequest.
type UpdatePasswordRequest struct {
	NewPassword string `json:"new_password"`
}

// User defines model for User.
type User struct {
	// PasswordHash Base64 encoded password hash. Exposing this is a security risk.
	PasswordHash []byte `json:"password_hash"`
	Username     string `json:"username"`
}

// VertexEmbedderConfig Configuration for Google Cloud Vertex AI embedding models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication. Requires IAM role `roles/aiplatform.user`.
//
// **Example Models:** gemini-embedding-001 (default, 3072 dims), multimodalembedding (images/audio/video)
//
// **Docs:** https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings
type VertexEmbedderConfig struct {
	// CredentialsPath Path to service account JSON key file. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Dimension The dimension of the embedding vector (768, 1536, or 3072 for gemini-embedding-001; 128-1408 for multimodalembedding).
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the Vertex AI embedding model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`
}

// VertexGeneratorConfig Configuration for Google Cloud Vertex AI generative models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication. In GCP environments
// (Cloud Run, GKE, Compute Engine) this is automatic. For local dev, run
// `gcloud auth application-default login`. Requires IAM role `roles/aiplatform.user`.
//
// **Example Models:** gemini-2.5-flash (default), gemini-2.5-pro, gemini-3.0-pro
//
// **Docs:** https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models
type VertexGeneratorConfig struct {
	// CredentialsPath Path to service account JSON key file. Sets GOOGLE_APPLICATION_CREDENTIALS environment variable. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Vertex AI model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// VertexRerankerConfig Configuration for the Google Vertex AI Ranking API.
//
// Uses Application Default Credentials (ADC) or explicit credentials path.
//
// **Prerequisites:**
// - Enable Discovery Engine API: `gcloud services enable discoveryengine.googleapis.com`
// - Grant IAM role: `roles/discoveryengine.admin` (includes `discoveryengine.rankingConfigs.rank` permission)
//
// **Models:** semantic-ranker-default@latest (default), semantic-ranker-fast-004
//
// **Docs:** https://cloud.google.com/generative-ai-app-builder/docs/ranking
//
// **IAM:** https://cloud.google.com/generative-ai-app-builder/docs/access-control
type VertexRerankerConfig struct {
	// CredentialsPath Path to service account JSON file. Falls back to GOOGLE_APPLICATION_CREDENTIALS environment variable.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Model The ranking model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Falls back to GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// TopN Maximum number of records to return. If not specified, returns all documents with scores.
	TopN int `json:"top_n,omitempty,omitzero"`
}

// WildcardQuery defines model for WildcardQuery.
type WildcardQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Field    string `json:"field,omitempty,omitzero"`
	Wildcard string `json:"wildcard"`
}

// UserNamePathParameter defines model for UserNamePathParameter.
type UserNamePathParameter = string

// BadRequest defines model for BadRequest.
type BadRequest = Error

// InternalServerError defines model for InternalServerError.
type InternalServerError = Error

// NotFound defines model for NotFound.
type NotFound = Error

// ListTablesParams defines parameters for ListTables.
type ListTablesParams struct {
	// Prefix Filter tables by name prefix (e.g., "prod_")
	Prefix string `form:"prefix,omitempty" json:"prefix,omitempty,omitzero"`

	// Pattern Filter tables by regex pattern (e.g., "^prod_.*_v[0-9]+$")
	Pattern string `form:"pattern,omitempty" json:"pattern,omitempty,omitzero"`
}

// LookupKeyParams defines parameters for LookupKey.
type LookupKeyParams struct {
	// Fields Comma-separated list of fields to include in the response.
	// If not specified, returns the full document. Supports:
	// - Simple fields: "title,author"
	// - Nested paths: "user.address.city"
	// - Wildcards: "_chunks.*"
	// - Exclusions: "-_chunks.*._embedding"
	// - Special fields: "_embeddings,_summaries,_chunks"
	Fields string `form:"fields,omitempty" json:"fields,omitempty,omitzero"`
}

// RemovePermissionFromUserParams defines parameters for RemovePermissionFromUser.
type RemovePermissionFromUserParams struct {
	// Resource The name of the resource for the permission to be removed.
	Resource string `form:"resource" json:"resource"`

	// ResourceType The type of the resource for the permission to be removed.
	ResourceType ResourceType `form:"resourceType" json:"resourceType"`
}

// AnswerAgentJSONRequestBody defines body for AnswerAgent for application/json ContentType.
type AnswerAgentJSONRequestBody = AnswerAgentRequest

// QueryBuilderAgentJSONRequestBody defines body for QueryBuilderAgent for application/json ContentType.
type QueryBuilderAgentJSONRequestBody = QueryBuilderRequest

// EvaluateJSONRequestBody defines body for Evaluate for application/json ContentType.
type EvaluateJSONRequestBody = EvalRequest

// GlobalQueryJSONRequestBody defines body for GlobalQuery for application/json ContentType.
type GlobalQueryJSONRequestBody = QueryRequest

// RagQueryJSONRequestBody defines body for RagQuery for application/json ContentType.
type RagQueryJSONRequestBody = RAGRequest

// CreateTableJSONRequestBody defines body for CreateTable for application/json ContentType.
type CreateTableJSONRequestBody = CreateTableRequest

// BackupTableJSONRequestBody defines body for BackupTable for application/json ContentType.
type BackupTableJSONRequestBody = BackupRequest

// BatchJSONRequestBody defines body for Batch for application/json ContentType.
type BatchJSONRequestBody = BatchRequest

// CreateIndexJSONRequestBody defines body for CreateIndex for application/json ContentType.
type CreateIndexJSONRequestBody = IndexConfig

// ScanKeysJSONRequestBody defines body for ScanKeys for application/json ContentType.
type ScanKeysJSONRequestBody = ScanKeysRequest

// LinearMergeJSONRequestBody defines body for LinearMerge for application/json ContentType.
type LinearMergeJSONRequestBody = LinearMergeRequest

// QueryTableJSONRequestBody defines body for QueryTable for application/json ContentType.
type QueryTableJSONRequestBody = QueryRequest

// TableRagQueryJSONRequestBody defines body for TableRagQuery for application/json ContentType.
type TableRagQueryJSONRequestBody = RAGRequest

// RestoreTableJSONRequestBody defines body for RestoreTable for application/json ContentType.
type RestoreTableJSONRequestBody = RestoreRequest

// UpdateSchemaJSONRequestBody defines body for UpdateSchema for application/json ContentType.
type UpdateSchemaJSONRequestBody = TableSchema

// CreateUserJSONRequestBody defines body for CreateUser for application/json ContentType.
type CreateUserJSONRequestBody = CreateUserRequest

// UpdateUserPasswordJSONRequestBody defines body for UpdateUserPassword for application/json ContentType.
type UpdateUserPasswordJSONRequestBody = UpdatePasswordRequest

// AddPermissionToUserJSONRequestBody defines body for AddPermissionToUser for application/json ContentType.
type AddPermissionToUserJSONRequestBody = Permission

// Getter for additional properties for ClusterStatus. Returns the specified
// element and whether it was found
func (a ClusterStatus) Get(fieldName string) (value interface{}, found bool) {
	if a.AdditionalProperties != nil {
		value, found = a.AdditionalProperties[fieldName]
	}
	return
}

// Setter for additional properties for ClusterStatus
func (a *ClusterStatus) Set(fieldName string, value interface{}) {
	if a.AdditionalProperties == nil {
		a.AdditionalProperties = make(map[string]interface{})
	}
	a.AdditionalProperties[fieldName] = value
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a *ClusterStatus) UnmarshalJSON(b []byte) error {
	object := make(map[string]json.RawMessage)
	err := json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["auth_enabled"]; found {
		err = json.Unmarshal(raw, &a.AuthEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'auth_enabled': %w", err)
		}
		delete(object, "auth_enabled")
	}

	if raw, found := object["health"]; found {
		err = json.Unmarshal(raw, &a.Health)
		if err != nil {
			return fmt.Errorf("error reading 'health': %w", err)
		}
		delete(object, "health")
	}

	if raw, found := object["message"]; found {
		err = json.Unmarshal(raw, &a.Message)
		if err != nil {
			return fmt.Errorf("error reading 'message': %w", err)
		}
		delete(object, "message")
	}

	if len(object) != 0 {
		a.AdditionalProperties = make(map[string]interface{})
		for fieldName, fieldBuf := range object {
			var fieldVal interface{}
			err := json.Unmarshal(fieldBuf, &fieldVal)
			if err != nil {
				return fmt.Errorf("error unmarshaling field %s: %w", fieldName, err)
			}
			a.AdditionalProperties[fieldName] = fieldVal
		}
	}
	return nil
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a ClusterStatus) MarshalJSON() ([]byte, error) {
	var err error
	object := make(map[string]json.RawMessage)

	object["auth_enabled"], err = json.Marshal(a.AuthEnabled)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'auth_enabled': %w", err)
	}

	object["health"], err = json.Marshal(a.Health)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'health': %w", err)
	}

	object["message"], err = json.Marshal(a.Message)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'message': %w", err)
	}

	for fieldName, field := range a.AdditionalProperties {
		object[fieldName], err = json.Marshal(field)
		if err != nil {
			return nil, fmt.Errorf("error marshaling '%s': %w", fieldName, err)
		}
	}
	return json.Marshal(object)
}

// AsTermiteChunkerConfig returns the union data inside the ChunkerConfig as a TermiteChunkerConfig
func (t ChunkerConfig) AsTermiteChunkerConfig() (TermiteChunkerConfig, error) {
	var body TermiteChunkerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteChunkerConfig overwrites any union data inside the ChunkerConfig as the provided TermiteChunkerConfig
func (t *ChunkerConfig) FromTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteChunkerConfig performs a merge with any union data inside the ChunkerConfig, using the provided TermiteChunkerConfig
func (t *ChunkerConfig) MergeTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAntflyChunkerConfig returns the union data inside the ChunkerConfig as a AntflyChunkerConfig
func (t ChunkerConfig) AsAntflyChunkerConfig() (AntflyChunkerConfig, error) {
	var body AntflyChunkerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAntflyChunkerConfig overwrites any union data inside the ChunkerConfig as the provided AntflyChunkerConfig
func (t *ChunkerConfig) FromAntflyChunkerConfig(v AntflyChunkerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAntflyChunkerConfig performs a merge with any union data inside the ChunkerConfig, using the provided AntflyChunkerConfig
func (t *ChunkerConfig) MergeAntflyChunkerConfig(v AntflyChunkerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t ChunkerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *ChunkerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsGoogleEmbedderConfig returns the union data inside the EmbedderConfig as a GoogleEmbedderConfig
func (t EmbedderConfig) AsGoogleEmbedderConfig() (GoogleEmbedderConfig, error) {
	var body GoogleEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided GoogleEmbedderConfig
func (t *EmbedderConfig) FromGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided GoogleEmbedderConfig
func (t *EmbedderConfig) MergeGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexEmbedderConfig returns the union data inside the EmbedderConfig as a VertexEmbedderConfig
func (t EmbedderConfig) AsVertexEmbedderConfig() (VertexEmbedderConfig, error) {
	var body VertexEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided VertexEmbedderConfig
func (t *EmbedderConfig) FromVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided VertexEmbedderConfig
func (t *EmbedderConfig) MergeVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaEmbedderConfig returns the union data inside the EmbedderConfig as a OllamaEmbedderConfig
func (t EmbedderConfig) AsOllamaEmbedderConfig() (OllamaEmbedderConfig, error) {
	var body OllamaEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OllamaEmbedderConfig
func (t *EmbedderConfig) FromOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OllamaEmbedderConfig
func (t *EmbedderConfig) MergeOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIEmbedderConfig returns the union data inside the EmbedderConfig as a OpenAIEmbedderConfig
func (t EmbedderConfig) AsOpenAIEmbedderConfig() (OpenAIEmbedderConfig, error) {
	var body OpenAIEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) FromOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) MergeOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockEmbedderConfig returns the union data inside the EmbedderConfig as a BedrockEmbedderConfig
func (t EmbedderConfig) AsBedrockEmbedderConfig() (BedrockEmbedderConfig, error) {
	var body BedrockEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided BedrockEmbedderConfig
func (t *EmbedderConfig) FromBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided BedrockEmbedderConfig
func (t *EmbedderConfig) MergeBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereEmbedderConfig returns the union data inside the EmbedderConfig as a CohereEmbedderConfig
func (t EmbedderConfig) AsCohereEmbedderConfig() (CohereEmbedderConfig, error) {
	var body CohereEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided CohereEmbedderConfig
func (t *EmbedderConfig) FromCohereEmbedderConfig(v CohereEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided CohereEmbedderConfig
func (t *EmbedderConfig) MergeCohereEmbedderConfig(v CohereEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t EmbedderConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *EmbedderConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsFuzziness0 returns the union data inside the Fuzziness as a Fuzziness0
func (t Fuzziness) AsFuzziness0() (Fuzziness0, error) {
	var body Fuzziness0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness0 overwrites any union data inside the Fuzziness as the provided Fuzziness0
func (t *Fuzziness) FromFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness0 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness0
func (t *Fuzziness) MergeFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzziness1 returns the union data inside the Fuzziness as a Fuzziness1
func (t Fuzziness) AsFuzziness1() (Fuzziness1, error) {
	var body Fuzziness1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness1 overwrites any union data inside the Fuzziness as the provided Fuzziness1
func (t *Fuzziness) FromFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness1 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness1
func (t *Fuzziness) MergeFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Fuzziness) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Fuzziness) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsGoogleGeneratorConfig returns the union data inside the GeneratorConfig as a GoogleGeneratorConfig
func (t GeneratorConfig) AsGoogleGeneratorConfig() (GoogleGeneratorConfig, error) {
	var body GoogleGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided GoogleGeneratorConfig
func (t *GeneratorConfig) FromGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided GoogleGeneratorConfig
func (t *GeneratorConfig) MergeGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexGeneratorConfig returns the union data inside the GeneratorConfig as a VertexGeneratorConfig
func (t GeneratorConfig) AsVertexGeneratorConfig() (VertexGeneratorConfig, error) {
	var body VertexGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided VertexGeneratorConfig
func (t *GeneratorConfig) FromVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided VertexGeneratorConfig
func (t *GeneratorConfig) MergeVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaGeneratorConfig returns the union data inside the GeneratorConfig as a OllamaGeneratorConfig
func (t GeneratorConfig) AsOllamaGeneratorConfig() (OllamaGeneratorConfig, error) {
	var body OllamaGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OllamaGeneratorConfig
func (t *GeneratorConfig) FromOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OllamaGeneratorConfig
func (t *GeneratorConfig) MergeOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIGeneratorConfig returns the union data inside the GeneratorConfig as a OpenAIGeneratorConfig
func (t GeneratorConfig) AsOpenAIGeneratorConfig() (OpenAIGeneratorConfig, error) {
	var body OpenAIGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) FromOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) MergeOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockGeneratorConfig returns the union data inside the GeneratorConfig as a BedrockGeneratorConfig
func (t GeneratorConfig) AsBedrockGeneratorConfig() (BedrockGeneratorConfig, error) {
	var body BedrockGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided BedrockGeneratorConfig
func (t *GeneratorConfig) FromBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided BedrockGeneratorConfig
func (t *GeneratorConfig) MergeBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAnthropicGeneratorConfig returns the union data inside the GeneratorConfig as a AnthropicGeneratorConfig
func (t GeneratorConfig) AsAnthropicGeneratorConfig() (AnthropicGeneratorConfig, error) {
	var body AnthropicGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAnthropicGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) FromAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAnthropicGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) MergeAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereGeneratorConfig returns the union data inside the GeneratorConfig as a CohereGeneratorConfig
func (t GeneratorConfig) AsCohereGeneratorConfig() (CohereGeneratorConfig, error) {
	var body CohereGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided CohereGeneratorConfig
func (t *GeneratorConfig) FromCohereGeneratorConfig(v CohereGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided CohereGeneratorConfig
func (t *GeneratorConfig) MergeCohereGeneratorConfig(v CohereGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t GeneratorConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *GeneratorConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Config returns the union data inside the IndexConfig as a BleveIndexV2Config
func (t IndexConfig) AsBleveIndexV2Config() (BleveIndexV2Config, error) {
	var body BleveIndexV2Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Config overwrites any union data inside the IndexConfig as the provided BleveIndexV2Config
func (t *IndexConfig) FromBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Config performs a merge with any union data inside the IndexConfig, using the provided BleveIndexV2Config
func (t *IndexConfig) MergeBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexConfig returns the union data inside the IndexConfig as a EmbeddingIndexConfig
func (t IndexConfig) AsEmbeddingIndexConfig() (EmbeddingIndexConfig, error) {
	var body EmbeddingIndexConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexConfig overwrites any union data inside the IndexConfig as the provided EmbeddingIndexConfig
func (t *IndexConfig) FromEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexConfig performs a merge with any union data inside the IndexConfig, using the provided EmbeddingIndexConfig
func (t *IndexConfig) MergeEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Config returns the union data inside the IndexConfig as a GraphIndexV0Config
func (t IndexConfig) AsGraphIndexV0Config() (GraphIndexV0Config, error) {
	var body GraphIndexV0Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Config overwrites any union data inside the IndexConfig as the provided GraphIndexV0Config
func (t *IndexConfig) FromGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Config performs a merge with any union data inside the IndexConfig, using the provided GraphIndexV0Config
func (t *IndexConfig) MergeGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["description"], err = json.Marshal(t.Description)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'description': %w", err)
	}

	object["enrichments"], err = json.Marshal(t.Enrichments)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'enrichments': %w", err)
	}

	object["name"], err = json.Marshal(t.Name)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'name': %w", err)
	}

	object["type"], err = json.Marshal(t.Type)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'type': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *IndexConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["description"]; found {
		err = json.Unmarshal(raw, &t.Description)
		if err != nil {
			return fmt.Errorf("error reading 'description': %w", err)
		}
	}

	if raw, found := object["enrichments"]; found {
		err = json.Unmarshal(raw, &t.Enrichments)
		if err != nil {
			return fmt.Errorf("error reading 'enrichments': %w", err)
		}
	}

	if raw, found := object["name"]; found {
		err = json.Unmarshal(raw, &t.Name)
		if err != nil {
			return fmt.Errorf("error reading 'name': %w", err)
		}
	}

	if raw, found := object["type"]; found {
		err = json.Unmarshal(raw, &t.Type)
		if err != nil {
			return fmt.Errorf("error reading 'type': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Stats returns the union data inside the IndexStats as a BleveIndexV2Stats
func (t IndexStats) AsBleveIndexV2Stats() (BleveIndexV2Stats, error) {
	var body BleveIndexV2Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Stats overwrites any union data inside the IndexStats as the provided BleveIndexV2Stats
func (t *IndexStats) FromBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Stats performs a merge with any union data inside the IndexStats, using the provided BleveIndexV2Stats
func (t *IndexStats) MergeBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexStats returns the union data inside the IndexStats as a EmbeddingIndexStats
func (t IndexStats) AsEmbeddingIndexStats() (EmbeddingIndexStats, error) {
	var body EmbeddingIndexStats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexStats overwrites any union data inside the IndexStats as the provided EmbeddingIndexStats
func (t *IndexStats) FromEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexStats performs a merge with any union data inside the IndexStats, using the provided EmbeddingIndexStats
func (t *IndexStats) MergeEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Stats returns the union data inside the IndexStats as a GraphIndexV0Stats
func (t IndexStats) AsGraphIndexV0Stats() (GraphIndexV0Stats, error) {
	var body GraphIndexV0Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Stats overwrites any union data inside the IndexStats as the provided GraphIndexV0Stats
func (t *IndexStats) FromGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Stats performs a merge with any union data inside the IndexStats, using the provided GraphIndexV0Stats
func (t *IndexStats) MergeGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexStats) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *IndexStats) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsTermQuery returns the union data inside the Query as a TermQuery
func (t Query) AsTermQuery() (TermQuery, error) {
	var body TermQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermQuery overwrites any union data inside the Query as the provided TermQuery
func (t *Query) FromTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermQuery performs a merge with any union data inside the Query, using the provided TermQuery
func (t *Query) MergeTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchQuery returns the union data inside the Query as a MatchQuery
func (t Query) AsMatchQuery() (MatchQuery, error) {
	var body MatchQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchQuery overwrites any union data inside the Query as the provided MatchQuery
func (t *Query) FromMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchQuery performs a merge with any union data inside the Query, using the provided MatchQuery
func (t *Query) MergeMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchPhraseQuery returns the union data inside the Query as a MatchPhraseQuery
func (t Query) AsMatchPhraseQuery() (MatchPhraseQuery, error) {
	var body MatchPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchPhraseQuery overwrites any union data inside the Query as the provided MatchPhraseQuery
func (t *Query) FromMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchPhraseQuery performs a merge with any union data inside the Query, using the provided MatchPhraseQuery
func (t *Query) MergeMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPhraseQuery returns the union data inside the Query as a PhraseQuery
func (t Query) AsPhraseQuery() (PhraseQuery, error) {
	var body PhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPhraseQuery overwrites any union data inside the Query as the provided PhraseQuery
func (t *Query) FromPhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePhraseQuery performs a merge with any union data inside the Query, using the provided PhraseQuery
func (t *Query) MergePhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMultiPhraseQuery returns the union data inside the Query as a MultiPhraseQuery
func (t Query) AsMultiPhraseQuery() (MultiPhraseQuery, error) {
	var body MultiPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMultiPhraseQuery overwrites any union data inside the Query as the provided MultiPhraseQuery
func (t *Query) FromMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMultiPhraseQuery performs a merge with any union data inside the Query, using the provided MultiPhraseQuery
func (t *Query) MergeMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzzyQuery returns the union data inside the Query as a FuzzyQuery
func (t Query) AsFuzzyQuery() (FuzzyQuery, error) {
	var body FuzzyQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzzyQuery overwrites any union data inside the Query as the provided FuzzyQuery
func (t *Query) FromFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzzyQuery performs a merge with any union data inside the Query, using the provided FuzzyQuery
func (t *Query) MergeFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPrefixQuery returns the union data inside the Query as a PrefixQuery
func (t Query) AsPrefixQuery() (PrefixQuery, error) {
	var body PrefixQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPrefixQuery overwrites any union data inside the Query as the provided PrefixQuery
func (t *Query) FromPrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePrefixQuery performs a merge with any union data inside the Query, using the provided PrefixQuery
func (t *Query) MergePrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsRegexpQuery returns the union data inside the Query as a RegexpQuery
func (t Query) AsRegexpQuery() (RegexpQuery, error) {
	var body RegexpQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromRegexpQuery overwrites any union data inside the Query as the provided RegexpQuery
func (t *Query) FromRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeRegexpQuery performs a merge with any union data inside the Query, using the provided RegexpQuery
func (t *Query) MergeRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsWildcardQuery returns the union data inside the Query as a WildcardQuery
func (t Query) AsWildcardQuery() (WildcardQuery, error) {
	var body WildcardQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromWildcardQuery overwrites any union data inside the Query as the provided WildcardQuery
func (t *Query) FromWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeWildcardQuery performs a merge with any union data inside the Query, using the provided WildcardQuery
func (t *Query) MergeWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsQueryStringQuery returns the union data inside the Query as a QueryStringQuery
func (t Query) AsQueryStringQuery() (QueryStringQuery, error) {
	var body QueryStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromQueryStringQuery overwrites any union data inside the Query as the provided QueryStringQuery
func (t *Query) FromQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeQueryStringQuery performs a merge with any union data inside the Query, using the provided QueryStringQuery
func (t *Query) MergeQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsNumericRangeQuery returns the union data inside the Query as a NumericRangeQuery
func (t Query) AsNumericRangeQuery() (NumericRangeQuery, error) {
	var body NumericRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromNumericRangeQuery overwrites any union data inside the Query as the provided NumericRangeQuery
func (t *Query) FromNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeNumericRangeQuery performs a merge with any union data inside the Query, using the provided NumericRangeQuery
func (t *Query) MergeNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermRangeQuery returns the union data inside the Query as a TermRangeQuery
func (t Query) AsTermRangeQuery() (TermRangeQuery, error) {
	var body TermRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermRangeQuery overwrites any union data inside the Query as the provided TermRangeQuery
func (t *Query) FromTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermRangeQuery performs a merge with any union data inside the Query, using the provided TermRangeQuery
func (t *Query) MergeTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDateRangeStringQuery returns the union data inside the Query as a DateRangeStringQuery
func (t Query) AsDateRangeStringQuery() (DateRangeStringQuery, error) {
	var body DateRangeStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDateRangeStringQuery overwrites any union data inside the Query as the provided DateRangeStringQuery
func (t *Query) FromDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDateRangeStringQuery performs a merge with any union data inside the Query, using the provided DateRangeStringQuery
func (t *Query) MergeDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBooleanQuery returns the union data inside the Query as a BooleanQuery
func (t Query) AsBooleanQuery() (BooleanQuery, error) {
	var body BooleanQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBooleanQuery overwrites any union data inside the Query as the provided BooleanQuery
func (t *Query) FromBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBooleanQuery performs a merge with any union data inside the Query, using the provided BooleanQuery
func (t *Query) MergeBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsConjunctionQuery returns the union data inside the Query as a ConjunctionQuery
func (t Query) AsConjunctionQuery() (ConjunctionQuery, error) {
	var body ConjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromConjunctionQuery overwrites any union data inside the Query as the provided ConjunctionQuery
func (t *Query) FromConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeConjunctionQuery performs a merge with any union data inside the Query, using the provided ConjunctionQuery
func (t *Query) MergeConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDisjunctionQuery returns the union data inside the Query as a DisjunctionQuery
func (t Query) AsDisjunctionQuery() (DisjunctionQuery, error) {
	var body DisjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDisjunctionQuery overwrites any union data inside the Query as the provided DisjunctionQuery
func (t *Query) FromDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDisjunctionQuery performs a merge with any union data inside the Query, using the provided DisjunctionQuery
func (t *Query) MergeDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchAllQuery returns the union data inside the Query as a MatchAllQuery
func (t Query) AsMatchAllQuery() (MatchAllQuery, error) {
	var body MatchAllQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchAllQuery overwrites any union data inside the Query as the provided MatchAllQuery
func (t *Query) FromMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchAllQuery performs a merge with any union data inside the Query, using the provided MatchAllQuery
func (t *Query) MergeMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchNoneQuery returns the union data inside the Query as a MatchNoneQuery
func (t Query) AsMatchNoneQuery() (MatchNoneQuery, error) {
	var body MatchNoneQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchNoneQuery overwrites any union data inside the Query as the provided MatchNoneQuery
func (t *Query) FromMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchNoneQuery performs a merge with any union data inside the Query, using the provided MatchNoneQuery
func (t *Query) MergeMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDocIdQuery returns the union data inside the Query as a DocIdQuery
func (t Query) AsDocIdQuery() (DocIdQuery, error) {
	var body DocIdQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDocIdQuery overwrites any union data inside the Query as the provided DocIdQuery
func (t *Query) FromDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDocIdQuery performs a merge with any union data inside the Query, using the provided DocIdQuery
func (t *Query) MergeDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBoolFieldQuery returns the union data inside the Query as a BoolFieldQuery
func (t Query) AsBoolFieldQuery() (BoolFieldQuery, error) {
	var body BoolFieldQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBoolFieldQuery overwrites any union data inside the Query as the provided BoolFieldQuery
func (t *Query) FromBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBoolFieldQuery performs a merge with any union data inside the Query, using the provided BoolFieldQuery
func (t *Query) MergeBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsIPRangeQuery returns the union data inside the Query as a IPRangeQuery
func (t Query) AsIPRangeQuery() (IPRangeQuery, error) {
	var body IPRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromIPRangeQuery overwrites any union data inside the Query as the provided IPRangeQuery
func (t *Query) FromIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeIPRangeQuery performs a merge with any union data inside the Query, using the provided IPRangeQuery
func (t *Query) MergeIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingBoxQuery returns the union data inside the Query as a GeoBoundingBoxQuery
func (t Query) AsGeoBoundingBoxQuery() (GeoBoundingBoxQuery, error) {
	var body GeoBoundingBoxQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingBoxQuery overwrites any union data inside the Query as the provided GeoBoundingBoxQuery
func (t *Query) FromGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingBoxQuery performs a merge with any union data inside the Query, using the provided GeoBoundingBoxQuery
func (t *Query) MergeGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoDistanceQuery returns the union data inside the Query as a GeoDistanceQuery
func (t Query) AsGeoDistanceQuery() (GeoDistanceQuery, error) {
	var body GeoDistanceQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoDistanceQuery overwrites any union data inside the Query as the provided GeoDistanceQuery
func (t *Query) FromGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoDistanceQuery performs a merge with any union data inside the Query, using the provided GeoDistanceQuery
func (t *Query) MergeGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingPolygonQuery returns the union data inside the Query as a GeoBoundingPolygonQuery
func (t Query) AsGeoBoundingPolygonQuery() (GeoBoundingPolygonQuery, error) {
	var body GeoBoundingPolygonQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingPolygonQuery overwrites any union data inside the Query as the provided GeoBoundingPolygonQuery
func (t *Query) FromGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingPolygonQuery performs a merge with any union data inside the Query, using the provided GeoBoundingPolygonQuery
func (t *Query) MergeGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoShapeQuery returns the union data inside the Query as a GeoShapeQuery
func (t Query) AsGeoShapeQuery() (GeoShapeQuery, error) {
	var body GeoShapeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoShapeQuery overwrites any union data inside the Query as the provided GeoShapeQuery
func (t *Query) FromGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoShapeQuery performs a merge with any union data inside the Query, using the provided GeoShapeQuery
func (t *Query) MergeGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Query) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Query) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsOllamaRerankerConfig returns the union data inside the RerankerConfig as a OllamaRerankerConfig
func (t RerankerConfig) AsOllamaRerankerConfig() (OllamaRerankerConfig, error) {
	var body OllamaRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaRerankerConfig overwrites any union data inside the RerankerConfig as the provided OllamaRerankerConfig
func (t *RerankerConfig) FromOllamaRerankerConfig(v OllamaRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided OllamaRerankerConfig
func (t *RerankerConfig) MergeOllamaRerankerConfig(v OllamaRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermiteRerankerConfig returns the union data inside the RerankerConfig as a TermiteRerankerConfig
func (t RerankerConfig) AsTermiteRerankerConfig() (TermiteRerankerConfig, error) {
	var body TermiteRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteRerankerConfig overwrites any union data inside the RerankerConfig as the provided TermiteRerankerConfig
func (t *RerankerConfig) FromTermiteRerankerConfig(v TermiteRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided TermiteRerankerConfig
func (t *RerankerConfig) MergeTermiteRerankerConfig(v TermiteRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereRerankerConfig returns the union data inside the RerankerConfig as a CohereRerankerConfig
func (t RerankerConfig) AsCohereRerankerConfig() (CohereRerankerConfig, error) {
	var body CohereRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereRerankerConfig overwrites any union data inside the RerankerConfig as the provided CohereRerankerConfig
func (t *RerankerConfig) FromCohereRerankerConfig(v CohereRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided CohereRerankerConfig
func (t *RerankerConfig) MergeCohereRerankerConfig(v CohereRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexRerankerConfig returns the union data inside the RerankerConfig as a VertexRerankerConfig
func (t RerankerConfig) AsVertexRerankerConfig() (VertexRerankerConfig, error) {
	var body VertexRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexRerankerConfig overwrites any union data inside the RerankerConfig as the provided VertexRerankerConfig
func (t *RerankerConfig) FromVertexRerankerConfig(v VertexRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided VertexRerankerConfig
func (t *RerankerConfig) MergeVertexRerankerConfig(v VertexRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t RerankerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["field"], err = json.Marshal(t.Field)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'field': %w", err)
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	object["template"], err = json.Marshal(t.Template)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'template': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *RerankerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["field"]; found {
		err = json.Unmarshal(raw, &t.Field)
		if err != nil {
			return fmt.Errorf("error reading 'field': %w", err)
		}
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	if raw, found := object["template"]; found {
		err = json.Unmarshal(raw, &t.Template)
		if err != nil {
			return fmt.Errorf("error reading 'template': %w", err)
		}
	}

	return err
}

// RequestEditorFn  is the function signature for the RequestEditor callback function
type RequestEditorFn func(ctx context.Context, req *http.Request) error

// Doer performs HTTP requests.
//
// The standard http.Client implements this interface.
type HttpRequestDoer interface {
	Do(req *http.Request) (*http.Response, error)
}

// Client which conforms to the OpenAPI3 specification for this service.
type Client struct {
	// The endpoint of the server conforming to this interface, with scheme,
	// https://api.deepmap.com for example. This can contain a path relative
	// to the server, such as https://api.deepmap.com/dev-test, and all the
	// paths in the swagger spec will be appended to the server.
	Server string

	// Doer for performing requests, typically a *http.Client with any
	// customized settings, such as certificate chains.
	Client HttpRequestDoer

	// A list of callbacks for modifying requests which are generated before sending over
	// the network.
	RequestEditors []RequestEditorFn
}

// ClientOption allows setting custom parameters during construction
type ClientOption func(*Client) error

// Creates a new Client, with reasonable defaults
func NewClient(server string, opts ...ClientOption) (*Client, error) {
	// create a client with sane default values
	client := Client{
		Server: server,
	}
	// mutate client and add all optional params
	for _, o := range opts {
		if err := o(&client); err != nil {
			return nil, err
		}
	}
	// ensure the server URL always has a trailing slash
	if !strings.HasSuffix(client.Server, "/") {
		client.Server += "/"
	}
	// create httpClient, if not already present
	if client.Client == nil {
		client.Client = &http.Client{}
	}
	return &client, nil
}

// WithHTTPClient allows overriding the default Doer, which is
// automatically created using http.Client. This is useful for tests.
func WithHTTPClient(doer HttpRequestDoer) ClientOption {
	return func(c *Client) error {
		c.Client = doer
		return nil
	}
}

// WithRequestEditorFn allows setting up a callback function, which will be
// called right before sending the request. This can be used to mutate the request.
func WithRequestEditorFn(fn RequestEditorFn) ClientOption {
	return func(c *Client) error {
		c.RequestEditors = append(c.RequestEditors, fn)
		return nil
	}
}

// The interface specification for the client above.
type ClientInterface interface {
	// AnswerAgentWithBody request with any body
	AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// QueryBuilderAgentWithBody request with any body
	QueryBuilderAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	QueryBuilderAgent(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// EvaluateWithBody request with any body
	EvaluateWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Evaluate(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GlobalQueryWithBody request with any body
	GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RagQueryWithBody request with any body
	RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetStatus request
	GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListTables request
	ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropTable request
	DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetTable request
	GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateTableWithBody request with any body
	CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BackupTableWithBody request with any body
	BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BatchWithBody request with any body
	BatchWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Batch(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListIndexes request
	ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropIndex request
	DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetIndex request
	GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateIndexWithBody request with any body
	CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ScanKeysWithBody request with any body
	ScanKeysWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	ScanKeys(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LookupKey request
	LookupKey(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LinearMergeWithBody request with any body
	LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// QueryTableWithBody request with any body
	QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// TableRagQueryWithBody request with any body
	TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RestoreTableWithBody request with any body
	RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateSchemaWithBody request with any body
	UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListUsers request
	ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetCurrentUser request
	GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteUser request
	DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserByName request
	GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateUserWithBody request with any body
	CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateUserPasswordWithBody request with any body
	UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RemovePermissionFromUser request
	RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserPermissions request
	GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// AddPermissionToUserWithBody request with any body
	AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)
}

func (c *Client) AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryBuilderAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryBuilderAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryBuilderAgent(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryBuilderAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) EvaluateWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewEvaluateRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Evaluate(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewEvaluateRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetStatusRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListTablesRequest(c.Server, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BatchWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Batch(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListIndexesRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequestWithBody(c.Server, tableName, indexName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequest(c.Server, tableName, indexName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ScanKeysWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewScanKeysRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ScanKeys(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewScanKeysRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LookupKey(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLookupKeyRequest(c.Server, tableName, key, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListUsersRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetCurrentUserRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteUserRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserByNameRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRemovePermissionFromUserRequest(c.Server, userName, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserPermissionsRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

// NewAnswerAgentRequest calls the generic AnswerAgent builder with application/json body
func NewAnswerAgentRequest(server string, body AnswerAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAnswerAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewAnswerAgentRequestWithBody generates requests for AnswerAgent with any type of body
func NewAnswerAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/answer")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewQueryBuilderAgentRequest calls the generic QueryBuilderAgent builder with application/json body
func NewQueryBuilderAgentRequest(server string, body QueryBuilderAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewQueryBuilderAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewQueryBuilderAgentRequestWithBody generates requests for QueryBuilderAgent with any type of body
func NewQueryBuilderAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/query-builder")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewEvaluateRequest calls the generic Evaluate builder with application/json body
func NewEvaluateRequest(server string, body EvaluateJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewEvaluateRequestWithBody(server, "application/json", bodyReader)
}

// NewEvaluateRequestWithBody generates requests for Evaluate with any type of body
func NewEvaluateRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/eval")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGlobalQueryRequest calls the generic GlobalQuery builder with application/json body
func NewGlobalQueryRequest(server string, body GlobalQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewGlobalQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewGlobalQueryRequestWithBody generates requests for GlobalQuery with any type of body
func NewGlobalQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/query")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRagQueryRequest calls the generic RagQuery builder with application/json body
func NewRagQueryRequest(server string, body RagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRagQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewRagQueryRequestWithBody generates requests for RagQuery with any type of body
func NewRagQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/rag")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetStatusRequest generates requests for GetStatus
func NewGetStatusRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/status")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListTablesRequest generates requests for ListTables
func NewListTablesRequest(server string, params *ListTablesParams) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "prefix", runtime.ParamLocationQuery, params.Prefix); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "pattern", runtime.ParamLocationQuery, params.Pattern); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropTableRequest generates requests for DropTable
func NewDropTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetTableRequest generates requests for GetTable
func NewGetTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateTableRequest calls the generic CreateTable builder with application/json body
func NewCreateTableRequest(server string, tableName string, body CreateTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewCreateTableRequestWithBody generates requests for CreateTable with any type of body
func NewCreateTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBackupTableRequest calls the generic BackupTable builder with application/json body
func NewBackupTableRequest(server string, tableName string, body BackupTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBackupTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBackupTableRequestWithBody generates requests for BackupTable with any type of body
func NewBackupTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/backup", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBatchRequest calls the generic Batch builder with application/json body
func NewBatchRequest(server string, tableName string, body BatchJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBatchRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBatchRequestWithBody generates requests for Batch with any type of body
func NewBatchRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/batch", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListIndexesRequest generates requests for ListIndexes
func NewListIndexesRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropIndexRequest generates requests for DropIndex
func NewDropIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetIndexRequest generates requests for GetIndex
func NewGetIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateIndexRequest calls the generic CreateIndex builder with application/json body
func NewCreateIndexRequest(server string, tableName string, indexName string, body CreateIndexJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateIndexRequestWithBody(server, tableName, indexName, "application/json", bodyReader)
}

// NewCreateIndexRequestWithBody generates requests for CreateIndex with any type of body
func NewCreateIndexRequestWithBody(server string, tableName string, indexName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewScanKeysRequest calls the generic ScanKeys builder with application/json body
func NewScanKeysRequest(server string, tableName string, body ScanKeysJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewScanKeysRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewScanKeysRequestWithBody generates requests for ScanKeys with any type of body
func NewScanKeysRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/lookup", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewLookupKeyRequest generates requests for LookupKey
func NewLookupKeyRequest(server string, tableName string, key string, params *LookupKeyParams) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "key", runtime.ParamLocationPath, key)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/lookup/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "fields", runtime.ParamLocationQuery, params.Fields); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewLinearMergeRequest calls the generic LinearMerge builder with application/json body
func NewLinearMergeRequest(server string, tableName string, body LinearMergeJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewLinearMergeRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewLinearMergeRequestWithBody generates requests for LinearMerge with any type of body
func NewLinearMergeRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/merge", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewQueryTableRequest calls the generic QueryTable builder with application/json body
func NewQueryTableRequest(server string, tableName string, body QueryTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewQueryTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewQueryTableRequestWithBody generates requests for QueryTable with any type of body
func NewQueryTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/query", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewTableRagQueryRequest calls the generic TableRagQuery builder with application/json body
func NewTableRagQueryRequest(server string, tableName string, body TableRagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewTableRagQueryRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewTableRagQueryRequestWithBody generates requests for TableRagQuery with any type of body
func NewTableRagQueryRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/rag", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRestoreTableRequest calls the generic RestoreTable builder with application/json body
func NewRestoreTableRequest(server string, tableName string, body RestoreTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRestoreTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewRestoreTableRequestWithBody generates requests for RestoreTable with any type of body
func NewRestoreTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/restore", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateSchemaRequest calls the generic UpdateSchema builder with application/json body
func NewUpdateSchemaRequest(server string, tableName string, body UpdateSchemaJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateSchemaRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewUpdateSchemaRequestWithBody generates requests for UpdateSchema with any type of body
func NewUpdateSchemaRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/schema", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListUsersRequest generates requests for ListUsers
func NewListUsersRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetCurrentUserRequest generates requests for GetCurrentUser
func NewGetCurrentUserRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/me")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDeleteUserRequest generates requests for DeleteUser
func NewDeleteUserRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserByNameRequest generates requests for GetUserByName
func NewGetUserByNameRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateUserRequest calls the generic CreateUser builder with application/json body
func NewCreateUserRequest(server string, userName UserNamePathParameter, body CreateUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewCreateUserRequestWithBody generates requests for CreateUser with any type of body
func NewCreateUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateUserPasswordRequest calls the generic UpdateUserPassword builder with application/json body
func NewUpdateUserPasswordRequest(server string, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateUserPasswordRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewUpdateUserPasswordRequestWithBody generates requests for UpdateUserPassword with any type of body
func NewUpdateUserPasswordRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/password", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRemovePermissionFromUserRequest generates requests for RemovePermissionFromUser
func NewRemovePermissionFromUserRequest(server string, userName UserNamePathParameter, params *RemovePermissionFromUserParams) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resource", runtime.ParamLocationQuery, params.Resource); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resourceType", runtime.ParamLocationQuery, params.ResourceType); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserPermissionsRequest generates requests for GetUserPermissions
func NewGetUserPermissionsRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewAddPermissionToUserRequest calls the generic AddPermissionToUser builder with application/json body
func NewAddPermissionToUserRequest(server string, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAddPermissionToUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewAddPermissionToUserRequestWithBody generates requests for AddPermissionToUser with any type of body
func NewAddPermissionToUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

func (c *Client) applyEditors(ctx context.Context, req *http.Request, additionalEditors []RequestEditorFn) error {
	for _, r := range c.RequestEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	for _, r := range additionalEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	return nil
}

// ClientWithResponses builds on ClientInterface to offer response payloads
type ClientWithResponses struct {
	ClientInterface
}

// NewClientWithResponses creates a new ClientWithResponses, which wraps
// Client with return type handling
func NewClientWithResponses(server string, opts ...ClientOption) (*ClientWithResponses, error) {
	client, err := NewClient(server, opts...)
	if err != nil {
		return nil, err
	}
	return &ClientWithResponses{client}, nil
}

// WithBaseURL overrides the baseURL.
func WithBaseURL(baseURL string) ClientOption {
	return func(c *Client) error {
		newBaseURL, err := url.Parse(baseURL)
		if err != nil {
			return err
		}
		c.Server = newBaseURL.String()
		return nil
	}
}

// ClientWithResponsesInterface is the interface specification for the client with responses above.
type ClientWithResponsesInterface interface {
	// AnswerAgentWithBodyWithResponse request with any body
	AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	// QueryBuilderAgentWithBodyWithResponse request with any body
	QueryBuilderAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error)

	QueryBuilderAgentWithResponse(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error)

	// EvaluateWithBodyWithResponse request with any body
	EvaluateWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*EvaluateResponse, error)

	EvaluateWithResponse(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*EvaluateResponse, error)

	// GlobalQueryWithBodyWithResponse request with any body
	GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	// RagQueryWithBodyWithResponse request with any body
	RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	// GetStatusWithResponse request
	GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error)

	// ListTablesWithResponse request
	ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error)

	// DropTableWithResponse request
	DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error)

	// GetTableWithResponse request
	GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error)

	// CreateTableWithBodyWithResponse request with any body
	CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	// BackupTableWithBodyWithResponse request with any body
	BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	// BatchWithBodyWithResponse request with any body
	BatchWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchResponse, error)

	BatchWithResponse(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchResponse, error)

	// ListIndexesWithResponse request
	ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error)

	// DropIndexWithResponse request
	DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error)

	// GetIndexWithResponse request
	GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error)

	// CreateIndexWithBodyWithResponse request with any body
	CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	// ScanKeysWithBodyWithResponse request with any body
	ScanKeysWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error)

	ScanKeysWithResponse(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error)

	// LookupKeyWithResponse request
	LookupKeyWithResponse(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error)

	// LinearMergeWithBodyWithResponse request with any body
	LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	// QueryTableWithBodyWithResponse request with any body
	QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	// TableRagQueryWithBodyWithResponse request with any body
	TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	// RestoreTableWithBodyWithResponse request with any body
	RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	// UpdateSchemaWithBodyWithResponse request with any body
	UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	// ListUsersWithResponse request
	ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error)

	// GetCurrentUserWithResponse request
	GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error)

	// DeleteUserWithResponse request
	DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error)

	// GetUserByNameWithResponse request
	GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error)

	// CreateUserWithBodyWithResponse request with any body
	CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	// UpdateUserPasswordWithBodyWithResponse request with any body
	UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	// RemovePermissionFromUserWithResponse request
	RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error)

	// GetUserPermissionsWithResponse request
	GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error)

	// AddPermissionToUserWithBodyWithResponse request with any body
	AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)

	AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)
}

type AnswerAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *AnswerAgentResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AnswerAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AnswerAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type QueryBuilderAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryBuilderResult
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r QueryBuilderAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r QueryBuilderAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type EvaluateResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *EvalResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r EvaluateResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r EvaluateResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GlobalQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GlobalQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GlobalQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetStatusResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ClusterStatus
	JSON401      *Error
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetStatusResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetStatusResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListTablesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]TableStatus
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListTablesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListTablesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *TableStatus
	JSON404      *NotFound
}

// Status returns HTTPResponse.Status
func (r GetTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
}

// Status returns HTTPResponse.Status
func (r CreateTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BackupTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *struct {
		Backup string `json:"backup,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON404 *NotFound
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BackupTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BackupTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BatchResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *struct {
		// Deleted Number of documents successfully deleted
		Deleted int `json:"deleted,omitempty,omitzero"`

		// Failed List of failed operations with error details
		Failed []struct {
			// Error Error message for this failure
			Error string `json:"error,omitempty,omitzero"`

			// Id The document ID that failed
			Id string `json:"id,omitempty,omitzero"`
		} `json:"failed,omitempty,omitzero"`

		// Inserted Number of documents successfully inserted
		Inserted int `json:"inserted,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON404 *NotFound
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BatchResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BatchResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListIndexesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListIndexesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListIndexesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r CreateIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ScanKeysResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ScanKeysResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ScanKeysResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LookupKeyResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *map[string]interface{}
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LookupKeyResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LookupKeyResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LinearMergeResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *LinearMergeResult
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LinearMergeResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LinearMergeResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type QueryTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r QueryTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r QueryTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type TableRagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON404      *NotFound
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r TableRagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r TableRagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RestoreTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON202      *struct {
		Restore string `json:"restore,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r RestoreTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RestoreTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateSchemaResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r UpdateSchemaResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateSchemaResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListUsersResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]struct {
		Username string `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON403 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r ListUsersResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListUsersResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetCurrentUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *struct {
		Permissions []Permission `json:"permissions,omitempty,omitzero"`
		Username    string       `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r GetCurrentUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetCurrentUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserByNameResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *User
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserByNameResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserByNameResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *User
	JSON400      *Error
	JSON409      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateUserPasswordResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateUserPasswordResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateUserPasswordResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RemovePermissionFromUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RemovePermissionFromUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RemovePermissionFromUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserPermissionsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]Permission
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserPermissionsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserPermissionsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type AddPermissionToUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AddPermissionToUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AddPermissionToUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

// AnswerAgentWithBodyWithResponse request with arbitrary body returning *AnswerAgentResponse
func (c *ClientWithResponses) AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

func (c *ClientWithResponses) AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

// QueryBuilderAgentWithBodyWithResponse request with arbitrary body returning *QueryBuilderAgentResponse
func (c *ClientWithResponses) QueryBuilderAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error) {
	rsp, err := c.QueryBuilderAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryBuilderAgentResponse(rsp)
}

func (c *ClientWithResponses) QueryBuilderAgentWithResponse(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error) {
	rsp, err := c.QueryBuilderAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryBuilderAgentResponse(rsp)
}

// EvaluateWithBodyWithResponse request with arbitrary body returning *EvaluateResponse
func (c *ClientWithResponses) EvaluateWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*EvaluateResponse, error) {
	rsp, err := c.EvaluateWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseEvaluateResponse(rsp)
}

func (c *ClientWithResponses) EvaluateWithResponse(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*EvaluateResponse, error) {
	rsp, err := c.Evaluate(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseEvaluateResponse(rsp)
}

// GlobalQueryWithBodyWithResponse request with arbitrary body returning *GlobalQueryResponse
func (c *ClientWithResponses) GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

func (c *ClientWithResponses) GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

// RagQueryWithBodyWithResponse request with arbitrary body returning *RagQueryResponse
func (c *ClientWithResponses) RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

func (c *ClientWithResponses) RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

// GetStatusWithResponse request returning *GetStatusResponse
func (c *ClientWithResponses) GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error) {
	rsp, err := c.GetStatus(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetStatusResponse(rsp)
}

// ListTablesWithResponse request returning *ListTablesResponse
func (c *ClientWithResponses) ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error) {
	rsp, err := c.ListTables(ctx, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListTablesResponse(rsp)
}

// DropTableWithResponse request returning *DropTableResponse
func (c *ClientWithResponses) DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error) {
	rsp, err := c.DropTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropTableResponse(rsp)
}

// GetTableWithResponse request returning *GetTableResponse
func (c *ClientWithResponses) GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error) {
	rsp, err := c.GetTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetTableResponse(rsp)
}

// CreateTableWithBodyWithResponse request with arbitrary body returning *CreateTableResponse
func (c *ClientWithResponses) CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

func (c *ClientWithResponses) CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

// BackupTableWithBodyWithResponse request with arbitrary body returning *BackupTableResponse
func (c *ClientWithResponses) BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

func (c *ClientWithResponses) BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

// BatchWithBodyWithResponse request with arbitrary body returning *BatchResponse
func (c *ClientWithResponses) BatchWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchResponse, error) {
	rsp, err := c.BatchWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchResponse(rsp)
}

func (c *ClientWithResponses) BatchWithResponse(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchResponse, error) {
	rsp, err := c.Batch(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchResponse(rsp)
}

// ListIndexesWithResponse request returning *ListIndexesResponse
func (c *ClientWithResponses) ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error) {
	rsp, err := c.ListIndexes(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListIndexesResponse(rsp)
}

// DropIndexWithResponse request returning *DropIndexResponse
func (c *ClientWithResponses) DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error) {
	rsp, err := c.DropIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropIndexResponse(rsp)
}

// GetIndexWithResponse request returning *GetIndexResponse
func (c *ClientWithResponses) GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error) {
	rsp, err := c.GetIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetIndexResponse(rsp)
}

// CreateIndexWithBodyWithResponse request with arbitrary body returning *CreateIndexResponse
func (c *ClientWithResponses) CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndexWithBody(ctx, tableName, indexName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

func (c *ClientWithResponses) CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndex(ctx, tableName, indexName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

// ScanKeysWithBodyWithResponse request with arbitrary body returning *ScanKeysResponse
func (c *ClientWithResponses) ScanKeysWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error) {
	rsp, err := c.ScanKeysWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseScanKeysResponse(rsp)
}

func (c *ClientWithResponses) ScanKeysWithResponse(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error) {
	rsp, err := c.ScanKeys(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseScanKeysResponse(rsp)
}

// LookupKeyWithResponse request returning *LookupKeyResponse
func (c *ClientWithResponses) LookupKeyWithResponse(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error) {
	rsp, err := c.LookupKey(ctx, tableName, key, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLookupKeyResponse(rsp)
}

// LinearMergeWithBodyWithResponse request with arbitrary body returning *LinearMergeResponse
func (c *ClientWithResponses) LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMergeWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

func (c *ClientWithResponses) LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMerge(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

// QueryTableWithBodyWithResponse request with arbitrary body returning *QueryTableResponse
func (c *ClientWithResponses) QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

func (c *ClientWithResponses) QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

// TableRagQueryWithBodyWithResponse request with arbitrary body returning *TableRagQueryResponse
func (c *ClientWithResponses) TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQueryWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

func (c *ClientWithResponses) TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQuery(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

// RestoreTableWithBodyWithResponse request with arbitrary body returning *RestoreTableResponse
func (c *ClientWithResponses) RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

func (c *ClientWithResponses) RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

// UpdateSchemaWithBodyWithResponse request with arbitrary body returning *UpdateSchemaResponse
func (c *ClientWithResponses) UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchemaWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

func (c *ClientWithResponses) UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchema(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

// ListUsersWithResponse request returning *ListUsersResponse
func (c *ClientWithResponses) ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error) {
	rsp, err := c.ListUsers(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListUsersResponse(rsp)
}

// GetCurrentUserWithResponse request returning *GetCurrentUserResponse
func (c *ClientWithResponses) GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error) {
	rsp, err := c.GetCurrentUser(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetCurrentUserResponse(rsp)
}

// DeleteUserWithResponse request returning *DeleteUserResponse
func (c *ClientWithResponses) DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error) {
	rsp, err := c.DeleteUser(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteUserResponse(rsp)
}

// GetUserByNameWithResponse request returning *GetUserByNameResponse
func (c *ClientWithResponses) GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error) {
	rsp, err := c.GetUserByName(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserByNameResponse(rsp)
}

// CreateUserWithBodyWithResponse request with arbitrary body returning *CreateUserResponse
func (c *ClientWithResponses) CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

func (c *ClientWithResponses) CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

// UpdateUserPasswordWithBodyWithResponse request with arbitrary body returning *UpdateUserPasswordResponse
func (c *ClientWithResponses) UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPasswordWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

func (c *ClientWithResponses) UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPassword(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

// RemovePermissionFromUserWithResponse request returning *RemovePermissionFromUserResponse
func (c *ClientWithResponses) RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error) {
	rsp, err := c.RemovePermissionFromUser(ctx, userName, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRemovePermissionFromUserResponse(rsp)
}

// GetUserPermissionsWithResponse request returning *GetUserPermissionsResponse
func (c *ClientWithResponses) GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error) {
	rsp, err := c.GetUserPermissions(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserPermissionsResponse(rsp)
}

// AddPermissionToUserWithBodyWithResponse request with arbitrary body returning *AddPermissionToUserResponse
func (c *ClientWithResponses) AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

func (c *ClientWithResponses) AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

// ParseAnswerAgentResponse parses an HTTP response from a AnswerAgentWithResponse call
func ParseAnswerAgentResponse(rsp *http.Response) (*AnswerAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AnswerAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest AnswerAgentResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseQueryBuilderAgentResponse parses an HTTP response from a QueryBuilderAgentWithResponse call
func ParseQueryBuilderAgentResponse(rsp *http.Response) (*QueryBuilderAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &QueryBuilderAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryBuilderResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseEvaluateResponse parses an HTTP response from a EvaluateWithResponse call
func ParseEvaluateResponse(rsp *http.Response) (*EvaluateResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &EvaluateResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest EvalResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGlobalQueryResponse parses an HTTP response from a GlobalQueryWithResponse call
func ParseGlobalQueryResponse(rsp *http.Response) (*GlobalQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GlobalQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRagQueryResponse parses an HTTP response from a RagQueryWithResponse call
func ParseRagQueryResponse(rsp *http.Response) (*RagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseGetStatusResponse parses an HTTP response from a GetStatusWithResponse call
func ParseGetStatusResponse(rsp *http.Response) (*GetStatusResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetStatusResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ClusterStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListTablesResponse parses an HTTP response from a ListTablesWithResponse call
func ParseListTablesResponse(rsp *http.Response) (*ListTablesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListTablesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropTableResponse parses an HTTP response from a DropTableWithResponse call
func ParseDropTableResponse(rsp *http.Response) (*DropTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetTableResponse parses an HTTP response from a GetTableWithResponse call
func ParseGetTableResponse(rsp *http.Response) (*GetTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	}

	return response, nil
}

// ParseCreateTableResponse parses an HTTP response from a CreateTableWithResponse call
func ParseCreateTableResponse(rsp *http.Response) (*CreateTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	}

	return response, nil
}

// ParseBackupTableResponse parses an HTTP response from a BackupTableWithResponse call
func ParseBackupTableResponse(rsp *http.Response) (*BackupTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BackupTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest struct {
			Backup string `json:"backup,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseBatchResponse parses an HTTP response from a BatchWithResponse call
func ParseBatchResponse(rsp *http.Response) (*BatchResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BatchResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest struct {
			// Deleted Number of documents successfully deleted
			Deleted int `json:"deleted,omitempty,omitzero"`

			// Failed List of failed operations with error details
			Failed []struct {
				// Error Error message for this failure
				Error string `json:"error,omitempty,omitzero"`

				// Id The document ID that failed
				Id string `json:"id,omitempty,omitzero"`
			} `json:"failed,omitempty,omitzero"`

			// Inserted Number of documents successfully inserted
			Inserted int `json:"inserted,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListIndexesResponse parses an HTTP response from a ListIndexesWithResponse call
func ParseListIndexesResponse(rsp *http.Response) (*ListIndexesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListIndexesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropIndexResponse parses an HTTP response from a DropIndexWithResponse call
func ParseDropIndexResponse(rsp *http.Response) (*DropIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetIndexResponse parses an HTTP response from a GetIndexWithResponse call
func ParseGetIndexResponse(rsp *http.Response) (*GetIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateIndexResponse parses an HTTP response from a CreateIndexWithResponse call
func ParseCreateIndexResponse(rsp *http.Response) (*CreateIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseScanKeysResponse parses an HTTP response from a ScanKeysWithResponse call
func ParseScanKeysResponse(rsp *http.Response) (*ScanKeysResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ScanKeysResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLookupKeyResponse parses an HTTP response from a LookupKeyWithResponse call
func ParseLookupKeyResponse(rsp *http.Response) (*LookupKeyResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LookupKeyResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest map[string]interface{}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLinearMergeResponse parses an HTTP response from a LinearMergeWithResponse call
func ParseLinearMergeResponse(rsp *http.Response) (*LinearMergeResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LinearMergeResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest LinearMergeResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseQueryTableResponse parses an HTTP response from a QueryTableWithResponse call
func ParseQueryTableResponse(rsp *http.Response) (*QueryTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &QueryTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseTableRagQueryResponse parses an HTTP response from a TableRagQueryWithResponse call
func ParseTableRagQueryResponse(rsp *http.Response) (*TableRagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &TableRagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseRestoreTableResponse parses an HTTP response from a RestoreTableWithResponse call
func ParseRestoreTableResponse(rsp *http.Response) (*RestoreTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RestoreTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest struct {
			Restore string `json:"restore,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateSchemaResponse parses an HTTP response from a UpdateSchemaWithResponse call
func ParseUpdateSchemaResponse(rsp *http.Response) (*UpdateSchemaResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateSchemaResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListUsersResponse parses an HTTP response from a ListUsersWithResponse call
func ParseListUsersResponse(rsp *http.Response) (*ListUsersResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListUsersResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []struct {
			Username string `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 403:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON403 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetCurrentUserResponse parses an HTTP response from a GetCurrentUserWithResponse call
func ParseGetCurrentUserResponse(rsp *http.Response) (*GetCurrentUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetCurrentUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest struct {
			Permissions []Permission `json:"permissions,omitempty,omitzero"`
			Username    string       `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteUserResponse parses an HTTP response from a DeleteUserWithResponse call
func ParseDeleteUserResponse(rsp *http.Response) (*DeleteUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserByNameResponse parses an HTTP response from a GetUserByNameWithResponse call
func ParseGetUserByNameResponse(rsp *http.Response) (*GetUserByNameResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserByNameResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateUserResponse parses an HTTP response from a CreateUserWithResponse call
func ParseCreateUserResponse(rsp *http.Response) (*CreateUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 409:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON409 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateUserPasswordResponse parses an HTTP response from a UpdateUserPasswordWithResponse call
func ParseUpdateUserPasswordResponse(rsp *http.Response) (*UpdateUserPasswordResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateUserPasswordResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRemovePermissionFromUserResponse parses an HTTP response from a RemovePermissionFromUserWithResponse call
func ParseRemovePermissionFromUserResponse(rsp *http.Response) (*RemovePermissionFromUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RemovePermissionFromUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserPermissionsResponse parses an HTTP response from a GetUserPermissionsWithResponse call
func ParseGetUserPermissionsResponse(rsp *http.Response) (*GetUserPermissionsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserPermissionsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []Permission
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseAddPermissionToUserResponse parses an HTTP response from a AddPermissionToUserWithResponse call
func ParseAddPermissionToUserResponse(rsp *http.Response) (*AddPermissionToUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AddPermissionToUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// Base64 encoded, gzipped, json marshaled Swagger object
var swaggerSpec = []string{

	"H4sIAAAAAAAC/+y9+3IjubE3+CpYjk+0pCWpW/fY5saErb7rTF90pB7PnjA7KLAKJDGqAmoAlCSOQvsM",
	"+yL7UvskXyATQKEuFKlLz7HjG//habFwTSQSiUTmL296icwLKZgwuje66RVU0ZwZpuCvnzRTn2jOTqhZ",
	"nPgv9kPKdKJ4YbgUvVHvy4KRUjMlaM6GvX6P2x8Laha9fs/+1hv1StdSr99T7NeSK5b2RkaVrN/TyYLl",
	"1LbKrmleZLb4L3IhUmlLm2Vhf9BGcTHv3d7e2gZ0IYVmMMSXND1lv5ZMG/tXIoVhAv5JiyLjCbVD3P1F",
	"23HeRF39SbFZb9T7brea/i5+1btvlJIKu6rP8yVNiXKd3fZ7x8LYOWdnTF0yhbW++Rh8p0RDr4RhwX7v",
	"kzRvZSnSbz+EU6ZlqRJGhDRkBn3aQq6ebfZI0GzpFqhQsmDKcPdXAv26VZ1KmTEq7PCNFqzry21gATn9",
	"hSWm1+9dD+ZyYH8c6AteDCSMi2aDQnIB/DmjmWa3/TCMU6bLzKwcDDcsh79nUuXU9Ea9WSapqZhPlPmU",
	"qbhnX+b7571qgFQpuozn8sQNP44U+oqpozkTJtoudXIkC8pFe3e/ZjNaZobAZyJnZM4EU9RIpclMKkKz",
	"jBS8YBkXjGjDCk1KkTGtibxkSvE0ZYJwQc7h2/lwLN7QZEEyLi5IQgXRBUv4bEkUM2pJEilmfF4q4FhC",
	"RUqo/S3l8Lftz6glF3NiFowIdm2q4QzH4mNpSpplS8Kuk6zU/JKRK24W5Fko9GxI3nCzYCr+jUhFnsH8",
	"npG81IZMGSmUvOQpS4djYUWaX8q7dswr28IHLi66mIJd0mztlruk2SsggK0Rxreu2jtfsKqb0+sJSIFr",
	"MzHyggndXtiP9JrnZU6MNDQjWMquprxiKVDarghnlywlqUzKnAlDXJvDsfh5wQTRzPTDR02osnQrBUvJ",
	"lm1Gm4Gi4sI2x5U228RIMuMG1oQLYhZck2mZzplt8CfNZmUGHTOhSyvvyYcPH32XJOM5d31YwcOuE8Zw",
	"fX7STJOXb06/4CT4b0xhM9rwHBgJFzGcL/t79n/9Xs6FpUBvtB/Wy+6bOQOJ+mvJlNsadcId2TW1O8GW",
	"WPojQdvZsWuWlIYNiT0T8TMM/opnmeUqo6jQVhw4EmuWU2F4QjSjKlmMheX4QhZlRg1LCRdGAqf7chMs",
	"R2acZakdArN7CToaxjP8502Pi5Rd2+H/s8fyKUtTLuYTnl73vvZ7QEtLh37P0CkcuYWSaZkY3bvtb1T3",
	"RVVVsUvOrnTv9uuGG+W/7HhPq5M05+IY6+23Nw5Mrr0IVjd5pomgplQ0IxkV85LOA9GlpXaSUa35jLMU",
	"JAnP7aZmaUyo3s8LaoCpLJmnTBsyp7nlvYwWRoIwS5kifzrY29v7W1shAXXEHsW1bQYSszd6DlzWUJZw",
	"nxlJXEXkg6U2LLdCJy9Mn1AQ1160cSn6MAEJgsuK1QWjlvPPyqlRNLGsMlMyJ+1tbztKrdqWW/FMLynP",
	"7KqFXRW2nxPzUMGOm/BZV3Nc203f2E/P67tpr2s3gfRfxxjRMXUG5W/7PSssJtooBstSoy8qkHX6vhEw",
	"v7OzNyRUshtFgRKgyZZnisQR1m3zvi/hqb9NuNCGUdhm/3n2+RPximfFBbGaUum1/3Q8W4mQr82ju3kk",
	"ewWFZtnnGWzf9WRytex+bcgn5B5qm3azwmOwOfW2gNfIaI7xYN/YtoZjMRZWpNVbmARxhse15RXKhSaF",
	"YgPXOM2IYlRLYddhi88IgwVKySWnYwFcMay3OoQVD5W2rTDlOmqFa0JLI22nCZz2BdWapcTIsbC7uLV7",
	"QC2BfWZHyEXJDchvs5DlfOG4uaEM3TXRtYpArfKXWt2waqARTFRY+nWKQVURuMvV7DieTh2ng0SA88Gd",
	"SinxfHkfKe17XaOM3n6t8/SZ3+/1wZ0wNYDVqCt6oNhVS4es67XKIQGNEatRQRb0ko2FVQbklaj0P7Jl",
	"F7itpW4DS9vaA9Q1eUJQU9bDsTieEYpNcw2KhR8YS/uEG3ux1TA0I4tBxi5ZFvVINXHCqIuHcDKbyTxL",
	"rkp9q3Pf/dit0ZL9V8pEwta2EkrWW5hJqxKWxbr6b125uPbtSrn3qjauOo9U34jd2FqD6ulZpCmbVpB9",
	"ktzRw+dLpuy9pSpDQB8NDLi1N9yzJ+H+cG97SF5JoXnKlCZTaRaETnlmJYiRvjhsNX9jsCIXLsg6kqUZ",
	"uRDyKmPpHEwkrRthjso4aEAdB6m7KeKCwnmsWMYuaefsTv0nlHGsa2ROrwQVzG7AeMKPGF/jHGwvRdcE",
	"Vp+O1cHYJeKQ7G1pD2edvwvHa2yXA9l5UBZh7vqOjVvv9l2D9SzT5FRdpFYOOZI1NcQNLulWjbntPznf",
	"PnwZNx/zvzQ3bj4NL+MmFU+05nFWzudMg6rdyULhTG3dEGon56aD6txJd2yVSOx2C9RVZ21DTXLaFpyI",
	"XtTiATjjgmb2hlqJvA4FkpTam2cqjY3qyHJwh8C2JTqGX2ojczIveQp8BFYnHIWRgvXtBYfyjMDp3Hen",
	"/TJjtXveS7jzJFyjGDAsWQirPg7JsUiyMrWfU0ZcBU2uFkzZKQDzmmHXzW+FwexVh6HMMrha2s0qVcrU",
	"kGxiqXoSu9NjrEh4K53grXTlutTurvHiVJzVYcjvZGQzy5avFqW4YOp+vJzJhGYEGyCJbcGynZM0/vrC",
	"dfiFqFLoqmDKFUtMtqwsU4xoIxWdMyIsWxRKJkzr/ljYErI0BDcnMLcg7NpZ5b/Yi7ZhYJ3nCRuSY6dB",
	"am7Zisz4NUsHmv/GxiIYqwZTaq8vYTTACEKShCYLuL1WF/6x2Nn5STM0nV0tmBjt7IzFgJyWAjaa3XsZ",
	"G8CYU1ZkcombcktfUZWTXKZs25b/b1mSVIpnhgjGUhKMPLswiNAzTZTUGkigfbUrKgwBoQuvEKa0uryd",
	"3DU3y2qEnhL+Et0x2LzMDMex2j1grIKF2873r1ha2vMhkdqEAcCIP3/69H8PaJKwzJ3IgXp2jll9tAVT",
	"mmsDBkxbbDfMF3qyc4tlxQ2aT21J3Ru92Ov37ApktAg2HvubZyW72YDvev2eZgV1m61nSWH5nqo5M1HN",
	"vdum/JuVWTbxoo+maOum2UlUqMvS0d4JtqEBmHXAgOcsHzgRK3teWgnpbbeFYtpSZItdMkHsxTwvzHK7",
	"78t7k6XdByxFphwlMzMiupzN+DWa1MBQmIbGn2niCIcmSt8Zndq+QtulZmSU1FqiihEpsqX9hrbRS5bY",
	"O1ZYK3tbg02MEoOATQBMaKmbvSltI3i1Ixm/YGQqpTZczPvOYprTooA/mUkaRqybLpEUM0JkeHrRMut5",
	"YzqqHhHZjQzHqOXDcFAOyYmylDcaTNkajoDAxHJGLplaksxyT3W42iPhbqN1k1PvHPSnMNjKWOgaIFNm",
	"rhgDm45mSWnC8PSQvGdZoUlOOZh7gi3RSQsUIVNZipQqzuqD7rYNVtsmGq/fQQ01zJcleJSg+bTIuDFg",
	"YWLD+bBPno3HYjwWz+CrrTBXtFjo7c5zvLFFayRr22+hcLTOjnR2bWHmQ+JOMNxBlOdoeUJ2oMrSBeW3",
	"PQbWrejqc/IL/HzTY8JW/WcPXwYmVE+WspxApX7vgi2vpErtrK186fcWJs96fashM8UTS11qmOHwMu+t",
	"mf1eZpUJqztIUErxn3pBoc2wIW2VTE4jpbSi6ZEwCyULnjTVig0P9FA/aBGXjBwdVwf41quMWq0Nxf02",
	"nI1HJ8fkgi3JJafknBZ8csGW5/6tRJHzo09f3p9+Pjl+NTk6OZ78+Oa/zwkTl1xJARaGS6o4nWbMnbNv",
	"UDKQj9DDaGeHJNDlQEshmBk8H7wYHOwdvNj768FfyZbjGSs/sZQsSh3K7O/v7Ycvh4MXgwXlF6X99Hx/",
	"7+AAO3wtE+hmYUyhR7u7qUz0kHpCDBOZ7zIBv+7SqSzNANvbRRLs2p17ydlV12Hmefv53l+/7/egQm/U",
	"Wz2fXvN8wzEAH+WFXY9Ssd5ob/jn1mnm6N7tJlItq1urITmegdnN3wr7ZEazTJMpTS6sPGqtWfeSde3r",
	"eOI3a+V1JQKDvHaaoLf7R51EwssRMxZcd9K1TRR7bCMfk+PX/pZcUQq/GAmnppdvq7t4Vn1tseCz7dor",
	"4d0DbcvJeOk7trFRMtNEUZHKXDANKkd0u7SX+gEa1N7z+YIpckmzktmD5IIRWZqiNCSX9tYFTTzOTmZk",
	"MbnoYEJZDC6ItgSAG4L3ahqSz1b50Ljl4XLrjL7kx6BSwKMymKLLqWa/lpYDgW26OcMOoWgP4VOZZKzU",
	"HYOISXSUwZUC5J69PVa0fxxdSpV1b82fTj+0ec/uUiZSOAXIljdV9PFO4xje6o52BzvjOku3ayMsFe+8",
	"/sXWDdxDXcaNlzS5KIuVPitT+DzhaccDseC/lozwlAljh6Xc2cJRtpTFkPyEr0ZEsRlTYE2DR2D46jwg",
	"QPslsnBMbHXQVwspNSOU5Izae8yszIigua1MreYN1gRN7MG6e2lvHlIQLsIDUEPtdFOAjTfY2x/svxhc",
	"HnTtPnvF9a8BDZXI3VR9iXCI+nmelUUhldF447IMbr8wkeqRvSd9gMvzjGcMr/Ijcm7/GO3u7hbULHaN",
	"3MWWzm3po5z+JgU5OxyRc3042t2dlskFMwNLgnZ5fDZ0JA20oVlGwHvAUon23TXCPT7mzFD7c5hGYCys",
	"0yQgDCJf4jB28S42wB71bqmZ0gOot1uReC1DVnwVEb6bP02yiNiz6TFokoW9AjNl+iRlGTMMJxkeFCPe",
	"svKSuiu89ypxusiRkTlPuFnu7MCS7eycYTG9oCrd2RmRz1Uz9ipFoYK3Z0CpSCXHJj56boDP2rYCrjQp",
	"t1SZwovhwaBYUM3sFT/nhmwdnLzaRhsPdgAq/wDbv1Lc2LbtgN/Lq1o7MF+a4ACvpLqAiewPyUe/2s6h",
	"kWZAb6bJ+w+viNVMtaF5gVY9lrHEaJJIqVIu8BZgux6LgyF5Ff2KQ4l7JYolUqV9K20NT3hB7dULyhEO",
	"7pJ6LA6H5GhmcBT+V6LLJGFWMYm7RXrUehiL50NyErfufJWcB4peimShpJClzpbOAURml1H3L4bklCUS",
	"b35SFugIxbRrJHHri+YWwwjc3CkMOB7bjPKsVAwX4oQpED0iYY53kHPcmk0thzI9IuNyb+8wIS9yTTJq",
	"mEiWtuyraHnjJRyR/+dgr170GGaBkyptodDm4R7RLJEihZXXZpBYjtqyWrqKp7uNI35XUkWFYUy7AR9l",
	"mV9QtxbE+R3amZIt6jeHv4HaT8jTYOx61aYNGg+gbxBDW4JdkYxRMA0yXeZNokNDxynLC9mYJtlKS/Sx",
	"ZY11ssuv6Yy5eb1kgs248bM6dbYtwYzdD8HKB8tLFZ5MXKT8kqcleFGgm5mt+9EeSmw24wm3gwnWnq2y",
	"SGHv2K5xaVMY+ZH3l7hjUy6YiIWRLqgTHNqLcRRk2HpZ4L8HhF1zsLFYdR6/2anYBTNM9ImlbPiSKEaN",
	"d6qM7igoGsHhzErs0Z//YjVQ+KfM0glNElkKYyWwG4OtBJ/3Dw7h1jFnvdHhnr2dUp45F/K/ux7s1any",
	"Rf9PuRDkNXqX0zn0mYAl270ls5yXee/rrev/+YvvQwcHL6IOqGArOqCCkbOcgwN8q4uv4FJdV2PC9Fe6",
	"GgYPzOPXzqfL1hiS1zXnS8VyeemdwVCGwcEKp8gnaRge+J+kGMCq2QbD2mieMWGyJeFzIRVLbcnXtpvA",
	"zM4KzlIyZTPLgp4hvMncakHAdrbuj77hgln5g23XRuhN7JUlsWGJXc8Nmz263db4ptvE2vJ79hR35kYw",
	"gFI15UZRtUSrgr27GDRVL2WpnE6DLyrRnaBSF5qX0KJzbes9a+f/csGWVmxZQpcrdNvKVAgr/pJpe7G2",
	"OzxxS/8TnOVCV4tvdVd4OrCjZtrfMMdhe4179i841zJmt8O4t+3Wl2RMzC1ZZjM4mOMFLaqDhwzIBWOF",
	"HWDuXgXp1N62FlKZGqtoqaxgytg1TyTY7NDFq0+0JAkq3oViM34Nj5LUEI26rb0zzi3pqWhZ8/9t5UQH",
	"A1klYgIPneve886WIvkABW07Xt28S8Z06qSWsbgYFBlNKu4i/pzBx96PUszl65cDeHV1laVCqfOlq1Hw",
	"MrdbxrJ7LlM+W0YvyNUTG00H+HWAipqino+b6m5RZKBkgSoAD6vSySRQK+HQ9OpuNJDYIl9ryCrNcMNP",
	"GOhM/gblDKdxG1t/4iLpkz/lZbbdJxSpGX8uSr3okz8VZQYF7BVHonr2Sua5FGDYsToRTu1YJIo5b/tS",
	"wKvYFjhY9+FNQ/fJpZXksAd/gnWo1GTbXVIqxYR5TQ2+9X2kAvakHZgmWzRNd1EKE8tzfQIyNG5NODcH",
	"lHB+Nfyh7l/3rehRFUs0BPdND2yAQWzY7dfvVWSBIrLojXqWenY/UbOwfw3Rl7zfA+NQb7R/2/cFo4nF",
	"FTKqzT84u2IpOCH6nsOmXNGtXZW4GdiAodveJS9sc5u6tAc238RVst97yVIlk4s3YEq/72P30c9nxDVQ",
	"vY7VH7vhHmfLJYrBIUEz7xAaWU+lIsdHH4mSmVMROo3ecsEUG0JHAybmGdeLweXzPqFgCBgabqgY4GfD",
	"rs3g8mC0d5dB+0oPXdVE5rtTnMiuvUloA/f1ecmDVXvg5DtLh+7pIrZsezt29xDrRmzXEUQgzpG8pR4w",
	"qs1gv9fSyECLmWj+G6uZdve77LdQFl5z0EIYliSODJGF4bktYhZKlvNFUZq19uRmR37Rg624aRTupsOz",
	"Pnl212K1rMIrydkR/DDvNEl9cWyK3wPn+gk494gw8LAQzaFUK9TRuf1XMRHsapJxweovdxD41lysnxcM",
	"IiiMhMfDAu4mULey+HJRlAaDdpySG9ZzuN7x/w5DJk79oc9h0ZbvfhCD/XuCf2hCE6uou9OV+b0f7Lp9",
	"MLv0nS2vT17BivfJR3s5pFkUbbJaLkQPUytfEQaX+6O9Plj0hllGc3o4OBz8eW864EIbVSbGFXDcKeQl",
	"HRRKwq/fSoR0OKA99qHoyTfyxrRt7peNKz79Zh5+0yej3/Ut6Glec4ZP50d9h1ixd4Fje3f+x0ElUhrs",
	"zfKJFFnHk2wkEC375SyXajkANxx3lWuLvHs4sN452jNDTUeEeMr1xaTUcI1qPXTY89O9UYG9wLLLdGmY",
	"rj04cWG+f95ew83dgZmP5W+EltmfSc60HR3hM6LtFKyWnqXwAjZllUfsIxzBFZuWPEtDtFvnilUk0MQp",
	"xmBeCVUfvHCW1Q3NJs63q4vlvSis7mzOAgR1nnIxOrlIyuytvZz8lw8NbehuUmbdKAPgDrZOlX8JhW77",
	"PbgAdRiXmm9FtruvK8bJqFg9ynuNJTPrY4mwK3v2lOvbfiXFL6UA62+t3kTItXVfc92qqxd2I9y/5ool",
	"9u9pqzTvIwIylYs5sow/oUv3qJuyRDGqGQEDhvs3unP4gASdSMW0ZWRaxVAH1k1lOQUnclFmGYY6oxtm",
	"63x5uTTslIr5CtQHK6FW+Ke4sOeDOAb6oG28BA/vVx4Goe5sIsUE5VWHf+gmsAl264InOxgfaHZFl3pE",
	"juC/4LQOxRWbU5UirMOMyNIkMgfLiO9+RL74sgDcsERoksoxyhU2PGeyNLXizlqDX7CedsWtejWBkPOO",
	"GuCkAx9DJasNOYc4nIq9/lcUqgaAf1TNd3qxVZ71bauZf6gFIAt4ua1IilGI9TgkxLewinXAs2hHncZL",
	"vNblv2KIR/r5w9DW1Tu1haLAvlgEVp13ycGWR38V5SwF2yDe2fmS19u57a+Lq2xHE6B9qIECE0wE60gO",
	"LZ344k0ahHbAaNRkllLgK3A77JV2xCt0mzkgeKC31hvdILW6fc+r5TiJ5t3W91tjcjriMNpgOZpTqv6c",
	"H3znTloVo7rhBbgeEduKVKKCZsvfXKASiPL+WHh3AfsbmF/cLsSodHvTNWy+rEe86wqSox7zrTujxP8d",
	"IoBmUiVsEhBELDetfTtwheGEtlf+qB1Hto1UkTNf+LFwNmVm+KRYKKrZBB//4jPwcLVjO43c6BAaBFrh",
	"Yl67wdduZmuRYeoABevtTj7CbBUsArsuMsrhnzhGYGfNtYtlQyI695daONVqnKzWnuuEIWixLixbc7fV",
	"HJao86aBCNxE5lMcOM0yN3gmFla78vcCO3V4X2xNw/n0uO3mDKR01cG4Oly8PtgoNvb3DiP1ADOTFZg1",
	"rzKq8BhASuGTcpriuQA2x87wObK1KHMqBorR1Cqi24+4XMZbqesxMNov1U5xd24cNdi4rwsqMIbXszM6",
	"04DF4IlDYe05W9trNUCJJ9pTZAu0Sh8VBd4wsM8bSCA1GBKHZfKY9VCyNAzDNdYpYLYkRH1AyMxjxXlo",
	"YQWzfnYPFmm07BiStdtArQKABHAnwAfglBVMpNpq6LVhjogLR8FX5WeKwavusz5ZLAtpFgzwXAKmgi0S",
	"f3j2CCpbJWEypcnFqtm+VBKcv2yZOcboVNP2m7ODRQIjcU2ehV6ebT9qrA88YXU5vSuA/TWDRuz1WJfT",
	"QSi5dlqprwjT+rZx7tF2aMnTFs82t0FEuxrySeelBCNO3zOamcVqpIUFfAdLXxnkoItWjVThUlwIeWXP",
	"LaxgB1CK6t8pmyuaIvQYXEW7dWRo9gz6WhcL2gi6Kc1i4qRRezLHIuXoU3vlzIe2PLOEw/OlEmWRwu3n",
	"2GFGlDk3vzElK4DJRaDj3Ug1MdHtaYTG1G7pA9dmb27FewgEa0O0vyYQAwVjrS3SWt9uN9ROpoB3sIe9",
	"ymPdVQ/y60LTXn1+/+b0zQPj0hovtYfDvWB26ZP9vYPnJOW53u67gqACZFzMS5pB6Tue2txbcCLz3RAl",
	"geHT9TsqPJtOPOExFNFbh3tVxFl7pPVHeuyud7+gMkf5EFH2igpCMw0QgJoZoHmdvpvHkMXziq1u7Sk2",
	"nipczILDjloW8HCBj8uWY2Q4XaP45kigtNt3v3jJ14CIsj/A3rLj7hIuHWFqnYvRJi/EtjjJ12LyODit",
	"/hTZ2Xr7zFClsKKpPrI3n163hvJeXtl+FlSkmXum1ySTYg6vIRTfH3J6je+zzjMxJumnz5/e9Pq9sy9H",
	"p196fejj68MDk5ASD3zOd2RcGdoq8xzdxDaPbX2UAEmww4EaFFmpa8Gs/kv1TzrYO4TH5PuKjWRBzT2C",
	"U2tj6hQTj41GbQqONaGoD5UhM4WehMtJwQTNzLILFg8+IIMA/4ZKT/UI/j8XDdtcyI1EzGrB0mqvRXBU",
	"ZRN2H3r7Ok/mc/BHsOy/e7DsPc+CUwZg1w87ChRU/n3VRuyzW2/c7vvPj9YWsZ3uJ42OIfyLK4QVIsyk",
	"YMoqaJuIU4f+UXM3txxg9ZfqF9Bt6o6Gd4vWbvJtJF8rhlstabubb+twspiIu9xEcqlNgFKLnEYgBtKU",
	"SoSjN4T69t0XDOarxwa4d/suKt1jy3agnW6wZZMubNIheWOlM0beofXq15ICRigV6Vh4oMPK9QB5ssQw",
	"cqB/QjM+RSgrQLRJJKDbGKov/n2fnu4F6ddJWkKLQkmaLDrA/DRTlyjzB+gSMLf/XvD5ogaQOYuAJgPQ",
	"G01TBR6yEexkF2/XbCp3vfE43PGoY7eEHY81j3kMu+1m5rpPzSOdjRLXnq75s2zkeNQKfYi3Y9Vu55aE",
	"2NAvlowr8R5qNF9pM6q/lpColBeCGKgHcYdGk6JUhdSsnoTCy5zoCYzRnCQyy+hUqk4sh580U/YABywF",
	"3FPV9b4r4QMqIx/grurgpjpMEC4Zw+rIxbuWBtwtq6fUzghE9CREEAvp/qp5KgzJMY7C2QlJymdwvhtn",
	"Jk9ogbDI3EUxva1j0TGc/suPBy9CrosB+QdCvMUlKgLxnGdUAaigC97KZUqzWmme0znTu7RMudy1OoO0",
	"2sl/yxKAwmmaVpAXvpqRIWawOYmCGqtH6lZ4cpQEAxwcwU81Z0IDFQ//8tyjYqE7hdduaJYNrH6Z5XWl",
	"RoIvfLxdLoSYXO7hswyYeUI/PiuQxwiEYl1CQJT5BMO17zqKsYQlAoZiBz0UoTXIa2oo4RpREmxtlvqo",
	"elcVwSqlAL0Uoi59jMAZ/80eWe9KngJuu3Z4j2c5nOHUUM2MJlsIC7C/t/ej3WR6e0T2B4ch1HxAPrKU",
	"l3lUwRYd7H/0pQ8H+3tR8Q+IkVdvnlXF9/f+zyiOHULn3VQcL0+ZXXa4WWQZy7jOybQ0ldNgwN8kDvol",
	"kIBdFwyybyCCBf8NZUqLmyx1AAfRSHKUphi/fwaDABqNhYMu1T7OcGdHCsyoBNgLijlcDC7Fzk6IyUvl",
	"lTA8Z0NoNY+mBnCbGE0YEAT8rCFzDo7WLBTTC5mlmmyFDT/NMHAQfQEcxEMghyZpCWICsQlxfIhoOiCf",
	"GASHt+g585gcgwWjl0tAAMkkxSX5yTlmcp/b7Hw3zJedV/hDoMfw+RzfLxyegevfAwCOxuL8/HxK9WIs",
	"Tj6ffSG7E9/s7uV+1C6UC7iwTPxaMnu9pjVS+wguDDUGoFnEiPCR8LoB69GvRjIWEYHw1VmxgL4ADxmW",
	"afxS+pAoGK0qC3e8APhLavVmK+iAFcmbjGrDE5QUbo8drSII2RKS5FQghERAivDHMiz0Z2S1ECYJdTxv",
	"QQlwHimowks8ibLKabIFCAKK5VbzxMAjDkcE5nCK6bldF6yHDUfxzmvPZtnqQG04w6LdOhKIO3tAr1Qu",
	"uOCG02xSyIwnnZgAQcPIuDZ4cEIVgDjgWgfDh3EpETdWo09CAyjLOz2Og15dUK0B17GWNVEfJurQnPxd",
	"66vPgPkYiBvKd6gXPnNjd4ol0An8jAS7wlnZ61qAcXd2wYKaRR/xtdA+YU/gKSMy58YgZAvkVgPEhFCj",
	"Hi6zSQbIhteln1mXRvmaRn7ZDcxdJfP2I/Y9Mup5knXchh/RbmN20MmdM7tv6qCKJG1P2OBYt+ZWHdA3",
	"OjLAhPbPYOZPch3xEKWTgiqNGlbHPS2t+dzbOgOHa9o2yK8I7LC6trsQT1yDK3ZidJWrqmhDldmsUii6",
	"yYC7xFkrjOKxNHbtPfrKBxbV+sx8HMXd5tVqBJ0ML5Pj9ElmytP6HNcgxzRGaWuvGB/cFs/CadXKoglx",
	"xogsr8oEsapnhFbmP+f1co8b71HX3bbWXqcNszpSN0cbPyKXNOMpZkLDWZLUTspHlfhun+lqgh6xm+sQ",
	"lsPFjKkKsUqVmcuTg4eGHau7fzVo3LUL3qRdviNH0EraJ1eMzxcGvSuFc/PzuNbBpNi2rCFG1YSazvA7",
	"PO1YOmfkimqPaFULHFq5le/hpulg8e63SEE/geGFNh6QONb7ooHdrAvYULPvnw+YSKRVAZx5M3DeBVvG",
	"BOkMgLpHOCKEMawdBBb7ZoMILiA1q5+lM3h3BNikBEAQATPJmTAmRjoMpdIspGLpZLoc9x7jIojwO5uy",
	"qL0uOMSeJ+dT3GIrCIMfdzfwyF5xRjzQidBxbeAc12wY7deHbwg7r9dgRG4H4pVtN6BQFHK1pnO0P4F9",
	"AG7nEAn3uTRzCT7LUCC8pwqZwqWaixE5FonMqzIuYZIvMZVmMSIvpVnYFrExBFWLa9Wi43C0XADue80d",
	"7t48YGnyZVmwzV9RKAmZ+JjfQe20QFkmryaaZbNJJmWh16b+jKLZEWAqoifFPC72ADK2yceER+f0ehLz",
	"/aoIVf8M6HMqs2pPPCHvg8LVNZ52jgp86v7m4+m+TVaiEu6UAbPGistnffKsEpYd3tPRBp/ER2Mz1RgW",
	"iSCEEcMqID/H3PZADXDlncxOUJ/6HLGjlberpo+FoVn0Uow8i4+fMYpAZBGBIhvr6aAjbQRK1fZ7vW+g",
	"5jsp51nTf3ZdoOY/mDLs+p6VPoMJ/b6VCiaOju9ZqRuqa12tTk/ix4Sf+qaePv5UrPJZ9l1qb8qpUqPi",
	"25ZheZFhfjhJELiQ/8bIQl7Vk8KPRSLFJQNoR3DP6QJXIl9Ca6Vm5D34eU6p0kQvhaHX+JTun24uqeKy",
	"1GRa8swMuCALlhUVXJFvi5whojkaSXd2zqCpnZ1R3L6bBhhLvTvLInz+RYM/CyIKbWMzrzA/lW2nGjXA",
	"B9byEkNyKUer2LpOvnz5EDxtRuQFybkoPaTfzs4rfDWvt65YwsC9ySeMqGALQ3I9hzPsSfIeSeJeGPaH",
	"ZGdHJ6qcvjd5trNDBuQUYQCRU3YxeMfQOd7H2DWkFieJPR1xzeAkff/l44exIIScn59XVIJfbm5C+2Rh",
	"8gxT+glze+srwH99x5qc41MQDgDfbc6hc//BDsn/bkfm6h+lqSaCXSF2FyJgTzPAw8tc4OFW0Scpv+yT",
	"xf5g8X2fZByTPm2HIaB7CUSJ+ST9ZoF+gJBTCt+PIdWrpd+BpR/7FQj3xrt3IFYz15V3iL+q6ZU0+o7P",
	"yBb71ceUjHs0MfySjXvbt7dH8E8wst7c7PKZo1xV6e8XbGlvFlZ9ohnUOcN/41kX13IPHId24DlLOYWx",
	"v2PiR26vScZl7INPzjOCu3z0efXc6tZw5XSweqmyH+Ax9jU19KfT4zDw6rM9gIdQZlKqrKPAuOd3XwSX",
	"ugs1hr8U83Gvsw7A//s3IpeMwFUqxKpKzfwG7U4c8QixUsMDiEGSjDMEyoVtBax0blWN0TkZELyREn8j",
	"BRXkp9PjAKqLJaGz3V8KNv+/plChPxwOzz1jnlsijHZ3z8ku/lvDHwPyM5va/p1fQfUC5hYIdauUGebQ",
	"6LE1N1PbQDPPAxjg/ZbCXA622NnhANjawCuOh/TdQv3QJ31oEvyCLc+3A8Gq1ygfGXiCD2ZczCu67ewc",
	"w/O9FXSv5ZXIJE3R80tDZMQWn0GyP5aCI3p0ggTChpZOXr/VKDCvjRdd+Ogw40obUtg5KCZSpgCLHz0H",
	"QnUr1Gz1U+8zYurteJzb33iWUVcqSAbkEZaUyooE79vr5+lnFiC0DT4ZT5dh5bSvqxm82WmypRkj9XvT",
	"qXeo3B55Kej0+IXUhlwtuGEZ18Z9PFH80h6AxycoGeF0K3zKubOz07eEGkOTC+0Zzw8UX4YBFEVHp9T+",
	"3t7Hl62yDk0lLni4F5qE9SXBVaLd6MHe878U133g5oFbd89GZ4yNgnspQksMucT8VzU15jtPv8EgARAY",
	"yMSws4Pb8IuEJ/MBeQN/Iu9wQb58/vzJJW0mW1/kBRODz4ozYdfmM0J+f5LGP1uuEH5VF3C/GOJ9I4ic",
	"7s8uNuUjVRdM/QAPP2AQFeaH5+uqpgxoyNQP4954bDrF1c+Qh0bDDP/muBBmyzWheGQlpt/0knKkSJnm",
	"c+G8EAsKW7Yy6DqZZiT58OGjVbYIIcchYkKTnZ3DvcH3e//hnOohf6fzWYjTGoAR+WrBMxayCNpuwHXv",
	"w4eP0Kwtr9jCcQ5NklLRZDkMs/yRLclbBk7ekSx+hbPzOiPu2/PROUzngi0H4EZPCspVUCYAsdkhmeew",
	"KHpEzq268c/vDr+OCOV9fGvv55nXYL7QaZlR5almW7cqtlS58wXxFPO9VOHUtuyHDx9JQZX2hprSCiZt",
	"qEjBcwBqfHSU0bhSTX0EiOBzSsRC9YO8YgqcnyFtqtP00jIB2ttlAXg9SF+kSQal7XhCjdDSW6oNJsSA",
	"Oy029QGBRX14iPOECHXAtSXxGiwZkLfcBSrUnXit0oWBWiATwozQhB2frvFuOSdbUymz7RE4vHznsODB",
	"4gOrCJdsl/vz3K7eeSRsjCpZOGVxw52TLS7M9gjc27yvny5o4jNLOixsh8QfS67QUtiS52QLbQjbIwL4",
	"dCQktkQLhOMZj8Qd2hKQxdrees7drj73FXR1qHoHfgz+8ATySrXhJmN2HkZJt+ksWZyH3ZlzuSOEoBF6",
	"RAB9/rXEM7Cb2eGTt6XgqUMIQw13RA7cD/Zo1SPy/MVeSxK99hnCBDk9ejfa2QlyCF6M3NdoD4VLDR7V",
	"ALMAdcFmyp2rGbQdzsOIV6B1F3qJHifVCTLnZlFOQaU0UooB9gr/drXfSXJsKRy8Pjsr06y4YPqCi925",
	"xMq1C6dbJX/rClkkQGmLaNk4Tb7g8lktFYsMYUGtdH9NTf1LSg18+ELn2n74DsJsqop0rm9vb27ssXF7",
	"2yc3N7u2gK0xFjc30Z3MLZVVfoIu4nQeO/vWIE+QtWyfguY4uMrOMKrd/yIDxMTeBW3hE8UTNiJ/urkp",
	"7L+iIUTunUAo0M7uHEAgT+sG0jGsaDBRp6+q25rjwcqDLO611pm9iOEWur19ubSN+7/C1au6rSXUsLlU",
	"9sbm8kXAje3////+X3KCf3sFOao8lekyGuXOzpsoNuUfLjbF+1aev3vz8fjTcRUBNPBhL7Cf0CBHjo6h",
	"7OeTN5+OVpZF61hc8OXR2ZvJT6cf/NUGrj9V0fiacHRyrLHqhw9HH48m7z+ffbHV0E7nk3vZ+u4q5G45",
	"kLjdKrCj/f3nh89dqqTj3N637O4/UQy6gXxFb4Ivtdtd3tGXQ/kqE1HkdL0FRgsccAV0DXavZTB3bVtt",
	"PEAVjQUkKgmxAlxgdpfqAEO1wsqw80nVlwvMcrhk02UBYQy22FhUJrYoyM9Bl/nMaQ5eJYpScM888Fru",
	"nWwNK3D6+0OCTm0RGCxedtA4t2AYPFEobgsFLRxMGT9DPo1GXE08mRG5IeMemmGg7U80d6aYcW9E/jkc",
	"DvFjqIIfh8PhV3J7Xos5g+Gen5//om3vN1bcjnuwp2xT497HZchjNO718bM3O0CBIEWtVmF79qWiAduS",
	"N3gkjXv5coLEREdqGPHecL9P9oYH9v8O+8QO1Ba/HYt4s/2kGXkFuThwg33kc4W2QXxHEgCL7pOTW4Fr",
	"7/DO17/Nf5hzp8GTPqQWLoHs2nm94qUcalT8X8T838HFOJoQOl7vGNMPFuHqHY9Bzmbg9BkyOc1DEExH",
	"nB7kCgi1B4cDndMsa3i1F0xQDnbplrG6M0yvbXbuABmcs5wL3uv34PZ/3et77/m+77AfpXYIgeGATdiF",
	"gxBkSBwX0X6sQYzEDTEho+iKKiqgOWOniVUl1qHMxREFm7wMVKMI/m31EaBOamQw7caxKQoyEz3cXWVD",
	"iHEuBogyTp4GZbzf02WeU8V/Yw8BFvQvGO1xt98H0DLqxTdybV4YPSRnjJE1DwdoVcWdVqWCrbm8vmdZ",
	"JvuRrddKXDKGPFSgNth/ULOg4uaGgbPozc0nUMOc8vB/EHseUsXIzc2R1YPIktnxyywdPnhtW156nn2/",
	"rnxB9JvrD4T3RwOse43gW8Gr+6EImXb5uzcfp6HY74r1/sYvVJ2HwvpV2+dIOMRpjym1znW8CcQVdXpJ",
	"s82dWThGTzAMAXa+PhgChCiZ9tJ6lILkPT1658IP+hheE/6SihxB6PDRnAlzGrL/ttxiXD9SdazXBxeW",
	"UJWBGOtSbBqG8MZXtIKly7kXsfEmRpXr0b7eQdkvUPS23/uldN6a95TRDlBik6E741GHe8M9vJmidlYE",
	"gDhwi2rBp2xBL7lUrcW6qHsItVxyfkRYD2jv7z/aO7ziiQZDfcKtmP37RZ8oltAss/8SaTL/+8V2Ha12",
	"LVytvYdMQqRX3Udo+KKFXJXYUyoUD3bgXUi2mzKAexYedeoRmCP4cjBxqYHrgL4tQn1x4PANwkOaPqwf",
	"dX24jia3Kzb9ykTeZ4aKlGayvs99dJgdFAabAQipfxurxxMb5u4G1d4MiQ5LgRi6LgvBuBMAtzuS/tQf",
	"R9VlbtcXbvs4VdNtbuw/xMoGYqXfQ+Nrm0TvwpXOYfNYNduBQpCtkATAMkJAq4VEO52+bqsgWRWfc9sM",
	"fN91qcqqjrrd5hx/THhXZPDxa0C1VG0ughffCN/Xyabth3vORSz29XHyeRV69asqM3q0SaFsK67CHeGT",
	"fKXeEzXiS1uBk/Ms45XU6YpYlIptxFhnWDLcYpYbVXJFV0qxs9B/h2TXRKo5FfASNV0GC2WLPpWZ6qHA",
	"A2HTQ79t7IF3lSHMu9O4hCxbM8rNYlZmgmndr1BTnAdPV2LlwKffarSnjY0Qxoqnc5+EIxuP6ZVjXblq",
	"FQc0nPfmc8XmVo7Y2wiH0N840320rVou1AjJPYGxdrSMn3EqK5tsHfGto9xqBnffY+KTY0ENcTVWaSv3",
	"a8zV6EYVMzTbwOm2ahFPtU0VhupQ6yAu5RAFWLWO0U0jNDQ2GUrv7FhmAnFJ4vNw6JGTrATfhrAB5LkR",
	"OXWaIRmQmXu1QWleQS3pSrbbmoFLR+Sk0jFb9aPTwBEZ08tju7Yhy+Mj8snyRgbC5DXXmK84Ja/KvMwQ",
	"mecd5cIWz5UakY+MCjtmXihwRTql4gI+0sJ99BwZxoa0+vDh44DqARz1XeTCD+gU4inkZMaIHGt/Jge6",
	"+BiMv5GtK6kuAKq8fiwTIyW4Y8aiKG4LVwjDn52+9TdbPnFHEJZ/LVmoMSuzCHgI+8caC3zIjJu/Ylk2",
	"qNwuoKCmM2aWcSn7y25k5IdiC5YVHQMuQRV1PSrFEtMsMaOJw4VyBf5GtkrNtIO5wHB/IErC8a+JE9wj",
	"cqRY+FU7bw0YT2TKRa7F3Om4ur1+z/KR1d2VAg2+gPy8bu16IFoC+cG+W1E3mHuxJFIHELjD/KFImKv9",
	"qzHwbhNx/SjoULkh94WLK3FpoMImb2cXfVAo31EoWTU9CFEznWF9TnjenTQwUmpQbiL6S7gddkUrY86D",
	"Dhtp3YMIUi4IGseiBuWrIwa1k7afXH51PJK29gb7249DcGyR6C1NmPkcAmobWiE1bIKgNhsHWMQh9e3k",
	"OytDzV0m+fv25gi0skOfsnqTEwxIUenST0gK1+i9CAL4F5jio32QPwG1Vo/JMJVv3uYXpvKYcl0NerVj",
	"s1WwutDnIlK3Vxg723AF3ZSUcVshRUGhmcIIRStBu7Gv24OTWSavyuJ+KInRI8kMGhiURYDZ00MC6emp",
	"d49iFVjhWNgjglwteLKAl32ESEwWjBZM7c7QIQ1eJf/3AEVsk4/MZFL6LDZLCNSrjOBv4ZsEj4jIkanK",
	"mSBc2F8C6X865PK9smt1LO7Ds2rdF2qxgzTRpfXboy6+LX/7jYNeYQ92sXTxceGs4sIcHnTdSqo9SUsj",
	"Ozbi1y4M15nvrpaNCYFEp4xQQVwPRCqMNZfj3tAPdPlEWWhXCe9ZTIy72qqohkDdM349yRz+4SbEA2G9",
	"PikvlOp62+lA7H9YlGPbpLhJmON9a6H/1L1rgaPIfWu5SMf7VjvyOefvW7E7hcJjgiRDW98gS2d3sgbw",
	"ynpXHSsrIiUxONJ7DHj/MR/c14h9HIvO4EeyLvbRHRjekRHqgDN6TgUv4EYeMOX+NwiQ9Fm7gAT+roMO",
	"dZG+8UfE5DeKmIQ60fsXUMWy0BWbBm9j533mfXiocSaf3zHY8oniLP10rUZ5Du3c3p4jiXVzuCSTc57E",
	"ESsKQJCWxFxJn+gBXjrd1P8I4/wjjPOPMM4/wjj/COP8I4zzjzDOP8I4/wjj/COM848wzt8xjNMOvXZJ",
	"Qe0tmmeYRSt88KXPFmAWTEf7p+/lrZPmTkpe+uvQcoQBmxjeGapBeKPvF6M8hzy9vR3ZstVtEn6PbpP2",
	"axQH+g8Acw3jP34dRZJGXUXt39x8V4rMSo2/Z1QbF1mKP0EIgm/83tGV9s6FquwE7zK3t84qYe/H9Q/h",
	"3gW+lQqdqG05sIb6idoWnfCyPzl7waiiZvRxQHyobI1EoaN2hKq7cFWBqh2LfiRotoQEC1yHaNbWLcvf",
	"oMbCG+7tVMDAP6GK0aj/s8bZDYpFJ0GBLieYhAY6jXSQUjM1caoTaCoHdS0G/fBtfycZ5L6g8TxcZpth",
	"FC73Sua5FKQZNbezY3fMVvBxGRyV8xyVssrta9uq6m9RanQ5IKJZyDsVOPtUvAlt/VdgbKmFMLsE/w5j",
	"2W1b5hrApBavatlzo3E4+VQP1waZ5rJa1PPuYpsVb9iWjiGOlHXkprFC0JkAsSJkW3kbNgfMBy9IXbqa",
	"im81znLFtL2U0cTwJBD/R8aKCJtNw1sQ8a4p12h9IFOWSXtH4SJO50ASBylqVzTJGFX9KpT7kjmUZkFz",
	"jAMJwGMDZy8k7hXXIy/OFU0Yer5smRrA29g/+F6w5Q+/MSXHPXuZ8vkHIesEpN4ItWBNFHOJ6tEUC7Rx",
	"VqSiOjJLzVbnmbW3lSrP7Lwwg+fD/c5Yxo4Es/ETwt3hjSuy+z42xJF6c/tG4Y7vmHwpS9BHX8rrJ3kE",
	"mkpjZD5R3cC//8yk6JOMmq/xY+laMHh4KTzG4gfwUlj9sbkLgZHFJGOz/4lhNd+f/Ega9Op+kgprdCKz",
	"5fyJIP1Xk6nAXiZg+tnc8eEdkye2xlpH70b7K+b8mtubUsKeKn8BNFaPCdvfu8jvlwDCZ6r5n+egMJJo",
	"cisoiavSomBGzYZDzOTGKRu6+j9b0KITh/8dk2Aj0LaAu305eAQwYsDRhE9usVzHyNhmAIxUKRf2IIgW",
	"rvK4cfDsa16FEfk3buvrHVN6x2TOTBdzKpa1HGwgTEHb+2UPnTzspb/X7+E1uVM6a0+4NdsOCdyCOYdf",
	"+9Vg7prLNxYp84hUm0wmkLY5qdBQ52S68IU3TLQcoFDI1js4cLdX4d6uS7rchFy5V9JlPOwjLIW9vf1g",
	"Q+iTw70/H5CU53q7O80y5cM5TGSYsstd1xgtONpTq4D+uvYTsiX3lrJUtvwAsyPEWQz3/nwQaUUdw6yr",
	"SE5ruV9mZr8Id2VmrpN388zMDeyFEEpop9UeSWXNdu40FTM4bI+tP3//lz7Zf3H4PUTnwsoolsg8ZyJl",
	"6XZ3lubVB0g0/1eZLFMSssx5LPRSDxImjKLZ/rPtIQlw5paF0X2EHB33SS2aDHnZUrQ7XXU7afSKpb07",
	"a3RFndXpolc03JGeX9oNPeHpBkRyhcnx60YYXTXxfshmV6fUdidFSpV1d/vT6Qc/24hNQ/bB0DuY+HQw",
	"e/FG5urtWsr5UvG1geirs1R3exrdT+CtuIZ4IbhOUB0MXwxmGdWLODV89K1QMvx9ONyzfz9EcgENdIdL",
	"533ESddyP91+XJUN3l8r12eBr8zt3kNy40zvzdVYu2GjZY93bJhbs8Fn9d8KJaNf3MIiEVobPh7UU232",
	"TmrXLuMdmwAebImiIpU5eEry2CUUks8MDoZ79R3aCik4WBe4LovJRVdMWTG4INrSBjSKOK9hV2BaMSm6",
	"wh+SjJV6RTMPD7Z/oNB7SlGmaLEAWJh/7N3DkdzWmlzuOTCYzjwxLJ2zCUTW3RG57vN+6ACOxlXdzU9v",
	"HMxeT3fTlQGPXk8gScekYGriDZqbSAjM/lGw6Alla4/8QEqBj1Pp9tPCq8SrEuB6WtAHPui0vSJrFmNV",
	"IO5ayJhW+O0rWQpTp1Ccy6U1sX8JgJ+QqGWTlC8OVQfo+61RdWDZP8mUnbEMlN3VCQsX8gpSpkNBAnkr",
	"d12mNUQDCkzhbedtEBS27KDCm+si4wk3IZcuJGiCshsjDGy+ILB9NtmBOKlqxiEbV3jiSz2sz2Ngl2w3",
	"kxnPzHqnZrtOb7EkSFvb9wTKtwMT3RBx/FQlCz9Wf/xTjTOEINlx709VXnlXcNwjAyg5Cwn86y25ipCy",
	"3uMbgSyYWPUjVHeXqMYogJohihGxGcVjsMkeiiIBO+C/umE2XrMko053qjh7ich5LCkNcw60gUS7tdl2",
	"bAF8DemKzOTJwr+VwBOPKZVAMsUZKp98PyDYKZtUnbThApmxY4tzzcS7vbUJ7g/d5wexQk76hzQQ9D6C",
	"CdxiabIANn5c555nO9BcYIaoc2C2MkhdPWXV8Wd7eEwKR1Ds1pvcA5ueYHmoaQxTHReaE/wAsLLaOX7h",
	"L45/G3nP7sxHjjXPDCsewWXIzhOacQg3W8H+7nOT/+uD32J5YZbkB0KzbPtb7Ag42iogvLWrUjs+Q5bS",
	"xzSw3MAWHPjBaqCr7NsRa399ChF5Eni1yXDuchLLBaPoJVOaZvAOX1CzmHF42+pI8DiXiptFvmoDhgIO",
	"bipcXgs6Z4qKC3tFdQl97X3v2WM2ZOhsUm3NzcP1G6QImlw1h0dk4U1ZWuILPVuF1OgCU0I5p8dshdXY",
	"foysTOOMp+vuRlV6VJercNXlDJUawEAO17NvedaBn/zqY8Z+jtFZn4p4F3dh2cCYLHvbTUK2LgZ6IZVh",
	"2gzgy/ZjdEx7DU1ZgZGV3XpvtVmx4CN78zrBBnq21wg7ifyw3lflIvad/175V7tyrn6zXKsPvUfgWCa5",
	"1aLW6wKLn6H4R1v6adTuVRBup44vIDV+pH23YVWoAVV7pRrkCiCOXaxMcFZHsdtAD/po23qECFoptQFJ",
	"Br9uOCIgIVb8BMvx4EGtkIduUCiZPPH8If4QAj6GcEbKDvmJTnx4GQMPaUxiHkePrzGZ9EYAQDp8XQa8",
	"gHvZdtZbdZ7ASPB0GiGO+UmUwS+difDtr4Cw0XlfjpzdnLi3PwkrU6YIMuePPTike/3exaT2C9yo3b3n",
	"EZnKm3unw2UFrFBc1CZSLWUDIqf7cPWOTc7aYe8Vjdvq/Vkh9m9q3KFAMrOUhCJPeb7ExuvNteG3tQS1",
	"W3xGWvYGcDXefoRSvMJo8EoKgZF5aFbdulowQWqWhtD1w/Nn30P763q7DP776IXxcBtCF/v9yJZgTQZ9",
	"NmJBiH3n2rPik6vZtr9Vppw33sS96aDWHSmPWpWGjLSL8CjRWOERd1xk7UcCQI4k+JJXIGztB5QIa6/7",
	"kRNwBapGpNKETmVpyNWCIhwwNOEfFHzY1xDSZ2F8Xw1i6MOHjwigGOKbx72zBbyIWB4FpDjFIZTKcKb0",
	"uLc97DDa3gbgPtMNNfw6CjYhF0JeQWTTtIKVfBrE4dZjx/EJwH89iQNcwtNuJK5VnnENVoP6Xc+jjWw0",
	"695FAe0H3982w6x5mbFLhg99BxvCs3RmyllXqeOZ9/Zr+9yMZtcNsU9rGeTqKUGoSAk3mhSlKqTuRL1m",
	"QvFkscKwHR6FQyEX0GAkhEKA5lKZvEOGpJRdQ6L6N1XjxNuFU3guS4ndgQtGDMRpWJpnNZeJf/Y0y6kw",
	"PJlAiiFQfRzw79dvIJO7zdufIj8Rz0Yrerx7tWGhO/VO6Ng1spLfN3txfhSvYxf3Y/XN6rSfzm/vnGjZ",
	"kQonCRt+LZUrbwO9oCqd6NDkQ9Cua/NsD7pqfNNGmnIORxtaaox6JaFWXC4WaB2s8WwcQVO9Yl7u9fo9",
	"eJuEf/nnmk7v6x/ZEmE0u1QoAkiTPi4acX5BU3FJH9pPfErmK4JSus+FFgU+cMGo+sjUnJ3QOauYpr09",
	"SmcgyaAKyW0dBMcI2I/uhVeXCQR290bkKMvAgVWloIpN4+xwLCWuJARrYd2CKgPoN6MI+INoI4sCRR0s",
	"KplaFYeqZZ8kGQcgDNQe7Em+RH8bYdcmKZWWCpsG/wzb8FsKUPvglyGTpFSKpX0iZBjpqgFGy+8+wB0R",
	"Rtzrt7L7VOsRkXllvo8PMV0DSUEc6aUAXUgjlIwfJui0VS4/WaoEwpx/0i540khywVhBjgACAzKXLEXi",
	"UGBEVTWkFHTpBV1bzk/zvbwi3BBArfZZIM+YSDuHA1krG2MCbKUzTMeJkKA6VAKgb0hiGHJeApMA+JCr",
	"g+ih2k8j4ie7My/Cxgmg4XSqLU9UA3JNPh+S49ldzFRqFvONi+O/Nn4HIkF+Pjr9dPwJgtI/SUTE9nBL",
	"wEzCVOvnnL/kJVMZLQq7imHAugtPNFXLiSrFekjK4xnAEvTdA6ZGXfwKtgFoB5ZoaUj4klMAckkWvmfk",
	"EwDlhH0L4dkA+W95xKcX8qpIIvOcQ8SoLftqwZILB5nql+OKZxmq1rl0yO8QTFmtj6MzxMWOxam7JPiL",
	"svZDtqq8A2WAi7SjCFyhkWJBt3GEacNuZlSbCWyltNMN9Pi1FWa2lBu/e/9V7BJw7nAXqpASa0DeAhiQ",
	"+2UEsar4PIy7nIx7454td1ZOtS0kQmGNpWt8VevMX5dsde8DheAaQDE70ojJI+CMsYC4JkQx1VYYuyxJ",
	"wI4ZtXOw+1kzoxuU67nI1dHe3mH3vQpW9X42mI+0cGZI2Pfk+DU+sLs/8dgZkZtxz/824elkH9KoDofD",
	"W3sNjL8chC+3yDFw2oMWPMKo42WlDjtplLFrnkg4hB3i33SJQgBPClgjlCvAsY6Y4AUGEhKbAYTeEJQs",
	"hebaOOuJ1dwBEwlvrjTLnGEBdrq2ii6Ci2yHFXI4FfRSWt6uXkzttdReLfy7AUq4Z9odlJCjFzBW1Ywm",
	"Tea/idZw3/6JmnfvAy2MLECw8IT1Rn/961+Hf/0r+kW74gdR8Y8SI5dd6YNW4cOo8I9sOZVUpVX5P0P5",
	"To1uKZIJ3EfWaXVnS5F8gIJNpc6z4de7dZeVgOIoUboeHFBoeSkpVVtybvFZTfZsr/AZDUKrO9URnEpX",
	"TEUNd/XW7GxIPovMZ4hufx/ew0IRZ0vZyNrVhAfvaPGCLREYfV1bQePFSnqiEypE15o0XzNgR7rSKDGd",
	"ApCWIHFRHvqXuo6QBpeUsW1xr/Ic1N7evSVqpYIw7tnPqVqCZ8jAqozuPCU5Tdm415lZKxL8mxxEXulH",
	"EbAFfpENNaSzG3srL+7idVeATFlCS80CdsWC6oWTQCnZKgVOKe1m982uad3Xiuht7THPZrd9Byx/12S5",
	"wBJ2Z5dFCmnStvbIBlu6GfHqb5Ohz7DnexXR66vcJa3gOfcoy57EJgirNaFZ1pFnrxkeEYquHNUnKdgT",
	"DktIwTYdF5RdObCThaJ61dAcTEy3bfR/FmMc51bA6NcbaGulV9Li35QKdySLcNl03YUasthQkXben+8P",
	"2t5F427iWiF1ZhQ1bL6sB8ApNWvFvEFxq/NDeXfty6eIQlhzObd302B5dT7pVterDEf443AslJqNmkmq",
	"yNsSQoUHrn2mffo3RCZUVXFli1uKlBkdC6WhMZcMC1OrhraET54VWpsuSc7Fbk6vPbgeJVdcpPIKRhs6",
	"v/JvvlhvLKxOYa+1eLtpzspK2iqAN4qIs9V0PUcTkFnpGeZegkY7uQAwj+6UCf+zDN/O6bK5hnY3sgs0",
	"3MW9kYPVKl9H9Mp0OlPTXxZ5Cewv3tNmSQrFc265pyuowLY5wf14l3ulvSe5Ug9/bHa9hdSkm99EwR5f",
	"+YTMYlJswRXNg9xrHy8Sd/ZwJ4FHOKrV0iy1WNvbetekRqwrTlAG9Ku1gwBTSvR8s8Km/G2773rR6WT7",
	"iFTfWBTABUzzSzbJKXC8KDPIsegZr218iqpgaqD1VVzbbSeaFVUjqB8uHlTzdg1Zqyt1lavkHknC2s9O",
	"LsfPmoMay7XX/Ottv4eJSR4GxYJ1V8GvIL55BWWCkSyKX9JkCcegnM0g436p2RACmAGopVRZDNLy+cOH",
	"o49Hk/efz74AQgu5pGol1oGQOU8QuAJD3rb+/P1fEIalT/LrKXWoFgM0423t7x08959plg1yLniWk63D",
	"vzy/C7wFYd0AfhTl3N+SH8I8G3h1DoelObIGTJ3HiYP47p6DnM8sARdSm9H+/vPD522Ilghf4C4IAbdM",
	"nfABzXE965NnLUI18QI6JrMansMrfism1b87mN2NvRbM3ok2E/HJSqiZagYrB/NEUfLd6X7ut63uSFTj",
	"SgScb5gHOABx4UNH79ptq/YPNHs4PBz9eW/aJ79eMXEwfDH688G0T1LGCs3YxUDt49ecW4U9G/152rf1",
	"Luno8Pl07X7J+FRRtex4o/nmEBwP3SIxUez2iMhi/wyESWTK1OjwcNrcLnEDf8Bh/N5wGF0S5Kk3+ilE",
	"sT3w+FRQuXZ89p5Q0qMvnuviwUhK35iKkOfsgUoI1H0oBtznkzefjtZjwLmUM9r1FmdkOTo51k3NZaWA",
	"tadlBKx1ONA5zbIIN27/xeH3XiNpFXZayzpsuSKjxi7MEFFnQe4COBOk9toEXU5fDIbDYa+CkesedyfW",
	"7v2A5Nzq3QkkV1+jBwDJdZwonzFVdoUe59mp4iPMmf3x9ANC4YeSIYsGQLsFHLkROXjxfZ+82D/oE6tX",
	"NiDnNkaIWknqNVsfCbka1W1lu5upbgD9VfCIp9aqbtXSVqqbS0EAJzcWeKYB9M7nv2ws+sujszcT2+hm",
	"Ol3nKJ9USD1Up0Ni3KHTdWK3IaZ1DbINf4KrSp/Iwz6Rz+GPe8qChwG1NbZrJyYvvKeJZDmxPWamo6UT",
	"/IDEgawjoRLZsqqM5Y77aTSDg27E3t8J1S1gj997k1ZAbtjGs+qfsKz2b7fCLdi20GuXbV/bW8B91sDX",
	"edIl+NfRbf/V1NIO6fh0surERRS1Qb02hwl/dHhOv1e9LT0KYKnr/FaYOq4FOkW2MInfwGX9+yYYIwgL",
	"VsWKP1Wc3iMM3WG1Wqvus1+sM/Y/tGd0LWuT9x7kBMiVR7XQCRu+ef1/uaV8y0UaeTU3PLC+MYxHAPb6",
	"tngeF7VDdL+WZP7uLPMPxs7wfe1Fnb14yr6enpGauBRP1261cRuBCehZ6kVql0R9/E5vHI4VEuFTd3lP",
	"gAy78RogGTXPJaRZmMnXp9jm3X6WAdbh98BngM4mM1mK9FHHNb6HTAzP2WSzzBr/XgfN47npsewSNVe7",
	"g1gpsZCFbl1CjgL6lscAIQ4EBPy9fb0ROXNIDVhmuiQLWWAKR7I1VYymZjHA9L0uJSHhcwH+LkgVTOte",
	"ScERsWN2Kbjcdct5QAcsX1cTUjVKMbe9Jxj5D0msFpSLbT/KjlYdKo8u83aLmbzC5rQhSpYGHBO9f0xE",
	"rUhs12TtI/ApGkg7XdA2CzdQSDnaWqHuBQIQIv4ba2LONgkUynXQpblEcA+2ZVesTM2rKKZaRagaCR9H",
	"NcOUsEoL4BV2og9A3IBRlAuDOc8CJJC2dfpPpirZOcFcG0rKOjOCrUO2MHX/PvkhGKsGLqWtXd7t3jdR",
	"OdbCZTl/nCdHzdqATm6nNulkKYRrBON8OsLcD8vrWxBmhZr9poIwN9J7jbEIF1Msv8Gd9XEHTwWd1YG0",
	"o7mYQ+ZogJlVMo/2ZDfk1xSl24OjnjugszpjpgCQ1FLZO+LX0XvuTYlunBbERPELWcUaoHvs74iF8sgF",
	"7pa5RyBXUdKio+Pdaws0XwFVgMZwhxJDthQDJGtYJPD5XSYZAASjEH6M0s/SOdsQEi4cNw9H4XsM7ZmC",
	"9Jl4QDWTk626oZ366D8ENUYLMmJV2F/sv+E+VWqm8AepyLOdZwjvmskpzRq2ZAjN0xNoozt00UUQbgIn",
	"4YeHiBKbQVBUhOjEoQi0aA7lDmyKRpMrsc6KUC7GIrAKb6/fg3DBXr9H0xyTv1U0cyVatPq38qZeD8Sz",
	"mdP0Cfglf+uEl8FF+m7DuCvXPc5SdDl2t5/tClVCAEID+n7q04CDzz75taQZN8vhWLxnWaG9V7QsDcnk",
	"1cBhIiUs1HcJ1AtesAyCACBZLsg8MR8LbHVOCw3AAeySu5B3jH+QhW9ouMKHChqYzGkxKZhKOvOVnGEz",
	"plS1CAsIDMf+U2W1s9z+0yyoO9Bce3TOxiJEY8QB12UGL7wGcvOPeyybyis97kEEMDbL7YJNAexxOBZv",
	"pSJuO/XJ4d5wD2AEOgZyuPcf7fBu21s9ePdw76kVWzrVMisNQ6q2KfmeqrS6hSZIL8X0QmbpkHgMVIxh",
	"dqEhLJNXSM9LmpVsLKhihF27iFTF5lSlkJ5dzog0CxYzImAFNKPO94Z7+089b2Qi2AxdqCqsIFJky4pz",
	"wgQJXnx+IIEVyQ5ptNhc+b3hC4DU0KE9WxguxoZkjGpDFjSb+Zezag8Mx+KoKDLO0pDIATw0XPUWnV48",
	"JZmcvJnkZWb4BJGN1uJLQPgxwIeEfB6Ar1EUjCq7T6C1InPYOEyTrak0iypDxVhQkdaTcmwPyU+azUpM",
	"p8dFohjV6AjFEg4EmS5daj0QMXSuGAT8E4e5TlI+A7dRU0dtW8hU1yDi7g+arU06SdnlJOyKFewUcxIX",
	"5BPRhorU7q5IBPq9w0jOqJMQTWbaH+41mKmLOW31Adnf0SZN2SXCu3gKag9bRTMrxjMOaClOKbVrhA2T",
	"DgCI/adksa5ggnC+boag9YWpHKusQ8GKwiE3KhrrOOsq3KdsKxxtXQWr3iw3HEekoqwre8rm7LrYrOzP",
	"PEsTqtLNSkOpM9BbNqvQjstZV8Mu+z2Kv6aGQfH7jOolioLNCr+S4pdSwAbacEhc369CPRJ8o9JVhPba",
	"0cjkON2cLG+t/rpZ8Rqm5Vqkuiq//Et5vXGden72e3RSS2K/Qb0oPzWEFsE/X5Y8S5la+ZY99/506zNO",
	"1x3vICbMdOq3n6gpFc1IRsW8pJB0qAVB6SNqsYn4WveWixQAaIpymnG9sNqFMjzJmAdozWmy4IJZ3QQ1",
	"6KANA+bEklHVCSYBM5msyiHl4SxxZHCZRz/lAGoJkDkpU0Py+ZIpBaEfeOvHpgmfeZ/CtAFXabjJmMtn",
	"jhMOGAxhmhNq7gFeCc9p02wNLCUOz0gytXzggkdnUgFomB+ry8Rbm4o9iXH6CWLl1u0VfkXW+ki5Bf66",
	"6jAN/Nn9CAsAiCnrROwGP81nmlRlQvI/50DoJwxubPvDve26PvqXTm1hYzczdl1kVKzIivu+zKkYKEZT",
	"oGpU1i4NQgwvfDRvKhliJl0tlgBLRzXRRpWJKRVL8bZyBcbIagXOXI40WKlnzS3xzJLCg6HgOh59eu0T",
	"PGuC3OeAg9k1TUy2JM8CKz7r2j8PCFl+FxbC7Xecr72Q8rzIINEzeX32wYFJDcfCuSGXGpDYFYOBcUFc",
	"sgvELmsF5gOzVqHOLVApKlJQ1pxpI9qGDtCh1yQgCFxfPOxVw1TeG1VbFgVti7OvsI0OIXMkloRrXTLd",
	"J5BLEVVrMBBSrcu8QFU7pynDe7j3xhTzimHqsgXOO/IsoYbNpVo+gwSc4EqAN3+7n/suKr7OElxow2h6",
	"H6nT2N44nJW7+31XssjwZBFnBSAL3sYCvQPmDiG5E6nS4So7tYP3On5th4M3RLwG3xMB7gwtB4CJaX9i",
	"qb3QIYYyLBGS9vT0rePy4ao3DjciqIqtwtBWGDdOg+0Kb09u1gtuOt1jO285rkfsoTuQHUYQDN339lD0",
	"PWALTf6wKxhmeBebdO2V4F2KjLLgRrdDsxau7kbPPIEpu555ZG7bKMwyGA/wt9+YkhWWQDCsrH7xrS2X",
	"NxduvGTt5dkwU4qlBKGXlGc+OGOj5LfNKXa+pmxGm1hIr4D10eufF498udt+FWK/BicUzGFonbJESXya",
	"YxDvdndWOOQePNSZWrxgpYkpaZSis26UiGAo7Tmdcl1kdFlZb7FHvSmUp88xMgFcmJUv5L5YZdREC4lD",
	"4LGHKM+o4mbpJU/d5unrjwVYNCtTMpg+SWz59OCpfsL4u52gYFQNQEWoQB41nriYyijl2g2kRr26rrV/",
	"H/Zfh+cRyFeKtJN+biM+Hf3milHD1N0kJB8A4NTX0vaMQEzMBZ8vmIr6a5IbtRdLTf9yEWm1DknzTnvq",
	"42nqlm6imCVqF1lDSoH3VKQZm1KliZUKGSDsImQshrvaFuJdF/QO9/risl8Nx+KLr7+gmlDAn47TBvic",
	"vhDgeXNjKT/En/A/9q5ze3vuIrhcdNvODuA3afLl8+dPZOuLvGBi8FlxJqwm+hmkGvkkUffa9kCmM4gU",
	"HHy/9x8uICcEGo7G4vz8fBEmPRY3N+gZ+0VKZAc3qNtbKIqjOfKimLxnWcGU3tkBh7Lzqu45GZBToJb2",
	"MwW9PS/sdoPhu9EBP4ZE+7ZRXEo9GgtCBuQc3Zs+UnXB1DnZssJme0SO0pR850CLIC8DQBCjsAphbSMQ",
	"ptuuIaudCHNOtrgw2yNyDH+i6NMFBczuquKBr5UyzKxv+0ZW2B4R1Ew1KyhYDtABgU5LKypgJOAOd64T",
	"VU7fmzxDcuTykmny/svHD8TQOV6M2LVRNDGaoBF+QM5zlnJqK/ysaKER4vun02O8D71j4kdu0Jqfy5Rm",
	"RGMEMdL/V1vvjXs6RHIrrt27YyKFV4F0LTDQr99LqnkCizOyPLmKE84BVDpayjtKk3j1foAtSXAdfthz",
	"LX1xdLMTvaulsBA/jHvjsRn3/EhKbWQe9uuInH/hJmMjUt9VYKi4vR2PxUuZLptfpzJd+vEoGhBHkUdh",
	"VN9BUukaIW5u/n7Blre3vjFo/eZm15aExsYi5nR0hGTab4M++fDhIwiunP/GUisgCysj+QUbud1mcCbH",
	"wqATJeSyk+Qf+EyDN+WxoKVZSDUi/0kFI68lGwvLXv/87vDriFDed061eRZt4ZAJ3q89DPTMxWdgfoAQ",
	"6znnZlFOIcTTSCkGOB/4t636TpJjy0a5306dNWlWXDB9wcXuXGLN2q1/Nbt1pm/x4cYTv+z3FOp2P0Sb",
	"qArODla8Ohagv31DpoluyX5uR33ucNbtsUC50J2NuRMFDtqA7Y62EHvrWsqSXFGBqZrswOKR+vNmi+d0",
	"bi/bJ6/f6j5hJhlu+2svkbOx+KXUBoTKkNQGDRkqBAa54f0ulaZQMi+cLK5mpFguTQQ9i8J+uOYQwFof",
	"rRQjpcp+gLexpFQZPpJZCQWZ451lCGaofV84q12QgVFrJ6/fbtSWF6bBGqBkDhSK2vrCrs0mjQWkezc0",
	"wH1yDXeKTztIXGEQGPWRo3wAAXNs59guWVEsKvuRX7N0RM7PHOyd3eZe2JCbm+/4jOAfq1q5udnlMyeM",
	"frbcJaTxcVgs7d/Fn1y7fcFSQjUpMsoFclRr73bN9c59e6eLZrjxrlECOyzHDXd4xQBRo4R0fxVgWIRg",
	"UqnM3uxYbaJILKwmkxMKECJKwU3Dp6EC83ofeAm2evW9ahcf3KsMD14APLtkhGaK0XQZGX2jKUg0CPuE",
	"KjwFYzhg1oN+J1IrQaqOEppl9Tf3ylQBer7mUkTgjRvByFUvOPEF/xctxfCUXn10kN6xrs5zq6z4KKTe",
	"qAdSn4v5rq3Vu739ehc4JPVOGZpQ8unzl0qlGZLX4R4crsYgUl3N6DrjnIy8/YJ4Vw+XPKNy8hiLM8bI",
	"1A5gAM0MAOyg4MMlzTMPJ1tkzLj0Q5DkC8ZTrajdsnYnvwn3zlTRmdEjcj529tcR/DLuwY4HNRGKsUKx",
	"BNbdSR2oUv0MxitX623tmmXZk1+ylMBOinvyX6Ba3ZTsfOn2gz285w2vo2gon09JoykwjbHrgop0omvQ",
	"vHXXsAiEN2dqXgGc1v0pak5xQLlSgE7h07AjLigsIbiwRGi9tfZsVbgKavSwGNUw+l0z6CAD0k5Ac7Ww",
	"FOi5h++BvplOsNsZTZh5sNv5W1sb1ZW2DIOPzsLdTPI3nys2RxN68CJcOhM4ipy6sQfeyuAyaxtlKRH0",
	"ks8r6w9e1leJiXXvi05PNzLQuMowiTvteNY8fmiW+Xp2i6LVC4w2oBNJvKtWSSqJ5r8xPJ7zQslLRgqm",
	"4JgQrZQb1eNkqbIoj16/l4DR4/7vkpsB6kZLUQHrugwR3qwXWe0WUrvjI0pMAqIrHDDdEgoo3UmFsXgl",
	"81wKOOWqpEHgAzMwTFBhKsMMiAf8cUSTnI2cSPlJMzUIEdvudjbulZqp0f7BoS8WsnaCBKy36h5TR17a",
	"hPN8ujSd3uAtDOF/+WNIwPNj9zlkNXCMXgFBBf5lVoeCVtDhDtYZZ73qIMKdy4xlreYyP+H55LLG1RfQ",
	"ifrwLOjX3F4kMCsWFKv20wh16YO9g8PB3v5gb9/VeOWOkkb74YQxLFkImcn5EujpHSxGTNzvpGq0s2RU",
	"VUPag6Oq+cb6ED57ENzFN+VJsLV6Z85g9A3wclbO1mC2l4XLK/ZIFvJ3IOQhbv9t7zRjXJpxb0TGPaeC",
	"q3Hv1ikrLEuDaGkVn8p0OWrWcW5hrcJWxMx4wmkGC25P6izjcyYS5quCJ1SrYoM1fGF0EWyVHo/HPXwq",
	"wNQP9m+sso41a7NBYdFmVmBMzEXp7yGPimHznNrMsMySjDqYsCp/PUcnIJeKP3g8O17arfkEA9P4p4SE",
	"CqK8IakZzoC2BQjI0izDaw7Ytsifqh1YCzloKRzOVXm1xuGGFl237rjaDYlLSZbGj9uNS91wLD42PaUT",
	"ByAXaS0guRlXke6K+fQwi131cN6tkkwsU0wA7bgeVT+p0J7vpZiAZXQTLLLgHS6dKjIkbyNSTXwAPpxL",
	"XHu/+IsIwWos3GsERCBjnEklVMiWWRYul9v+3nZj/gd73bmf1JzV7g53+ljWcoDc9ntyNtNd2B+fumat",
	"L3jRePh0qll4YA6ytOaJU73sQBpJFKys/u7my6Yl6K419oycYprvXV00gbi5yXR5lxjoeH5t4K0og7nx",
	"3OuVU8NdFGvDCdA1Q7bsMUZ+AN9GBg+hfYKG+x8I9T/ZhUWqFfByupZs5KxlaIHkn9kVtZov0nK6rL1c",
	"Ojf8uoSNdHd34DqnhRpiUyRFihCYdbcPN5QCLw/E3F0fjFjD5gWMkhobbOA/Wp3dXsqufriF+5HtEenU",
	"fuodCyMj3ztICIOiy+WFwfyi7TVy0qo7pc3W6enb7SEmR7zLVEhLI3Nq3NYPhkNsG0xV7v4a27EQsXAs",
	"PJplkLFe+EIICjlv2/vPmyb8an+2/DmdfhDrBi6RY8Pd1jEzbNJOQO17+KXiiwEJrxBVhGwYam2gV/yC",
	"FyzltNPztNu9yGdl1Z2RvPgJLSUh/Ad5o8p42/Y7UnGjmzsfOUfXLr+6lYN3nrGtkdvDBdJXN0brblz4",
	"1hvJdbuYFB9/2/OJvXMeolB5r51qgk3PR/udV3FBoOScvDpCNWFw9umNvbe5Y6Ay4Q47TbGQlboNBQDp",
	"r12ORMJn0TbHbJHdiKmPt0q1VrUaKqqrbtKP11ZXkfc0TtOVrlJgO4npPeg2cZzT9XyJDZ/nL19OvGdx",
	"YjVaGa9AYM+aZ9qqXGcrpcjP8HDo5Mci8BNJAOFAAeJwR54f2YGt77Mv1sfJBcl5lnHNEilS3RztvTM7",
	"NkO47VACDVe6RJ5tZiJ2GqWiQldJP+2GCoGEcOPU7saJCDuuFkI4gbELb2sEzNMQiE9eMm1cOJ6ifL4w",
	"M6muqErJzDnKVQfJwPKbZRl7IXypGL1wl+HrcG/i9szV5XQAroHo8exGiAoRo/YMD526UVEFY9VeHRwA",
	"GMZkSpOLEfG+5WSqJLXKm/15rsDv2e15rrSBtztRYSq6Ayd0FdongrE0+EhfY4bsxTJlUVeLZSHNgmFw",
	"IhUa3L2cJavvXqEhohQVSbcEUW90quHtdTeRImGFp6SOFV6fjR/WDC4+jrrANm7+vX7Pjq3TzN4KcXsk",
	"IECwM94d6rHaF/z06N1Kr1DAGOvAA7A/240ZApTcy4el6nJ3RrPMkiFoWlZfLy05rVZ17XJVYY1noYln",
	"w7F4Q5MFybi4AK0P2WKJrTbeDvxx6WyW6L2kll5Rg+S1oWnbModw8ag7gP2ACT4LKb1DgBAs9kaKA9Di",
	"AxcXXXday2BrwbUuaVbp348J+UIPiDu8SBJ0Myo1BM6Du0TNm8RS7sOHj+GRo4pBosR5lfl6XEMYiHs5",
	"dj/WjSm2tZnMMnmFniII9YVWtpub8HpwezsiR5U2hHInbfgEE5661x2WpRpbaOjxth07Fju7Z7ppOfHB",
	"RlEU2PZY/LcsYdClZt1+k5izz0hHOv4bc8AOdr5990hkp5dJWWiXwLJyUbPkqSDTgWHznA6c010E0Rxc",
	"Ko9fa4j4GhHvrhURyvl78dT+87sSHYf/nlFtbm/75OZmF38Cjwl04GrcJF56fA6zYJpVTfc9UWChDahj",
	"hDqlcGQvTh2jGYvXMiHRmBoOabZENJCx+AfNeGpn+ESTWxUHxbsuE00Wq07JyHA4JCCBkFdAKHgZRJ1W",
	"42+k/nduNJFXAk0j6H7e9NWNrI2IAJZVXdsLsT1tqGECGMLIOQNJtWXvMAh8AgcwDuqZxp62XWi/C9aB",
	"sY3IP2/GqJmhwbegBVMac4g3NgsWGA6H+BXatL/t791+xZbh4E6oNq1m0b+pUfFFnwyHQ7tQ9SGgz9+K",
	"0q6rHB2EnmT0zQFMpbxwjTRtBrbADQ46Hpod1abCvxZTgfAgx1hvv30Y6KU2LJ+sldJYLghoSSA1DdoW",
	"4PmX/4baa7yzrSQDYxS4uM3KjBwdE6o1uLubITlzNZtiuWHxtrzINcu601dYSTzRRjGa21/aVzwBe+Ts",
	"7A0JpeI7buSW9J9nnz+FF/E2iEaX+mK39UoFZsU9/Oidv4LgKSJSfslTryIva7fv6m29kRngkmbujrjJ",
	"WV5dAqGL+HZ5x62w2uJD8mrBkgv8BSs/CzGh4CEIF2nncQAGS8qzUuEF8vHGjuBksOGcA2f5Brsu2jFk",
	"xDdDwFLQyXpd2JXr5KVWsrLqWbWZmJh1Aba8DQZpPFbgQuEu/kGjWZ92rEodtZkB98SXd2lFut2Ju1Qc",
	"eEWxB1Wlg8Dz67oxtlDF3AA6qLopIktnvrhN8Dy4Yfes9UoumLpvpX8wZdh1s9LX/8Xeu243ciNroq+C",
	"JXuWSTVJUVKV7dZeXrNVkqqstm5bUtk90/SIUCZEZisJZCeQkti1tH+eBziPeJ7kLEQELplM6lYX2z39",
	"xy4xM3ENBAKBiO9bvNTeZpVEF3BLwNMSTrvoeqAlEZqoxlIhJwlXa/91K+Rm37WkPxx8+2br7fq3rcSp",
	"98/IM1oQp1amlsUOxKRajl7f0bYanCDAV7CDvtJbuYGBbD0e1+ARl6ISUkQWvNljEcQj2M4lZGyTo7rz",
	"zSpxA1HDHIyjfXGlt7Jaxy1cCvJ4KrRRVmT8UflpARdveHJdFd5G+BWKMuV8GUXWacthF/zu7ryHYbCL",
	"uLE8uVZXVxfkJc/c5BHi1sYCDKx/j1IKseEZzxkV9SDNz+tWLOIQ1AwBFjy/8M1qYCAPh8Nmi/bxE1c9",
	"S0XOFzx+NQzkYftVLL+74AYyYuuVbvaecLdsR99/XaPdeBB9mepd0t3NYUt/Xe2P9beFwHpx31KVWbJm",
	"dnJrBrqMmJCxbcvY8v4t1vFOuNiJOO8yHzfBOuKuyBUIIV2Xx6jxrqQVR3TQur7PEi5/EnMdraOm/MMD",
	"uOe2By2IKgSEXTyAEQgah7hEiN8ajCT4K/Avluk4zMGWgaFDriB/w9UGEum9UxdGPY5Y5zOdKSwb6/Cx",
	"298Y9U2AvwlxIrsuQQ+vpDuevp1VRSFKdqkqmXZbweVeGsIaGZMtIawjqeLAToO5ACH0KgqMouLt0QrC",
	"QPBohdlboxX73pHQ9iALpBn2NatnBzxNS6H1IMnMHF9zwGDwzkUyreS1Hqzisz0XzA8P+/7pIMSW4IuQ",
	"7MXzqFHhDTr1XdCZyZ1YqTD7fXugLfbFLn3ihhoYPtEvCrL9nceAGuUQWUNqOMaRpA8lIiAqJwlXGkD/",
	"8KJbewQpRnzWuL9cXWUJ5HkUouy78kfSlx8y/wmLkXG45cc7x5Y4vcVYz3q422Lc531L4Gcjyu+hINAo",
	"8M8Py2IJi4FxFGMH9I9q1nZnxEvjrBqv1bwC7ASPOaDhItllQOOhYbIfgnnpYrUXA9UhNhvPmyNpK7sU",
	"k0zKKGUw0ovBJMJo6eGwzSryqusi9O1JGtPppobGtKV804y5X9SYYUhyyOoHjdkIiVqqQD8m0GxxUJ3S",
	"5HkeSXO82eAmxdoBK+zuSgyLTbzM4aMWh1FtPpj0AVkKW83HyhLsq0ahIIlQ6XIR2mgToTZjxoVZgT5s",
	"J4mxv9YDJFGlBXpMUBKlAIjyLXbuLmH9PTKczgsurQq7FvNbVabaXfxpFjKa48AmMoMOxI3I2YZ7CaUN",
	"LyTDDWR0MclbrybhKvJWVXkaQdwSJLaJNHDnx/nuHuszrHWzWWsNld0Bssf1tZthU16m4QjSOErMjbgA",
	"wXnUKTMndMwFf0BURpuf5cyokk/EmQ9WaDLT6OuLCra7xcCATF+zCoNIJLP16CfB6UDqZtFG9/rLFF3u",
	"IfZpyjUrRSIgAQ1sgHYX5WK/Ksg8dnt1C9+kfxBWx7GPDXJx6inTWJBdjvMnrpqGH+7BoKSaIzmK/oAb",
	"NPL/WUsaR9VgosiMl9epupXOl5pnMhzDw8Wfi5v+mycjyFJEF06yFLfVX616aX2+ji/0/A8b7gtCoVsw",
	"2Z3bttVVEfJOXafAuWUPWa4zMYbHA32CiKhak0uh1xc7Yn+1u4Le+PVRp5lreusKmcsElnydycz2HaMN",
	"GkbEXCbTUkk3pTloC0i7geydEC0HinHkCrJWyy88Q3/fKb+CC95CaaunEqsLAaKnc8W1Edr0/J6BhYC+",
	"qRVxIi7tAvrpZ4bP4DV/81J7NaR6YFjZL9sH8UdCllkyBR1oP4vyoFn0yCUa1Zve0TQcqtLR29H2QB3g",
	"11LWGlWLd4bWoGRcCm364upKlYbVCg+U+Fc8zzWc5iGN2b4FV63ZTKjK9JhG0rUemyltWIpIMXUNHmbX",
	"aXI/dPCW77Y9p1zL9kTOcxeb1dCpsbwsvXxqQYM1i3Ty5z5YGmIJgEEXHCAHRGr8OnLNxNaiT4Z4SaDd",
	"vv08hDssLBlEu/uwDFz2seKhU2f4qv3IbpEvbmu8wS62taEHoOG+xjBObXohbuXiUQLxYUOCE7mcg+sk",
	"RNGmcdLjoj+RFrrntGlm4WA0CKRLuHwV5+nwN+CYodV2bvCv0Hi9dJhdpmKYtqYnfoaJAtBQnyeAiS9+",
	"BOxhmbA4l4S0yivlWHX0AwaEYvQmWndpWx6lkt6F7SJRGnOBDi08P0VlWAvcHzC4pFwVl7WD2lqk7LIy",
	"8CoKUbrsFGRMfpG6OMjWvTP1sVaQTYWgMKE5egq2q7grslL0AvULqAyTI5QzaD9t+KxgHXft0MXMaM3e",
	"qVAH7cKO8H/j1fSbHvvmu9T+d/3b76ff1I9zkevFVdXeiQCTzDPposNCo+zyOD8/wF4QrX7cTpJzEJrR",
	"yoX/cLQCEczRGNb8jjAJYRCA1css6cCNKHXrHPyMDzycD8gnnCPxVDLLJlEAfM3+bY3avV+qTbwV/jQ/",
	"FW4w973mDqPRqL8IIcgPasjaEWDBNKqXtagJf7WtF+UsDvFuQagmhMqWszOgBT92VQxvOaTLVnXsWSQ+",
	"27X2M1q6rIURkP5na2ZwBc04AAvIKs/RFKklFUc6KPoEw0wf/+ThskNrHi7woXMUXSjvTKt6IMBjlFh2",
	"jdK3DHzMtRteSD6ip5lmnCVCmpLn4GPA2HxR3mRu56DvdCgpCgg3mShZAok/DroHLogx7GDGC1BXx0dH",
	"f6XfEatblXPaATsOEtQoNlW3DC/e2a0qr3WXsLF2XMWA5K63VletxXyFoVr+LuBOpH2As/DtvJwTQqMj",
	"R66y3PQz2WOS2uSkFkzwbTknJidoPOxmdP1mW5crnlL2DzRjLcFp0Wsf7Pv3a6Fv1GwcFmruwfoWOxQz",
	"23M7XmQCbfRnmbTniPPzA3hrY4udWGWrAXCLjjDWqLWbGt59yEkurnKgQ02Fg1rNAiphUpXAEZSlQqKb",
	"p8SLLL0Ad15kF1WZr2ytTI0pttbWcpXwfKq02fp++P2wZvNvfaB7Rby0ID5+CgaA0V/pragbUea8uIBh",
	"p3eiMIBw/+6xHle2VkYIXodciNGnw/uF3CPX3rbt9f3pgdufnHRvn+wzIVOILfD7eWtXv+kO2A6XjOca",
	"oO61MIAlun10/vbgf12c750e7p/vXdg6hLzJSiXBRnKRxPUjydLB9PtimbUmGEWD/Qzc8cX13zjOklcd",
	"J45lEqELBoRgVpRCAwSeuBHSmhLgmur23PvOqoOYA8p53EquzBbT1dVVdkfobmDh+cK/0YwEBc0eVxm/",
	"1JACQc+srb6V1EripUCU5krXXZ5RqpdVNJlmqCgRgs+qLHr/qjJV6XFP0VsCOwvm3tKlSVHAn8IkzZzY",
	"Nk0cC37kA3k9fPwen7pqouDrIrrnGrCT0o680UzcJUKDR9yrMMjKL+cst4sjuhtbeTQCAFdm7K9xi3Rx",
	"6fjqUEdTBA1ziQrwIZKSYrIJqtU+2tnuY+QmiNX/Q8qyvmJc0xaWRFOhPDj2IUMdX7cdoQI8hVqipBZJ",
	"Zfwo6wFDRsgZz8Ayd3k9jCel0rTt4bUOd7lxLXwf0dhHyi0ef9JzjWOyB72NgJF1kWfAIeiV1mgkRyP5",
	"DV3ZlByy9XSX7khhqWAysh1I5nL/B+1ZtzU9WxvRhSE9R4Ja2RxZK8EwMANG1gntlxmS45PQc0yzQvil",
	"7J/icbltENBRywDDuh37PMK/bqJ3u5H1rHALw2WNABJjlNPBg5FGDzO9NKxgXIG/LjfrFgM8n2PXtYfu",
	"NVz8QQk0l7yMkqxDUbh4SehA/PuII1tG67rbKlYv3ZcHj26MTx9Xd7PWQgQg+0XOk9jVVM+FxHuCQyUn",
	"avdNX5s5IGdTRtkgXNoRzoKDrDJqhin6I0lMPXRaZDmfi7LHAGVZOlA5nvZnKs2u5n3055Y8EQ4Bdh8C",
	"KLg0W6ur0SVhGeEVHB2fsxueZylcI/AJz6Q20V2RO5fD7khYZjpGuRrJy8oAraJmmflGs0JpnVGKPUYc",
	"sExCFXEgBkBpArA4dF6mTEht99i5qsrIn+916EgSPRTcImUtaHIfVq7FPBBEba1vbFr70RcFJ39VrGyt",
	"fJ3JZMWRuq98PbjJxK1e6a0AIt/K1joE9cKLZPjucjAx/Qc51+bnTNw6Gp76GoFmLPgUnZRciznruJQ8",
	"Tjq6B04tLp0BAhZGJrUoje627mJRt5bFSkWjaBQIGPIfWdNdAqH2k+LpveAcF23RQFVhW/mM4AgSCr9s",
	"siuWGSCikt8YJu5s6zswALR2GFbRfTyRwo58bWweXNPHxaK/QBXPGA7Hco5y0ZyGv5wdH51wM8VIJGsi",
	"khYcrXw9gLgxq/owbutrCMOy/1aliyrDpzXisEhWFz1tKLwLfjYgi7CqPoA0dKywuXGDZ19XUgvTY7HA",
	"dwfsHAHFCiFTALR16ot1aPuGbzOZrH09q/Ie+G3hJygMIK8X5kgVbiU9MjntAZ91fVoVVnH5dkWXTbYJ",
	"K70V7Jj9B675r4tKT/H/eW7/z9P0XJ3hKwW0zXYF/pdJ+B+/s/+ra4KvSwHXGq03VCW/EaX2uTLLWago",
	"eQeMWgRLMO7blhuLok3IHMUjFoL4lADp1RmyH6K/uw9CBzxC5euW6vMOkV7jAUFCJ7sCf4dIuysPQPA9",
	"0pJW1fqGa/HtKzIrousG1AYPQ1o+ver2RX5GytTqWwiLiuYBrmLAO27nw6o5DAu7gOjRH4D5IlbCj4Jv",
	"LvBGPb3lFyKdtF3uxO2HVz6mAw8mj6UT8RF9AHKli1uRTaYtK+oEEzFdJxi+pxnPFV2KwOx9UobmxX0H",
	"l+ivL5fuoDmqvBUyyP6M+RKPagtPmHQBOMq1/blttf6c6cxgJDVMNzhMFJoJL+YAR/cl3f88Jh27/uX7",
	"3oqdxmUXkoTii+J66VDtwMfEfoBoePiwJpqfai3VVsATjB4KBLWvs0yGw0GIK/6Y8Z3xu4toY3gsE8TL",
	"C4OPcI+oJLK2pB+1RdiW1HJBQyrMstYsBKB+6vbE2sI1Z1ljIrVBUdefUFvAGb+tOcNlLojP2pz7j9ZQ",
	"woGXPXAp+TBj4ILwRw6bSI6eekCpGVxPQjh7D5bjCdf6VpXpUowYKW4vCnqpHtcoxe3ZZlJumpP/1Pr2",
	"uEzjGfKfPOZ6qJXfZhC/15jrVm+W++RiyvV0mUXEnEXk3mb27QHbuyuU9lkPcF+nRVIBpmGZ6eu6I/Uv",
	"797O//fGn6vD2WAweApEuD28uGClUMzf1VSmSjw6IP7rXqOTbYODOat7CGX4DK/XO6Ws/b2TqyplWAjb",
	"3m+iHmrWEVb6izLToj8peSq6DpVbIxY4XZO5gKGdUqSYZqhZZ3t3p4sRSpWZ4r0ZegxPHRXy/vYhK1Uu",
	"2Nj+V6/xrMi5sQMM50PHLUeZIeGukk3ELJNZ37e3Pxyue2q0HtscfrfB0mymu70IgDEK5iMSH16lmVq7",
	"yVKhukRjpxKowNFDJXaEBhMYLiCJwuTWPs/WXLThjbB/pSrRa+E+ZW0iDFwX9aOMpYa3Js1mQmJwiG1w",
	"byVXCQXsrFS6T1fI61GCcFu30fSxAgGUvSuzeX+SFH36rZ4zTJm5Cw6bJEzbRbuZ787x7hqbJ3gBDEAP",
	"1wJQ08WAbVtNLRH9zii2vbsDAiCV7L/bOYnv+ZYEjoUhqeVXfrfRdsfi33bO0CZrDet89+33Pbb+evNb",
	"cCyAXGC67eJA/gdb3/i+v/5q+H0DuNO/FXtpI3Udpi2+mqjPYIObO15+pZi4ZRlW4vbJvr+oiEr6pse+",
	"EZWdu/6t0GZ92R3ru+Pjdwd7FzsHx+93Lw6Od7bP94+PBiyOd6oV2zoZLfddSwTwYV/4Uv0S55V7Pbmk",
	"ijYMBS/0Hx4aX3qR7e8+YaxOTo//srdzvvRG+qV+dByDJqrXyzV1UD6fV1XvS9ZcuCPZwdacVrLH3v20",
	"1wOqxcoIticnmRTdsK86xF3E8Ibbe5aKmx4rKzmS4wmoV6g0RrbtOzSyXE0yOf6EG8bG4HX/Kud66jeL",
	"bi9+VpTK/705GNq/P8W+APC9azhRzV1gudLnd/5G8dXwz98ubAO+My/YAhBHxLazKoHQ9rvPtymcCaPd",
	"Kts+OTnYR3V0sXO6t7t3dL6/fXDWvt4+ejv5l9XMkWg8nugYbu59tERIwYRTTPu+tlz/x5L3VN3/qMaP",
	"C/19avvGomlR3qZUuWYll6maSaEhMihkpbDOcDDsbwyG3QH7EWmpiXZvxq+FY1edKYRRT9Xs4avzjQev",
	"znsrRhUX120n0aJ/7dNSI9oEvMnXqDp9uL9RBfvJR/44wFimq0u8RzMoX+0iZJtQtPEeJLmodEsjcIjW",
	"YYgaqz8a+y8SUtCKB/TEiAISySD9pxQNsH2y/9xtGeFb8izJDIt0MrjUaL87KQX0SWdGuFhOQmvbzXSi",
	"IN4JN2fbgi3mdl7S3JoJfDt1bwt4mTY4XmTabnKQIf+u5NL4jXjL7cTNL3k6y+SYUpJTodm4+QYFSOAA",
	"avhzzApRzjKtMYXLdi1s4S4XuE+wSKSV/jPnRmgTb+jNN6+4Nv3h8NUTt/LaBt7nRdEHVjpR4mZO7aYI",
	"g+3DjykLmWz7CWqOumHgdvuH+/07OP7hLv+2lh/3ku3+iWeQR8ejBdKKt8Ti1fagRwv9NDtS6yC9dC9S",
	"xYV8GtBBosr06UAHTXBeYC/Rg/ack6fpUgcH85mTFG6pmsfzKfybv7Zl7zlvIOSdYROBeX67wsUBTYIb",
	"C/trGBirBlbu7+Ga5EqhN1gankDf0CW4si3NFSR9hyjxJg85vJFe0j/a+Bzs7+i4TDPbw0vgD74W8z4Y",
	"FBhYjLy+NXADVL3AsmmYkoyz1VXMOoAMW4jklLrSyM9qRGJ329XVwUjuG8fRghAwlwJjbEzERe9i6klu",
	"rDiU0u5+CS/4ZZZnhvB4U5FnN6Jk0/llmaWeH9UwnfAceQO/+or9MuWGHfJru1Nij9/L7B+VwMdfsR/x",
	"a8cx32erq28ON16zP3n2eU88s7q6xd42uOewkQuR0E/gmsG6Dr2DyJYO2asINIql25p6zHGgg6eRmJaz",
	"VCgsYs/7Qxwkn7ZlYcJGjx0XQm7v99j2L2fsjUhLlVz3nGnxDozmnh2ZaamKLMESf+RlestLwbaTRORk",
	"d9oyz/YPd2vgEta8+PmvG2vbP/+1/3p9w0rD3fff9tjR3vGR/WP79LAL7T073GOds4Qj89QhN2V2x/bu",
	"DLre0G2wfXroZmU3EsgdJ0/RiKGk7QqdTbBhhJYdCd+kVFWhiYcXUZpYh0JGkrzSRpTYNBcY2FESI8Ah",
	"x5bm50dVZv+0yy9nkK6byYmtb9eWVqcCKnhpQIZF6iKUMVmXIvSciXcJISveZsNq4v5C8A6HO1yYyG2I",
	"ZaSoTygSk86dkCVK2XZxo0oKmd042XFYBUZIQ7/mKkGTw1b4NpOi/67kQJe0a5tlVxaIOJ1AKLPdDigk",
	"vSREOAE56wAdoFmHktF7+HIvcC714gT8HuPXEm0xO7nb+/0jNMjfCrDEaWZPt9/BXHpYYA/D3efVxJYk",
	"0vggBM05E+WNKPtndqfbu0HXki1sGxFUtidCGlxajhXJ0WeUqjI+a8rP5QJIDE2QC4dxOU8odQQs4+P0",
	"nWnToYja7rKcLGokDOaeHylb6JvAghE8nQF72IE3QLm54Kko+xBlYPWM0NqXHTQLcG0bYdUDvQFi5Xuc",
	"qluZK572ojJ6pIXoQitxp1K7nJw6Otl9S7zvP54fHuBh7/3pgWYdux+twaa0pjfXrGlHA3F2dvqWFZhX",
	"4SgaCMLUBdDCkJMWsFJmt3i2d1eIMgO2S+jcDvLBHwB6WCa061A/gHmc7f6kyfnZgxC8M9j8sMEnczO1",
	"Jy3bZFCQJ/tgx2DpYJBSnrzXUVDHDrIjjO/6uK32V8eMS6mI8Q6Hh1J7aBoo0u4MIu1CuDLKJAU/YwCe",
	"Zp2vM5n0KPAPguy6EehZI0gZyz/IpOAlA7ZAXD3cCMDFR+A3u70S7Zwz4RBM+g7OxTlDWBJaNecO8vcU",
	"8H5JVFowgbGrRBbhY8VK9xWWBqxHzEPXQJ9jbk6HcI9U0O7+GRGs7RHiKgMSPmra+YEDG6yLb5SXbdsU",
	"oSJB8HUfdBWqegx26WDcD8wTPXUSF9oK4DIb3zLcs0A5YjuOEf8FdgN25hJC6k0qBc+d2xAXkk8csdMR",
	"tgU7sXb5mWxG8/lTdSlKKewIH1M8JuzmV8TuNibBc8Ga46C/rN3jlEWeXYlknuSCzbjkE4FIeraCk1LN",
	"hJmKSrNDq18TmJY3lILJZkpmBgmZXSYAzrW6tMqtNhT/W5Sqv0vNZ+8LuDGA4k5VDk2p6De3IzYMRNyj",
	"3eC/zcUdxLzv11YQGkV2BUPR44DRfzMcs4611ro9NrZbDP5C1hiMyyl/k5n/ss+RxwteKEWOkzzNiiB3",
	"tOOjNiYjKjDyCfp53GNjp4lF/GORFcJKhv+NdRDfJaI1CvqVKoOjjFPMiuqklKwx63jkMr/CvCDZLiHl",
	"I3QIQ2Ad0KF96Pgdsb/iBuJbS9Enuu1W+/PnDOxTPOH+ybEblkyVjFxoERNhZO120JCkMk/yajIBO2e7",
	"dgDYYntcA6QkT1OnOxBFB0LNwLVaiom1haw9ZayGgpuOPEsExcm4A1Ces1MMTzylHMOF0xCulEGm1nIx",
	"4TkcdwHA0x9+TqrLPEvY9sn+SgSysHKzzvNiytcpRUDyIlvZWtkcDAebFHUNp7k1PoGzJYK1wYFUtcHV",
	"gpvu4OAQcjkQaXde4/b33GW9kP3CCGwIrG2rputcNT3PY1wDCalr1KkI5YmUDhO24sA2IwlqbkBml3Yt",
	"JPO0R/YQ1gY/UGARlkRAdVwDowPmSw7i7IH9FIbbvgW22AoeoYU2b1Q6d6dbFxYdfJmITuqOyfxx9kJf",
	"g8fRrh/XKfaqRvu4MRx+nhYElgNxZ9ZgWPpId1EvsBlG3LRliSMD5xOKwaWytTBN9bSpHptmRl9AADL8",
	"m34QErw0XCsAOgk4Jj2ayR7xflxUxUXAfY5eS5UUPeSXaLnJbvEyoHyA3R0A63oR+Qcl2aqyQfhx31t5",
	"9QnnB7gl25q4T3lVPG5qGQhbXn+ZRjhzDGSABjh2I0HiVeRA+huQCnhku5X4wMP6Lz/vQMb/RHtCuIs4",
	"Ecg2yKk95NEnT/Qj2o9LpwBBTsHElE2WYPJ54KEV4Tchs6uC/SONif0J0iJY+9gL4gGGPFKMmsZkLasJ",
	"Yx6ewQI3MLClBEBmQosmPuBMB7QCJDUjlFbAybOmExzSnPIF+xpBz8JIgIFNoRsg9RRd4D8KIFzfaEoY",
	"BPCLCURSRJRUmWSn2++YszcwFqCub6Gvb3BmPqfWjev5jdRuvQmkdxeWF9pZ6LGswWZ+aSVDs+Au/zHc",
	"niQe8Jo0xpQC7h+27tXnbx1i9UllTY5Kpr+t1nNjYxVGwvOcqH+7z9KGIBEQkhsx+8HCbKqdx/WdY2hs",
	"12+nlWT2jQo5LpWMINu44f6YRxYUgJY7HRbhPRuhUS/4onru3+Dk48kUjvBke3nQTveOknSNe+oVxcwd",
	"7+wJANYjw3PIhSkrMx04IOGLLNUx56xI7S9dQke2U9BjRSkSOBz0mEyTSY/NyrLHZrzASg8ODvtc9/9e",
	"pRPRVi8+QB+oK5jOJD07v2Z6VeVSaN3z+Lburymiq/aY5lfCzHuOvMw9L62apz8y9MNc/KPieEpd0Ix7",
	"OFziMylEJPf6TRRhzCu2uNL2vJgsAxD+0powCG5TKTolGHJrYTPu/n7UEorzS/TSmeEy5bmSIh4AZ108",
	"ros8XUS7MtrDQ6H2nPLkd7Fq1OOGw+ZCfHboiqoBM5IphSPsrtFwA3XsCrjom3dhEDMyHo/tLIzkh5Fk",
	"rMaz6Kn/Rys9fNhKt1jjSrhU6XyLMH3L0co9fRjROY7kPdSKbTqrH5MfaxKhHGjfolYWSfsWud8yb1Yn",
	"Io42DSUQMKv98m9EgHJhexHzkvza7MZGoxs/1u404b7wsa5ENJpPHdycF0YVbALnsDC4rWMwzSbTGLGC",
	"vmJubpYNADWrrfexwb3YuKLMEoEUG8nGcDhk20e7LJMX2qjkGrRpaDFR/mKNAQ8AisB/RsukZfjXX9eH",
	"/xeE7HG0IY+MvDX1o2HHXiEtAr5ghOTSbPFkJraeMT08MdmNaHRVON6bZeNGnCapAB3fsmReN2TtaBcD",
	"cMB3AH0Fbtcqv3aHkx7TQqYBFtgz02pGH8OZcryDOqN/DrRRsWK+68vUDt84IvAWiHhrS8bPRyM53qKG",
	"RQytqDjsuLVI5mhlex8eBan722hFzC5hln2nX983ikxVAlPWNg3ReI5WTGVUmfEcBtKXtz50I7hgYbwD",
	"TjmMUfmMp65gZfRW2ka6XlyLn+YLH9FOfelLj2fBHPnixohjev2jOX1OUCEz7qgM/0Fy94gZUfLJc4wI",
	"iJJA9zD3LAmBYxFizivtoJMDxLG/KCmRNcKJGAAhQ4HIGtHi+Oycne11iWGU5324YaJr0kX/8imffM4F",
	"B+zBv4lRH3iLP6EzWV0FZgs3mR5TMma4cMQWT3H0nm6/I2lp9/J6qWm4eSk6JnM36FbWarzLX1wXICH0",
	"H1UT2NZ3vA+gv+0DZ94FXounaokA0j0RrWQxgQvQYdtOBc/NlDQGsK+pKzh9QDBh7dBBflmKxVrcR4Uh",
	"3O/PuL52sHIPML4wMfSC64z3kLScndc/v5i8l8g8CIjQ/UaenT8vR1LbVosfzDUndagq9p4tc++EcdNH",
	"AxTJFD24CPEHJFV4/Iykqj7vB5k25/hKb8WndCDuXCuCCR1nLxG5mvjIAkqYPYBcNBHA4Edg0VjZWnGr",
	"ga6WsYCVmBIkYi3ZeP26JYHz0aYBn7i70w6N+z/QkMHqxc3fhv0///qnr5sN/T/2cHExWF3WVixwWWPb",
	"KFbsFH7UenoamkREGrCIJNHCwZET3B5JR1D6D4vwG+5RJ76U1AMwIODjOCl1Ig8/LBP4tQ/w/yM+E/eo",
	"S+0BbVH+d0tVnBPDdGOeXrXkYWHGTamKYrlD73c3hLaP7rbr4fHrtSuJd8IsGaNPtzfURHjZnUkqDM9y",
	"Hd3UPDxyR8q8xSuWZ+pZU6vukTF7UG0eRZmVbgZAtxC6F6kWL60rTYP3OZrx196SQ8YO4Ffa84QUtzH5",
	"kIs1oDvQiKioR2jmFHpS4z93fsr3WrAdrp2LkkgITOCiktGFcsoNb3XuyGp2gVYKeIfq/pLz0Narp3hA",
	"64VtOicb3vCC+0YyZn9qEh5FD1nwVdZ+bS3JPbBzgT4hzEoh11N4IeTPLHwNjry05ed6wTjPjYLxJR8i",
	"CwEr5JsjFs3Ryq/1D+57zcqJOfoT148Ec3bnfXpLLlU6/0wNadYd/3nfmCxfDCVD9jPZ53ke+5mxZ9je",
	"qGhfLP3DlTyqEXjVHOKjFfvK/aJH1wsrCvxFlt41xDSUFQdqYoHUhPulC8olGvmcm6cvrNfU2Jqn1zbD",
	"wRom3PBcUfxLI5wu+P+fvSzJwf3llqXzqP+myxOd7L+D1dmY7i+wSHuLEwLXDI9UjqmUT69cVjNRZsmn",
	"VBLhZqR+HfIyVeEF/3FVQV77h5QFhW9H40PXOvi41uDoFReivLD8XMYyrTRIhqsN/ggzTan2PO/PMpnl",
	"s8Y7VUlvLHDHrK+/2nzl1FoYsAX99tVX7I3Qhp2UPDFZgpZJn+1as8YhwxNDUElcdJDe6IKDayjxwGlf",
	"EhPtlbh12WoYP6ZnkHjLDdfCaNZZ729CSLY1imaCy0xOrio6tziap/iYTNeH0ZVW7YoUytpRUttxZRwz",
	"ky5VzQ6KskVJFKBltRzNlksTtAaDSf/pfbhRDb+RL5co8ZadJBDQvX6Go1jNPPfGrnCUPi87Ij/j0IED",
	"FtvnLznprl3y5LpCiPhnHUrsEqBvP+J48sBxpC6Ab6CqzymAWMOzZO95HsVGNrwf9wifIFywPYHmblFQ",
	"sQsui4XBsYybT+N3eObp+Qs5KqjHi64Kq2QXHeat8m+S6QvEv4WW+wstBNvez7UETDL9YiuAIiDagIMc",
	"qEXEVBtrXfdlGxgRBn0tpwvB5zFrCOZuQAhZcN94J2q9zXjvs3gjC1/PhNZ8IggfKNNQV1W2wsdmS7hu",
	"fSLZ/i6ySFJ/nkR72SQtQWqVFw2x//QpHLRtmqi2MtpDB/746sdd6qEiICYbsLFQRDXCb7xYOUVk60vv",
	"YvbpnS9xawB1veTWILY1g1/zdzuv/gohbvfiPMLT3863u7BnPCxFax/gH0+64ICJXmlX982b8VTc/UEv",
	"OCRlt0LewROnd9l1x5IR+3THk9raa4tQgHl48XXHF7ySzmpN/d0up95DtWU03S21+VX2aQw+POcF8fr0",
	"Zh+UTdCHT7f62sSPp+kfSAlsp2nQAZDM+AQNsETH5kq96Bj9mc4MjVCzhEuNxE2Zt0fA7rV/ynCldy3m",
	"rORyIly6kYsfmjGuR1KK2zyTop8KIi/BULEOBhl3ByyEDgMkWiY14/gOMf7ZOkfS9t5WZStxdSNCjn0p",
	"JreiNE8iZoxTO0cyMy5X00xLVU3QEdPsJWzcgGNqPHuV6zn2ddDi77Ij9pOY68+04lzx0VnreZ6t9iji",
	"hqy1zlYPkV1hkrK26WEc/fujFRz9pwQX/gScYACh0YnjRkkw/qVsfjt3S9dSWEEvMfdRiax9uBbz++U2",
	"P7z0E3BxPahrdtRsxvvE5itSb4tHLmzibWoCRY/kcuhI+6LV7BEPN6H+6C2k2UdkYahky10U9zAubrRi",
	"XzkS2ghEENIuP2PA07QUWg+SzMzxNQcnCe8QifhgFZ/tuSwLeNj3TwdxHgs0x/aA51F7whu6d0EB0EL3",
	"qAj7VS3AK25+zwHVAY/lkpAvrGnlEUX9UWbiQ+yEjx7NTwFlKiQS/8ssTFwYtAazp527f1f25U8iCtqH",
	"STKKkWHRWi8S8n38AXEmyon4vdouc5lMSyWzf6JRci1E4ZBCM4loh+jBc4BpkNVNqGlIMXw2VUV2Ne+N",
	"5InSZlIK3WNnm8i7L+d1+DX6csC2c63YtVS3knG9RaX6xiCKy0g6NFR41LMatQRLkef0i+gnajYTZYKv",
	"QBzUG2WmVA85i7QBrmslmeNMpkZdzjFlw479tZgPGLmcNJC2i/4tnzOYPlC+++SBkuK2jiaHlcFdI0HZ",
	"JVO7S3nQObzyRJ8Vja4rgF9qMMVCOazgE0EBXB7OjvDY9lMxK5QhsMQjhTOk7WvsUphbISR8rgfsjF8J",
	"xCsGHJyRxHO4nMMLwJhsVUJZFUaklD3v48cAS88WTRejduw8NG1t2LdP9jXrOBlgvyi1Q4+6NIEs59eC",
	"iTvYxUAsbnkppqrSwoUIG+WG5Qo4Tm77OUfQzdrVKbXyl+3To/2jdzgCBjLj6QpZukB8mDRyPqsbUea8",
	"KCCp2k6LHozkGUCh9hNEUoRR3D7ZB8bKNosVcQYBZvAzGa1RDb/RDW2tBcsy6eHx40n0/wKGaKQZQYpb",
	"cSMjyY+VX5fywTicBHiJ8vgSozVkvD/7/thZTp//1gyyzz7n7fH/VTmff/y1g53j7oCTLJiKSzKuWuTf",
	"pWo+//rYp+R9EUMqyhoNuYBwPVUfhN9bNimDH/HwGXLZfULiYrIpxhD9O+P03xmnnynj9KUq7Y+UorpU",
	"PbxMRwpIL32ZlUAfA+DgFzEWTrHCz2kuUBXP0iEbHxFrE01A5Noqs8lElE+LLmlzJOG8uHAzX9wf5gLI",
	"9cB5ccGA9kGNz7aEo8H/Tf0oVYtM47EfMfM/k0xjPh6++nsJ3SWSADQl/oXPgji9CwClj0cEQyD5QwgC",
	"kE6v4ZyI1wc8zwE81QME6Lk2YhbxtwIrXETyNmhxVmjzHmr+VFFLdXX3fHL2R2LpWiTLi1IUAPpb4Axg",
	"pZufv9K3qrzM0lRI1ndQBotz/eXNHVwy7COCvCqSRLdUrGTGy2MNBemRFULxLD7EjRx9+TyGgRAp1DZo",
	"Q9PYwQ+g9o9cFvXVEGZHPznS76Q2o83A0o9eX7/z9fQHkWDA9yB/8qKQPSTRH+z/WiIB6y10FwLRGaBd",
	"evHFdsl91Qo5Xrog7t8G5PQNT9lpHdXUyTTLtEdq+XIIzzAkvyHA84tlEKee8SUi13uO2nxUzt4JUI9v",
	"5t4u/kwGJbT+WVrq30L7B1OcRADQDEL1cts4w7W1NLwCAmOF8oSb6Yn7eeWp8BrQFs8JM8luhAxTi2xb",
	"Wt+qMh2w937GJUTQMAPcmUUpEpEKmYjBkuRNr50/V+6mraDm0GgRFkiihKtaP/CfNsXoJYs6tOx3tB1l",
	"5HvMZFGZsNDXnCSwWaZn3CRTWu5//vyt3FHyKs+SmvJhPC8FT+dM3GXa/BYY4C9WArUE2qcbTH4GWhw9",
	"L1cSVRszC12AAIOUm/Yn7ZP4pa3uxDX286x8rMhV8sDqPxK3oQ9PX/yfTpBo5z7EHL22JrpePOYt+uKq",
	"QMZjB4wk0cb/713/uU4yUFtFWBdPWvP1I/SyA9OpmKmb+oEpfMnKyvmY0VoOsP6loMAqv+Hb83ILji6U",
	"H87mb0s1o339QZfz+ZSKDre4WJ9zVkStNIpd2jdsTelgSZCrK+BB33TwDKgyFaW+8BdIj0VC2vbalz55",
	"e89tzQ+1+ZFLm1BIWxRvy1H3JJp+bOLvRq04Gg+86gvyE2yPeNR+RyqHqZKdqpgQycsFms5eOv84uglX",
	"dizXnqUsUlGRV+4JR2ue51GBzztin0QK70tkFj/kb/z3Mfxf/Rhe1KRtibR/3gP5dpq603h9c3l0xWyn",
	"aWjpufqM5+x4kbTYr6HZzqmGVL5f9JD9BDs7tPPBfNHfy5H73yv6eSm19eXz0A6GJduq2ozWQ55JCHnH",
	"Vzx99BovsrWbdVjLVOyHhdjVLLlmmTQhNwCa4mIWKZR/+2Tf4dLuYJj9QXZZQj6Y/ZneIqQ6DZys/UBp",
	"erb7E2VX2CKPCyGhsaQsYGK2EEtudfWdAubwSWam1eUgUTMiv04v6R/0v/5E0b/GxKo/L8QZ9AwK+M/G",
	"Z32jx6wji5mj9p6bqZLwKr1QwC9j1jmZn+wDj/52nmPbeYlWdh/yEzC5pjD1rBoYrZN9n2KbqFREZLQw",
	"fG+tXRGYxHkOCQ03mbjtsSvBTVViPD4vM60koQNXWrCEa8EmVZYiz6AWyJb9t5mdeZdfCPX82lkkDU9V",
	"oruQCUFG/kQA8zqyKkNU010/zXSRc7wvgA0HEobP6I3Fk8ch0utDEzFYgs1VVTqJIdD8b/QikUKQJATc",
	"/xFeQIJaz6LgPvN0tV64QtzrI7wMWzjTWNDcTrWdUKnSOnuD36N4jh+kAqj+U0icUbYefLGS/IZnOQRA",
	"XVaBMOCqkkn8fSWjKnfKzGQJzx3EkWb86kokSJ+JxWXI8Gg/hVBE+AzL7t9mqfCf0rjRyGdygosGx48l",
	"U5Fc+/HaYuN3e+dsDZvyT1gkJ6WaCTMVlXbMlu4t+nMMpJ+qNOzVxnBoS3+vQdK08AVTPqyxg2QoBHXm",
	"W0QxLjjAPBcldDSTVyX3cNWDWBRbyBUWpdFJymF4qUUgUQgpDSmTbeI4YEjIgMKCbwRcJxAKTNENFGGE",
	"CeOE9oz4jEcS/6UR1hvXo++i90yAdELOiWsQtQ9V7OoqBPRiUaurFNBbaaNmruXizggJBt9gJH+ZZrnw",
	"SAA9ghSH7BTC3/TLRIsbYTXMpZDiKoOc46AoIaPMgIDuSQ1iCY1MlNSZxnQtIlz0w4NfHxcmmwFrBwBZ",
	"ZHJiC3lb5Tk7F3cGf7U6S6NfIpOeyh2PVUVRqqLMrOwgDfYM87mo/DfC2Jk+gyQxW7Rtbp/f8pKmAuQJ",
	"EUW1oxX0FKx4BVTHGV1dxRwGajk0BTtOCWug2J3lSuG8PoiRpj2aJnbmZjna+qDDGigxy7T2djylYS5h",
	"Npow0A/gM7eDpi/BZn4EmflBXObleOVPwB9+IRpyE/t3CU75yxswNbP8kTqtffRInXDIbqkSju1EX7jY",
	"wvunNfFpI+PS6h9paSsc96OA3CBlhD6wrDMPIThH4Ms1aWtLwrfFXvFci9qbL0WGv18Oyb47l3yWJZG2",
	"Yp1xW4vGyOY8fqS9Y9ZnxxJSqgEQCyEicA+wByI2DmM8Zp1SQHattKc3q/4i3dR9pDp7/rS1EWBQnvvK",
	"sEuABNO5ysVd5iwSnatbUULBi7gU9FmkRTVLM22VYEr8mQg3cQzSo1dXtxzk8rhNuMao2iR+VOs2QDjX",
	"2SkiOAsswO4s8htrRE9FmRk2XjL5Yzw5FLwU0thStu0yhH2VCtpabCMt1bHj41yyRv06YYPB4N6BXJNK",
	"3/PKGn//KmoirNzxSEJbbFPoG9jycLFoGvu5HeqpukWzCaYSJ3LADp2NgZYCXqwHywPe8tuj378x3Rm+",
	"gePLw5DvVoJcCIXfnwDgGjHJoch6Qx4vta7K4yrGUKo128asY1/uwpYcfr64oA/p2PYLchjYbbzPdX+u",
	"qv7TetYL1A1cX8xVRYDuz23OxqTkM8ffYKdvR80uHcbAaZULtxDG9vsxfm83lDEcC2eVqWAlEp3tjWCd",
	"ZKqUFkxJwbhmRZlB9pZtXhfN8PCDZh0st0eFdlnCJbuEc+Al6BSkk+BlxiH/b+zGr8fGi/0fo1ZpecD+",
	"xPynVpuoWypbVabWRtaB4ztPU0197i4uAJDk8Ui+USoXHJwGpEuCfkEvOgz1Vs3YadvH69o/FXde48YA",
	"9F8tVxPOIO9bozJn3K1MXEWIEb+I5KMJ9WZ8gaoGXgYAAmv89vFvYu5YNNieuV+18RW43sGeYke7j3ed",
	"rcLRY4/Mfo+N80xej7sM7WVoVYp+BAU1TIWfbOxcx24T47AsmSrtn7gsvNx1B3XleA7rkeYEDH/6xa+T",
	"PmuyqgdyFKOuhYMGwZOi5PlcZxqitlBwCKzfnnH8iAF/sy8qELv33Yp8qNIfzw8PmOET0M+gU0Nt8KxW",
	"nh+OPtu744npQwiR1+0watDqf4q0Gwra39U9W4nusYQbMVHIOo1U2nqwdHH22V46EUz27bC7gkscicoo",
	"B9IwaNFsfq5op8BKQAxYn70/PViz/3azTf3yVbiJ/YodIU0HzIdb1mFSicTDFomQyJp1COgYD85XueJW",
	"TvxQJKqSRvcYkIrYmUtUKWgILrF8W9p5WYk1WOjshueVP2l/xXa5EWvn2UxEzUi5ESabwYjZR9rwWeHB",
	"73zVGKK25uJTIDqoxyD9N5T/TihdcGOXf6hgIhS4OWwFB9xkpkrFWq7kBP7F4FmoKFdEmt9jiVJlavcN",
	"18eJUHrKcXJ3YP7u2ESoScmLaZYweBZKulSV3ZtBWkoxofM+NtRBc4VWemQuW/jPyFIR0LpQOtFxATYp",
	"HLSjqVlgJaJZydWlLfBNJq1+AI9AXFRUQjbjExJs+79L/CKsINAVsJ3uS0qFtj/uXy0YUdYMbViqqPtQ",
	"g12J0pqQYAPGx+oxrBtnsi9uKGP2//0//y8bR4bQwquOxwZV3sjhdsffBuqaxc9JhuPX/U+/eluyMmrG",
	"TZawt8jsH1wG3D0C8wG2W/S0Bdg5HqHHkYPHeTXHF8aJ/9gaS7u0MKItzH/p39TuW4/mBt+iwe80xIwX",
	"Hog67JsuBx2NKFv89n7k4vcFUr+ht+wI89d3lLQrz5nSv0yFDFZumOxIApzXzsX++iNSwygmCqzq6iq7",
	"E25oTuL9Dc57uCPZWUYbC04Mmqkym2ShUCAVghJ+IiVJux8Yo0st2LN247XVxNzDQJ9n2dcPGLo0PmSe",
	"WnODzNyg3sOjaItf3AXi12g76YiWHan7ABEQnMJwqEHJLOzUkfkCbwi7sTLYWMGZ3Sfb2wmFfcefb8Ex",
	"l8nJVrSom+cQQS69FiofrMvR9vTZdpq278TNLTdy75ObHvqJ9gbYy00DApaLtTHAEGBpVaIPHM1ij7V4",
	"NX/ozAs6tlCl4bJmylx5NfLVVw7iDDyfjs4ouC3bjiykW6b8RrBpNpmKMtjridKGpRVACQQh0pmuG0RU",
	"hF2xVxzc8v5ke1kZOtU7N3ph7Tie4yTT5tU26qD+YoHzrVI3opwKnjb3PegU7lhRi+pKFc5kqds+oE/x",
	"NDTO34U1uEATADgd13SWYdpB6vlGWY1Kc7DrtOz5+QHrWJukf676B9mN6EbKnsZDhwYycVdkZTCBIVLS",
	"/lGjmuBXdoB5hB2TBp7Q3fDaQtddDN3lnHHI1J+UEP+V2A2qKtjf1SUrKwmXBwrPQqf8yrBc8FSU3vSA",
	"G2y2ExOU2kfuBwG9vrUKHRMW4CoCMQLwhmNsTH7h2jxudXs7Bj6r5jC0xZMYxh/jKxuvAsXhg/5yKuvz",
	"+8uB19pRGD7qAB6tBP9tS7X3DzDYtXg3f1S3LDPsVpXXGpgl+ywIBQiYIBGqAxC5MfW38lkZrATScZrF",
	"NgatjMs5I/48dBPUDBiRMm6I3CNTEjaVN4uiV1ZSW1u8nLPNIdMiUTLVLUKI8LW2D2m8IoBbzh6n3Lq2",
	"O0MmNMtmM5Fm3Ih8zjqX4kqVwtXZ9aiNCJRTCmQiESnrrA+Hw7h8YyU4mwl0FU2Uv9GHpiVKaiF15Q+/",
	"O3i1Y9fBqUP9QfPH3Z9yd/1j6gcWO1JG8NSu+HioH1kkeIp5YIl8l9YeRtyDdC664OZpawiq+vwrKG7W",
	"kkVkd3q8SCQWRW4EBAEsri9otGd3fOwao35V4QKYyBqLG/aUywYCdgBBouUYiQeZrgRbWpQC0EIzWTPz",
	"NW5M+E4m2enbnc3NzT8z7LwLwBpvDDde94fr/eH6+frG1nC4NRz+b/T9hfXvnHsARA1132Y5BiIwiN/y",
	"6hxO204lvMVhliNpG+1ECxDl2TsVqQ54D23PzaG2B8ewnOHX1zP742s2y2RlaPPfeDW1P268YlNVlfjb",
	"d+Bm+Y6lfK5Zx1B+Gdds/dvvp2ia2n/Zl9bZrRDXrs1NjmxU+VGYQCvb7uKKWZ8uWzE51+aCQ9SdlYow",
	"3VSX17Lr0B9StuPaZ+MBYckikI1XAkoiwjy+Z60ouB9OUVdj+QSTei6sLWgPNTscjOUndgx2y9Bo+7Fg",
	"QhrQl9RyNxXUdq++qeoDNWGnCoOLnljr5rA2VAdq0mahuLR2rHZzCNPvDY+aaTvl9qQhykybLKHJDoEI",
	"Z0aVfCJowVmhDQdeDPRImQN3t1vDeMuM6cwI8PR4nD3urHcJQxqk8kihvyEVWpQZz527UgqR4g4KNjPt",
	"aTrhEj777/XhsG+3lDtvHU+5hOdga9UQ4dmlSjNcGIeZzGYco5j4RHizl3X+e3PILueGDFT3aRdHAUMb",
	"3sJ+6MSiz+iK6FrMqUdWuCg+KFidnf+eZUmpaMV2qdPZrLAnJSUpFILQe6HYhBPC7yzLc5D+2FjFFu3Q",
	"iLwRU36TqZKadNq66Xc89f1ljpcjB7D198FZHVjROkWJ2x5LKwzmFGD0wCev+1gcm5Q8gcyATKVMUFzL",
	"bZkZcjAgYVspqIQU7RM0A1JvHHiDQHcZVQuzcTsV+cxjOUKYkxPWekSWlcCINc/WnKvJxF3lOJFxIVi0",
	"SvaP3h4zjLezldhCYls9XmU/bLzyxVwA8vMNz3/YHGpXCsyBSFlV0CKPDSjwy/7waoNFxb2e2Wk1PL+g",
	"939Y39z8rnbxcqhSusy0TVs4EayubiONLqw/hVmuMFp2akkISA3qKDKmfj4Il5LbRZFnEO1nSsUTk93Y",
	"tdvwien6hhcybLHPcD/Hy2u6e/f2oZ9st2vP1A013S0gYZots32aFWZOVwDQxjyP1xPBu0EUnFGoRU5K",
	"cZOpSufzlpkoxYxn1IidKZcT+6mrcfmQSXHbaBxert+GvZnT6MUmcdvY7YXWlyLheVLlhIpimxLmMHIg",
	"ojQcZDMHO+nupXdylVw3gd99SPjqKl7TH52fgH9kLhOW2C+0CzRz4ZQQoOmKxAVAOgiithZG0e0jxCzy",
	"3zX1QgW4RULBvxAESBeFSSzJEHB2fuDHrzlm7toQhJrKCkY9GES2CGe/OeNNle6fR1yqOPxxAWxsMfgR",
	"SZUfDH10eJTgsY9UD3qVgNw65l1cI87FXg3SGmH4RxJh/RwSZc85PrKbLK2I+Yi2SefnRw7L41rM3N7V",
	"VZZkCOuE1TLloGyC87c2sJxp3LcoIwSxcaHlI+njgK21VBjy8TkiSee0vhbzPtwisYJnpe7WGCY7/k4Y",
	"dn3X+t3MrujLysrQecml5onvxUJgu1GzLKHLYQgLxv2FmehDDxjur4RUibe6I7nRL6Zcw+3+LDOss3Gy",
	"Y3cZZVSi8gED1zhv0uUyXXCpw6hhPLLzko9k0+lF8MWZsTY0Z2nUwaidgyUuhPUBO6QwM4eQynO46BKa",
	"/XiwE1mwEDArcojmiTqLDRzJjQHbiX6lnThqAjEn9NBNmGQFhDjgiGbgS9UjuTlg2+gFA5pJEyhYRdqr",
	"VYuDWqthJF8N2Elcut0UpDLoB+FOXaGKRgxVld9E1b8esFORKLBccqUKb1hgIXT/52H04ZKRbNq4bRTD",
	"jWP+FmP93RlxddVfEzkqCLrx2z7Z9xqU9dnfrV6pMCSbhMStCyoH5NOFujvTB/UrxMhjJDtJnyoZv1Sl",
	"YUZNhJmix8Xuh9Bdq3YgFH2xFziKUy7TXKTsJuMwkX6ISHt7FWBL+e+N4Uw7RR5FWOAiMo11t7oa2f81",
	"o5Y+QO+N3gIyjc2EvQ6Fw6l7SdmNdiATCPjsYd4r2HhdmdFGcqtKbfqQhdFZ6C6Z4u8qXnJphJ/WaApI",
	"XGHE3RG8g8okM/MuXn0sDDMmSfrJYB2786NvDBCeZ00pxMg/zysSdYp1guFcF1y4eeNXotugDYntD6Db",
	"EGgaeLITlCqSqBjopCjVVZYL9idrPjsc7K53uPcNhQmh6gbuZnCKuEGKpfFNlV/TRYhLGAXdmud9Vfal",
	"slv+hGkx49IdDcE6gW0NCS46u1aTnc1lAl38v4Emh7rzEQw52SI/Ts/jzDcYcXp+h11OhPPAZoNH2AYb",
	"B05BwScuEq8TOnEt7IrZGLAzYfcf/B2IcIyqWzRBOdpNhAYF6GS2WFVgD50fbqEzD5D7IKvPK7szFIIb",
	"UGdS3BlsRZ/JGpmPV+A1Vp+25Ub31yRTa4fzs/86gMvks72DvZ1ztsrenh4fOiIfzY5Pd/dO2Zv/xbKU",
	"Hewf7p8zOLsev317tnfOhuORZKy/QP6z+6ZB0lMj5sFvTitJB2kXaDxVVZnP11Ke5fMuXnFyv2J8bCou",
	"DLtvQbshuQiQTyEXcWO48ao/XF9zHRj8XSv5PwHz4ocsRV4koGD8YeN1rfWR0Cfc8FxNXF5FqVUZyQl+",
	"Q327FIma+SwR0DpUM97k+VZvMtARB/xaYNJX6Sk7IcCFdcZ2Xa4Nh8N1aPO4x/wvG+6XwWDQxfrRIEa1",
	"hRIDqz1wJRGDEr59QrDgWFUmGQxIj2kr3nSnrFG0LueeUco23Lb6ssySa90iJanIDUckkSAo1noPklIb",
	"40YTm3RO+CYmzdRonSgHx+5S0ecY821F/I1LQHLGjmfCImMHJxHoK8BHRWlmfUd3xWpsV1hGnTwr8GP1",
	"y0o2+LBajJEzJHMIqZY9u2RLLlNbEbpj0c/3pViq6ByVAC+fTBkBrsNdK4aF47EMJuSGl5mqtPcV2kdC",
	"UsLj2IrR1traWsHNdM2oNfwQ4tkUJCJaMSP3VZ+N9ebW2tpllVwLA5/YF7dn/J9KsrNNW7/Dfo/OlaW4",
	"rLI8dTISocEzLXmhp8qH2bGfrMQ5t+pI7malSEx0UKOzJFGaACIHhUu4E2c4JOIOlpWsktk/KtzF4tN0",
	"E4B+8TAN6zycVFvO0sT+4m8Vyc6ppe1dNYJMe+wGY/AWAut6IxkULOS+cWu3UnQ3nMzt3g1icyqSrChh",
	"jk65vGZvgbeTdU5P3/rDKm6WtehbiHiFENwzUuBweYvJdUQrMpeG32ECiroV5VWVs6j5mZyA6MCtZT0V",
	"LrNb5fhSpfMtu1oqI0rwNrkAURxsVdq3to92rV48PrX/PTo+hxdPgSQ5FDUXvNwCA1tsDDeGmJc6La3F",
	"E14arWC4TgEPRiveCXlGhp7v6hHHPOqcy0nFQ000UQvTgsyr8HGY23Av7uNLXNondIE4dZyVCfshFVl3",
	"pzl+13BUDwXOVCpyP2k/okRgS3CKR5Kin3QjdMnV6zQtdq1dWlqC1G1hF7awC9rg8VYUJMNFMkbT6y5U",
	"Ryuu3ug7TEO0mpTjWTzPswkEd7r7MzduUQj8hS3/QtrDTi3knQIF6eoCuurZalHxXCGXDhIpoUXoxPfK",
	"X3n4dQC/sJNSXGV3FFCPdEiRBrmdKi2QlBj3FiJy9kKP3t1GvgJWdlFg0SuOincLbpKhL05G4N4CioeD",
	"Ar23vrGJV9jw16vX345WGq2GdT2S20WRzxmvLV6uGZds+2jXbjcYB9nePD+j9dmlOPT5lhHJVKpcTeZQ",
	"WmMljlbuXWeCRx1OEBj5DnrKnh8Ac4CaJlOaCPzB3975eXQd28NIrGgmXNhfo7edo+Pz0NFuo6fClfto",
	"Z1NRlAIhvo9PCSlgC5TdjUijvjZ8DXZ/F85/QlH7eHcJHmFrw0NciU6UF9qSy+tMTnqUlhwhhYVynf4+",
	"3X7HOgQ8xfP+djWxoyFS9s4jRXQxULSxC8nUgUmIEGxLquDg4JAopRf0T+mqciXBa8RZ5lbWA0xjsf5r",
	"EF9los55lYQLAR/IGeoAGyEE/cJu6lNK9K0o2fYEEvxGct/rFePorFQFPghcrD6CDh8GjA0Yg52ca221",
	"uQ6DpxkIicYramtoupBa5L6mwRcaUuvhGhZVbasREI9JiIDm0AvNOnaXdZXpLosDsfd36bmmHagbT0dC",
	"LUfPTI9RxKXuuWagL55GlAZv38sc7SWnLhe+zX/tQAFAFVgTCnOiMJ0+ZNPbCtg/Koh49fp1fdDctVy0",
	"brBA/uR36C7GPoHWGDe3IIrebGwwY+/5sQdrEs1SoGlNd1JW0y63kgDikOewkF2Ic9Azta3UWwReZ23Y",
	"WmktB02MXkohE5WKEjdxOmlAPouXb49QCULZ91PuoQkGtum2eKdRZkColCRViaEhXC5YC1FSb49p5Vy/",
	"M2bVId129n0wnGsK+eKMKthriEVA67FpF7Ru7xOM2M95ATeYbleHQ7l9Y304pJ9K6kwtYIwEraRIsDzn",
	"M+4jwUYr0CsK4BJyknC19l+3Qm723cj0h4Nv32y9Xf82+iiKxqklzy3EX9lJ3HSiw07KSsJM0g6rKgPH",
	"VhLrMHFzlgpDiCw4pxNewGlUEwjOLJPZrJqBm0xPVZ62wze0DugM4nUEywUvZYAssENVycbozTJ5AS24",
	"AH1mnw0Hr8Po8Tt6POHFRSHKhKLzNoeD4cJo9Nm4Ud54i/0kRIE2iuu+38gg6lIb9tf/4Sm3VEGvYWlt",
	"1Y/tYVoVGAKMGV4sLVWB0g1C/df/4R1fEDyZVCa7EXU19hV7NSB37Zmx62ECW9UOJtJO1e0yk7iM9ITL",
	"mMVjcFlejVmHglW7W8tOV32nMNIeuiXZrYB7JjZT2gDwEgaplfpqbEvJOTT/DCTFFyLtPp9n/6St+lZk",
	"kymNrh2R7Ar84Caf4xGdZ7m6EeUY78RD37KrSAeEjQ0uBPxQvXY+U287o64dx3bg2CU6R5YrBDEUpSCV",
	"0bBlIvtlJEFvR/YL7TwOZuWSAszhpFTS7yay7gQvya+xulrLFcEbJcryCLuQ3RTd3ktzugXe4bNgpdfc",
	"lKwTRu1PXh7QL4y621lvRjHJy1LdglCnCmMuNjGXzWkxCD/28q7BuYvF4DpFnQ/Io6oyeSZKHTseFgge",
	"Fz0PDoTmAdeDw1kPiFp0msJMmKc7HbAIa2zNVMrzZl4eIkp4J0IzRcHcKp8jjAkQkB/hDYFoO78Z+pzb",
	"yAOBFYzkm8ON15TO3Gw8Wa5g+Q9ClhwcrRFLBwNemvBB9fQvErCdRghHS4yiDwGO2+51cZyBALkpWXrn",
	"H87E7MKqTJ+QXo/5PcbMZAcS4N4es46Daepusf0rgPPoOZAyHFarZMRMAX1oPmedSgs42qqSGQGRN936",
	"fTFVYsfVnToYzyeqzMx0ttyDwzqY2hVcON1WHw7rLPpwugtOHNZZcOJ0F704rLPoxen6zAKc3W/0YjZo",
	"mGSXckb2tu2U0Y+kTC1m7Xuh5ddSkrxSwuxZWDcksNtFUaq7bGZX4XVfCl5a1SWtMr+E8dn+6eio66Bf",
	"wEJYsCfrAn7TzM0dLB45G7P7Iy/TW16KPk8SkdPpIs20gZddkFYUaHK2f7gLuQRllfgD2N33365tH+5u",
	"se2f/7qBl4I//7X/en0D1SxdOKJmoUbGoFd9tn16uMWO9o6P4OOzwz3WOUt4TsFIpszuAkJKl/m2gu/G",
	"SsybzPyXPUNI40LB0MObVolIndxfKWWKEsJ6ZOoCZkOS3pFi707exxEQykf92tJ2Tt6TfklFkat5FIba",
	"krj0iGYgAWlRCn72anohzWbYezDBvn9FP+PLL7aLeZ73rb2Zz6LnVUlPp8YUW2truTVjpkqbrfX1V5uv",
	"Wmxhn4uQUuKx00+ueeMttkf/rIfAwcA608NLsI6VHc8bhfqhGG+5xeV/Yp16ErdrgLV1annfXbq9EHk6",
	"3qIEYgi6vPQBiX85Oz464WbqHNouG6JxMhjDTw4ra0C7n/v96wGgE19aA5vgUoyYFTk3YrzFfoSglktu",
	"DQf6FTUL5nEUpZoVJjLN8A7F87nbAchst9ei7RdPjeB9DyGimEG/xqs0U2tWOFR9/wDD2oHeNbYK2sf9",
	"BJ6QeLVu5y2+aCeOGmJ3rFkU5KIuDX7TPwaZZR28QzqE42l3cTk9IOgPi/mThNzJ94kqqpzTcVxvsXEo",
	"zs4xuJr70KO+w0+Z3V3yjH7LeTkR/sgIeLT7j3alEJJnbV0B0BY/tv3Nvp4BBgy9yYvs4lqQe1Jf9weD",
	"QdyVQ9eF9mLGrLP+evPbtNtreQP7wTqbw+822t7gKe8Phxu+DA98odQkF+ydsEP2WMcn+NbjHR8OX0WH",
	"W/V3kRhKixytzOZ9+im4FAg6w7nT+/Y4WfJ8vV3Bfvft91HyTU22cZHF8Bd0KsAlFhBOtn85Y29EWqrk",
	"+rFeX9JrbaILl6MDkxkuIyHr34SWI4CH75k9V/fXW2d9eWFWaJc+3bBPEzUVpRjg70JO8kxP+zebC49g",
	"kPJMTiqe2+cORjaM3b5Pih5J0t/u5JFwH9juQT9AZ+EhAxSXs3XaFV/I6QGsrzOvK1nn/Fb1zwyfiK7L",
	"lMQygp/N+7xhSutQQGYqyGWGJ7voYat/ZvlW//m3ctig3b2aH4EXFpzn/Ia3bvpxfJU9af8cD2dnDB+O",
	"u35U9cKwApSJ31c6sWLtejgONAko5w6XokhdXSjaZBmsruK+AeEpWHuP/tEvphnI6iW/bjyBTzbHDnDW",
	"qmcEBS9M/5Wy78G/+qYqL8OfChpKX6Fuw6/gn/2NwbB/lXM97Yu7Aj7C39cHr61uavwCb1JZ29JMS1Vg",
	"XO04ybk9dWz2X/e1klKY/sZw49X6cAPXpHuqikrDk+HGxp/HDtsWlIoDHcdCB8sL7N9sbA39PnWEjqdo",
	"2XYopsQtIQCrJs+xA2BIMd6iVVF+zCpZH248Y5nUNpGnbiOPbSQL8o+T/o1e9KNbLYYjgbchmHDpvImo",
	"13y+LPfZgjV15BGgvcQfijTjlC8bkG1QGUYDTqq0F+dgccl8bCyDHB0w8Zypdsvnwd+yP8N4QRAhrsW3",
	"rxjeR6SsA0Fb70/3uyBU9q8t6M3a3wsx+Y9LeLuH8cz4B57aXfwavVzIp797Ky6LB17GZr4/PcCQNLLl",
	"EMEOcekBum6T/kHBSl7It+3WwjASkP3srOIXFkhoO+H+Da8rbTfaToIO93i0ckJRgidTZVQIbbAf+vTz",
	"toHOfn5zfHo7/OndRG1vb28fnb2f7r2fbDdMPsTGosNF/w2cX0/gXAFChBnj2T/R710HPkiUvBEgew6j",
	"hXy4QeJR/FqOMZ9oU1x2HePyp6m22kBusQ8fYHjv70cjuePu6NmHD+6+Hh7shvLss6j4+3tfwafelOsb",
	"qJsWdgYRciFmEQ6cVgIXR9aOt2ddmPrHf9dAXzGpslSsUeIZZW9DmpmblpbU6IRDTiqGuEYZsogxQ3ca",
	"WyGz3pVuD7p3pl56KRJh9w1AAaglH3ONjuE7E7tMsKfU8fGHDx7H6v5+vMX2MZULPWwQwEevfZUR1Ob9",
	"/WAw+PBhLbuCD3ZcKAfPWa4mWeLex9T3suRz94X9BSsxaPPBU+0+qGRutbaPDXGf4e/UuhtRQnaVr5S+",
	"/k9Qwvf3VkV8+PCf12Lu/32Vldr4v3IOf2yxA6UKBABzoQqrq2+qLDf9TLIfRV6I0gVtrw/Y6qpOyury",
	"RzPLV1dZnxFLGQrwmjZzCHqYaMKiMiVPDKbwEhhvqWYAIgUiOx6PgxzBLx8++PLZ1MzyC3Jq3N+7D+D/",
	"rmLNxqibsQGkm/FKiB7YJrnfAfwcvwd2Jyluc4jewDymS8jsFDkCW7BO0WNpdtNj0/X+9Nsey7MeEybB",
	"4GcWYiOKnGfUPYzdKgXkk6WsFDz1vBdwZbO6Kv4BA7fn7mdDcK4LtXVTqpeOkRXCjviHIwYZrWDi8Gil",
	"e3+/Df8kwWy8b+XBGuaYdQWvO8xFkOn4K1IVm7bNsHFDs98J+VNmWKoMeYhwT0ebwy4/24fFG5mlPcHP",
	"qzL/AXaZXW74+9N93/Dw2EwzPYB3Lqoyb3kB/SlWNRHLJGgl+GLw92KCoVAL38B+6tInXHgwflTIZR81",
	"I48XK6HBY4zFJ4f3pwcI60hpECBFaHMAHGXd5nEmjw90WGb2DAaDsZNJbzewtchwYH32i7i09etmbJHH",
	"cpsXwgUIYHoBCzHWbUHVwDXuVhPZJazPzjb7INEGwOxc5HaHQFToxeaAX4s5gi/DgAUsyR1q3Il3J4Zx",
	"W11FexFAIdWtzBUHCOBSaPCbd7Irim3v9ur2hB9YX9LJ7luNu8mdcVoLs9hAaWJOQilkCvEnnDwE/nOr",
	"z+znp7DcczrEh3LQVDlU/8zynNNbXimgjBCbFvS4VLmXD9cz3D2LUtkJwvQgN3OOicuFcVj7B1UcgV9P",
	"lTbsdpoZkWfa0MOTMruxe8/+Cao92Nw9+sTZ2elbxo3hybV2ouWagjBxECmjo016fTg8fLPwrslmQlW1",
	"FzeHvkiYwciFvlDoxvDV98VdD4m2aGadoJwJscXaSaDWar7dr9wI9fsJefhfgSaGhXaulESNDH96Epvz",
	"4+Mjj0Z0rq6F7B+XGQYxEpDoEcHFdJeqt1AFAwWGCH5eqbQ/ZrmQEzM95OW1KH9AyGC7rUvzw6vHPk0F",
	"jKEofxitjEamVSFBz95SEn+ImVtd3Rz2vx3+D0StxhssvE6iPQpXz1/Ojo+chO0oBFGhawpCwtvCO8pG",
	"jroTSshNxx4iaAXE1Nud+W9fbf66xXjWo9v9We42+3N+CX5wmg5beiWzAAXgORhcLce167ODg0NW8FKT",
	"548xduzdZ6i+4hEfs86lUnl3C7Azv2IYUwIQCdB2xHuOhNSUlfD6FydqDKDR3S3wOBJjGdMFT2CZBfH2",
	"n/l5G7MOhmZ33d0QHdIVomQbGgq0GeEunY1prsfuDe3WiDsZqsoUldmq2VB4Vc72G5x47tLYJ8kx5ErZ",
	"Yn/hUrBdhXqvfcIWZM1DxUU7HsjfWY0Vz6/jiA/PKCX7OOPwb/r6nWL7tk+eCa71Y54X10JfZ3JtovDj",
	"kfzF+z3c4a2Hd0J4F4dmPssAASz1bhTIdjUIJ5WV0SE708whJol0UMMD3kPVb0cUtlt3n+e431yNnp00",
	"3GI1r/4QPxaLkxOCDkczmhhJAnCyXwXPPAFHR11/mdh25q0fSZcdRpefQxtnUN9VklJ/zep9FIB+rgpC",
	"MPGYOWNMMKCrTeYJVwjYGTaLohSFkKlm468HY3cHSzmwjpHm60HL3SkA4Rd5lmQmmjd6H+hV/jb8dYCX",
	"5mOv0LLoZsHOcNj8UapcijKnxIuBQxGmC1my/RE9HTL5fTwQJgz6PKo6bUogGazdbbsR9flEGagBsG/2",
	"nAvlhSLih+qzOyqOlBFb8a27XXNqlhmMQyecv8smfDqs6cih764FNr9/Fe7IIvcyLFGHX+jcOi91IH33",
	"7fetHiLvGPooj8+L/cuLd4zPvKd5qObmfcKSmOWTsM/gZQc7E6YqXu6af7357aJ4EgXJ02UzvvB+zpX3",
	"wqX31x+OT/aOtvcvtk/2L37a+1/3rePQCim+ukohwMEWvs20yAEK6kfEr/aPtE9kwKj6ZA7x8x7MmQ5d",
	"axQFB3jX5FYHmkvvMmuhr4rDVhuahmXSKDYT3KqhqyqnGBEdUSvhetIY2Tx3UFjmVvW1gWNgEDX2Jx8h",
	"040A0OFY1COAJPqKmBxQJxOBKJ5GbzTbyVUFoFsUuAGEAHa7UIXdFNcKe85J5j2W2BejiBAKUyGJXNMJ",
	"d0hXZHbFBgokUzswc9q8b/21bErMlIjqdOUieviNylJ2O1W5CHkSNZDFkNuC9owtZzvGZD/zsX3nkL6C",
	"r9Vw29cWSaXqUO5buNuuD9guJhrGGGuLGOXgCWgFwHwQQpeG8vOD6Lpwtc/A2tjKPrCM+u8JMLkbjsYm",
	"jny3hkLr8EYZpRG4dwjTrQ3sskDf5Y3ZdNH0dnsk8gMirWprTXs2LTUrSkSUgflhK+dFi8oDg7cNCx+k",
	"zVNfyEVY/GDSEfMFXRV42qbuSCKsDqIkeRR+4GtnHCz5EplPB/bEy8g12APE22K04r+Ev40qUBByXtgt",
	"AN29LqNReFT8XcJ8+MXWPeVFIaRGdTBXFTidMIwePvifDqUDnQPa/Y4Im4i4DfBcTMgyS6Z2hfWaWGcE",
	"RBAlbDuEvgB5P2A/ilJ8Y1vCDUJTFiIx2LBQKULvsA4h7jvlJcUtheABPAWBNNb8KF1/U7vtvjoStxRl",
	"bxTbczCK54ga6EP0Wnpe796ycQiqyx7FbXdry+fS2hry5PjsnK1hyuLaB/g/XOOs0UitfYB/wG9PMDFq",
	"JsNgMFhc03u+fX7ya92hOyU/HPWrTewd8hXVJ9ChW0ZIruHlAHDZRI+NYi2XoMdCuiig4hLPA14b2N2c",
	"yM2LUk1KobVXFYeNB/UhB7ibp444Dd2BUteMGzYGJK0LbAPxo4QBdfUBBjC8GXKty1KVeC3pWPe2QV7C",
	"fPjYhNbkonpNkGrUay5OICbXiLALMLpbLsrYlPMm1u9bnuUijQptJ6gwZeY0l7grlLQbPc9h4tXV1QPT",
	"GRD4GhPqUJmxbEQ4DT2zB7RM+mwjMxUx+Tfg9mVXTKsZMq5jBwO0L3QrQu1rkZzOeFECmrN/P0a7DkaU",
	"nGbt5OwwKlo0J6cqBYPgrWiom5iyMeTRTcab+yxcAjgdRp7j1dUdNZsp6brJzhIheZmp2i2nPyQDeM37",
	"wIjvvVjRgNM0NCYeUwVFeZMlwsHbae8fb/TD7XcdF5wTope6rVlRVBB4EewquAAfyVYsjERPFJAfo2XR",
	"AfF3EJRxNh486PrrylMrc4CCC/f5zovrr2hIiilvzpRz7xpGmh5yCkOQs7PRvW0Mt9/o9HeO2zKcY+zI",
	"/6NShkzVxbBufz8JsXioIICuD1D/0QroxdcVXd+BgwioOkpbR/xkeSO0ySY8ugk7pSnWRhV0Wzzjd4wb",
	"e5oyzWmlWcVN2jMzwrTWdNXq6lue53YIXTronITwLST5ZCBLsOThEqjnQTFDaqUDtaXv7eBe8RzVC/yx",
	"IDi3SzUkzH2r8/BxcBVKBzKinD0CrVJ70yeflRNx4TpBli11sR5TdD7NtNeMHrcgv+Vz7WBQXLKsU3VR",
	"yLTVz1VYzX5z8bDUaM0swH6fK0IDJMXSTB6wp6tSFegodhs/GitsvLt3sHe+96i+hBV3Koge2UNgY1Vb",
	"bNxi6LQVsjmITA+4zNILW1LfGRZEiK2MPfJFpKLOyuzUkyC7zoarIW4rx4rkWE7j2kbSoWhR7jQcPnEw",
	"CSCAp2LAGvHYHZ/I1qVF0wSxXTSAA5kTQHS9wZCxQ/53VUbmu1tekFUAI6SF0T0H7EWBZsFW3XqKrYkf",
	"++WCf/poTiyzT2X2idRkSYoA3JDP5nQ1TnBoHkpwIcDuXckLykSlpGxgWD0/P4BQUXgaBhVYOd2ogmYC",
	"vNNMST3NCvSUOhAJU3K7ZQVMlQE7yK4jbJseg+Lg4KZH0oXitlJ/ORO/ECXyHiPyf7yMAmFp6BI7vrE7",
	"qLhd7AyiteE1jbXCbCN8Bn7URuinA6vJCNqUcMBkSiirtiVSEK414vD5MoBtA8fCO+D7U1W4CIh+BO4U",
	"jybiuNmDRhR2Ngl9aGcZ8QcTN1Vt2bsqyXh+AW80BeIrP/8P0ZlFc2TfjtH9RRk38un0Zk9qeSkSIQ2S",
	"OTgc5IcZnh4lAtuDiX8mCZjXVzU2sI8l8eIJLgY2BUDyACB+Lep8LF27uDDoArSi7RJ3zPhpTAiGYr1I",
	"BrawOJtHxIdYwKjQZzKAebm60TU2QJyZ+JfVVdYxgXugi4BF3g4HU71BO+EtJXIZRtQYj5ITLJK4hUTG",
	"sSc6IglyvbBtRHX8nDbGKwOVV9xSpB5XNL7QTG4C5lr0sW82iMuiNLIOEfpkkoHcIBhwn+06iI24NMpf",
	"ArZLj8HBarRWD9Bf+XkFQAIPnbzIgcW4Dsby+fnBl+DEepAACzYE/XI9imGTF0+gY1yv6dlzu3gZfo1Y",
	"4K6I/6C5r6kj4swCsmH4yMExAQa9Hcxt+pW9FSJ9eX8+RrsGyBwrATnXBijIbKuhh3Gh/8FUbs92pEfa",
	"6K4WCL1OBUAbS2Rj+4hJM6WAbfsi2rIfI9JsTp0rwwfRRWX9ByvFVSn0lAEGtN3EcwJIUnlam183ifEZ",
	"+SOkscgu7Bg+Vw7tORm+g73bTtZDUgg+gTxLEWdOpuo2OoZnQKv/JGYyrzXcTlnXHgHAwKHBtmiPBr8Z",
	"cYfRvg7AlsA3hkqytpvq+nZKIAq++CaZmec7tOV21rswUlAqkU2UAmIs6+bAkzjOoJSAAv18orK6/RVz",
	"pDnk6UBVtrDrL6crI6P8+VRlMH2OSKg5acu5y5YzlCEeBvov6cVlbGQotnZywGDpthOPedFrZx+LOPAQ",
	"k7wudG0sZKIpzH9Xl25rvbAn8Qtj8h82n0tGht1BIrL1je8CE9n3f14gInv9anPDG7qH5BkFK1GkTaMc",
	"Nt5z+3ltoadMZ3a1EnXGpUjsVFJugJ03q9RdD71eQQmStuk3utZ077VtMqPFJ8ylhGjNk06f7SCGOHgg",
	"YD0ihlrhAUaFJ1f2dz3BwidCmyi9Ak1ndEdQUbjET3IuGU8SYBqZEPp/xAywgKLSQo0G7pyoVc7z4zx5",
	"i8xk23nuT6GJmoH8z7j0vr5l1GcP1bSEBM07eET70DxAX3biD+ALjGBwfoktXHuMyYxm6lbC9FKEOSHN",
	"pxPHLRZ40yjmo82uZR3bRL8YwzeU1XWkwDkgvH2+FY0o0GbFTdNTXoqw3cS2LiHnw2tOpBoMbTtc2sbM",
	"QKJRlchWyX2A8g0j/kmOj85PkFHf4VzGrOetvG/kqloIBrLWLWXlxqhoNbNePzmAwIvgRc0zsTSaIJgn",
	"FEngQ53ItnT26xNK6EWPlxifzSp4bsXiwlE/f1wV69Pl8RD2QOHjm+onqfpFfhj32Eei8izJFmYG6fXV",
	"Vd0LNKhdsHn9m6uJ82D8AsDTwFCSTaax6o2ogOg7UDQp2CyxzLPsypfs6EA4u1TG5EKK5JoOt3glo6eq",
	"BN6uBmsg9sfOQN+e/DN3vHHokGjQa5+MGzQqdeRnUdr11HQpXZLd4aMtMDIhYHBBoa41MRojqMBSUNwu",
	"AgPUdqY+24OrgBZ/CIE/NvfiEsO6Y1RDmPmHyQlRmzxITngc80Ygh5RRGIESqnqvRdlSPPz81CLtms7w",
	"uBkKPvE/thQfPbz/1T42fPKuVFWhV7b+9sEVQVfhJ9VlngFpx0pvxfCJfWdlgpr/AsDkRbrSWyF1Vh+2",
	"FprHRa6KFhDJhRn41Q5GNGbR0DdaRiMadfHX+1/v//8AAAD//+nDH7cfDAMA",
}

// GetSwagger returns the content of the embedded swagger specification file
// or error if failed to decode
func decodeSpec() ([]byte, error) {
	zipped, err := base64.StdEncoding.DecodeString(strings.Join(swaggerSpec, ""))
	if err != nil {
		return nil, fmt.Errorf("error base64 decoding spec: %w", err)
	}
	zr, err := gzip.NewReader(bytes.NewReader(zipped))
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}
	var buf bytes.Buffer
	_, err = buf.ReadFrom(zr)
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}

	return buf.Bytes(), nil
}

var rawSpec = decodeSpecCached()

// a naive cached of a decoded swagger spec
func decodeSpecCached() func() ([]byte, error) {
	data, err := decodeSpec()
	return func() ([]byte, error) {
		return data, err
	}
}

// Constructs a synthetic filesystem for resolving external references when loading openapi specifications.
func PathToRawSpec(pathToFile string) map[string]func() ([]byte, error) {
	res := make(map[string]func() ([]byte, error))
	if len(pathToFile) > 0 {
		res[pathToFile] = rawSpec
	}

	return res
}

// GetSwagger returns the Swagger specification corresponding to the generated code
// in this file. The external references of Swagger specification are resolved.
// The logic of resolving external references is tightly connected to "import-mapping" feature.
// Externally referenced files must be embedded in the corresponding golang packages.
// Urls can be supported but this task was out of the scope.
func GetSwagger() (swagger *openapi3.T, err error) {
	resolvePath := PathToRawSpec("")

	loader := openapi3.NewLoader()
	loader.IsExternalRefsAllowed = true
	loader.ReadFromURIFunc = func(loader *openapi3.Loader, url *url.URL) ([]byte, error) {
		pathToFile := url.String()
		pathToFile = path.Clean(pathToFile)
		getSpec, ok := resolvePath[pathToFile]
		if !ok {
			err1 := fmt.Errorf("path not found: %s", pathToFile)
			return nil, err1
		}
		return getSpec()
	}
	var specData []byte
	specData, err = rawSpec()
	if err != nil {
		return
	}
	swagger, err = loader.LoadFromData(specData)
	if err != nil {
		return
	}
	return
}
