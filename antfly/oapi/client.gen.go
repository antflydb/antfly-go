// Package oapi provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/oapi-codegen/oapi-codegen/v2 version v2.5.0 DO NOT EDIT.
package oapi

import (
	"bytes"
	"compress/gzip"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"path"
	"strings"
	"time"

	"github.com/getkin/kin-openapi/openapi3"
	"github.com/oapi-codegen/runtime"
)

const (
	BasicAuthScopes = "BasicAuth.Scopes"
)

// Defines values for AntflyType.
const (
	AntflyTypeBlob            AntflyType = "blob"
	AntflyTypeBoolean         AntflyType = "boolean"
	AntflyTypeDatetime        AntflyType = "datetime"
	AntflyTypeEmbedding       AntflyType = "embedding"
	AntflyTypeGeopoint        AntflyType = "geopoint"
	AntflyTypeGeoshape        AntflyType = "geoshape"
	AntflyTypeHtml            AntflyType = "html"
	AntflyTypeKeyword         AntflyType = "keyword"
	AntflyTypeLink            AntflyType = "link"
	AntflyTypeNumeric         AntflyType = "numeric"
	AntflyTypeSearchAsYouType AntflyType = "search_as_you_type"
	AntflyTypeText            AntflyType = "text"
)

// Defines values for ChunkerProvider.
const (
	ChunkerProviderAntfly  ChunkerProvider = "antfly"
	ChunkerProviderMock    ChunkerProvider = "mock"
	ChunkerProviderTermite ChunkerProvider = "termite"
)

// Defines values for ChunkingStrategy.
const (
	ChunkingStrategyFixed ChunkingStrategy = "fixed"
	ChunkingStrategyHugot ChunkingStrategy = "hugot"
)

// Defines values for ClusterHealth.
const (
	ClusterHealthDegraded  ClusterHealth = "degraded"
	ClusterHealthError     ClusterHealth = "error"
	ClusterHealthHealthy   ClusterHealth = "healthy"
	ClusterHealthUnhealthy ClusterHealth = "unhealthy"
	ClusterHealthUnknown   ClusterHealth = "unknown"
)

// Defines values for EdgeDirection.
const (
	EdgeDirectionBoth EdgeDirection = "both"
	EdgeDirectionIn   EdgeDirection = "in"
	EdgeDirectionOut  EdgeDirection = "out"
)

// Defines values for EmbedderProvider.
const (
	EmbedderProviderBedrock EmbedderProvider = "bedrock"
	EmbedderProviderGemini  EmbedderProvider = "gemini"
	EmbedderProviderMock    EmbedderProvider = "mock"
	EmbedderProviderOllama  EmbedderProvider = "ollama"
	EmbedderProviderOpenai  EmbedderProvider = "openai"
	EmbedderProviderVertex  EmbedderProvider = "vertex"
)

// Defines values for FailedOperationOperation.
const (
	FailedOperationOperationDelete FailedOperationOperation = "delete"
	FailedOperationOperationUpsert FailedOperationOperation = "upsert"
)

// Defines values for Fuzziness1.
const (
	Fuzziness1Auto Fuzziness1 = "auto"
)

// Defines values for GeneratorProvider.
const (
	GeneratorProviderAnthropic GeneratorProvider = "anthropic"
	GeneratorProviderBedrock   GeneratorProvider = "bedrock"
	GeneratorProviderGemini    GeneratorProvider = "gemini"
	GeneratorProviderMock      GeneratorProvider = "mock"
	GeneratorProviderOllama    GeneratorProvider = "ollama"
	GeneratorProviderOpenai    GeneratorProvider = "openai"
	GeneratorProviderVertex    GeneratorProvider = "vertex"
)

// Defines values for GeoShapeGeometryRelation.
const (
	GeoShapeGeometryRelationContains   GeoShapeGeometryRelation = "contains"
	GeoShapeGeometryRelationIntersects GeoShapeGeometryRelation = "intersects"
	GeoShapeGeometryRelationWithin     GeoShapeGeometryRelation = "within"
)

// Defines values for GraphQueryType.
const (
	GraphQueryTypeKShortestPaths GraphQueryType = "k_shortest_paths"
	GraphQueryTypeNeighbors      GraphQueryType = "neighbors"
	GraphQueryTypeShortestPath   GraphQueryType = "shortest_path"
	GraphQueryTypeTraverse       GraphQueryType = "traverse"
)

// Defines values for IndexType.
const (
	IndexTypeAknnV0     IndexType = "aknn_v0"
	IndexTypeFullTextV0 IndexType = "full_text_v0"
	IndexTypeGraphV0    IndexType = "graph_v0"
)

// Defines values for LinearMergePageStatus.
const (
	LinearMergePageStatusError   LinearMergePageStatus = "error"
	LinearMergePageStatusPartial LinearMergePageStatus = "partial"
	LinearMergePageStatusSuccess LinearMergePageStatus = "success"
)

// Defines values for MatchQueryOperator.
const (
	MatchQueryOperatorAnd MatchQueryOperator = "and"
	MatchQueryOperatorOr  MatchQueryOperator = "or"
)

// Defines values for MergeStrategy.
const (
	MergeStrategyFailover MergeStrategy = "failover"
	MergeStrategyRrf      MergeStrategy = "rrf"
	MergeStrategyRsf      MergeStrategy = "rsf"
)

// Defines values for PathFindWeightMode.
const (
	PathFindWeightModeMaxWeight PathFindWeightMode = "max_weight"
	PathFindWeightModeMinHops   PathFindWeightMode = "min_hops"
	PathFindWeightModeMinWeight PathFindWeightMode = "min_weight"
)

// Defines values for PathWeightMode.
const (
	PathWeightModeMaxWeight PathWeightMode = "max_weight"
	PathWeightModeMinHops   PathWeightMode = "min_hops"
	PathWeightModeMinWeight PathWeightMode = "min_weight"
)

// Defines values for PermissionType.
const (
	PermissionTypeAdmin PermissionType = "admin"
	PermissionTypeRead  PermissionType = "read"
	PermissionTypeWrite PermissionType = "write"
)

// Defines values for QueryRequestExpandStrategy.
const (
	QueryRequestExpandStrategyIntersection QueryRequestExpandStrategy = "intersection"
	QueryRequestExpandStrategyUnion        QueryRequestExpandStrategy = "union"
)

// Defines values for RerankerProvider.
const (
	RerankerProviderOllama  RerankerProvider = "ollama"
	RerankerProviderTermite RerankerProvider = "termite"
)

// Defines values for ResourceType.
const (
	ResourceTypeAsterisk ResourceType = "*"
	ResourceTypeTable    ResourceType = "table"
	ResourceTypeUser     ResourceType = "user"
)

// Defines values for RouteType.
const (
	RouteTypeQuestion RouteType = "question"
	RouteTypeSearch   RouteType = "search"
)

// Defines values for SyncLevel.
const (
	SyncLevelAknn        SyncLevel = "aknn"
	SyncLevelEnrichments SyncLevel = "enrichments"
	SyncLevelFullText    SyncLevel = "full_text"
	SyncLevelPropose     SyncLevel = "propose"
	SyncLevelWrite       SyncLevel = "write"
)

// Defines values for TransformOpType.
const (
	TransformOpTypeAddToSet    TransformOpType = "$addToSet"
	TransformOpTypeCurrentDate TransformOpType = "$currentDate"
	TransformOpTypeInc         TransformOpType = "$inc"
	TransformOpTypeMax         TransformOpType = "$max"
	TransformOpTypeMin         TransformOpType = "$min"
	TransformOpTypeMul         TransformOpType = "$mul"
	TransformOpTypePop         TransformOpType = "$pop"
	TransformOpTypePull        TransformOpType = "$pull"
	TransformOpTypePush        TransformOpType = "$push"
	TransformOpTypeRename      TransformOpType = "$rename"
	TransformOpTypeSet         TransformOpType = "$set"
	TransformOpTypeUnset       TransformOpType = "$unset"
)

// Analyses defines model for Analyses.
type Analyses struct {
	Pca  bool `json:"pca,omitempty,omitzero"`
	Tsne bool `json:"tsne,omitempty,omitzero"`
}

// AnalysesResult defines model for AnalysesResult.
type AnalysesResult struct {
	Pca  []float64 `json:"pca,omitempty,omitzero"`
	Tsne []float64 `json:"tsne,omitempty,omitzero"`
}

// AnswerAgentRequest defines model for AnswerAgentRequest.
type AnswerAgentRequest struct {
	// Queries Array of query requests to execute. The query text will be transformed for semantic search
	// and populated into the semantic_search field of each query.
	Queries []QueryRequest `json:"queries"`

	// Query User's natural language query to be classified and improved
	Query string `json:"query"`

	// Summarizer A unified configuration for a generative AI provider.
	Summarizer GeneratorConfig `json:"summarizer"`

	// SystemPrompt Optional system prompt to guide classification and answer generation
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`

	// UserContext Optional user context to customize the content guidance for each section of the answer agent response.
	//
	// **What you can customize**: Style, tone, length, detail level, and focus of content for each section independently.
	//
	// **What is fixed**: The response format is always markdown with consistent structure (## Reasoning, ## Answer, ## Follow-up Questions).
	// Markdown formatting (headings, bullets, code blocks, etc.) is always applied and cannot be disabled.
	//
	// **Architecture**: These contexts are passed as template variables to the prompt template. Defaults are set
	// at the application layer, and users can override them via this API to customize content guidance.
	UserContext UserContext `json:"user_context,omitempty,omitzero"`

	// WithFollowup Include suggested follow-up questions as separate events after the answer
	WithFollowup bool `json:"with_followup,omitempty,omitzero"`

	// WithReasoning Include the LLM's reasoning process as separate events before the answer
	WithReasoning bool `json:"with_reasoning,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results (classification, queries, results, answer) instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// AnswerAgentResult Answer agent result with classification and generated answer with inline resource references
type AnswerAgentResult struct {
	// Answer Generated answer (markdown format with inline resource references)
	Answer string `json:"answer,omitempty,omitzero"`

	// ClassificationTransformation Query classification and transformation result combining all query enhancements
	ClassificationTransformation ClassificationTransformationResult `json:"classification_transformation,omitempty,omitzero"`

	// FollowupQuestions Suggested follow-up questions (if with_followup was enabled)
	FollowupQuestions []string `json:"followup_questions,omitempty,omitzero"`

	// QueryResults Results from each executed query
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`

	// Reasoning LLM's reasoning process (if with_reasoning was enabled)
	Reasoning string `json:"reasoning,omitempty,omitzero"`
}

// AntflyChunkerConfig Configuration for the local Antfly chunking provider.
//
// This provider runs chunking directly within the storage node process,
// without requiring an external Termite service. It uses simple fixed-size
// tokenizer-based chunking with no caching overhead.
//
// **Use this when:**
// - Running single-node deployments (swarm mode)
// - You don't need embedding/chunk caching across nodes
// - You want minimal setup complexity
//
// **Use Termite instead when:**
// - Running multi-node clusters where caching reduces costs
// - You need ONNX-accelerated chunking (hugot strategy)
// - You want persistent chunk/embedding caches
type AntflyChunkerConfig struct {
	// FullText Configuration for full-text indexing of chunks in Bleve.
	// When present (even if empty), chunks will be stored with :cft: suffix and indexed in Bleve's _chunks field.
	// When absent, chunks use :c: suffix and are only used for vector embeddings.
	// This object is reserved for future options like boosting, field mapping, etc.
	FullText map[string]interface{} `json:"full_text,omitempty,omitzero"`

	// MaxChunks Maximum number of chunks to generate per document. Prevents excessive chunking of very large documents.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs).
	Separator string `json:"separator,omitempty,omitzero"`

	// TargetTokens Target number of tokens per chunk. Chunker will aim for chunks around this size.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`
}

// AntflyType defines model for AntflyType.
type AntflyType string

// AnthropicGeneratorConfig Configuration for the Anthropic generative AI provider (Claude models).
// Uses the firebase/genkit compat_oai/anthropic plugin with OpenAI-compatible API.
//
// Defaults to claude-3-7-sonnet-20250219 if no model is specified.
//
// API key can be provided via the 'api_key' field or the ANTHROPIC_API_KEY environment variable.
//
// Supported models:
// - claude-3-7-sonnet-20250219 (latest, most capable)
// - claude-3-5-haiku-20241022 (fast and efficient)
// - claude-3-5-sonnet-20240620 (balanced performance)
// - claude-3-opus-20240229 (highly capable)
// - claude-3-haiku-20240307 (fastest)
type AnthropicGeneratorConfig struct {
	// ApiKey The Anthropic API key. If not provided, falls back to ANTHROPIC_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The full model ID of the Anthropic model to use (e.g., 'claude-3-7-sonnet-20250219', 'claude-3-5-haiku-20241022').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-1.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Anthropic API endpoint (optional, uses default if not specified).
	Url string `json:"url,omitempty,omitzero"`
}

// BackupRequest defines model for BackupRequest.
type BackupRequest struct {
	// BackupId Unique identifier for this backup. Used to reference the backup for restore operations.
	// Choose a meaningful name that includes date/version information.
	BackupId string `json:"backup_id"`

	// Location Storage location for the backup. Supports multiple backends:
	// - Local filesystem: `file:///path/to/backup`
	// - Amazon S3: `s3://bucket-name/path/to/backup`
	//
	// The backup includes all table data, indexes, and metadata for the specified table.
	Location string `json:"location"`
}

// BatchRequest Batch insert, delete, and transform operations in a single request. All operations are processed atomically within each shard.
//
// Benefits:
// - Reduces network overhead compared to individual requests
// - More efficient indexing (updates are batched)
// - Atomic within shard boundaries
//
// The inserts are upserts - existing keys are overwritten, new keys are created.
type BatchRequest struct {
	// Deletes Array of document IDs to delete. Documents are removed from all indexes.
	//
	// Notes:
	// - Non-existent keys are silently ignored
	// - Deletions are processed before inserts in the same batch
	// - Keys are permanently removed from storage and indexes
	Deletes []string `json:"deletes,omitempty,omitzero"`

	// Inserts Map of document IDs to document objects. Each key is the unique identifier for the document.
	//
	// Best practices:
	// - Use consistent key naming schemes (e.g., "user:123", "article:456")
	// - Key length affects storage and performance - keep them reasonably short
	// - Keys are sorted lexicographically, so choose prefixes that support range scans
	Inserts map[string]map[string]interface{} `json:"inserts,omitempty,omitzero"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write
	// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`

	// Transforms Array of transform operations for in-place document updates using MongoDB-style operators.
	//
	// Transform operations allow you to modify documents without read-modify-write races:
	// - Operations are applied atomically on the server
	// - Multiple operations per document are applied in sequence
	// - Supports numeric operations ($inc, $mul), array operations ($push, $pull), and more
	//
	// Common use cases:
	// - Increment counters (views, likes, votes)
	// - Update timestamps ($currentDate)
	// - Manage arrays (add/remove tags, items)
	// - Update nested fields without overwriting the entire document
	Transforms []Transform `json:"transforms,omitempty,omitzero"`
}

// BedrockEmbedderConfig Configuration for the Bedrock embedding provider.
type BedrockEmbedderConfig struct {
	// BatchSize The batch size for embedding requests.
	BatchSize int `json:"batch_size,omitempty,omitzero"`

	// Model The name of the Bedrock model to use.
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service.
	Region string `json:"region,omitempty,omitzero"`

	// StripNewLines Whether to strip new lines from the input text.
	StripNewLines bool `json:"strip_new_lines,omitempty,omitzero"`
}

// BedrockGeneratorConfig Configuration for the AWS Bedrock generative AI provider.
type BedrockGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Bedrock model to use.
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service.
	Region string `json:"region,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-1.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// BleveIndexV2Config defines model for BleveIndexV2Config.
type BleveIndexV2Config struct {
	// MemOnly Whether to use memory-only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`
}

// BleveIndexV2Stats defines model for BleveIndexV2Stats.
type BleveIndexV2Stats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// Rebuilding Whether the index is currently rebuilding
	Rebuilding bool `json:"rebuilding,omitempty,omitzero"`

	// TotalIndexed Number of documents in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`
}

// BoolFieldQuery defines model for BoolFieldQuery.
type BoolFieldQuery struct {
	Bool bool `json:"bool"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
}

// BooleanQuery defines model for BooleanQuery.
type BooleanQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost   Boost            `json:"boost,omitzero"`
	Filter  Query            `json:"filter,omitempty,omitzero"`
	Must    ConjunctionQuery `json:"must,omitempty,omitzero"`
	MustNot DisjunctionQuery `json:"must_not,omitempty,omitzero"`
	Should  DisjunctionQuery `json:"should,omitempty,omitzero"`
}

// Boost A floating-point number used to decrease or increase the relevance scores of a query.
type Boost = float64

// ByteRange defines model for ByteRange.
type ByteRange = [][]byte

// ChunkerConfig defines model for ChunkerConfig.
type ChunkerConfig struct {
	// Provider The chunking provider to use.
	Provider ChunkerProvider `json:"provider"`
	union    json.RawMessage
}

// ChunkerProvider The chunking provider to use.
type ChunkerProvider string

// ChunkingStrategy Document chunking strategy.
// - hugot: ONNX-accelerated chunking using sentence boundary detection
// - fixed: Simple fixed-size chunking by token count
type ChunkingStrategy string

// ClassificationTransformationResult Query classification and transformation result combining all query enhancements
type ClassificationTransformationResult struct {
	// Confidence Classification confidence (0.0 to 1.0)
	Confidence float32 `json:"confidence"`

	// ImprovedQuery Clarified query with added context for answer generation (human-readable)
	ImprovedQuery string `json:"improved_query"`

	// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
	RouteType RouteType `json:"route_type"`

	// SemanticQuery Optimized query for vector/semantic search (concept extraction with synonyms)
	SemanticQuery string `json:"semantic_query"`
}

// ClusterHealth Overall health status of the cluster
type ClusterHealth string

// ClusterStatus defines model for ClusterStatus.
type ClusterStatus struct {
	// AuthEnabled Indicates whether authentication is enabled for the cluster
	AuthEnabled bool `json:"auth_enabled,omitempty"`

	// Health Overall health status of the cluster
	Health ClusterHealth `json:"health"`

	// Message Optional message providing details about the health status
	Message              string                 `json:"message,omitempty,omitzero"`
	AdditionalProperties map[string]interface{} `json:"-"`
}

// ConjunctionQuery defines model for ConjunctionQuery.
type ConjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Conjuncts []Query `json:"conjuncts"`
}

// CreateTableRequest defines model for CreateTableRequest.
type CreateTableRequest struct {
	// Description Optional human-readable description of the table and its purpose.
	// Useful for documentation and team collaboration.
	Description string `json:"description,omitempty,omitzero"`

	// Indexes Map of index name to index configuration. Indexes enable different query capabilities:
	// - Full-text indexes for BM25 search
	// - Vector indexes for semantic similarity
	// - Multimodal indexes for images/audio/video
	//
	// You can add multiple indexes to support different query patterns.
	Indexes map[string]IndexConfig `json:"indexes,omitempty,omitzero"`

	// NumShards Number of shards to create for the table. Data is partitioned across shards based on key ranges.
	//
	// Guidelines:
	// - Small datasets (<100K docs): 1-3 shards
	// - Medium datasets (100K-1M docs): 3-10 shards
	// - Large datasets (>1M docs): 10+ shards
	//
	// More shards enable better parallelism but increase overhead. Choose based on expected data size and query patterns.
	NumShards uint `json:"num_shards,omitempty,omitzero"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema `json:"schema,omitempty,omitzero"`
}

// CreateUserRequest defines model for CreateUserRequest.
type CreateUserRequest struct {
	// InitialPolicies Optional list of initial permissions for the user.
	InitialPolicies []Permission `json:"initial_policies,omitzero"`
	Password        string       `json:"password"`

	// Username Username for the new user. If provided in the path, this field can be omitted or must match the path parameter.
	Username string `json:"username,omitempty,omitzero"`
}

// DateRange defines model for DateRange.
type DateRange struct {
	From *string `json:"from,omitempty"`
	Name string  `json:"name"`
	To   *string `json:"to,omitempty"`
}

// DateRangeResult defines model for DateRangeResult.
type DateRangeResult struct {
	Count int     `json:"count"`
	From  *string `json:"from,omitempty"`
	Name  string  `json:"name"`
	To    *string `json:"to,omitempty"`
}

// DateRangeStringQuery defines model for DateRangeStringQuery.
type DateRangeStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost          Boost     `json:"boost,omitzero"`
	DatetimeParser string    `json:"datetime_parser,omitempty,omitzero"`
	End            time.Time `json:"end,omitempty,omitzero"`
	Field          string    `json:"field,omitempty,omitzero"`
	InclusiveEnd   bool      `json:"inclusive_end,omitzero"`
	InclusiveStart bool      `json:"inclusive_start,omitzero"`
	Start          time.Time `json:"start,omitempty,omitzero"`
}

// DisjunctionQuery defines model for DisjunctionQuery.
type DisjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Disjuncts []Query `json:"disjuncts"`
	Min       float64 `json:"min,omitempty,omitzero"`
}

// DocIdQuery defines model for DocIdQuery.
type DocIdQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost    `json:"boost,omitzero"`
	Ids   []string `json:"ids"`
}

// DocumentSchema Defines the structure of a document type
type DocumentSchema struct {
	// Description A description of the document type.
	Description string `json:"description,omitempty,omitzero"`

	// Schema A valid JSON Schema defining the document's structure.
	// This is used to infer indexing rules and field types.
	Schema map[string]interface{} `json:"schema,omitempty,omitzero"`
}

// Edge A typed, weighted connection between documents
type Edge struct {
	// CreatedAt When the edge was created
	CreatedAt time.Time `json:"created_at,omitempty,omitzero"`

	// Metadata Optional edge metadata
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`

	// Source Base64-encoded source document key
	Source []byte `json:"source"`

	// Target Base64-encoded target document key
	Target []byte `json:"target"`

	// Type Edge type (e.g., "cites", "similar_to", "authored_by")
	Type string `json:"type"`

	// UpdatedAt When the edge was last updated
	UpdatedAt time.Time `json:"updated_at,omitempty,omitzero"`

	// Weight Edge weight/confidence (0.0 to 1.0)
	Weight float64 `json:"weight"`
}

// EdgeDirection Direction of edges to query:
// - out: Outgoing edges from the node
// - in: Incoming edges to the node
// - both: Both outgoing and incoming edges
type EdgeDirection string

// EdgeTypeConfig Configuration for a specific edge type
type EdgeTypeConfig struct {
	// AllowSelfLoops Whether to allow edges from a node to itself
	AllowSelfLoops bool `json:"allow_self_loops,omitempty,omitzero"`

	// MaxWeight Maximum allowed edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum allowed edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// Name Edge type name (e.g., 'cites', 'similar_to')
	Name string `json:"name"`

	// RequiredMetadata Required metadata fields for this edge type
	RequiredMetadata []string `json:"required_metadata,omitempty,omitzero"`
}

// EdgesResponse defines model for EdgesResponse.
type EdgesResponse struct {
	// Count Total number of edges returned
	Count int    `json:"count,omitempty,omitzero"`
	Edges []Edge `json:"edges,omitempty,omitzero"`
}

// EmbedderConfig defines model for EmbedderConfig.
type EmbedderConfig struct {
	// Provider The embedding provider to use.
	Provider EmbedderProvider `json:"provider"`
	union    json.RawMessage
}

// EmbedderProvider The embedding provider to use.
type EmbedderProvider string

// EmbeddingIndexConfig defines model for EmbeddingIndexConfig.
type EmbeddingIndexConfig struct {
	// Chunker A unified configuration for a chunking provider.
	Chunker ChunkerConfig `json:"chunker,omitempty,omitzero"`

	// Dimension Vector dimension
	Dimension int `json:"dimension"`

	// Embedder A unified configuration for an embedding provider.
	Embedder EmbedderConfig `json:"embedder,omitempty,omitzero"`

	// Field Field to extract embeddings from
	Field string `json:"field,omitempty,omitzero"`

	// MemOnly Whether to use in-memory only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`

	// Summarizer A unified configuration for a generative AI provider.
	Summarizer GeneratorConfig `json:"summarizer,omitempty,omitzero"`

	// Template Handlebars template for generating prompts. See https://handlebarsjs.com/guide/ for more information.
	Template string `json:"template,omitempty,omitzero"`
}

// EmbeddingIndexStats defines model for EmbeddingIndexStats.
type EmbeddingIndexStats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalIndexed Number of vectors in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`

	// TotalNodes Total number of nodes in the index
	TotalNodes uint64 `json:"total_nodes,omitempty,omitzero"`
}

// Error defines model for Error.
type Error struct {
	Error string `json:"error"`
}

// FacetOption defines model for FacetOption.
type FacetOption struct {
	DateRanges    []DateRange    `json:"date_ranges,omitempty,omitzero"`
	Field         string         `json:"field,omitempty,omitzero"`
	NumericRanges []NumericRange `json:"numeric_ranges,omitempty,omitzero"`
	Size          int            `json:"size,omitempty,omitzero"`
}

// FacetResult defines model for FacetResult.
type FacetResult struct {
	DateRanges    []DateRangeResult    `json:"date_ranges,omitempty,omitzero"`
	Field         string               `json:"field,omitempty,omitzero"`
	Missing       int                  `json:"missing,omitempty,omitzero"`
	NumericRanges []NumericRangeResult `json:"numeric_ranges,omitempty,omitzero"`
	Terms         []TermFacetResult    `json:"terms,omitempty,omitzero"`
	Total         int                  `json:"total,omitempty,omitzero"`
}

// FailedOperation defines model for FailedOperation.
type FailedOperation struct {
	Error     string                   `json:"error,omitempty,omitzero"`
	Id        string                   `json:"id,omitempty,omitzero"`
	Operation FailedOperationOperation `json:"operation,omitempty,omitzero"`
}

// FailedOperationOperation defines model for FailedOperation.Operation.
type FailedOperationOperation string

// Fuzziness The fuzziness of the query. Can be an integer or "auto".
type Fuzziness struct {
	union json.RawMessage
}

// Fuzziness0 defines model for .
type Fuzziness0 = int32

// Fuzziness1 defines model for Fuzziness.1.
type Fuzziness1 string

// FuzzyQuery defines model for FuzzyQuery.
type FuzzyQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness `json:"fuzziness,omitempty,omitzero"`
	PrefixLength int32     `json:"prefix_length,omitempty,omitzero"`
	Term         string    `json:"term"`
}

// GeneratorConfig defines model for GeneratorConfig.
type GeneratorConfig struct {
	// Provider The generative AI provider to use.
	Provider GeneratorProvider `json:"provider"`
	union    json.RawMessage
}

// GeneratorProvider The generative AI provider to use.
type GeneratorProvider string

// GeoBoundingBoxQuery defines model for GeoBoundingBoxQuery.
type GeoBoundingBoxQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost `json:"boost,omitzero"`

	// BottomRight [lon, lat]
	BottomRight []float64 `json:"bottom_right"`
	Field       string    `json:"field,omitempty,omitzero"`

	// TopLeft [lon, lat]
	TopLeft []float64 `json:"top_left"`
}

// GeoBoundingPolygonQuery defines model for GeoBoundingPolygonQuery.
type GeoBoundingPolygonQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost         Boost      `json:"boost,omitzero"`
	Field         string     `json:"field,omitempty,omitzero"`
	PolygonPoints []GeoPoint `json:"polygon_points"`
}

// GeoDistanceQuery defines model for GeoDistanceQuery.
type GeoDistanceQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Distance string `json:"distance"`
	Field    string `json:"field,omitempty,omitzero"`

	// Location [lon, lat]
	Location []float64 `json:"location"`
}

// GeoPoint defines model for GeoPoint.
type GeoPoint struct {
	Lat float64 `json:"lat,omitempty,omitzero"`
	Lon float64 `json:"lon,omitempty,omitzero"`
}

// GeoShape A GeoJSON shape object. This is a simplified representation.
type GeoShape struct {
	Coordinates []interface{} `json:"coordinates"`
	Type        string        `json:"type"`
}

// GeoShapeGeometry defines model for GeoShapeGeometry.
type GeoShapeGeometry struct {
	Relation GeoShapeGeometryRelation `json:"relation"`

	// Shape A GeoJSON shape object. This is a simplified representation.
	Shape GeoShape `json:"shape"`
}

// GeoShapeGeometryRelation defines model for GeoShapeGeometry.Relation.
type GeoShapeGeometryRelation string

// GeoShapeQuery defines model for GeoShapeQuery.
type GeoShapeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost            `json:"boost,omitzero"`
	Field    string           `json:"field,omitempty,omitzero"`
	Geometry GeoShapeGeometry `json:"geometry"`
}

// GoogleEmbedderConfig Configuration for the Google embedding provider.
type GoogleEmbedderConfig struct {
	// ApiKey The Google API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimension The dimension of the embedding.
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1').
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the embedding model to use (e.g., 'text-embedding-004').
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Url The URL of the Google API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// GoogleGeneratorConfig Configuration for the Google generative AI provider (Gemini). Defaults to gemini-2.5-flash if no model is specified.
type GoogleGeneratorConfig struct {
	// ApiKey The Google API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1').
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the generative model to use (e.g., 'gemini-2.5-flash', 'gemini-1.5-pro').
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Google API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// GraphIndexV0Config Configuration for graph_v0 index type
type GraphIndexV0Config struct {
	// EdgeTypes List of edge types with their configurations
	EdgeTypes []EdgeTypeConfig `json:"edge_types,omitempty,omitzero"`

	// MaxEdgesPerDocument Maximum number of edges per document (0 = unlimited)
	MaxEdgesPerDocument int `json:"max_edges_per_document,omitempty,omitzero"`
}

// GraphIndexV0Stats Statistics for graph_v0 index
type GraphIndexV0Stats struct {
	// EdgeTypes Count of edges per edge type
	EdgeTypes map[string]uint64 `json:"edge_types,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalEdges Total number of edges in the graph
	TotalEdges uint64 `json:"total_edges,omitempty,omitzero"`
}

// GraphNodeSelector Defines how to select start/target nodes for graph queries
type GraphNodeSelector struct {
	// Keys Explicit list of node keys
	Keys []string `json:"keys,omitempty,omitzero"`

	// Limit Maximum number of nodes to select from the referenced results
	Limit int `json:"limit,omitempty,omitzero"`

	// ResultRef Reference to search results to use as nodes:
	// - "$full_text_results" - use full-text search results
	// - "$aknn_results.index_name" - use vector search results from specific index
	ResultRef string `json:"result_ref,omitempty,omitzero"`
}

// GraphQuery Declarative graph query to execute after full-text/vector searches
type GraphQuery struct {
	// Fields Which fields to return from documents
	Fields []string `json:"fields,omitempty,omitzero"`

	// IncludeDocuments Fetch full documents for graph results
	IncludeDocuments bool `json:"include_documents,omitempty,omitzero"`

	// IncludeEdges Include edge details for each node
	IncludeEdges bool `json:"include_edges,omitempty,omitzero"`

	// IndexName Graph index name (must be graph_v0 type)
	IndexName string `json:"index_name"`

	// Params Parameters for graph traversal and pathfinding
	Params GraphQueryParams `json:"params"`

	// StartNodes Defines how to select start/target nodes for graph queries
	StartNodes GraphNodeSelector `json:"start_nodes"`

	// TargetNodes Defines how to select start/target nodes for graph queries
	TargetNodes GraphNodeSelector `json:"target_nodes,omitempty,omitzero"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryParams Parameters for graph traversal and pathfinding
type GraphQueryParams struct {
	// Algorithm Graph algorithm to run (e.g., 'pagerank', 'betweenness')
	Algorithm string `json:"algorithm,omitempty,omitzero"`

	// AlgorithmParams Parameters for the graph algorithm
	AlgorithmParams map[string]interface{} `json:"algorithm_params,omitempty,omitzero"`

	// DeduplicateNodes Remove duplicate nodes (traversal)
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information (traversal)
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// K Number of paths to find (k-shortest-paths)
	K int `json:"k,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum number of results (traversal)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// WeightMode Path weighting algorithm for pathfinding:
	// - min_hops: Minimize number of edges
	// - min_weight: Minimize sum of edge weights
	// - max_weight: Maximize product of edge weights
	WeightMode PathWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// GraphQueryResult Results of a graph query
type GraphQueryResult struct {
	// Nodes Result nodes
	Nodes []GraphResultNode `json:"nodes,omitempty,omitzero"`

	// Paths Result paths (for pathfinding queries)
	Paths []Path `json:"paths,omitempty,omitzero"`

	// Took Query execution time
	Took time.Duration `json:"took,omitempty,omitzero"`

	// Total Total number of results
	Total int `json:"total"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryType Type of graph query to execute
type GraphQueryType string

// GraphResultNode A node in graph query results
type GraphResultNode struct {
	// Depth Distance from start node
	Depth int `json:"depth,omitempty,omitzero"`

	// Distance Weighted distance
	Distance float64 `json:"distance,omitempty,omitzero"`

	// Document Full document (if include_documents=true)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Edges Connected edges (when include_edges=true)
	Edges []Edge `json:"edges,omitempty,omitzero"`

	// Key Document key
	Key string `json:"key"`

	// Path Keys in path from start to this node
	Path []string `json:"path,omitempty,omitzero"`

	// PathEdges Edges in path from start to this node
	PathEdges []PathEdge `json:"path_edges,omitempty,omitzero"`
}

// IPRangeQuery defines model for IPRangeQuery.
type IPRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Cidr  string `json:"cidr"`
	Field string `json:"field,omitempty,omitzero"`
}

// IndexConfig Configuration for an index
type IndexConfig struct {
	// Description Optional description of the index and its purpose
	Description string `json:"description,omitempty,omitzero"`

	// Enrichments List of enrichment names to apply to documents before indexing. Enrichments must be defined at the table level.
	Enrichments []string `json:"enrichments,omitempty,omitzero"`

	// Name Name of the index
	Name string `json:"name"`

	// Type The type of the index.
	Type  IndexType `json:"type"`
	union json.RawMessage
}

// IndexStats Statistics for an index
type IndexStats struct {
	union json.RawMessage
}

// IndexStatus defines model for IndexStatus.
type IndexStatus struct {
	// Config Configuration for an index
	Config      IndexConfig           `json:"config"`
	ShardStatus map[string]IndexStats `json:"shard_status"`

	// Status Statistics for an index
	Status IndexStats `json:"status"`
}

// IndexType The type of the index.
type IndexType string

// KeyRange Key range processed in this request
type KeyRange struct {
	From string `json:"from,omitempty,omitzero"`
	To   string `json:"to,omitempty,omitzero"`
}

// LinearMergePageStatus Status of a linear merge page operation:
// - "success": All records in batch processed successfully
// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
// - "error": Fatal error occurred, no records processed successfully
type LinearMergePageStatus string

// LinearMergeRequest Linear merge operation for syncing sorted records from external sources.
// Use this to keep Antfly in sync with an external database or data source.
//
// **How it works:**
// 1. Send sorted records from your external source
// 2. Server upserts records that exist in your batch
// 3. Server deletes Antfly records in the key range that are absent from your batch
// 4. If stopped at shard boundary, use next_cursor for next request
//
// **WARNING:** Not safe for concurrent operations with overlapping key ranges.
type LinearMergeRequest struct {
	// DryRun If true, returns what would be deleted without making changes.
	//
	// Use cases:
	// - Validate sync behavior before committing
	// - Check which records will be removed
	// - Test key range boundaries
	//
	// Response includes deleted_ids array when dry_run=true.
	DryRun bool `json:"dry_run,omitempty,omitzero"`

	// LastMergedId ID of last record from previous merge request.
	// - First request: Use empty string ""
	// - Subsequent requests: Use next_cursor from previous response
	// - Defines lower bound of key range to process
	//
	// This enables pagination for large datasets.
	LastMergedId string `json:"last_merged_id,omitempty,omitzero"`

	// Records Map of resource ID to resource object: {"resource_id_1": {...}, "resource_id_2": {...}}
	//
	// Requirements:
	// - Keys must be sorted lexicographically by your client
	// - Server will process keys in sorted order
	// - Use consistent key naming (e.g., all start with same prefix)
	//
	// This format avoids duplicate IDs and matches Antfly's batch write interface.
	Records map[string]interface{} `json:"records"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write
	// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`
}

// LinearMergeResult defines model for LinearMergeResult.
type LinearMergeResult struct {
	// Deleted Records deleted or would be deleted (if dry_run=true)
	Deleted int `json:"deleted"`

	// DeletedIds IDs that were deleted (or would be deleted if dry_run=true). Only included if dry_run=true.
	DeletedIds []string          `json:"deleted_ids,omitempty,omitzero"`
	Failed     []FailedOperation `json:"failed,omitempty,omitzero"`

	// KeyRange Key range processed in this request
	KeyRange KeyRange `json:"key_range,omitempty,omitzero"`

	// KeysScanned Total number of keys scanned from Antfly during range query
	KeysScanned int `json:"keys_scanned,omitempty,omitzero"`

	// Message Additional information (e.g., "stopped at shard boundary", "dry run - no changes made")
	Message string `json:"message,omitempty,omitzero"`

	// NextCursor ID of last record in this batch (use for next request)
	NextCursor string `json:"next_cursor"`

	// Skipped Records skipped because content hash matched (unchanged)
	Skipped int `json:"skipped"`

	// Status Status of a linear merge page operation:
	// - "success": All records in batch processed successfully
	// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
	// - "error": Fatal error occurred, no records processed successfully
	Status LinearMergePageStatus `json:"status"`
	Took   time.Duration         `json:"took,omitempty,omitzero"`

	// Upserted Records inserted or updated (0 if dry_run=true)
	Upserted int `json:"upserted"`
}

// MatchAllQuery defines model for MatchAllQuery.
type MatchAllQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost                  `json:"boost,omitzero"`
	MatchAll map[string]interface{} `json:"match_all"`
}

// MatchNoneQuery defines model for MatchNoneQuery.
type MatchNoneQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost                  `json:"boost,omitzero"`
	MatchNone map[string]interface{} `json:"match_none"`
}

// MatchPhraseQuery defines model for MatchPhraseQuery.
type MatchPhraseQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness   Fuzziness `json:"fuzziness,omitempty,omitzero"`
	MatchPhrase string    `json:"match_phrase"`
}

// MatchQuery defines model for MatchQuery.
type MatchQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness          `json:"fuzziness,omitempty,omitzero"`
	Match        string             `json:"match"`
	Operator     MatchQueryOperator `json:"operator,omitempty,omitzero"`
	PrefixLength int32              `json:"prefix_length,omitempty,omitzero"`
}

// MatchQueryOperator defines model for MatchQuery.Operator.
type MatchQueryOperator string

// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
// failover: Use full_text_search if embedding generation fails
type MergeStrategy string

// MultiPhraseQuery defines model for MultiPhraseQuery.
type MultiPhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness  `json:"fuzziness,omitempty,omitzero"`
	Terms     [][]string `json:"terms"`
}

// NumericRange defines model for NumericRange.
type NumericRange struct {
	From *float64 `json:"from,omitempty"`
	Name string   `json:"name"`
	To   *float64 `json:"to,omitempty"`
}

// NumericRangeQuery defines model for NumericRangeQuery.
type NumericRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost   `json:"boost,omitzero"`
	Field        string  `json:"field,omitempty,omitzero"`
	InclusiveMax bool    `json:"inclusive_max,omitzero"`
	InclusiveMin bool    `json:"inclusive_min,omitzero"`
	Max          float64 `json:"max,omitzero"`
	Min          float64 `json:"min,omitzero"`
}

// NumericRangeResult defines model for NumericRangeResult.
type NumericRangeResult struct {
	Count int      `json:"count"`
	From  *float64 `json:"from,omitempty"`
	Name  string   `json:"name"`
	To    *float64 `json:"to,omitempty"`
}

// OllamaEmbedderConfig Configuration for the Ollama embedding provider.
type OllamaEmbedderConfig struct {
	// Model The name of the Ollama model to use.
	Model string `json:"model"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OllamaGeneratorConfig Configuration for the Ollama generative AI provider.
type OllamaGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Ollama model to use (e.g., 'llama3.2', 'llava').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OllamaRerankerConfig Configuration for the Ollama reranking provider.
type OllamaRerankerConfig struct {
	// Model The name of the Ollama model to use for reranking.
	Model string `json:"model"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIEmbedderConfig Configuration for the OpenAI embedding provider.
type OpenAIEmbedderConfig struct {
	// ApiKey The OpenAI API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Model The name of the OpenAI model to use.
	Model string `json:"model"`

	// Url The URL of the OpenAI API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIGeneratorConfig Configuration for the OpenAI generative AI provider.
type OpenAIGeneratorConfig struct {
	// ApiKey The OpenAI API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (-2.0 to 2.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the OpenAI model to use (e.g., 'gpt-4o', 'gpt-4-turbo').
	Model string `json:"model"`

	// PresencePenalty Penalty for token presence (-2.0 to 2.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the OpenAI API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// Path defines model for Path.
type Path struct {
	Edges  []PathEdge `json:"edges,omitempty,omitzero"`
	Length int        `json:"length,omitempty,omitzero"`

	// Nodes Ordered list of node keys (base64-encoded)
	Nodes       []string `json:"nodes,omitempty,omitzero"`
	TotalWeight float64  `json:"total_weight,omitempty,omitzero"`
}

// PathEdge defines model for PathEdge.
type PathEdge struct {
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`
	Source   string                 `json:"source,omitempty,omitzero"`
	Target   string                 `json:"target,omitempty,omitzero"`
	Type     string                 `json:"type,omitempty,omitzero"`
	Weight   float64                `json:"weight,omitempty,omitzero"`
}

// PathFindRequest defines model for PathFindRequest.
type PathFindRequest struct {
	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by specific edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`
	K         int      `json:"k,omitempty,omitzero"`
	MaxDepth  int      `json:"max_depth,omitempty,omitzero"`
	MaxWeight float64  `json:"max_weight,omitempty,omitzero"`
	MinWeight float64  `json:"min_weight,omitempty,omitzero"`

	// Source Source node key (base64-encoded)
	Source string `json:"source"`

	// Target Target node key (base64-encoded)
	Target string `json:"target"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindResult defines model for PathFindResult.
type PathFindResult struct {
	Paths        []Path  `json:"paths,omitempty,omitzero"`
	PathsFound   int     `json:"paths_found,omitempty,omitzero"`
	SearchTimeMs float64 `json:"search_time_ms,omitempty,omitzero"`
	Source       string  `json:"source,omitempty,omitzero"`
	Target       string  `json:"target,omitempty,omitzero"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindWeightMode Algorithm for path finding:
// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
// - max_weight: Path with maximum product of edge weights (strongest connection chain)
// - min_weight: Path with minimum sum of edge weights (lowest cost route)
type PathFindWeightMode string

// PathWeightMode Path weighting algorithm for pathfinding:
// - min_hops: Minimize number of edges
// - min_weight: Minimize sum of edge weights
// - max_weight: Maximize product of edge weights
type PathWeightMode string

// Permission defines model for Permission.
type Permission struct {
	// Resource Resource name (e.g., table name, target username, or '*' for global).
	Resource string `json:"resource"`

	// ResourceType Type of the resource, e.g., table, user, or global ('*').
	ResourceType ResourceType `json:"resource_type"`

	// Type Type of permission.
	Type PermissionType `json:"type"`
}

// PermissionType Type of permission.
type PermissionType string

// PhraseQuery defines model for PhraseQuery.
type PhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness `json:"fuzziness,omitempty,omitzero"`
	Terms     []string  `json:"terms"`
}

// PrefixQuery defines model for PrefixQuery.
type PrefixQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Prefix string `json:"prefix"`
}

// Pruner Configuration for pruning search results based on score quality.
// Helps filter out low-relevance results in RAG pipelines by detecting
// score gaps or deviations from top results.
type Pruner struct {
	// MaxScoreGapPercent Stop returning results when score drops more than this percentage
	// from the previous result. Detects "elbows" in score distribution.
	// For example, 30.0 stops when score drops 30% from previous result.
	MaxScoreGapPercent float64 `json:"max_score_gap_percent,omitempty,omitzero"`

	// MinAbsoluteScore Hard minimum score threshold. Results with scores below this value
	// are excluded regardless of other pruning settings.
	MinAbsoluteScore float64 `json:"min_absolute_score,omitempty,omitzero"`

	// MinScoreRatio Keep only results with score >= max_score * min_score_ratio.
	// For example, 0.5 keeps results scoring at least half of the top result.
	// Applied after fusion scoring.
	MinScoreRatio float64 `json:"min_score_ratio,omitempty,omitzero"`

	// RequireMultiIndex Only keep results that appear in multiple indexes (both full-text
	// and vector search). Useful for increasing precision by requiring
	// agreement between different retrieval methods.
	RequireMultiIndex bool `json:"require_multi_index,omitempty,omitzero"`

	// StdDevThreshold Keep results within N standard deviations below the mean score.
	// For example, 1.0 keeps results with score >= mean - 1*stddev.
	// Useful for statistical outlier detection in result sets.
	StdDevThreshold float64 `json:"std_dev_threshold,omitempty,omitzero"`
}

// Query defines model for Query.
type Query struct {
	union json.RawMessage
}

// QueryHit A single query result hit
type QueryHit struct {
	// ID ID of the record.
	ID string `json:"_id"`

	// IndexScores Scores partitioned by index when using RRF search.
	IndexScores map[string]interface{} `json:"_index_scores,omitempty,omitzero"`

	// Score Relevance score of the hit.
	Score  float64                `json:"_score"`
	Source map[string]interface{} `json:"_source,omitempty,omitzero"`
}

// QueryHits A list of query hits.
type QueryHits struct {
	Hits []QueryHit `json:"hits"`

	// MaxScore Maximum score of the results.
	MaxScore float64 `json:"max_score,omitempty,omitzero"`

	// Total Total number of hits available.
	Total uint64 `json:"total,omitempty"`
}

// QueryRequest defines model for QueryRequest.
type QueryRequest struct {
	Analyses *Analyses `json:"analyses,omitempty"`

	// Count If true, returns only the total count of matching documents without retrieving the actual documents.
	// Useful for pagination and displaying result counts.
	Count bool `json:"count,omitempty,omitzero"`

	// DistanceOver Minimum distance threshold for semantic similarity search. Results with distance
	// less than this value are excluded.
	//
	// Useful for excluding near-exact duplicates or finding dissimilar documents.
	DistanceOver *float32 `json:"distance_over,omitempty"`

	// DistanceUnder Maximum distance threshold for semantic similarity search. Results with distance
	// greater than this value are excluded. Lower distances indicate higher similarity.
	//
	// Useful for filtering out low-confidence matches.
	DistanceUnder *float32 `json:"distance_under,omitempty"`

	// DocumentRenderer Optional Handlebars template string for rendering document content in RAG queries.
	// Template has access to document fields via `{{this.fields.fieldName}}`.
	//
	// **Default**: Uses TOON (Token-Oriented Object Notation) format for 30-60% token reduction:
	// ```handlebars
	// {{encodeToon this.fields}}
	// ```
	//
	// **Available Helpers**:
	// - `encodeToon` - Renders fields in compact TOON format with configurable options:
	//   - `lengthMarker` (bool): Add # prefix to array counts (default: true)
	//   - `indent` (int): Indentation spacing (default: 2)
	//   - `delimiter` (string): Field separator for tabular arrays
	// - `scrubHtml` - Removes HTML tags and extracts text
	// - `media` - Wraps data URIs for GenKit multimodal support
	// - `eq` - Equality comparison for conditionals
	//
	// **Examples**:
	// - Basic TOON: `{{encodeToon this.fields}}`
	// - Compact TOON: `{{encodeToon this.fields lengthMarker=false indent=0}}`
	// - Tabular data: `{{encodeToon this.fields delimiter="\t"}}`
	// - Custom template: `Title: {{this.fields.title}}\nBody: {{this.fields.body}}`
	// - Traditional format: `{{#each this.fields}}{{@key}}: {{this}}\n{{/each}}`
	//
	// TOON format produces compact, LLM-optimized output like:
	// ```
	// title: Introduction to Vector Search
	// author: Jane Doe
	// tags[#3]: ai,search,ml
	// ```
	DocumentRenderer string `json:"document_renderer,omitempty,omitzero"`

	// Embeddings Pre-computed embeddings to use for semantic searches instead of embedding the semantic_search string.
	// The keys are the index names, and values are the embedding vectors.
	//
	// Use when you've already generated embeddings on the client side to avoid redundant embedding calls.
	Embeddings map[string][]float32 `json:"embeddings,omitempty,omitzero"`

	// ExclusionQuery Bleve query applied as a NOT condition. Documents matching this query are excluded
	// from results. Applied before scoring.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Excluding drafts: `"status:draft"`
	// - Removing deprecated content: `"deprecated:true"`
	// - Filtering out archived items: `"status:archived"`
	ExclusionQuery json.RawMessage `json:"exclusion_query,omitempty,omitzero"`

	// ExpandStrategy Strategy for merging graph results with search results:
	// - union: Include nodes from both search and graph results
	// - intersection: Only include nodes appearing in both
	ExpandStrategy QueryRequestExpandStrategy `json:"expand_strategy,omitempty,omitzero"`

	// Facets Faceting configuration for aggregating results by field values.
	// Useful for building faceted navigation and filters.
	Facets map[string]FacetOption `json:"facets,omitempty,omitzero"`

	// Fields List of fields to include in the results. If not specified, all fields are returned.
	// Use to reduce response size and improve performance.
	Fields []string `json:"fields,omitempty,omitzero"`

	// FilterPrefix Filter results by key prefix. Only returns documents whose keys start with this string.
	// Applied before scoring to improve performance.
	//
	// Common use cases:
	// - Multi-tenant filtering: `"tenant:acme:"`
	// - User-specific data: `"user:123:"`
	// - Document type filtering: `"article:"`
	FilterPrefix []byte `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query applied as an AND condition. Documents must match both the main query
	// and this filter. Applied before scoring for better performance.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Status filtering: `"status:published"`
	// - Date ranges: `"created_at:>2023-01-01"`
	// - Category filtering: `"category:technology AND language:en"`
	FilterQuery json.RawMessage `json:"filter_query,omitempty,omitzero"`

	// FullTextSearch Bleve query for full-text search. Supports all Bleve query types.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Examples:
	// - Simple: `{"query": "computer"}`
	// - Field-specific: `{"query": "body:computer"}`
	// - Boolean: `{"query": "artificial AND intelligence"}`
	// - Range: `{"query": "year:>2020"}`
	// - Phrase: `{"query": "\"exact phrase\""}`
	FullTextSearch json.RawMessage `json:"full_text_search,omitempty,omitzero"`

	// GraphSearches Declarative graph queries to execute after full-text/vector searches.
	// Results can reference search results using node selectors like $full_text_results.
	GraphSearches map[string]GraphQuery `json:"graph_searches,omitempty,omitzero"`

	// Indexes List of vector index names to use for semantic search. Required when using semantic_search.
	// Multiple indexes can be specified, and their results will be merged using RRF.
	Indexes []string `json:"indexes,omitempty,omitzero"`

	// Limit Maximum number of results to return. For semantic_search, this is the topk parameter.
	// Default varies by query type (typically 10).
	Limit int `json:"limit,omitempty,omitzero"`

	// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
	// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
	// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
	// failover: Use full_text_search if embedding generation fails
	MergeStrategy MergeStrategy `json:"merge_strategy,omitempty,omitzero"`

	// Offset Number of results to skip for pagination. Only available for full_text_search queries.
	// Not supported for semantic_search due to vector index limitations.
	Offset int `json:"offset,omitempty,omitzero"`

	// OrderBy Sort order for results. Map of field names to boolean (true = descending, false = ascending).
	// Only applicable for full_text_search queries. Semantic searches are always sorted by similarity score.
	OrderBy map[string]bool `json:"order_by,omitempty,omitzero"`

	// Pruner Configuration for pruning search results based on score quality.
	// Helps filter out low-relevance results in RAG pipelines by detecting
	// score gaps or deviations from top results.
	Pruner Pruner `json:"pruner,omitempty,omitzero"`

	// Reranker A unified configuration for a reranking provider.
	Reranker *RerankerConfig `json:"reranker,omitempty"`

	// SemanticSearch Natural language query for vector similarity search. Results are ranked by semantic similarity
	// to the query and can be combined with full_text_search using Reciprocal Rank Fusion (RRF).
	//
	// The semantic_search string is automatically embedded using the configured embedding model
	// for the specified indexes.
	SemanticSearch string `json:"semantic_search,omitempty,omitzero"`

	// Table Name of the table to query. Optional for global queries.
	Table string `json:"table,omitempty,omitzero"`
}

// QueryRequestExpandStrategy Strategy for merging graph results with search results:
// - union: Include nodes from both search and graph results
// - intersection: Only include nodes appearing in both
type QueryRequestExpandStrategy string

// QueryResponses Responses from multiple query operations.
type QueryResponses struct {
	Responses []QueryResult `json:"responses,omitempty,omitzero"`
}

// QueryResult Result of a query operation as an array of results and a count.
type QueryResult struct {
	// Analyses Analysis results like PCA and t-SNE per index embeddings.
	Analyses map[string]AnalysesResult `json:"analyses,omitempty,omitzero"`

	// Error Error message if the query failed.
	Error  string                 `json:"error,omitempty,omitzero"`
	Facets map[string]FacetResult `json:"facets,omitempty,omitzero"`

	// GraphResults Results from declarative graph queries.
	GraphResults map[string]GraphQueryResult `json:"graph_results,omitempty,omitzero"`

	// Hits A list of query hits.
	Hits QueryHits `json:"hits"`

	// Status HTTP status code of the query operation.
	Status int32 `json:"status"`

	// Table Which table this result came from
	Table string `json:"table,omitempty,omitzero"`

	// Took Duration of the query in milliseconds.
	Took time.Duration `json:"took"`
}

// QueryStringQuery defines model for QueryStringQuery.
type QueryStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Query string `json:"query"`
}

// RAGRequest defines model for RAGRequest.
type RAGRequest struct {
	// Prompt Optional custom user prompt template for the LLM. If not provided, a default prompt is used.
	// The prompt can reference the following variables:
	// - {{documents}}: Array of retrieved documents with id and fields
	// - {{semantic_search}}: The user's semantic search query (if provided)
	// You can use Handlebars template syntax to customize the prompt, including loops and conditionals.
	// To generate a comma-separated list of document IDs, use: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	Prompt string `json:"prompt,omitempty,omitzero"`

	// Queries Array of retrieval queries to execute. Each query must specify a table and can specify its own limit and document_renderer.
	// Results from all queries are concatenated together (respecting each query's limit).
	// For single table: [{"table": "papers", "semantic_search": "...", "limit": 10}]
	// For broadcast: [{"table": "images", "limit": 5, ...}, {"table": "products", "limit": 5, ...}]
	// For mixed: [{"table": "papers", "semantic_search": "...", "limit": 10}, {"table": "books", "full_text_search": {...}, "limit": 5}]
	Queries []QueryRequest `json:"queries"`

	// Summarizer A unified configuration for a generative AI provider.
	Summarizer GeneratorConfig `json:"summarizer"`

	// SystemPrompt Optional system prompt to guide the summarization
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// RAGResult RAG result with individual query results and summary
type RAGResult struct {
	// QueryResults Results from each query. Check each result's status and error fields for failures.
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`

	// SummaryResult Result of a summarization operation. The summary is formatted as markdown with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
	SummaryResult SummarizeResult `json:"summary_result,omitempty,omitzero"`
}

// RegexpQuery defines model for RegexpQuery.
type RegexpQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Regexp string `json:"regexp"`
}

// RerankerConfig defines model for RerankerConfig.
type RerankerConfig struct {
	// Field Field name to extract from documents for reranking.
	Field string `json:"field,omitempty,omitzero"`

	// Provider The reranking provider to use.
	Provider RerankerProvider `json:"provider"`

	// Template Handlebars template to render document text for reranking.
	Template string `json:"template,omitempty,omitzero"`
	union    json.RawMessage
}

// RerankerProvider The reranking provider to use.
type RerankerProvider string

// ResourceType Type of the resource, e.g., table, user, or global ('*').
type ResourceType string

// RestoreRequest defines model for RestoreRequest.
type RestoreRequest = BackupRequest

// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
type RouteType string

// ShardConfig defines model for ShardConfig.
type ShardConfig struct {
	ByteRange ByteRange `json:"byte_range"`
}

// StorageStatus defines model for StorageStatus.
type StorageStatus struct {
	// DiskUsage Disk usage in bytes.
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Empty Whether the table has received data.
	Empty bool `json:"empty,omitempty,omitzero"`
}

// SuccessMessage defines model for SuccessMessage.
type SuccessMessage struct {
	Message string `json:"message,omitempty,omitzero"`
}

// SummarizeResult Result of a summarization operation. The summary is formatted as markdown with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
type SummarizeResult struct {
	// Summary The generated summary text in markdown format with inline resource references like [resource_id res1] or [resource_id res1, res2]
	Summary string `json:"summary"`
}

// SyncLevel Synchronization level for batch operations:
// - "propose": Wait for Raft proposal acceptance (fastest, default)
// - "write": Wait for Pebble KV write
// - "full_text": Wait for full-text index WAL write
// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
type SyncLevel string

// Table defines model for Table.
type Table struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema            `json:"schema,omitempty,omitzero"`
	Shards map[string]ShardConfig `json:"shards"`
}

// TableSchema Schema definition for a table with multiple document types
type TableSchema struct {
	// DefaultType Default type to use from the document_types.
	DefaultType string `json:"default_type,omitempty,omitzero"`

	// DocumentSchemas A map of type names to their document json schemas.
	DocumentSchemas map[string]DocumentSchema `json:"document_schemas,omitempty,omitzero"`

	// EnforceTypes Whether to enforce that documents must match one of the provided document types.
	// If false, documents not matching any type will be accepted but not indexed.
	EnforceTypes bool `json:"enforce_types,omitempty,omitzero"`

	// TtlDuration The duration after which documents should expire, based on the ttl_field timestamp (optional).
	// Uses Go duration format (e.g., '24h', '7d', '168h').
	TtlDuration string `json:"ttl_duration,omitempty,omitzero"`

	// TtlField The field containing the timestamp for TTL expiration (optional).
	// Defaults to "_timestamp" if ttl_duration is specified but ttl_field is not.
	TtlField string `json:"ttl_field,omitempty,omitzero"`

	// Version Version of the schema. Used for migrations.
	Version uint32 `json:"version,omitempty,omitzero"`
}

// TableStatus defines model for TableStatus.
type TableStatus struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema        TableSchema            `json:"schema,omitempty,omitzero"`
	Shards        map[string]ShardConfig `json:"shards"`
	StorageStatus StorageStatus          `json:"storage_status"`
}

// TermFacetResult defines model for TermFacetResult.
type TermFacetResult struct {
	Count int    `json:"count"`
	Term  string `json:"term"`
}

// TermQuery defines model for TermQuery.
type TermQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
	Term  string `json:"term"`
}

// TermRangeQuery defines model for TermRangeQuery.
type TermRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost  `json:"boost,omitzero"`
	Field        string `json:"field,omitempty,omitzero"`
	InclusiveMax bool   `json:"inclusive_max,omitzero"`
	InclusiveMin bool   `json:"inclusive_min,omitzero"`
	Max          string `json:"max,omitzero"`
	Min          string `json:"min,omitzero"`
}

// TermiteChunkerConfig Configuration for the Termite chunking provider.
//
// Termite is a centralized HTTP service that provides chunking with multi-tier caching.
// It supports multiple chunking strategies similar to how generators support different models.
//
// **Chunking Strategies:**
// - hugot: ONNX-accelerated chunking using sentence boundary detection
// - fixed: Simple fixed-size chunking by token count (default, no ONNX required)
//
// **Caching:**
// - L1: Memory cache with 2-minute TTL
// - L2: Persistent Pebble database
// - Singleflight deduplication for concurrent identical requests
type TermiteChunkerConfig struct {
	// ApiUrl The URL of the Termite API endpoint (e.g., 'http://localhost:8080'). Can also be set via ANTFLY_TERMITE_URL environment variable.
	ApiUrl string `json:"api_url,omitempty,omitzero"`

	// FullText Configuration for full-text indexing of chunks in Bleve.
	// When present (even if empty), chunks will be stored with :cft: suffix and indexed in Bleve's _chunks field.
	// When absent, chunks use :c: suffix and are only used for vector embeddings.
	// This object is reserved for future options like boosting, field mapping, etc.
	FullText map[string]interface{} `json:"full_text,omitempty,omitzero"`

	// MaxChunks Maximum number of chunks to generate per document. Prevents excessive chunking of very large documents.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs). Only used with fixed strategy.
	Separator string `json:"separator,omitempty,omitzero"`

	// Strategy Document chunking strategy.
	// - hugot: ONNX-accelerated chunking using sentence boundary detection
	// - fixed: Simple fixed-size chunking by token count
	Strategy ChunkingStrategy `json:"strategy"`

	// TargetTokens Target number of tokens per chunk. Chunker will aim for chunks around this size.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`

	// Threshold Minimum confidence threshold for separator detection. Only used with hugot strategy.
	Threshold float32 `json:"threshold,omitempty,omitzero"`
}

// TermiteRerankerConfig Configuration for the Termite reranking provider.
type TermiteRerankerConfig struct {
	// Model The name of the reranking model (e.g., cross-encoder model name).
	Model string `json:"model"`

	// Url The URL of the Termite API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// Transform In-place document transformation using MongoDB-style operators. Transforms are applied atomically
// at the storage layer, eliminating read-modify-write races.
//
// **Important:** Transform results are NOT validated against the table schema. This improves performance
// but means it's possible to create invalid documents. Use with care and ensure your operations maintain
// schema compliance.
type Transform struct {
	// Key Document key (must be a string, not an object like inserts)
	Key string `json:"key"`

	// Operations List of operations to apply in sequence
	Operations []TransformOp `json:"operations"`

	// Upsert If true, create document if it doesn't exist (like MongoDB upsert)
	Upsert bool `json:"upsert,omitempty,omitzero"`
}

// TransformOp defines model for TransformOp.
type TransformOp struct {
	// Op MongoDB-style update operator
	Op TransformOpType `json:"op"`

	// Path JSONPath to field (e.g., "$.user.name", "$.tags", or "user.name")
	Path string `json:"path"`

	// Value Value for operation (not required for $unset, $currentDate). Type depends on operator (number for $inc/$mul, any for $set, etc.)
	Value interface{} `json:"value,omitempty,omitzero"`
}

// TransformOpType MongoDB-style update operator
type TransformOpType string

// TraversalResult A single result from graph traversal
type TraversalResult struct {
	// Depth Distance from start node (0 = start node)
	Depth int `json:"depth"`

	// Document Document data (if loaded)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Key Base64-encoded document key
	Key []byte `json:"key"`

	// Path Sequence of keys from start to this node (if include_paths=true)
	Path [][]byte `json:"path,omitempty,omitzero"`

	// PathEdges Sequence of edges from start to this node (if include_paths=true)
	PathEdges []Edge `json:"path_edges,omitempty,omitzero"`

	// TotalWeight Product of edge weights along the path
	TotalWeight float64 `json:"total_weight,omitempty,omitzero"`
}

// TraversalRules Rules for graph traversal
type TraversalRules struct {
	// DeduplicateNodes Visit each node only once
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter edges by type (empty = all types)
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information in results
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth (0 = unlimited)
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum results to return (0 = unlimited)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight filter
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight filter
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`
}

// TraverseResponse defines model for TraverseResponse.
type TraverseResponse struct {
	// Count Total number of results
	Count   int               `json:"count,omitempty,omitzero"`
	Results []TraversalResult `json:"results,omitempty,omitzero"`
}

// UpdatePasswordRequest defines model for UpdatePasswordRequest.
type UpdatePasswordRequest struct {
	NewPassword string `json:"new_password"`
}

// User defines model for User.
type User struct {
	// PasswordHash Base64 encoded password hash. Exposing this is a security risk.
	PasswordHash []byte `json:"password_hash"`
	Username     string `json:"username"`
}

// UserContext Optional user context to customize the content guidance for each section of the answer agent response.
//
// **What you can customize**: Style, tone, length, detail level, and focus of content for each section independently.
//
// **What is fixed**: The response format is always markdown with consistent structure (## Reasoning, ## Answer, ## Follow-up Questions).
// Markdown formatting (headings, bullets, code blocks, etc.) is always applied and cannot be disabled.
//
// **Architecture**: These contexts are passed as template variables to the prompt template. Defaults are set
// at the application layer, and users can override them via this API to customize content guidance.
type UserContext struct {
	// AnswerContext Custom content guidance for the answer section. Controls the tone, content depth, level of detail,
	// and what information to emphasize. Does not control markdown formatting (which is always applied).
	AnswerContext string `json:"answer_context,omitempty,omitzero"`

	// FollowupContext Custom content guidance for follow-up questions. Controls the quantity, focus area, tone,
	// and style of follow-up questions. Does not control markdown formatting.
	FollowupContext string `json:"followup_context,omitempty,omitzero"`

	// ReasoningContext Custom content guidance for the reasoning section. Controls what information to include,
	// the level of detail, and the focus of the reasoning process. Does not control markdown formatting.
	ReasoningContext string `json:"reasoning_context,omitempty,omitzero"`
}

// VertexEmbedderConfig Configuration for Google Cloud Vertex AI embedding models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication by default.
// Suitable for production deployments on Google Cloud Platform.
//
// **Authentication Priority:**
// 1. credentials_path (path to service account key file)
// 2. GOOGLE_APPLICATION_CREDENTIALS environment variable
// 3. Application Default Credentials (ADC) - RECOMMENDED
//   - In GCP: automatic (Cloud Run, GKE, Compute Engine)
//   - Local dev: `gcloud auth application-default login`
//
// **Required IAM Permission:** `roles/aiplatform.user`
//
// **Supported Models:**
// - text-embedding-004 (latest, 768 dimensions)
// - textembedding-gecko@003, @002, @001 (legacy)
// - textembedding-gecko-multilingual@001 (multilingual support)
// - text-multilingual-embedding-002 (multilingual, 768 dimensions)
// - multimodalembedding (images, audio, video - 128/256/512/1408 dimensions)
type VertexEmbedderConfig struct {
	// CredentialsPath Path to service account JSON key file. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Dimension The dimension of the embedding vector. Model-specific (e.g., 768 for text-embedding-004, 128-1408 for multimodalembedding).
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the Vertex AI embedding model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`
}

// VertexGeneratorConfig Configuration for Google Cloud Vertex AI generative models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication by default.
// Suitable for production deployments on Google Cloud Platform.
//
// **Authentication Priority:**
// 1. credentials_path (path to service account key file)
// 2. GOOGLE_APPLICATION_CREDENTIALS environment variable
// 3. Application Default Credentials (ADC) - RECOMMENDED
//   - In GCP: automatic (Cloud Run, GKE, Compute Engine)
//   - Local dev: `gcloud auth application-default login`
//
// **Note:** credentials_json is not supported by the genkit VertexAI plugin.
// Use credentials_path or ADC instead.
//
// **Required IAM Permission:** `roles/aiplatform.user`
//
// **Supported Models:**
// - gemini-2.5-flash (default, fast and efficient)
// - gemini-1.5-pro (balanced performance)
// - gemini-1.5-flash (cost-effective)
// - gemini-2.0-pro (advanced reasoning)
//
// Defaults to gemini-2.5-flash if no model is specified.
type VertexGeneratorConfig struct {
	// CredentialsPath Path to service account JSON key file. Sets GOOGLE_APPLICATION_CREDENTIALS environment variable. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Vertex AI model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// WildcardQuery defines model for WildcardQuery.
type WildcardQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Field    string `json:"field,omitempty,omitzero"`
	Wildcard string `json:"wildcard"`
}

// UserNamePathParameter defines model for UserNamePathParameter.
type UserNamePathParameter = string

// BadRequest defines model for BadRequest.
type BadRequest = Error

// InternalServerError defines model for InternalServerError.
type InternalServerError = Error

// NotFound defines model for NotFound.
type NotFound = Error

// ListTablesParams defines parameters for ListTables.
type ListTablesParams struct {
	// Prefix Filter tables by name prefix (e.g., "prod_")
	Prefix string `form:"prefix,omitempty" json:"prefix,omitempty,omitzero"`

	// Pattern Filter tables by regex pattern (e.g., "^prod_.*_v[0-9]+$")
	Pattern string `form:"pattern,omitempty" json:"pattern,omitempty,omitzero"`
}

// RemovePermissionFromUserParams defines parameters for RemovePermissionFromUser.
type RemovePermissionFromUserParams struct {
	// Resource The name of the resource for the permission to be removed.
	Resource string `form:"resource" json:"resource"`

	// ResourceType The type of the resource for the permission to be removed.
	ResourceType ResourceType `form:"resourceType" json:"resourceType"`
}

// AnswerAgentJSONRequestBody defines body for AnswerAgent for application/json ContentType.
type AnswerAgentJSONRequestBody = AnswerAgentRequest

// GlobalQueryJSONRequestBody defines body for GlobalQuery for application/json ContentType.
type GlobalQueryJSONRequestBody = QueryRequest

// RagQueryJSONRequestBody defines body for RagQuery for application/json ContentType.
type RagQueryJSONRequestBody = RAGRequest

// CreateTableJSONRequestBody defines body for CreateTable for application/json ContentType.
type CreateTableJSONRequestBody = CreateTableRequest

// BackupTableJSONRequestBody defines body for BackupTable for application/json ContentType.
type BackupTableJSONRequestBody = BackupRequest

// BatchJSONRequestBody defines body for Batch for application/json ContentType.
type BatchJSONRequestBody = BatchRequest

// CreateIndexJSONRequestBody defines body for CreateIndex for application/json ContentType.
type CreateIndexJSONRequestBody = IndexConfig

// LinearMergeJSONRequestBody defines body for LinearMerge for application/json ContentType.
type LinearMergeJSONRequestBody = LinearMergeRequest

// QueryTableJSONRequestBody defines body for QueryTable for application/json ContentType.
type QueryTableJSONRequestBody = QueryRequest

// TableRagQueryJSONRequestBody defines body for TableRagQuery for application/json ContentType.
type TableRagQueryJSONRequestBody = RAGRequest

// RestoreTableJSONRequestBody defines body for RestoreTable for application/json ContentType.
type RestoreTableJSONRequestBody = RestoreRequest

// UpdateSchemaJSONRequestBody defines body for UpdateSchema for application/json ContentType.
type UpdateSchemaJSONRequestBody = TableSchema

// CreateUserJSONRequestBody defines body for CreateUser for application/json ContentType.
type CreateUserJSONRequestBody = CreateUserRequest

// UpdateUserPasswordJSONRequestBody defines body for UpdateUserPassword for application/json ContentType.
type UpdateUserPasswordJSONRequestBody = UpdatePasswordRequest

// AddPermissionToUserJSONRequestBody defines body for AddPermissionToUser for application/json ContentType.
type AddPermissionToUserJSONRequestBody = Permission

// Getter for additional properties for ClusterStatus. Returns the specified
// element and whether it was found
func (a ClusterStatus) Get(fieldName string) (value interface{}, found bool) {
	if a.AdditionalProperties != nil {
		value, found = a.AdditionalProperties[fieldName]
	}
	return
}

// Setter for additional properties for ClusterStatus
func (a *ClusterStatus) Set(fieldName string, value interface{}) {
	if a.AdditionalProperties == nil {
		a.AdditionalProperties = make(map[string]interface{})
	}
	a.AdditionalProperties[fieldName] = value
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a *ClusterStatus) UnmarshalJSON(b []byte) error {
	object := make(map[string]json.RawMessage)
	err := json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["auth_enabled"]; found {
		err = json.Unmarshal(raw, &a.AuthEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'auth_enabled': %w", err)
		}
		delete(object, "auth_enabled")
	}

	if raw, found := object["health"]; found {
		err = json.Unmarshal(raw, &a.Health)
		if err != nil {
			return fmt.Errorf("error reading 'health': %w", err)
		}
		delete(object, "health")
	}

	if raw, found := object["message"]; found {
		err = json.Unmarshal(raw, &a.Message)
		if err != nil {
			return fmt.Errorf("error reading 'message': %w", err)
		}
		delete(object, "message")
	}

	if len(object) != 0 {
		a.AdditionalProperties = make(map[string]interface{})
		for fieldName, fieldBuf := range object {
			var fieldVal interface{}
			err := json.Unmarshal(fieldBuf, &fieldVal)
			if err != nil {
				return fmt.Errorf("error unmarshaling field %s: %w", fieldName, err)
			}
			a.AdditionalProperties[fieldName] = fieldVal
		}
	}
	return nil
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a ClusterStatus) MarshalJSON() ([]byte, error) {
	var err error
	object := make(map[string]json.RawMessage)

	object["auth_enabled"], err = json.Marshal(a.AuthEnabled)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'auth_enabled': %w", err)
	}

	object["health"], err = json.Marshal(a.Health)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'health': %w", err)
	}

	object["message"], err = json.Marshal(a.Message)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'message': %w", err)
	}

	for fieldName, field := range a.AdditionalProperties {
		object[fieldName], err = json.Marshal(field)
		if err != nil {
			return nil, fmt.Errorf("error marshaling '%s': %w", fieldName, err)
		}
	}
	return json.Marshal(object)
}

// AsTermiteChunkerConfig returns the union data inside the ChunkerConfig as a TermiteChunkerConfig
func (t ChunkerConfig) AsTermiteChunkerConfig() (TermiteChunkerConfig, error) {
	var body TermiteChunkerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteChunkerConfig overwrites any union data inside the ChunkerConfig as the provided TermiteChunkerConfig
func (t *ChunkerConfig) FromTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteChunkerConfig performs a merge with any union data inside the ChunkerConfig, using the provided TermiteChunkerConfig
func (t *ChunkerConfig) MergeTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAntflyChunkerConfig returns the union data inside the ChunkerConfig as a AntflyChunkerConfig
func (t ChunkerConfig) AsAntflyChunkerConfig() (AntflyChunkerConfig, error) {
	var body AntflyChunkerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAntflyChunkerConfig overwrites any union data inside the ChunkerConfig as the provided AntflyChunkerConfig
func (t *ChunkerConfig) FromAntflyChunkerConfig(v AntflyChunkerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAntflyChunkerConfig performs a merge with any union data inside the ChunkerConfig, using the provided AntflyChunkerConfig
func (t *ChunkerConfig) MergeAntflyChunkerConfig(v AntflyChunkerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t ChunkerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *ChunkerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsGoogleEmbedderConfig returns the union data inside the EmbedderConfig as a GoogleEmbedderConfig
func (t EmbedderConfig) AsGoogleEmbedderConfig() (GoogleEmbedderConfig, error) {
	var body GoogleEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided GoogleEmbedderConfig
func (t *EmbedderConfig) FromGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided GoogleEmbedderConfig
func (t *EmbedderConfig) MergeGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexEmbedderConfig returns the union data inside the EmbedderConfig as a VertexEmbedderConfig
func (t EmbedderConfig) AsVertexEmbedderConfig() (VertexEmbedderConfig, error) {
	var body VertexEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided VertexEmbedderConfig
func (t *EmbedderConfig) FromVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided VertexEmbedderConfig
func (t *EmbedderConfig) MergeVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaEmbedderConfig returns the union data inside the EmbedderConfig as a OllamaEmbedderConfig
func (t EmbedderConfig) AsOllamaEmbedderConfig() (OllamaEmbedderConfig, error) {
	var body OllamaEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OllamaEmbedderConfig
func (t *EmbedderConfig) FromOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OllamaEmbedderConfig
func (t *EmbedderConfig) MergeOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIEmbedderConfig returns the union data inside the EmbedderConfig as a OpenAIEmbedderConfig
func (t EmbedderConfig) AsOpenAIEmbedderConfig() (OpenAIEmbedderConfig, error) {
	var body OpenAIEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) FromOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) MergeOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockEmbedderConfig returns the union data inside the EmbedderConfig as a BedrockEmbedderConfig
func (t EmbedderConfig) AsBedrockEmbedderConfig() (BedrockEmbedderConfig, error) {
	var body BedrockEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided BedrockEmbedderConfig
func (t *EmbedderConfig) FromBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided BedrockEmbedderConfig
func (t *EmbedderConfig) MergeBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t EmbedderConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *EmbedderConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsFuzziness0 returns the union data inside the Fuzziness as a Fuzziness0
func (t Fuzziness) AsFuzziness0() (Fuzziness0, error) {
	var body Fuzziness0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness0 overwrites any union data inside the Fuzziness as the provided Fuzziness0
func (t *Fuzziness) FromFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness0 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness0
func (t *Fuzziness) MergeFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzziness1 returns the union data inside the Fuzziness as a Fuzziness1
func (t Fuzziness) AsFuzziness1() (Fuzziness1, error) {
	var body Fuzziness1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness1 overwrites any union data inside the Fuzziness as the provided Fuzziness1
func (t *Fuzziness) FromFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness1 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness1
func (t *Fuzziness) MergeFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Fuzziness) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Fuzziness) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsGoogleGeneratorConfig returns the union data inside the GeneratorConfig as a GoogleGeneratorConfig
func (t GeneratorConfig) AsGoogleGeneratorConfig() (GoogleGeneratorConfig, error) {
	var body GoogleGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided GoogleGeneratorConfig
func (t *GeneratorConfig) FromGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided GoogleGeneratorConfig
func (t *GeneratorConfig) MergeGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexGeneratorConfig returns the union data inside the GeneratorConfig as a VertexGeneratorConfig
func (t GeneratorConfig) AsVertexGeneratorConfig() (VertexGeneratorConfig, error) {
	var body VertexGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided VertexGeneratorConfig
func (t *GeneratorConfig) FromVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided VertexGeneratorConfig
func (t *GeneratorConfig) MergeVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaGeneratorConfig returns the union data inside the GeneratorConfig as a OllamaGeneratorConfig
func (t GeneratorConfig) AsOllamaGeneratorConfig() (OllamaGeneratorConfig, error) {
	var body OllamaGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OllamaGeneratorConfig
func (t *GeneratorConfig) FromOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OllamaGeneratorConfig
func (t *GeneratorConfig) MergeOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIGeneratorConfig returns the union data inside the GeneratorConfig as a OpenAIGeneratorConfig
func (t GeneratorConfig) AsOpenAIGeneratorConfig() (OpenAIGeneratorConfig, error) {
	var body OpenAIGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) FromOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) MergeOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockGeneratorConfig returns the union data inside the GeneratorConfig as a BedrockGeneratorConfig
func (t GeneratorConfig) AsBedrockGeneratorConfig() (BedrockGeneratorConfig, error) {
	var body BedrockGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided BedrockGeneratorConfig
func (t *GeneratorConfig) FromBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided BedrockGeneratorConfig
func (t *GeneratorConfig) MergeBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAnthropicGeneratorConfig returns the union data inside the GeneratorConfig as a AnthropicGeneratorConfig
func (t GeneratorConfig) AsAnthropicGeneratorConfig() (AnthropicGeneratorConfig, error) {
	var body AnthropicGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAnthropicGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) FromAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAnthropicGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) MergeAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t GeneratorConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *GeneratorConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Config returns the union data inside the IndexConfig as a BleveIndexV2Config
func (t IndexConfig) AsBleveIndexV2Config() (BleveIndexV2Config, error) {
	var body BleveIndexV2Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Config overwrites any union data inside the IndexConfig as the provided BleveIndexV2Config
func (t *IndexConfig) FromBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Config performs a merge with any union data inside the IndexConfig, using the provided BleveIndexV2Config
func (t *IndexConfig) MergeBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexConfig returns the union data inside the IndexConfig as a EmbeddingIndexConfig
func (t IndexConfig) AsEmbeddingIndexConfig() (EmbeddingIndexConfig, error) {
	var body EmbeddingIndexConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexConfig overwrites any union data inside the IndexConfig as the provided EmbeddingIndexConfig
func (t *IndexConfig) FromEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexConfig performs a merge with any union data inside the IndexConfig, using the provided EmbeddingIndexConfig
func (t *IndexConfig) MergeEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Config returns the union data inside the IndexConfig as a GraphIndexV0Config
func (t IndexConfig) AsGraphIndexV0Config() (GraphIndexV0Config, error) {
	var body GraphIndexV0Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Config overwrites any union data inside the IndexConfig as the provided GraphIndexV0Config
func (t *IndexConfig) FromGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Config performs a merge with any union data inside the IndexConfig, using the provided GraphIndexV0Config
func (t *IndexConfig) MergeGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["description"], err = json.Marshal(t.Description)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'description': %w", err)
	}

	object["enrichments"], err = json.Marshal(t.Enrichments)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'enrichments': %w", err)
	}

	object["name"], err = json.Marshal(t.Name)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'name': %w", err)
	}

	object["type"], err = json.Marshal(t.Type)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'type': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *IndexConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["description"]; found {
		err = json.Unmarshal(raw, &t.Description)
		if err != nil {
			return fmt.Errorf("error reading 'description': %w", err)
		}
	}

	if raw, found := object["enrichments"]; found {
		err = json.Unmarshal(raw, &t.Enrichments)
		if err != nil {
			return fmt.Errorf("error reading 'enrichments': %w", err)
		}
	}

	if raw, found := object["name"]; found {
		err = json.Unmarshal(raw, &t.Name)
		if err != nil {
			return fmt.Errorf("error reading 'name': %w", err)
		}
	}

	if raw, found := object["type"]; found {
		err = json.Unmarshal(raw, &t.Type)
		if err != nil {
			return fmt.Errorf("error reading 'type': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Stats returns the union data inside the IndexStats as a BleveIndexV2Stats
func (t IndexStats) AsBleveIndexV2Stats() (BleveIndexV2Stats, error) {
	var body BleveIndexV2Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Stats overwrites any union data inside the IndexStats as the provided BleveIndexV2Stats
func (t *IndexStats) FromBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Stats performs a merge with any union data inside the IndexStats, using the provided BleveIndexV2Stats
func (t *IndexStats) MergeBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexStats returns the union data inside the IndexStats as a EmbeddingIndexStats
func (t IndexStats) AsEmbeddingIndexStats() (EmbeddingIndexStats, error) {
	var body EmbeddingIndexStats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexStats overwrites any union data inside the IndexStats as the provided EmbeddingIndexStats
func (t *IndexStats) FromEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexStats performs a merge with any union data inside the IndexStats, using the provided EmbeddingIndexStats
func (t *IndexStats) MergeEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Stats returns the union data inside the IndexStats as a GraphIndexV0Stats
func (t IndexStats) AsGraphIndexV0Stats() (GraphIndexV0Stats, error) {
	var body GraphIndexV0Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Stats overwrites any union data inside the IndexStats as the provided GraphIndexV0Stats
func (t *IndexStats) FromGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Stats performs a merge with any union data inside the IndexStats, using the provided GraphIndexV0Stats
func (t *IndexStats) MergeGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexStats) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *IndexStats) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsTermQuery returns the union data inside the Query as a TermQuery
func (t Query) AsTermQuery() (TermQuery, error) {
	var body TermQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermQuery overwrites any union data inside the Query as the provided TermQuery
func (t *Query) FromTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermQuery performs a merge with any union data inside the Query, using the provided TermQuery
func (t *Query) MergeTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchQuery returns the union data inside the Query as a MatchQuery
func (t Query) AsMatchQuery() (MatchQuery, error) {
	var body MatchQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchQuery overwrites any union data inside the Query as the provided MatchQuery
func (t *Query) FromMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchQuery performs a merge with any union data inside the Query, using the provided MatchQuery
func (t *Query) MergeMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchPhraseQuery returns the union data inside the Query as a MatchPhraseQuery
func (t Query) AsMatchPhraseQuery() (MatchPhraseQuery, error) {
	var body MatchPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchPhraseQuery overwrites any union data inside the Query as the provided MatchPhraseQuery
func (t *Query) FromMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchPhraseQuery performs a merge with any union data inside the Query, using the provided MatchPhraseQuery
func (t *Query) MergeMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPhraseQuery returns the union data inside the Query as a PhraseQuery
func (t Query) AsPhraseQuery() (PhraseQuery, error) {
	var body PhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPhraseQuery overwrites any union data inside the Query as the provided PhraseQuery
func (t *Query) FromPhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePhraseQuery performs a merge with any union data inside the Query, using the provided PhraseQuery
func (t *Query) MergePhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMultiPhraseQuery returns the union data inside the Query as a MultiPhraseQuery
func (t Query) AsMultiPhraseQuery() (MultiPhraseQuery, error) {
	var body MultiPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMultiPhraseQuery overwrites any union data inside the Query as the provided MultiPhraseQuery
func (t *Query) FromMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMultiPhraseQuery performs a merge with any union data inside the Query, using the provided MultiPhraseQuery
func (t *Query) MergeMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzzyQuery returns the union data inside the Query as a FuzzyQuery
func (t Query) AsFuzzyQuery() (FuzzyQuery, error) {
	var body FuzzyQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzzyQuery overwrites any union data inside the Query as the provided FuzzyQuery
func (t *Query) FromFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzzyQuery performs a merge with any union data inside the Query, using the provided FuzzyQuery
func (t *Query) MergeFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPrefixQuery returns the union data inside the Query as a PrefixQuery
func (t Query) AsPrefixQuery() (PrefixQuery, error) {
	var body PrefixQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPrefixQuery overwrites any union data inside the Query as the provided PrefixQuery
func (t *Query) FromPrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePrefixQuery performs a merge with any union data inside the Query, using the provided PrefixQuery
func (t *Query) MergePrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsRegexpQuery returns the union data inside the Query as a RegexpQuery
func (t Query) AsRegexpQuery() (RegexpQuery, error) {
	var body RegexpQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromRegexpQuery overwrites any union data inside the Query as the provided RegexpQuery
func (t *Query) FromRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeRegexpQuery performs a merge with any union data inside the Query, using the provided RegexpQuery
func (t *Query) MergeRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsWildcardQuery returns the union data inside the Query as a WildcardQuery
func (t Query) AsWildcardQuery() (WildcardQuery, error) {
	var body WildcardQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromWildcardQuery overwrites any union data inside the Query as the provided WildcardQuery
func (t *Query) FromWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeWildcardQuery performs a merge with any union data inside the Query, using the provided WildcardQuery
func (t *Query) MergeWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsQueryStringQuery returns the union data inside the Query as a QueryStringQuery
func (t Query) AsQueryStringQuery() (QueryStringQuery, error) {
	var body QueryStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromQueryStringQuery overwrites any union data inside the Query as the provided QueryStringQuery
func (t *Query) FromQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeQueryStringQuery performs a merge with any union data inside the Query, using the provided QueryStringQuery
func (t *Query) MergeQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsNumericRangeQuery returns the union data inside the Query as a NumericRangeQuery
func (t Query) AsNumericRangeQuery() (NumericRangeQuery, error) {
	var body NumericRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromNumericRangeQuery overwrites any union data inside the Query as the provided NumericRangeQuery
func (t *Query) FromNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeNumericRangeQuery performs a merge with any union data inside the Query, using the provided NumericRangeQuery
func (t *Query) MergeNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermRangeQuery returns the union data inside the Query as a TermRangeQuery
func (t Query) AsTermRangeQuery() (TermRangeQuery, error) {
	var body TermRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermRangeQuery overwrites any union data inside the Query as the provided TermRangeQuery
func (t *Query) FromTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermRangeQuery performs a merge with any union data inside the Query, using the provided TermRangeQuery
func (t *Query) MergeTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDateRangeStringQuery returns the union data inside the Query as a DateRangeStringQuery
func (t Query) AsDateRangeStringQuery() (DateRangeStringQuery, error) {
	var body DateRangeStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDateRangeStringQuery overwrites any union data inside the Query as the provided DateRangeStringQuery
func (t *Query) FromDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDateRangeStringQuery performs a merge with any union data inside the Query, using the provided DateRangeStringQuery
func (t *Query) MergeDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBooleanQuery returns the union data inside the Query as a BooleanQuery
func (t Query) AsBooleanQuery() (BooleanQuery, error) {
	var body BooleanQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBooleanQuery overwrites any union data inside the Query as the provided BooleanQuery
func (t *Query) FromBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBooleanQuery performs a merge with any union data inside the Query, using the provided BooleanQuery
func (t *Query) MergeBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsConjunctionQuery returns the union data inside the Query as a ConjunctionQuery
func (t Query) AsConjunctionQuery() (ConjunctionQuery, error) {
	var body ConjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromConjunctionQuery overwrites any union data inside the Query as the provided ConjunctionQuery
func (t *Query) FromConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeConjunctionQuery performs a merge with any union data inside the Query, using the provided ConjunctionQuery
func (t *Query) MergeConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDisjunctionQuery returns the union data inside the Query as a DisjunctionQuery
func (t Query) AsDisjunctionQuery() (DisjunctionQuery, error) {
	var body DisjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDisjunctionQuery overwrites any union data inside the Query as the provided DisjunctionQuery
func (t *Query) FromDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDisjunctionQuery performs a merge with any union data inside the Query, using the provided DisjunctionQuery
func (t *Query) MergeDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchAllQuery returns the union data inside the Query as a MatchAllQuery
func (t Query) AsMatchAllQuery() (MatchAllQuery, error) {
	var body MatchAllQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchAllQuery overwrites any union data inside the Query as the provided MatchAllQuery
func (t *Query) FromMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchAllQuery performs a merge with any union data inside the Query, using the provided MatchAllQuery
func (t *Query) MergeMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchNoneQuery returns the union data inside the Query as a MatchNoneQuery
func (t Query) AsMatchNoneQuery() (MatchNoneQuery, error) {
	var body MatchNoneQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchNoneQuery overwrites any union data inside the Query as the provided MatchNoneQuery
func (t *Query) FromMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchNoneQuery performs a merge with any union data inside the Query, using the provided MatchNoneQuery
func (t *Query) MergeMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDocIdQuery returns the union data inside the Query as a DocIdQuery
func (t Query) AsDocIdQuery() (DocIdQuery, error) {
	var body DocIdQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDocIdQuery overwrites any union data inside the Query as the provided DocIdQuery
func (t *Query) FromDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDocIdQuery performs a merge with any union data inside the Query, using the provided DocIdQuery
func (t *Query) MergeDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBoolFieldQuery returns the union data inside the Query as a BoolFieldQuery
func (t Query) AsBoolFieldQuery() (BoolFieldQuery, error) {
	var body BoolFieldQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBoolFieldQuery overwrites any union data inside the Query as the provided BoolFieldQuery
func (t *Query) FromBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBoolFieldQuery performs a merge with any union data inside the Query, using the provided BoolFieldQuery
func (t *Query) MergeBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsIPRangeQuery returns the union data inside the Query as a IPRangeQuery
func (t Query) AsIPRangeQuery() (IPRangeQuery, error) {
	var body IPRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromIPRangeQuery overwrites any union data inside the Query as the provided IPRangeQuery
func (t *Query) FromIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeIPRangeQuery performs a merge with any union data inside the Query, using the provided IPRangeQuery
func (t *Query) MergeIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingBoxQuery returns the union data inside the Query as a GeoBoundingBoxQuery
func (t Query) AsGeoBoundingBoxQuery() (GeoBoundingBoxQuery, error) {
	var body GeoBoundingBoxQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingBoxQuery overwrites any union data inside the Query as the provided GeoBoundingBoxQuery
func (t *Query) FromGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingBoxQuery performs a merge with any union data inside the Query, using the provided GeoBoundingBoxQuery
func (t *Query) MergeGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoDistanceQuery returns the union data inside the Query as a GeoDistanceQuery
func (t Query) AsGeoDistanceQuery() (GeoDistanceQuery, error) {
	var body GeoDistanceQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoDistanceQuery overwrites any union data inside the Query as the provided GeoDistanceQuery
func (t *Query) FromGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoDistanceQuery performs a merge with any union data inside the Query, using the provided GeoDistanceQuery
func (t *Query) MergeGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingPolygonQuery returns the union data inside the Query as a GeoBoundingPolygonQuery
func (t Query) AsGeoBoundingPolygonQuery() (GeoBoundingPolygonQuery, error) {
	var body GeoBoundingPolygonQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingPolygonQuery overwrites any union data inside the Query as the provided GeoBoundingPolygonQuery
func (t *Query) FromGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingPolygonQuery performs a merge with any union data inside the Query, using the provided GeoBoundingPolygonQuery
func (t *Query) MergeGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoShapeQuery returns the union data inside the Query as a GeoShapeQuery
func (t Query) AsGeoShapeQuery() (GeoShapeQuery, error) {
	var body GeoShapeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoShapeQuery overwrites any union data inside the Query as the provided GeoShapeQuery
func (t *Query) FromGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoShapeQuery performs a merge with any union data inside the Query, using the provided GeoShapeQuery
func (t *Query) MergeGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Query) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Query) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsOllamaRerankerConfig returns the union data inside the RerankerConfig as a OllamaRerankerConfig
func (t RerankerConfig) AsOllamaRerankerConfig() (OllamaRerankerConfig, error) {
	var body OllamaRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaRerankerConfig overwrites any union data inside the RerankerConfig as the provided OllamaRerankerConfig
func (t *RerankerConfig) FromOllamaRerankerConfig(v OllamaRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided OllamaRerankerConfig
func (t *RerankerConfig) MergeOllamaRerankerConfig(v OllamaRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermiteRerankerConfig returns the union data inside the RerankerConfig as a TermiteRerankerConfig
func (t RerankerConfig) AsTermiteRerankerConfig() (TermiteRerankerConfig, error) {
	var body TermiteRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteRerankerConfig overwrites any union data inside the RerankerConfig as the provided TermiteRerankerConfig
func (t *RerankerConfig) FromTermiteRerankerConfig(v TermiteRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided TermiteRerankerConfig
func (t *RerankerConfig) MergeTermiteRerankerConfig(v TermiteRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t RerankerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["field"], err = json.Marshal(t.Field)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'field': %w", err)
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	object["template"], err = json.Marshal(t.Template)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'template': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *RerankerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["field"]; found {
		err = json.Unmarshal(raw, &t.Field)
		if err != nil {
			return fmt.Errorf("error reading 'field': %w", err)
		}
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	if raw, found := object["template"]; found {
		err = json.Unmarshal(raw, &t.Template)
		if err != nil {
			return fmt.Errorf("error reading 'template': %w", err)
		}
	}

	return err
}

// RequestEditorFn  is the function signature for the RequestEditor callback function
type RequestEditorFn func(ctx context.Context, req *http.Request) error

// Doer performs HTTP requests.
//
// The standard http.Client implements this interface.
type HttpRequestDoer interface {
	Do(req *http.Request) (*http.Response, error)
}

// Client which conforms to the OpenAPI3 specification for this service.
type Client struct {
	// The endpoint of the server conforming to this interface, with scheme,
	// https://api.deepmap.com for example. This can contain a path relative
	// to the server, such as https://api.deepmap.com/dev-test, and all the
	// paths in the swagger spec will be appended to the server.
	Server string

	// Doer for performing requests, typically a *http.Client with any
	// customized settings, such as certificate chains.
	Client HttpRequestDoer

	// A list of callbacks for modifying requests which are generated before sending over
	// the network.
	RequestEditors []RequestEditorFn
}

// ClientOption allows setting custom parameters during construction
type ClientOption func(*Client) error

// Creates a new Client, with reasonable defaults
func NewClient(server string, opts ...ClientOption) (*Client, error) {
	// create a client with sane default values
	client := Client{
		Server: server,
	}
	// mutate client and add all optional params
	for _, o := range opts {
		if err := o(&client); err != nil {
			return nil, err
		}
	}
	// ensure the server URL always has a trailing slash
	if !strings.HasSuffix(client.Server, "/") {
		client.Server += "/"
	}
	// create httpClient, if not already present
	if client.Client == nil {
		client.Client = &http.Client{}
	}
	return &client, nil
}

// WithHTTPClient allows overriding the default Doer, which is
// automatically created using http.Client. This is useful for tests.
func WithHTTPClient(doer HttpRequestDoer) ClientOption {
	return func(c *Client) error {
		c.Client = doer
		return nil
	}
}

// WithRequestEditorFn allows setting up a callback function, which will be
// called right before sending the request. This can be used to mutate the request.
func WithRequestEditorFn(fn RequestEditorFn) ClientOption {
	return func(c *Client) error {
		c.RequestEditors = append(c.RequestEditors, fn)
		return nil
	}
}

// The interface specification for the client above.
type ClientInterface interface {
	// AnswerAgentWithBody request with any body
	AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GlobalQueryWithBody request with any body
	GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RagQueryWithBody request with any body
	RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetStatus request
	GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListTables request
	ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropTable request
	DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetTable request
	GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateTableWithBody request with any body
	CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BackupTableWithBody request with any body
	BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BatchWithBody request with any body
	BatchWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Batch(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListIndexes request
	ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropIndex request
	DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetIndex request
	GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateIndexWithBody request with any body
	CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LookupKey request
	LookupKey(ctx context.Context, tableName string, key string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LinearMergeWithBody request with any body
	LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// QueryTableWithBody request with any body
	QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// TableRagQueryWithBody request with any body
	TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RestoreTableWithBody request with any body
	RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateSchemaWithBody request with any body
	UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListUsers request
	ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetCurrentUser request
	GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteUser request
	DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserByName request
	GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateUserWithBody request with any body
	CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateUserPasswordWithBody request with any body
	UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RemovePermissionFromUser request
	RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserPermissions request
	GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// AddPermissionToUserWithBody request with any body
	AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)
}

func (c *Client) AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetStatusRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListTablesRequest(c.Server, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BatchWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Batch(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListIndexesRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequestWithBody(c.Server, tableName, indexName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequest(c.Server, tableName, indexName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LookupKey(ctx context.Context, tableName string, key string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLookupKeyRequest(c.Server, tableName, key)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListUsersRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetCurrentUserRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteUserRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserByNameRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRemovePermissionFromUserRequest(c.Server, userName, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserPermissionsRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

// NewAnswerAgentRequest calls the generic AnswerAgent builder with application/json body
func NewAnswerAgentRequest(server string, body AnswerAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAnswerAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewAnswerAgentRequestWithBody generates requests for AnswerAgent with any type of body
func NewAnswerAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/answer")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGlobalQueryRequest calls the generic GlobalQuery builder with application/json body
func NewGlobalQueryRequest(server string, body GlobalQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewGlobalQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewGlobalQueryRequestWithBody generates requests for GlobalQuery with any type of body
func NewGlobalQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/query")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRagQueryRequest calls the generic RagQuery builder with application/json body
func NewRagQueryRequest(server string, body RagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRagQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewRagQueryRequestWithBody generates requests for RagQuery with any type of body
func NewRagQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/rag")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetStatusRequest generates requests for GetStatus
func NewGetStatusRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/status")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListTablesRequest generates requests for ListTables
func NewListTablesRequest(server string, params *ListTablesParams) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "prefix", runtime.ParamLocationQuery, params.Prefix); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "pattern", runtime.ParamLocationQuery, params.Pattern); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropTableRequest generates requests for DropTable
func NewDropTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetTableRequest generates requests for GetTable
func NewGetTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateTableRequest calls the generic CreateTable builder with application/json body
func NewCreateTableRequest(server string, tableName string, body CreateTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewCreateTableRequestWithBody generates requests for CreateTable with any type of body
func NewCreateTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBackupTableRequest calls the generic BackupTable builder with application/json body
func NewBackupTableRequest(server string, tableName string, body BackupTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBackupTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBackupTableRequestWithBody generates requests for BackupTable with any type of body
func NewBackupTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/backup", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBatchRequest calls the generic Batch builder with application/json body
func NewBatchRequest(server string, tableName string, body BatchJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBatchRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBatchRequestWithBody generates requests for Batch with any type of body
func NewBatchRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/batch", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListIndexesRequest generates requests for ListIndexes
func NewListIndexesRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropIndexRequest generates requests for DropIndex
func NewDropIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetIndexRequest generates requests for GetIndex
func NewGetIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateIndexRequest calls the generic CreateIndex builder with application/json body
func NewCreateIndexRequest(server string, tableName string, indexName string, body CreateIndexJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateIndexRequestWithBody(server, tableName, indexName, "application/json", bodyReader)
}

// NewCreateIndexRequestWithBody generates requests for CreateIndex with any type of body
func NewCreateIndexRequestWithBody(server string, tableName string, indexName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewLookupKeyRequest generates requests for LookupKey
func NewLookupKeyRequest(server string, tableName string, key string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "key", runtime.ParamLocationPath, key)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/lookup/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewLinearMergeRequest calls the generic LinearMerge builder with application/json body
func NewLinearMergeRequest(server string, tableName string, body LinearMergeJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewLinearMergeRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewLinearMergeRequestWithBody generates requests for LinearMerge with any type of body
func NewLinearMergeRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/merge", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewQueryTableRequest calls the generic QueryTable builder with application/json body
func NewQueryTableRequest(server string, tableName string, body QueryTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewQueryTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewQueryTableRequestWithBody generates requests for QueryTable with any type of body
func NewQueryTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/query", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewTableRagQueryRequest calls the generic TableRagQuery builder with application/json body
func NewTableRagQueryRequest(server string, tableName string, body TableRagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewTableRagQueryRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewTableRagQueryRequestWithBody generates requests for TableRagQuery with any type of body
func NewTableRagQueryRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/rag", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRestoreTableRequest calls the generic RestoreTable builder with application/json body
func NewRestoreTableRequest(server string, tableName string, body RestoreTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRestoreTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewRestoreTableRequestWithBody generates requests for RestoreTable with any type of body
func NewRestoreTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/restore", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateSchemaRequest calls the generic UpdateSchema builder with application/json body
func NewUpdateSchemaRequest(server string, tableName string, body UpdateSchemaJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateSchemaRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewUpdateSchemaRequestWithBody generates requests for UpdateSchema with any type of body
func NewUpdateSchemaRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/schema", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListUsersRequest generates requests for ListUsers
func NewListUsersRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetCurrentUserRequest generates requests for GetCurrentUser
func NewGetCurrentUserRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/me")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDeleteUserRequest generates requests for DeleteUser
func NewDeleteUserRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserByNameRequest generates requests for GetUserByName
func NewGetUserByNameRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateUserRequest calls the generic CreateUser builder with application/json body
func NewCreateUserRequest(server string, userName UserNamePathParameter, body CreateUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewCreateUserRequestWithBody generates requests for CreateUser with any type of body
func NewCreateUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateUserPasswordRequest calls the generic UpdateUserPassword builder with application/json body
func NewUpdateUserPasswordRequest(server string, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateUserPasswordRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewUpdateUserPasswordRequestWithBody generates requests for UpdateUserPassword with any type of body
func NewUpdateUserPasswordRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/password", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRemovePermissionFromUserRequest generates requests for RemovePermissionFromUser
func NewRemovePermissionFromUserRequest(server string, userName UserNamePathParameter, params *RemovePermissionFromUserParams) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resource", runtime.ParamLocationQuery, params.Resource); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resourceType", runtime.ParamLocationQuery, params.ResourceType); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserPermissionsRequest generates requests for GetUserPermissions
func NewGetUserPermissionsRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewAddPermissionToUserRequest calls the generic AddPermissionToUser builder with application/json body
func NewAddPermissionToUserRequest(server string, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAddPermissionToUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewAddPermissionToUserRequestWithBody generates requests for AddPermissionToUser with any type of body
func NewAddPermissionToUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

func (c *Client) applyEditors(ctx context.Context, req *http.Request, additionalEditors []RequestEditorFn) error {
	for _, r := range c.RequestEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	for _, r := range additionalEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	return nil
}

// ClientWithResponses builds on ClientInterface to offer response payloads
type ClientWithResponses struct {
	ClientInterface
}

// NewClientWithResponses creates a new ClientWithResponses, which wraps
// Client with return type handling
func NewClientWithResponses(server string, opts ...ClientOption) (*ClientWithResponses, error) {
	client, err := NewClient(server, opts...)
	if err != nil {
		return nil, err
	}
	return &ClientWithResponses{client}, nil
}

// WithBaseURL overrides the baseURL.
func WithBaseURL(baseURL string) ClientOption {
	return func(c *Client) error {
		newBaseURL, err := url.Parse(baseURL)
		if err != nil {
			return err
		}
		c.Server = newBaseURL.String()
		return nil
	}
}

// ClientWithResponsesInterface is the interface specification for the client with responses above.
type ClientWithResponsesInterface interface {
	// AnswerAgentWithBodyWithResponse request with any body
	AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	// GlobalQueryWithBodyWithResponse request with any body
	GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	// RagQueryWithBodyWithResponse request with any body
	RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	// GetStatusWithResponse request
	GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error)

	// ListTablesWithResponse request
	ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error)

	// DropTableWithResponse request
	DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error)

	// GetTableWithResponse request
	GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error)

	// CreateTableWithBodyWithResponse request with any body
	CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	// BackupTableWithBodyWithResponse request with any body
	BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	// BatchWithBodyWithResponse request with any body
	BatchWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchResponse, error)

	BatchWithResponse(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchResponse, error)

	// ListIndexesWithResponse request
	ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error)

	// DropIndexWithResponse request
	DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error)

	// GetIndexWithResponse request
	GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error)

	// CreateIndexWithBodyWithResponse request with any body
	CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	// LookupKeyWithResponse request
	LookupKeyWithResponse(ctx context.Context, tableName string, key string, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error)

	// LinearMergeWithBodyWithResponse request with any body
	LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	// QueryTableWithBodyWithResponse request with any body
	QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	// TableRagQueryWithBodyWithResponse request with any body
	TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	// RestoreTableWithBodyWithResponse request with any body
	RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	// UpdateSchemaWithBodyWithResponse request with any body
	UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	// ListUsersWithResponse request
	ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error)

	// GetCurrentUserWithResponse request
	GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error)

	// DeleteUserWithResponse request
	DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error)

	// GetUserByNameWithResponse request
	GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error)

	// CreateUserWithBodyWithResponse request with any body
	CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	// UpdateUserPasswordWithBodyWithResponse request with any body
	UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	// RemovePermissionFromUserWithResponse request
	RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error)

	// GetUserPermissionsWithResponse request
	GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error)

	// AddPermissionToUserWithBodyWithResponse request with any body
	AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)

	AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)
}

type AnswerAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *AnswerAgentResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AnswerAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AnswerAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GlobalQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GlobalQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GlobalQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetStatusResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ClusterStatus
	JSON401      *Error
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetStatusResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetStatusResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListTablesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]TableStatus
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListTablesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListTablesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *TableStatus
	JSON404      *NotFound
}

// Status returns HTTPResponse.Status
func (r GetTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
}

// Status returns HTTPResponse.Status
func (r CreateTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BackupTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *struct {
		Backup string `json:"backup,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON404 *NotFound
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BackupTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BackupTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BatchResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *struct {
		// Deleted Number of documents successfully deleted
		Deleted int `json:"deleted,omitempty,omitzero"`

		// Failed List of failed operations with error details
		Failed []struct {
			// Error Error message for this failure
			Error string `json:"error,omitempty,omitzero"`

			// Id The document ID that failed
			Id string `json:"id,omitempty,omitzero"`
		} `json:"failed,omitempty,omitzero"`

		// Inserted Number of documents successfully inserted
		Inserted int `json:"inserted,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON404 *NotFound
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BatchResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BatchResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListIndexesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListIndexesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListIndexesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r CreateIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LookupKeyResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *map[string]interface{}
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LookupKeyResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LookupKeyResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LinearMergeResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *LinearMergeResult
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LinearMergeResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LinearMergeResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type QueryTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r QueryTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r QueryTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type TableRagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON404      *NotFound
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r TableRagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r TableRagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RestoreTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON202      *struct {
		Restore string `json:"restore,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r RestoreTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RestoreTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateSchemaResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r UpdateSchemaResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateSchemaResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListUsersResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]struct {
		Username string `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON403 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r ListUsersResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListUsersResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetCurrentUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *struct {
		Permissions []Permission `json:"permissions,omitempty,omitzero"`
		Username    string       `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r GetCurrentUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetCurrentUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserByNameResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *User
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserByNameResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserByNameResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *User
	JSON400      *Error
	JSON409      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateUserPasswordResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateUserPasswordResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateUserPasswordResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RemovePermissionFromUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RemovePermissionFromUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RemovePermissionFromUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserPermissionsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]Permission
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserPermissionsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserPermissionsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type AddPermissionToUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AddPermissionToUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AddPermissionToUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

// AnswerAgentWithBodyWithResponse request with arbitrary body returning *AnswerAgentResponse
func (c *ClientWithResponses) AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

func (c *ClientWithResponses) AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

// GlobalQueryWithBodyWithResponse request with arbitrary body returning *GlobalQueryResponse
func (c *ClientWithResponses) GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

func (c *ClientWithResponses) GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

// RagQueryWithBodyWithResponse request with arbitrary body returning *RagQueryResponse
func (c *ClientWithResponses) RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

func (c *ClientWithResponses) RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

// GetStatusWithResponse request returning *GetStatusResponse
func (c *ClientWithResponses) GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error) {
	rsp, err := c.GetStatus(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetStatusResponse(rsp)
}

// ListTablesWithResponse request returning *ListTablesResponse
func (c *ClientWithResponses) ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error) {
	rsp, err := c.ListTables(ctx, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListTablesResponse(rsp)
}

// DropTableWithResponse request returning *DropTableResponse
func (c *ClientWithResponses) DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error) {
	rsp, err := c.DropTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropTableResponse(rsp)
}

// GetTableWithResponse request returning *GetTableResponse
func (c *ClientWithResponses) GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error) {
	rsp, err := c.GetTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetTableResponse(rsp)
}

// CreateTableWithBodyWithResponse request with arbitrary body returning *CreateTableResponse
func (c *ClientWithResponses) CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

func (c *ClientWithResponses) CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

// BackupTableWithBodyWithResponse request with arbitrary body returning *BackupTableResponse
func (c *ClientWithResponses) BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

func (c *ClientWithResponses) BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

// BatchWithBodyWithResponse request with arbitrary body returning *BatchResponse
func (c *ClientWithResponses) BatchWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchResponse, error) {
	rsp, err := c.BatchWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchResponse(rsp)
}

func (c *ClientWithResponses) BatchWithResponse(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchResponse, error) {
	rsp, err := c.Batch(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchResponse(rsp)
}

// ListIndexesWithResponse request returning *ListIndexesResponse
func (c *ClientWithResponses) ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error) {
	rsp, err := c.ListIndexes(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListIndexesResponse(rsp)
}

// DropIndexWithResponse request returning *DropIndexResponse
func (c *ClientWithResponses) DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error) {
	rsp, err := c.DropIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropIndexResponse(rsp)
}

// GetIndexWithResponse request returning *GetIndexResponse
func (c *ClientWithResponses) GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error) {
	rsp, err := c.GetIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetIndexResponse(rsp)
}

// CreateIndexWithBodyWithResponse request with arbitrary body returning *CreateIndexResponse
func (c *ClientWithResponses) CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndexWithBody(ctx, tableName, indexName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

func (c *ClientWithResponses) CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndex(ctx, tableName, indexName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

// LookupKeyWithResponse request returning *LookupKeyResponse
func (c *ClientWithResponses) LookupKeyWithResponse(ctx context.Context, tableName string, key string, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error) {
	rsp, err := c.LookupKey(ctx, tableName, key, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLookupKeyResponse(rsp)
}

// LinearMergeWithBodyWithResponse request with arbitrary body returning *LinearMergeResponse
func (c *ClientWithResponses) LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMergeWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

func (c *ClientWithResponses) LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMerge(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

// QueryTableWithBodyWithResponse request with arbitrary body returning *QueryTableResponse
func (c *ClientWithResponses) QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

func (c *ClientWithResponses) QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

// TableRagQueryWithBodyWithResponse request with arbitrary body returning *TableRagQueryResponse
func (c *ClientWithResponses) TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQueryWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

func (c *ClientWithResponses) TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQuery(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

// RestoreTableWithBodyWithResponse request with arbitrary body returning *RestoreTableResponse
func (c *ClientWithResponses) RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

func (c *ClientWithResponses) RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

// UpdateSchemaWithBodyWithResponse request with arbitrary body returning *UpdateSchemaResponse
func (c *ClientWithResponses) UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchemaWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

func (c *ClientWithResponses) UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchema(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

// ListUsersWithResponse request returning *ListUsersResponse
func (c *ClientWithResponses) ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error) {
	rsp, err := c.ListUsers(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListUsersResponse(rsp)
}

// GetCurrentUserWithResponse request returning *GetCurrentUserResponse
func (c *ClientWithResponses) GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error) {
	rsp, err := c.GetCurrentUser(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetCurrentUserResponse(rsp)
}

// DeleteUserWithResponse request returning *DeleteUserResponse
func (c *ClientWithResponses) DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error) {
	rsp, err := c.DeleteUser(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteUserResponse(rsp)
}

// GetUserByNameWithResponse request returning *GetUserByNameResponse
func (c *ClientWithResponses) GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error) {
	rsp, err := c.GetUserByName(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserByNameResponse(rsp)
}

// CreateUserWithBodyWithResponse request with arbitrary body returning *CreateUserResponse
func (c *ClientWithResponses) CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

func (c *ClientWithResponses) CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

// UpdateUserPasswordWithBodyWithResponse request with arbitrary body returning *UpdateUserPasswordResponse
func (c *ClientWithResponses) UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPasswordWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

func (c *ClientWithResponses) UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPassword(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

// RemovePermissionFromUserWithResponse request returning *RemovePermissionFromUserResponse
func (c *ClientWithResponses) RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error) {
	rsp, err := c.RemovePermissionFromUser(ctx, userName, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRemovePermissionFromUserResponse(rsp)
}

// GetUserPermissionsWithResponse request returning *GetUserPermissionsResponse
func (c *ClientWithResponses) GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error) {
	rsp, err := c.GetUserPermissions(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserPermissionsResponse(rsp)
}

// AddPermissionToUserWithBodyWithResponse request with arbitrary body returning *AddPermissionToUserResponse
func (c *ClientWithResponses) AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

func (c *ClientWithResponses) AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

// ParseAnswerAgentResponse parses an HTTP response from a AnswerAgentWithResponse call
func ParseAnswerAgentResponse(rsp *http.Response) (*AnswerAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AnswerAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest AnswerAgentResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseGlobalQueryResponse parses an HTTP response from a GlobalQueryWithResponse call
func ParseGlobalQueryResponse(rsp *http.Response) (*GlobalQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GlobalQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRagQueryResponse parses an HTTP response from a RagQueryWithResponse call
func ParseRagQueryResponse(rsp *http.Response) (*RagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseGetStatusResponse parses an HTTP response from a GetStatusWithResponse call
func ParseGetStatusResponse(rsp *http.Response) (*GetStatusResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetStatusResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ClusterStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListTablesResponse parses an HTTP response from a ListTablesWithResponse call
func ParseListTablesResponse(rsp *http.Response) (*ListTablesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListTablesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropTableResponse parses an HTTP response from a DropTableWithResponse call
func ParseDropTableResponse(rsp *http.Response) (*DropTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetTableResponse parses an HTTP response from a GetTableWithResponse call
func ParseGetTableResponse(rsp *http.Response) (*GetTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	}

	return response, nil
}

// ParseCreateTableResponse parses an HTTP response from a CreateTableWithResponse call
func ParseCreateTableResponse(rsp *http.Response) (*CreateTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	}

	return response, nil
}

// ParseBackupTableResponse parses an HTTP response from a BackupTableWithResponse call
func ParseBackupTableResponse(rsp *http.Response) (*BackupTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BackupTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest struct {
			Backup string `json:"backup,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseBatchResponse parses an HTTP response from a BatchWithResponse call
func ParseBatchResponse(rsp *http.Response) (*BatchResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BatchResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest struct {
			// Deleted Number of documents successfully deleted
			Deleted int `json:"deleted,omitempty,omitzero"`

			// Failed List of failed operations with error details
			Failed []struct {
				// Error Error message for this failure
				Error string `json:"error,omitempty,omitzero"`

				// Id The document ID that failed
				Id string `json:"id,omitempty,omitzero"`
			} `json:"failed,omitempty,omitzero"`

			// Inserted Number of documents successfully inserted
			Inserted int `json:"inserted,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListIndexesResponse parses an HTTP response from a ListIndexesWithResponse call
func ParseListIndexesResponse(rsp *http.Response) (*ListIndexesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListIndexesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropIndexResponse parses an HTTP response from a DropIndexWithResponse call
func ParseDropIndexResponse(rsp *http.Response) (*DropIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetIndexResponse parses an HTTP response from a GetIndexWithResponse call
func ParseGetIndexResponse(rsp *http.Response) (*GetIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateIndexResponse parses an HTTP response from a CreateIndexWithResponse call
func ParseCreateIndexResponse(rsp *http.Response) (*CreateIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLookupKeyResponse parses an HTTP response from a LookupKeyWithResponse call
func ParseLookupKeyResponse(rsp *http.Response) (*LookupKeyResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LookupKeyResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest map[string]interface{}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLinearMergeResponse parses an HTTP response from a LinearMergeWithResponse call
func ParseLinearMergeResponse(rsp *http.Response) (*LinearMergeResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LinearMergeResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest LinearMergeResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseQueryTableResponse parses an HTTP response from a QueryTableWithResponse call
func ParseQueryTableResponse(rsp *http.Response) (*QueryTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &QueryTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseTableRagQueryResponse parses an HTTP response from a TableRagQueryWithResponse call
func ParseTableRagQueryResponse(rsp *http.Response) (*TableRagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &TableRagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseRestoreTableResponse parses an HTTP response from a RestoreTableWithResponse call
func ParseRestoreTableResponse(rsp *http.Response) (*RestoreTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RestoreTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest struct {
			Restore string `json:"restore,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateSchemaResponse parses an HTTP response from a UpdateSchemaWithResponse call
func ParseUpdateSchemaResponse(rsp *http.Response) (*UpdateSchemaResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateSchemaResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListUsersResponse parses an HTTP response from a ListUsersWithResponse call
func ParseListUsersResponse(rsp *http.Response) (*ListUsersResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListUsersResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []struct {
			Username string `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 403:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON403 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetCurrentUserResponse parses an HTTP response from a GetCurrentUserWithResponse call
func ParseGetCurrentUserResponse(rsp *http.Response) (*GetCurrentUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetCurrentUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest struct {
			Permissions []Permission `json:"permissions,omitempty,omitzero"`
			Username    string       `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteUserResponse parses an HTTP response from a DeleteUserWithResponse call
func ParseDeleteUserResponse(rsp *http.Response) (*DeleteUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserByNameResponse parses an HTTP response from a GetUserByNameWithResponse call
func ParseGetUserByNameResponse(rsp *http.Response) (*GetUserByNameResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserByNameResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateUserResponse parses an HTTP response from a CreateUserWithResponse call
func ParseCreateUserResponse(rsp *http.Response) (*CreateUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 409:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON409 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateUserPasswordResponse parses an HTTP response from a UpdateUserPasswordWithResponse call
func ParseUpdateUserPasswordResponse(rsp *http.Response) (*UpdateUserPasswordResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateUserPasswordResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRemovePermissionFromUserResponse parses an HTTP response from a RemovePermissionFromUserWithResponse call
func ParseRemovePermissionFromUserResponse(rsp *http.Response) (*RemovePermissionFromUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RemovePermissionFromUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserPermissionsResponse parses an HTTP response from a GetUserPermissionsWithResponse call
func ParseGetUserPermissionsResponse(rsp *http.Response) (*GetUserPermissionsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserPermissionsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []Permission
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseAddPermissionToUserResponse parses an HTTP response from a AddPermissionToUserWithResponse call
func ParseAddPermissionToUserResponse(rsp *http.Response) (*AddPermissionToUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AddPermissionToUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// Base64 encoded, gzipped, json marshaled Swagger object
var swaggerSpec = []string{

	"H4sIAAAAAAAC/+y9+Xcjt9Eo+q/g0b5npPlIahmPk/CcnBfNaiWz6JPG8f2eOZcDdoMkoibQAdCS6Dn6",
	"399BFYBGd4MitTl2bn6xNWwshUKhUFWo5Wsvk8tSCiaM7o2+9kqq6JIZpuBfP2qmPtAlO6FmceK/2A85",
	"05nipeFS9Ea9TwtGKs2UoEs27PV73P5YUrPo9Xv2t96oV7mRev2eYv+suGJ5b2RUxfo9nS3YktpR2RVd",
	"loVt/g+5ELm0rc2qtD9oo7iY966vr+0AupRCMwDxBc1P2T8rpo39VyaFYQL+pGVZ8IxaEPf+oS2cX6Op",
	"vlVs1hv1vtmrl7+HX/Xea6Wkwqma63xBc6LcZNf93rEwds3FGVMXTGGvR4fBT0o0zEoYNuz3PkjzRlYi",
	"f3wQTpmWlcoYEdKQGcxpG7l+dtgjQYuV26BSyZIpw92/MpjX7epUyoJRYcE3WrDUl+tAAnL6D5aZXr93",
	"NZjLgf1xoM95OZAAFy0GpeQC6HNGC82u+wGMU6arwqwFhhu2hH/PpFpS0xv1ZoWkpiY+US2nTMUz+zbf",
	"f9erAaRK0VW8lgce+H6o0JdMHc2ZMNFxaaLjnxVT7s/mhh/Z+YmcEdti5Y+AJkYSdsWyyrAhsTwAPxt2",
	"ZcglLwoyZcQoKrRdPsvJTCqi2ZIKwzOiGVXZYiyoyEkpy6qghuWECyOJWbDQboLtyIyzIrcgMJotcCLL",
	"aQLH+Plrj4ucXVnwf+6x5ZTlORfzCc+vep/7vYIvuemNDvb7PUOnwGJKJfMqM7p33d+q7/O6q2IXnF3q",
	"3vXnfr3HNx2l/7bwntacY8nFMfY76FIPLK67CZYXP9FEUFMpWpCCinlF5wHp0mI7K6jWfMZZTixe+bJU",
	"8oLlMaJ6Py2oIVQxQPOUaUPmdMnFnBS0NLLUpBI5U+Tbw/39/f+3y4D7PV0tl1TxX/AmuGnZb5lgihqp",
	"Xkox49h5pQ1bTkoll6XpLvKjI2CC7Qi2s6ubVzyvF4gMDRZJgbLJHOeyw8Sr/R9ZwWIpWbCinFUF0QtZ",
	"lna9diRtqDDD1CrthTUBPnplNq3Tbs1L1/S637vkZjGZyaKQl1WJa5xRYEBwGrscPSuqnBFdzedMGzgo",
	"tu+gKglQDJdCE6qJZvZ2NoywCzs9oTPDFGwj4qBeRsRXARjFqJbCrmxraOyw7969f6JJ6Gx3I2M6CcuU",
	"zaSjqU3AaKMYUFwDGJQFmrC8FvbAkbOz1yR0sjxAAT/XZKdJDn3iOFjft+g7YHYJF9owChzkr2cfPxAv",
	"QyTAvI5FlJ/dcWyQfT+wys9tltxmtf7iaTFUpFlq2zhYicVNir4dYbNA6dCQi4ILZvviVazYjCkmMqZ7",
	"/RZbd/vRAeJte+CdJVXnubwUBO+rTTPtps5NcwWTwP/xaG44SC8bnT81+jpcXvd7/mhNwunoLu7sxsO0",
	"w2ekcUrJJdWEAbnldlmBq3fWl+TWE0dvXThOHanOlFzi3eVuzJx4wrrNDeJR0IaidcBjCNYd4oCD+lML",
	"CW3RO0nrZlasXi4qcc48l+9AgL9XyJ1BCrBsopAZLQgOQDI7goPugudMDcdiLD4tuA6/EFUJXTfMuWKZ",
	"KVawBi5QaDBS2StRyJz5dfbHwraQlSF4qoH1C8KunBz9iaklNwzkaZ6xITk2VpnRRHN7h5AZv2L5QPNf",
	"2FgYec6EZQGDKdUsr6GBkyIkyWi2ACZ1wdSC0RyW8fTpj9qyRq7J5YKJ0dOnYzEgp5UApGsu5gUbAMw5",
	"Kwu5WgJH3dGXVC3JUuZs17a3N1kuxRNDBGM5CWLKHgARZqaZkloDCrTvdkmFIUsu+BL0BlOVxJJYwa64",
	"WdUQekx4XpkAdlkVhiOsWVFpqyfaZoqF+RXLq4xpkkltAgAA8ccPH/73gGYZKxzbCdjbWVRzaSyPp4bN",
	"V7sNuEum7D1tOSV02AsrhzntKuMb/2tvSa8m0FL3Rs/3+z27FwUtJ7B57jdPVPYMAQVaBo9XmlXiehYp",
	"9gRQNWcm6rl/3eaus6ooJl5IoHnOUYA5iRqlrrbumbADDUB2BmHUXXW4EMIFeVGwCzYci58WTJBSMW0x",
	"smOvX8JnhC1Ls9rt+/Ze/LYnguVInqNsZkZEV7MZv0LxEITePAz+RBOHOBS3/WR0aucKY1eakVHWGMlK",
	"WFIUK/sN5fwLlhmpairVQ3eckXcQblkSqLC5W72p7CAlMuiCnzMylVIbLuZ9J/0vKQhufcJMNmzteoo5",
	"xYQQSRp2/5ub8Z5e8WW1JKiORWi3cqe7JS0dklxmlT2dQ3KinODDriyX4ResJmc5IxdWJi8s9YQ+2oqZ",
	"cAirZSz3W0VtzkCFb1PqjUB/CMBicwusG4BMmblkTJDMijhZZQJ4ekh+YEWpyZJyYSiHJkB0jm8gM5la",
	"pZ5aCacB9H4K6OjYRPD6E9S6lX1bgpcKqoRlwY0BPsCG82GfPBmPxXgsnsBX22GuaLnQu0k5vXVEGyjr",
	"4OwTNI722aHO7i2sfEjcXYYniPIlAOHIgSqLF+Tk9kLYtKPrb8xP8PPXHhO268891HInVE9WsppAp37v",
	"nK0upbLaG/CXfm9hlkWv3xPVkimeWexSwwwHq5oXX62+Ks57/d6cSbAC4J96QWHMcCBtl0JOIwm2xumR",
	"MAslS561Fbgtr/bQP2hlF4wcHddX+c7Lglolw15uhd4djsWP9sa1fWdcMXu57s2ZOOcGLipqJpLyPRqG",
	"LYtqzgWytY8lE0fHA2zHrb5wdHIM9+4rpAQ4GRlMOHg2+MNASyGYGRzuHz7fPzz4k+WeQiIoli3pkmWg",
	"QsMYRyfH5JytSEaF5aduBTm54BTAfUJLPjlnqyfeQuEw8OHTD6cfT45fTo5Ojid/e/0/hIkLrqSwnIBc",
	"UMWtlAUznFVlKZW9DxEbI3v73QDuTkEN06ZPllIbktHSjrTb6PR8sKD8vLJ9vjvYPzwkOzOqDXBqNpvx",
	"jDNh2j3qab7b//5wn+xMaUFFxnJ7OEAIF1lrGllWGjscHv6J7Cz4fGFFuRRENTz7z/b/gPAwbYHo3t3+",
	"KH+3/6fv+z1ASm/UW4+RXvs6RyKBY7MsLflVivVG+8M/dC5vt3lpi3ZNxY4IhuR4BjZPTwV9MqNFocmU",
	"ZueWyLbc9RQbixf+deP1VHP8cD05EdjrtdEkEa92yIz59I147SLFSinurBy/AlAamMIvRoKQ4Nn5+ime",
	"xF/bVPtkt2HhuxnS7r0Q732CbRklC00UFblcCqsPcRHZkMjO/nB/cDDc3x2SH/h8wRS5oEXF7MV5zois",
	"TFkZspSKuSEsqB0r7xI3Du6GxCXqrL8WWFlOzhNUKMvBOdEWAaAb+ReYIflohS34wFC1tNtgZEn+FkQo",
	"y4xB4dTVVLN/VpYEgW7SpGFBKLsgfKiyglU6AUSMoqMClCng80aSCPf3w0ulivTZ/PH0XZf47DFlIodb",
	"j+x4W3gftTlH8cjtTc3ldxsQVoonFd/YIISHKGX5eUGz86pca1+fwucJzxPGXcH/WTHCcyaMBUu5u5Qj",
	"c6nKIfnRitZG1vYXNODCV2itGEj7RJaOiK3M/XIhpWaEkiWjVoObVQURdGk7U6tpgLFPEytI7F1YTUsK",
	"wkUwurTEbLcEOHiD/YPBwfPBxWHq9Fnl3ht8WiKg09F9iyA0+HW6+1CjrmkJ3H5hIseb8R2YDWa8YGgi",
	"HpEv9h+jvb29kprFnpF7ONIX2/poSX+Rgpw9G5Ev+tlob29aZefMDCwKuu2tihJQGnBDi4KA5d9iifad",
	"2gS2xZwsmaH257CMQFjYp41AAGK5QjD2UPcc4Ix6r9JM6QH026tRvJEga7qKEJ+mT5MtIvJsv26abGGV",
	"f6ZMn+SsYIbhIoMRL6Ityy+pM174FyHLCIq4jdULnR2G5YQaueQZLWqjDfKnBVUobL1ggs24wY0+dYYE",
	"wcylVOfBpIISocLDwEXOL3he0SK8Stm+7+05CKJOrVDvVKWldARsatfLchBUjgA0DxZAFClBnjIQN9i7",
	"KvHvAWFXHNRUKyLgNwvqpeLGMNEngl3WXzLFqAHRsin3ILbh/ckSwegPf7SXGvwpi3xCs0xWwthNdTDY",
	"TvD54PAZSDJz1hs927cCPuWFe0H/i5thmMll/RT/V7kQ5BU+rtM5zJlV2sglWLZLxZa8WvY+uzeQ0XfP",
	"vw8THD6PJqCCrZmACkbOlhze/ztTfIYX5SZnDMtf+/LotWhy/ArkHuwxJK+8dg3oVWwpwaJgr0R7bt1Z",
	"Ber6IA1D0vogxQB2zQ4Y9kbzgglTrAifC6lYblu+stMkSNk9d3iC8PZHy1iBrGzfv/mBS2alZxy7AaG3",
	"V9bGmJYxazM1bG2njugmbaVqo95j1ltsQNmiasqNomqF6o4Vhwza/VayUo5Nos06EjNqDtQWbMvk3jZn",
	"1kPy2vIJq4ZxVBKrNddlbW1x/ERbYZ1mhmdu63/UDKwi9ebb6xDssBZqpr3UOg7Ha9yz/6LK8Kxg9jiM",
	"e7tuf0nBxNyiZTazgDY2NFKbyICcM1ZaAJfOEk+nVoBbSGUapKJREyzYFc8kmD2QYfaJliTDu7xUbMav",
	"QF2mhmi8Lq0YOreop6JjEP3d8okEAemVyCYFu0A15qYXk7OVyN5BQzuOv8Fu4jHJa84SFheDsqBZTV3E",
	"3yOVvQDJeynm8tWLgTarwstfUiHX+ZQalBaFvLRHxpL7UuZ8tqrthKR+r6D5AL8O7HVidQ1Pxx+blyx4",
	"+TSvWOl4ErgJwaXo5akIkNio2RjI3oKgNGTM9g1CmbM9xWPsfMtF1iffLqtit08oYjP+XFZ60SffllUB",
	"DazUJBWzyHkpl0spQFnMqHZLOxaZYgAQsDmmNNkBf4s+mIV1n1xYTg5n8EfYB2L4kmlDl6WdLquUYsK8",
	"ogaNEO+pgDNpAdNkh+b5HnJhYmmuT4CHxqMJ93CIHM7vhr/U7YZbxFrWo2qSaDHurz2wKwS2YY9fv1ej",
	"BZrIsjfqWezZ80TNwv5riK4l/R7om73RwXXfN4wWFncoqDZ/5+yS5b3rz7Y1zhwO5Zpp7a7Ew8ABDNP2",
	"Lnhph9vWwyWQ+RZuS1YSZbmS2flrsEbe9uXQda4fF+pXw87jN9zGE81/YWlFEr6DMRcV5jCkFyc3GlLa",
	"I4J25XRTD2lsFmkaNSgoKEPDDRUDmB3egAYXBym1SrF5UqkCc9VPZwS/dxDlnzaT3jxG8XIi2OWk4CIl",
	"B/y0YGbBlIUe2oJAC21rywMXZWXA8Wu42aHiBv0Z4b2r1fmns7DitN25Sx73Nbs9NnV428Ywbak92D88",
	"HFwcjvZ/JWJ5MKPar2otexh7131g3v4EWNHm2KoCfz+sqb9Fs2w5kaJY3XhU7ZW6ZEupVgN4mHWSafd0",
	"buFDalTF0lw8gvbMUJPw9825Pp9UGqTCjinIcl13FkD9seQyXRnwYapNclyY77/r7uG2gPd7zHtmt7zL",
	"7M9kybSFjvAZ0XYJVugocrARTq1CaRRn6ELZPA3bT6/YtOJFnnTOCTtWo0ATd8+Dthi63nnjLKkbWkzc",
	"a3+K5D1/q0VQp9BCn4fcjCQVSVm8sbLWf3vH19YVLmWR9hkHB4FNkskLaHTd74E8l9CV29Y0O93nNXAy",
	"KtZDeStYCrPZfxanshdKtXnsl1L8oxKZRXuj30TIjX1fcd3pqxf2INy+55ot9hZH9+500LYFHBHgqVzM",
	"kWT8tVs5s3fOMqs5MwL6mPsbX7wKdgFats6kYtoSMq09xAPp5rKaFgyez4sCHbnRMadzv7xYGXZq1em0",
	"D7/lUGue8JxT92Hs4X3YtcV0/OVoUXycoWwumPvrRmkbPbWa41jR/6ZOKV89VBhaURHhMXUDweFIJ755",
	"+yCFcUCLaO92JdBKnnVkOZrwBmwaNDZ4dBnETg+EW/Aoszc2v0Iu3nXpqnfkJFp6V2jqgBXLbM6RYymz",
	"c3h59iA497KUm8VLN95ZgHKtDS5M7Vc0tPoquM2NbnCsQ/OEZsLAg5GzaK9IzgyDM2tHAcyMyFnb3bEe",
	"ZrpC0RcVctR03XoBBHvMAL3JVW726e2sG1hJyhm66U7sXaczuZxy8E+kReECIphYWKYA11lH7Aeiyy1O",
	"EmJsc9a6KYivdsutBHsvAdbHZUzWhHq8LKjC04FrQdNrnuNxAXctOCjtyAeys6iWVAwUozn4YCTVAlkZ",
	"hi5GGw74qW0Jnkrg5uUCctbA/LE0fMl/CTDXToB7rZgfspNJkbHSEHZlwDgrnSuPXgkpVku9u/HJK1pE",
	"B50dWPvxfqdu9pfoyvoDo4VZJJZ2wZQlrAV8BzGx0l5wdW6w0ZGoxLmQl/aQYAcLQCXqv3M2VzTHqByQ",
	"TNOnBoY9g7k2uZa2nFoqs5g4N+7uYo5Fbkmbgd8uyJ62PbPoQhriwQc8qIb1GhMyqFxy8wtTso41WwQ8",
	"3uzrHyPd3p8oid8QFORldeS/4AXODOWFJnQqKwOwNjZpIx05UJNE0Zan7inyZW483ZAqthL/Ova0eAn1",
	"uMlVwIPjJ7ufa/0SGthei/wmayFRK38U8PUHHrOMJmWlSqkZ+vbNqgKoyWsYEUdndEkyaUUyqZI+Bz9q",
	"puyWw5s/MorarTgVVIis+B08zTg30M75CgF/65/DbtoaUHrrqLbksxbqc+hsId2/GtLOkBwjFO7AkZzP",
	"wLfDOB4KrnS84BYiMI2/afqIM1z+i/eHz0M85YD8HV2v4xY1gviS28vFrMKLwFLmtGi05ks6Z3qPVjmX",
	"e1bQkWMxFv8jK/CCpHleu2b4bkaGh6j2IkpqDFPgjNKU4qJAS1AzwVqwZEIDFp/98TvvrYrymHcEpEUx",
	"sLdrsWw6/lkSWtL4uJwLMbnYx8sL3GvDPD7S1vvuQ7OU4iKq5QS8AfRNejO2ADdTOG6BcaILCHlFDbV8",
	"taTKAKmx3Ptbu64YTiIFPEjCUx6+Hr2teM7A2Ar7f7a091BODdXMaLIzrvb3n2UH+/t/sydL747IweCZ",
	"GxM2mOW8WkYdbNPBwXvf+tngYD9q/g4d1pvDs7r5wf5/hdZjAU4WDn5HwFNm9xpsZkXBCq6XZFqZWl8L",
	"YTHE+SWFdbOrkmVWdgVnGhA/LXe4kYSetQwTSTvfdrHuwCDPsGmSEJCPWla0lo1ywQ2nxaSUBc+ST+qB",
	"lxZcG2QR0AU8BLjW4cHRuIQKw23Dw07CAEi1SQ036J8l1Ro8yxs5F/SzTD0zJ3/R+vIjeJ0H5Ib2a+Jk",
	"8T03FbAM3M+vSLBLXBU5ntWe1M7UVFKz6KPHG3pSO49rK15YupCKLCtt0OEg9GiaZ7fJH9HSUf3KUnfn",
	"KxrZAVpRP0ouu6akW8Tje5R1TezyHuO2VgeT3LiyWgGrTRA3mnsCSrp2A3RKqYGPwyCaAotzXmmB9TkG",
	"7AxW/iCClw+SmJRUabxLOlhnmDejNhZRwwYusqLTeJ0h0UoVVlTmF2ziBlxzEiMbZt1FG6rMdp1C020A",
	"TrGzjtnuvjh2491buAXNubkyb7e7+U2lhiBJ8DI7zh9kpTxvrnGD41ULStt7DXwgF5+F26plCGIzeHHF",
	"KFdVZRgtNyO0dt9w2vAtZPujlBTfGC/9ZByA3D7e8Yhc0ILnGHyPqyS5XZR3p/DTPtH1An3MINfBDMzF",
	"jKnaoVNVViewkgJeGhZWJya0cJw6Ba/zlLp5BKPkfXLJ+Hxh0Ogi0F4WIuvCU0nXtoQunhNqks89eNux",
	"fM4g3Nq1bhiq1x7l7Z98vFvy7TYpyCcAXhjjDmlnHBiYMiDlaqzZ998NmMikFQFcZoFAeedsFSMkaXC/",
	"xfMXWHw3AoHNHg0IZ29rPUFaPNtPtddhxg3T6HLolLWJkc4FsTILqVg+ma7Gvd17AIPea9uSaEG1d3h7",
	"cDrFI7YGMfhxbwsL7Jo74havkjGTdlQbKMcNG6D9fPcDYdf1CjIXBIbsA7FkZToRV6EpZD7K56hpg1IE",
	"+qCszIh8rMxcWmaIDYJTjpA5+O5xMSLHIpPLuo1LsuRbTKVZjMgLaRZ2RBwMfZLjXg27P0LLBUSeNixo",
	"t6YBi5NPq5Jt7+1DfZRFhlSavPnAx3KiWTGbFFKWemO2mch7Av0zI3xSzClhLyBjh7zPc/ySXk1iul/3",
	"Iur9jwAYlrsDiR0fjvZB4ErB042SxyeNR4cnrU3WrBJ0yhBbaNnlkz55UjPLJ+lnD3fAJ/HV2M7Vgk2i",
	"oB50AQ2xWDG13VECXKuT2QXqU5+WaLRWu2o7PRlaRC5qSLOKmUqJ2GslsohAk63ldJCRtvLp7Dpz3vZZ",
	"+62U84K1xtn0rP13pgy7umWnj2AsvG0niDS/Zae0p+t93t39UA//8C7WuNTGAdrOCgtOqqH1YH//u5Y1",
	"tmSCcgCtA2/ycb07c+J1fc6WXPBev3cBm97re6tv30/Y700R4b0+vsWnHtde+7liM373xKFPwJZuENFj",
	"QG3Ebi/UmebrFpsygsQG8G1oooYiGCmaELxBNUn6t9fGU4qC6Iy76xxb+iVyMUDXRPIwron3TElo2LIs",
	"qEncOT9QkRdsSpUmvhEcFP/ijsS6LI0ekjPGyMKYUo/29hah3z/0MJPLPUheuAd9lxg3VkfYNuyWP7Ci",
	"kH3y9es3fEZ22D/JB3vZjSEWZ9zbvb62f1CzoOLrVwYWv69fbRP7/z0+u77+f4jPePj169GcXV+TFbPw",
	"yyIf3nlvO6YWT76f114D/nD9xy303l6Z6EXxeD6ZHhRIGbZZwoBmv6qDaMis3KShsH/18TkSmA/Zb99G",
	"+3/bAaOe9A3NmPkYDGct8qWGTfCZbmtBKjadd4ye603KLuDqtrN9wG5rJ/QRMdukLAJUrMuhfC9UrE9o",
	"uB4h8M6FvtTd+/IBsLUeJsNc/OB2EVFMLWPMpQa0R2v7XeAFy0Pc3w3nofsskcakjMcK3ksQ1w6WiIIZ",
	"lpCfksBVv/zCBdMu4ejKCfuBLXBhnh2mtJF6YloZmZjtczoLjZvO3xPo7kte4pshFcTNQKRCw5kc94Ye",
	"0NUDuXCvo9BZjIybxqqxBhHxbMavJoVzW9kGeUCRmz3aoVWKxyUCre6msnWlqm10ttv2QqXt1r1Aa7tt",
	"rzWhaFv4WKczp91H4QtjPYKr9fpAuTVZuQ73v/tjnZVrXprBdzKp+iXSb8Ukd7M2uCZv3H01wjg52Frt",
	"8C2TL2QlrAj7Ql49CK+YSmPkcqLSxu6fCyn6pKDmc2xW2vgAepuIg/XMyshyUrDZvwKsNpvykLTwleZc",
	"YY9OZLGaS/HIPL3EWSYgrW4vBLxl8gSSMG4yC7bGX7PmV5CwPmMP9WYPgzVF6IP98+XtnB7W53r6tSko",
	"QBItbg0mcVc6GCyo2RLEQm7tppCa/wzycSbent8yCW/kkLDTZUAZEv8MTjErNfJzxVwa4GBIaJuMpcq5",
	"oC6zTkf6dE+SG4QHtHbHY32+YUlvmVwykyJOxYqOsAman2YZPKNnEjLS2j8xD1OSO2uPuA3HDhHcedpz",
	"aVADMDet5ZFZyjxC1TaLCahtLyoMlFxMyqa+ZUQ99t0qz8KNmTTdOD6NZoq9tIym/k1s//C7lPwfWnv5",
	"P4CYDvZez6Ii8F4WssrrvHT+hanSg4wJo2hx8CSdgjiRVTNpHr85G0CN5WQSze6Ia6AplbR7n0wz2Fmt",
	"a0yOX6WLoGyRfzHaXJ988QFTKqb1i9vR77okxG9BdtwdkjhRMAqUg8Ph88GsoHqxPj3wg5+BR6bSx051",
	"4Wm/jcGNlB/tT5L02wM+qX87GD4flEr+CkfhIVJfHG5MfXH4b5f64jfBRBQtF5inYn97DgLp1yYX++4R",
	"IulkwvI5hiEmDtU75+QfnAZc8JJZMK6ayrje1s+/5SuTcp+lVxN44Z+UTE28N9s2Rx5dBxoZwXb2yZ9J",
	"JaACWqMmzEOY9eNdCc9E7WSx1HBteKYTO7JhM9aFdW18qrju1uqohGliKHYE6SzsN/GwFLw8tvEXca85",
	"gN/Hfs2Bbf8gc3bGCnjZWu/tvJCXEFkGDQk4ve85N018hQpE4St/dWjinK0SWHh9VRY84yYE4oB3F7Td",
	"2rFn+w1xBQQ3n0BcVL3i4MoXcj7nvrLZfZ77cIgJsJmuD1TILi19vLYvt+auZeqqC4EH4rj3bR1F5xqO",
	"e2QALeuSNs2RXEcI0HM/DeFIT6xYELq7GjItKDBzqvf/g26xv/ftn7bv6ssJhPzf6Wj4VywrqJNpagJd",
	"RRUzXfW+gKK9xmoTlIy+aCnnCu7rY2rMD24qJRBNsZf6g5O1S5A9qSfpepswY2GriiLKLVQf2g4t397z",
	"wwOxht35aobAr32weMiMb8n4fpN7mk1U14MVRjHAOxC+NmX1LWZnuI8bN8hnm02QgUxPsL2PH6of/Dd2",
	"b7DruujOPQbYIv1EDTjmoEgbpqI9aK4r4OfzQxzxk4Dr5jaHqtgxXRtFL5jStMBEwNQsZly4LF5tJ+W5",
	"VNwslusIKDSAo13VCl9J50xRcW6VIReUYtWOJ/chqDDZpCat7aNHWqgIAkW9hntEkuQsr7CQNVvnqHKK",
	"SV1DO3ed7oTd2L3PWc9jr/1NInrt4u/8bdfpCG8gDxiZriIt4TF5taXFG9gkhNRGzmkPhbzzm/ybACZL",
	"3vaQkJ3zAaTFZtoM4MvufUQdqw3lrExldfHiV31YseE9Z1tbCbQr7oUytikk3232dfE0fvJfK4YgFTfw",
	"WHPjkBOr/m8Mk6dm8RM0f29bP4z0ty6JlS/9ClGakRDYuQTW8jNIbuVvs+3eG+002PEDrPDOHGMNp3BA",
	"4ZndwQJ94XrzWtju1mkLKKb+uSOMRsrzdcnDUMy2PMyFqMXuNBt02t6oZzsNX1WhovitlO/NavcDaHEP",
	"J0IhzA8iJn1KhjnaX+2q05pQ5M3hGCFkabTHdCqVxZG/EOD66vV755PGL/o+0WftE5N4kgXjABcN8OsN",
	"bMdbJy8b/3Dv635QZVrax+0JIH6/b6mEPnA5NHlIfhvbFLeXDt/ESiAUn+7oj3+2/XbvISSuUQJfYvi2",
	"C1nTZOdywQRpaI5h6rvHRN1CGmI3pXrEuOO764Qp8oP6IlygfBeRIMSBcu1J8cHFTjvfOtX8tbc8bgvU",
	"povkXrvS4ox2E+7BEI9PwJX4YfLG8Tzt1btlPmPon3oVaQU/bQy6FcHsvp1raCKX+Sb3yWRg1qZOided",
	"68/9O+W4S6TDQAtOK6ld6oGQCcWzxRpDWHgLCo3AKARqDy3LYhXXPdJ1eSlMczEkr+vBibcjQfoMqPkS",
	"Zd+D0jjDZg2pkA7TFcP28VKrW1SQum/47ofovdeT0ZoZt8i8l5RmnA0IBllL79s9NN2L1nGK25H6dn26",
	"L2bXNy600qk4Yn/gb5HfELK8TfSGZKRbDOnXmSjsFAbfdpBuHkwLbRipBfVaRK0RWRcu2jym2djxuJE7",
	"sB+SDfZ73ryb9F77G1uFjGKdK9rV8KqrzMGzHFTKx5Rz/a2ykK1JIpZ8jHvHBaPqPVNzdkLnrCaa7vGo",
	"nCZbQBeytH1ISedRPSn3IqSrzC5g3BtBPUjFMqlyuOqx2k69QNfS4nKFfSFFIi1s3xNshlmvZVkiq2vU",
	"Zlz1SVZAiUfMVg/vpy5fsrB7k1VKS4VDw7OsHfgNtcoYBorJDKot5H0iZIB0HYDR9rsPaGW2EN+YzTdC",
	"89rym+9ivAaUYvrOlcgADVgdzoMJMhO7gtK7hUuiozHfKtKNkVh3DjO/Q02vlchcOmlRd82poVOXWx/z",
	"L8JYkIHy6dMf5CXhhlxKda5HT5+OxcGQnDGRJ8GBMoAtmMbi0PZQF0yFspm+E9Swg1qMFjzo7QooPgt9",
	"XHVIv4yInuzJDBkzcSwoYjbVliZqgNyQ30HmwRuIqdIsphtAvv23P4GIkJ+OTj8cf3g7evqUfJCGaDrD",
	"sOBMCle6I65/Bth2GetLVya0TvHZVSDVaqKqphskJPdrK1THMwJ6lnvw0+TSLv8SjgFIBxZpeShftqSQ",
	"yj1b1MlFf2yUXfs7LTiUPwMambIFveBSeVEkk8slN4aLuW37csGyc3IJL49+Oy55UaALA1S4tM0+MW2i",
	"/WkWVPWpLqIixAjyhOfalZEDRc1hBFS0VgZQh5hugryCajOBo5Qnvb+wdjlkNkL4kVhKxS64rLQ7hb6s",
	"LaTe5UoHOhhBHUm2LM2K4Ckn4964h5XyQrVtX0IMWzfoqjGZr9mOBUfR9aGQl0whxiykEZFLz56wKm1I",
	"160tM+ai5hpFI5trO6tyqWReZWa0v/8snS4FdvV2Or5LfKyYS+h1/AofpN0/8doZka/jnv9twvPJgeXJ",
	"X4fD4XWfNL8chi/XSDFw24MUPAplM704vK50JpmukAngTQF7hHwFKNYhE8vAWg6Jw0iVY9XE9QVD3Usc",
	"LQqnuGIOeyvoYizfbtghNL4QeiEtbdcvVMevMHkdJDUNHO6JdhclFn0E8XpGM9bJoFzv4QHYkbGs5jta",
	"GlkCY+EZ643+9Kc/Df/0J3SHdM0Po+bvZaVZ3fqw0/hZ1PhvbDWVFDLBuvZ/gPYPVqqzneffkeHnm2WX",
	"tcHJyFFSZmxkWp5LStXlnDt81uA9u2tcxQLTSrEZd8NdMhUNnJqtPZmr8e+YY+f7sHeb4r8ziB3eOmqp",
	"HWqcGPGcrTDIetNYQeLFTnqiMypEak/aNnI4ka41ckwnAOQVcFzkh/5JJeGavK6ewFFgaM23Tp+Cb62A",
	"gGn4crWCl/iBFRndfUqWNGeppHxWIa4Z/zYXkRf6kQXsgB9VSwxJTmO18vImWncNyJRltEKuBixtQfXC",
	"caCc7FQCl5SnyX07NS2tVkQvNvd5jIEEhlaKvGmxWO4aT7bLXUh29skWR7odMeS1yTBnOPO9GunNXU5x",
	"q/cWwUdF8SA2QditCS3i5AFRotOGV3RouhaqD1KwBwRLSMG2hQvargXsZKGoXgcaFbRY/bImn/O/NpQf",
	"11YC9JsNtI3Wa3HxO8XCDYknXPIWn1BSQXx2uobU7XMjpHCcRq5lUs0KXD6QRalZJ3YFmocqXE7t89Wn",
	"Gi6qWHzbWV6dDyskKg6GI/xxOBZKzUbklGXcCqO0IKdUnJM3FQS4Ddz4TPv6dljUS9XNlW1uMVIVdCyU",
	"hsEKdD49s33qsYTFW8F/qUebrsiSi70lvSIYdUkoueQil5cAbZg8JEPGfmNhZQqr1qJ2016V5bR1RFsU",
	"CGO7NVOJIpqVtv/1gyapAMqV3MgT/rUE380Ps72EdnNkPAycot5Gmp+1VQo6sTtrn359G7iTH6qYweNO",
	"v21+zRhVj0w+dU7/Jb26bRkAl/9+cxc39h0KXK5Nsb+h5/UGtN62mkQrSdVjFJRIJvrcMnwU+24V/rxl",
	"xW83Yrvg953ibt1YjxQyl861czvE/S6KsCe2JPhYw6dnw8Mn+PcFXRNn+p/Y0MeMDf01CP0UfOnvyCAU",
	"dH4sBgGzhSl+q+wilRp5WyxC3/tnmXDj3BRhv+0u4EgPw6ZrqB4N73dl0wjatmz6vsifgfVKZKtJyQQt",
	"TGKkE/yAEELF4dCJ7FgWaXfjdpxycJjOL/QvvHG61FWnOoB8ak/8XwNTqen67AZMM5Gx26DT93lQbP52",
	"rr/f2s31qGf/xLl6doPgt89Pdm+/yX6vNsrc2ZN5TQDER5UzxfJukDbZmTZq9+w+hu8qhtHXQS0PWGzm",
	"rm6lYbc6u75tvaf7F3K6fxWm+5ZQun+tod/IVr7hIl9flPmR4w27FXQeJfDwvF3jpmaw+/s3Vj+4c5Bf",
	"yB0WTfb8Ied6eEJqB9A93LjrKrCdoUuGZ6kpjvrQ9dY+1Zk7HnrKW4YA2oPXCgO8qf7X54c45mkHhRBl",
	"92uEy8Fkk5msRH6v69pV04aaqtul9Px9XTT3p6b7kks0XONFynKJhSx151nqKKQJ8CGZxMVkgqOU7zci",
	"Zy5wDttMV2QhSwIGVLIzVYzmZjGYgasb7nKf8LmAhyLEit6F8QIXHBELM7o+OW5LnOtQyH3lepIdbZQU",
	"czt7VFEzW1Audj2UiVFd+LCult0RC3mJw2lDlKwMvOj7h6UIWxHbbvDaewQOtmKJE5kh7AqgAdTT6+xQ",
	"eoMgWpr/wto5mtoICu0SeGlvEai0tu2anWk8x8VYqxHVQOF9sFYXKk9kiF13W516F8K49hsGvNhf+r54",
	"py9G3idSkSdPn2BOjkJOabHbLLQD/n16AmOk/R+dG+I2MSkePAxL2S6OpUZEMpgl4KINyg0BLq0h14bh",
	"1tXm44AGe/h7/R74HPb6PZovMQNvjTPXooOr39WT7O2q9a1/eT0Bl4THzjoOk2x2IXHt0nBWIpVlv2sS",
	"LFUFXgytfFtWSsuJFPjwT/5Z0YKb1XAsfmBFqckMNQpZGVLIy4FiBbuASGffnwtyevSWlLxkBXgSTFck",
	"Z8ZyfzEfCxx1TksN0Qfsgju/eXSikKUfKOUsb3kSDDCZ03JSMpUlcx2e4TCmUg03DfAux/lzJUuNtbnM",
	"gjoPPDcenbOxCC4dsdd2VZgheQVr0WTcY8VUXupxD9yIcVhuN2wKeQiGY/FGKuKOU5882x/uQyxCApBn",
	"+/+r6yNuZ2t6AD/bf+gcHnSqZVEZhlhNVURTeX0jZ4gvxfRCFvmQ+IwX6Ajt/EtYIS8Rnxe0qNhYUMUI",
	"u3JurYrNqcoLV8pFQpm4mhAh4KDtur4/3D946HUjEcFhSIVmsRJL1anOAsm42t9/xv5MAimSp6Q1Ynvn",
	"94fPIS5Hh/FsYxASDCkY1YYsaDHzVsT6DAzH4qgsC87ykD0O/Hpc9w6enj8kmhy/mSyrwnCsW7Y5SAV8",
	"mCEGKSQRhCCdsmRU2XMCo5WFC7BjmuxMpVnUafHGgoq8mQlwd0h+1GxWFcC1uMgUoxrfjVjGASHTFUFw",
	"gcXQuWIQNVBXb+czSHNofMJNWpAlMwuZN4vH36ESocknObuYhFOxhpxiSuKCfCDaUJHb0xWxQH92GFky",
	"6jhEm5gOhvstYkoRp+0+IAdPtclzdoExYh6D2se+0sKy8YJDyJVx4jkXbmCSiCI5eEgSS3mXhPt1uzDc",
	"T0wtscumUNrIp3KrprGMs6nDbdp2fNo2dYgKWG2EIxJRNrU9ZXN2VW7X9ide5BlV+XatodUZyC3bdeg6",
	"am3qYbf9Fs1D+bnbQPUCWcF2jV9K8Y9KwAHaEiSub9eh6U6+VevazXsjNDI7zrdHC9SU3a55IzHGxnD3",
	"RCGmLfo0i+TcYpJGJaEt+kVFQsDXDP78IZXq94jYC6pgjeRBZMG7Id03RCtiIuBMqvWVXF2U1vEryzvx",
	"jkZB5JaBfGcou0Fos/2J5fZKxVQYIKyiD/Lp6Rt3Jw/XZe1xEEFXHBVAWyNengbtAe8vt+oFN8nH2uQ9",
	"42bEGdK+pQBBMDXc+r3Mz4AjtHUxu4NhhZ/X3Wk/8FQaiqPw1omEsuBGdx0xFvwWFagCUabsxnJpxyjN",
	"Kohv+NsvTMnavTeItuudJRrb5RW2rbesuz1bplGzmCD0gnLwWh1um7q8vcSkxXY73LgMgGse8SA6Q2/O",
	"jXHk21331xX674R7g0KC+oFFSuaT1EOogz2ddToZHwPuhF370XakmalolJm5KRZG0cRWBM+5Lgu6qvVn",
	"nFFvG5HtU5FNwL1/bZJI36xWK1FGdYEURPMlL6jiZuU5T1Pr9P3HAnTKWpkH5ZPEuqePgfcLxt/tAgWj",
	"asCuaGbqWF0wT/g8hznXDpAG9pra18FtyH+Ti31AXyWSRRP9QXw4/M0Vo1bHvBGF5B3Eqfte2t4RGNq8",
	"4HOry9fztdGNhiOLTW87ggwuObgnuYDoGzXa++PUbd1EMYvUFFpDZqhUKXgX+Y/+mXaE+NSF8Epn/3Kp",
	"MYdj8cn3X1BNKKQRibM/+VTuF5ySL1+/WswP8Sf8H5Z7/+KSc7jSRU+fQhiOJp8+fvxAdj7JcyYGHxVn",
	"wrCcfASuRj5IrBS36+PRLeTP9gff7/8v5x6mWF5lLpPLly9f6jr2Y/H1K77TfpISycEBdX0NTRGaI8+K",
	"yQ+sKJnST5/C88aXuu8XMiCngC3tV8oFsTzRHjcA30EH9BjKpNhBcSv1aCwIGZAv6Hn0nqpzpr6QHcts",
	"dkfkKM/JNy4CH9JrQSYJZFZkx5krRsBMd91AVjoR5gvZ4cLsjsgx/BNZny4ppF6pOx76XjnDuih2biSF",
	"3REBWZhoVlJwyETXOzqtLKsASOBx5ovOVDX9wSwLRMdSXjBNfvj0/h0xdI45AdiVUTQzlt6uIGvBlyXL",
	"ObUdflK01Jip5cfTY0xZ9ZaJv3GD9pSlzGlBdFWWUmFX9k/b77Uz3iK6FdfO8ptJ4UUgjRv5Go+c378X",
	"VPMMNmdkaXIdJXyB3CDRVt7QmsS792c4kgT34c/7bqRPDm92oTeNFDbiz+PeeGzGPQ9JpY1chvM6Il8+",
	"cVOwEWmeKmN/vL4ej8ULma/aX6cyX3l4FA2B40ijANU3UEuggYivX/9yzlbX134wGP3r1z3bEgYbi5jS",
	"8VmOaX8M+uTdu/fAuJb8F5ZbBllaHsnP2cidNoMrORYGn/Qg0a0kf0dD2Rmw9rGglVlINSJ/pYKRV5KN",
	"hSWvn7959nlEKO+7J95l4QZtvJCt3+Zk9jvvvX1jfrBuDdA0E08EyLUeVxUbWGRVkNUzzB27zNdXnquo",
	"QbjQhlHIp1I7m6fCNHFZllUvnMMhBUM3i+o56D6cUrgT6+/1uGiyrBPtgNq0ktWTC0ZooRjNV8GduLEE",
	"iWmNfF4rnkPOF0gdAvxZ5FSYaKKMFkXTahlVIrqCqDIpJv/0hrTtIrNqHTgW0P+hpRie0sv3LrNCfNfy",
	"pWU23qelN+oB9XAx37O9etfdwtSQM88pOtSbtTWh5MPHTzVLGpJXQY4Noi2II65nJI64ZxqvfxBvLHc5",
	"jGoz+VicMUamFoABDDOAYtElH67osvBRvWXBjMsCB7kWAZ56R2dSAXN8HeTGXNGZ0SPyZezSBozgl3EP",
	"2AeweWjGSsUy2HcnJECX+mdQPl2vNw0xyZInv2A5gZMUz+S/QLdmmhj3GnnQ7zkq6NlZ5lKtRhEoH09J",
	"ayhQbdlVSUU+0Y0I6ebjWhQLvWRqDgG/cX0XZ5FuPCsC5iphRQ3iqw+4mk52C+ERIAqaboxnu4bKsTBC",
	"nCrFDYNPDBYWLmC4hpMDzAzVQ+phkjHHM5oxc+ech29sb5QhuzwMPsIJ7uZanc8Vm1MTv1ZOVygvOZbT",
	"VNamFS+ABAFelhNBL/i81t5Q2F7HJtaVFvJZS+viQh7HLvdaOGnHM6hgFopjYlok188eUdRaQemC9HQS",
	"ZU0Wkl8RzX9hmGd1WSp5wUjJFFwTopP56OceXH899MKv05n2exkoLfmEmlvkNgUMWPxM6vf2pNtstBXn",
	"bOVkTJeox6vlkda9kNpdH1F+KGBd4YJJcyjAdBILY/FSLpdSwC1X526DV4SBYYKC/uA4BrAH/HFEsyUb",
	"OZbyo2ZqEPx/nXQ17lWaqdHB4TPfLGSkBg7YHJUqw7PCjRibXaYrw9LlwwHBv6NrSJCjD6/W3EOVNngZ",
	"IaOCFzrKBY6CT5awz7jqdRcRnlxmLGm1t/kB7yeXvLO5gY7Vl9W04Hrhro0BeWX1UkxOCM3q8zTCt8TD",
	"/cNng/2Dwf6B6/HSXSWt8cMNY1i2ELKQ8xXgs6BiXtE5GzFxu5uqNc6KUVWDtA9XVTsHxV3o7E7BE49K",
	"k2AraRXSG5IzVO408Nm4OXjyPwQJeRUQaYjbv626M8atGfdGZNxzIrga966dsMKKPLCWTnOrS43afdzD",
	"WqexZTEznnFawIbbm7oo+JyJjPmu8JbU6dgiDd8YH1k7rcfjcQ9NfZiBx/4bu2wizcZqkFl0iRUIE1MC",
	"h8p+dxQmonqDHVkiXW+QY4LxLSsODiEnJ1xwGRV1zcm2Qxi+/YAbv3Yl3TTopqRbCnKNwOGcPdZLHA60",
	"SN26QbUbEpcZMo8fp1pK3XAs3rd9Tewyp6whtQDnZlxFsiumNcVkovXDV1okmViimAi55FnTR3sSFLbb",
	"CSZb1w6NinSiKDIkbyJUTbw7N9xLXHvPovMoHnIsnDWRXECWVivn1EyF7JhV6VJqHuzvttZ/uJ9Owafm",
	"rKE73PhK3UjFdN3vydlMpyJJPqRWrc952Xq4cKJZeCAKvLSRqai2zEI2X2SsrGk3923zCmTXBnnCFlHP",
	"OBv26hROwPN4Ml3dxAYSzyet6B1lMEWpsz47MdwlYEU9IRwbNwzZsdcY+TNUOWDwkNEnaHj7M6H+J7ux",
	"iLUSXj42oo2cdQwtkIO5uKRW8kVcTleNlwfnyNTksJHs7i5c9+jYiP+LuEgZXFtv9oKBVvBKi0keNrtz",
	"N5JBQMRLgwxS5Q1MpWgRxJvo7vZcdv3DC+hHdkbEU/epZiygJkqQUkXuWZdLz4Vpnrt75LhVOrPYzunp",
	"m90h5qhdZwOznIJWRi6pcUcf+VjghGCqcvprbMfC8Pax8LkGAo/1zLedjzi67uOr3qXHzRZcMFIwih68",
	"jjZ96fQuF8UkRjcVocDoASMRp0MSXnrqkIFA4g1AL/k5L1nOaTJ0O/3a73Ndpwuq4Sc0fAR/SNzqOo94",
	"1w1AxYNu7wvgQtFSnu9rgb+hvh0WBWhB6xQofHqJ2LTdTIpvMYn8EtFj+V3kI/+IXi+w5VwB33ntKAky",
	"y8nLI7z1B2cfXkNtd+TqtUV2eJ8a7/WpxRy86cwY9zcydXa1BhWlz6gu5f2Ez3XoPY2TH+br5NEkMr1D",
	"yzZ+LLqZhbblnv7p04mzYpLMCqgy3oFAnsNWOcBkBsm1XAQLbjv+sQj0RDLLXSDlXoojJUsV+py2TTi5",
	"IEteFFyzTIpcD+9ZvLAT02JBCThc66EUO0feM8AlWH1ujmLBZimATo/ervWxKZVcluaGp/sMnwErDaEF",
	"tnH9hO+vp3fv3gcjpsuAY7UB4l59fT9utR8wYn6CUBD4saks2dFmsijkJbwCUcUhOT9o0V+/Buvg9fWI",
	"HNXsEfxyWN7y2SE8d9ZbVuQaR2jd03YcC4td3RPd1owcQe3wWVjV7lj8j6wAaKtOJf0aVsJQeDtH1PFf",
	"mAt9sevtOyOwXV4hZaldntD6Cdmip86VAwx/uaQD9ygeJfQILg/HrzQU3xgR/5waIcq9x/Lc/vlNhY49",
	"fymoNtfXffL16x7+ZL+6B9aWaPHCRzCZBdOsHrrvkQIbbYA/E+puiZEVjBLQjMUrmZEIptaDsW0RATIW",
	"UFfDrvCBFpfiLo65JhwKWyRWCzWRYWBIXtNAK2DbRGltRahjc17i9L9zo4m8FKj6oHtY25cmsibAjUCL",
	"emoKBUVERg0TQBBGzhmE/uxYoQZDw7BEPwD1RONMuy74wTnTAmwj8vPXMbJqNOiUtGRKY6r21mHBBsPh",
	"EL/CmPa3g/3rzzjyVEmaZ1SbzrB8SedMtzo+7xOsW9ECAd/k17R2Uy35FcsfCPo2AFMpz90gbZ2gUWyj",
	"Bs1CtW2xxYbPIwZQHWO/g64BA99m+C+b1a52FjMoIaENW042snhsF7i7JPMK3s0XEB4N8/tCvjVbsGwQ",
	"NFWyYEU5qwpydEyo1uDLZobkzEPe4uktc5glZK5ZkU56Ztn4RBvFoGZIQmCE2i3k7Ow1Ca1iiTnyWfjr",
	"2ccP4bmsG6OUuk05q6v9wRasvVzXiPhHb710g/eRyPkFzyvHRlYNwb5+hWte0NByfV30Bpeoz/zQFRmC",
	"X7DzE+1lO/CPAlHbPTGChYLyolIoYt5fHQqvig7yjTVMPJL9gClRPI6yebSgYQWTbBa3XLskSXTSYdbv",
	"KK0U0x6M9oOpt0DhPQOubE41CCLO5sSWPhnhthabE9/eZaWz4kwqiLUr84DZ1N5ctVAC7y2bYOwEYjsA",
	"EljdNogtmZF0mxAobli71+fu29IRqQRaYhJ+B2tymUZWOrfhPee50gtpD3s5E/OMyr3/vmTi2cBDMtgf",
	"fv9i9Obg+168nT0Ji7T7tLW7bmeTk+n3uguIMniGYgM4O+YH4IYlXT8aWR3WJlNwbhDQsk+izBQg0CrI",
	"ROHMSTtPnmIqx1Du3GWfsA17/d7TZrqFtbkpTpk2UsWVBLd75XxBs/OqDBf3ZzuUrMyaBb4s7F04c2a2",
	"OibFgjMiMAZYEYMjwczFE0CzXRJelsgOuyoLCVe7e1CIs7T4kXo+sVByM84WVOU1O2pxzpVh21UjerFy",
	"oX+dkxuNkeKIZ0aqRoHMdrY2fT6p0uWGXnF9Tio0CAli59FbRaqAV2WZyuv50wKl5dqOuaBQUpGBb1hO",
	"DR2mBYTuurCO5fu6VlI7sWD4UFNmqAwVnpCblTK3s4y2b8wbDYwNMS6y5IDy625qEiqtGfThWFJ1nls9",
	"xQkvBRf1Ya11dv+k+XNUew5DpzOe40PyZ0vOye8H2KAffjj0PRCUrp3Ty0lJ9lW7hPpFwTXERb2Y2D3+",
	"hjWBdbMBsmL6oLsQ+2vf/vfw88brLaob3d3OUMStkbLKrh0rZreesFYiWygp/JZCoTj0iAHHmtry7arK",
	"uoGstvIT5Xgzn9IZ2GZKqWkBsRQlRr/szKg2TJu+t+Ds4iCQ3aYxxAmb2gP0t79jtT1sFpSmRtPaCwNN",
	"xD8dvYs7RQXAsXxtcFGOyn6H2t5N0He0Q4esdFwkvE6T6xZAz4VoANV4isSCgUAZU6bNgM1mUhnSGDy8",
	"0OzMaFFoMqXZOXgYQ91PKYjhSyYr0ycas2v1yVJqQ3IMwtht+FHWu+vzBgXU9Zol0bFEcpK3f/J21gcq",
	"2W58MGDNsT6Fd0wwA0KqVAhsfOey1z7f3++nCnkEP4U7l7yutdnOkVlbNwUH2DQ8LOoMm/oi3XeGNb5g",
	"u7CmS627GWs8pfhCDGXXeRh+j3yPnBiKtxrmf/MvYnnsj6i7hXPxoIeEXW0HGTTkgieDdyXxOX2C8Qqd",
	"p1IyV2ji8HVXNHsnwnrb2tL5Et/wAdDwhI8+KQED/9CQ9QWGTD9PiZn0KcP0DQKEJK4l5mXJUy6OUgRB",
	"1xuRW3sxHIvjGboS9KMxhDS1yz4Vzo3EO9Qgt2Y5mVYGmiIR5ckELJYiTTHJ/ZtG8u70X52jE5YnrsFx",
	"JcLZVckV69d5rYBlmGKCXhOW+2lDlyXZ8arILjota/JW1nO4W9gnbj/8bvGkT578Ibf/Pfj+j4snu42F",
	"RC9Bfqr0IhAKq11RLCoG4AWg7PH49OkdrsLlT4/hdHQORDPuTULHcQ9eIyMcWmmpfpW3m1AjgcPmrVnA",
	"BVM6uQd/xw+eWJA+IVkPOtMs+Tx6zG7Iv+tquK3hJkEK307xwQumW2BIo1A/2a6oZVMF6NaJbIyVrkZk",
	"tfT4uXa0dckjVFU3G3WgVX9tSSQE4ZENULeAdB2E/3ZVutY0jEqT3DjgTXqUM/28XFS3r2Dj+pLMdm5Y",
	"fcAvyH3lmlCSMWEU1A7MCb6zM3XB/c3h+ul6pPryHhjOFMnAiWdu74rgZafr2z30c96CnGnvAWV52UJe",
	"emFYKu37R4m8wAqlXVT0Sz/YWRhs9PSplaAX1VyaEfn44cP/HtgbqHDaVpjeO48KA8+5vvRvnRHLjjLD",
	"txv0isZ/DSB+JQwzXbmQapdb10knfSIkTE78Udh1ECN2HJTvDkbkPVtKtQK0OUnocLDkwqoTnz69g1aH",
	"I3JieS6WJneajJVt7d2GbttiXrBZwecLQ3LmkxnwOu43qxSgj+dMYAowX7W+7Z5HSz6Bohe9hTHlaG+v",
	"kBktFlKb0R/3/7jfEP1HX13aEMCHxvzr8oKpgpah8Ir9LbIIelNcvxeip3ujnsUOOCt4F9IeYDsk545G",
	"279OVazZpk6Hp/O4UEe42ZOrfbI7JC+pILTQElyImYGA/aMPn968+5/Jp9en748/vZ7YOZi44EoKkJa8",
	"O0BTOVmLzxvrhDTxfYvkPl1O0FJs3RMU7h3hAuMLhmPx0yKUkLH4uWACy3yWZrXb9+29fAc2SueYOMpm",
	"ZkR0NZvxK4zxQlkvDP5EE0crKAD5yejUzhXGtlL7KGuMRBXDVCiVFzOcRhw5cLkq/MgyCXrsMHXh2s8q",
	"U6mQXADtJnDHoIMsCERLWpbwT2aytuNqiifHtB9ZQyzJb3LkdkuNqg2BV5qXY4fkRFnMG03YVca0vY1q",
	"tgOu82pFCns4otwkvRvLH1x3D+eNQH9IlEZyA4QUi5kUmmWVCeDpIcGMsUvKQbjF4NcrQ2impHY3h2e4",
	"zlUsUYInLkZeM4rY5OR4RkvTDCkZorQduiw45BgNp308FuOxeOIcyRUF5zXtq/EDjaGrreVCoQ5wUmXc",
	"1u3dX1ax53uLuTV2o7MdvrBCe1cs2QBSh8QJB3g4Kcck5I7SqLIod4GJ/Be2mVhayS0dZJCdJZ3VJ8rs",
	"0s5L43cl3K8dVMOV3UD1Xas2dUR2h/DP66WquxUG9BfKA1YGrIfCwmGOYOHouBIayn2y3XbvXLAudRk+",
	"YNWqT4oKbcdKpLgSg7KgWWzp8Y0RvSibvZdiLl+9GGizgpwwTiYckjC0i0DwwZxGLtF5fSyoQdUUlTVS",
	"0BVTfQL5Q4QPt6b5YClzPlsN0JyqaMa8YHkMoXxUmNHTp/V8tRuEYpC94IIWPAe5ks4pF9pETzVeLYYr",
	"yUX56jj+cyysMr5kVGjCzRNNSqk1d97qGCRBuIApIg4PVbgxZQ4sXuSECW0vtpWsVGROD/x3LBAUfMTh",
	"iTjrrz2o9xeifQ8On/V89XZwvbeKtyx7o963XGS9vo9v/HZ4wdml7vV7EKveGx3A6zc0dALnKwqiXuhQ",
	"UG3+ztkly1FTbp6RZNnBEJ8MxWTAYDVlhDr+3gebEhX+1odrnQvNlNG7qbMRL2tdWFqERSOBwMBbV2ON",
	"Qrat40kgnI9lyvGkKi2Um5Mrh5RwjijCseEzwg3JJdPiiSHsykK/AwhwZ4fgFLubvYgs5hu4ufFMfyy7",
	"6rosb4EOX0GhpCYRZfPXs48foKyGkU4uc1xw3Pt2WGmmhpb1od/bt0ND5+ADJxXB4Hb3dbchfNe02jV0",
	"IfF2zFyQBs2y+jreYccSm8cbfPu2EpqZPokJfndIPmGobclEDqlePPsiO+76hr5cZHvfLquiD2ZT+AkG",
	"s9LnbmePZOlP0obNST/0N/lpVVrGFeCK3nosCL1+Dxdm/8Az/21Z6QX+vyjs/2mef5Jn2KQE2OxS4H9c",
	"wP/olf1fkxN8q1irdHv0QKToBVOaFuteikN+VeesBpZ9jDswvm/iwaBMEZlPH4uDYOYGCHbd2Sd/jv69",
	"27tHGTF/VG+nuQWOB6m/dviMFJI2S2fduuRQkrW+aFTmqhkLcoObkz3crh5V4knIMVPLbyF5RrQP8BIC",
	"xmm7H5bNYT6SCZS2+jPkdIuZ8Ma0FPeopDUJlTbXww9N7rOATYX/HrC+ZTvBVrqGEy2ke5OA3XvQ7O/d",
	"eweP6D3qr9WcoyqS0Xf2Zwz528gtQirQSVSv1N3PqdP6d665Qf9V2G6wUkgUE+5cX+BRy0IiuU59vDcY",
	"dsifwXUfOj5KndXGCdhC6HEZiKB+GRe1chAKFej74DddS/LZOrNNoBcCnfCOqATmI8zvdUVYSBpO06Gu",
	"5VojUicHwEPDE3OLuqRnGpiIbbjcML3+oxXMrI0Q60wQjwrO9b05FPNxwDe8Cd6cC7tD/JHBJqKjbRWU",
	"hsC1VbDwjyA5nlCtL6VaX9hWsMtJ6Ro13QoFuzx7lqln5uQvWl9+VHm8Q6HLJtNDY/yUQPyjRt/hdiVO",
	"7DJZUL1YJxERLxH51sS2HpLXV6XUITEhPJdpllUQ7a+4Pm/a+//69s3q/zv8U/V+ORwOt0me5cvaNdH1",
	"D7kQuWQbERJ691uLXIecl2iXvcHpCpyovPm2EyfoMx/PK56jJC0V3oMu0543NVGhL5kidI6VePAAOEvL",
	"TwtqyMpFKobxnz4dkTOrp/SJkYL1XRbZvovfQy9CTOMyk1kFRaU8OB0ouEBFjAlTrOJpIXPXFcvtbOhT",
	"7nLUOacPu8GY3qLpYZpJ4R/jtFFVBu8KO998Q04Z1VKAVeKbb8gRLBv+fANRRYOqJP/t3KD17nAs3jd9",
	"PdFCvWAUnjP6ZFoVBTO6jzHO00Jm59ophxFswf6FwXtWQ51CSTI6LVz286dPj1S24IYBqG65mvmtRYOW",
	"JRr0pw3REiGs1fkmteNqhyT4odgRNDPB9BalbvDmNwugpShMyCMvmFIuemsJj2pwqI5OjpuU1qayVH04",
	"JLBJto6gXYbgJMFGBKq9ZdqeDCULnz3HEqDvC/d/37mxypkjyD4mg7sEqoqEFSMJW5YLCvZ28koy9JbK",
	"cPy2ry/uP/ozdfa3nYmndxKCWi1nV2zBBDwSucVgFkKWLQQ89yKcPuU0pvxKPjYCpVbl3ZA5C3Tu3f11",
	"C5v/rKgw3Kz67uBSxag75IhDZ+6dpcfaBoVtRL3172vPU2MiHM5FLKDLRzs4K6AFrFQ8Q8U3EYrlzv3d",
	"STAMkaDCFFk5cbo/FrZ3mxx9gquaOzbnKJXMmL4jPl1hMz/WVHE265ODwWFwp9C+RvB2EQJ/Z8qwq9eY",
	"ceYWTzBvpZwXjLwsZJUTHIQcHbeT02iyY8FSpeKaDeaK5mzXJ0/UmLLR8SnvPPpSMXCToLbv0auXu+it",
	"WpkFOk8YV3vOSaPDsTiruAmux2WdqjtnZSFX6JcoRRPgk4Iai2TPoZvDnygurVwBniIHQ5LVMIEKRXZK",
	"ZyH1/jk0Qx+UcwZJGtnuWBwOyduPH9++ez05Ojl5d/zy6NPxxw+Tl6evX73+8On46N1Z0mthLJ4Nt8TL",
	"gJy+fvnx/fvXH169fjUWhJABORbk7cuTUZ1PiOzggk8r0Sdv//a6D7njK8PIazHnAtPzkwF5J5FRXYzI",
	"l3kGXSzO46tk4BM1FHLOhatGELLCHR+9J3Vx3NHTp+SLkgXTe5SXHtn2AnL9zkIKsPdAJ84px57fQaCh",
	"wf7+d2THXnba9Mkfvv8jyfnSclp7hfvmdes5y87lX/b3n/XJX/b3D+G/B2SnYHOarda1H4B3VMHFvKIF",
	"doh/8V5QoXujfQPUw2bPJMB16YAoRgDD3vuEVjmXfWIvFkkG5ODwj3uHz7/fe35wuHfw3X5rrOYbUvjU",
	"G/3h+z/2e4XMnBNvr9ID51Z2EAUSdhGNF7tlC1Afq7dcDeZZOXC/NSMLL+C89zpvSO2DsqZid+LgQOC1",
	"Pz1DcmSVR4G5bYwkR69ewukWUgzevjyJT84aV/IaH5HiCqhJ+DT7xp5XtzPMD5FI63y+7knEbjDcIR1k",
	"9u3uDWDXwCu3u+3x43GkRdYbF3tbNPewuYIGX1Ns7hl0zZOtWOd9L6KRnvTJE1bZ/RtcMm0O1vlbOS72",
	"8t3HH19N3n1ERhZJn0Y2h01uyJYv8GsvkjjAtI7eTBFxKsA5UPXXm5DnGpLjV1sg4uT0419fv/y01vXs",
	"rm/3iIF2noa7X8g+uumC/edG/r/iRv4gDbPXb4wiiGXBgIMo+eYUa5vNmTjnxpHM0TEpi2rOhUsi30G0",
	"VMCNXc6M4aNIAXO25IIPDofPB7OC6kXk2jujGpPhsNmMZ5wJvJldj4Phc3thkZ0pLayEn8c+H+2GbuhM",
	"YhCflfwvGo0Oh/s4Gs0vcLQgeINHccwBOyDzGRHS8a44CqTj/rH+qqZXwTntu/0/fV9f3u3J7nB1Y+4G",
	"yxkqBVW//vB4l/kZM/ouJ+/+YsC/7W0akcbmtMW1A2nwdq1rS6A9MCmLRHe2R12C8ra90Ndf44lBf5uX",
	"eOvQJO5ktBkoKnK5FEyDZ3cdX0x29of7lq3sDskPWLvP1TZa0nPmS1AtJeaqzeXyZkfMwxsdMfs9I8vJ",
	"eepRoxycE22xD+aIkJsanULhQxS4aWRJ/hY8t2sDbzVFlyyD9JUmIQtCmUounRWs0gkgEEUHgKLW6Y9w",
	"/4AOquslsWYJ7kcLkbp002yO5gotP6dih/1jCES9IohQUs5KUhCIB7/3Rr2p/bXerYUxZe/6Gl6JZxIf",
	"w4ShGazNleE9EmYGKSfq4BQ92tubc7OopsNMLvcotMin7o9UZlj7O77b5NyucAqFxc7ZaoBFLyGYAQt+",
	"xUnzCQOxCMrvGCs2UvL0KcY8QXw/OMELDebM2M6OQVAueTPaP6cMXQxNVGTOh/K4bJCWHJSw/CqjJZ3y",
	"ghuXyC9nBb9giixWU8XzUDjJEJ3RAl9UvvmGwNvGe3puZWlc8Y+C/7Ni+Pkb8gP29sXjBuTp0xfvD5+T",
	"/wpl5UJG6qdPR+RNqygFAtmJvtgiCTXO9T4oonZ0iJ3HvGI4up2pT1r2CNgRnjOJQ7wOiplPEqTtWJhR",
	"qU8+lkwcHffJ0U9n5AXLlczO+17SfwuMvm8xs1Cy5JnHyquIIF76/Ywgxp1+xTSfC3iecmkuo82fK1mV",
	"2hXIMhS9t5zHWlZU2jC1i0t1fsk7UmDUB0TYO/z8IBX/xZJ/QSBYn4u5ne+VHa2Zozuu2+2CKzBUP1FT",
	"U7EgsuM0b7hgg7eKQlrxV7aVJTTYcXeJuDQT4bUrW7kKXyuRocVZkx2XGaKPjft1bvJ+nA2jT+i5ELse",
	"10fHgw/IU98wYKYO0adHb/Hlz2fIC+ksB7SaL7HKaXSXAThnTF0wNTiz18BriJjBwfD5jRzNmTBIaT7d",
	"uPFZ7WRlQghjrRzhx3oaHC445fk4DiQCl4e1Dmt0cuiO86/fXRcg6YAEZL4OmLKDvqDZ+RyDNWoLRJ15",
	"z2dSgXELRnOmBuBz5Iz6MLajabtJ9sIgr69KpjgUVYF5QTx2WRleXxln04PNx4eKL1cDZKODp18IvCrS",
	"+vb14WPueDjHUniwjbzzEenO1x/9TTXZ+ZaLrO/8XMGndDeqW93yycfx33HBqCJQNgLJgxoGCVSx4o5l",
	"p67+ANbN90kGr+DuLggmwXFkEcrynvpavnbMRK44XKrLKhxcI0MFYBwN8mWTkCgJ1hwXafGpUPE1zrtb",
	"uAclahau0rTfsDcFu4IQgOMGhpFJflqVUKmVfKmTfV7sfyE7lnvv9skXe8bwF8edYdZT+oKb/7bfMUM4",
	"NFCsQIAXvKzhchwIydEx1S+BBpn7+UuffAm5JuMfS16ygov6N7KD2WamNUXXROomA9HG8nH7s3RzZhjH",
	"9IXshEzHYQdCMJddEtaGgAWhR7CvTmU/+kIQuF4GCjRRbODqciXvo79zuK9QU/gvXwZBEavyORNWXXo3",
	"uv128GJxY54U1XwOfLf98P6a6hUEFeS5py3M6QOed6AeWJVPG2X5u7EUDNp6wTPm3Ia8QFQU5BS9NU9d",
	"nGNHOsIjPORyr2BzWoA4DCX1gjB0Uk0LnlmNshelfOhdHNCiXNADFzEhaMl7o96z4f7wmXNCB+luD3w6",
	"9B6+OYOA6iTSpuQFhr13797D0z4mnFs1igCGrOj9OhiIuNRHUCDXHuNm0ut+KHjUSFnSPHFWefDjsdwJ",
	"F1BpMqStFu7FfOjuHe0hdNdl310IOBv84PyscCTv3aIhuyvGbA7jYIrjHNBtW8Fl1EORmmnzQuYrL+16",
	"L/HatIZlw7zYTDfXRQgzhNx/TfHduaI1Ckoc7u8/DgR1dlR2ZfYALQNMfdscsO1V3b7MXb5c3E8YBo/K",
	"qLNNzSiyPllwoyfgjw1/ux+YyPvR63WdVaXvdrLvvAQmVTmp0x9GzXJwCMHKEF0je0LriLyf6vR5/SgR",
	"sAv0laqV/Pe63/vuAfcHqlakQDx2YWYtR62Q+fn5rwOEv66BBhyCY7US4tAihfJnSHsa8uz1YokPzN53",
	"FPgg68Bch1oFkzguygK0FyodpNnda2RMOlRMcdI5LQribiKDYYIupTJK7Y1URdjRodyrdnhZ+pJ9aMBu",
	"62dgwP7y5YvdlrH4OhaENJKGh8I2414fPyZzh99Y0c91jHKTj8W1qy4ORvUmq94Ekgs81AGiZEr0taWD",
	"oipBYQSXqsz2/HkcF20Ld/a497m9jMPWMn5o6Nmgw25aSpQTflvkFrQ0siRz4AU1cpM4WPD5In5QcL2I",
	"35t1CHBgpVYfl2ztAlcqnjEss5gd7u/vuyKNE21kdu4KWF+HkaB+Bc5Yh+jBEPhndEwS6D943kT/TxiB",
	"7+uNbsA8uBbWaI8r/WKDZoncrbeHwqNMa6mtiuvdXr4wOIO0qYkj87xFax9eAe/H+wvWCoUKquLcizR9",
	"opnIm6WjoMyCJq4z8LUvL5FnDD5BBt+YU18NRG7R92U4FlALArKKQkitHRm7j8fiy8gBFpUbQMZh8Zag",
	"zHHv6Bg+1VT387jHllPY5bDo59etIXOZwZaltiHC57hnKiMVpwUgMox3sO8x2JG33kIuZrSbPo681SyP",
	"cN3vpTDdHC4hK/x60lmrQlniBsbbpRZRfnX5wxcb+L0JHifIkAmNK8qtNosRis5vI0SA5RBVFBryBte5",
	"yaOqrc1SfHVhiGHTz5176Rr9vhPC987Z2etdlx2fFgPDl8GU09VxTun8MQ9cVB3qVz46demMB1Ro5Kx2",
	"tvWbGXIrxTmffarnbZSN06O3jlrSmkagmpaq4SzGvsAp0Fqj9MevzguwJsnvlRNY6HdOg/X6KFiv39aZ",
	"nrflEnXayjlLpk83lRL4uuTTvC0YLayKAxwDSqnIGWgf8MDVUDrcM7x7n+jeo8y4TJiPeL5e4uQh5WZn",
	"Y1wDv5i6kFojHT2Q6MHjk8mPglZmIRXkSBy03dACW6qpNjVLQOaepzpkFa9vTXNvmfHb5xAU0ZT7MFlS",
	"QecMchEgVaH6GVFVc9/fcW0+YZN+LzyNYyqYZFCxU2enK/S9QMG7TtxhFZBJOykH/Ah5pXujnj8NzryJ",
	"A/TiJNlRHu/D588T/o0bQYNaON6uWgP3fwCQ4dPJxc/7gz99/q9v24D+H6tcTIZP18GKA64DNpV03G7h",
	"vc7TdgGeURrdbnBnIiu1L9nnqKNm+jeT8Auan3Z49eNSPeTqgZB1T6We5OGHdQS/9xX+/4Eu2TXyUqug",
	"den/lZLlJ1eZpbVP3yX8WcDWnytZlkmm9NtEoV2jT8J+M/76aSbxlpk1OHq4u6FBwl2SdZjH6DZE9neb",
	"MfdBmjeyEvmt+axpTLcBZzeyzU6Ras9bXMINx1oCtfbaAu9tOOPn/hol4yWklLL6hGCXcTp+GWrutVP3",
	"931p776vCFp7gXs75Y+akZdUexOlS6BbO2RXIgTOYh2bpHFHVMsJSilgHWraSz7VsM62sYA2B3vmjWyw",
	"OjTfCELsT+0SANFHUtsqG78mR/If7F6gTQg9pZzpqW5Q+3R1eoMhL0/83BwY97k1MDYKz/jwaOJsc+ds",
	"dSlVPu59bna47rcnB8Ppg8+PJVfszbs9JFOZrx4JkPbc8T+vW5sVhnEBmAMuBrQoYjszrgzhjYYOw7o/",
	"/MjjRkmLhkF83LNNrrsW3UCsSPATnl+1yLQeK3YWwAEdCNdrD5R3fgt+YNsfrOcO2Ial14LhMw1l1NBC",
	"ujeY1pNubf+/9bF0Bu5f71h6i/q/9Hiikf03cDpb2/0rHNJ+d0PgmWHD5OiCu/3koloyxbOHZBL1y0jz",
	"OeRurCIQ/mZW4az2NzEL50IU4cc96+DnBsBRE+8m0zl+PurDnTRw0Gwgf4zez272ohgsueDFstWmUq5F",
	"J4f6wcF3z77zbK1GWIe/ffMNecG0ISeKZoZnKJkMyCsr1vhkrS5ZvmK+3KyRwUGlkbh1QM4gzRtKH+zS",
	"e3Ciy5heWrXESjWaGU12DgbPwC3ICkVLRgUX81nl9BZX+qehJtclpf2TVuOJFMZ6KYWGopcU3QOnsiEH",
	"RR7MjhQAsobfcOLRBKXBWqR/eBtuNMO/yJbrisSs0yQwx2pTh3P+AkURhF3mU9vfTUW+hdKBCIvl87to",
	"untTqAmKCZBuo5TYI+D63kM9uUEdaRIgli59TAJsFUfdhvZuZ1FsRWgEvNfGpOiBbYv0GF1CxSV4T0oC",
	"almHZu9od7il9vwrGSrcirumCstkuwbzJP2bbHEH8k8UqvyVDoKF97GOgMkWv9oJcB4QqQAsHxwY1W6L",
	"ua7vmQrqmlFepAb1Gbzxe5zIG/0HoZh8bb4JRtQmzPju032Rhd6uVK7L3MO1L0ifitXja6q/BWfm41dY",
	"V8mtZ6t0Oe084pjt/E4oDl23qcqW4kSNk5F2Hfj9sx//qIeMwCWXBxkLSVRjSNidmVNUfnTtW8yxa/Nr",
	"vBrAXHd5NYhlzdqu+Zvd1/CEEMPd3Uf4+q+z7XbujJupaO8r/LHVAwdsdC/N7tsv4zm7+p0+cAgXYQFB",
	"QVtu77rnjjUYezj1pHH2Uh4KsA93fu74FZ+keQPU3+xx6t80G3fbnZgtnLKHEfhQz6vJ6+HFvkaV6q2l",
	"vhT50Tz/HTGBozyveYCR23GANTy2kPK8Kve+nrPV9frrGhr9ja3uyyduqhixUTY7hVBIMvPn/t9GGkP0",
	"EgrZXfh2gtdvisH8jUVem7BJRhKkrPS852z1IBLCkqk5u70S/EgKb8tPMgT1QsSolcTOGSu5mPskBlzg",
	"J1TkWrG9mFKhMoux2DmR2swV031ytpAln6365OxZHwLop4pn53p3SF5Is3B9nSCvDZQGk4K4ElNjoRs5",
	"qrTFyznDDNJOJdBQ544NLumKAHZHYzEgx05DEOyyGZGME4It2IVDZwsq5nXgMpqkUadwy/YDYInMeBxS",
	"0jlzD+wBe+Nqf//we3Kcs2UpjYso/yARddo2C6UbbXc9JGd0xrCUAMTKjQXKSWIFDaDIlD2xqipNSCcd",
	"3vchHtsOHadY8+ks+oQNMrlcMgvs0cmx7mNFm4KeM8KuoDJwfyykIpdUsYWsNPO+Wkb69VtKKOTloKCY",
	"gqBhw/bZvI9OPxx/eItLNUTbFbUK38LuOCuAq2EJxKUs/vVwLLCG7iArOMTp2TUdnRxDNY9hwlSOQekQ",
	"k/5I93U0w7/IVN6AwLk/d+4Z+Iy15di/tRHSpSEAQtom38BdLAF1XOGtrfTeJfHxbZPg4/+YNvr/qyJr",
	"fv8HAxdHQ870jjy2xq89Qf8+IOb2RvoQ+PCrSCtRbE4dcQFGwCYSfmsxOwR+xHiBOmIwhH10Q3rwpfY/",
	"cT3/iet5pLieu7K031Mg0Fr2cDceySCI525SgutsRXr5qwgLpzjhY4oLbopb8ZDDe7xoRhsQ5QFXfD5n",
	"ars3vJS1BvfFP+qH4X43Zja/AuovZSsSB9eRW0vCEfL/pcaKKkHTqLxj9rRHommMesCmvxUHKZcuDkWJ",
	"f2NFD7fXE/IT7bwDN/tdgbveTXGaELRoBUH/YEqLwpXEcmGYeqUNWw6Jy2auCc2XXJAy5DMfJiwR2vwI",
	"Mz/U23CT3d2+Kt0Gj4UEZQVSitxs/hXRnDjps8ef9I1UU57nTJCBDxjt7vWvL+7gkSH3eEqvHCX6owJV",
	"GKPjsYeEtOGE+Gpl3pHAWfGKVRxsy7Cc3DAVs/wSO8Ds9zwWrfqRYXe2L7N50tjRtvvOvc/Xb/w8/U4o",
	"GKKonbG4S2Q3UfRX+7+Ev0WrqLsz60c6QJp6sWGacr9LplZU3lVu3Z38uLh/QXPiLnXvyO5pmnAd4uF3",
	"oxv/kSnQokRIUz9+/k5oELee0DUk178N29xIZ28ZsMcXqyAXP5JACdDfikv9h2h/Z4yzQibUdvUJdNvS",
	"4VKQ1k2AYCxRnlCzOPE/97YNYgZYQvbXOb9got5azLuM1ZGH5Mew4wILzRvIml8qlrGciYwN14TIBO78",
	"WBEydoKGQSNBLBCqgjWtPOIf1pH7Loe6huw3dB1xZ3vkoqxMfdD3QnnvJddLarKFO+5/enwoX0oxK3jW",
	"YD6EForRfEXYFddG7/6OmEAjTGl7gWkvrhD/YEyiSmWgdg8gkCvab/tW9yT2tNOd1LXpH+PkpwvrJ7br",
	"A7us17D94X84QnI393uMhEiB6FexyVr0q7MCEeOOLUuzii7+/9z6tzWSAdsq63Ox1ZlvqtDrFKZTtpQX",
	"TYWp7klU5W3MKC3XyZMVc+5R4cK3+nIiWyGMX+vmb5Rcunv9RpNzu7xYmM8bKyIoDdT9UjBTPlyTPcoP",
	"cKNturYMSJUzpSfhAWmTu6GF1zZ6cHg/2ZlvgnnDo009SCobVkLVPYm2H0H8zbAVgEvM3VNfTT+17BFj",
	"7TfEcohU5FQWLPrF0wWKzoE6fz+8CU92TNfAKFpiSWSV20K1pkURDXg7FfskYni/RvzWTfbG/6jh/+5q",
	"eNmgtjXU/rgK+VGee228eblsPDFHeV5D+kk+op4dH5KE/FqD7Y1qWLTnV1Wyt5CzazhvjMr5rajc/znR",
	"twtcah6fm24wHNlOlRJa31MuwJ8dm4RCUXu05HsXB3CW3bCdrlJwY287kRN88iYrWSnvn+8SzD7R3aTD",
	"Phugz977AzSwP36qMw77bkzkpeTC+EpOOvJe3JDDeIRFt3AgqGB4VBREyLyZ6ThwGlpgh5xB7fkcghik",
	"nQcbVoJeUF6AG8u0qpPrziqRxf0rEU35UnGoy+jTAWhCsaC3mBM3HBRYxK7gUAbdcOzBJc9Z6Orw5jDv",
	"6sMNHP5ItmDZecDXiHx5+/oT2UNQfvliG54ouWRmwSpNllaCybRv5f75xSpKUDvvu8P9fVd63wp9moWB",
	"Mf2RMBZJhvnSpB4i56mACKYFU7BQLmaKhtSOGDfhtIZEIuJ+72qQc10WFN8g6jzP7+tGXYUGP/pIES5S",
	"5DgkmLzYVXSFFnUOBCymCHXf63IaLn7aEy16u/z/tF3rchu3kn4VlJ2qQ/pwSFqynSyrTm1RFzva2JJW",
	"cpI6tUxpQA5EIhoCs4MZyYxLf/cB9hH3SbbQ3bjMRZLtk/xJZA7uaPQNja/tP/AvgxCYmG3MT9Hbl0Cd",
	"8LrFDYjGh8G9jYyLL15QWCbmf6ORC5+GcbxQv25kLjwI54jgNy0pOawqf0yMuBUlz9lSKHEtK3saKNOh",
	"Nfou+bXArJ7HygBZwiDjpJ6UnMgvD9Y+Kyq5BYRrl4vQJYNlH8WnihK31kYYtC6l8qm3UDkuilIXpbS0",
	"c5CLW8G2+OSG2j8Qld1pzEJrm7bDTfgdL4XPL+nQt4xLwRPS+IEjv4nJ5XIJ0shhKDhxelNkO/D6BwVl",
	"+lA02vY4Meal22X7jXYJJmwqrjJeZo3S8ZaGvYTdaEMmPoJl2A8w+gCO4RMoho9iGD6M7fkFWH3fiBzY",
	"xsl7ANPz2wewqbb5E31aKfdEn2Aq9XQJxhel+umO8P7LhvhlK+PyBz8x0l7oyifBK4HKIEbj4ck8hnYY",
	"ARU2qK3vvbJt9prnRjRKfiuK6v3D8KVHO8W3chVxKzZI+0aUDkFfSJ8Yb8oSTEZP4BGICIgywKq1LA1r",
	"DAlG4aWjsjq4ZX8Rbxo+0Z21IlLIVweP6/Pcd4ZTglzPg2uXGtZqJCbXd6KEhk+uQbn1L0dGrlrERQ3L",
	"pLFMMKNcU8JUImNnQD3mxYuZgydM+4grRdamsFJj2gB32ERytk1R+9iAlSzqbxWTaiNKWUWZhZubn6KX",
	"puClUJVtZW6PIchVamjWHSMd1dTlrnrgjPpzwsbj8b0DhCSWHvIfuzS8afPkpgsFY7FDoTog8vCwGFr7",
	"nV3qjb5DtQm2EjdyzD44HQM1BbweDZoHlPLi0ctvfJEKdSAp7uPwqJaC3EW4l08ABon4nSHXrR/I0602",
	"WXncRQqtWrUtZQNbGDObh5+vrqhiil3/ini/Vown3CQ7XSdfNrNRgDnm5mqnawI//drh7K1LvnVYx3b7",
	"DiEvP2osF3Uu3EFIbf0U61uBkjKrk2zrqoaTSKnfbgUbrDZaG8G0EowbVpQS3uDY4Q1RDQ8/GDbAdkfU",
	"6JCtuGJLeDq7BJ6C0Mu8lBxecaVu/UYs7c4/Ra7S84H9nfmqlpvoO2pb11VjjGzA60onPMsMzXnYPQBA",
	"yelCHWidCw5WKPGSwF/QFwpLPWsoO31yvMn9M/HJc9wYrPX5w2zCKeQJpKBn3J1MPEWIpwpHEGr5wGp7",
	"RnnO0itkNVAY3ohb5TfBfxPKdVdh+0p51Yft62YHMsWudoI3Vr3EMWJP7P6IpblUN+mQob4Mo8oQkR+S",
	"wWNOZNxsnNzAiok0HEumS/tPPBae7objJnOEpONuT0Dxp1/8OUlYOwNpABKv9I1QLmE9Jkvm+c5IA7E3",
	"SDgEbGttHL9ikOvQNxWSoCbuRD7W6Y8fP7xnFV8DfwaeGnqDb432/HIk7PgTX1UJBIJ43g6rBqP+Q2TD",
	"0NDJkRnZTsyIrXgl1hozNGLaSTN+8HAm7DhbC6YSu+yu4RJXoq60e0c/7uFsfq9IUmAnQAYsYT9fvJ/Y",
	"v91u07x8F25jn7NThLSG/XDHOmwqAV7bJhE+0LABgQKi4Xyda27pxC/FSteqMiMGANx251a6FLQES2zf",
	"tvaxrMUEDjq75XntLe3n7IhXYvJRbkU0jIxXopJbWDH7yVR8W5BiFHWNgUYTF2UAMR4jl4Tbtf9OaFPw",
	"yh7/0MFaaHBz2A7e80pWdSYmuVZr+IvBt9BRrinB7IittC4zKzfcHNdCmw3HzT2E/fvE1kJDtn25YvAt",
	"tLTUtZXNQC2lWJO9jwO9JCYVRunztdrGf0FE5zjrvKVOdFyATgqGdrQ1HQR/2pVcL22DB1JZ/gAegbip",
	"qAW55WsibPu/JdZopSUGcXqi6EGr/fHkuqNEWTW0paki70MOdi1Kq0KCDhib1SmcG6eydwVKyv7vf/6X",
	"pZEi1CnqMN+R5S0cxmVcN8C8d6sTDcfF/U+/eV3SZ5N+i1lwg8vAJ5oG9QHELXraAso4AIY7TFByCpBX",
	"M72qHPmnVlk6ooMRiTBf05c0ri49IxcG6qLC7zjElhcetDHITfeSGJUo2/z8JHHZ8v27dO+jhNmyU3yF",
	"fKiVPXlOlf51I1TQcsNmRxTgvHYugtObSC2lmNJF1NfX8pNwS3Meyzew91Ai2V1GHQssBsN0KdcyNAoA",
	"/NDCT8QkSfqBMvqgBnvZr7z2qpiUovur9OtHFF1aH1JPrbpBam5g7+FTJOK7UiAuRuJkIHok0vAR0Hyw",
	"wnCpgcl0JHWkvkAJYQUrA8EKzuyEdG9HFLaMt2/BMSfVehYd6rYdIsil1wN7j305iPuEzbOsXxK3RW7k",
	"3ic3PcwT9Q3Ql9sKBBwXq2OAIsCyukQfOKrFkCYALcPHbF7gsYUuK64aqsy1ZyPPn7PzKOO3g/4Pbss+",
	"k4V4y4bfCraR640og76+0qZiWQ0PwgMRGWmaChE1YU/sNQe3vLdsl3VFVr1zoxdWj+M5bjIJr75VB/YX",
	"E5wflb4V5UbwrC33YFIosaIRNZkq2GSZEx8wp3gbWvZ3YRUu4ARS2ZNlyJZhRv6BnmU/KMtR41uMzsvP",
	"7h0G5hF49AbDgQOA4I0wqpE4IJ9DDDU8IZjhEeTrDhhEO7UaLRS+sXawACM3fnkrs5rngJKH4HL+agNh",
	"m88aru/j62u5kvjGDrtl2r0rCjw8XKEA8J5BDwVdzyNQCYx8ofx1Hl+tRFHRUXXYyU723IhdAsogK7gs",
	"zbABqjzwpt2N2AXDhHCYAHcKrmf+JOQ4BIVbqAgVjuoTIBx7AA+OPQIGJ7tQcCMPxtICfxv5mT+M+UaA",
	"Zz/qOyYrdqfLGwNJmV6OGV5+tKaHcy742jk6BmESN2I3XKi9MbsUKnOTA8y3SjcpzW3mQu2P/aIAoNqM",
	"1QXOsCgFDLYzmUdw7BDA7tWYXYhC8Ar2TtnDC6NImGrg1rnQgSaAXQuQDlaD1APCAZx82F3+53uQ1ZfH",
	"748PP7IX7O3F2QeHWWfY2cXR8QU7+CeTGXt/8uHkI3s5nU7Z2du3l8cf2TRdKMaSDs7d0UELpq6VXsXW",
	"uajhQa/UmfPjbnRd5rtJxmW+G6IE4Z5EvesPgQvZ/PwExg13t/A8GC7s96Z7r5Lpy4mbwPh3o9W/Q2Do",
	"P2SGEICQI/8fe68bo4/w+Bp5uFZ1aXQZ0QnWobktxUpv/SUcsDfqGRmlH/U+gCyy9/xG4J06kBRo82A/",
	"sIG16/hkOp2+hDGnI+Z/2XO/jMfjIfaPjArFI1IMcMyAFkggglj6nLAzsCupGCzIiBmBaQorYFxAWsud",
	"B0+0Aw/QkD1Ukom84hhuGwjFctVAKY01bg2xDWiIJfFOsgFsSFecVgxG1dGlbkn8wN3vWgqH5XaMjyAe",
	"cRMB4wlCBOgWP3HIjqwB7IhtNHEiAxRkUtaqBf2IFbycgPKIeGQ1KF5Ko9XIHtmSq8x2BIFITAmRuXuH",
	"vx6nkeQbpgtRGSNUEvuBnqiguIQNsVq/rjFGAKiCr26EoniS1JLRbDKZFLzaTCpNKXTAXaAhzsOSGQRB",
	"oLKzP5tMlvXqRlRQxRacb/kfWrHLfdu/A0iJ5H0plrXMM0cjEWQKM4oXZqO9F4P9ZCkO5bj95UiW1pQL",
	"ApRkPOF+QdgqaaNOEwjCGyWYLFmt5H/XDtU0aDltlJaukgPnPGgQPToOQaSBOi+taYdRBo2oiHbiztGD",
	"mQcRJpQYLIQWcKtmkvPcZ8ACsrkQK1mUsEcXXN2wtzXETw0uLt56JQKFZcO5CQ5F8HBeEgMH2xFjFwh7",
	"a6cq/gnv9/SdKCGNVxi+NVosLYBN3Iw0kFZUpkud7Wb2tNSVKMGqdP43XGxd2lLz0yPLF88u7H9Pzz5C",
	"wQtL/1FTO8HLmeX0+2JvujfFsJ9NaXXZUGjxDK2hAj4snnnn+qXLu+imesqruuQ5y7la1zz0RBvV2RaY",
	"J1YOexvQ67z67qJqYAoEPOcS0YE8pCab0SeXaFSYoHiGBiFdnN+0H5EicCS4xQtFxqVpWYatZJM0tX5q",
	"6bkDCHk0XbJKuGQEynCOomh7XUBAlHgv1MMoD8tJeQ48Ns/lGnxnz7oZ/NwNw5Vt/0rpLaUjbCS3w1Tn",
	"ECGkMnaMd1R29JbxXCPgHKINokboyPfa1Zv5c4BJ088h/zrdVyBmYMRB7jbaAN+Ay0aXCi8K70X3XOs6",
	"CDu7wtTuuA61EeUM4g1gLo5G4A4Dms/ljXDlXu7th8R4s1ev3yyetUYN53qh5kWR7xhvHF5uGFdsfnpk",
	"xQ26mfqH53e0ubvk5t/NKrHaKJ3r9Q5aa53ExbN7N5kjv1xgQeDFAvApaz9suVRuaCqjjcAfvEPY76Ob",
	"2DEautFOOK9Ka7aD07OPYaLD1kyFa/fJyWaiKAXiYJxdUCDmDJjdrciiuVrxHnspTnUlXCQmXYqg3V4U",
	"uQQd/toKQ7PSnmhLrm6kWo8o6it6ThPadfz7Yv6ODeh1Bs+Teb22qyEy9g49lXbO6IdrSSGVMefMDL5M",
	"YgXv339A2d/lP6XryrWESSAR2NOdrEfgOGP+10KHlKIJDOnBGiM/WegDdITgUwVp6m/szJ0o2XwN8RML",
	"deL5SuUwH3UNYZp4WL3HGj+u/crBGhzm3BjLzU1YPMOASAxealpF03ks7UFM3OJbo7qo5BbwE4HV9ioB",
	"8ZoEBzOHWRg2sFLWdWaGLPZznxzRd0MSaBhvx4pGjjc2I0YOLTNyw0AfCa1orPd0QBi7io8LMXxE83Fv",
	"oUO8dJxf6Ct0HmzC7vVWZzxv37pgvJDXYchYM452qzvtb4Ap+YUt6vl8GieG9jeqkQKEHSzUwYe913RZ",
	"3R48HRxgPONwBwKSHSMl8RKnHRzadO6TU+MwziQPsRhtEfxQUmuSmS4bcjMtNn3ciu2VlSo+3KAZPnaG",
	"984uBMSVTtnABeEOZ+wEXEVi5ELQcVmlYlux1QDxaS382giQrLpkFaQVWA+xj7fCalk+zsSuq2N6jOdr",
	"Xcpqs31YgWQDdNwHDXLYq0KyQVeFHHZ0SDbo6JDDrhLJBl0l0iWzdbv7N9O96wub7C4U6LjbSVXmCYd4",
	"NybDEy0lKI6uQy/DuSGCnVv74JPc2lN4kyjBrQHMlJDrzRLWZ/7T6enQBfYBG3GaYfsMNvXfcPNKJAuv",
	"N9jXEG4zwXJMs77xBtlmcovBabbQ/g+v6OeehMtPJFt+KtHyFyZZbkVdXjifHN56uuPjhpfO2DH96XPn",
	"Bi7gJI5fYBOfRZ63GvVLkc7c3vuf2KB5g+wGwGQrPHJItr3Is3RGt5eVxvK02f9xeXZ6zquNM/foRVPa",
	"iulJ4ScXqDsm5ux+/24MD9yWUrsTk1ZiW+S8EumM/chVloslLw1zvyLhY/h4UeptUUUSGT0MHhLcLoC0",
	"055E0gG2F21TdIRhAD1fCzPhdSb1xBKHbrK3GbskPOAuJyMx4zfwnMirV9r0WGqOHA27lRxU3kAXTWrw",
	"MukMaJYN0MPyAUy9Yfc4PULoj5P5FxG5o+9zXdTWNEWLc8bS0JzdYzDEEphR4oK3tp+WXNJvOS/Xwlvc",
	"Z4VQ85Mnp1IIxWXfVCBizK9tsp9AlnFfkhfy6kaQ8m5ukvF4HE/lg5tCfzMpG7x8vf8mG456SuA82GB/",
	"+v1eXwme8WQ63fNt+Kgbrde5YO+EXbKnJr7GUk9PfDp95UsVpf5drKorSdnpt7uEfvJFXNyOMzaTlVBV",
	"yfOX/Qz2+zc/hEVrWgF4yOLYG9CD/k5HLIRXzX+9ZAciK/Xq5qlZL6lYH+mC63BcyYqriMiS2zByjB7y",
	"MxPcVMnL3l1/uDFLtA9+3bNfV3ojSjHG34Va59Jsktv9zidYpFyqdc1z+929YQtrd+JvZBfql2Zy+hVX",
	"IZ81RRwBz0IdGBiXE8X9jC8EUUGg8aXnlWzw8U4nlxVfiyE+c+PUBnHMSgeLELa0GYdYbYQi8WBZWPyx",
	"923Pw6L+rxflIKCd18mvwDc2nOf8lvcK/fj20dr4v8TLOUihYjr0q2o6ywpxVF6uDGLGOvSxQKgSUH4r",
	"PIoic30haZNm8OIFyg24vMHeR/RHUmwk0OqS37S+QJX91L12s+wZGlgXVfJK23LwV1LV5TL8U8NAqRby",
	"NqwFfyZ742lynXOzScSnAirh7y/Hry1vav0CJamtuao2pS7kCppb5dwqxfvJ68RopUSV7E33Xr2c7uGZ",
	"dF91URv4Mt3b+7fUPawDpgLNcNfo+OEGk9u92dTLqVNeyVsRH9sB3bi4IwQvZfHM+eiPDG8jehnlv3JK",
	"Xk73vuKYNITIl4qRpwRJh/5x0/9mOj5p4GK4EvkuIPk79zPyNR+Jz5kRBQeuE7Mj//zUU/wHkUnO3oL9",
	"HMLqkBlGC06sdBS5Bu14fJoRtoV2ZBSRd8d3wR1wssXbdCAhbsSbV0yolabn0envxXo2mYCxuFrCZzQc",
	"LTkW6uFvd2JZ9H/Ern6+eI+XrqSPYQh8VRj6G67V7B90HecJdW7Fg0t394vTbL+xQQrXCx4mdMjZJemz",
	"5tzDycWzc7oHP9/oSgfnva2IBXDd5C8HZxd305/erfV8Pp+fXv68Of55PW9paRhLS/ZAcgAel3MwBWDf",
	"D8E4kH8IeGUUvWYuIfDuFjK5+5gucrAGIkWK6bE8/iQ5hs+MoEbDTqLPrrfGus3Y58+wmvf3i4U6dE5n",
	"9vmzc0DDh6PQnv0WNX9/7zv4s+VoU+a5bWGXYBS+eMEGYSnpReHnzz4W9P4+nVEeSPKDwC0tFXsu6bnK",
	"/f14PP78eSKvocKh89fznOV6LVeuvOCrDb50cTXsL9hJhaoLfEX+4DmMW/MRWl9o9eJImDSstgTmGNaI",
	"EeyTUJUso6MgDTOilDyXf1D+Rx/2e/ypgshQrfDAOMvZQTy4Hj2UTLAX20Y2holic1bLgxcCaMvTw8MQ",
	"H+0eHH4t4UYU6s32PlJtUtJDNPQw+bRIx0+VuIx3aHhOAo8cdEEvmvx7vRQvusiJwPy7SorfhtdbRSkK",
	"oTLD0u/GqfN2UCyWe3j63bjHSwHvXYpcrmQV7RuVh1eU/zX9bYzuKYhlgGA8GenwdodpywTRtw+V43QB",
	"OHbBwuT6oHAPfCRRlVwZ7xjGwBV/n998HRmwRBpeJLei/l5bAhsHJ/ax43zfSCJ+qf5y/nKqKzGL/Vv2",
	"zOmtrPA+JGN3Ms/tqjZ9XHCmI9XZKeD7P7wK1mikyMERRSHipcw38/3v3/zQy9g9P/+XGPU3a3Jda/4r",
	"LaLHem5r7j2Cwi75eQgRRLOCXYqqLr5dCX69/6ZLnvTS8MtpM3YtfY1zqeNe+u7z2fnx6fzkan5+cvXT",
	"8T/ve9eh9+XAixeH+GQ2OG7vpBE5AJT8iGHq/pNx8B+Mr1Z1yVc7iDv3MdsUtjWh6xAIaycFFtBsnHrT",
	"90odoHfoDUKL00BuNLYV3LKh6zonb6yJXlDjeTKVFbxrGDt0eKcTY40kNgikxv7ufdHD6J0DQAGNKICa",
	"atGDLeTJhBOEjtBbww5zXYMmTi5SePdjxYUurFCcFKW85avdiK1swcj3Sg5hosiJWfGcYv9QhrtbJg+X",
	"4t8skPC+8w6QjABoMOr72vnO+a2WGbvb6FwkQUiTykDu63DH2km2371jxYvNRyPoz+IgupyT4uuSz1BX",
	"hB7Xbh6hy7+wySaaHjUcAW91m4+B5X6znyu+flfqukBwLWqC/Ofn9TKXEMEY4Xr1QiX1vDzohun1XGB3",
	"1vs3O/VohaKFbo2D1q8BM/bb/f8HAAD///GYoPJLBgIA",
}

// GetSwagger returns the content of the embedded swagger specification file
// or error if failed to decode
func decodeSpec() ([]byte, error) {
	zipped, err := base64.StdEncoding.DecodeString(strings.Join(swaggerSpec, ""))
	if err != nil {
		return nil, fmt.Errorf("error base64 decoding spec: %w", err)
	}
	zr, err := gzip.NewReader(bytes.NewReader(zipped))
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}
	var buf bytes.Buffer
	_, err = buf.ReadFrom(zr)
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}

	return buf.Bytes(), nil
}

var rawSpec = decodeSpecCached()

// a naive cached of a decoded swagger spec
func decodeSpecCached() func() ([]byte, error) {
	data, err := decodeSpec()
	return func() ([]byte, error) {
		return data, err
	}
}

// Constructs a synthetic filesystem for resolving external references when loading openapi specifications.
func PathToRawSpec(pathToFile string) map[string]func() ([]byte, error) {
	res := make(map[string]func() ([]byte, error))
	if len(pathToFile) > 0 {
		res[pathToFile] = rawSpec
	}

	return res
}

// GetSwagger returns the Swagger specification corresponding to the generated code
// in this file. The external references of Swagger specification are resolved.
// The logic of resolving external references is tightly connected to "import-mapping" feature.
// Externally referenced files must be embedded in the corresponding golang packages.
// Urls can be supported but this task was out of the scope.
func GetSwagger() (swagger *openapi3.T, err error) {
	resolvePath := PathToRawSpec("")

	loader := openapi3.NewLoader()
	loader.IsExternalRefsAllowed = true
	loader.ReadFromURIFunc = func(loader *openapi3.Loader, url *url.URL) ([]byte, error) {
		pathToFile := url.String()
		pathToFile = path.Clean(pathToFile)
		getSpec, ok := resolvePath[pathToFile]
		if !ok {
			err1 := fmt.Errorf("path not found: %s", pathToFile)
			return nil, err1
		}
		return getSpec()
	}
	var specData []byte
	specData, err = rawSpec()
	if err != nil {
		return
	}
	swagger, err = loader.LoadFromData(specData)
	if err != nil {
		return
	}
	return
}
