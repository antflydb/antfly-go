// Package oapi provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/oapi-codegen/oapi-codegen/v2 version v2.5.1 DO NOT EDIT.
package oapi

import (
	"bytes"
	"compress/gzip"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"path"
	"strings"
	"time"

	"github.com/getkin/kin-openapi/openapi3"
	"github.com/oapi-codegen/runtime"
)

const (
	BasicAuthScopes = "BasicAuth.Scopes"
)

// Defines values for AntflyType.
const (
	AntflyTypeBlob            AntflyType = "blob"
	AntflyTypeBoolean         AntflyType = "boolean"
	AntflyTypeDatetime        AntflyType = "datetime"
	AntflyTypeEmbedding       AntflyType = "embedding"
	AntflyTypeGeopoint        AntflyType = "geopoint"
	AntflyTypeGeoshape        AntflyType = "geoshape"
	AntflyTypeHtml            AntflyType = "html"
	AntflyTypeKeyword         AntflyType = "keyword"
	AntflyTypeLink            AntflyType = "link"
	AntflyTypeNumeric         AntflyType = "numeric"
	AntflyTypeSearchAsYouType AntflyType = "search_as_you_type"
	AntflyTypeText            AntflyType = "text"
)

// Defines values for BingSearchConfigFreshness.
const (
	BingSearchConfigFreshnessDay   BingSearchConfigFreshness = "Day"
	BingSearchConfigFreshnessMonth BingSearchConfigFreshness = "Month"
	BingSearchConfigFreshnessWeek  BingSearchConfigFreshness = "Week"
)

// Defines values for BraveSearchConfigFreshness.
const (
	BraveSearchConfigFreshnessPd BraveSearchConfigFreshness = "pd"
	BraveSearchConfigFreshnessPm BraveSearchConfigFreshness = "pm"
	BraveSearchConfigFreshnessPw BraveSearchConfigFreshness = "pw"
	BraveSearchConfigFreshnessPy BraveSearchConfigFreshness = "py"
)

// Defines values for ChainCondition.
const (
	ChainConditionAlways      ChainCondition = "always"
	ChainConditionOnError     ChainCondition = "on_error"
	ChainConditionOnRateLimit ChainCondition = "on_rate_limit"
	ChainConditionOnTimeout   ChainCondition = "on_timeout"
)

// Defines values for ChatMessageRole.
const (
	ChatMessageRoleAssistant ChatMessageRole = "assistant"
	ChatMessageRoleSystem    ChatMessageRole = "system"
	ChatMessageRoleTool      ChatMessageRole = "tool"
	ChatMessageRoleUser      ChatMessageRole = "user"
)

// Defines values for ChatToolName.
const (
	ChatToolNameAddFilter        ChatToolName = "add_filter"
	ChatToolNameAskClarification ChatToolName = "ask_clarification"
	ChatToolNameFetch            ChatToolName = "fetch"
	ChatToolNameSearch           ChatToolName = "search"
	ChatToolNameWebsearch        ChatToolName = "websearch"
)

// Defines values for ChunkerProvider.
const (
	ChunkerProviderAntfly  ChunkerProvider = "antfly"
	ChunkerProviderMock    ChunkerProvider = "mock"
	ChunkerProviderTermite ChunkerProvider = "termite"
)

// Defines values for ClusterBackupResponseStatus.
const (
	ClusterBackupResponseStatusCompleted ClusterBackupResponseStatus = "completed"
	ClusterBackupResponseStatusFailed    ClusterBackupResponseStatus = "failed"
	ClusterBackupResponseStatusPartial   ClusterBackupResponseStatus = "partial"
)

// Defines values for ClusterHealth.
const (
	ClusterHealthDegraded  ClusterHealth = "degraded"
	ClusterHealthError     ClusterHealth = "error"
	ClusterHealthHealthy   ClusterHealth = "healthy"
	ClusterHealthUnhealthy ClusterHealth = "unhealthy"
	ClusterHealthUnknown   ClusterHealth = "unknown"
)

// Defines values for ClusterRestoreRequestRestoreMode.
const (
	ClusterRestoreRequestRestoreModeFailIfExists ClusterRestoreRequestRestoreMode = "fail_if_exists"
	ClusterRestoreRequestRestoreModeOverwrite    ClusterRestoreRequestRestoreMode = "overwrite"
	ClusterRestoreRequestRestoreModeSkipIfExists ClusterRestoreRequestRestoreMode = "skip_if_exists"
)

// Defines values for ClusterRestoreResponseStatus.
const (
	ClusterRestoreResponseStatusFailed    ClusterRestoreResponseStatus = "failed"
	ClusterRestoreResponseStatusPartial   ClusterRestoreResponseStatus = "partial"
	ClusterRestoreResponseStatusTriggered ClusterRestoreResponseStatus = "triggered"
)

// Defines values for CohereEmbedderConfigInputType.
const (
	CohereEmbedderConfigInputTypeClassification CohereEmbedderConfigInputType = "classification"
	CohereEmbedderConfigInputTypeClustering     CohereEmbedderConfigInputType = "clustering"
	CohereEmbedderConfigInputTypeSearchDocument CohereEmbedderConfigInputType = "search_document"
	CohereEmbedderConfigInputTypeSearchQuery    CohereEmbedderConfigInputType = "search_query"
)

// Defines values for CohereEmbedderConfigTruncate.
const (
	CohereEmbedderConfigTruncateEND   CohereEmbedderConfigTruncate = "END"
	CohereEmbedderConfigTruncateNONE  CohereEmbedderConfigTruncate = "NONE"
	CohereEmbedderConfigTruncateSTART CohereEmbedderConfigTruncate = "START"
)

// Defines values for EdgeDirection.
const (
	EdgeDirectionBoth EdgeDirection = "both"
	EdgeDirectionIn   EdgeDirection = "in"
	EdgeDirectionOut  EdgeDirection = "out"
)

// Defines values for EmbedderProvider.
const (
	EmbedderProviderBedrock EmbedderProvider = "bedrock"
	EmbedderProviderCohere  EmbedderProvider = "cohere"
	EmbedderProviderGemini  EmbedderProvider = "gemini"
	EmbedderProviderMock    EmbedderProvider = "mock"
	EmbedderProviderOllama  EmbedderProvider = "ollama"
	EmbedderProviderOpenai  EmbedderProvider = "openai"
	EmbedderProviderVertex  EmbedderProvider = "vertex"
)

// Defines values for EvaluatorName.
const (
	EvaluatorNameCitationQuality EvaluatorName = "citation_quality"
	EvaluatorNameCoherence       EvaluatorName = "coherence"
	EvaluatorNameCompleteness    EvaluatorName = "completeness"
	EvaluatorNameCorrectness     EvaluatorName = "correctness"
	EvaluatorNameFaithfulness    EvaluatorName = "faithfulness"
	EvaluatorNameHelpfulness     EvaluatorName = "helpfulness"
	EvaluatorNameMap             EvaluatorName = "map"
	EvaluatorNameMrr             EvaluatorName = "mrr"
	EvaluatorNameNdcg            EvaluatorName = "ndcg"
	EvaluatorNamePrecision       EvaluatorName = "precision"
	EvaluatorNameRecall          EvaluatorName = "recall"
	EvaluatorNameRelevance       EvaluatorName = "relevance"
	EvaluatorNameSafety          EvaluatorName = "safety"
)

// Defines values for FailedOperationOperation.
const (
	FailedOperationOperationDelete FailedOperationOperation = "delete"
	FailedOperationOperationUpsert FailedOperationOperation = "upsert"
)

// Defines values for FilterSpecOperator.
const (
	FilterSpecOperatorContains FilterSpecOperator = "contains"
	FilterSpecOperatorEq       FilterSpecOperator = "eq"
	FilterSpecOperatorGt       FilterSpecOperator = "gt"
	FilterSpecOperatorGte      FilterSpecOperator = "gte"
	FilterSpecOperatorIn       FilterSpecOperator = "in"
	FilterSpecOperatorLt       FilterSpecOperator = "lt"
	FilterSpecOperatorLte      FilterSpecOperator = "lte"
	FilterSpecOperatorNe       FilterSpecOperator = "ne"
	FilterSpecOperatorPrefix   FilterSpecOperator = "prefix"
	FilterSpecOperatorRange    FilterSpecOperator = "range"
)

// Defines values for Fuzziness1.
const (
	Fuzziness1Auto Fuzziness1 = "auto"
)

// Defines values for GeneratorProvider.
const (
	GeneratorProviderAnthropic GeneratorProvider = "anthropic"
	GeneratorProviderBedrock   GeneratorProvider = "bedrock"
	GeneratorProviderCohere    GeneratorProvider = "cohere"
	GeneratorProviderGemini    GeneratorProvider = "gemini"
	GeneratorProviderMock      GeneratorProvider = "mock"
	GeneratorProviderOllama    GeneratorProvider = "ollama"
	GeneratorProviderOpenai    GeneratorProvider = "openai"
	GeneratorProviderVertex    GeneratorProvider = "vertex"
)

// Defines values for GeoShapeGeometryRelation.
const (
	GeoShapeGeometryRelationContains   GeoShapeGeometryRelation = "contains"
	GeoShapeGeometryRelationIntersects GeoShapeGeometryRelation = "intersects"
	GeoShapeGeometryRelationWithin     GeoShapeGeometryRelation = "within"
)

// Defines values for GoogleSearchConfigSearchType.
const (
	GoogleSearchConfigSearchTypeImage GoogleSearchConfigSearchType = "image"
	GoogleSearchConfigSearchTypeWeb   GoogleSearchConfigSearchType = "web"
)

// Defines values for GraphQueryType.
const (
	GraphQueryTypeKShortestPaths GraphQueryType = "k_shortest_paths"
	GraphQueryTypeNeighbors      GraphQueryType = "neighbors"
	GraphQueryTypePattern        GraphQueryType = "pattern"
	GraphQueryTypeShortestPath   GraphQueryType = "shortest_path"
	GraphQueryTypeTraverse       GraphQueryType = "traverse"
)

// Defines values for IndexType.
const (
	IndexTypeAknnV0     IndexType = "aknn_v0"
	IndexTypeFullTextV0 IndexType = "full_text_v0"
	IndexTypeGraphV0    IndexType = "graph_v0"
)

// Defines values for LinearMergePageStatus.
const (
	LinearMergePageStatusError   LinearMergePageStatus = "error"
	LinearMergePageStatusPartial LinearMergePageStatus = "partial"
	LinearMergePageStatusSuccess LinearMergePageStatus = "success"
)

// Defines values for MatchQueryOperator.
const (
	MatchQueryOperatorAnd MatchQueryOperator = "and"
	MatchQueryOperatorOr  MatchQueryOperator = "or"
)

// Defines values for MergeStrategy.
const (
	MergeStrategyFailover MergeStrategy = "failover"
	MergeStrategyRrf      MergeStrategy = "rrf"
	MergeStrategyRsf      MergeStrategy = "rsf"
)

// Defines values for PathFindWeightMode.
const (
	PathFindWeightModeMaxWeight PathFindWeightMode = "max_weight"
	PathFindWeightModeMinHops   PathFindWeightMode = "min_hops"
	PathFindWeightModeMinWeight PathFindWeightMode = "min_weight"
)

// Defines values for PathWeightMode.
const (
	PathWeightModeMaxWeight PathWeightMode = "max_weight"
	PathWeightModeMinHops   PathWeightMode = "min_hops"
	PathWeightModeMinWeight PathWeightMode = "min_weight"
)

// Defines values for PermissionType.
const (
	PermissionTypeAdmin PermissionType = "admin"
	PermissionTypeRead  PermissionType = "read"
	PermissionTypeWrite PermissionType = "write"
)

// Defines values for QueryRequestExpandStrategy.
const (
	QueryRequestExpandStrategyIntersection QueryRequestExpandStrategy = "intersection"
	QueryRequestExpandStrategyUnion        QueryRequestExpandStrategy = "union"
)

// Defines values for QueryStrategy.
const (
	QueryStrategyDecompose QueryStrategy = "decompose"
	QueryStrategyHyde      QueryStrategy = "hyde"
	QueryStrategySimple    QueryStrategy = "simple"
	QueryStrategyStepBack  QueryStrategy = "step_back"
)

// Defines values for RerankerProvider.
const (
	RerankerProviderCohere  RerankerProvider = "cohere"
	RerankerProviderOllama  RerankerProvider = "ollama"
	RerankerProviderTermite RerankerProvider = "termite"
	RerankerProviderVertex  RerankerProvider = "vertex"
)

// Defines values for ResourceType.
const (
	ResourceTypeAsterisk ResourceType = "*"
	ResourceTypeTable    ResourceType = "table"
	ResourceTypeUser     ResourceType = "user"
)

// Defines values for RouteType.
const (
	RouteTypeQuestion RouteType = "question"
	RouteTypeSearch   RouteType = "search"
)

// Defines values for SemanticQueryMode.
const (
	SemanticQueryModeHypothetical SemanticQueryMode = "hypothetical"
	SemanticQueryModeRewrite      SemanticQueryMode = "rewrite"
)

// Defines values for SerperSearchConfigSearchType.
const (
	SerperSearchConfigSearchTypeImages   SerperSearchConfigSearchType = "images"
	SerperSearchConfigSearchTypeNews     SerperSearchConfigSearchType = "news"
	SerperSearchConfigSearchTypePlaces   SerperSearchConfigSearchType = "places"
	SerperSearchConfigSearchTypeSearch   SerperSearchConfigSearchType = "search"
	SerperSearchConfigSearchTypeShopping SerperSearchConfigSearchType = "shopping"
)

// Defines values for SerperSearchConfigTimePeriod.
const (
	SerperSearchConfigTimePeriodD SerperSearchConfigTimePeriod = "d"
	SerperSearchConfigTimePeriodM SerperSearchConfigTimePeriod = "m"
	SerperSearchConfigTimePeriodW SerperSearchConfigTimePeriod = "w"
	SerperSearchConfigTimePeriodY SerperSearchConfigTimePeriod = "y"
)

// Defines values for SyncLevel.
const (
	SyncLevelAknn        SyncLevel = "aknn"
	SyncLevelEnrichments SyncLevel = "enrichments"
	SyncLevelFullText    SyncLevel = "full_text"
	SyncLevelPropose     SyncLevel = "propose"
	SyncLevelWrite       SyncLevel = "write"
)

// Defines values for TableBackupStatusStatus.
const (
	TableBackupStatusStatusCompleted TableBackupStatusStatus = "completed"
	TableBackupStatusStatusFailed    TableBackupStatusStatus = "failed"
	TableBackupStatusStatusSkipped   TableBackupStatusStatus = "skipped"
)

// Defines values for TableRestoreStatusStatus.
const (
	TableRestoreStatusStatusFailed    TableRestoreStatusStatus = "failed"
	TableRestoreStatusStatusSkipped   TableRestoreStatusStatus = "skipped"
	TableRestoreStatusStatusTriggered TableRestoreStatusStatus = "triggered"
)

// Defines values for TavilySearchConfigSearchDepth.
const (
	TavilySearchConfigSearchDepthAdvanced TavilySearchConfigSearchDepth = "advanced"
	TavilySearchConfigSearchDepthBasic    TavilySearchConfigSearchDepth = "basic"
)

// Defines values for TransformOpType.
const (
	TransformOpTypeAddToSet    TransformOpType = "$addToSet"
	TransformOpTypeCurrentDate TransformOpType = "$currentDate"
	TransformOpTypeInc         TransformOpType = "$inc"
	TransformOpTypeMax         TransformOpType = "$max"
	TransformOpTypeMin         TransformOpType = "$min"
	TransformOpTypeMul         TransformOpType = "$mul"
	TransformOpTypePop         TransformOpType = "$pop"
	TransformOpTypePull        TransformOpType = "$pull"
	TransformOpTypePush        TransformOpType = "$push"
	TransformOpTypeRename      TransformOpType = "$rename"
	TransformOpTypeSet         TransformOpType = "$set"
	TransformOpTypeUnset       TransformOpType = "$unset"
)

// Defines values for WebSearchProvider.
const (
	WebSearchProviderBing       WebSearchProvider = "bing"
	WebSearchProviderBrave      WebSearchProvider = "brave"
	WebSearchProviderDuckduckgo WebSearchProvider = "duckduckgo"
	WebSearchProviderGoogle     WebSearchProvider = "google"
	WebSearchProviderSerper     WebSearchProvider = "serper"
	WebSearchProviderTavily     WebSearchProvider = "tavily"
)

// Analyses defines model for Analyses.
type Analyses struct {
	Pca  bool `json:"pca,omitempty,omitzero"`
	Tsne bool `json:"tsne,omitempty,omitzero"`
}

// AnalysesResult defines model for AnalysesResult.
type AnalysesResult struct {
	Pca  []float64 `json:"pca,omitempty,omitzero"`
	Tsne []float64 `json:"tsne,omitempty,omitzero"`
}

// AnswerAgentRequest defines model for AnswerAgentRequest.
type AnswerAgentRequest struct {
	// AgentKnowledge Background knowledge that guides the agent's understanding of the domain.
	// Similar to CLAUDE.md, this provides context that applies to all steps
	// (classification, retrieval, and answer generation).
	//
	// Examples:
	// - "This data contains medical records. Use clinical terminology and be precise about diagnoses."
	// - "This is a software engineering knowledge base. Assume a technical audience."
	// - "This table stores legal documents. Reference laws and regulations accurately."
	AgentKnowledge string `json:"agent_knowledge,omitempty,omitzero"`

	// Chain Default chain of generators for all pipeline steps unless overridden in `steps`.
	// Each link can specify retry configuration and a condition for trying the next generator.
	// Mutually exclusive with 'generator'. Either 'generator' or 'chain' must be provided.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Eval Configuration for inline evaluation of query results.
	// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
	Eval EvalConfig `json:"eval,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// MaxContextTokens Maximum total tokens allowed for retrieved document context.
	// When set, documents are pruned (lowest-ranked first) to fit within this budget.
	// Useful for ensuring LLM context limits are not exceeded.
	// Uses BERT tokenizer for estimation.
	MaxContextTokens int `json:"max_context_tokens,omitempty,omitzero"`

	// Queries Array of query requests to execute. The query text will be transformed for semantic search
	// and populated into the semantic_search field of each query.
	Queries []QueryRequest `json:"queries"`

	// Query User's natural language query to be classified and improved
	Query string `json:"query"`

	// ReserveTokens Tokens to reserve for system prompt, answer generation, and other overhead.
	// Subtracted from max_context_tokens to determine available context budget.
	// Defaults to 4000 if max_context_tokens is set.
	ReserveTokens int `json:"reserve_tokens,omitempty,omitzero"`

	// Steps Per-step configuration for the answer agent pipeline. Each step can have
	// its own generator (or chain of generators) and step-specific options.
	// If a step is not configured, it uses the top-level generator as default.
	Steps AnswerAgentSteps `json:"steps,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results (classification, queries, results, answer) instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`

	// WithoutGeneration When true, skip AI answer generation and return search results only.
	// Useful when you want search quality without LLM cost, such as for
	// quota management or rate limiting scenarios.
	WithoutGeneration bool `json:"without_generation,omitempty,omitzero"`
}

// AnswerAgentResult defines model for AnswerAgentResult.
type AnswerAgentResult struct {
	// Answer Generated answer in markdown format
	Answer string `json:"answer"`

	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0)
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// ClassificationTransformation Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
	ClassificationTransformation ClassificationTransformationResult `json:"classification_transformation,omitempty,omitzero"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance,omitempty,omitzero"`

	// EvalResult Complete evaluation result
	EvalResult EvalResult `json:"eval_result,omitempty,omitzero"`

	// FollowupQuestions Suggested follow-up questions
	FollowupQuestions []string `json:"followup_questions,omitempty,omitzero"`

	// QueryResults Results from each executed query
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`
}

// AnswerAgentSteps Per-step configuration for the answer agent pipeline. Each step can have
// its own generator (or chain of generators) and step-specific options.
// If a step is not configured, it uses the top-level generator as default.
type AnswerAgentSteps struct {
	// Answer Configuration for the answer generation step. This step generates the final
	// answer from retrieved documents using the reasoning as context.
	Answer AnswerStepConfig `json:"answer,omitempty,omitzero"`

	// Classification Configuration for the classification step. This step analyzes the query,
	// selects the optimal retrieval strategy, and generates semantic transformations.
	Classification ClassificationStepConfig `json:"classification,omitempty,omitzero"`

	// Confidence Configuration for confidence assessment. Evaluates answer quality and
	// resource relevance. Can use a model calibrated for scoring tasks.
	Confidence ConfidenceStepConfig `json:"confidence,omitempty,omitzero"`

	// Followup Configuration for generating follow-up questions. Uses a separate generator
	// call which can use a cheaper/faster model.
	Followup FollowupStepConfig `json:"followup,omitempty,omitzero"`
}

// AnswerConfidence Confidence assessment for the generated answer
type AnswerConfidence struct {
	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0). Considers both ability to answer from provided resources and general knowledge.
	AnswerConfidence float32 `json:"answer_confidence"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance"`
}

// AnswerResult Result from answer generation with optional confidence and follow-up questions
type AnswerResult struct {
	// Answer Generated answer in markdown format
	Answer string `json:"answer"`

	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0)
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance,omitempty,omitzero"`

	// FollowupQuestions Suggested follow-up questions
	FollowupQuestions []string `json:"followup_questions,omitempty,omitzero"`
}

// AnswerStepConfig Configuration for the answer generation step. This step generates the final
// answer from retrieved documents using the reasoning as context.
type AnswerStepConfig struct {
	// AnswerContext Custom guidance for answer tone, detail level, and style
	AnswerContext string `json:"answer_context,omitempty,omitzero"`

	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// SystemPrompt Custom system prompt for answer generation
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`
}

// AntflyChunkerConfig defines model for AntflyChunkerConfig.
type AntflyChunkerConfig struct {
	// FullText Configuration for full-text indexing of chunks in Bleve.
	// When present (even if empty), chunks will be stored with :cft: suffix and indexed in Bleve's _chunks field.
	// When absent, chunks use :c: suffix and are only used for vector embeddings.
	// This object is reserved for future options like boosting, field mapping, etc.
	FullText map[string]interface{} `json:"full_text,omitempty,omitzero"`

	// MaxChunks Maximum number of chunks to generate per document.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries. Only used by fixed-size chunkers.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs). Only used by fixed-size chunkers.
	Separator string `json:"separator,omitempty,omitzero"`

	// TargetTokens Target number of tokens per chunk.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`

	// Threshold Minimum confidence threshold for separator detection (0.0-1.0). Only used by ONNX models.
	Threshold float32 `json:"threshold,omitempty,omitzero"`
}

// AntflyType defines model for AntflyType.
type AntflyType string

// AnthropicGeneratorConfig Configuration for the Anthropic generative AI provider (Claude models).
//
// API key via `api_key` field or `ANTHROPIC_API_KEY` environment variable.
//
// **Example Models:** claude-sonnet-4-5-20250929 (default), claude-opus-4-5-20251101, claude-3-5-haiku-20241022
//
// **Docs:** https://docs.anthropic.com/en/docs/about-claude/models/overview
type AnthropicGeneratorConfig struct {
	// ApiKey The Anthropic API key. If not provided, falls back to ANTHROPIC_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The full model ID of the Anthropic model to use (e.g., 'claude-sonnet-4-5-20250929', 'claude-opus-4-5-20251101').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-1.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Anthropic API endpoint (optional, uses default if not specified).
	Url string `json:"url,omitempty,omitzero"`
}

// BackupInfo defines model for BackupInfo.
type BackupInfo struct {
	// AntflyVersion Antfly version that created the backup
	AntflyVersion string `json:"antfly_version,omitempty,omitzero"`

	// BackupId The backup identifier
	BackupId string `json:"backup_id"`

	// Location Storage location of the backup
	Location string `json:"location"`

	// Tables Tables included in the backup
	Tables []string `json:"tables"`

	// Timestamp When the backup was created
	Timestamp time.Time `json:"timestamp"`
}

// BackupListResponse defines model for BackupListResponse.
type BackupListResponse struct {
	// Backups List of available backups
	Backups []BackupInfo `json:"backups"`
}

// BackupRequest defines model for BackupRequest.
type BackupRequest struct {
	// BackupId Unique identifier for this backup. Used to reference the backup for restore operations.
	// Choose a meaningful name that includes date/version information.
	BackupId string `json:"backup_id"`

	// Location Storage location for the backup. Supports multiple backends:
	// - Local filesystem: `file:///path/to/backup`
	// - Amazon S3: `s3://bucket-name/path/to/backup`
	//
	// The backup includes all table data, indexes, and metadata for the specified table.
	Location string `json:"location"`
}

// BatchRequest Batch insert, delete, and transform operations in a single request.
//
// **Atomicity**:
// - **Single shard**: Operations are atomic within shard boundaries
// - **Multiple shards**: Uses distributed 2-phase commit (2PC) for atomic cross-shard writes
//
// **How distributed transactions work**:
// 1. Metadata server allocates HLC timestamp and selects coordinator shard
// 2. Coordinator writes transaction record, participants write intents
// 3. After all intents succeed, coordinator commits transaction
// 4. Participants are notified asynchronously to resolve intents
// 5. Recovery loop ensures notifications complete even after coordinator failure
//
// **Performance**:
// - Single-shard batches: < 5ms latency
// - Cross-shard transactions: ~20ms latency
// - Intent resolution: < 30 seconds worst-case (via recovery loop)
//
// **Guarantees**:
// - All writes succeed or all fail (atomicity across all shards)
// - Coordinator failure is recoverable (new leader resumes notifications)
// - Idempotent resolution (duplicate notifications are safe)
//
// **Benefits**:
// - Reduces network overhead compared to individual requests
// - More efficient indexing (updates are batched)
// - Automatic distributed transactions when operations span shards
//
// The inserts are upserts - existing keys are overwritten, new keys are created.
type BatchRequest struct {
	// Deletes Array of document IDs to delete. Documents are removed from all indexes.
	//
	// Notes:
	// - Non-existent keys are silently ignored
	// - Deletions are processed before inserts in the same batch
	// - Keys are permanently removed from storage and indexes
	Deletes []string `json:"deletes,omitempty,omitzero"`

	// Inserts Map of document IDs to document objects. Each key is the unique identifier for the document.
	//
	// Best practices:
	// - Use consistent key naming schemes (e.g., "user:123", "article:456")
	// - Key length affects storage and performance - keep them reasonably short
	// - Keys are sorted lexicographically, so choose prefixes that support range scans
	Inserts map[string]map[string]interface{} `json:"inserts,omitempty,omitzero"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write
	// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`

	// Transforms Array of transform operations for in-place document updates using MongoDB-style operators.
	//
	// Transform operations allow you to modify documents without read-modify-write races:
	// - Operations are applied atomically on the server
	// - Multiple operations per document are applied in sequence
	// - Supports numeric operations ($inc, $mul), array operations ($push, $pull), and more
	//
	// Common use cases:
	// - Increment counters (views, likes, votes)
	// - Update timestamps ($currentDate)
	// - Manage arrays (add/remove tags, items)
	// - Update nested fields without overwriting the entire document
	Transforms []Transform `json:"transforms,omitempty,omitzero"`
}

// BedrockEmbedderConfig Configuration for the AWS Bedrock embedding provider.
//
// Uses AWS credentials from environment or IAM roles.
//
// **Example Models:** cohere.embed-english-v4, amazon.titan-embed-text-v2:0
//
// **Docs:** https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html
type BedrockEmbedderConfig struct {
	// BatchSize The batch size for embedding requests to optimize throughput.
	BatchSize int `json:"batch_size,omitempty,omitzero"`

	// Model The Bedrock model ID to use (e.g., 'cohere.embed-english-v4', 'amazon.titan-embed-text-v2:0').
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service (e.g., 'us-east-1').
	Region string `json:"region,omitempty,omitzero"`

	// StripNewLines Whether to strip new lines from the input text before embedding.
	StripNewLines bool `json:"strip_new_lines,omitempty,omitzero"`
}

// BedrockGeneratorConfig Configuration for the AWS Bedrock generative AI provider.
//
// Provides access to models from Anthropic, Meta, Amazon, Cohere, Mistral, and others.
//
// **Example Models:** anthropic.claude-sonnet-4-5-20250929-v1:0, meta.llama3-3-70b-instruct-v1:0, amazon.nova-pro-v1:0
//
// **Docs:** https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html
type BedrockGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The Bedrock model ID to use (e.g., 'anthropic.claude-sonnet-4-5-20250929-v1:0').
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service.
	Region string `json:"region,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-1.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// BingSearchConfig defines model for BingSearchConfig.
type BingSearchConfig struct {
	// ApiKey Bing Search API key (or set BING_SEARCH_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Endpoint Bing API endpoint URL
	Endpoint string `json:"endpoint,omitempty,omitzero"`

	// Freshness Filter results by freshness
	Freshness BingSearchConfigFreshness `json:"freshness,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// BingSearchConfigFreshness Filter results by freshness
type BingSearchConfigFreshness string

// BleveIndexV2Config defines model for BleveIndexV2Config.
type BleveIndexV2Config struct {
	// MemOnly Whether to use memory-only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`
}

// BleveIndexV2Stats defines model for BleveIndexV2Stats.
type BleveIndexV2Stats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// Rebuilding Whether the index is currently rebuilding
	Rebuilding bool `json:"rebuilding,omitempty,omitzero"`

	// TotalIndexed Number of documents in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`
}

// BoolFieldQuery defines model for BoolFieldQuery.
type BoolFieldQuery struct {
	Bool bool `json:"bool"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
}

// BooleanQuery defines model for BooleanQuery.
type BooleanQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost   Boost            `json:"boost,omitzero"`
	Filter  Query            `json:"filter,omitempty,omitzero"`
	Must    ConjunctionQuery `json:"must,omitempty,omitzero"`
	MustNot DisjunctionQuery `json:"must_not,omitempty,omitzero"`
	Should  DisjunctionQuery `json:"should,omitempty,omitzero"`
}

// Boost A floating-point number used to decrease or increase the relevance scores of a query.
type Boost = float64

// BraveSearchConfig defines model for BraveSearchConfig.
type BraveSearchConfig struct {
	// ApiKey Brave Search API key (or set BRAVE_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Freshness Freshness filter: pd=day, pw=week, pm=month, py=year
	Freshness BraveSearchConfigFreshness `json:"freshness,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// Spellcheck Enable spellcheck suggestions
	Spellcheck bool `json:"spellcheck,omitempty,omitzero"`

	// TextDecorations Include text decorations (bold, italic markers)
	TextDecorations bool `json:"text_decorations,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// BraveSearchConfigFreshness Freshness filter: pd=day, pw=week, pm=month, py=year
type BraveSearchConfigFreshness string

// ByteRange defines model for ByteRange.
type ByteRange = [][]byte

// ChainCondition Condition for trying the next generator in chain:
// - always: Always try next regardless of outcome
// - on_error: Try next on any error (default)
// - on_timeout: Try next only on timeout errors
// - on_rate_limit: Try next only on rate limit errors
type ChainCondition string

// ChainLink A single link in a generator chain with optional retry and condition
type ChainLink struct {
	// Condition Condition for trying the next generator in chain:
	// - always: Always try next regardless of outcome
	// - on_error: Try next on any error (default)
	// - on_timeout: Try next only on timeout errors
	// - on_rate_limit: Try next only on rate limit errors
	Condition ChainCondition `json:"condition,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator"`

	// Retry Retry configuration for generator calls
	Retry RetryConfig `json:"retry,omitempty,omitzero"`
}

// ChatAgentRequest defines model for ChatAgentRequest.
type ChatAgentRequest struct {
	// AccumulatedFilters Filters accumulated from previous conversation turns.
	// These are applied to all queries automatically.
	// New filters discovered in this turn will be added to this list in the response.
	AccumulatedFilters []FilterSpec `json:"accumulated_filters,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator"`

	// MaxContextTokens Maximum tokens for retrieved document context
	MaxContextTokens int `json:"max_context_tokens,omitempty,omitzero"`

	// Messages Conversation history. Include all previous messages to maintain context.
	// The last message should typically be from the user.
	Messages []ChatMessage `json:"messages"`

	// Queries Base query configurations. The chat agent will modify these queries
	// based on conversation context, applying filters and transformations.
	Queries []QueryRequest `json:"queries"`

	// Steps Per-step configuration for the chat agent pipeline. Similar to AnswerAgentSteps
	// but includes tool-specific configuration.
	Steps ChatAgentSteps `json:"steps,omitempty,omitzero"`

	// SystemPrompt Optional custom system prompt for the chat agent.
	// If not provided, uses a default conversational RAG prompt.
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// ChatAgentResult defines model for ChatAgentResult.
type ChatAgentResult struct {
	// Answer Final answer text (if available)
	Answer string `json:"answer,omitempty,omitzero"`

	// AnswerConfidence Confidence in the answer
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// AppliedFilters Filters that have been applied in this conversation
	AppliedFilters []FilterSpec `json:"applied_filters,omitempty,omitzero"`

	// ClassificationTransformation Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
	ClassificationTransformation ClassificationTransformationResult `json:"classification_transformation,omitempty,omitzero"`

	// Messages Updated conversation history including the assistant's response
	Messages []ChatMessage `json:"messages"`

	// PendingClarification A request for clarification from the user
	PendingClarification ClarificationRequest `json:"pending_clarification,omitempty,omitzero"`

	// QueryResults Search results from executed queries
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`

	// ToolCallsMade Number of tool calls made in this turn
	ToolCallsMade int `json:"tool_calls_made,omitempty,omitzero"`
}

// ChatAgentSteps Per-step configuration for the chat agent pipeline. Similar to AnswerAgentSteps
// but includes tool-specific configuration.
type ChatAgentSteps struct {
	// Answer Configuration for the answer generation step. This step generates the final
	// answer from retrieved documents using the reasoning as context.
	Answer AnswerStepConfig `json:"answer,omitempty,omitzero"`

	// Classification Configuration for the classification step. This step analyzes the query,
	// selects the optimal retrieval strategy, and generates semantic transformations.
	Classification ClassificationStepConfig `json:"classification,omitempty,omitzero"`

	// Tools Configuration for chat agent tools.
	//
	// If `enabled_tools` is empty/omitted, defaults to: add_filter, ask_clarification, search.
	//
	// For models that don't support native tool calling (e.g., Ollama),
	// a prompt-based fallback is used with structured output parsing.
	Tools ChatToolsConfig `json:"tools,omitempty,omitzero"`
}

// ChatMessage A message in the conversation history
type ChatMessage struct {
	// Content Text content of the message
	Content string `json:"content"`

	// Role Role of the message sender in the conversation
	Role ChatMessageRole `json:"role"`

	// ToolCalls Tool calls made by the assistant (only for assistant role)
	ToolCalls []ChatToolCall `json:"tool_calls,omitempty,omitzero"`

	// ToolResults Results from tool executions (only for tool role)
	ToolResults []ChatToolResult `json:"tool_results,omitempty,omitzero"`
}

// ChatMessageRole Role of the message sender in the conversation
type ChatMessageRole string

// ChatToolCall A tool call made by the assistant
type ChatToolCall struct {
	// Arguments Arguments passed to the tool as key-value pairs
	Arguments map[string]interface{} `json:"arguments"`

	// Id Unique identifier for this tool call
	Id string `json:"id"`

	// Name Name of the tool being called
	Name string `json:"name"`
}

// ChatToolName Available tool names for the chat agent.
// - add_filter: Add search filters (field constraints)
// - ask_clarification: Ask user for clarification
// - search: Execute semantic searches
// - websearch: Search the web (requires websearch_config)
// - fetch: Fetch URL content (subject to security controls)
type ChatToolName string

// ChatToolResult Result from executing a tool call
type ChatToolResult struct {
	// Error Error message if tool execution failed
	Error string `json:"error,omitempty,omitzero"`

	// Result Result data from the tool execution
	Result map[string]interface{} `json:"result"`

	// ToolCallId ID of the tool call this result corresponds to
	ToolCallId string `json:"tool_call_id"`
}

// ChatToolsConfig Configuration for chat agent tools.
//
// If `enabled_tools` is empty/omitted, defaults to: add_filter, ask_clarification, search.
//
// For models that don't support native tool calling (e.g., Ollama),
// a prompt-based fallback is used with structured output parsing.
type ChatToolsConfig struct {
	// EnabledTools List of tools to enable. If empty, defaults to filter, clarification, and search.
	EnabledTools []ChatToolName `json:"enabled_tools,omitempty,omitzero"`

	// FetchConfig Configuration for URL content fetching.
	//
	// Uses lib/scraping for downloading and processing. Supports:
	// - HTTP/HTTPS URLs with security validation
	// - HTML pages (extracts readable text via go-readability)
	// - PDF files (extracts text)
	// - Images (returns as data URIs)
	// - Plain text files
	// - S3 URLs (requires s3_credentials)
	//
	// Security features (from lib/scraping.ContentSecurityConfig):
	// - Allowed host whitelist
	// - Private IP blocking (SSRF prevention)
	// - Download size limits
	// - Timeout controls
	FetchConfig FetchConfig `json:"fetch_config,omitempty,omitzero"`

	// MaxToolIterations Maximum number of tool call iterations per turn.
	// Prevents infinite loops in tool execution.
	MaxToolIterations int `json:"max_tool_iterations,omitempty,omitzero"`

	// WebsearchConfig A unified configuration for web search providers.
	//
	// Each provider has specific configuration requirements. Use the appropriate
	// provider-specific config or set common options at the top level.
	//
	// **Environment Variables (fallbacks):**
	// - GOOGLE_CSE_API_KEY, GOOGLE_CSE_ID
	// - BING_SEARCH_API_KEY
	// - SERPER_API_KEY
	// - TAVILY_API_KEY
	// - BRAVE_API_KEY
	WebsearchConfig WebSearchConfig `json:"websearch_config,omitempty,omitzero"`
}

// ChunkOptions Per-request configuration for chunking. All fields are optional - zero/omitted values use chunker defaults.
type ChunkOptions struct {
	// MaxChunks Maximum number of chunks to generate per document.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries. Only used by fixed-size chunkers.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs). Only used by fixed-size chunkers.
	Separator string `json:"separator,omitempty,omitzero"`

	// TargetTokens Target number of tokens per chunk.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`

	// Threshold Minimum confidence threshold for separator detection (0.0-1.0). Only used by ONNX models.
	Threshold float32 `json:"threshold,omitempty,omitzero"`
}

// ChunkerConfig defines model for ChunkerConfig.
type ChunkerConfig struct {
	// Provider The chunking provider to use.
	Provider ChunkerProvider `json:"provider"`
	union    json.RawMessage
}

// ChunkerProvider The chunking provider to use.
type ChunkerProvider string

// ClarificationRequest A request for clarification from the user
type ClarificationRequest struct {
	// Options Optional list of suggested answers for the user to choose from
	Options []string `json:"options,omitempty,omitzero"`

	// Question The clarifying question to ask the user
	Question string `json:"question"`

	// Required Whether the clarification is required before proceeding
	Required bool `json:"required,omitempty,omitzero"`
}

// ClassificationStepConfig Configuration for the classification step. This step analyzes the query,
// selects the optimal retrieval strategy, and generates semantic transformations.
type ClassificationStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// ForceSemanticMode Mode for semantic query generation:
	// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
	// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
	ForceSemanticMode SemanticQueryMode `json:"force_semantic_mode,omitempty,omitzero"`

	// ForceStrategy Strategy for query transformation and retrieval:
	// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
	// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
	// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
	// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
	ForceStrategy QueryStrategy `json:"force_strategy,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// MultiPhraseCount Number of alternative query phrasings to generate
	MultiPhraseCount int `json:"multi_phrase_count,omitempty,omitzero"`

	// WithReasoning Include pre-retrieval reasoning explaining query analysis and strategy selection
	WithReasoning bool `json:"with_reasoning,omitempty,omitzero"`
}

// ClassificationTransformationResult Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
type ClassificationTransformationResult struct {
	// Confidence Classification confidence (0.0 to 1.0)
	Confidence float32 `json:"confidence"`

	// ImprovedQuery Clarified query with added context for answer generation (human-readable)
	ImprovedQuery string `json:"improved_query"`

	// MultiPhrases Alternative phrasings of the query for expanded retrieval coverage
	MultiPhrases []string `json:"multi_phrases,omitempty,omitzero"`

	// Reasoning Pre-retrieval reasoning explaining query analysis and strategy selection (only present when with_classification_reasoning is enabled)
	Reasoning string `json:"reasoning,omitempty,omitzero"`

	// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
	RouteType RouteType `json:"route_type"`

	// SemanticMode Mode for semantic query generation:
	// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
	// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
	SemanticMode SemanticQueryMode `json:"semantic_mode"`

	// SemanticQuery Optimized query for vector/semantic search. Content style depends on semantic_mode: keywords for 'rewrite', hypothetical answer for 'hypothetical'
	SemanticQuery string `json:"semantic_query"`

	// StepBackQuery Broader background query for context (only present when strategy is 'step_back')
	StepBackQuery string `json:"step_back_query,omitempty,omitzero"`

	// Strategy Strategy for query transformation and retrieval:
	// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
	// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
	// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
	// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
	Strategy QueryStrategy `json:"strategy"`

	// SubQuestions Decomposed sub-questions (only present when strategy is 'decompose')
	SubQuestions []string `json:"sub_questions,omitempty,omitzero"`
}

// ClusterBackupRequest defines model for ClusterBackupRequest.
type ClusterBackupRequest struct {
	// BackupId Unique identifier for this backup. Used to reference the backup for restore operations.
	// Choose a meaningful name that includes date/version information.
	BackupId string `json:"backup_id"`

	// Location Storage location for the backup. Supports multiple backends:
	// - Local filesystem: `file:///path/to/backup`
	// - Amazon S3: `s3://bucket-name/path/to/backup`
	//
	// The backup includes all table data, indexes, and metadata.
	Location string `json:"location"`

	// TableNames Optional list of tables to backup. If omitted, all tables are backed up.
	TableNames []string `json:"table_names,omitempty,omitzero"`
}

// ClusterBackupResponse defines model for ClusterBackupResponse.
type ClusterBackupResponse struct {
	// BackupId The backup identifier
	BackupId string `json:"backup_id"`

	// Status Overall backup status
	Status ClusterBackupResponseStatus `json:"status"`

	// Tables Status of each table backup
	Tables []TableBackupStatus `json:"tables"`
}

// ClusterBackupResponseStatus Overall backup status
type ClusterBackupResponseStatus string

// ClusterHealth Overall health status of the cluster
type ClusterHealth string

// ClusterRestoreRequest defines model for ClusterRestoreRequest.
type ClusterRestoreRequest struct {
	// BackupId Unique identifier of the backup to restore from.
	BackupId string `json:"backup_id"`

	// Location Storage location where the backup is stored.
	Location string `json:"location"`

	// RestoreMode How to handle existing tables:
	// - `fail_if_exists`: Abort if any table already exists (default)
	// - `skip_if_exists`: Skip existing tables, restore others
	// - `overwrite`: Drop and recreate existing tables
	RestoreMode ClusterRestoreRequestRestoreMode `json:"restore_mode,omitempty,omitzero"`

	// TableNames Optional list of tables to restore. If omitted, all tables in the backup are restored.
	TableNames []string `json:"table_names,omitempty,omitzero"`
}

// ClusterRestoreRequestRestoreMode How to handle existing tables:
// - `fail_if_exists`: Abort if any table already exists (default)
// - `skip_if_exists`: Skip existing tables, restore others
// - `overwrite`: Drop and recreate existing tables
type ClusterRestoreRequestRestoreMode string

// ClusterRestoreResponse defines model for ClusterRestoreResponse.
type ClusterRestoreResponse struct {
	// Status Overall restore status
	Status ClusterRestoreResponseStatus `json:"status"`

	// Tables Status of each table restore
	Tables []TableRestoreStatus `json:"tables"`
}

// ClusterRestoreResponseStatus Overall restore status
type ClusterRestoreResponseStatus string

// ClusterStatus defines model for ClusterStatus.
type ClusterStatus struct {
	// AuthEnabled Indicates whether authentication is enabled for the cluster
	AuthEnabled bool `json:"auth_enabled,omitempty"`

	// Health Overall health status of the cluster
	Health ClusterHealth `json:"health"`

	// Message Optional message providing details about the health status
	Message              string                 `json:"message,omitempty,omitzero"`
	AdditionalProperties map[string]interface{} `json:"-"`
}

// CohereEmbedderConfig Configuration for the Cohere embedding provider.
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** embed-english-v3.0 (default, 1024 dims), embed-multilingual-v3.0
//
// **Docs:** https://docs.cohere.com/reference/embed
type CohereEmbedderConfig struct {
	// ApiKey The Cohere API key. Can also be set via COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// InputType Specifies the type of input for optimized embeddings.
	InputType CohereEmbedderConfigInputType `json:"input_type,omitempty,omitzero"`

	// Model The name of the Cohere embedding model to use.
	Model string `json:"model"`

	// Truncate How to handle inputs longer than the max token length.
	Truncate CohereEmbedderConfigTruncate `json:"truncate,omitempty,omitzero"`
}

// CohereEmbedderConfigInputType Specifies the type of input for optimized embeddings.
type CohereEmbedderConfigInputType string

// CohereEmbedderConfigTruncate How to handle inputs longer than the max token length.
type CohereEmbedderConfigTruncate string

// CohereGeneratorConfig Configuration for the Cohere generative AI provider (Command models).
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** command-r-plus (default), command-r, command-a-03-2025
//
// **Docs:** https://docs.cohere.com/reference/chat
type CohereGeneratorConfig struct {
	// ApiKey The Cohere API key. If not provided, falls back to COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (0.0-1.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Cohere model to use.
	Model string `json:"model"`

	// PresencePenalty Penalty for token presence (0.0-1.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-1.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// CohereRerankerConfig Configuration for the Cohere reranking provider.
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** rerank-english-v3.0 (default), rerank-multilingual-v3.0
//
// **Docs:** https://docs.cohere.com/reference/rerank
type CohereRerankerConfig struct {
	// ApiKey The Cohere API key. Can also be set via COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// MaxChunksPerDoc Maximum number of chunks per document for long document handling.
	MaxChunksPerDoc int `json:"max_chunks_per_doc,omitempty,omitzero"`

	// Model The name of the Cohere reranking model to use.
	Model string `json:"model"`

	// TopN Number of most relevant documents to return. If not specified, returns all documents with scores.
	TopN int `json:"top_n,omitempty,omitzero"`
}

// ConfidenceStepConfig Configuration for confidence assessment. Evaluates answer quality and
// resource relevance. Can use a model calibrated for scoring tasks.
type ConfidenceStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Context Custom guidance for confidence assessment approach
	Context string `json:"context,omitempty,omitzero"`

	// Enabled Enable confidence scoring
	Enabled bool `json:"enabled,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`
}

// ConjunctionQuery defines model for ConjunctionQuery.
type ConjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Conjuncts []Query `json:"conjuncts"`
}

// CreateTableRequest defines model for CreateTableRequest.
type CreateTableRequest struct {
	// Description Optional human-readable description of the table and its purpose.
	// Useful for documentation and team collaboration.
	Description string `json:"description,omitempty,omitzero"`

	// Indexes Map of index name to index configuration. Indexes enable different query capabilities:
	// - Full-text indexes for BM25 search
	// - Vector indexes for semantic similarity
	// - Multimodal indexes for images/audio/video
	//
	// You can add multiple indexes to support different query patterns.
	Indexes map[string]IndexConfig `json:"indexes,omitempty,omitzero"`

	// NumShards Number of shards to create for the table. Data is partitioned across shards based on key ranges.
	//
	// **Sizing Guidelines:**
	// - Small datasets (<100K docs): 1-3 shards
	// - Medium datasets (100K-1M docs): 3-10 shards
	// - Large datasets (>1M docs): 10+ shards
	//
	// More shards enable better parallelism but increase overhead. Choose based on expected data size and query patterns.
	//
	// **When to Add More Shards:**
	//
	// Antfly supports **online shard reallocation** without downtime. Add more shards when:
	// - Individual shards exceed size thresholds (configurable)
	// - Query latency increases due to large shard size
	// - Need better parallelism for write-heavy workloads
	//
	// Use the internal `/reallocate` endpoint to trigger automatic shard splitting:
	// ```bash
	// POST /_internal/v1/reallocate
	// ```
	//
	// This enqueues a reallocation request that the leader processes asynchronously, splitting
	// large shards and redistributing data without service interruption.
	//
	// **Advantages over Elasticsearch:**
	// - Automatic shard splitting (no manual reindexing required)
	// - Online operation (no downtime)
	// - Transparent to applications (keys remain accessible during reallocation)
	NumShards uint `json:"num_shards,omitempty,omitzero"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema `json:"schema,omitempty,omitzero"`
}

// CreateUserRequest defines model for CreateUserRequest.
type CreateUserRequest struct {
	// InitialPolicies Optional list of initial permissions for the user.
	InitialPolicies []Permission `json:"initial_policies,omitzero"`
	Password        string       `json:"password"`

	// Username Username for the new user. If provided in the path, this field can be omitted or must match the path parameter.
	Username string `json:"username,omitempty,omitzero"`
}

// Credentials defines model for Credentials.
type Credentials struct {
	// AccessKeyId AWS access key ID. Supports keystore syntax for secret lookup. Falls back to AWS_ACCESS_KEY_ID environment variable if not set.
	AccessKeyId string `json:"access_key_id,omitempty,omitzero"`

	// Endpoint S3-compatible endpoint (e.g., 's3.amazonaws.com' or 'localhost:9000' for MinIO)
	Endpoint string `json:"endpoint,omitempty,omitzero"`

	// SecretAccessKey AWS secret access key. Supports keystore syntax for secret lookup. Falls back to AWS_SECRET_ACCESS_KEY environment variable if not set.
	SecretAccessKey string `json:"secret_access_key,omitempty,omitzero"`

	// SessionToken Optional AWS session token for temporary credentials. Supports keystore syntax for secret lookup.
	SessionToken string `json:"session_token,omitempty,omitzero"`

	// UseSsl Enable SSL/TLS for S3 connections (default: true for AWS, false for local MinIO)
	UseSsl bool `json:"use_ssl,omitempty,omitzero"`
}

// DateRange defines model for DateRange.
type DateRange struct {
	From *string `json:"from,omitempty"`
	Name string  `json:"name"`
	To   *string `json:"to,omitempty"`
}

// DateRangeResult defines model for DateRangeResult.
type DateRangeResult struct {
	Count int     `json:"count"`
	From  *string `json:"from,omitempty"`
	Name  string  `json:"name"`
	To    *string `json:"to,omitempty"`
}

// DateRangeStringQuery defines model for DateRangeStringQuery.
type DateRangeStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost          Boost     `json:"boost,omitzero"`
	DatetimeParser string    `json:"datetime_parser,omitempty,omitzero"`
	End            time.Time `json:"end,omitempty,omitzero"`
	Field          string    `json:"field,omitempty,omitzero"`
	InclusiveEnd   bool      `json:"inclusive_end,omitzero"`
	InclusiveStart bool      `json:"inclusive_start,omitzero"`
	Start          time.Time `json:"start,omitempty,omitzero"`
}

// DisjunctionQuery defines model for DisjunctionQuery.
type DisjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Disjuncts []Query `json:"disjuncts"`
	Min       float64 `json:"min,omitempty,omitzero"`
}

// DocIdQuery defines model for DocIdQuery.
type DocIdQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost    `json:"boost,omitzero"`
	Ids   []string `json:"ids"`
}

// DocumentSchema Defines the structure of a document type
type DocumentSchema struct {
	// Description A description of the document type.
	Description string `json:"description,omitempty,omitzero"`

	// Schema A valid JSON Schema defining the document's structure.
	// This is used to infer indexing rules and field types.
	Schema map[string]interface{} `json:"schema,omitempty,omitzero"`
}

// DuckDuckGoSearchConfig defines model for DuckDuckGoSearchConfig.
type DuckDuckGoSearchConfig struct {
	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// NoHtml Remove HTML from results
	NoHtml bool `json:"no_html,omitempty,omitzero"`

	// NoRedirect Skip HTTP redirect for bang queries
	NoRedirect bool `json:"no_redirect,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// Edge A typed, weighted connection between documents
type Edge struct {
	// CreatedAt When the edge was created
	CreatedAt time.Time `json:"created_at,omitempty,omitzero"`

	// Metadata Optional edge metadata
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`

	// Source Base64-encoded source document key
	Source []byte `json:"source"`

	// Target Base64-encoded target document key
	Target []byte `json:"target"`

	// Type Edge type (e.g., "cites", "similar_to", "authored_by")
	Type string `json:"type"`

	// UpdatedAt When the edge was last updated
	UpdatedAt time.Time `json:"updated_at,omitempty,omitzero"`

	// Weight Edge weight/confidence (0.0 to 1.0)
	Weight float64 `json:"weight"`
}

// EdgeDirection Direction of edges to query:
// - out: Outgoing edges from the node
// - in: Incoming edges to the node
// - both: Both outgoing and incoming edges
type EdgeDirection string

// EdgeTypeConfig Configuration for a specific edge type
type EdgeTypeConfig struct {
	// AllowSelfLoops Whether to allow edges from a node to itself
	AllowSelfLoops bool `json:"allow_self_loops,omitempty,omitzero"`

	// MaxWeight Maximum allowed edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum allowed edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// Name Edge type name (e.g., 'cites', 'similar_to')
	Name string `json:"name"`

	// RequiredMetadata Required metadata fields for this edge type
	RequiredMetadata []string `json:"required_metadata,omitempty,omitzero"`
}

// EdgesResponse defines model for EdgesResponse.
type EdgesResponse struct {
	// Count Total number of edges returned
	Count int    `json:"count,omitempty,omitzero"`
	Edges []Edge `json:"edges,omitempty,omitzero"`
}

// EmbedderConfig defines model for EmbedderConfig.
type EmbedderConfig struct {
	// Provider The embedding provider to use.
	Provider EmbedderProvider `json:"provider"`
	union    json.RawMessage
}

// EmbedderProvider The embedding provider to use.
type EmbedderProvider string

// EmbeddingIndexConfig defines model for EmbeddingIndexConfig.
type EmbeddingIndexConfig struct {
	// Chunker A unified configuration for a chunking provider.
	Chunker ChunkerConfig `json:"chunker,omitempty,omitzero"`

	// Dimension Vector dimension
	Dimension int `json:"dimension"`

	// Embedder A unified configuration for an embedding provider.
	//
	// Embedders can be configured with templates to customize how documents are
	// converted to text before embedding. Templates use Handlebars syntax and
	// support various built-in helpers.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full document as context
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active user{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// Document with metadata:
	// ```handlebars
	// Title: {{metadata.title}}
	// Date: {{metadata.date}}
	// Tags: {{#each metadata.tags}}{{this}}, {{/each}}
	//
	// {{content}}
	// ```
	//
	// HTML content extraction:
	// ```handlebars
	// Product: {{name}}
	// Description: {{scrubHtml description_html}}
	// Price: ${{price}}
	// ```
	//
	// Multimodal with image:
	// ```handlebars
	// Product: {{title}}
	// {{media url=image}}
	// Description: {{description}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{title}}
	// {{#if author}}By: {{author}}{{/if}}
	// {{#if (eq category "premium")}} Premium Content{{/if}}
	// {{body}}
	// ```
	//
	// **Environment Variables:**
	// - `GEMINI_API_KEY` - API key for Google AI
	// - `OPENAI_API_KEY` - API key for OpenAI
	// - `OPENAI_BASE_URL` - Base URL for OpenAI-compatible APIs
	// - `OLLAMA_HOST` - Ollama server URL (e.g., http://localhost:11434)
	//
	// **Importing Pre-computed Embeddings:**
	//
	// You can import existing embeddings (from OpenAI, Cohere, or any provider) by including
	// them directly in your documents using the `_embeddings` field. This bypasses the
	// embedding generation step and writes vectors directly to the index.
	//
	// **Steps:**
	// 1. Create the index first with the appropriate dimension
	// 2. Write documents with `_embeddings: { "<indexName>": [...<embedding>...] }`
	//
	// **Example:**
	// ```json
	// {
	//   "title": "My Document",
	//   "content": "Document text...",
	//   "_embeddings": {
	//     "my_vector_index": [0.1, 0.2, 0.3, ...]
	//   }
	// }
	// ```
	//
	// **Use Cases:**
	// - Migrating from another vector database with existing embeddings
	// - Using embeddings generated by external systems
	// - Importing pre-computed OpenAI, Cohere, or other provider embeddings
	// - Batch processing embeddings offline before ingestion
	Embedder EmbedderConfig `json:"embedder,omitempty,omitzero"`

	// Field Field to extract embeddings from
	Field string `json:"field,omitempty,omitzero"`

	// MemOnly Whether to use in-memory only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`

	// Summarizer A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Summarizer GeneratorConfig `json:"summarizer,omitempty,omitzero"`

	// Template Handlebars template for generating prompts. See https://handlebarsjs.com/guide/ for more information.
	Template string `json:"template,omitempty,omitzero"`
}

// EmbeddingIndexStats defines model for EmbeddingIndexStats.
type EmbeddingIndexStats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalIndexed Number of vectors in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`

	// TotalNodes Total number of nodes in the index
	TotalNodes uint64 `json:"total_nodes,omitempty,omitzero"`
}

// Error defines model for Error.
type Error struct {
	Error string `json:"error"`
}

// EvalConfig Configuration for inline evaluation of query results.
// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
type EvalConfig struct {
	// Evaluators List of evaluators to run
	Evaluators []EvaluatorName `json:"evaluators,omitempty,omitzero"`

	// GroundTruth Ground truth data for evaluation
	GroundTruth GroundTruth `json:"ground_truth,omitempty,omitzero"`

	// Judge A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Judge GeneratorConfig `json:"judge,omitempty,omitzero"`

	// Options Options for evaluation behavior
	Options EvalOptions `json:"options,omitempty,omitzero"`
}

// EvalOptions Options for evaluation behavior
type EvalOptions struct {
	// K K value for @K metrics (precision@k, recall@k, ndcg@k)
	K int `json:"k,omitempty,omitzero"`

	// PassThreshold Score threshold for pass/fail determination
	PassThreshold float32 `json:"pass_threshold,omitempty,omitzero"`

	// TimeoutSeconds Timeout for evaluation in seconds
	TimeoutSeconds int `json:"timeout_seconds,omitempty,omitzero"`
}

// EvalRequest Standalone evaluation request for POST /eval endpoint.
// Useful for testing evaluators without running a query.
type EvalRequest struct {
	// Context Retrieved documents/context
	Context []map[string]interface{} `json:"context,omitempty,omitzero"`

	// Evaluators List of evaluators to run
	Evaluators []EvaluatorName `json:"evaluators"`

	// GroundTruth Ground truth data for evaluation
	GroundTruth GroundTruth `json:"ground_truth,omitempty,omitzero"`

	// Judge A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Judge GeneratorConfig `json:"judge,omitempty,omitzero"`

	// Options Options for evaluation behavior
	Options EvalOptions `json:"options,omitempty,omitzero"`

	// Output Generated output to evaluate (optional for retrieval-only)
	Output string `json:"output,omitempty,omitzero"`

	// Query Original query/input to evaluate
	Query string `json:"query,omitempty,omitzero"`

	// RetrievedIds IDs of retrieved documents (for retrieval metrics)
	RetrievedIds []string `json:"retrieved_ids,omitempty,omitzero"`
}

// EvalResult Complete evaluation result
type EvalResult struct {
	// DurationMs Total evaluation duration in milliseconds
	DurationMs int `json:"duration_ms,omitempty,omitzero"`

	// Scores Scores organized by category
	Scores EvalScores `json:"scores,omitempty,omitzero"`

	// Summary Aggregate statistics across all evaluators
	Summary EvalSummary `json:"summary,omitempty,omitzero"`
}

// EvalScores Scores organized by category
type EvalScores struct {
	// Generation Generation quality scores (faithfulness, relevance, etc.)
	Generation map[string]EvaluatorScore `json:"generation,omitempty,omitzero"`

	// Retrieval Retrieval metric scores (recall, precision, ndcg, etc.)
	Retrieval map[string]EvaluatorScore `json:"retrieval,omitempty,omitzero"`
}

// EvalSummary Aggregate statistics across all evaluators
type EvalSummary struct {
	// AverageScore Average score across all evaluators
	AverageScore float32 `json:"average_score,omitempty,omitzero"`

	// Failed Number of evaluators that failed
	Failed int `json:"failed,omitempty,omitzero"`

	// Passed Number of evaluators that passed
	Passed int `json:"passed,omitempty,omitzero"`

	// Total Total number of evaluators run
	Total int `json:"total,omitempty,omitzero"`
}

// EvaluatorName Available evaluator types:
//
// **Retrieval metrics** (require ground_truth.relevant_ids):
// - recall: Recall@k - fraction of relevant docs retrieved
// - precision: Precision@k - fraction of retrieved docs that are relevant
// - ndcg: Normalized Discounted Cumulative Gain
// - mrr: Mean Reciprocal Rank
// - map: Mean Average Precision
//
// **LLM-as-judge metrics** (require judge config):
// - relevance: Is output relevant to query? (works on retrieval-only too)
// - faithfulness: Is output grounded in context?
// - completeness: Does output fully address query?
// - coherence: Is output well-structured?
// - safety: Is output safe/appropriate?
// - helpfulness: Is output useful?
// - correctness: Is output factually correct? (uses expectations)
// - citation_quality: Are citations accurate?
type EvaluatorName string

// EvaluatorScore Result from a single evaluator
type EvaluatorScore struct {
	// Metadata Additional evaluator-specific data
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`

	// Pass Whether the evaluation passed the threshold
	Pass bool `json:"pass,omitempty,omitzero"`

	// Reason Human-readable explanation of the result
	Reason string `json:"reason,omitempty,omitzero"`

	// Score Numeric score (0-1)
	Score float32 `json:"score,omitempty,omitzero"`
}

// FacetOption defines model for FacetOption.
type FacetOption struct {
	DateRanges    []DateRange    `json:"date_ranges,omitempty,omitzero"`
	Field         string         `json:"field,omitempty,omitzero"`
	NumericRanges []NumericRange `json:"numeric_ranges,omitempty,omitzero"`
	Size          int            `json:"size,omitempty,omitzero"`
}

// FacetResult defines model for FacetResult.
type FacetResult struct {
	DateRanges    []DateRangeResult    `json:"date_ranges,omitempty,omitzero"`
	Field         string               `json:"field,omitempty,omitzero"`
	Missing       int                  `json:"missing,omitempty,omitzero"`
	NumericRanges []NumericRangeResult `json:"numeric_ranges,omitempty,omitzero"`
	Terms         []TermFacetResult    `json:"terms,omitempty,omitzero"`
	Total         int                  `json:"total,omitempty,omitzero"`
}

// FailedOperation defines model for FailedOperation.
type FailedOperation struct {
	Error     string                   `json:"error,omitempty,omitzero"`
	Id        string                   `json:"id,omitempty,omitzero"`
	Operation FailedOperationOperation `json:"operation,omitempty,omitzero"`
}

// FailedOperationOperation defines model for FailedOperation.Operation.
type FailedOperationOperation string

// FetchConfig Configuration for URL content fetching.
//
// Uses lib/scraping for downloading and processing. Supports:
// - HTTP/HTTPS URLs with security validation
// - HTML pages (extracts readable text via go-readability)
// - PDF files (extracts text)
// - Images (returns as data URIs)
// - Plain text files
// - S3 URLs (requires s3_credentials)
//
// Security features (from lib/scraping.ContentSecurityConfig):
// - Allowed host whitelist
// - Private IP blocking (SSRF prevention)
// - Download size limits
// - Timeout controls
type FetchConfig struct {
	// AllowedHosts Whitelist of allowed hostnames for fetching.
	// If empty, all hosts are allowed (except private IPs).
	// Example: ["docs.example.com", "api.example.com"]
	AllowedHosts []string `json:"allowed_hosts,omitempty,omitzero"`

	// BlockPrivateIps Block requests to private IP ranges (SSRF prevention).
	// Blocked: 127.0.0.0/8, 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16
	BlockPrivateIps *bool `json:"block_private_ips,omitempty"`

	// MaxContentLength Maximum content length in characters (truncated if exceeded)
	MaxContentLength int `json:"max_content_length,omitempty,omitzero"`

	// MaxDownloadSizeBytes Maximum download size in bytes (default: 100MB)
	MaxDownloadSizeBytes int         `json:"max_download_size_bytes,omitempty,omitzero"`
	S3Credentials        Credentials `json:"s3_credentials,omitempty,omitzero"`

	// TimeoutSeconds Download timeout in seconds
	TimeoutSeconds int `json:"timeout_seconds,omitempty,omitzero"`
}

// FilterSpec A filter specification to apply to search queries
type FilterSpec struct {
	// Field Field name to filter on
	Field string `json:"field"`

	// Operator Filter operator:
	// - eq: Equals
	// - ne: Not equals
	// - gt/gte: Greater than (or equal)
	// - lt/lte: Less than (or equal)
	// - contains: Contains substring
	// - prefix: Starts with
	// - range: Between two values (value should be array [min, max])
	// - in: Value in list (value should be array)
	Operator FilterSpecOperator `json:"operator"`

	// Value Filter value (string, number, boolean, or array for range/in operators)
	Value interface{} `json:"value"`
}

// FilterSpecOperator Filter operator:
// - eq: Equals
// - ne: Not equals
// - gt/gte: Greater than (or equal)
// - lt/lte: Less than (or equal)
// - contains: Contains substring
// - prefix: Starts with
// - range: Between two values (value should be array [min, max])
// - in: Value in list (value should be array)
type FilterSpecOperator string

// FollowupStepConfig Configuration for generating follow-up questions. Uses a separate generator
// call which can use a cheaper/faster model.
type FollowupStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Context Custom guidance for follow-up question focus and style
	Context string `json:"context,omitempty,omitzero"`

	// Count Number of follow-up questions to generate
	Count int `json:"count,omitempty,omitzero"`

	// Enabled Enable follow-up question generation
	Enabled bool `json:"enabled,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`
}

// Fuzziness The fuzziness of the query. Can be an integer or "auto".
type Fuzziness struct {
	union json.RawMessage
}

// Fuzziness0 defines model for .
type Fuzziness0 = int32

// Fuzziness1 defines model for Fuzziness.1.
type Fuzziness1 string

// FuzzyQuery defines model for FuzzyQuery.
type FuzzyQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness `json:"fuzziness,omitempty,omitzero"`
	PrefixLength int32     `json:"prefix_length,omitempty,omitzero"`
	Term         string    `json:"term"`
}

// GeneratorConfig defines model for GeneratorConfig.
type GeneratorConfig struct {
	// Provider The generative AI provider to use.
	Provider GeneratorProvider `json:"provider"`
	union    json.RawMessage
}

// GeneratorProvider The generative AI provider to use.
type GeneratorProvider string

// GeoBoundingBoxQuery defines model for GeoBoundingBoxQuery.
type GeoBoundingBoxQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost `json:"boost,omitzero"`

	// BottomRight [lon, lat]
	BottomRight []float64 `json:"bottom_right"`
	Field       string    `json:"field,omitempty,omitzero"`

	// TopLeft [lon, lat]
	TopLeft []float64 `json:"top_left"`
}

// GeoBoundingPolygonQuery defines model for GeoBoundingPolygonQuery.
type GeoBoundingPolygonQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost         Boost      `json:"boost,omitzero"`
	Field         string     `json:"field,omitempty,omitzero"`
	PolygonPoints []GeoPoint `json:"polygon_points"`
}

// GeoDistanceQuery defines model for GeoDistanceQuery.
type GeoDistanceQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Distance string `json:"distance"`
	Field    string `json:"field,omitempty,omitzero"`

	// Location [lon, lat]
	Location []float64 `json:"location"`
}

// GeoPoint defines model for GeoPoint.
type GeoPoint struct {
	Lat float64 `json:"lat,omitempty,omitzero"`
	Lon float64 `json:"lon,omitempty,omitzero"`
}

// GeoShape A GeoJSON shape object. This is a simplified representation.
type GeoShape struct {
	Coordinates []interface{} `json:"coordinates"`
	Type        string        `json:"type"`
}

// GeoShapeGeometry defines model for GeoShapeGeometry.
type GeoShapeGeometry struct {
	Relation GeoShapeGeometryRelation `json:"relation"`

	// Shape A GeoJSON shape object. This is a simplified representation.
	Shape GeoShape `json:"shape"`
}

// GeoShapeGeometryRelation defines model for GeoShapeGeometry.Relation.
type GeoShapeGeometryRelation string

// GeoShapeQuery defines model for GeoShapeQuery.
type GeoShapeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost            `json:"boost,omitzero"`
	Field    string           `json:"field,omitempty,omitzero"`
	Geometry GeoShapeGeometry `json:"geometry"`
}

// GoogleEmbedderConfig Configuration for the Google AI (Gemini) embedding provider.
//
// API key via `api_key` field or `GEMINI_API_KEY` environment variable.
//
// **Example Models:** gemini-embedding-001 (default, 3072 dims)
//
// **Docs:** https://ai.google.dev/gemini-api/docs/embeddings
type GoogleEmbedderConfig struct {
	// ApiKey The Google API key. Can also be set via GEMINI_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimension The dimension of the embedding vector (768, 1536, or 3072 recommended).
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1'). Required for Vertex AI, optional for Gemini API.
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the embedding model to use.
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID (optional for Gemini API, required for Vertex AI).
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Url The URL of the Google API endpoint (optional, uses default if not specified).
	Url string `json:"url,omitempty,omitzero"`
}

// GoogleGeneratorConfig Configuration for the Google generative AI provider (Gemini).
//
// **Example Models:** gemini-2.5-flash (default), gemini-2.5-pro, gemini-3.0-pro
//
// **Docs:** https://ai.google.dev/gemini-api/docs/models
type GoogleGeneratorConfig struct {
	// ApiKey The Google API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1').
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the generative model to use (e.g., 'gemini-2.5-flash', 'gemini-2.5-pro', 'gemini-3.0-pro').
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Google API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// GoogleSearchConfig defines model for GoogleSearchConfig.
type GoogleSearchConfig struct {
	// ApiKey Google API key (or set GOOGLE_CSE_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// CseId Custom Search Engine ID (or set GOOGLE_CSE_ID env var)
	CseId string `json:"cse_id,omitempty,omitzero"`

	// DateRestrict Restrict results by date (e.g., 'd7' for last 7 days, 'm1' for last month)
	DateRestrict string `json:"date_restrict,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// SearchType Type of search to perform
	SearchType GoogleSearchConfigSearchType `json:"search_type,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// GoogleSearchConfigSearchType Type of search to perform
type GoogleSearchConfigSearchType string

// GraphIndexV0Config Configuration for graph_v0 index type
type GraphIndexV0Config struct {
	// EdgeTypes List of edge types with their configurations
	EdgeTypes []EdgeTypeConfig `json:"edge_types,omitempty,omitzero"`

	// MaxEdgesPerDocument Maximum number of edges per document (0 = unlimited)
	MaxEdgesPerDocument int `json:"max_edges_per_document,omitempty,omitzero"`
}

// GraphIndexV0Stats Statistics for graph_v0 index
type GraphIndexV0Stats struct {
	// EdgeTypes Count of edges per edge type
	EdgeTypes map[string]uint64 `json:"edge_types,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalEdges Total number of edges in the graph
	TotalEdges uint64 `json:"total_edges,omitempty,omitzero"`
}

// GraphNodeSelector Defines how to select start/target nodes for graph queries
type GraphNodeSelector struct {
	// Keys Explicit list of node keys
	Keys []string `json:"keys,omitempty,omitzero"`

	// Limit Maximum number of nodes to select from the referenced results
	Limit int `json:"limit,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`

	// ResultRef Reference to search results to use as nodes:
	// - "$full_text_results" - use full-text search results
	// - "$aknn_results.index_name" - use vector search results from specific index
	ResultRef string `json:"result_ref,omitempty,omitzero"`
}

// GraphQuery Declarative graph query to execute after full-text/vector searches
type GraphQuery struct {
	// Fields Which fields to return from documents
	Fields []string `json:"fields,omitempty,omitzero"`

	// IncludeDocuments Fetch full documents for graph results
	IncludeDocuments bool `json:"include_documents,omitempty,omitzero"`

	// IncludeEdges Include edge details for each node
	IncludeEdges bool `json:"include_edges,omitempty,omitzero"`

	// IndexName Graph index name (must be graph_v0 type)
	IndexName string `json:"index_name"`

	// Params Parameters for graph traversal and pathfinding
	Params GraphQueryParams `json:"params,omitempty,omitzero"`

	// Pattern Pattern steps for pattern query type
	Pattern []PatternStep `json:"pattern,omitempty,omitzero"`

	// ReturnAliases Which aliases to return from pattern query (empty = all)
	ReturnAliases []string `json:"return_aliases,omitempty,omitzero"`

	// StartNodes Defines how to select start/target nodes for graph queries
	StartNodes GraphNodeSelector `json:"start_nodes,omitempty,omitzero"`

	// TargetNodes Defines how to select start/target nodes for graph queries
	TargetNodes GraphNodeSelector `json:"target_nodes,omitempty,omitzero"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryParams Parameters for graph traversal and pathfinding
type GraphQueryParams struct {
	// Algorithm Graph algorithm to run (e.g., 'pagerank', 'betweenness')
	Algorithm string `json:"algorithm,omitempty,omitzero"`

	// AlgorithmParams Parameters for the graph algorithm
	AlgorithmParams map[string]interface{} `json:"algorithm_params,omitempty,omitzero"`

	// DeduplicateNodes Remove duplicate nodes (traversal)
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information (traversal)
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// K Number of paths to find (k-shortest-paths)
	K int `json:"k,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum number of results (traversal)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`

	// WeightMode Path weighting algorithm for pathfinding:
	// - min_hops: Minimize number of edges
	// - min_weight: Minimize sum of edge weights
	// - max_weight: Maximize product of edge weights
	WeightMode PathWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// GraphQueryResult Results of a graph query
type GraphQueryResult struct {
	// Matches Pattern matches (for pattern queries)
	Matches []PatternMatch `json:"matches,omitempty,omitzero"`

	// Nodes Result nodes
	Nodes []GraphResultNode `json:"nodes,omitempty,omitzero"`

	// Paths Result paths (for pathfinding queries)
	Paths []Path `json:"paths,omitempty,omitzero"`

	// Took Query execution time
	Took time.Duration `json:"took,omitempty,omitzero"`

	// Total Total number of results
	Total int `json:"total"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryType Type of graph query to execute
type GraphQueryType string

// GraphResultNode A node in graph query results
type GraphResultNode struct {
	// Depth Distance from start node
	Depth int `json:"depth,omitempty,omitzero"`

	// Distance Weighted distance
	Distance float64 `json:"distance,omitempty,omitzero"`

	// Document Full document (if include_documents=true)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Edges Connected edges (when include_edges=true)
	Edges []Edge `json:"edges,omitempty,omitzero"`

	// Key Document key
	Key string `json:"key"`

	// Path Keys in path from start to this node
	Path []string `json:"path,omitempty,omitzero"`

	// PathEdges Edges in path from start to this node
	PathEdges []PathEdge `json:"path_edges,omitempty,omitzero"`
}

// GroundTruth Ground truth data for evaluation
type GroundTruth struct {
	// Expectations Context for evaluators about what to expect in the response.
	// Provides guidance for LLM judges (e.g., "Should mention pricing tiers").
	Expectations string `json:"expectations,omitempty,omitzero"`

	// RelevantIds Document IDs known to be relevant (for retrieval metrics)
	RelevantIds []string `json:"relevant_ids,omitempty,omitzero"`
}

// IPRangeQuery defines model for IPRangeQuery.
type IPRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Cidr  string `json:"cidr"`
	Field string `json:"field,omitempty,omitzero"`
}

// IndexConfig Configuration for an index
type IndexConfig struct {
	// Description Optional description of the index and its purpose
	Description string `json:"description,omitempty,omitzero"`

	// Enrichments List of enrichment names to apply to documents before indexing. Enrichments must be defined at the table level.
	Enrichments []string `json:"enrichments,omitempty,omitzero"`

	// Name Name of the index
	Name string `json:"name"`

	// Type The type of the index.
	Type  IndexType `json:"type"`
	union json.RawMessage
}

// IndexStats Statistics for an index
type IndexStats struct {
	union json.RawMessage
}

// IndexStatus defines model for IndexStatus.
type IndexStatus struct {
	// Config Configuration for an index
	Config      IndexConfig           `json:"config"`
	ShardStatus map[string]IndexStats `json:"shard_status"`

	// Status Statistics for an index
	Status IndexStats `json:"status"`
}

// IndexType The type of the index.
type IndexType string

// KeyRange Key range processed in this request
type KeyRange struct {
	From string `json:"from,omitempty,omitzero"`
	To   string `json:"to,omitempty,omitzero"`
}

// LinearMergePageStatus Status of a linear merge page operation:
// - "success": All records in batch processed successfully
// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
// - "error": Fatal error occurred, no records processed successfully
type LinearMergePageStatus string

// LinearMergeRequest Linear merge operation for syncing sorted records from external sources.
// Use this to keep Antfly in sync with an external database or data source.
//
// **How it works:**
// 1. Send sorted records from your external source
// 2. Server upserts records that exist in your batch
// 3. Server deletes Antfly records in the key range that are absent from your batch
// 4. If stopped at shard boundary, use next_cursor for next request
//
// **WARNING:** Not safe for concurrent operations with overlapping key ranges.
type LinearMergeRequest struct {
	// DryRun If true, returns what would be deleted without making changes.
	//
	// Use cases:
	// - Validate sync behavior before committing
	// - Check which records will be removed
	// - Test key range boundaries
	//
	// Response includes deleted_ids array when dry_run=true.
	DryRun bool `json:"dry_run,omitempty,omitzero"`

	// LastMergedId ID of last record from previous merge request.
	// - First request: Use empty string ""
	// - Subsequent requests: Use next_cursor from previous response
	// - Defines lower bound of key range to process
	//
	// This enables pagination for large datasets.
	LastMergedId string `json:"last_merged_id,omitempty,omitzero"`

	// Records Map of resource ID to resource object: {"resource_id_1": {...}, "resource_id_2": {...}}
	//
	// Requirements:
	// - Keys must be sorted lexicographically by your client
	// - Server will process keys in sorted order
	// - Use consistent key naming (e.g., all start with same prefix)
	//
	// This format avoids duplicate IDs and matches Antfly's batch write interface.
	Records map[string]interface{} `json:"records"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write
	// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`
}

// LinearMergeResult defines model for LinearMergeResult.
type LinearMergeResult struct {
	// Deleted Records deleted or would be deleted (if dry_run=true)
	Deleted int `json:"deleted"`

	// DeletedIds IDs that were deleted (or would be deleted if dry_run=true). Only included if dry_run=true.
	DeletedIds []string          `json:"deleted_ids,omitempty,omitzero"`
	Failed     []FailedOperation `json:"failed,omitempty,omitzero"`

	// KeyRange Key range processed in this request
	KeyRange KeyRange `json:"key_range,omitempty,omitzero"`

	// KeysScanned Total number of keys scanned from Antfly during range query
	KeysScanned int `json:"keys_scanned,omitempty,omitzero"`

	// Message Additional information (e.g., "stopped at shard boundary", "dry run - no changes made")
	Message string `json:"message,omitempty,omitzero"`

	// NextCursor ID of last record in this batch (use for next request)
	NextCursor string `json:"next_cursor"`

	// Skipped Records skipped because content hash matched (unchanged)
	Skipped int `json:"skipped"`

	// Status Status of a linear merge page operation:
	// - "success": All records in batch processed successfully
	// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
	// - "error": Fatal error occurred, no records processed successfully
	Status LinearMergePageStatus `json:"status"`
	Took   time.Duration         `json:"took,omitempty,omitzero"`

	// Upserted Records inserted or updated (0 if dry_run=true)
	Upserted int `json:"upserted"`
}

// MatchAllQuery defines model for MatchAllQuery.
type MatchAllQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost                  `json:"boost,omitzero"`
	MatchAll map[string]interface{} `json:"match_all"`
}

// MatchNoneQuery defines model for MatchNoneQuery.
type MatchNoneQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost                  `json:"boost,omitzero"`
	MatchNone map[string]interface{} `json:"match_none"`
}

// MatchPhraseQuery defines model for MatchPhraseQuery.
type MatchPhraseQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness   Fuzziness `json:"fuzziness,omitempty,omitzero"`
	MatchPhrase string    `json:"match_phrase"`
}

// MatchQuery defines model for MatchQuery.
type MatchQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness          `json:"fuzziness,omitempty,omitzero"`
	Match        string             `json:"match"`
	Operator     MatchQueryOperator `json:"operator,omitempty,omitzero"`
	PrefixLength int32              `json:"prefix_length,omitempty,omitzero"`
}

// MatchQueryOperator defines model for MatchQuery.Operator.
type MatchQueryOperator string

// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
// failover: Use full_text_search if embedding generation fails
type MergeStrategy string

// MultiPhraseQuery defines model for MultiPhraseQuery.
type MultiPhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness  `json:"fuzziness,omitempty,omitzero"`
	Terms     [][]string `json:"terms"`
}

// NodeFilter Filter nodes during graph traversal using existing query primitives
type NodeFilter struct {
	// FilterPrefix Filter by key prefix
	FilterPrefix string `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query to filter nodes (same syntax as search filter_query)
	FilterQuery map[string]interface{} `json:"filter_query,omitempty,omitzero"`
}

// NumericRange defines model for NumericRange.
type NumericRange struct {
	From *float64 `json:"from,omitempty"`
	Name string   `json:"name"`
	To   *float64 `json:"to,omitempty"`
}

// NumericRangeQuery defines model for NumericRangeQuery.
type NumericRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost   `json:"boost,omitzero"`
	Field        string  `json:"field,omitempty,omitzero"`
	InclusiveMax bool    `json:"inclusive_max,omitzero"`
	InclusiveMin bool    `json:"inclusive_min,omitzero"`
	Max          float64 `json:"max,omitzero"`
	Min          float64 `json:"min,omitzero"`
}

// NumericRangeResult defines model for NumericRangeResult.
type NumericRangeResult struct {
	Count int      `json:"count"`
	From  *float64 `json:"from,omitempty"`
	Name  string   `json:"name"`
	To    *float64 `json:"to,omitempty"`
}

// OllamaEmbedderConfig Configuration for the Ollama embedding provider.
//
// Local embeddings for privacy and offline use. URL via `url` field or `OLLAMA_HOST` env var.
//
// **Example Models:** nomic-embed-text (768 dims), mxbai-embed-large (1024 dims), all-minilm (384 dims)
//
// **Docs:** https://ollama.com/search?c=embedding
type OllamaEmbedderConfig struct {
	// Model The name of the Ollama model to use (e.g., 'nomic-embed-text', 'mxbai-embed-large').
	Model string `json:"model"`

	// Url The URL of the Ollama API endpoint. Can also be set via OLLAMA_HOST environment variable.
	Url string `json:"url,omitempty,omitzero"`
}

// OllamaGeneratorConfig Configuration for the Ollama generative AI provider.
//
// Ollama provides local LLM inference for privacy and offline use.
//
// **Example Models:** llama3.3:70b, qwen2.5:72b, deepseek-r1:70b, mistral:7b, llava:34b
//
// **Docs:** https://ollama.com/library
type OllamaGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Ollama model to use (e.g., 'llama3.3:70b', 'qwen2.5:72b', 'deepseek-coder:33b').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OllamaRerankerConfig Configuration for the Ollama reranking provider.
type OllamaRerankerConfig struct {
	// Model The name of the Ollama model to use for reranking.
	Model string `json:"model"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIEmbedderConfig Configuration for the OpenAI embedding provider.
//
// API key via `api_key` field or `OPENAI_API_KEY` environment variable.
// Supports OpenAI-compatible APIs via `url` field.
//
// **Example Models:** text-embedding-3-small (default, 1536 dims), text-embedding-3-large (3072 dims)
//
// **Docs:** https://platform.openai.com/docs/guides/embeddings
type OpenAIEmbedderConfig struct {
	// ApiKey The OpenAI API key. Can also be set via OPENAI_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimensions Output dimension for the embedding (uses MRL for dimension reduction). Recommended: 256, 512, 1024, 1536, or 3072.
	Dimensions int `json:"dimensions,omitempty,omitzero"`

	// Model The name of the OpenAI model to use.
	Model string `json:"model"`

	// Url The URL of the OpenAI API endpoint. Defaults to OpenAI's API. Can be set via OPENAI_BASE_URL environment variable.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIGeneratorConfig Configuration for the OpenAI generative AI provider.
//
// **Example Models:** gpt-4.1 (default), gpt-4.1-mini, o3, o4-mini
//
// **Docs:** https://platform.openai.com/docs/models
type OpenAIGeneratorConfig struct {
	// ApiKey The OpenAI API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (-2.0 to 2.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the OpenAI model to use (e.g., 'gpt-4.1', 'gpt-4.1-mini', 'o4-mini').
	Model string `json:"model"`

	// PresencePenalty Penalty for token presence (-2.0 to 2.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the OpenAI API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// Path defines model for Path.
type Path struct {
	Edges  []PathEdge `json:"edges,omitempty,omitzero"`
	Length int        `json:"length,omitempty,omitzero"`

	// Nodes Ordered list of node keys (base64-encoded)
	Nodes       []string `json:"nodes,omitempty,omitzero"`
	TotalWeight float64  `json:"total_weight,omitempty,omitzero"`
}

// PathEdge defines model for PathEdge.
type PathEdge struct {
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`
	Source   string                 `json:"source,omitempty,omitzero"`
	Target   string                 `json:"target,omitempty,omitzero"`
	Type     string                 `json:"type,omitempty,omitzero"`
	Weight   float64                `json:"weight,omitempty,omitzero"`
}

// PathFindRequest defines model for PathFindRequest.
type PathFindRequest struct {
	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by specific edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`
	K         int      `json:"k,omitempty,omitzero"`
	MaxDepth  int      `json:"max_depth,omitempty,omitzero"`
	MaxWeight float64  `json:"max_weight,omitempty,omitzero"`
	MinWeight float64  `json:"min_weight,omitempty,omitzero"`

	// Source Source node key (base64-encoded)
	Source string `json:"source"`

	// Target Target node key (base64-encoded)
	Target string `json:"target"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindResult defines model for PathFindResult.
type PathFindResult struct {
	Paths        []Path  `json:"paths,omitempty,omitzero"`
	PathsFound   int     `json:"paths_found,omitempty,omitzero"`
	SearchTimeMs float64 `json:"search_time_ms,omitempty,omitzero"`
	Source       string  `json:"source,omitempty,omitzero"`
	Target       string  `json:"target,omitempty,omitzero"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindWeightMode Algorithm for path finding:
// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
// - max_weight: Path with maximum product of edge weights (strongest connection chain)
// - min_weight: Path with minimum sum of edge weights (lowest cost route)
type PathFindWeightMode string

// PathWeightMode Path weighting algorithm for pathfinding:
// - min_hops: Minimize number of edges
// - min_weight: Minimize sum of edge weights
// - max_weight: Maximize product of edge weights
type PathWeightMode string

// PatternEdgeStep Edge constraints in a pattern step
type PatternEdgeStep struct {
	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// MaxHops Maximum number of hops (>1 = variable-length path)
	MaxHops int `json:"max_hops,omitempty,omitzero"`

	// MaxWeight Maximum edge weight filter
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinHops Minimum number of hops (1 = direct edge)
	MinHops int `json:"min_hops,omitempty,omitzero"`

	// MinWeight Minimum edge weight filter
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// Types Edge types to traverse (empty = any)
	Types []string `json:"types,omitempty,omitzero"`
}

// PatternMatch A single match from a pattern query
type PatternMatch struct {
	// Bindings Map of alias to matched node
	Bindings map[string]GraphResultNode `json:"bindings,omitempty,omitzero"`

	// Path Edges traversed in this match
	Path []PathEdge `json:"path,omitempty,omitzero"`
}

// PatternStep A step in a graph pattern query
type PatternStep struct {
	// Alias Name for this node (reuse alias for cycle detection)
	Alias string `json:"alias,omitempty,omitzero"`

	// Edge Edge constraints in a pattern step
	Edge PatternEdgeStep `json:"edge,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`
}

// Permission defines model for Permission.
type Permission struct {
	// Resource Resource name (e.g., table name, target username, or '*' for global).
	Resource string `json:"resource"`

	// ResourceType Type of the resource, e.g., table, user, or global ('*').
	ResourceType ResourceType `json:"resource_type"`

	// Type Type of permission.
	Type PermissionType `json:"type"`
}

// PermissionType Type of permission.
type PermissionType string

// PhraseQuery defines model for PhraseQuery.
type PhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness `json:"fuzziness,omitempty,omitzero"`
	Terms     []string  `json:"terms"`
}

// PrefixQuery defines model for PrefixQuery.
type PrefixQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Prefix string `json:"prefix"`
}

// Pruner Configuration for pruning search results based on score quality.
// Helps filter out low-relevance results in RAG pipelines by detecting
// score gaps or deviations from top results.
type Pruner struct {
	// MaxScoreGapPercent Stop returning results when score drops more than this percentage
	// from the previous result. Detects "elbows" in score distribution.
	// For example, 30.0 stops when score drops 30% from previous result.
	MaxScoreGapPercent float64 `json:"max_score_gap_percent,omitempty,omitzero"`

	// MinAbsoluteScore Hard minimum score threshold. Results with scores below this value
	// are excluded regardless of other pruning settings.
	MinAbsoluteScore float64 `json:"min_absolute_score,omitempty,omitzero"`

	// MinScoreRatio Keep only results with score >= max_score * min_score_ratio.
	// For example, 0.5 keeps results scoring at least half of the top result.
	// Applied after fusion scoring.
	MinScoreRatio float64 `json:"min_score_ratio,omitempty,omitzero"`

	// RequireMultiIndex Only keep results that appear in multiple indexes (both full-text
	// and vector search). Useful for increasing precision by requiring
	// agreement between different retrieval methods.
	RequireMultiIndex bool `json:"require_multi_index,omitempty,omitzero"`

	// StdDevThreshold Keep results within N standard deviations below the mean score.
	// For example, 1.0 keeps results with score >= mean - 1*stddev.
	// Useful for statistical outlier detection in result sets.
	StdDevThreshold float64 `json:"std_dev_threshold,omitempty,omitzero"`
}

// Query defines model for Query.
type Query struct {
	union json.RawMessage
}

// QueryBuilderRequest defines model for QueryBuilderRequest.
type QueryBuilderRequest struct {
	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// Intent Natural language description of the search intent
	Intent string `json:"intent"`

	// SchemaFields List of searchable field names to consider. Overrides table schema if provided.
	SchemaFields []string `json:"schema_fields,omitempty,omitzero"`

	// Table Name of the table to build query for. If provided, uses table schema for field context.
	Table string `json:"table,omitempty,omitzero"`
}

// QueryBuilderResult defines model for QueryBuilderResult.
type QueryBuilderResult struct {
	// Confidence Model's confidence in the generated query (0.0-1.0)
	Confidence float64 `json:"confidence,omitempty,omitzero"`

	// Explanation Human-readable explanation of what the query does and why it was structured this way
	Explanation string `json:"explanation,omitempty,omitzero"`

	// Query Generated search query in simplified DSL format.
	// Can be used directly in QueryRequest.full_text_search or filter_query.
	Query map[string]interface{} `json:"query"`

	// Warnings Any issues, limitations, or assumptions made when generating the query
	Warnings []string `json:"warnings,omitempty,omitzero"`
}

// QueryHit A single query result hit
type QueryHit struct {
	// ID ID of the record.
	ID string `json:"_id"`

	// IndexScores Scores partitioned by index when using RRF search.
	IndexScores map[string]interface{} `json:"_index_scores,omitempty,omitzero"`

	// Score Relevance score of the hit.
	Score  float64                `json:"_score"`
	Source map[string]interface{} `json:"_source,omitempty,omitzero"`
}

// QueryHits A list of query hits.
type QueryHits struct {
	Hits []QueryHit `json:"hits"`

	// MaxScore Maximum score of the results.
	MaxScore float64 `json:"max_score,omitempty,omitzero"`

	// Total Total number of hits available.
	Total uint64 `json:"total,omitempty"`
}

// QueryRequest defines model for QueryRequest.
type QueryRequest struct {
	Analyses *Analyses `json:"analyses,omitempty"`

	// Count If true, returns only the total count of matching documents without retrieving the actual documents.
	// Useful for pagination and displaying result counts.
	Count bool `json:"count,omitempty,omitzero"`

	// DistanceOver Minimum distance threshold for semantic similarity search. Results with distance
	// less than this value are excluded.
	//
	// Useful for excluding near-exact duplicates or finding dissimilar documents.
	DistanceOver *float32 `json:"distance_over,omitempty"`

	// DistanceUnder Maximum distance threshold for semantic similarity search. Results with distance
	// greater than this value are excluded. Lower distances indicate higher similarity.
	//
	// Useful for filtering out low-confidence matches.
	DistanceUnder *float32 `json:"distance_under,omitempty"`

	// DocumentRenderer Optional Handlebars template string for rendering document content in RAG queries.
	// Template has access to document fields via `{{this.fields.fieldName}}`.
	//
	// **Default**: Uses TOON (Token-Oriented Object Notation) format for 30-60% token reduction:
	// ```handlebars
	// {{encodeToon this.fields}}
	// ```
	//
	// **Available Helpers**:
	// - `encodeToon` - Renders fields in compact TOON format with configurable options:
	//   - `lengthMarker` (bool): Add # prefix to array counts (default: true)
	//   - `indent` (int): Indentation spacing (default: 2)
	//   - `delimiter` (string): Field separator for tabular arrays
	// - `scrubHtml` - Removes HTML tags and extracts text
	// - `media` - Wraps data URIs for GenKit multimodal support
	// - `eq` - Equality comparison for conditionals
	//
	// **Examples**:
	// - Basic TOON: `{{encodeToon this.fields}}`
	// - Compact TOON: `{{encodeToon this.fields lengthMarker=false indent=0}}`
	// - Tabular data: `{{encodeToon this.fields delimiter="\t"}}`
	// - Custom template: `Title: {{this.fields.title}}\nBody: {{this.fields.body}}`
	// - Traditional format: `{{#each this.fields}}{{@key}}: {{this}}\n{{/each}}`
	//
	// TOON format produces compact, LLM-optimized output like:
	// ```
	// title: Introduction to Vector Search
	// author: Jane Doe
	// tags[#3]: ai,search,ml
	// ```
	//
	// **References**:
	// - TOON Specification: https://github.com/toon-format/toon
	// - Go Implementation: https://github.com/alpkeskin/gotoon
	DocumentRenderer string `json:"document_renderer,omitempty,omitzero"`

	// EmbeddingTemplate Optional Handlebars template for multimodal embedding of the semantic_search query.
	// The template has access to `this` which contains the semantic_search string value.
	//
	// Use this when you want to embed multimodal content (images, PDFs, etc.) instead of
	// just text. The template is rendered using dotprompt with access to remote content helpers.
	//
	// **Available Helpers**:
	// - `remoteMedia url=<url>` - Fetches and embeds remote images/media
	// - `remotePDF url=<url>` - Fetches and extracts content from PDFs
	// - `remoteText url=<url>` - Fetches and includes remote text content
	//
	// **Examples**:
	// - PDF search: `{{remotePDF url=this}}`
	// - Image search: `{{remoteMedia url=this}}`
	// - Mixed: `Search for: {{this}} {{#if this}}{{remoteMedia url=this}}{{/if}}`
	//
	// When not specified, the semantic_search string is embedded as plain text.
	EmbeddingTemplate string `json:"embedding_template,omitempty,omitzero"`

	// Embeddings Pre-computed embeddings to use for semantic searches instead of embedding the semantic_search string.
	// The keys are the index names, and values are the embedding vectors.
	//
	// Use when you've already generated embeddings on the client side to avoid redundant embedding calls.
	Embeddings map[string][]float32 `json:"embeddings,omitempty,omitzero"`

	// ExclusionQuery Bleve query applied as a NOT condition. Documents matching this query are excluded
	// from results. Applied before scoring.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Excluding drafts: `"status:draft"`
	// - Removing deprecated content: `"deprecated:true"`
	// - Filtering out archived items: `"status:archived"`
	ExclusionQuery json.RawMessage `json:"exclusion_query,omitempty,omitzero"`

	// ExpandStrategy Strategy for merging graph results with search results:
	// - union: Include nodes from both search and graph results
	// - intersection: Only include nodes appearing in both
	ExpandStrategy QueryRequestExpandStrategy `json:"expand_strategy,omitempty,omitzero"`

	// Facets Faceting configuration for aggregating results by field values.
	// Useful for building faceted navigation and filters.
	Facets map[string]FacetOption `json:"facets,omitempty,omitzero"`

	// Fields List of fields to include in the results. If not specified, all fields are returned.
	// Use to reduce response size and improve performance.
	Fields []string `json:"fields,omitempty,omitzero"`

	// FilterPrefix Filter results by key prefix. Only returns documents whose keys start with this string.
	// Applied before scoring to improve performance.
	//
	// Common use cases:
	// - Multi-tenant filtering: `"tenant:acme:"`
	// - User-specific data: `"user:123:"`
	// - Document type filtering: `"article:"`
	FilterPrefix []byte `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query applied as an AND condition. Documents must match both the main query
	// and this filter. Applied before scoring for better performance.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Status filtering: `"status:published"`
	// - Date ranges: `"created_at:>2023-01-01"`
	// - Category filtering: `"category:technology AND language:en"`
	FilterQuery json.RawMessage `json:"filter_query,omitempty,omitzero"`

	// FullTextSearch Bleve query for full-text search. Supports all Bleve query types.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Examples:
	// - Simple: `{"query": "computer"}`
	// - Field-specific: `{"query": "body:computer"}`
	// - Boolean: `{"query": "artificial AND intelligence"}`
	// - Range: `{"query": "year:>2020"}`
	// - Phrase: `{"query": "\"exact phrase\""}`
	FullTextSearch json.RawMessage `json:"full_text_search,omitempty,omitzero"`

	// GraphSearches Declarative graph queries to execute after full-text/vector searches.
	// Results can reference search results using node selectors like $full_text_results.
	GraphSearches map[string]GraphQuery `json:"graph_searches,omitempty,omitzero"`

	// Indexes List of vector index names to use for semantic search. Required when using semantic_search.
	// Multiple indexes can be specified, and their results will be merged using RRF.
	Indexes []string `json:"indexes,omitempty,omitzero"`

	// Limit Maximum number of results to return. For semantic_search, this is the topk parameter.
	// Default varies by query type (typically 10).
	Limit int `json:"limit,omitempty,omitzero"`

	// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
	// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
	// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
	// failover: Use full_text_search if embedding generation fails
	MergeStrategy MergeStrategy `json:"merge_strategy,omitempty,omitzero"`

	// Offset Number of results to skip for pagination. Only available for full_text_search queries.
	// Not supported for semantic_search due to vector index limitations.
	Offset int `json:"offset,omitempty,omitzero"`

	// OrderBy Sort order for results. Map of field names to boolean (true = descending, false = ascending).
	// Only applicable for full_text_search queries. Semantic searches are always sorted by similarity score.
	OrderBy map[string]bool `json:"order_by,omitempty,omitzero"`

	// Pruner Configuration for pruning search results based on score quality.
	// Helps filter out low-relevance results in RAG pipelines by detecting
	// score gaps or deviations from top results.
	Pruner Pruner `json:"pruner,omitempty,omitzero"`

	// Reranker A unified configuration for a reranking provider.
	Reranker *RerankerConfig `json:"reranker,omitempty"`

	// SemanticSearch Natural language query for vector similarity search. Results are ranked by semantic similarity
	// to the query and can be combined with full_text_search using Reciprocal Rank Fusion (RRF).
	//
	// The semantic_search string is automatically embedded using the configured embedding model
	// for the specified indexes. Use `embedding_template` for multimodal queries.
	SemanticSearch string `json:"semantic_search,omitempty,omitzero"`

	// Table Name of the table to query. Optional for global queries.
	Table string `json:"table,omitempty,omitzero"`
}

// QueryRequestExpandStrategy Strategy for merging graph results with search results:
// - union: Include nodes from both search and graph results
// - intersection: Only include nodes appearing in both
type QueryRequestExpandStrategy string

// QueryResponses Responses from multiple query operations.
type QueryResponses struct {
	Responses []QueryResult `json:"responses,omitempty,omitzero"`
}

// QueryResult Result of a query operation as an array of results and a count.
type QueryResult struct {
	// Analyses Analysis results like PCA and t-SNE per index embeddings.
	Analyses map[string]AnalysesResult `json:"analyses,omitempty,omitzero"`

	// Error Error message if the query failed.
	Error  string                 `json:"error,omitempty,omitzero"`
	Facets map[string]FacetResult `json:"facets,omitempty,omitzero"`

	// GraphResults Results from declarative graph queries.
	GraphResults map[string]GraphQueryResult `json:"graph_results,omitempty,omitzero"`

	// Hits A list of query hits.
	Hits QueryHits `json:"hits"`

	// Status HTTP status code of the query operation.
	Status int32 `json:"status"`

	// Table Which table this result came from
	Table string `json:"table,omitempty,omitzero"`

	// Took Duration of the query in milliseconds.
	Took time.Duration `json:"took"`
}

// QueryStrategy Strategy for query transformation and retrieval:
// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
type QueryStrategy string

// QueryStringQuery defines model for QueryStringQuery.
type QueryStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Query string `json:"query"`
}

// RAGRequest defines model for RAGRequest.
type RAGRequest struct {
	// Chain Chain of generators with retry/fallback semantics. Mutually exclusive with 'generator'.
	// Each link can specify retry configuration and a condition for trying the next generator.
	// Either 'generator' or 'chain' must be provided.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Eval Configuration for inline evaluation of query results.
	// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
	Eval EvalConfig `json:"eval,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// Prompt Optional custom user prompt template for the LLM. If not provided, a default prompt is used.
	// The prompt can reference the following variables:
	// - {{documents}}: Array of retrieved documents with id and fields
	// - {{semantic_search}}: The user's semantic search query (if provided)
	// You can use Handlebars template syntax to customize the prompt, including loops and conditionals.
	// To generate a comma-separated list of document IDs, use: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	Prompt string `json:"prompt,omitempty,omitzero"`

	// Queries Array of retrieval queries to execute. Each query must specify a table and can specify its own limit and document_renderer.
	// Results from all queries are concatenated together (respecting each query's limit).
	// For single table: [{"table": "papers", "semantic_search": "...", "limit": 10}]
	// For broadcast: [{"table": "images", "limit": 5, ...}, {"table": "products", "limit": 5, ...}]
	// For mixed: [{"table": "papers", "semantic_search": "...", "limit": 10}, {"table": "books", "full_text_search": {...}, "limit": 5}]
	Queries []QueryRequest `json:"queries"`

	// SystemPrompt Optional system prompt to guide the summarization
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// RAGResult RAG result with individual query results and summary
type RAGResult struct {
	// EvalResult Complete evaluation result
	EvalResult EvalResult `json:"eval_result,omitempty,omitzero"`

	// QueryResults Results from each query. Check each result's status and error fields for failures.
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`

	// SummaryResult Result of a summarization operation. The summary is formatted as markdown with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
	SummaryResult SummarizeResult `json:"summary_result,omitempty,omitzero"`
}

// RegexpQuery defines model for RegexpQuery.
type RegexpQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Regexp string `json:"regexp"`
}

// RerankerConfig defines model for RerankerConfig.
type RerankerConfig struct {
	// Field Field name to extract from documents for reranking.
	Field string `json:"field,omitempty,omitzero"`

	// Provider The reranking provider to use.
	Provider RerankerProvider `json:"provider"`

	// Template Handlebars template to render document text for reranking.
	Template string `json:"template,omitempty,omitzero"`
	union    json.RawMessage
}

// RerankerProvider The reranking provider to use.
type RerankerProvider string

// ResourceType Type of the resource, e.g., table, user, or global ('*').
type ResourceType string

// RestoreRequest defines model for RestoreRequest.
type RestoreRequest = BackupRequest

// RetryConfig Retry configuration for generator calls
type RetryConfig struct {
	// BackoffMultiplier Multiplier for exponential backoff
	BackoffMultiplier float32 `json:"backoff_multiplier,omitempty,omitzero"`

	// InitialBackoffMs Initial backoff delay in milliseconds
	InitialBackoffMs int `json:"initial_backoff_ms,omitempty,omitzero"`

	// MaxAttempts Maximum number of retry attempts
	MaxAttempts int `json:"max_attempts,omitempty,omitzero"`

	// MaxBackoffMs Maximum backoff delay in milliseconds
	MaxBackoffMs int `json:"max_backoff_ms,omitempty,omitzero"`
}

// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
type RouteType string

// ScanKeysRequest Request to scan keys in a table within a key range.
// If no range is specified, scans all keys in the table.
type ScanKeysRequest struct {
	// ExclusiveTo If true, exclude keys matching 'to' from the results.
	// Default: false (inclusive upper bound).
	ExclusiveTo bool `json:"exclusive_to,omitempty,omitzero"`

	// Fields List of fields to include in each result. If not specified,
	// only returns the key. Supports:
	// - Simple fields: "title", "author"
	// - Nested paths: "user.address.city"
	// - Wildcards: "_chunks.*"
	// - Exclusions: "-_chunks.*._embedding"
	// - Special fields: "_embeddings", "_summaries", "_chunks"
	Fields []string `json:"fields,omitempty,omitzero"`

	// FilterQuery Bleve query to filter documents. Only documents matching this query
	// are included in results. Uses the sear library for efficient per-document
	// matching without requiring a full index.
	//
	// Examples:
	// - Status filtering: `{"query": "status:published"}`
	// - Date ranges: `{"query": "created_at:>2023-01-01"}`
	// - Field matching: `{"query": "category:technology"}`
	FilterQuery json.RawMessage `json:"filter_query,omitempty,omitzero"`

	// From Start of the key range to scan (exclusive by default).
	// Can be a full key or a prefix. If not specified, starts from
	// the beginning of the table.
	From string `json:"from,omitempty,omitzero"`

	// InclusiveFrom If true, include keys matching 'from' in the results.
	// Default: false (exclusive lower bound for pagination).
	InclusiveFrom bool `json:"inclusive_from,omitempty,omitzero"`

	// Limit Maximum number of results to return. If not specified, returns all
	// matching keys in the range. Useful for pagination or sampling.
	Limit int `json:"limit,omitempty,omitzero"`

	// To End of the key range to scan (inclusive by default).
	// Can be a full key or a prefix. If not specified, scans to
	// the end of the table.
	To string `json:"to,omitempty,omitzero"`
}

// SemanticQueryMode Mode for semantic query generation:
// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
type SemanticQueryMode string

// SerperSearchConfig defines model for SerperSearchConfig.
type SerperSearchConfig struct {
	// ApiKey Serper API key (or set SERPER_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// SearchType Type of search to perform
	SearchType SerperSearchConfigSearchType `json:"search_type,omitempty,omitzero"`

	// TimePeriod Time period filter: d=day, w=week, m=month, y=year
	TimePeriod SerperSearchConfigTimePeriod `json:"time_period,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// SerperSearchConfigSearchType Type of search to perform
type SerperSearchConfigSearchType string

// SerperSearchConfigTimePeriod Time period filter: d=day, w=week, m=month, y=year
type SerperSearchConfigTimePeriod string

// ShardConfig defines model for ShardConfig.
type ShardConfig struct {
	ByteRange ByteRange `json:"byte_range"`
}

// StorageStatus defines model for StorageStatus.
type StorageStatus struct {
	// DiskUsage Disk usage in bytes.
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Empty Whether the table has received data.
	Empty bool `json:"empty,omitempty,omitzero"`
}

// SuccessMessage defines model for SuccessMessage.
type SuccessMessage struct {
	Message string `json:"message,omitempty,omitzero"`
}

// SummarizeResult Result of a summarization operation. The summary is formatted as markdown with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
type SummarizeResult struct {
	// Summary The generated summary text in markdown format with inline resource references like [resource_id res1] or [resource_id res1, res2]
	Summary string `json:"summary"`
}

// SyncLevel Synchronization level for batch operations:
// - "propose": Wait for Raft proposal acceptance (fastest, default)
// - "write": Wait for Pebble KV write
// - "full_text": Wait for full-text index WAL write
// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
type SyncLevel string

// Table defines model for Table.
type Table struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema            `json:"schema,omitempty,omitzero"`
	Shards map[string]ShardConfig `json:"shards"`
}

// TableBackupStatus defines model for TableBackupStatus.
type TableBackupStatus struct {
	// Error Error message if backup failed
	Error string `json:"error,omitempty,omitzero"`

	// Name Table name
	Name string `json:"name"`

	// Status Backup status for this table
	Status TableBackupStatusStatus `json:"status"`
}

// TableBackupStatusStatus Backup status for this table
type TableBackupStatusStatus string

// TableRestoreStatus defines model for TableRestoreStatus.
type TableRestoreStatus struct {
	// Error Error message if restore failed
	Error string `json:"error,omitempty,omitzero"`

	// Name Table name
	Name string `json:"name"`

	// Status Restore status for this table
	Status TableRestoreStatusStatus `json:"status"`
}

// TableRestoreStatusStatus Restore status for this table
type TableRestoreStatusStatus string

// TableSchema Schema definition for a table with multiple document types
type TableSchema struct {
	// DefaultType Default type to use from the document_types.
	DefaultType string `json:"default_type,omitempty,omitzero"`

	// DocumentSchemas A map of type names to their document json schemas.
	DocumentSchemas map[string]DocumentSchema `json:"document_schemas,omitempty,omitzero"`

	// EnforceTypes Whether to enforce that documents must match one of the provided document types.
	// If false, documents not matching any type will be accepted but not indexed.
	EnforceTypes bool `json:"enforce_types,omitempty,omitzero"`

	// TtlDuration The duration after which documents should expire, based on the ttl_field timestamp (optional).
	// Uses Go duration format (e.g., '24h', '7d', '168h').
	TtlDuration string `json:"ttl_duration,omitempty,omitzero"`

	// TtlField The field containing the timestamp for TTL expiration (optional).
	// Defaults to "_timestamp" if ttl_duration is specified but ttl_field is not.
	TtlField string `json:"ttl_field,omitempty,omitzero"`

	// Version Version of the schema. Used for migrations.
	Version uint32 `json:"version,omitempty,omitzero"`
}

// TableStatus defines model for TableStatus.
type TableStatus struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema        TableSchema            `json:"schema,omitempty,omitzero"`
	Shards        map[string]ShardConfig `json:"shards"`
	StorageStatus StorageStatus          `json:"storage_status"`
}

// TavilySearchConfig defines model for TavilySearchConfig.
type TavilySearchConfig struct {
	// ApiKey Tavily API key (or set TAVILY_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// ExcludeDomains Exclude results from these domains
	ExcludeDomains []string `json:"exclude_domains,omitempty,omitzero"`

	// IncludeAnswer Include AI-generated answer summary
	IncludeAnswer bool `json:"include_answer,omitempty,omitzero"`

	// IncludeDomains Only include results from these domains
	IncludeDomains []string `json:"include_domains,omitempty,omitzero"`

	// IncludeRawContent Include raw HTML content of pages
	IncludeRawContent bool `json:"include_raw_content,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// SearchDepth Search depth:
	// - basic: Fast search with standard results
	// - advanced: Deeper search with more comprehensive results
	SearchDepth TavilySearchConfigSearchDepth `json:"search_depth,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// TavilySearchConfigSearchDepth Search depth:
// - basic: Fast search with standard results
// - advanced: Deeper search with more comprehensive results
type TavilySearchConfigSearchDepth string

// TermFacetResult defines model for TermFacetResult.
type TermFacetResult struct {
	Count int    `json:"count"`
	Term  string `json:"term"`
}

// TermQuery defines model for TermQuery.
type TermQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
	Term  string `json:"term"`
}

// TermRangeQuery defines model for TermRangeQuery.
type TermRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost  `json:"boost,omitzero"`
	Field        string `json:"field,omitempty,omitzero"`
	InclusiveMax bool   `json:"inclusive_max,omitzero"`
	InclusiveMin bool   `json:"inclusive_min,omitzero"`
	Max          string `json:"max,omitzero"`
	Min          string `json:"min,omitzero"`
}

// TermiteChunkerConfig defines model for TermiteChunkerConfig.
type TermiteChunkerConfig struct {
	// ApiUrl The URL of the Termite API endpoint (e.g., 'http://localhost:8080'). Can also be set via ANTFLY_TERMITE_URL environment variable.
	ApiUrl string `json:"api_url,omitempty,omitzero"`

	// FullText Configuration for full-text indexing of chunks in Bleve.
	// When present (even if empty), chunks will be stored with :cft: suffix and indexed in Bleve's _chunks field.
	// When absent, chunks use :c: suffix and are only used for vector embeddings.
	// This object is reserved for future options like boosting, field mapping, etc.
	FullText map[string]interface{} `json:"full_text,omitempty,omitzero"`

	// MaxChunks Maximum number of chunks to generate per document.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// Model The chunking model to use. Either 'fixed' for simple token-based chunking, or a model name from models/chunkers/{name}/.
	Model string `json:"model"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries. Only used by fixed-size chunkers.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs). Only used by fixed-size chunkers.
	Separator string `json:"separator,omitempty,omitzero"`

	// TargetTokens Target number of tokens per chunk.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`

	// Threshold Minimum confidence threshold for separator detection (0.0-1.0). Only used by ONNX models.
	Threshold float32 `json:"threshold,omitempty,omitzero"`
}

// TermiteRerankerConfig Configuration for the Termite reranking provider.
type TermiteRerankerConfig struct {
	// Model The name of the reranking model (e.g., cross-encoder model name).
	Model string `json:"model"`

	// Url The URL of the Termite API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// Transform In-place document transformation using MongoDB-style operators. Transforms are applied atomically
// at the storage layer, eliminating read-modify-write races.
//
// **Important:** Transform results are NOT validated against the table schema. This improves performance
// but means it's possible to create invalid documents. Use with care and ensure your operations maintain
// schema compliance.
type Transform struct {
	// Key Document key (must be a string, not an object like inserts)
	Key string `json:"key"`

	// Operations List of operations to apply in sequence
	Operations []TransformOp `json:"operations"`

	// Upsert If true, create document if it doesn't exist (like MongoDB upsert)
	Upsert bool `json:"upsert,omitempty,omitzero"`
}

// TransformOp defines model for TransformOp.
type TransformOp struct {
	// Op MongoDB-style update operator
	Op TransformOpType `json:"op"`

	// Path JSONPath to field (e.g., "$.user.name", "$.tags", or "user.name")
	Path string `json:"path"`

	// Value Value for operation (not required for $unset, $currentDate). Type depends on operator (number for $inc/$mul, any for $set, etc.)
	Value interface{} `json:"value,omitempty,omitzero"`
}

// TransformOpType MongoDB-style update operator
type TransformOpType string

// TraversalResult A single result from graph traversal
type TraversalResult struct {
	// Depth Distance from start node (0 = start node)
	Depth int `json:"depth"`

	// Document Document data (if loaded)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Key Base64-encoded document key
	Key []byte `json:"key"`

	// Path Sequence of keys from start to this node (if include_paths=true)
	Path [][]byte `json:"path,omitempty,omitzero"`

	// PathEdges Sequence of edges from start to this node (if include_paths=true)
	PathEdges []Edge `json:"path_edges,omitempty,omitzero"`

	// TotalWeight Product of edge weights along the path
	TotalWeight float64 `json:"total_weight,omitempty,omitzero"`
}

// TraversalRules Rules for graph traversal
type TraversalRules struct {
	// DeduplicateNodes Visit each node only once
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter edges by type (empty = all types)
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information in results
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth (0 = unlimited)
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum results to return (0 = unlimited)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight filter
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight filter
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`
}

// TraverseResponse defines model for TraverseResponse.
type TraverseResponse struct {
	// Count Total number of results
	Count   int               `json:"count,omitempty,omitzero"`
	Results []TraversalResult `json:"results,omitempty,omitzero"`
}

// UpdatePasswordRequest defines model for UpdatePasswordRequest.
type UpdatePasswordRequest struct {
	NewPassword string `json:"new_password"`
}

// User defines model for User.
type User struct {
	// PasswordHash Base64 encoded password hash. Exposing this is a security risk.
	PasswordHash []byte `json:"password_hash"`
	Username     string `json:"username"`
}

// VertexEmbedderConfig Configuration for Google Cloud Vertex AI embedding models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication. Requires IAM role `roles/aiplatform.user`.
//
// **Example Models:** gemini-embedding-001 (default, 3072 dims), multimodalembedding (images/audio/video)
//
// **Docs:** https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings
type VertexEmbedderConfig struct {
	// CredentialsPath Path to service account JSON key file. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Dimension The dimension of the embedding vector (768, 1536, or 3072 for gemini-embedding-001; 128-1408 for multimodalembedding).
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the Vertex AI embedding model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`
}

// VertexGeneratorConfig Configuration for Google Cloud Vertex AI generative models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication. In GCP environments
// (Cloud Run, GKE, Compute Engine) this is automatic. For local dev, run
// `gcloud auth application-default login`. Requires IAM role `roles/aiplatform.user`.
//
// **Example Models:** gemini-2.5-flash (default), gemini-2.5-pro, gemini-3.0-pro
//
// **Docs:** https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models
type VertexGeneratorConfig struct {
	// CredentialsPath Path to service account JSON key file. Sets GOOGLE_APPLICATION_CREDENTIALS environment variable. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Vertex AI model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// VertexRerankerConfig Configuration for the Google Vertex AI Ranking API.
//
// Uses Application Default Credentials (ADC) or explicit credentials path.
//
// **Prerequisites:**
// - Enable Discovery Engine API: `gcloud services enable discoveryengine.googleapis.com`
// - Grant IAM role: `roles/discoveryengine.admin` (includes `discoveryengine.rankingConfigs.rank` permission)
//
// **Models:** semantic-ranker-default@latest (default), semantic-ranker-fast-004
//
// **Docs:** https://cloud.google.com/generative-ai-app-builder/docs/ranking
//
// **IAM:** https://cloud.google.com/generative-ai-app-builder/docs/access-control
type VertexRerankerConfig struct {
	// CredentialsPath Path to service account JSON file. Falls back to GOOGLE_APPLICATION_CREDENTIALS environment variable.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Model The ranking model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Falls back to GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// TopN Maximum number of records to return. If not specified, returns all documents with scores.
	TopN int `json:"top_n,omitempty,omitzero"`
}

// WebSearchConfig A unified configuration for web search providers.
//
// Each provider has specific configuration requirements. Use the appropriate
// provider-specific config or set common options at the top level.
//
// **Environment Variables (fallbacks):**
// - GOOGLE_CSE_API_KEY, GOOGLE_CSE_ID
// - BING_SEARCH_API_KEY
// - SERPER_API_KEY
// - TAVILY_API_KEY
// - BRAVE_API_KEY
type WebSearchConfig struct {
	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// WebSearchProvider The web search provider to use.
//
// - **google**: Google Custom Search API (requires CSE setup)
// - **bing**: Microsoft Bing Web Search API
// - **serper**: Serper.dev Google Search API (simpler setup)
// - **tavily**: Tavily AI Search API (optimized for RAG)
// - **brave**: Brave Search API
// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
type WebSearchProvider string

// WildcardQuery defines model for WildcardQuery.
type WildcardQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Field    string `json:"field,omitempty,omitzero"`
	Wildcard string `json:"wildcard"`
}

// SchemasChatAgentResult Result from the chat agent. Contains the assistant's response,
// any pending clarifications, applied filters, and conversation state.
type SchemasChatAgentResult struct {
	// Answer Final answer text (if available)
	Answer string `json:"answer,omitempty,omitzero"`

	// AnswerConfidence Confidence in the answer
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// AppliedFilters Filters that have been applied in this conversation
	AppliedFilters []FilterSpec `json:"applied_filters,omitempty,omitzero"`

	// Messages Updated conversation history including the assistant's response
	Messages []ChatMessage `json:"messages"`

	// PendingClarification A request for clarification from the user
	PendingClarification ClarificationRequest `json:"pending_clarification,omitempty,omitzero"`

	// QueryResults Search results from executed queries
	QueryResults []map[string]interface{} `json:"query_results,omitempty,omitzero"`

	// ToolCallsMade Number of tool calls made in this turn
	ToolCallsMade int `json:"tool_calls_made,omitempty,omitzero"`
}

// UserNamePathParameter defines model for UserNamePathParameter.
type UserNamePathParameter = string

// BadRequest defines model for BadRequest.
type BadRequest = Error

// InternalServerError defines model for InternalServerError.
type InternalServerError = Error

// NotFound defines model for NotFound.
type NotFound = Error

// ListBackupsParams defines parameters for ListBackups.
type ListBackupsParams struct {
	// Location Storage location to search for backups.
	// - Local filesystem: `file:///path/to/backup`
	// - Amazon S3: `s3://bucket-name/path/to/backup`
	Location string `form:"location" json:"location"`
}

// ListTablesParams defines parameters for ListTables.
type ListTablesParams struct {
	// Prefix Filter tables by name prefix (e.g., "prod_")
	Prefix string `form:"prefix,omitempty" json:"prefix,omitempty,omitzero"`

	// Pattern Filter tables by regex pattern (e.g., "^prod_.*_v[0-9]+$")
	Pattern string `form:"pattern,omitempty" json:"pattern,omitempty,omitzero"`
}

// LookupKeyParams defines parameters for LookupKey.
type LookupKeyParams struct {
	// Fields Comma-separated list of fields to include in the response.
	// If not specified, returns the full document. Supports:
	// - Simple fields: "title,author"
	// - Nested paths: "user.address.city"
	// - Wildcards: "_chunks.*"
	// - Exclusions: "-_chunks.*._embedding"
	// - Special fields: "_embeddings,_summaries,_chunks"
	Fields string `form:"fields,omitempty" json:"fields,omitempty,omitzero"`
}

// RemovePermissionFromUserParams defines parameters for RemovePermissionFromUser.
type RemovePermissionFromUserParams struct {
	// Resource The name of the resource for the permission to be removed.
	Resource string `form:"resource" json:"resource"`

	// ResourceType The type of the resource for the permission to be removed.
	ResourceType ResourceType `form:"resourceType" json:"resourceType"`
}

// AnswerAgentJSONRequestBody defines body for AnswerAgent for application/json ContentType.
type AnswerAgentJSONRequestBody = AnswerAgentRequest

// ChatAgentJSONRequestBody defines body for ChatAgent for application/json ContentType.
type ChatAgentJSONRequestBody = ChatAgentRequest

// QueryBuilderAgentJSONRequestBody defines body for QueryBuilderAgent for application/json ContentType.
type QueryBuilderAgentJSONRequestBody = QueryBuilderRequest

// BackupJSONRequestBody defines body for Backup for application/json ContentType.
type BackupJSONRequestBody = ClusterBackupRequest

// EvaluateJSONRequestBody defines body for Evaluate for application/json ContentType.
type EvaluateJSONRequestBody = EvalRequest

// GlobalQueryJSONRequestBody defines body for GlobalQuery for application/json ContentType.
type GlobalQueryJSONRequestBody = QueryRequest

// RagQueryJSONRequestBody defines body for RagQuery for application/json ContentType.
type RagQueryJSONRequestBody = RAGRequest

// RestoreJSONRequestBody defines body for Restore for application/json ContentType.
type RestoreJSONRequestBody = ClusterRestoreRequest

// CreateTableJSONRequestBody defines body for CreateTable for application/json ContentType.
type CreateTableJSONRequestBody = CreateTableRequest

// BackupTableJSONRequestBody defines body for BackupTable for application/json ContentType.
type BackupTableJSONRequestBody = BackupRequest

// BatchJSONRequestBody defines body for Batch for application/json ContentType.
type BatchJSONRequestBody = BatchRequest

// CreateIndexJSONRequestBody defines body for CreateIndex for application/json ContentType.
type CreateIndexJSONRequestBody = IndexConfig

// ScanKeysJSONRequestBody defines body for ScanKeys for application/json ContentType.
type ScanKeysJSONRequestBody = ScanKeysRequest

// LinearMergeJSONRequestBody defines body for LinearMerge for application/json ContentType.
type LinearMergeJSONRequestBody = LinearMergeRequest

// QueryTableJSONRequestBody defines body for QueryTable for application/json ContentType.
type QueryTableJSONRequestBody = QueryRequest

// TableRagQueryJSONRequestBody defines body for TableRagQuery for application/json ContentType.
type TableRagQueryJSONRequestBody = RAGRequest

// RestoreTableJSONRequestBody defines body for RestoreTable for application/json ContentType.
type RestoreTableJSONRequestBody = RestoreRequest

// UpdateSchemaJSONRequestBody defines body for UpdateSchema for application/json ContentType.
type UpdateSchemaJSONRequestBody = TableSchema

// CreateUserJSONRequestBody defines body for CreateUser for application/json ContentType.
type CreateUserJSONRequestBody = CreateUserRequest

// UpdateUserPasswordJSONRequestBody defines body for UpdateUserPassword for application/json ContentType.
type UpdateUserPasswordJSONRequestBody = UpdatePasswordRequest

// AddPermissionToUserJSONRequestBody defines body for AddPermissionToUser for application/json ContentType.
type AddPermissionToUserJSONRequestBody = Permission

// Getter for additional properties for ClusterStatus. Returns the specified
// element and whether it was found
func (a ClusterStatus) Get(fieldName string) (value interface{}, found bool) {
	if a.AdditionalProperties != nil {
		value, found = a.AdditionalProperties[fieldName]
	}
	return
}

// Setter for additional properties for ClusterStatus
func (a *ClusterStatus) Set(fieldName string, value interface{}) {
	if a.AdditionalProperties == nil {
		a.AdditionalProperties = make(map[string]interface{})
	}
	a.AdditionalProperties[fieldName] = value
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a *ClusterStatus) UnmarshalJSON(b []byte) error {
	object := make(map[string]json.RawMessage)
	err := json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["auth_enabled"]; found {
		err = json.Unmarshal(raw, &a.AuthEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'auth_enabled': %w", err)
		}
		delete(object, "auth_enabled")
	}

	if raw, found := object["health"]; found {
		err = json.Unmarshal(raw, &a.Health)
		if err != nil {
			return fmt.Errorf("error reading 'health': %w", err)
		}
		delete(object, "health")
	}

	if raw, found := object["message"]; found {
		err = json.Unmarshal(raw, &a.Message)
		if err != nil {
			return fmt.Errorf("error reading 'message': %w", err)
		}
		delete(object, "message")
	}

	if len(object) != 0 {
		a.AdditionalProperties = make(map[string]interface{})
		for fieldName, fieldBuf := range object {
			var fieldVal interface{}
			err := json.Unmarshal(fieldBuf, &fieldVal)
			if err != nil {
				return fmt.Errorf("error unmarshaling field %s: %w", fieldName, err)
			}
			a.AdditionalProperties[fieldName] = fieldVal
		}
	}
	return nil
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a ClusterStatus) MarshalJSON() ([]byte, error) {
	var err error
	object := make(map[string]json.RawMessage)

	object["auth_enabled"], err = json.Marshal(a.AuthEnabled)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'auth_enabled': %w", err)
	}

	object["health"], err = json.Marshal(a.Health)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'health': %w", err)
	}

	object["message"], err = json.Marshal(a.Message)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'message': %w", err)
	}

	for fieldName, field := range a.AdditionalProperties {
		object[fieldName], err = json.Marshal(field)
		if err != nil {
			return nil, fmt.Errorf("error marshaling '%s': %w", fieldName, err)
		}
	}
	return json.Marshal(object)
}

// AsTermiteChunkerConfig returns the union data inside the ChunkerConfig as a TermiteChunkerConfig
func (t ChunkerConfig) AsTermiteChunkerConfig() (TermiteChunkerConfig, error) {
	var body TermiteChunkerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteChunkerConfig overwrites any union data inside the ChunkerConfig as the provided TermiteChunkerConfig
func (t *ChunkerConfig) FromTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteChunkerConfig performs a merge with any union data inside the ChunkerConfig, using the provided TermiteChunkerConfig
func (t *ChunkerConfig) MergeTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAntflyChunkerConfig returns the union data inside the ChunkerConfig as a AntflyChunkerConfig
func (t ChunkerConfig) AsAntflyChunkerConfig() (AntflyChunkerConfig, error) {
	var body AntflyChunkerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAntflyChunkerConfig overwrites any union data inside the ChunkerConfig as the provided AntflyChunkerConfig
func (t *ChunkerConfig) FromAntflyChunkerConfig(v AntflyChunkerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAntflyChunkerConfig performs a merge with any union data inside the ChunkerConfig, using the provided AntflyChunkerConfig
func (t *ChunkerConfig) MergeAntflyChunkerConfig(v AntflyChunkerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t ChunkerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *ChunkerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsGoogleEmbedderConfig returns the union data inside the EmbedderConfig as a GoogleEmbedderConfig
func (t EmbedderConfig) AsGoogleEmbedderConfig() (GoogleEmbedderConfig, error) {
	var body GoogleEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided GoogleEmbedderConfig
func (t *EmbedderConfig) FromGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided GoogleEmbedderConfig
func (t *EmbedderConfig) MergeGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexEmbedderConfig returns the union data inside the EmbedderConfig as a VertexEmbedderConfig
func (t EmbedderConfig) AsVertexEmbedderConfig() (VertexEmbedderConfig, error) {
	var body VertexEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided VertexEmbedderConfig
func (t *EmbedderConfig) FromVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided VertexEmbedderConfig
func (t *EmbedderConfig) MergeVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaEmbedderConfig returns the union data inside the EmbedderConfig as a OllamaEmbedderConfig
func (t EmbedderConfig) AsOllamaEmbedderConfig() (OllamaEmbedderConfig, error) {
	var body OllamaEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OllamaEmbedderConfig
func (t *EmbedderConfig) FromOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OllamaEmbedderConfig
func (t *EmbedderConfig) MergeOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIEmbedderConfig returns the union data inside the EmbedderConfig as a OpenAIEmbedderConfig
func (t EmbedderConfig) AsOpenAIEmbedderConfig() (OpenAIEmbedderConfig, error) {
	var body OpenAIEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) FromOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) MergeOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockEmbedderConfig returns the union data inside the EmbedderConfig as a BedrockEmbedderConfig
func (t EmbedderConfig) AsBedrockEmbedderConfig() (BedrockEmbedderConfig, error) {
	var body BedrockEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided BedrockEmbedderConfig
func (t *EmbedderConfig) FromBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided BedrockEmbedderConfig
func (t *EmbedderConfig) MergeBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereEmbedderConfig returns the union data inside the EmbedderConfig as a CohereEmbedderConfig
func (t EmbedderConfig) AsCohereEmbedderConfig() (CohereEmbedderConfig, error) {
	var body CohereEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided CohereEmbedderConfig
func (t *EmbedderConfig) FromCohereEmbedderConfig(v CohereEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided CohereEmbedderConfig
func (t *EmbedderConfig) MergeCohereEmbedderConfig(v CohereEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t EmbedderConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *EmbedderConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsFuzziness0 returns the union data inside the Fuzziness as a Fuzziness0
func (t Fuzziness) AsFuzziness0() (Fuzziness0, error) {
	var body Fuzziness0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness0 overwrites any union data inside the Fuzziness as the provided Fuzziness0
func (t *Fuzziness) FromFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness0 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness0
func (t *Fuzziness) MergeFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzziness1 returns the union data inside the Fuzziness as a Fuzziness1
func (t Fuzziness) AsFuzziness1() (Fuzziness1, error) {
	var body Fuzziness1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness1 overwrites any union data inside the Fuzziness as the provided Fuzziness1
func (t *Fuzziness) FromFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness1 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness1
func (t *Fuzziness) MergeFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Fuzziness) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Fuzziness) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsGoogleGeneratorConfig returns the union data inside the GeneratorConfig as a GoogleGeneratorConfig
func (t GeneratorConfig) AsGoogleGeneratorConfig() (GoogleGeneratorConfig, error) {
	var body GoogleGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided GoogleGeneratorConfig
func (t *GeneratorConfig) FromGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided GoogleGeneratorConfig
func (t *GeneratorConfig) MergeGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexGeneratorConfig returns the union data inside the GeneratorConfig as a VertexGeneratorConfig
func (t GeneratorConfig) AsVertexGeneratorConfig() (VertexGeneratorConfig, error) {
	var body VertexGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided VertexGeneratorConfig
func (t *GeneratorConfig) FromVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided VertexGeneratorConfig
func (t *GeneratorConfig) MergeVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaGeneratorConfig returns the union data inside the GeneratorConfig as a OllamaGeneratorConfig
func (t GeneratorConfig) AsOllamaGeneratorConfig() (OllamaGeneratorConfig, error) {
	var body OllamaGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OllamaGeneratorConfig
func (t *GeneratorConfig) FromOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OllamaGeneratorConfig
func (t *GeneratorConfig) MergeOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIGeneratorConfig returns the union data inside the GeneratorConfig as a OpenAIGeneratorConfig
func (t GeneratorConfig) AsOpenAIGeneratorConfig() (OpenAIGeneratorConfig, error) {
	var body OpenAIGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) FromOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) MergeOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockGeneratorConfig returns the union data inside the GeneratorConfig as a BedrockGeneratorConfig
func (t GeneratorConfig) AsBedrockGeneratorConfig() (BedrockGeneratorConfig, error) {
	var body BedrockGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided BedrockGeneratorConfig
func (t *GeneratorConfig) FromBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided BedrockGeneratorConfig
func (t *GeneratorConfig) MergeBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAnthropicGeneratorConfig returns the union data inside the GeneratorConfig as a AnthropicGeneratorConfig
func (t GeneratorConfig) AsAnthropicGeneratorConfig() (AnthropicGeneratorConfig, error) {
	var body AnthropicGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAnthropicGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) FromAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAnthropicGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) MergeAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereGeneratorConfig returns the union data inside the GeneratorConfig as a CohereGeneratorConfig
func (t GeneratorConfig) AsCohereGeneratorConfig() (CohereGeneratorConfig, error) {
	var body CohereGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided CohereGeneratorConfig
func (t *GeneratorConfig) FromCohereGeneratorConfig(v CohereGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided CohereGeneratorConfig
func (t *GeneratorConfig) MergeCohereGeneratorConfig(v CohereGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t GeneratorConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *GeneratorConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Config returns the union data inside the IndexConfig as a BleveIndexV2Config
func (t IndexConfig) AsBleveIndexV2Config() (BleveIndexV2Config, error) {
	var body BleveIndexV2Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Config overwrites any union data inside the IndexConfig as the provided BleveIndexV2Config
func (t *IndexConfig) FromBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Config performs a merge with any union data inside the IndexConfig, using the provided BleveIndexV2Config
func (t *IndexConfig) MergeBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexConfig returns the union data inside the IndexConfig as a EmbeddingIndexConfig
func (t IndexConfig) AsEmbeddingIndexConfig() (EmbeddingIndexConfig, error) {
	var body EmbeddingIndexConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexConfig overwrites any union data inside the IndexConfig as the provided EmbeddingIndexConfig
func (t *IndexConfig) FromEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexConfig performs a merge with any union data inside the IndexConfig, using the provided EmbeddingIndexConfig
func (t *IndexConfig) MergeEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Config returns the union data inside the IndexConfig as a GraphIndexV0Config
func (t IndexConfig) AsGraphIndexV0Config() (GraphIndexV0Config, error) {
	var body GraphIndexV0Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Config overwrites any union data inside the IndexConfig as the provided GraphIndexV0Config
func (t *IndexConfig) FromGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Config performs a merge with any union data inside the IndexConfig, using the provided GraphIndexV0Config
func (t *IndexConfig) MergeGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["description"], err = json.Marshal(t.Description)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'description': %w", err)
	}

	if t.Enrichments != nil {
		object["enrichments"], err = json.Marshal(t.Enrichments)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'enrichments': %w", err)
		}
	}

	object["name"], err = json.Marshal(t.Name)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'name': %w", err)
	}

	object["type"], err = json.Marshal(t.Type)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'type': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *IndexConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["description"]; found {
		err = json.Unmarshal(raw, &t.Description)
		if err != nil {
			return fmt.Errorf("error reading 'description': %w", err)
		}
	}

	if raw, found := object["enrichments"]; found {
		err = json.Unmarshal(raw, &t.Enrichments)
		if err != nil {
			return fmt.Errorf("error reading 'enrichments': %w", err)
		}
	}

	if raw, found := object["name"]; found {
		err = json.Unmarshal(raw, &t.Name)
		if err != nil {
			return fmt.Errorf("error reading 'name': %w", err)
		}
	}

	if raw, found := object["type"]; found {
		err = json.Unmarshal(raw, &t.Type)
		if err != nil {
			return fmt.Errorf("error reading 'type': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Stats returns the union data inside the IndexStats as a BleveIndexV2Stats
func (t IndexStats) AsBleveIndexV2Stats() (BleveIndexV2Stats, error) {
	var body BleveIndexV2Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Stats overwrites any union data inside the IndexStats as the provided BleveIndexV2Stats
func (t *IndexStats) FromBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Stats performs a merge with any union data inside the IndexStats, using the provided BleveIndexV2Stats
func (t *IndexStats) MergeBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexStats returns the union data inside the IndexStats as a EmbeddingIndexStats
func (t IndexStats) AsEmbeddingIndexStats() (EmbeddingIndexStats, error) {
	var body EmbeddingIndexStats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexStats overwrites any union data inside the IndexStats as the provided EmbeddingIndexStats
func (t *IndexStats) FromEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexStats performs a merge with any union data inside the IndexStats, using the provided EmbeddingIndexStats
func (t *IndexStats) MergeEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Stats returns the union data inside the IndexStats as a GraphIndexV0Stats
func (t IndexStats) AsGraphIndexV0Stats() (GraphIndexV0Stats, error) {
	var body GraphIndexV0Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Stats overwrites any union data inside the IndexStats as the provided GraphIndexV0Stats
func (t *IndexStats) FromGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Stats performs a merge with any union data inside the IndexStats, using the provided GraphIndexV0Stats
func (t *IndexStats) MergeGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexStats) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *IndexStats) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsTermQuery returns the union data inside the Query as a TermQuery
func (t Query) AsTermQuery() (TermQuery, error) {
	var body TermQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermQuery overwrites any union data inside the Query as the provided TermQuery
func (t *Query) FromTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermQuery performs a merge with any union data inside the Query, using the provided TermQuery
func (t *Query) MergeTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchQuery returns the union data inside the Query as a MatchQuery
func (t Query) AsMatchQuery() (MatchQuery, error) {
	var body MatchQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchQuery overwrites any union data inside the Query as the provided MatchQuery
func (t *Query) FromMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchQuery performs a merge with any union data inside the Query, using the provided MatchQuery
func (t *Query) MergeMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchPhraseQuery returns the union data inside the Query as a MatchPhraseQuery
func (t Query) AsMatchPhraseQuery() (MatchPhraseQuery, error) {
	var body MatchPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchPhraseQuery overwrites any union data inside the Query as the provided MatchPhraseQuery
func (t *Query) FromMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchPhraseQuery performs a merge with any union data inside the Query, using the provided MatchPhraseQuery
func (t *Query) MergeMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPhraseQuery returns the union data inside the Query as a PhraseQuery
func (t Query) AsPhraseQuery() (PhraseQuery, error) {
	var body PhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPhraseQuery overwrites any union data inside the Query as the provided PhraseQuery
func (t *Query) FromPhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePhraseQuery performs a merge with any union data inside the Query, using the provided PhraseQuery
func (t *Query) MergePhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMultiPhraseQuery returns the union data inside the Query as a MultiPhraseQuery
func (t Query) AsMultiPhraseQuery() (MultiPhraseQuery, error) {
	var body MultiPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMultiPhraseQuery overwrites any union data inside the Query as the provided MultiPhraseQuery
func (t *Query) FromMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMultiPhraseQuery performs a merge with any union data inside the Query, using the provided MultiPhraseQuery
func (t *Query) MergeMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzzyQuery returns the union data inside the Query as a FuzzyQuery
func (t Query) AsFuzzyQuery() (FuzzyQuery, error) {
	var body FuzzyQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzzyQuery overwrites any union data inside the Query as the provided FuzzyQuery
func (t *Query) FromFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzzyQuery performs a merge with any union data inside the Query, using the provided FuzzyQuery
func (t *Query) MergeFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPrefixQuery returns the union data inside the Query as a PrefixQuery
func (t Query) AsPrefixQuery() (PrefixQuery, error) {
	var body PrefixQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPrefixQuery overwrites any union data inside the Query as the provided PrefixQuery
func (t *Query) FromPrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePrefixQuery performs a merge with any union data inside the Query, using the provided PrefixQuery
func (t *Query) MergePrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsRegexpQuery returns the union data inside the Query as a RegexpQuery
func (t Query) AsRegexpQuery() (RegexpQuery, error) {
	var body RegexpQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromRegexpQuery overwrites any union data inside the Query as the provided RegexpQuery
func (t *Query) FromRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeRegexpQuery performs a merge with any union data inside the Query, using the provided RegexpQuery
func (t *Query) MergeRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsWildcardQuery returns the union data inside the Query as a WildcardQuery
func (t Query) AsWildcardQuery() (WildcardQuery, error) {
	var body WildcardQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromWildcardQuery overwrites any union data inside the Query as the provided WildcardQuery
func (t *Query) FromWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeWildcardQuery performs a merge with any union data inside the Query, using the provided WildcardQuery
func (t *Query) MergeWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsQueryStringQuery returns the union data inside the Query as a QueryStringQuery
func (t Query) AsQueryStringQuery() (QueryStringQuery, error) {
	var body QueryStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromQueryStringQuery overwrites any union data inside the Query as the provided QueryStringQuery
func (t *Query) FromQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeQueryStringQuery performs a merge with any union data inside the Query, using the provided QueryStringQuery
func (t *Query) MergeQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsNumericRangeQuery returns the union data inside the Query as a NumericRangeQuery
func (t Query) AsNumericRangeQuery() (NumericRangeQuery, error) {
	var body NumericRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromNumericRangeQuery overwrites any union data inside the Query as the provided NumericRangeQuery
func (t *Query) FromNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeNumericRangeQuery performs a merge with any union data inside the Query, using the provided NumericRangeQuery
func (t *Query) MergeNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermRangeQuery returns the union data inside the Query as a TermRangeQuery
func (t Query) AsTermRangeQuery() (TermRangeQuery, error) {
	var body TermRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermRangeQuery overwrites any union data inside the Query as the provided TermRangeQuery
func (t *Query) FromTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermRangeQuery performs a merge with any union data inside the Query, using the provided TermRangeQuery
func (t *Query) MergeTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDateRangeStringQuery returns the union data inside the Query as a DateRangeStringQuery
func (t Query) AsDateRangeStringQuery() (DateRangeStringQuery, error) {
	var body DateRangeStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDateRangeStringQuery overwrites any union data inside the Query as the provided DateRangeStringQuery
func (t *Query) FromDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDateRangeStringQuery performs a merge with any union data inside the Query, using the provided DateRangeStringQuery
func (t *Query) MergeDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBooleanQuery returns the union data inside the Query as a BooleanQuery
func (t Query) AsBooleanQuery() (BooleanQuery, error) {
	var body BooleanQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBooleanQuery overwrites any union data inside the Query as the provided BooleanQuery
func (t *Query) FromBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBooleanQuery performs a merge with any union data inside the Query, using the provided BooleanQuery
func (t *Query) MergeBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsConjunctionQuery returns the union data inside the Query as a ConjunctionQuery
func (t Query) AsConjunctionQuery() (ConjunctionQuery, error) {
	var body ConjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromConjunctionQuery overwrites any union data inside the Query as the provided ConjunctionQuery
func (t *Query) FromConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeConjunctionQuery performs a merge with any union data inside the Query, using the provided ConjunctionQuery
func (t *Query) MergeConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDisjunctionQuery returns the union data inside the Query as a DisjunctionQuery
func (t Query) AsDisjunctionQuery() (DisjunctionQuery, error) {
	var body DisjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDisjunctionQuery overwrites any union data inside the Query as the provided DisjunctionQuery
func (t *Query) FromDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDisjunctionQuery performs a merge with any union data inside the Query, using the provided DisjunctionQuery
func (t *Query) MergeDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchAllQuery returns the union data inside the Query as a MatchAllQuery
func (t Query) AsMatchAllQuery() (MatchAllQuery, error) {
	var body MatchAllQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchAllQuery overwrites any union data inside the Query as the provided MatchAllQuery
func (t *Query) FromMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchAllQuery performs a merge with any union data inside the Query, using the provided MatchAllQuery
func (t *Query) MergeMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchNoneQuery returns the union data inside the Query as a MatchNoneQuery
func (t Query) AsMatchNoneQuery() (MatchNoneQuery, error) {
	var body MatchNoneQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchNoneQuery overwrites any union data inside the Query as the provided MatchNoneQuery
func (t *Query) FromMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchNoneQuery performs a merge with any union data inside the Query, using the provided MatchNoneQuery
func (t *Query) MergeMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDocIdQuery returns the union data inside the Query as a DocIdQuery
func (t Query) AsDocIdQuery() (DocIdQuery, error) {
	var body DocIdQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDocIdQuery overwrites any union data inside the Query as the provided DocIdQuery
func (t *Query) FromDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDocIdQuery performs a merge with any union data inside the Query, using the provided DocIdQuery
func (t *Query) MergeDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBoolFieldQuery returns the union data inside the Query as a BoolFieldQuery
func (t Query) AsBoolFieldQuery() (BoolFieldQuery, error) {
	var body BoolFieldQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBoolFieldQuery overwrites any union data inside the Query as the provided BoolFieldQuery
func (t *Query) FromBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBoolFieldQuery performs a merge with any union data inside the Query, using the provided BoolFieldQuery
func (t *Query) MergeBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsIPRangeQuery returns the union data inside the Query as a IPRangeQuery
func (t Query) AsIPRangeQuery() (IPRangeQuery, error) {
	var body IPRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromIPRangeQuery overwrites any union data inside the Query as the provided IPRangeQuery
func (t *Query) FromIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeIPRangeQuery performs a merge with any union data inside the Query, using the provided IPRangeQuery
func (t *Query) MergeIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingBoxQuery returns the union data inside the Query as a GeoBoundingBoxQuery
func (t Query) AsGeoBoundingBoxQuery() (GeoBoundingBoxQuery, error) {
	var body GeoBoundingBoxQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingBoxQuery overwrites any union data inside the Query as the provided GeoBoundingBoxQuery
func (t *Query) FromGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingBoxQuery performs a merge with any union data inside the Query, using the provided GeoBoundingBoxQuery
func (t *Query) MergeGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoDistanceQuery returns the union data inside the Query as a GeoDistanceQuery
func (t Query) AsGeoDistanceQuery() (GeoDistanceQuery, error) {
	var body GeoDistanceQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoDistanceQuery overwrites any union data inside the Query as the provided GeoDistanceQuery
func (t *Query) FromGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoDistanceQuery performs a merge with any union data inside the Query, using the provided GeoDistanceQuery
func (t *Query) MergeGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingPolygonQuery returns the union data inside the Query as a GeoBoundingPolygonQuery
func (t Query) AsGeoBoundingPolygonQuery() (GeoBoundingPolygonQuery, error) {
	var body GeoBoundingPolygonQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingPolygonQuery overwrites any union data inside the Query as the provided GeoBoundingPolygonQuery
func (t *Query) FromGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingPolygonQuery performs a merge with any union data inside the Query, using the provided GeoBoundingPolygonQuery
func (t *Query) MergeGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoShapeQuery returns the union data inside the Query as a GeoShapeQuery
func (t Query) AsGeoShapeQuery() (GeoShapeQuery, error) {
	var body GeoShapeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoShapeQuery overwrites any union data inside the Query as the provided GeoShapeQuery
func (t *Query) FromGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoShapeQuery performs a merge with any union data inside the Query, using the provided GeoShapeQuery
func (t *Query) MergeGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Query) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Query) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsOllamaRerankerConfig returns the union data inside the RerankerConfig as a OllamaRerankerConfig
func (t RerankerConfig) AsOllamaRerankerConfig() (OllamaRerankerConfig, error) {
	var body OllamaRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaRerankerConfig overwrites any union data inside the RerankerConfig as the provided OllamaRerankerConfig
func (t *RerankerConfig) FromOllamaRerankerConfig(v OllamaRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided OllamaRerankerConfig
func (t *RerankerConfig) MergeOllamaRerankerConfig(v OllamaRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermiteRerankerConfig returns the union data inside the RerankerConfig as a TermiteRerankerConfig
func (t RerankerConfig) AsTermiteRerankerConfig() (TermiteRerankerConfig, error) {
	var body TermiteRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteRerankerConfig overwrites any union data inside the RerankerConfig as the provided TermiteRerankerConfig
func (t *RerankerConfig) FromTermiteRerankerConfig(v TermiteRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided TermiteRerankerConfig
func (t *RerankerConfig) MergeTermiteRerankerConfig(v TermiteRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereRerankerConfig returns the union data inside the RerankerConfig as a CohereRerankerConfig
func (t RerankerConfig) AsCohereRerankerConfig() (CohereRerankerConfig, error) {
	var body CohereRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereRerankerConfig overwrites any union data inside the RerankerConfig as the provided CohereRerankerConfig
func (t *RerankerConfig) FromCohereRerankerConfig(v CohereRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided CohereRerankerConfig
func (t *RerankerConfig) MergeCohereRerankerConfig(v CohereRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexRerankerConfig returns the union data inside the RerankerConfig as a VertexRerankerConfig
func (t RerankerConfig) AsVertexRerankerConfig() (VertexRerankerConfig, error) {
	var body VertexRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexRerankerConfig overwrites any union data inside the RerankerConfig as the provided VertexRerankerConfig
func (t *RerankerConfig) FromVertexRerankerConfig(v VertexRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided VertexRerankerConfig
func (t *RerankerConfig) MergeVertexRerankerConfig(v VertexRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t RerankerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["field"], err = json.Marshal(t.Field)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'field': %w", err)
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	object["template"], err = json.Marshal(t.Template)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'template': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *RerankerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["field"]; found {
		err = json.Unmarshal(raw, &t.Field)
		if err != nil {
			return fmt.Errorf("error reading 'field': %w", err)
		}
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	if raw, found := object["template"]; found {
		err = json.Unmarshal(raw, &t.Template)
		if err != nil {
			return fmt.Errorf("error reading 'template': %w", err)
		}
	}

	return err
}

// RequestEditorFn  is the function signature for the RequestEditor callback function
type RequestEditorFn func(ctx context.Context, req *http.Request) error

// Doer performs HTTP requests.
//
// The standard http.Client implements this interface.
type HttpRequestDoer interface {
	Do(req *http.Request) (*http.Response, error)
}

// Client which conforms to the OpenAPI3 specification for this service.
type Client struct {
	// The endpoint of the server conforming to this interface, with scheme,
	// https://api.deepmap.com for example. This can contain a path relative
	// to the server, such as https://api.deepmap.com/dev-test, and all the
	// paths in the swagger spec will be appended to the server.
	Server string

	// Doer for performing requests, typically a *http.Client with any
	// customized settings, such as certificate chains.
	Client HttpRequestDoer

	// A list of callbacks for modifying requests which are generated before sending over
	// the network.
	RequestEditors []RequestEditorFn
}

// ClientOption allows setting custom parameters during construction
type ClientOption func(*Client) error

// Creates a new Client, with reasonable defaults
func NewClient(server string, opts ...ClientOption) (*Client, error) {
	// create a client with sane default values
	client := Client{
		Server: server,
	}
	// mutate client and add all optional params
	for _, o := range opts {
		if err := o(&client); err != nil {
			return nil, err
		}
	}
	// ensure the server URL always has a trailing slash
	if !strings.HasSuffix(client.Server, "/") {
		client.Server += "/"
	}
	// create httpClient, if not already present
	if client.Client == nil {
		client.Client = &http.Client{}
	}
	return &client, nil
}

// WithHTTPClient allows overriding the default Doer, which is
// automatically created using http.Client. This is useful for tests.
func WithHTTPClient(doer HttpRequestDoer) ClientOption {
	return func(c *Client) error {
		c.Client = doer
		return nil
	}
}

// WithRequestEditorFn allows setting up a callback function, which will be
// called right before sending the request. This can be used to mutate the request.
func WithRequestEditorFn(fn RequestEditorFn) ClientOption {
	return func(c *Client) error {
		c.RequestEditors = append(c.RequestEditors, fn)
		return nil
	}
}

// The interface specification for the client above.
type ClientInterface interface {
	// AnswerAgentWithBody request with any body
	AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ChatAgentWithBody request with any body
	ChatAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	ChatAgent(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// QueryBuilderAgentWithBody request with any body
	QueryBuilderAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	QueryBuilderAgent(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BackupWithBody request with any body
	BackupWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Backup(ctx context.Context, body BackupJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListBackups request
	ListBackups(ctx context.Context, params *ListBackupsParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// EvaluateWithBody request with any body
	EvaluateWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Evaluate(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GlobalQueryWithBody request with any body
	GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RagQueryWithBody request with any body
	RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RestoreWithBody request with any body
	RestoreWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Restore(ctx context.Context, body RestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetStatus request
	GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListTables request
	ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropTable request
	DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetTable request
	GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateTableWithBody request with any body
	CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BackupTableWithBody request with any body
	BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BatchWithBody request with any body
	BatchWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Batch(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListIndexes request
	ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropIndex request
	DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetIndex request
	GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateIndexWithBody request with any body
	CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ScanKeysWithBody request with any body
	ScanKeysWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	ScanKeys(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LookupKey request
	LookupKey(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LinearMergeWithBody request with any body
	LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// QueryTableWithBody request with any body
	QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// TableRagQueryWithBody request with any body
	TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RestoreTableWithBody request with any body
	RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateSchemaWithBody request with any body
	UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListUsers request
	ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetCurrentUser request
	GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteUser request
	DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserByName request
	GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateUserWithBody request with any body
	CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateUserPasswordWithBody request with any body
	UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RemovePermissionFromUser request
	RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserPermissions request
	GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// AddPermissionToUserWithBody request with any body
	AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)
}

func (c *Client) AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ChatAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewChatAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ChatAgent(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewChatAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryBuilderAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryBuilderAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryBuilderAgent(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryBuilderAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Backup(ctx context.Context, body BackupJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListBackups(ctx context.Context, params *ListBackupsParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListBackupsRequest(c.Server, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) EvaluateWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewEvaluateRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Evaluate(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewEvaluateRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Restore(ctx context.Context, body RestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetStatusRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListTablesRequest(c.Server, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BatchWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Batch(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListIndexesRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequestWithBody(c.Server, tableName, indexName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequest(c.Server, tableName, indexName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ScanKeysWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewScanKeysRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ScanKeys(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewScanKeysRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LookupKey(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLookupKeyRequest(c.Server, tableName, key, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListUsersRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetCurrentUserRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteUserRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserByNameRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRemovePermissionFromUserRequest(c.Server, userName, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserPermissionsRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

// NewAnswerAgentRequest calls the generic AnswerAgent builder with application/json body
func NewAnswerAgentRequest(server string, body AnswerAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAnswerAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewAnswerAgentRequestWithBody generates requests for AnswerAgent with any type of body
func NewAnswerAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/answer")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewChatAgentRequest calls the generic ChatAgent builder with application/json body
func NewChatAgentRequest(server string, body ChatAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewChatAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewChatAgentRequestWithBody generates requests for ChatAgent with any type of body
func NewChatAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/chat")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewQueryBuilderAgentRequest calls the generic QueryBuilderAgent builder with application/json body
func NewQueryBuilderAgentRequest(server string, body QueryBuilderAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewQueryBuilderAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewQueryBuilderAgentRequestWithBody generates requests for QueryBuilderAgent with any type of body
func NewQueryBuilderAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/query-builder")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBackupRequest calls the generic Backup builder with application/json body
func NewBackupRequest(server string, body BackupJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBackupRequestWithBody(server, "application/json", bodyReader)
}

// NewBackupRequestWithBody generates requests for Backup with any type of body
func NewBackupRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backup")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListBackupsRequest generates requests for ListBackups
func NewListBackupsRequest(server string, params *ListBackupsParams) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backups")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "location", runtime.ParamLocationQuery, params.Location); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewEvaluateRequest calls the generic Evaluate builder with application/json body
func NewEvaluateRequest(server string, body EvaluateJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewEvaluateRequestWithBody(server, "application/json", bodyReader)
}

// NewEvaluateRequestWithBody generates requests for Evaluate with any type of body
func NewEvaluateRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/eval")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGlobalQueryRequest calls the generic GlobalQuery builder with application/json body
func NewGlobalQueryRequest(server string, body GlobalQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewGlobalQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewGlobalQueryRequestWithBody generates requests for GlobalQuery with any type of body
func NewGlobalQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/query")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRagQueryRequest calls the generic RagQuery builder with application/json body
func NewRagQueryRequest(server string, body RagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRagQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewRagQueryRequestWithBody generates requests for RagQuery with any type of body
func NewRagQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/rag")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRestoreRequest calls the generic Restore builder with application/json body
func NewRestoreRequest(server string, body RestoreJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRestoreRequestWithBody(server, "application/json", bodyReader)
}

// NewRestoreRequestWithBody generates requests for Restore with any type of body
func NewRestoreRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/restore")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetStatusRequest generates requests for GetStatus
func NewGetStatusRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/status")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListTablesRequest generates requests for ListTables
func NewListTablesRequest(server string, params *ListTablesParams) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "prefix", runtime.ParamLocationQuery, params.Prefix); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "pattern", runtime.ParamLocationQuery, params.Pattern); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropTableRequest generates requests for DropTable
func NewDropTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetTableRequest generates requests for GetTable
func NewGetTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateTableRequest calls the generic CreateTable builder with application/json body
func NewCreateTableRequest(server string, tableName string, body CreateTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewCreateTableRequestWithBody generates requests for CreateTable with any type of body
func NewCreateTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBackupTableRequest calls the generic BackupTable builder with application/json body
func NewBackupTableRequest(server string, tableName string, body BackupTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBackupTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBackupTableRequestWithBody generates requests for BackupTable with any type of body
func NewBackupTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/backup", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBatchRequest calls the generic Batch builder with application/json body
func NewBatchRequest(server string, tableName string, body BatchJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBatchRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBatchRequestWithBody generates requests for Batch with any type of body
func NewBatchRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/batch", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListIndexesRequest generates requests for ListIndexes
func NewListIndexesRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropIndexRequest generates requests for DropIndex
func NewDropIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetIndexRequest generates requests for GetIndex
func NewGetIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateIndexRequest calls the generic CreateIndex builder with application/json body
func NewCreateIndexRequest(server string, tableName string, indexName string, body CreateIndexJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateIndexRequestWithBody(server, tableName, indexName, "application/json", bodyReader)
}

// NewCreateIndexRequestWithBody generates requests for CreateIndex with any type of body
func NewCreateIndexRequestWithBody(server string, tableName string, indexName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewScanKeysRequest calls the generic ScanKeys builder with application/json body
func NewScanKeysRequest(server string, tableName string, body ScanKeysJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewScanKeysRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewScanKeysRequestWithBody generates requests for ScanKeys with any type of body
func NewScanKeysRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/lookup", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewLookupKeyRequest generates requests for LookupKey
func NewLookupKeyRequest(server string, tableName string, key string, params *LookupKeyParams) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "key", runtime.ParamLocationPath, key)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/lookup/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "fields", runtime.ParamLocationQuery, params.Fields); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewLinearMergeRequest calls the generic LinearMerge builder with application/json body
func NewLinearMergeRequest(server string, tableName string, body LinearMergeJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewLinearMergeRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewLinearMergeRequestWithBody generates requests for LinearMerge with any type of body
func NewLinearMergeRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/merge", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewQueryTableRequest calls the generic QueryTable builder with application/json body
func NewQueryTableRequest(server string, tableName string, body QueryTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewQueryTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewQueryTableRequestWithBody generates requests for QueryTable with any type of body
func NewQueryTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/query", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewTableRagQueryRequest calls the generic TableRagQuery builder with application/json body
func NewTableRagQueryRequest(server string, tableName string, body TableRagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewTableRagQueryRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewTableRagQueryRequestWithBody generates requests for TableRagQuery with any type of body
func NewTableRagQueryRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/rag", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRestoreTableRequest calls the generic RestoreTable builder with application/json body
func NewRestoreTableRequest(server string, tableName string, body RestoreTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRestoreTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewRestoreTableRequestWithBody generates requests for RestoreTable with any type of body
func NewRestoreTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/restore", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateSchemaRequest calls the generic UpdateSchema builder with application/json body
func NewUpdateSchemaRequest(server string, tableName string, body UpdateSchemaJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateSchemaRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewUpdateSchemaRequestWithBody generates requests for UpdateSchema with any type of body
func NewUpdateSchemaRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/schema", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListUsersRequest generates requests for ListUsers
func NewListUsersRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetCurrentUserRequest generates requests for GetCurrentUser
func NewGetCurrentUserRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/me")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDeleteUserRequest generates requests for DeleteUser
func NewDeleteUserRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserByNameRequest generates requests for GetUserByName
func NewGetUserByNameRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateUserRequest calls the generic CreateUser builder with application/json body
func NewCreateUserRequest(server string, userName UserNamePathParameter, body CreateUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewCreateUserRequestWithBody generates requests for CreateUser with any type of body
func NewCreateUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateUserPasswordRequest calls the generic UpdateUserPassword builder with application/json body
func NewUpdateUserPasswordRequest(server string, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateUserPasswordRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewUpdateUserPasswordRequestWithBody generates requests for UpdateUserPassword with any type of body
func NewUpdateUserPasswordRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/password", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRemovePermissionFromUserRequest generates requests for RemovePermissionFromUser
func NewRemovePermissionFromUserRequest(server string, userName UserNamePathParameter, params *RemovePermissionFromUserParams) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resource", runtime.ParamLocationQuery, params.Resource); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resourceType", runtime.ParamLocationQuery, params.ResourceType); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserPermissionsRequest generates requests for GetUserPermissions
func NewGetUserPermissionsRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewAddPermissionToUserRequest calls the generic AddPermissionToUser builder with application/json body
func NewAddPermissionToUserRequest(server string, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAddPermissionToUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewAddPermissionToUserRequestWithBody generates requests for AddPermissionToUser with any type of body
func NewAddPermissionToUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

func (c *Client) applyEditors(ctx context.Context, req *http.Request, additionalEditors []RequestEditorFn) error {
	for _, r := range c.RequestEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	for _, r := range additionalEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	return nil
}

// ClientWithResponses builds on ClientInterface to offer response payloads
type ClientWithResponses struct {
	ClientInterface
}

// NewClientWithResponses creates a new ClientWithResponses, which wraps
// Client with return type handling
func NewClientWithResponses(server string, opts ...ClientOption) (*ClientWithResponses, error) {
	client, err := NewClient(server, opts...)
	if err != nil {
		return nil, err
	}
	return &ClientWithResponses{client}, nil
}

// WithBaseURL overrides the baseURL.
func WithBaseURL(baseURL string) ClientOption {
	return func(c *Client) error {
		newBaseURL, err := url.Parse(baseURL)
		if err != nil {
			return err
		}
		c.Server = newBaseURL.String()
		return nil
	}
}

// ClientWithResponsesInterface is the interface specification for the client with responses above.
type ClientWithResponsesInterface interface {
	// AnswerAgentWithBodyWithResponse request with any body
	AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	// ChatAgentWithBodyWithResponse request with any body
	ChatAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error)

	ChatAgentWithResponse(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error)

	// QueryBuilderAgentWithBodyWithResponse request with any body
	QueryBuilderAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error)

	QueryBuilderAgentWithResponse(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error)

	// BackupWithBodyWithResponse request with any body
	BackupWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupResponse, error)

	BackupWithResponse(ctx context.Context, body BackupJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupResponse, error)

	// ListBackupsWithResponse request
	ListBackupsWithResponse(ctx context.Context, params *ListBackupsParams, reqEditors ...RequestEditorFn) (*ListBackupsResponse, error)

	// EvaluateWithBodyWithResponse request with any body
	EvaluateWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*EvaluateResponse, error)

	EvaluateWithResponse(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*EvaluateResponse, error)

	// GlobalQueryWithBodyWithResponse request with any body
	GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	// RagQueryWithBodyWithResponse request with any body
	RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	// RestoreWithBodyWithResponse request with any body
	RestoreWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreResponse, error)

	RestoreWithResponse(ctx context.Context, body RestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreResponse, error)

	// GetStatusWithResponse request
	GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error)

	// ListTablesWithResponse request
	ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error)

	// DropTableWithResponse request
	DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error)

	// GetTableWithResponse request
	GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error)

	// CreateTableWithBodyWithResponse request with any body
	CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	// BackupTableWithBodyWithResponse request with any body
	BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	// BatchWithBodyWithResponse request with any body
	BatchWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchResponse, error)

	BatchWithResponse(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchResponse, error)

	// ListIndexesWithResponse request
	ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error)

	// DropIndexWithResponse request
	DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error)

	// GetIndexWithResponse request
	GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error)

	// CreateIndexWithBodyWithResponse request with any body
	CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	// ScanKeysWithBodyWithResponse request with any body
	ScanKeysWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error)

	ScanKeysWithResponse(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error)

	// LookupKeyWithResponse request
	LookupKeyWithResponse(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error)

	// LinearMergeWithBodyWithResponse request with any body
	LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	// QueryTableWithBodyWithResponse request with any body
	QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	// TableRagQueryWithBodyWithResponse request with any body
	TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	// RestoreTableWithBodyWithResponse request with any body
	RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	// UpdateSchemaWithBodyWithResponse request with any body
	UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	// ListUsersWithResponse request
	ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error)

	// GetCurrentUserWithResponse request
	GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error)

	// DeleteUserWithResponse request
	DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error)

	// GetUserByNameWithResponse request
	GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error)

	// CreateUserWithBodyWithResponse request with any body
	CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	// UpdateUserPasswordWithBodyWithResponse request with any body
	UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	// RemovePermissionFromUserWithResponse request
	RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error)

	// GetUserPermissionsWithResponse request
	GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error)

	// AddPermissionToUserWithBodyWithResponse request with any body
	AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)

	AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)
}

type AnswerAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *AnswerAgentResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AnswerAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AnswerAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ChatAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ChatAgentResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ChatAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ChatAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type QueryBuilderAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryBuilderResult
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r QueryBuilderAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r QueryBuilderAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BackupResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ClusterBackupResponse
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BackupResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BackupResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListBackupsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *BackupListResponse
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListBackupsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListBackupsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type EvaluateResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *EvalResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r EvaluateResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r EvaluateResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GlobalQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GlobalQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GlobalQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RestoreResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON202      *ClusterRestoreResponse
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r RestoreResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RestoreResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetStatusResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ClusterStatus
	JSON401      *Error
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetStatusResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetStatusResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListTablesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]TableStatus
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListTablesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListTablesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *TableStatus
	JSON404      *NotFound
}

// Status returns HTTPResponse.Status
func (r GetTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
}

// Status returns HTTPResponse.Status
func (r CreateTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BackupTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *struct {
		Backup string `json:"backup,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON404 *NotFound
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BackupTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BackupTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BatchResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *struct {
		// Deleted Number of documents successfully deleted
		Deleted int `json:"deleted,omitempty,omitzero"`

		// Failed List of failed operations with error details
		Failed []struct {
			// Error Error message for this failure
			Error string `json:"error,omitempty,omitzero"`

			// Id The document ID that failed
			Id string `json:"id,omitempty,omitzero"`
		} `json:"failed,omitempty,omitzero"`

		// Inserted Number of documents successfully inserted
		Inserted int `json:"inserted,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON404 *NotFound
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BatchResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BatchResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListIndexesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListIndexesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListIndexesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r CreateIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ScanKeysResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ScanKeysResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ScanKeysResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LookupKeyResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *map[string]interface{}
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LookupKeyResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LookupKeyResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LinearMergeResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *LinearMergeResult
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LinearMergeResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LinearMergeResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type QueryTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r QueryTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r QueryTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type TableRagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON404      *NotFound
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r TableRagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r TableRagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RestoreTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON202      *struct {
		Restore string `json:"restore,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r RestoreTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RestoreTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateSchemaResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r UpdateSchemaResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateSchemaResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListUsersResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]struct {
		Username string `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON403 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r ListUsersResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListUsersResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetCurrentUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *struct {
		Permissions []Permission `json:"permissions,omitempty,omitzero"`
		Username    string       `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r GetCurrentUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetCurrentUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserByNameResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *User
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserByNameResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserByNameResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *User
	JSON400      *Error
	JSON409      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateUserPasswordResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateUserPasswordResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateUserPasswordResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RemovePermissionFromUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RemovePermissionFromUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RemovePermissionFromUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserPermissionsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]Permission
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserPermissionsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserPermissionsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type AddPermissionToUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AddPermissionToUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AddPermissionToUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

// AnswerAgentWithBodyWithResponse request with arbitrary body returning *AnswerAgentResponse
func (c *ClientWithResponses) AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

func (c *ClientWithResponses) AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

// ChatAgentWithBodyWithResponse request with arbitrary body returning *ChatAgentResponse
func (c *ClientWithResponses) ChatAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error) {
	rsp, err := c.ChatAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseChatAgentResponse(rsp)
}

func (c *ClientWithResponses) ChatAgentWithResponse(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error) {
	rsp, err := c.ChatAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseChatAgentResponse(rsp)
}

// QueryBuilderAgentWithBodyWithResponse request with arbitrary body returning *QueryBuilderAgentResponse
func (c *ClientWithResponses) QueryBuilderAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error) {
	rsp, err := c.QueryBuilderAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryBuilderAgentResponse(rsp)
}

func (c *ClientWithResponses) QueryBuilderAgentWithResponse(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error) {
	rsp, err := c.QueryBuilderAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryBuilderAgentResponse(rsp)
}

// BackupWithBodyWithResponse request with arbitrary body returning *BackupResponse
func (c *ClientWithResponses) BackupWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupResponse, error) {
	rsp, err := c.BackupWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupResponse(rsp)
}

func (c *ClientWithResponses) BackupWithResponse(ctx context.Context, body BackupJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupResponse, error) {
	rsp, err := c.Backup(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupResponse(rsp)
}

// ListBackupsWithResponse request returning *ListBackupsResponse
func (c *ClientWithResponses) ListBackupsWithResponse(ctx context.Context, params *ListBackupsParams, reqEditors ...RequestEditorFn) (*ListBackupsResponse, error) {
	rsp, err := c.ListBackups(ctx, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListBackupsResponse(rsp)
}

// EvaluateWithBodyWithResponse request with arbitrary body returning *EvaluateResponse
func (c *ClientWithResponses) EvaluateWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*EvaluateResponse, error) {
	rsp, err := c.EvaluateWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseEvaluateResponse(rsp)
}

func (c *ClientWithResponses) EvaluateWithResponse(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*EvaluateResponse, error) {
	rsp, err := c.Evaluate(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseEvaluateResponse(rsp)
}

// GlobalQueryWithBodyWithResponse request with arbitrary body returning *GlobalQueryResponse
func (c *ClientWithResponses) GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

func (c *ClientWithResponses) GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

// RagQueryWithBodyWithResponse request with arbitrary body returning *RagQueryResponse
func (c *ClientWithResponses) RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

func (c *ClientWithResponses) RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

// RestoreWithBodyWithResponse request with arbitrary body returning *RestoreResponse
func (c *ClientWithResponses) RestoreWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreResponse, error) {
	rsp, err := c.RestoreWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreResponse(rsp)
}

func (c *ClientWithResponses) RestoreWithResponse(ctx context.Context, body RestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreResponse, error) {
	rsp, err := c.Restore(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreResponse(rsp)
}

// GetStatusWithResponse request returning *GetStatusResponse
func (c *ClientWithResponses) GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error) {
	rsp, err := c.GetStatus(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetStatusResponse(rsp)
}

// ListTablesWithResponse request returning *ListTablesResponse
func (c *ClientWithResponses) ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error) {
	rsp, err := c.ListTables(ctx, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListTablesResponse(rsp)
}

// DropTableWithResponse request returning *DropTableResponse
func (c *ClientWithResponses) DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error) {
	rsp, err := c.DropTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropTableResponse(rsp)
}

// GetTableWithResponse request returning *GetTableResponse
func (c *ClientWithResponses) GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error) {
	rsp, err := c.GetTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetTableResponse(rsp)
}

// CreateTableWithBodyWithResponse request with arbitrary body returning *CreateTableResponse
func (c *ClientWithResponses) CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

func (c *ClientWithResponses) CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

// BackupTableWithBodyWithResponse request with arbitrary body returning *BackupTableResponse
func (c *ClientWithResponses) BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

func (c *ClientWithResponses) BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

// BatchWithBodyWithResponse request with arbitrary body returning *BatchResponse
func (c *ClientWithResponses) BatchWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchResponse, error) {
	rsp, err := c.BatchWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchResponse(rsp)
}

func (c *ClientWithResponses) BatchWithResponse(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchResponse, error) {
	rsp, err := c.Batch(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchResponse(rsp)
}

// ListIndexesWithResponse request returning *ListIndexesResponse
func (c *ClientWithResponses) ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error) {
	rsp, err := c.ListIndexes(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListIndexesResponse(rsp)
}

// DropIndexWithResponse request returning *DropIndexResponse
func (c *ClientWithResponses) DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error) {
	rsp, err := c.DropIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropIndexResponse(rsp)
}

// GetIndexWithResponse request returning *GetIndexResponse
func (c *ClientWithResponses) GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error) {
	rsp, err := c.GetIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetIndexResponse(rsp)
}

// CreateIndexWithBodyWithResponse request with arbitrary body returning *CreateIndexResponse
func (c *ClientWithResponses) CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndexWithBody(ctx, tableName, indexName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

func (c *ClientWithResponses) CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndex(ctx, tableName, indexName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

// ScanKeysWithBodyWithResponse request with arbitrary body returning *ScanKeysResponse
func (c *ClientWithResponses) ScanKeysWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error) {
	rsp, err := c.ScanKeysWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseScanKeysResponse(rsp)
}

func (c *ClientWithResponses) ScanKeysWithResponse(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error) {
	rsp, err := c.ScanKeys(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseScanKeysResponse(rsp)
}

// LookupKeyWithResponse request returning *LookupKeyResponse
func (c *ClientWithResponses) LookupKeyWithResponse(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error) {
	rsp, err := c.LookupKey(ctx, tableName, key, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLookupKeyResponse(rsp)
}

// LinearMergeWithBodyWithResponse request with arbitrary body returning *LinearMergeResponse
func (c *ClientWithResponses) LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMergeWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

func (c *ClientWithResponses) LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMerge(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

// QueryTableWithBodyWithResponse request with arbitrary body returning *QueryTableResponse
func (c *ClientWithResponses) QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

func (c *ClientWithResponses) QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

// TableRagQueryWithBodyWithResponse request with arbitrary body returning *TableRagQueryResponse
func (c *ClientWithResponses) TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQueryWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

func (c *ClientWithResponses) TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQuery(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

// RestoreTableWithBodyWithResponse request with arbitrary body returning *RestoreTableResponse
func (c *ClientWithResponses) RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

func (c *ClientWithResponses) RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

// UpdateSchemaWithBodyWithResponse request with arbitrary body returning *UpdateSchemaResponse
func (c *ClientWithResponses) UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchemaWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

func (c *ClientWithResponses) UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchema(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

// ListUsersWithResponse request returning *ListUsersResponse
func (c *ClientWithResponses) ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error) {
	rsp, err := c.ListUsers(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListUsersResponse(rsp)
}

// GetCurrentUserWithResponse request returning *GetCurrentUserResponse
func (c *ClientWithResponses) GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error) {
	rsp, err := c.GetCurrentUser(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetCurrentUserResponse(rsp)
}

// DeleteUserWithResponse request returning *DeleteUserResponse
func (c *ClientWithResponses) DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error) {
	rsp, err := c.DeleteUser(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteUserResponse(rsp)
}

// GetUserByNameWithResponse request returning *GetUserByNameResponse
func (c *ClientWithResponses) GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error) {
	rsp, err := c.GetUserByName(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserByNameResponse(rsp)
}

// CreateUserWithBodyWithResponse request with arbitrary body returning *CreateUserResponse
func (c *ClientWithResponses) CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

func (c *ClientWithResponses) CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

// UpdateUserPasswordWithBodyWithResponse request with arbitrary body returning *UpdateUserPasswordResponse
func (c *ClientWithResponses) UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPasswordWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

func (c *ClientWithResponses) UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPassword(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

// RemovePermissionFromUserWithResponse request returning *RemovePermissionFromUserResponse
func (c *ClientWithResponses) RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error) {
	rsp, err := c.RemovePermissionFromUser(ctx, userName, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRemovePermissionFromUserResponse(rsp)
}

// GetUserPermissionsWithResponse request returning *GetUserPermissionsResponse
func (c *ClientWithResponses) GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error) {
	rsp, err := c.GetUserPermissions(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserPermissionsResponse(rsp)
}

// AddPermissionToUserWithBodyWithResponse request with arbitrary body returning *AddPermissionToUserResponse
func (c *ClientWithResponses) AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

func (c *ClientWithResponses) AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

// ParseAnswerAgentResponse parses an HTTP response from a AnswerAgentWithResponse call
func ParseAnswerAgentResponse(rsp *http.Response) (*AnswerAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AnswerAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest AnswerAgentResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseChatAgentResponse parses an HTTP response from a ChatAgentWithResponse call
func ParseChatAgentResponse(rsp *http.Response) (*ChatAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ChatAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ChatAgentResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseQueryBuilderAgentResponse parses an HTTP response from a QueryBuilderAgentWithResponse call
func ParseQueryBuilderAgentResponse(rsp *http.Response) (*QueryBuilderAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &QueryBuilderAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryBuilderResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseBackupResponse parses an HTTP response from a BackupWithResponse call
func ParseBackupResponse(rsp *http.Response) (*BackupResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BackupResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ClusterBackupResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListBackupsResponse parses an HTTP response from a ListBackupsWithResponse call
func ParseListBackupsResponse(rsp *http.Response) (*ListBackupsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListBackupsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest BackupListResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseEvaluateResponse parses an HTTP response from a EvaluateWithResponse call
func ParseEvaluateResponse(rsp *http.Response) (*EvaluateResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &EvaluateResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest EvalResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGlobalQueryResponse parses an HTTP response from a GlobalQueryWithResponse call
func ParseGlobalQueryResponse(rsp *http.Response) (*GlobalQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GlobalQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRagQueryResponse parses an HTTP response from a RagQueryWithResponse call
func ParseRagQueryResponse(rsp *http.Response) (*RagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseRestoreResponse parses an HTTP response from a RestoreWithResponse call
func ParseRestoreResponse(rsp *http.Response) (*RestoreResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RestoreResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest ClusterRestoreResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetStatusResponse parses an HTTP response from a GetStatusWithResponse call
func ParseGetStatusResponse(rsp *http.Response) (*GetStatusResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetStatusResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ClusterStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListTablesResponse parses an HTTP response from a ListTablesWithResponse call
func ParseListTablesResponse(rsp *http.Response) (*ListTablesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListTablesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropTableResponse parses an HTTP response from a DropTableWithResponse call
func ParseDropTableResponse(rsp *http.Response) (*DropTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetTableResponse parses an HTTP response from a GetTableWithResponse call
func ParseGetTableResponse(rsp *http.Response) (*GetTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	}

	return response, nil
}

// ParseCreateTableResponse parses an HTTP response from a CreateTableWithResponse call
func ParseCreateTableResponse(rsp *http.Response) (*CreateTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	}

	return response, nil
}

// ParseBackupTableResponse parses an HTTP response from a BackupTableWithResponse call
func ParseBackupTableResponse(rsp *http.Response) (*BackupTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BackupTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest struct {
			Backup string `json:"backup,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseBatchResponse parses an HTTP response from a BatchWithResponse call
func ParseBatchResponse(rsp *http.Response) (*BatchResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BatchResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest struct {
			// Deleted Number of documents successfully deleted
			Deleted int `json:"deleted,omitempty,omitzero"`

			// Failed List of failed operations with error details
			Failed []struct {
				// Error Error message for this failure
				Error string `json:"error,omitempty,omitzero"`

				// Id The document ID that failed
				Id string `json:"id,omitempty,omitzero"`
			} `json:"failed,omitempty,omitzero"`

			// Inserted Number of documents successfully inserted
			Inserted int `json:"inserted,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListIndexesResponse parses an HTTP response from a ListIndexesWithResponse call
func ParseListIndexesResponse(rsp *http.Response) (*ListIndexesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListIndexesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropIndexResponse parses an HTTP response from a DropIndexWithResponse call
func ParseDropIndexResponse(rsp *http.Response) (*DropIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetIndexResponse parses an HTTP response from a GetIndexWithResponse call
func ParseGetIndexResponse(rsp *http.Response) (*GetIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateIndexResponse parses an HTTP response from a CreateIndexWithResponse call
func ParseCreateIndexResponse(rsp *http.Response) (*CreateIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseScanKeysResponse parses an HTTP response from a ScanKeysWithResponse call
func ParseScanKeysResponse(rsp *http.Response) (*ScanKeysResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ScanKeysResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLookupKeyResponse parses an HTTP response from a LookupKeyWithResponse call
func ParseLookupKeyResponse(rsp *http.Response) (*LookupKeyResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LookupKeyResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest map[string]interface{}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLinearMergeResponse parses an HTTP response from a LinearMergeWithResponse call
func ParseLinearMergeResponse(rsp *http.Response) (*LinearMergeResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LinearMergeResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest LinearMergeResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseQueryTableResponse parses an HTTP response from a QueryTableWithResponse call
func ParseQueryTableResponse(rsp *http.Response) (*QueryTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &QueryTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseTableRagQueryResponse parses an HTTP response from a TableRagQueryWithResponse call
func ParseTableRagQueryResponse(rsp *http.Response) (*TableRagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &TableRagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseRestoreTableResponse parses an HTTP response from a RestoreTableWithResponse call
func ParseRestoreTableResponse(rsp *http.Response) (*RestoreTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RestoreTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest struct {
			Restore string `json:"restore,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateSchemaResponse parses an HTTP response from a UpdateSchemaWithResponse call
func ParseUpdateSchemaResponse(rsp *http.Response) (*UpdateSchemaResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateSchemaResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListUsersResponse parses an HTTP response from a ListUsersWithResponse call
func ParseListUsersResponse(rsp *http.Response) (*ListUsersResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListUsersResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []struct {
			Username string `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 403:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON403 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetCurrentUserResponse parses an HTTP response from a GetCurrentUserWithResponse call
func ParseGetCurrentUserResponse(rsp *http.Response) (*GetCurrentUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetCurrentUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest struct {
			Permissions []Permission `json:"permissions,omitempty,omitzero"`
			Username    string       `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteUserResponse parses an HTTP response from a DeleteUserWithResponse call
func ParseDeleteUserResponse(rsp *http.Response) (*DeleteUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserByNameResponse parses an HTTP response from a GetUserByNameWithResponse call
func ParseGetUserByNameResponse(rsp *http.Response) (*GetUserByNameResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserByNameResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateUserResponse parses an HTTP response from a CreateUserWithResponse call
func ParseCreateUserResponse(rsp *http.Response) (*CreateUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 409:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON409 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateUserPasswordResponse parses an HTTP response from a UpdateUserPasswordWithResponse call
func ParseUpdateUserPasswordResponse(rsp *http.Response) (*UpdateUserPasswordResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateUserPasswordResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRemovePermissionFromUserResponse parses an HTTP response from a RemovePermissionFromUserWithResponse call
func ParseRemovePermissionFromUserResponse(rsp *http.Response) (*RemovePermissionFromUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RemovePermissionFromUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserPermissionsResponse parses an HTTP response from a GetUserPermissionsWithResponse call
func ParseGetUserPermissionsResponse(rsp *http.Response) (*GetUserPermissionsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserPermissionsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []Permission
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseAddPermissionToUserResponse parses an HTTP response from a AddPermissionToUserWithResponse call
func ParseAddPermissionToUserResponse(rsp *http.Response) (*AddPermissionToUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AddPermissionToUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// Base64 encoded, gzipped, json marshaled Swagger object
var swaggerSpec = []string{

	"H4sIAAAAAAAC/+y9jXIjubEu+CpY2jda6iUpqdU9Y/PGhK3+HZ3pvyN1e+5Zs4MCq0ASVhVQA6AkcTq0",
	"z7Avsi+1T7KBTACFYoEi9dNj+565N864xcJvAkhkJjK//NrLZFlJwYTRvdHXXkUVLZlhCv76rJl6T0v2",
	"kZrFR//FfsiZzhSvDJeiN+p9WjBSa6YELdmw1+9x+2NFzaLX79nfeqNe7Vrq9XuK/VJzxfLeyKia9Xs6",
	"W7CS2lbZFS2rwhb/h1yIXNrSZlnZH7RRXMx719fXtgFdSaEZDPE5zU/YLzXTxv6VSWGYgH/Sqip4Ru0Q",
	"9/6h7Ti/Rl39UbFZb9T7w14z/T38qvdeKSUVdtWe53OaE+U6u+73joWxcy5OmbpgCmt98zH4TomGXgnD",
	"gv3ee2ley1rk334IJ0zLWmWMCGnIDPq0hVw92+yRoMXSLVClZMWU4e6vDPp1qzqVsmBU2OEbLVjqy3XY",
	"AnL6D5aZXr93NZjLgf1xoM95NZAwLloMKskF7M8ZLTS77odhnDBdF2btYLhhJfw9k6qkpjfqzQpJTbP5",
	"RF1OmYp79mW+e9prBkiVost4Lg/c8P1IoS+ZOpozYaLj0iYHtV8n50JeFiyfs+45f06z87myC05CKWIW",
	"1JB5zXOmiVkwAq080qQWOVPaUJFzMSdyBh9zWVIuhmNxykteUEWMJC/eHn1++WpY5n1iFlyTSskLaA12",
	"8ZXBHmAf2y4koUVBtGGVHoudrKBa85nb4X2imFGcXdCiT6jICYVpkzkTTEGJ3eFYjMUrZDR6NBYDMu59",
	"st3m1FDoknKhSclyntGCKJZJlesh+awZyQou4FfDVMmFLOR8Cd1MGakUy7hmhE5lbUjO6VxIzfRw3Iv6",
	"4JpQouXMXFLFCBNzLhizjC2i55RqNiRHWtclI5QYli2wU1rnnImMtZs0dFowoo1UTJOCzWlBcpnVpT3K",
	"Q3LCZkzZSqSglxrGqti8LoAWmtAsqxU1rFhCo1122+9lC8pFdyu8ZDNaF4bAZ7u6jsRSaTKTCtao4hUr",
	"uGC4WKQWBdOayAumFM9zJggX5Ay+nQ3H4hXNFqTg4pxkVBBdsYzPlrCeS7ssMz6vcQlxYe1vOYe/bX9G",
	"LS0Z7R4Tds+E4QzH4l1taloUS8KusqLW/IKRS24W5FEo9GhIXnGzYCr+jUhFHsH8HpGy1gZXGfZmPgRi",
	"hfN9Ext9YVt4y8V5ilPYnbqRD1/Q4gUQwNYI49tU7Y0v2NQt6dXEHaqJkedM6O7CvqNXvKxLYqSxGx1K",
	"2dWUlywHSrsTxvKwz/xBHY7FzwsmiGam32xCYrd6pWrBcrJjm9FmoKg4t81xpc2uPdIzbmBNuEAeMK3z",
	"ObMNftZsVhfQMRO6hrPy9u27wBsKXnLXh72N2FXGGK7PZ800ef7q5BNOgv/KFDajDS9hI+EiBqHjYN/+",
	"v36v5MJSoDc6COtlmemcwTX7S82U45dtwh3ZNbUnwZZYejkBGBa7Yllt2JBYQQk/w+AveVHYXWUUFdre",
	"EY7EmpVUGJ4RzajKFmNhd3wlK3tuWU64MBJ2ui83wXJkxlmR2yEwe5ago2E8w79/7XGRsys7/L/3WDll",
	"uWXOE55f9b70e0BLS4d+D7iKFeKUzOvM6N51f6u6z5qqil1wdql711+2PCj/acd70ohXJRfHWO+ge3Bg",
	"ct1FsALrI00ENbWiBSmomNd0HoguLbX9lcFy4CS8tIea5TGhej/DlaMYkHnKtCFzWtq9V9DKyMrdbuSP",
	"T/b39/+SYpuKgXzWOmbAMXujp7DLViRoPGdGElcR98FSG1ZaplNWpt+9zPCOk8C4LFtdMGp3/mk9NYpm",
	"dqvMlCxJ99jbjnKGtxgj9ILyAq4Rf6rC8XNsHirYcRM+SzXHtT30K+fpafs07adOE3D/TRsjkl1Oofx1",
	"v2eZxUQbxWBZWvRFraJN31cC5nd6+oqESvagKJAMNenIEe6Y930JT/1dwoU2jMIx+4/TD++J10aaXRBJ",
	"tXaYsjaTZs1aQwXpbHWswENhEsQKdeTouLvy7iY3tRKOSYSpSGFvc884L21jS1mTSyqML/pLTQtulsSN",
	"zjFUbfpE19mCULjCx+KXWhpKSironAGft9yfGoZM11JQZ0xQxaUexsJDLLs3yt7f3ZltWOiXVXl2VU71",
	"Ujstig8zYF+bt4mrZfnVCn9GGoJ46oiFYsAaETK64DQeNEd+5sVKECUtS2+3MAnsHJcqyJSVYoMgnxLF",
	"qJbCUnGHzwiDDZqTC07HAk7FsN3qEHZ8qLRrLxOuo1asbFkbaTvNQNqpqNYsJ0aOBcjlnT1kuwE+Y0fI",
	"RW23BMjpsp4v3Gluawg3TnSjINSq/KlVN6waSEQTFZZ+k2DUVITd5WomrucTdzyAI8L96G7lnPh9eZtb",
	"yve6QUO7/tLe06ee37UH95GpAaxGW9AFwbZZOty6XqoeEpCYsRoVZEEv2FhYYUheikb+JTt2gbtS+i5s",
	"aVt7gLI2zwiqj/YwH8+somKb5hoEKz8wlvcJN6TWTtszshoU7IIVUY9UE8fhUnsIJ7Mdz7fkasTX9u67",
	"3XZbacn+K7d60cZWQsl2CzNpReK62lT/tSsX175ey/detMbV3iPNN2IPttbAkv0WWeVNa8g+yW7o4cMF",
	"U1Zva8oQkMfDBtzZH+5bSeBguL87JC+k0Nzq+GQqzYLQKYdLxSroWByOmteYLMsFq5GOeGnR6L1WUO2Y",
	"SUpURkACTAgSznyCCwryiGIFu6DJ2Z34T94WkRiZk6tBBLUHMJ7wPca3cg92lyI1gfW3Y3Mxplgckr3L",
	"7eGu8waieI3tcuB2HtRVmLu+4eC2u32zsvXspimpOs8tH3IkW5WQt7BcWQnouv/g+/buy7j9mP+ld+P2",
	"0/A8btLsic48Tuv5nGlQNZJbKNypHQ2pdXNuO6jkSbrhqERsN81Q1921K2KSk7bgRvSsFi/AGRe0sBp6",
	"w/ISAiSptTdPNRIb1ZHl5AaGbUskhl9rI0uwvMI+AqsbjsJIwfpWwaO8IHA7991tvyxYS899DjofGi5F",
	"3hgbh+RYZEWd2885I66CtuqEslOAzWuGtzAYvkgYCu0GV0t7WKXKmRqSbSx1D2J3u48VDbXyCWrla9el",
	"pbvHixOpgt3XreRGNrNi+WJRi3Ommr28nU4E1T6gWAc6UXuPzeqimPjtRXO0p9LiY1QopU13T45taACm",
	"AzASOe06s71ru77P7S709sFKMW1llx12wQSxyk9ZmeVu35f3ZjEwaue4A0bZzIyIrmczfoVmGzBG5aHx",
	"R5pMXH0wg/nO6NT2FdquNSOjrNUSVQyUZvsN7W8XLLNybDByWYkYzj+uCgG9C8w0uZu9qW0jSGdS8HNG",
	"plJqqyP3nVWupFUFfzKTrRhKvnaXPaFI9LdiX4XMaEFwz+Cc7Vq4y8VrrM0jiyKqFropmHPFMlMsG2Ms",
	"LgOdMyIsJ6iUzJjW/bHwxgPkx8DPBGFX7nXyE1MlNwxeKXnGhuTYKQ2a20mTGb9i+UDzX9lYBPvsYErt",
	"EoTRwMoLSTKaLWBLNTausXj8+LNmaC2+XDAxevx4LAbkpBbAWy27LdgAxpyzqpBL5MM7+pKqkpQyZ7u2",
	"/H/JmuRSPDJEMJY3S74Hgwg900xJrYEE2lcDiwrcs/Aaa2qrvtnJXXGzbEboKeHtRonBlnVhOI7Vsj1j",
	"ZWrktL5/xfI6gycxbcIAYMQf3r//XwOaZaxwQlignp1j0R5txZTm2oDN3hbbC/OFnuzcWhsTXwzg5PRG",
	"z/b7PbsCBa2CWdP+5reS5a+w73r9nmYVdfy1Z0lhWR1Vc2aimvvXgbt9gr3+tceEFVn+3kM71YTqyVLW",
	"EzgJ/d45W15KldumLMfq9xamLHp9K9cwxbNev5dTwwwHJwNvg+r3CnsFWI4vQZTAf+oFhTbD/G2VQk4j",
	"UaK50Y6EWShZ8Wz1MthSpAj1A++/YOTouDmDOy8Kau9aXDF8ojz6eEzO2ZJccErOaMUn52x55i38ipwd",
	"vf/048mHj8cvJkcfjyc/vfqvM8LEBVdSgF54QRWn04K5o+IePMk76GH0+DHJoMuBlkIwM3g6eDZ4sv/k",
	"2f6fn/yZ7Djt3XJkLCWrWocyBwf7B+HL4eDZYEH5eW0/PT3Yf/IEO3wpM+hmYUylR3t7ucz0kHpCDDNZ",
	"7jEBv+7Bi+kA29tDEuzZfXbB2WVqP/od9HT/z9/1e1ChN+qtn09vdYviGGAflZVdj1qx3mh/+P11RwZD",
	"uqc9XppldWs1JMczMJZ4Wb5PZrQoNJnS7NwKO501Sy9ZSqqKJ77uyQ4FfFAogpXfC6teI/LW6qiTyBzv",
	"iBlZqG+ma5coVhDAfUyOX3rdpqEUfjES7uEdNpwP++TR+i4eNV87W/DRbutt6+aBdrWPeOkTx9goWWii",
	"qMhlKZgGISbSCawqNkAzyI98vmCKXNCiZpqU9JwRWZuqNqSUVlaGJu5n3TCympwnNqGsBudEWwLAJe8d",
	"tIbkgxVnNB55UEmcqY78FIQUeAoFA2I91eyX2u5A2DbpnWGHUHWH8L7OClbrxCBiEh0VIBUA37Myf0P7",
	"+9GlVkX6aH4+edvde/aUMpHDLUB2vILZR7HEbXgrjdoT7EyiLN9tjbBWPCm0xzopnqGUSvqcZud1dSxm",
	"MuF7A/fg5MJe0DKhPjmJzn1Hl5hMMbjx4Y0S2m4diIuD4f5wP7X5sfCE52nq4WfCcyaMJYJaOWcgoQyw",
	"FByywf7B4OBZqicrjprkhE6dVOlL+PVKTEQfjvb2yuW0zs6Z2UNKue71nhvO3s3jgEfpBOv8BL8Tjspu",
	"7rlkdxB/Bw9GZxTDJ/EvW1s37N+8ZNrQMnGG8L2vofsl1X5pW2RoZvjpYH90uD/a3/+/4s1ppZ+BE39u",
	"3qLN+scDC1SKlm39Nn7LtTnxT5+d7exWpztZW80udfPm7ItuqdZHhyj1/NKdpr5hEmtd4W44IZ8F/6Vm",
	"0elwch7XbirgK5bjW773voqWF31oQLclsnIXitUwXyyk1IxQUjJq1YJZXRBBS+dh57Yo+KmxPc8HuAhP",
	"aCtKZa9zPgcXT+55RL1A6+d5WleVVEajAlO5xWQiR8e6t6CLznjB0BgyImf2j9He3l5FzWLPyD1s6cyW",
	"Pirpr1KQ08MROYMTj+d9YEnQLY8Pr55TedrQonAOcTk1tO+MBO75tmSGgpOfn0Zg8lhnlYA3sh3gBgOo",
	"dyPrueHkbThkJltE23PVEdNkC6tRMmX6JGcFMwwnGZ5ko71luRp1GrH3S3J6wZGRJc+4WT5+DEv2+PEp",
	"FtMLqvLHj0fkQ9MMVYxQqODNA1CKTGUtcqo4qsaPH7/zuwE+a9sKOGPl3FJlCm+uTwbVgmpmNeaSG7Lz",
	"5OOLXbSSYQegbw+w/UvFjW3bDvhHedlqB+ZLMxzgpVTnMJGDIXnnV9v5SdMC6M00+fHtCxK4HtpFWcEy",
	"Y7VrqXIu4BETuh6LJ0PyIvoVhxL36jxE+1byMTzjFRVGYznCwQtbj8XhkBzNDI7C/0p0nWXMKglxt0iP",
	"Vg9j8XRIPsatO28358OklyJbKClkrYulcyGSxUXU/bMhOWGZ1amWpJCyQlc6pl0jmVtftF4YRsAuR2HA",
	"8dhmlBe1YrgQH5kC1iMy5vYO7hy3ZlO7Q5kekXG9v3+YkWelJgU1TGRLW/ZFtLzxEo7I//1kv130GGaB",
	"k6ptodDm4T7RLJMih5XXZpDZHbVjNWYVT3cXR/ympooKw5h2Az4qCr+gbi2I81y1MyU71B8Ob/4Bx2PY",
	"02A7etGlDZoGoW9gQzuCXZKCUbC0MV2Xq0SHho5zVlZyZZpkJ6/RdZ+trJNdfk1nzM3rORNsxo2f1Ykz",
	"FQlm7HkIRjNYXqrwZuIi5xc8r8EPBR0Vbd139lJisxnPuB1MsOXu1FUOZ8d2jUubw8iPvMfJDYfSijcR",
	"M9IVdYxDezaOjAxbryv894CwKw4WVKta4zc7Fbtghok+sZQNX5y8tGpY7SFr1F5+G33/J6sNwj9lkU9o",
	"lslaGBDlcAy2Enw+eHLofOJ7o8P9fo+VlBcuMuWvrodhJssmxOU/5EKQlxi0QufQZwZvAe41npW8Lntf",
	"rl3/T599Fzp48izqgAq2pgMqGDktOcTVdLr4ApEabTEmTH+ts2rw4T1+6bwCbY0hedly31WslBfenRB5",
	"GFyscIu8l8Z50r+XYgCrZhsMa6N5wYQploTPhVQstyVf2m7CZnZGZZaTKZvZLeg3hLdAWykItp2t+5Nv",
	"uGKW/2DbrRF6i3XzTrBi2Ny8G7YW7KN9k35A6XjOe4q7xwQwclM15UZRtUQLnyalna3d/EtZK+/kDyJw",
	"pJ834sKqQahKrm27Z+08iM7Z0rItS+h6jWzLQl1Y8edMG1Ipe8Izt/QQHiGFbhbfyq7oI7hglu05a884",
	"HK9xz/4F91rB7HEY93bd+pKCibkly2wGF3O8oFVz8ZABOWessgMs3bsqnRZLohdSmdZW0VJZxlSwK57J",
	"uaLVAp3k+kRLkqHgXSk241fwrEsN0SjbEkXF3JKeio5x/N+WTyQ2kBUiJvBUvEkBO12K7C0UtO14cfMm",
	"HpOUSe3G4mJQFTRrdhfx9ww+l7+TYi5fPh/Au7WrLBVynU+pRiFOAdxdjSSlzPlsGb3BNy9WNB/g1wEK",
	"aor6fbwq7kLUUe6kUnialo4ngVgJl6YXd6OBVEw1k4obskIzWNsyBjKT16DcI0bcxs4fucj65I9lXez2",
	"CUVqxp+rWi/65I9VXUABq+JIFM9eyLKUAoysVibCqR2LTDEXr1ELeGTaARf9PrxY6j65sJwczuBnWIdG",
	"TLbdZbVSTJiX1ODT2TtwDMaBabJD83wPuTCxe65PgIfGrQnnKIIczq+Gv9S9f4RlParZEiuM+2sP7PGB",
	"bdjj1+81ZIEisuqNepZ69jxRs7B/DTEaod8DQ21vdHDd9wWjicUVCqrN3zi7ZDm4cfqew6Fc061dlbgZ",
	"OICh294Fr2xz2wZFhG2+jbNpv/ec5Upm56/gWYvd9p3q51PiGmgeQttvx6DH2XKZYnBJ0MK71EYvGVKR",
	"46N3RMnCiQjJByi5YIoNoaMBE/OC68Xg4mmfUDAEDA03VAzws2FXZnDxZLR/0+PSpR66qpks96Y4kT2r",
	"SWgD+joEKboXpoHj7ywfumfE+JXJvymlh9h+UHIdQWDzHMlb6wGj2gwOeh2JDKSYiea/stYzy0E/aYe1",
	"Wr4ti9b6sCRxbJGsDC9tEbNQsp4vqtpsfNtZ7cgveni3WX2gSdPhUZ88ummxOi80a8mZCJ+ZJ01Sn9w2",
	"xe9h5/oJOG+DMPCwEKtDaVYo0bn9VzUR7HJScMH0VhEbEINjJIG6oJtA3eb1hYuqNhj25YTcsJ7DzaET",
	"Nzwq4NTv+jQdHfn04zSc348+JJdmVlB3tyvzZz+8sfTB7NJ3trw+eQEr3ifvrHLoY3IhXmk9X4geide+",
	"6A0uDkb7fbDoDYuClvRwcDj4fn864EIbVWfGFXC7U8gLOqiUhF+/FQtJuPDd99H2wQ/y1rRdPS9bV3z4",
	"wzz8ps+3v+m77MO8rA4fzhP9BrbCxfwUvHBu63L4M5u2Kna9Dtd6VdhOCVb2PhUQvqKZIc+P37+ZnL46",
	"OnnxY+w9QS6o2k3tEP/S2/Zm8MedVnw4tay35JmSWs4MnPiL74f7e+h81PFugMG13pA/n7zd+Djc780U",
	"0wu7B7vzfc0L4wyDhdFkuiRN4X5whnoJ/tE/M2ZljHdSmEXCS+lODoPv/OQJTO5nNo2o7xj0KTN1Bf5q",
	"B0PyAsxs5OjX2qo0aC4h1AQuatkhLYbUfrcERfs5VqIkXl7v5Q628TfMhPV2HtQOYeScLfUNDLu9ekwM",
	"ar1nl9Wt4YBWHH8YXLLpAH9s+xZ1N75Vgo9Fzq7+9qTZ+it8nZUTKYpl8i3XSwKW75aslGo5AO9SZ8Po",
	"3vW38H2/cbSnhpoE4krO9fmk1jQF6HFqBUf38A6GMssnp0sDj8DNxubCfPe0y7y2jyRgHhtnJSrX/kxK",
	"pu3oCJ8Rbadg1dMiBzeMKWuc6e8RQ6LYtOZFHgKFkyvWkEATpxGCXTFUvfPCWR5vaDFxLsspXu9lgMZY",
	"4UyfUOchFyO5i6QsXlut/D99VP2K0iJlkUbtAS/njU/2UMiyQttHwqq6+khqu/uyZpyMivWjvNVYCrM5",
	"DBG7skJXvbntF1L8oxbw7NGqNxFyY92XXHfq6oU9CLevuWaJtblZ5TwiIExYbon3mxNNa+fNkLNMMaoZ",
	"Acud+zf6FPpYJp0BDI2cEdrATzQOKrKeQvyJqIsCUSIwuqAjWD1X9IL99uKH7XWt/HFy9LdXW0keN134",
	"/hPB7TciVf5DTpd9Ul3+cMnYeZ9U5Q+lveP7pFr+sGRURZJAZZlgdWn/U9r/LJPuyrpiRZEtWHa+LSxC",
	"U4NojOdy0VsJmC52ZSY5y2QwfG1Sjn0gEai+UU2yM5UFRBPTgmcQMciU3k3rwreXbVYXEx8u4h8DzlSl",
	"+AXNloOZzGCvO5QEeJjx8dSWD1dM5OFZNCUenfK5IHUVS0RT2yNIJ076oBXfA7GoI/TkVC+mErwOUgKP",
	"FVmxjWHTKK2qPX9nUHQWSAo1S8NOqJivQSWzN/4ap2OHwPIkhmN50n0Fg2CrFx6RqS1zSzHB+z+xaNsg",
	"ONmrEILKwIpNi0u61CNyBP8L8WNQXLE5VTkiTM2IrE0mSzCx++5H5JMvC/gZS4TOa7zdXWHDSyZr0yru",
	"zP74BetpV9zq6RMAxEjUaNAyQqXoOONUev2YQs0A8I+m+eRZb4Lcus8v3uMHMLXABaghKQICtEOCEWqL",
	"iryB1uoCQMRLvDH6rtkQ9wy5g6FtqndiC0Ux9rFI0XSekiteLKjZAI2XZXWJ8EsTZN1r1TlEVXOFfQw8",
	"u+CyhnDPC6Y0cilTK4GRZUyz1iORw7hzOCltWI/hWLxnl+7+AJ8q8DbxvqtcQ7shho7mOTYInwquTScS",
	"YHsoM5zgacWyh46pvB0yGdjJbsYiuz2wl1NDdNKe1KzagltFbtkEyALSnV9g3whYSCkH4JcoyPfTgpGC",
	"ahN0HhTxiFlW7nVxGjns1xrMryvvXwHbs/eag1cjcW9h2mEPlhAzxkjBqBKouChZeBBWEIiaNo4RwJNo",
	"BkH0m9oakp9hwEtZY5hjyRC+DQwZ0yWp6qmHGwVP1b80vVOtuTZUmJUh/BfTfeSYYeZAIyf8tMb+Zfvg",
	"X/MOaZzaqmtB3J5bmRbBwlpQLBqx2zKABQMYFjhg7onZwAl2jY4FRjEi8k+zcdwu6MMph6vOn+GW32Zw",
	"B14P3OZIN2mC19LgbX4tvxEE21bYXYG1BuSuDeHTHwJCxbo4atNaCASraUddQUQHDTEd8TLQgpwcvXHN",
	"DdOQlw+LLbbF447nPDEPvRkmK7qxbgeS5f53sNpAFy/rRbPXW2hZ8Z7WhhrWJ0bKglj+5Tytg0ixgpPl",
	"rxyraF4SFKi1PSiXzgiTFVQFR0eAHgI0R/ToPZ6RM1uDi/mkVfCMQEAzw0Bv2B4F+C867ppzXRV02QLT",
	"GAtCYKyXlOO2sgzGvdK5B7qSnmNYMyLsNZ7TT3AwOLtE76u3PJiUnHPtECyeZ+6q98LEmR3rJXqYBraQ",
	"wVtciC6Im/0ngXNtwNg6bSPRoV9AjLLFmf6GOFsrvOa2KFsRc28wtiKc4lUYr7GY1lFchj0EDZRWq4t/",
	"VRgsO+StOPgnW/Am+Kr4vk1oIsHEK7oHxAlUKVXDY5ivPK9ZDct99cZr10Hy9VEW7Bbiwokt7mgzAZ6W",
	"euDz/I6UNGdW7gHoGC/gkB0UZwALzf9mx7F7C/ASIPoLWhTJcDI7uu2w7oA54ylEs0sYG3y507BuOJfx",
	"xQak74eV/HLzxjmRRQooSRZsZZWJZoC+mthNkXYNAmM/kjq96NFD8q3Tpxu6JzZyuOnSC9895WqO9vzb",
	"Aawc+WoNiKML4ZUFoZqcs+UAHMpIRbnSKZPPLUPXwsRSRwj9SjuvFrQMKwPVpwyBJIoi8VqzujcgBEpg",
	"RoiGSuu2iF2T98lRHIVAQhiDbVGnxcSBVYYn3vB6lAdDn79wdxBdIZNCG2WVN/RepPq8LW+MyJE+R3kB",
	"0DPjb7YCNjsir/DqW4VzxjCpSzb15dy1aQd8yaZkx5FJN2UQ/mwOw5kxYyu9tv8Dgc6eFe7oGj3KjSSa",
	"ZbXiBrQY8IXYbVueAiHghKzMD/A73Bt4GEKv34Oebzw22yDTOVZkBavWrmsfnG1fDNvcDcJwUpsPAJm9",
	"oLz1MXTDxqDBJow+7jF19MLVkYwfbWARGmZiEMpVo7aiUE7O7anceI5anYVp3nSO9PYuYpFIBLICSPJW",
	"9HVwtRP4FSRgwHDakyU3xqpgeQMcPYrOXb97mvruWEDbr+3qomcZeOEjNI/3xQ8QAo5uEJqErk0fwA1s",
	"tz8W1Cl3DkxoRosC8De4xpcs0GLQS6xWVk9HsIaKKs3FPCWqtSa7PqQZPgPcO5QHHQGo0qIG8YRYIQLG",
	"ITpCtGNVWqc1cTK/3PL2BkaaECrgfDtWs9EUaMu27XewE7lhqZehZ/0t3N/8aWjaAD96q0ENx+KjYhfu",
	"ZXzGBTcMYvvwobx1JJF+wSHqyUbL3yqb3TT3zhNjWiKOkNeSqojTJxPaiIdwGkKIovOXpwFhjBZkQH5l",
	"Svrj5sFHwN8fgeLClhsmvRI9ptNmr0SHmxZDycTBDWmftlWYqPUOD43To6tDpsxcMgb2Mg0reuEmpYfk",
	"R1ZUumNY9eGZCNnVRCM7HBQ49dNlBDnmiaTTo4/Aq7oarvtEkB0jTH9VcGMiZvRoPBbjsXgEX20FiDjS",
	"u7caUAxe0ULO6mJY2M9dR1K7TNDuGr/DhWJ6IYvEFfUOj0sMqBpKuwQVngw5MyxbhcRpzfLD+/f/y/H0",
	"pOdi10MxfZbS4IdSsC2sXg6Drd3OdX+T7t0FXsRAkJUsUiEWYAssRqY++uKrN3lo50v3ffuI1ALDvbvc",
	"giZw/tLxDLDhehtR3AxSay1m2+pEko69nTE5n7hhJIaWGDfR9Ofw45IiZnxdrgVGOPJWuq5k3n5X6XBF",
	"uY5VB4N04e55HSBv0YbTqBugEpgQUGg77N0mltQbJ9dQFGYDLwcBEthIK1DFs0oIvn6LbR3GEDqLLLG+",
	"GW8chZhdlnaMSyR+0GuRLtYaqLYMYWibwzpovVTQYvmrA+sF+2V/LDzgg/0NAmjc8zdmZrDan2HzZTvr",
	"g270uORjzYr16t8BBXcmVcYmIYuQZRMboz9dYTDPvrMVmnYc2bay7J76wvd9OK4LwyfVQlHNJhi+He/z",
	"w/5ayYNGoGT44getcDFvSTst3/rNomQrScf2zlHrUoOwq6qgXLgzD+4ZtFhqrh2eMxLRAZi01NEbvKdW",
	"z1zS2t/Zuv+Jr6Lt09Z9umzU2HKKA/euDEvCxIKKjHkHVzt1iBDvTMNpQ+64uRA3us4jZX3KhPZgI3Hm",
	"t4ZS90mmJmvyVrnbzScjcaAA4LvhhdwkhDTZWdQlFQPFaG6Vzt17eEnHRykVzh2dl+akOFMGjhqiFK8q",
	"KhDH3m9nhEMB6/wDw8Hba6Z11lo61gOdKWcx96jVgGcC53zlwa2VisfZDO6zHkrWhiH47SbPJ1sSMHRB",
	"e7kvOw8trNmsH1zIaR4tO0Jm762YOiFJCBgnMYQ/evJtDXNEHLgvylKPFIO4/Ed9slhW0iyYwQyYDmTf",
	"Fok/PLoHla2QMJnS7HzdbJ8rCfA90yb5aTNtfzgTWyRsJK7Jo9DLo917jfWON6yupzclcXjJoBHwfa2n",
	"g1By47RyX/HR7jfP9RAdhw4/7ezZ1WMQ0a6V/SctkAKi5P/+CIHfCsnzfw+YwFvBAd4ChXQCT1Rb6JmI",
	"xglJKx0hj2ckGNjDHDwoV3bOclJXwxTS0V1xS++KXrhyhG5GCf0tcGi1oabW61MHua5cscZC4b12IPCC",
	"KsNpYcVFfGX60gY3aEpuDT97Cv2FjK0mAkTdVsEDBFskNLZ2q1UMiK9u5jcs5o+MFmaxnoQL+O5I6OVC",
	"t0jxs7w4F/LS7lGsYBlyLZp/52yuaI7Qt/AGmDYGQbMnyCQfhke38IcdjCKw4JmS5W/FOjHrQzQOrl0a",
	"lG/AjtwEg6DYhGzYDT7hswmAuelO4MaP8tISaEFFXrAGpw83E/D0s3YLZyNyNJUK4LWpWLqNTgurtiyx",
	"Ad0OxDizkkGrgdNzXq321W/uSQCVgJoeUIidjchLJSuXKxUhAldbaD2Ld6bdHoSznELb7cPfKfdgrN/N",
	"by3vbwFWO6y+5Ib5p14E4aCuuwk28We/zB0GbRSfz5nagkHHJe/HoN1gbsWhHQW2ZNG3YMungXI3+TWs",
	"eCXVZjFxGmrCQUHkHJFyvVuuLW/5ZGMN9ulqGyOs5/OJGGm7b39lSjob2LVn/ZtdF+OLpwnRuOEAec8Q",
	"fHSAjEaQBc3HM9ixti6qjf4VbqjJFQB0m7thbWHddTBbm5K/vPjw46uTV3fM/LKCv3Q43A+st08O9p88",
	"JTkv9W7fFQShveBiXtMCSt+Ax+AQnjJZ7gXNBnMMtR+kwM164gmPb+/+RbnX5HTpjrQNvYXd9W6XtsVR",
	"PuRseUEFoYWG1PCaGaB5m77bZ2mJ5xXfp90prrAZh0TucuouK3CsQ2d0u2NksLhEOckiLtht3/3iteEV",
	"n+G+F2Bc8Eg38rObCCa5GF3yisgrsLPJ4/QvbYChZOtdNq1qYVlTe2Sv3r/cIKIAJTUppJjD+xbFW7Ok",
	"V/hY7vBGY5K+//D+Va/fO/10dPKp14c+vtw99QdS4o4gXY6Ma5NHybJE8Mfts0fdi4Fk2OFADaqi1q10",
	"Uf5L80862D8E+fi2bCNbUHOL9E+tMSXZxH3zPa0yjg3Jnu7KQ2YK8UGXk4oJWphlynsIPjgnbrt/Q6WH",
	"grb65+WbWl3IrVjMesbSaa9DcDRvZuw29PZ1HgxJ7Pd0VP/u6ahueRecMEXbTk23uAoUVP5txUbsMy03",
	"7vb953tLi9hO2n8pMYR/cYGw8bWcVExZAe0WPpctEGm7A6z80vwCsk0bPvRm1pom31b8tdlw6zltuvmu",
	"DCeribjJJbSU2oQU0xEiFlhDwBnYX70hgU/ffUHTfhvx24ESpah0iyPrX4xu558UZ9nXmmkNLrPkleXO",
	"mE8DXzR/qWkBeUZEPhYB/C7gKuGerPHpB+if0YJPMd8r+GNmUqFNS5//+7oj3SrVeZK0hFaVkhT841eT",
	"nGumLpDnDxBtYG7/veDzRdwWn0UJ+EM2ZJrnCnBvowjiNOhkZFO5ye/HxYxHHbslTIIu3d1B6jq9mduA",
	"YfdEUstce7oFLrQVqtqNRrCm3eSRBHOus62tsf+3aL7WZtT2oCFRqRCog+ZqkQMcVFWrSgJuymfNZnUB",
	"27EFwuRy6dOSZLIo6FSq5PvrZ82UvcDh6RPPVKPeOz/rljsFCiNvQVcFb9ykCcLhRKzPR3LT0gCWZONe",
	"l8wrgjCJ+PAs3V/teGdyjKNwdkKS8xnc78Zja9CKTnnB7YjgveB1O3+8C+F7/u7JMzd1W+hvmJY9LtEQ",
	"COO0IfO2S8lQypwWrdK8pHOm92idc7lnZQZppZP/kjXJ7J2f580Lta9mZIg+Wp1ERY2VI3Un6VBYRER8",
	"RBDOkgnM7Hn4p6c+7zT6TnvphhbFwMqXRdkWaiSENsXH5VyIycU+uuqAmSf040qEvP5QLMUERF1OMAnT",
	"TVcxlgCXZnw98XIoJswjL6mhAH9AlYGtxnIfjOGqBiwUK5dCLhWP/H3Kf7VX1pua5xBrr11S9NMS7nBq",
	"qGZGkx1M9nWwv/+TPWR6d0QOBochgdSAvGM5r8uogi06OHjnSx8ODvaj4m+pmrPV5llT/GD//4yyU0FC",
	"LDcVt5enzC47aBZFwQquS+JwABw6ok9ST5y7RiABu6pYZq9szEvHf0We0tlNljqYFFRCmCoM4hQGATQa",
	"C5cNVnvHisePpbA0dAn5FHPZ7rgUjx+HTBu5vBSGl2wIrZbR1CAnPeYICXnB/KyvIDGadikGMAhEk51w",
	"4KcFpgNB/1CXuC2QQ5O8BjZRAN1xfJj2f0DeM/An79Bz5jPtDRaMXiwhr18hKS7JZ4c6Ca5Cln+f7YX5",
	"srMGnRnkGHjyaQC0fP8+YGc0FmdnZ1OqF2Px8cPpJ7I38c3uXRxE7UI5dCeB149falYDxkxM6hB7AO44",
	"gGOEmd98fiu9kqyv34xkLCICafdkGXKqwUOG3TR+KX2iAxitqit3vUBKx9zKzQBCZbcieVVQbXjmgo3x",
	"jB2tIwjZEZKUVGBiuJD/zV/LsNAfcKsFzySo4/cWlACH4ooqVOIR1swnr9uBvGCKlVbyxHQCHK6IWmFP",
	"DT1324z1cAUFNx27BffYVk9yp1g0LSMBu7MX9FrhggtuOC0mlSx4xrd61nVVIHEZ1zoYPgLY17Zi9MfQ",
	"APLyJJxqkKsrqvWlVCCWxg4EmTo0H/+q9eUHlceGj1A+IV7YYabhAD67L2FGgl3irKy65q2k3i5YUbPo",
	"o0+ci7qnwircPqJRKlLW2mAetFCjDYLfzOUfciFyuTnxcZjZGonSp7RJAgAyrSfnbJl0Jzn6+dTnxrAX",
	"3fHLyOvNbnh8vF4KQ6+c3JIpZkghJTh2vW5Zjo9+Pp0cvXjx6vR08tOr/5ocv0zaG0KqcmbaxFjKWg1w",
	"MINzthzwfDM+fusx6nAAqSINnMsmY7qLbdSHLkcGvdTDTJaP7Fo9sme2WEhtRn/e399/5ODlxfGH3RWv",
	"lXblHpjUvER7kPLcAkpNGvqnie8I2qzBfRfg9NWLk1efonW4wyJgJ9FaJF3TGBxktLbfwERwlhrTv6PR",
	"3x40VlYSEgdGGZluNffUsKGXAY4ozQQmWhfbI6O93fv09hT6Pj20qoJgLjmoNyCOiK0PJY5+PoWnFM2c",
	"zSujRbOVtolueUkjtNv2MYaQvI67yxYeyd5zwfO+hFnrHu2usCno5MtNM7st7FtDkm78aoia2mAeC8kx",
	"E9Bbof1TmPmD2BVyapgVKSYVVRpVpRQXayEZ35ADfz38vFWanWVr4hpcc6VGNpmmijZUme0qhaJbJu3v",
	"boBVsPf70ti1d2/bDfDx9sw82vvN7yTNCJIbXmbH+YPMlOftOd7O4c3WXjM+MPucBrFzNbJiBmnAIGOk",
	"xxxBfPxgx3chDbcwXR2ljFSt9pKPEY1sfAskKnJBC56T/zj98J7gLEluJ+Wxun23j3QzwaHTkzzkCliJ",
	"Zkw1CaVVDY7rwmWDhDHrYQq8PHkK6uzc/t8b+a1yBAg5gbSAm264E0x4+eOnd29D5po1oJ9926jV6ZSd",
	"xaaGwdv1x0+fPhJfBW7DKXVRa4ik+CBI+Q01ybFArDqEHQyw+VGJAJoPeLMAcM1YjJiPCVbtyUHszPCu",
	"5tIGgwDC4W3RzeN/kpIuQYrCR5wGP9JlY/ewWU7BfS8NGz1+jDHeAPVq92F36ORywbMFWVA32BBG81qC",
	"Sp7XGN5Xa9bH3MVWV0esT29+83123i/r7Nz+31w6GH6eBt5/lacBEW3BvE8uGZ8vDAZ5Opko4J+EV6zu",
	"Yw4mO59Qk0xngwoWy+eMXFLtU6O3EnGsvXRuES3qwmRux06CNAvDC22sUu4WIXHwVJMGcv7u6YCJTFqt",
	"072oBR6JsvjNCRBukd4HYDI2DgKLfbNBBK/Dlghu6QwOhSH/dsYN05h821nNJ0a6ZNy1WUjF8sl0Oe7d",
	"J1IR8zhvu0UB7ttVeeh9ikdsDWHw494WgeFrpJk7xjK6XRt2jms2jPbL3Q+EnddLuDC6iTjqrudpKAo+",
	"7rmDrgeTNBiEIRPGh9rMJYROQ4HgwiNkDnZcLkbkWGSybMo4wEpfYirNYkSeS7OwLWJjmJ0/rtUKxsDR",
	"cvuTrd31vrwdTT4tK7b9wz0lAcmX+RPUBfcsCnk50ayYTQCKbOOlHmWHw0zlET0p0ApEJWObvE+6sZJe",
	"TeJ9vy7jk/c8gcGw3B1IrPhwex9Ug9R49vtrcKe+9XjSBsyGVYIZMyQ/tuzyUZ88apjlo92bgHYm8dW4",
	"Ki46EB1fxIO7hQDheLfdUVdZaz2wE9TrY3Ai9JS2W5+hReSchHsWRbU4mCYywkORrTVKkJG2ym7eDbW4",
	"LRDYGynnxWrIxiYgsL8xZdjVLSshIOVtK1VMHB3fslI65/umWsnglfvAm/mmHh7fTKwLk/Fdav964Ct7",
	"mE/DygqyN8MTNngR8V8ZWcjLyEmMKjYWCCJtHNRyMks3+RRaqzUjP0JowZQq7W2r4L3lvQUuqIKMMNOa",
	"F2bABVmwomoUCt8WOcWYd3yXe/z4FJp6/HgUt++mAe9zXgNZhM//AEv6Hqam3sVmXkDelrltpxk1pBiK",
	"cwmRjGYLT6v4QZd8+vQ2ss0+IyUXtWHat46OWu3WFcsYeNQuGJnVkRseodrjZODcn3uS/IgkcY/aB0Py",
	"+LHOVD390ZTF48dkQJx6jTtlDzFEDJ2j5YBdGUUzQzJ7O+KawU1qlXFI73B2dtZQCX75+jW0T6x+P3HY",
	"ydfXvgL8r+9YkzP0PsABoKvAGXTuP9gh+d/tyFz9ozzXRLBLTAJPZ5Adp5DZOWGFwz/aqfok5xd9sjgY",
	"LL7rk4L3CTPZcDcMAT0aAawGpwfrBK7n6gIQdmiObjRLS78nln7sFyDcK+9RCC85iuvGIdGranotjf7A",
	"Z2SH/eJDucc9zEQx7u1eXx9hUopaM/X16x6fOco1lf56zpZWs7DiEy2gzin+G++6uJZ7Uz+0Ay9ZzimM",
	"/Q0TP3GrJhmX9AU+OWc8nxGjbDx83BqunQ5Wr1XxA/j/vKSGfj45DgNvPtsLeAhlJrUqEgXGIX+0ezGB",
	"gwc1hv+o5uNesg5EavtnNAdX4SpVYl2lVQSMbieOeIRYruEz0QMgOJjpnD8NbKUzK2qMzsiAoEZKvEYK",
	"Isjnk2PtpR0sCZ3t/aNi8/85hQr94XB45jfmmSXCaG/vjOzhvzX8MYD80Z9P3jpXtsbpwgOUg2wVAEN9",
	"a26mtoFVJBB48/VHCtE+bLH2A6XLq0x2UD70sCCrBD9nSzsDR7DGAcIDFH1EHw0u5g3dHj8+Bo8xy+he",
	"yktRSJqjs7GGYLwdPnMZaiD2KbpBAmFDSx9fvtbIMK+MZ134zj3jShtS2TkoSGzAcssyYRFCdcvUbPUT",
	"76Zo2u3UduTknfyVFwV1pQJnwD3iIeF9OImfp58ZXhCVkga9lKbLsHIBTl4zcBPRZEczRtp604n34d8d",
	"eS7o5PiF1IZcLrhhBdfGffyo+IW9AI8/ImeE263yIM+npyevCTWGZufabzw/UHRGApte/IJ4sL//7nmn",
	"rMumGBc83A9NwvqS4J3XbfTJ/tM/VVd92M0Dt+5+G50yNmrSc4JL1pBLiG3Ya4kxf/D0GwwySAI5Fk+B",
	"WcMx/CTBS2tAXsGfuHe4IJ8+fHhPcFOTnU/ynInBB8WZsGvzAZH+30vjPWXWML+mC9AvhqhvBJaT/uzC",
	"Id9BStYf8C2WQ+7TH55uqpoztAyrH8a98dgk2dXPAFekYYZ/cbsQZss1oXhlZaa/6pjrSJEzzefCOb5X",
	"FI5sjOcO5DOSvH37zgpbhJBj05itHz8+3B98t/8/3BO6Ys4KjGGNFVV4fuG543LBCxbQpm034C3+9u07",
	"aNaWV2zhdg7NslrRbDkMs/yJLclrBnFFES9+gbPzMiOe27PRGUxnJa+HP0ZWI3Jr4vPkjsiZFTf+/ofD",
	"LyNCeR9t5P2y8BLMJzqtC6o81SDDleD2L+d+6Cnme2lQ3WzZt2/feUh8kHdqy5i0oZB+y9V45yijcaVW",
	"5REgwnMm2IwbHTPVt9Jb6DOpjXaSXl5nQHu7LJCuHlCuNCmgtB1PqBFaek21gcxcqNNiU2/BUz9EJDrn",
	"u1AHvCkzL8GSAXnNXWxcO26EezcL5AlhRg7TPbpd49NyRnamUha7mGDkD1Zam/ErsPjAKoKSrTF34pld",
	"vbMVH4hwy+KBOyM7XJjdEXhUe/dyXdHMg48LhCJGJbnFuUJL4UiekR20IeyOCOR7j4C8wQLh9gwMNW5L",
	"SMEgrR45c6f6zFfQzaXqY8Yw3tATyAvVhpuC2XmY5unFSO/Ufeq8vAkhaIQekf+ggpGXEu/A9GaHT96W",
	"grcOIQwl3BF54n6wV6sekafP9juc6KVLEcgFOTl6A69Kjg/B26b7Gp2hoNTgVQ1oj1DXv2Y15z/ch9Fe",
	"gdZdtL9PJuNvkDk3i3oKIqWRUgywV/i3q/1GkmNL4RBokKxMi+qc6XMu9uYSK7cUTrdKXuvyL9gotEW0",
	"XLlNPuHyWSnV4aPBglru/pKa9pecGvjwic61/fAHiOxsKtK5vr7++tVeG9fXffL1654tYGuMxdevkU7m",
	"lgqeV70s4mQeO/vOID/i1rJ9Clri4Bo7w6il/0UGCHjrtYU/Kp6xEfnj16+V/Vc0hCiiAPOCW8HhxgEE",
	"8nQ0kMSwosFEnb5otDW3Bxun5bjXVmdWEcMjdH39fGkb938F1avR1jJq2Fwqq7FVipW8LkFj+//+3/+H",
	"fMS/vYAcVZ7KfBmN8vHjV5Fn3N+cZ5x35z978+rd8fvjJuh00GQ9l4qgQY4cHUPZDx9fvT9aWxatY3HB",
	"50enryafT9561QbUn6ZorCYcfTxGeKgPb98evTua/Pjh9JOthnY6cKhmCuo7VchpOY1j48HB08Onuzjj",
	"49LqW/b0f1QMuoEch69C+I47XT62hEP5BnwqivPZAaMFDrjv4i37BOxey2Du2rXSeEBMHguzYGUTnsYF",
	"WcpaRRcYihWWh501aWK1iwV28OjTJSQXA1Y3Fo2JLYordwjqOXrja4fyGgXGuWeeVkZ8wyrtM+KjH3VT",
	"xik7aJxbMIzXqxS3hYIUDqaMn22Pq6Gc8WRG5CsZ99AMA22/p6UzxYx7I/L34XCIH0MV/DgcDr+Q67NW",
	"mDMM9+zs7B/a9v7VsttxD86UbWrce7cknk+Oe3387M0OUCBwUUj0PByGUtGAbcmveCWNe+VygsTE2B0Y",
	"8f7woE/2h0/sfw77xA7UFr8ei/iwfdaMvKA6HLB3fK7QNojvSC5bKbYOsp7V4V14WXf/2SY+65U96VEc",
	"QAlkVy7QApVyqNHs/yre/4ld3PanWOn4OXh3V0H1jscgZzOIM3B2WC7mIe4yERpu6T4ItQeHA12GtGIh",
	"kKpignKwS3eM1cnI8K7ZOZHEYs5KLniv3wPt/6rX9wFbfd9hvzdFEz1gzzosEsh9kYLeCTwkDsXrPtZg",
	"Do4tc45EAX1NINrqjJ0k1pTYBHYfB7Ft8zLQjCJ4Yq4m0AdfMBlMu3E4JCbTuLu7SjmRolgm3RH8o2wN",
	"eu6gZKW9EiFI2FmX7vMaq+uypIr/yu6S38C/YHTH3X0fQMuoZ9+4a8vK6CE5ZYxseDhAqyqetAYxuOUc",
	"/iMrCtmPbL2QAXLc+w+5ECA22H9Qs6Di61cGbs1fv74HMcwJD/8HsfchVYx8/Xpk5SDI8a6JLPLhnde2",
	"40/qt++XtS+I/nCdGmoSsR451+eTOo00d8p/DdgIeKNxQaZLA+54rfCk755230a33zTb5j/UdgpWqyxy",
	"cKGbMg+8nwA6vIUzkTS0wKspBRHYRIh6icCF9WAg6oNSAociZM705sdpKPbNBpN8k/YLtSZ/ZXN8jgRh",
	"8fJtjFZaxb+NOr2gxfbOLBwD9hiiTjhfH4w6da6Ww7E4yoHznhy9cRFvfeJScLu/pIozYJ+EZOjddInY",
	"j1Q35EpsygCsRy22jXx75SuuS2KIEP0To+rNAJNvoOwnKHrd7/2jdt6at+TRUeqoTUP3CQG7W+kW3kxR",
	"O2vChRyeUrPgU7agF1x2016dtz2EOi45PyGSFLT315+sDq94psFQn3HLZv963ieKZbQo7L9Ens3/er7b",
	"TpqzMWuO1UMmK/novI/QsJM68jSTajUhnW1hb0Z5Ae9LquTCAx3eA+YKXw4mmmVS5G3vrsMOoT5h6VXC",
	"c0F8/ajrw000uV5z6NcmPjs1VOS0kO1zHidDw/hmyIXi38baEBaGOd2gOZvBobsWmMoH2UYSYWYdeMuJ",
	"v44aZW7PF+76OEVZdFcO9u9sZQu20u+h8bVLojdBpXNwcFbMdjhEZCckFsXcEy5pzsCKwElft3WZYRSf",
	"c9sMfN9DANOoo7TbnNsfE54Cozh+CfDLqruL4MU3SjPkeNPu3T3noi325X78eV0SrRcuS0D7kELZTgSQ",
	"u8In5Vq5J2rEl7YMp+RFwRuukwqSl4pttbFOsWTQYpZbVXJF13Kx09B/grNrItWcCniJmi6DhbJDn8ZM",
	"dVesm3Dood8u3M2bxhDm3WmQcmRnRrlZzOpCMA0g9A6oy3nwpCJBwj79VqM9WTkIYax4O/dJuLLxml47",
	"1rWr1uyAFee9+VyxueUjVhvhgDbhYWBoUURcuetCjZnBJjDWVHJ/+IxTWdvkppSyAQ/+Bj0mvjkW1HQS",
	"ya9IK7drzNVIA1kaWmzhdNu0iLfatgJDc6kliEs5xKs2rWMc3ggNjasbSj9+bDcTsEsS34dDD9ZnOfgu",
	"hA3gnhuREycZkgGZuVcb5OYNup9ueLutGXbpiHxsZMxO/eg2cETG3AfYrm3I7vEReW/3RgHM5CXX8PrK",
	"cvKiLusCweDeUC5s8VKpEXnHqLBj5pUCV6QTKs7hI63cR78jw9iQVm/fvhtQPYCrPkUu/IBOIZ5CjmeM",
	"yLH2d3Kgi4/B+AvZuZTqHDKmta9lYqQEd8yYFcVt4Qoh4oaTt/5iy/tENVj+pWShxqwuIqw77B9rLPAh",
	"M27+khXFoHG7gIKazphZxqXsL3uRkR+KLVhRJQZcgyjqelSKZWa1xIxmDorQFfgL2YEAQERWwgA/IErm",
	"wv0mjnGPyJFi4VftvDVgPJEpF3ctMCm3ur1+z+4jK7srBRJ81bO83K0dppoI5Af7bkPdYO7FkkgdSHwT",
	"5g9FwlztXysDT5uI21dBQuSGFJwurkRzMY8PeTch/J1C+Y5CyabpQYiaSYb1OeZ5gw120ZKMkG8i4FjQ",
	"DlORtZh6MWEjbXsQQeZHQeOo6SB8JaKlk7R9X5cs3K5kZ39wsHs/0OAOiV7TjJkPIfR7RSqkhk0QR23r",
	"AIsY/KGbA3gtKILAmd62N0egtR1q/itbgzaRJkUjSz8gKVyjtyIIQC5hptHuRf4A1Fo/JsNUuX2bn5gq",
	"Y8qlGvRix3arYGWhD1Ukbq8xdnaBNdKUlHFbITNYpZnCCEXLQdPpFrqDYyYGANhkC/180niSzGxVLuZD",
	"ByunScGnezpTtPLeVblzI/VucM1TZYOxA9f5j58+fdyz/zmNXKCD2yxgKFD0eh4gWgA4JZEd99KliWo5",
	"9l5wSuZyEHnUwbX28eVrdI+OKtryu/gmi00GKGTduCFj7SaSABoBtMVDHK+XVDTRh5MISgj8HYLr8My5",
	"MzqnhZhcQ+cn4su+iGSddX7Aa5yAwffXeQKjc2va9xeg5pzZLXNOzQnLlIsmnNjek3ePGw8mBW9GCsm6",
	"YBdEG+V4RlhZmSUm4YImMa7GVdxhVxmrDKnCxCAjh/czIH8f9wD7PAogcKHXFW//+GUsbmHJ6PeAfhPX",
	"74RvEY76HAJSnI3Q+UqG5UA+1l2M4VhAPZaPyMGT74f79v/v/alPDvajf3//ZHjwHfx18KRPDv5s//wT",
	"/v3dWNzpNdUjMAGkOu61SeGAw6KJPtvf399fF+jqT77zpbWS8YKCB73SZMdnl8kJnzncy1YG5xhdnV5N",
	"PG+Y2C05wTfAtjH96Z+eff/d+tHkrT3t3xE7Hu1pE07rlG50A4iK3tqyvepK37Zpb3WB8MIwdVqxLIWF",
	"MYOvIeCaes9QWlXoYeTQRRrYkxVMr5ucCTxKseskDduN11HqvfW1q+YKADdjv4wwvgoYkGBWyTSEhV/m",
	"Zm9u2Ii8Ad8nl25oRyosAtysMHuFLYKuyt3vdp9SLvQIvO/AxVrXUxywU5Jn/GpETg1VzjcKdEp7Zkfk",
	"uUMQMZfS5wHZwVccvYCH4ilz3sh/L7nok5Jefdn1cfx/g4JcIGhlut5uS2tiv1gtyWo4cwP/sf8EmbqA",
	"f/rJoF4141dWgwLpEML7UwoO9Lp2NXBMzpW576wkfeJ4CfrOwfTAPmx72uMirKHe7dh9cQdF+8CPIPX2",
	"+lpaVl9Xt8sEEHllzKCBQV0FKHkNCaG11dXQH5s1gPxjYXVSh2WThTQA2YLRiqm9GXrAgxvUfw/g/y75",
	"yExmtc/evwRkgObV/TV8k+CCGXlON3kBhcMZyKhmyfxAUVy855H9taa/xOLGaZHaD6MbHaxumU4gQZrI",
	"Sv7tMwu8rn/9lYMhw4pdYukC8oNyzIU5fJK6zholgNZGJljCl1Sekpnvzivz+DgJyTIsqxLE9WA5AoDb",
	"yHFv6Ae6fBBYufXa4iwmxk1tNVS79hwyEmw2Ew+0w8QQVnOK2lIphpbISnc3WIXuG+Y2uAq3rYUO27eu",
	"BZ6pt63loBVuW+1ImIWSFc9uWzGdJvA+qAyhrYeHZViTkBC06TfNtbIGmgHRGLyLondY92gCK2ALY5FE",
	"WyCbwBbcheEjJ6AO6MQlFbyCJ4CAm/7fAJHB3bNIAm9cRQ/+SN74HaLhG0E0QJ3I4QaoYrfQJZsG1dS5",
	"u3unYWc0+k3RHR4I2MFP10qUZ9DO9fUZklivDpcUcs6zOERWAT7oMlZiZl5HcgGmv+NG/I4b8TtuxO+4",
	"Eb/jRvyOG/E7bsTvuBG/40b8jhvxO27Eb4QbYYfeUlJQeovmGWbRwSt47jPimQXT0fnpe37ruLnjkhde",
	"HVqOECEC8SRCNcBT8P0irMSQ59fXI1u20Sbh90ibtF8j4Im/QZ6DMP7jlxF0RdRV1P7Xr3+oRWG5xl8L",
	"qo2DssCfIObRN35rOAerc6EoO0Fd5vraWSWsftz+EPQu8GFQGLVly4E11E/UtuiYl/3J2QtGDTWjjwPi",
	"sTlaJAoddSExnMLVIGMkFv1I0GIJSQS5DvAZHS3La1Bj4Q33dipg4J9QxWjU/+nK3Q2CRZKgQJePmGgV",
	"Oo1kkFozNXGiE0gqT9pSDAb+2f4+FpDfkcbzcNlbh1F8/gtZllKQ1TD9x4/tidkJTrWDo3peolDW+Jnv",
	"WlH9NXKNVMQDmoW8F6OzT8WH0NZ/AcaWFmYKPo349CPu2DLXACZufFFYkchzl2gcjj+18WEwGQVmbsxa",
	"NbHNZm/Ylo4BuIIl8q9aJuhMgFgRMoq+DocD5oMKUkpWaznNOMsV01Ypo5nhWSD+T4xVERisyz/hfWGv",
	"0PpApqyQVkfhIk5ZSDKHYW5XNCsYVf0GO+aCuQQm6CzSuNqCnw9sQeLcxjzU81zRjKGr7Y5pIcqOvYfZ",
	"OVv+8CtTctyzypTPsQ/uLpBeMtSCNVEM7E3A2i+cGuCsSO0sFyvICfQKc47p3shqKyFlfG9emcHT4UES",
	"PAEj0u12rRXrjfaH31/HTwg34ymkDcb3xlSg3ty+Fb7CGyafyxrk0efy6kEegabSGFlOVDrTwN8LKfqk",
	"oOZL/Fi6MU8SvBQeY/En8FLY/LG9z6KR1aRgs3/GsFbfn/xIVuiVfpIKa/RRFsv5A2W7Wk+mCnuZgOln",
	"e0/LN0x+hCSKmyLLVtpfM+eX3GpKGXuo1F7QWDsI/WD/vLxdbjSfjfWfv4PCSKLJraHkR5/ask3Bgpot",
	"h1jIrbOZpfo/XdAqmfjnDZNgI9C2gNO+HB4TGDHgasInt5ivIxTHasStVDkX1PmddVx8XT6YDa/CmGog",
	"buvLDVN6w2TJTGpzKlZ0PHrBc09b/bLtBoRqcpI7a0+4DccOCdzJqwK/9pvB3DSXb8xS5hGptplMIO3q",
	"pEJDycmkEhps4Y9k1dSAvUZ23sCFu7sOaN+jsF1wSs5oxSfnbOnAxIhUXYy3VKrUYQtxi7yzwgbk1MLL",
	"PgJv2t8/CDaEPjnc//4JyXmpd9OpuCgfzmEiw5xd7LnGaMXRntogCLWlHzeJkC634i4/a5ypf//7J5FU",
	"lBhmW0RyUst1xwHZ95WSifwiuCxp4LxCCy3JlBHN0BO8Td40dVNMfQXsKXh42ml1R9JYs507TbMZHJjY",
	"zvff/alPDp4dfgdOdrAyimWyLJnIWb47TLqnrL9Aovm/KGSdk5BJ3SdfqfUgY8IoWhw82h2SkD/FbmF0",
	"HyFHx33SCl/HvQzJ61JEcesZJ0Zas7TdwYI3aYc60GIsxYbbdk3DXfFDSXugk6mlO0Ryhcnxy5W4/Wbi",
	"/ZCxvU2p3SRFalWku/188tbPNtqmTUZo33sf0/B5s5fPiYzmKrcvGhAexTci3+Aared3CZelWzC8NWqI",
	"Z4KbGNWT4bPBrKB6EZjUbj/+VikZ/j4c7tu/78K5gAbJeIZbsJPUcj/ceUwer0it/LrG8b2Ja27M7d5D",
	"Ms1D1h/asBobD2y07PGJDXNbbfBR+7dKyegXt7BIhM6Bjwf1UIc9Se2WMp44BPBgSxQVuSzBU5LHLqGQ",
	"7W7wZLjfPqGdGMYnm5ByZDU5TwWxV4Nzoi1tQKKIc/enIuGrSZWKt8wKVus1zdwd3eeOTO/BWdm3ymC7",
	"lku0OQQEHlg5482HD2/evpq8OH0VyxlWvkgCwGSaJTew89jGwZFXYs4Fw5uq083xyxt7wPBOZn/IkrBC",
	"+CVki50uSQ5YNu44598/wgTyVBvyPcnpUvfJo/Ig+rWUwix2Wwe4PEjn6LfTmTQpNj0TumTTLt9ZVsBz",
	"XNiKkaRiyu6ZyMCF9cAeulWc4xZpfD3baC2Az+B74qP7KEmu0M6L01e7dqhtT00u2tzohRRaBlH+lJm6",
	"WkH6pYFjURMuusxVy2wj/s7LZAlebc53vTNu8O8KrSZHHXehWavhp0Pyhpmwy6nIyYvTV+T45Zp8vuyC",
	"FRLyczWt7KGP6gAXcu/iYE9eMHXB2WU62e8bRasFAEv+bf8WkSG21uRi38FJJjNNsnzOYPfdhH3lMwfq",
	"AK/MVdtvV28Nh9VOmJnK9k6vJpDmb1IxNfEvFNtc+Zg/sGLRm+jOPvmB1MKllN59WIDGeFUC4GcHPM3D",
	"1nRXZMNirIPy2Qg6ed090rUwbQrF2SA7E/uXgAgNqR63SRrpcDmBvt8alxOW/b3M2SkrQHtdn5x/IS8x",
	"zNAWtORSZs/lakY80bAp1sYgnrNlggqvrqqCZ9wQH14MKV6h7NaRvdsvCByfbU4gTqqZccjnG97s824e",
	"+9sDt9puJhh3uREFQeYMg/sQzcP2PYHy3WvfDTEKDPUSgJPnqcYZQrDmuPfHWV0UE8OubItQcNwjAyhp",
	"vwzAIbLdkqtIz4XwdYbACyZWnwjVnVVkZRRAzYCDguju4j7oxnfFoYMT8J9poL6XLCuoU4aanb1E7G2W",
	"1fbOBY/4QKK91mzXheGm4+uzhX/8hDdbSPIPZIpz3D/4ecB0CWzSdNINKGXGji3OVhmf9s4huD34tx/E",
	"Gj7pX8aB0fuQRPBzp9kCtvH9Ovd7NqEGwAxR5sB8x2Wt4XII15/t4T5J4EFT2/yGFrbpRywPNY1hKmGh",
	"+IgfIDGFdp6c+IvbvyuZk2/q2LV1alh1j12G23lCCw7xo2u2v/u8uv/bg98BZAnyA6FFsfstTgRcbQ2U",
	"9sZVaV2f1z5b/X0aWG7xuBP2g5VA1z1YRVv7y0OwyI9hr65uOGdtiPmCUfSCKU0LxIShZjHj8FidwB6Z",
	"S8XNolx3AEMBB1gb1NeKzpmi4vxRnzyaYkC/YFo/us+BDJ1NmqO5PeDXCimCJNfMoXf3lchZXqPLDVuH",
	"9e4izUI5J8fshNXYvQ+vdGFCaBbdpBu9DIVdtvN1yplDLJguI/XsW951EPiy/pqxn+P8Dg9FvPOb0DBh",
	"TIjBIXKycz7QC6kM02YAX3bvI2MCDgurPAZMSu5tDisWvGdvXibYQs72EmGSyHfr/ZKlfYx857DLXKH+",
	"Ru+FW/TNxfq+0cz6zfq+sx6BY5mUVoraLAssfobi72zphxG714FAn7h9IWeExtJ3F5iRGhC114pBrgAi",
	"YcfCBGdtHOwt5KB3tq17sKC1XBuwKPHrliMCEmLF97Acdx7UGn7oBoWcyRPPX+J3IeB9CGekTPBP9MpF",
	"ZQxCHnjJ4mO12WTSGwHQ0/BlHQBAbmXb2WzVeQAjwcNJhDjmBxEGPy1Tzlverp/WlyPjvmP3DGCR+Hwx",
	"RZhqf+3BJd3r984nrV9Ao3Z6z5e7y3irZyfhgwZWKC5aE2mWcgVkM325ek9FZ+2wesWKtnr7rRA7LK7o",
	"UMCZWU5CkYe8X2Lj9fbS8OvYaAARvR17A8QO7N5DKF5jNHghhcBQWzSr7lwumCAtS0Poemtz/z0YWPKZ",
	"MQTkoFvV3W0Iqe33E1uCNRnk2WgLApgF134rPriYbftbZ8p55U3c2w5q05Vyr1VZ4ZF2Ee7FGpuMJglF",
	"1n4kAAVPQnBIA+PcfUCJ0LrTXgsAFNI0IpUmdCprQy4XFBOKQBP+QcHHcQ4hAS8G7LYww96+fYcQ7AGw",
	"YNw7RUy7EnEtSaU4xEYazpQe93aHY5HOVtJA3d+w6Y9fanIu5KVwb6oB2P1BcpZ0HjuOPwKA8IN4tGY8",
	"T2P5rnN1XdlqUD/l77CSz3LTuyjAd+H723YgVM8LdsHwoe/JlnhLyVybmyolnnmvv3TvzWh26SRdtJWD",
	"up1UkIqccKNJVatK6mTeHCYUzxZrDNvhUTgUchFKMa5mY/IOOVZzdgXYxq+axom3C+fwXJYTewIXjBh4",
	"trc0L1o+UH/vaVZSYXg2gSSlIPq41CFfvgFPTpu330eOX34brenx5tWGhU7KndCxa2Ttft/uxfleex27",
	"uN1W365O9+n8+saJ1olkmlk48Bup3Hgb6AVV+USHJu+SL6c1z+6gm8a3bWSVz+FoQ0sro15LqDXKxQKt",
	"g609G4fENa+YF/u9fg/eJuFf/rkmGU7xE1siEH9KhEJsVA90gO4+IKk4SOjuE5+S5Zoos/S90KHAWy4Y",
	"Ve+YmrOPdM6aTdM9HrUzkBRQhZS2DqLdBPR498Kr6wyQGnojclQU4JGuchDFpnF+aZYTVxKiL7FuRZUB",
	"OKtRhORDtJFVhawOFpVMrYhD1bJPsoIDsg1KD/YmX6K/jbBrk9VKS4VNg3+Gbfg1hWRd4Jchs6xWiuV9",
	"ImQY6boBRsvvPoCOCCPu9Tv5QZv1iMi8NmPg25iugaTAjvRSgCykERvKDxNk2iYbuKxVBrgFn7WLhjaS",
	"nDNWkSPAtAGc6KXIHKyTaKqGpOQuQblry7mV/SgvCTcE8t5477JTJvLkcCDv/cqYwK3sFBP6Y1IBHSpB",
	"qiBIgx6y5sMmAW8zVwfzD2g/jWg/2ZN5Hg5OSDtEpxryCYQBuSafDsnx7KbNVGsW7xsHzHFl/AlEgvx8",
	"dPL++D2gTLyXmFPH46fBZhKmWT/n/CUvmCpoBXkMwoB1CiA4V8uJqsVmjNnjGeCM9InPLwCy+KUHhkai",
	"5SFlZEkBmSlb+J5xnwDKLpzbv2FOBIZ7xCco9aJIJsuSQwi4LftiwbJzh4Hsl+OSFwWK1qV0uaMgOrpZ",
	"H0dnCHQfixOnJHhFWfshW1HeoayAIu0oAio0UizINo4wXRzdgmozgaOUJ91ij19aZgZOpzh+9/6r2AUA",
	"V+IpVCGp7oC8BnQv98sIgs/xeRhPORn3xj1I4FBPtS0kQmGNpVv7qtWZV5cgr4LzgUK0HKCYHWm0ySMk",
	"nLGAQEWEJdaWGbs8q86l1s7BnmfNjF6hXM+Foo/29w/TehWs6u1sMO9o5cyQcO7J8Ut8YHd/4rUzIl/H",
	"Pf/bhOeTA8uTvw6Hw2urBsZfnoQv15HTLEjBI4QRWDbisONGBbvimYRL2EF4TpfIBPCmgDVCvgI71hET",
	"vMCAQ2IzALkdUAak0FwbZz2xkjuAnKHmSovCGRYwx4gVdBEtaDeskAOeoRfS7u3mxdSqpVa18O8GyOEe",
	"aXdRXipuGIAmqxnNVjf/12gND+yfKHn33tLKyAoYC89Yb/TnP/95+Oc/Y6CDK/4kKv5OIhSBK/2kU/gw",
	"KvwTW04lVXlT/nson5ToliKbgD6ySao7XYrsLRRcFer8Nvxys+yyNiURcpTUgwMyLc8lpepyzh0+a/Ge",
	"3TU+o4FppZOlwq10yVTUcKq31c6G5IOAOxuYY+f78Fa5SJp8i1tZu1YTDCVaPGdLTK20qa0g8WIlPdEZ",
	"FSK1JquvGXAiXWnkmE4AyGvguMgP/UtdIkbJpXXvWtybTGmtt3dviVorIGBmmFwtwTNkYEVGd5+SkuZs",
	"3EsGTkSMf5uLyAv9yAJ2wC9yRQxJdmO18uqmve4KkCnLaK1ZAKNZUL1wHCgnO7XAKa1JtLKdmpZWK6K3",
	"tfs8m133XWqqmybLBZawJ7uucsgis7NPtjjSqyHsXpsMfYYz32uI3l7lFLeC59yjongQmyCs1oQWRSJT",
	"92q8Uyi6dlTvpWAPOCwhBdt2XFB27cA+LhTV64bmcJ/SttF/btIAnFsFo99soG2VXkuLf1Mq3JBuDtmh",
	"V6ghywsVeVJ/vn0WhhSN08S1TOrUKGrYfNkOJlNq1gkmg+JW5ofyTu0rpwgr2nI5t7ppsLw6n3Qr6zWG",
	"I/xxOBZKzUaraW7J6xpi/weufaZ9AmmEGlVNcWWLW4rUBR0LpaExl04XMpI2bQmffje0Nl2Skou9kl55",
	"tExKLrnI5SWMNnR+6d98sd5YWJnCqrWo3azOClJ2hYj8KMTVVtPtLK9AZqVnmL0VGk3uAgAxu5En/HM3",
	"fDcr5PYS2s1QTdBwavdGDlbrfB3RK9PJTKv+sriXwP7iPW2WpFK85Hb3pIIKbJsTlzfqBvdKqyeF7FJ3",
	"fWx2vf3iF3t7TRTs8Y1PyCwmxQ6oaD5rhfbxInFnd3cSuIejWitRa2dre1vvhuTqbcEJyoB8tXU6P/98",
	"s8am/G27T73oJLd9RKpvzApAAdP8gk1KCjte1AVkafcbr2t8iqpgrq/NVVzbXSeaNVUj7C4u7lTzegNZ",
	"G5V6uwj4lTTD3Wcnl7Rrw0WN5bpr/uW638NMQ3fDVsK66/CUMGFBg02EkSyKX9AMY5XlbFZwwQBRBhAJ",
	"AHmpVkWMuvTh7dujd0eTHz+cfjrzofRrwUuELHmGSDQY8rbz/Xd/QlylPimvptTB1AzQjLdzsP/kqf9M",
	"i2JQcsGLkuwc/unpTWhMiNMI0dPI5/6S/RDmuQJA6YCVVke2gjvpgR8BsKHnckgUloALqc3o4ODp4dMu",
	"5lIEGHITJohbpiQeyOq4HvXJow6hVgFAEpNZj7fjBb81k+rfjE7hxt5Cp0jCR0X7ZC12VDODtYN5INiL",
	"dP6u2x2rGzJPuRIBuB/mAQ5AXPjQ0ZtO27rzA80eDg9H3+9P++SXSyaeDJ+Nvn8y7ZOcsUozdj5QB/i1",
	"5FZgL0bfT/u23gUdHT6dbjwvBZ8qqpaJN5pvjqlz1yMSE8Uej4gs9s9AmEzmTI0OD6erxyVu4Hd8m98a",
	"3ybFQR76oJ9AFNsdr08FlVvXZ+8BOT364rku7gyN9o2pCIkL7yiEQN27gjp++Pjq/dFmUEefBt/1FqdY",
	"Ovp4rFcll7UM1t6WEVLe4UCXtCgiIMiDZ4ffeYmkU9hJLZvAIquCGrswQ4SRBr4LaGuQq28buEh9PhgO",
	"h70GFzI97iR49u2QId3q3YgM2V6jOyBDJm6UD5CGI4KD9Nup2Uc7gPf37uQt5rYIJUNaHMBqDMCQI/Lk",
	"2Xd98gxywe8/ebqCIbk15NtaUm84+kjI9TCNa9vdTnQDLL+KR3tqo+jWLG0jurmcInBzY4FHGgCcfELb",
	"lUV/fnT6amIb3U6mS47yQZnUXWU6JMYNMl0SjBFB6lsYjPgTqCp9Ig/7RD6FP27JC+6GvLhyXJMg2/Ce",
	"JrLlxPZYmERLH/EDEgfSCIVKZMeKMnZ33E6iGTxJQ3D/RjCNIZnArQ9pg8yIbTxq/gnLav92K9zBYQy9",
	"pmz72moBt1kDX+dBl+BfR7b9VxNLE9zx4XjVRxdR1AX12h73/97hOf1e87Z0L4Cl1P2tMBdkB3SK7GBW",
	"zoFL4/lNMEYQFqyJFX+oOL17GLrDanVW3aez2WTsv2vP6FrWJe8tyAmQK/dqIZkHYPv6/3JL+ZqLPPJq",
	"XvHA+sYwHgHY69vieZy3LtGDmMHu70cs9uDhsDN8X/tRZ88esq+H30iruBQP125zcFcCE9Cz1LPUFEe9",
	"/0lfuRwbJMKH7vKWABn24K2AZLQ8l5BmYSZfHuKYp/0sA6zDb4HPAJ1NZrIW+b2uaw8izEs22S5Vzr/X",
	"RXP/3XTf7RI119JBLJdYyEp3lJCjgL7lMUCIAwEBf29fb0ROHVIDlpkuyUJWmJOV7EwVo7lZDDAft8sx",
	"SvhcgL8LUkVD9raGC46IHbPLqefULecBHbB8XU3IvSrF3PaeYeQ/ZKVbUC52/SgTrTpUHl2X3RYLeYnN",
	"aUOUrA04Jnr/mIhaEdtu8dp74FOsIO2koG0WbqCQQ7izQukFAhAi/itbxZxdJVAol6DL6hKBHmzLrlmZ",
	"lldRTLWGUC0S3o9qhilhhRbAK0yiD0DcgFGUC4NJDAMkkLZ1+g8mKtk5wVxXhJRNZgRbh+yM6/39Q3ZA",
	"fgjGqoHLUW2Xd7f3TUSOjXBZzh/nwVGztqCTO6mrdLIUwjWCcT4cYW6H5fUtCLNGzH7VQJgb6b3GWISL",
	"KZbfQGe938XTQGclkHY0F3NIBQ8ws0qW0ZlMQ35NkbvdOeo5AZ2VjJkCQFJLZe+I30bvuTUl0jgtiIni",
	"F7KJNUD32N8QC+WeC5zmuUfAV5HToqPjzWsLNF8DVYDGcIcSQ3YUAyRrWCTw+V1mBQAEIxO+j9DP8jnb",
	"EhIuXDd3R+G7D+2Zgny4eEGtZhtcp6Gd+Og/BDVGCzJiVdhf7L9Bn6o1U/iDVOTRY8wKMi/klBYrtmQI",
	"zdMTaCMduugiCLeBk/DDQ0SJ7SAoGkIkcSgCLVaHcgM2xUqTa7HOqlAuxiKwAm+v34NwwV6/R/MSszk2",
	"NHMlOrT6t/Km3gzEs53T9EfwS/7WGWyDi/TNhnFXLj3OWqQcu7vPdpWqIQBhBfp+6vP6g88++aWmBTfL",
	"4Vj8yIpKe69oWRtSyMuBw0TKWKjPBTk5ekMqXrECggAg+zXwPDEfC2x1TisNwAHsgruQd4x/kJVvaLjG",
	"hwoamMxpNamYypL5Sk6xGVOrVoQFBIZj/7my0llp/2kW1F1orj06Z2MRojHigOu6gBdeOxdNxj1WTOWl",
	"HvcgAhib5XbBpgD2OByL11IRd5z65HB/uA8wAomBHO7/j254t+2tHbx7uP/Qgi2dalnUhiFVu5T8kaq8",
	"0UIzpJdieiGLfEg8BirGMLvQEFbIS6TnBS1qNhZUMcKuXESqYnOq8oJpAAaRZsHijQhYAatR5/vD/YOH",
	"njduIjgMKVQVVhEpimWzc8IECSo+P5CwFcljstLi6srvD58BpIYO7dnCoBgbUjCqDVnQYuZfzpozMByL",
	"o6oqOMtDIgfw0HDVO3R69pBkcvxmUtaF4RNENtqILwHhxwAfEvJ5AL5GVTGq7DmB1qrCYeMwTXam0iya",
	"DBVjQUXeTsqxOySfNZvVmB+Ti0wxqtERimUcCDJdulyZwGLoXDEI+CcOc53kfAZuo6aN2raQuW5BxN0e",
	"NFubfJKzi0k4FWu2U7yTuCDviTZU5PZ0RSzQnx1GSkYdh1jdTAfD/ZXNlNqctvqAHDzWJs/ZBcK7eApq",
	"D1tFC8vGCw5oKU4otWuEDZMEAMTBQ26xVDBBuF+3Q9D6xFSJVTahYEXhkFsVjWWcTRVuU7YTjrapghVv",
	"lluOIxJRNpU9YXN2VW1X9mde5BlV+XalodQpyC3bVejG5WyqYZf9FsVfUsOg+G1G9RxZwXaFX0jxj1rA",
	"AdpySFzfrkI7Enyr0k2E9sbRyOw4354sr638ul3xFqblRqQ6Jp/LGkwnz+XV1nU8jPGtO/koi+V82wVo",
	"J5yH0CL45/OaFzlTa9+y596fbnMK+bbjHcSEmaR8+56aWtGCFFTMawpJhzoQlD6iFpuI1brXXOQAQFPV",
	"04LrhZUulOFZwTxAa0mzBRfMyiYoQQdpGDAnloyqJJgEzGSyLoeUh7PEkYEyj37KAdQSIHNypobkwwVT",
	"CkI/UOvHpgmfeZ/CfAWu0nADV5HDp4gR/cI0J9TcArwSntOmxQZYShyekWRq94ELHp1JBaBhfqwutXZr",
	"KvYmxulniJXbtlf4FdnoI+UW+Mu6yzTsz/QjLAAg5iyJ2A1+mo80acqE5H/OgdBPGNzYDob7u2159E9J",
	"aWFrNzN2VRVUrElz/WNdUjFQjOZA1aisXRqEGF74aN5cMsRMulwsAZaOaqKNqjMDGVJBW7kEY2SzAqcu",
	"Rxqs1KPVI/HIksKDoeA6Hr1/6TO2a4K7zwEHsyuamWJJHoWt+Ch1fu4Qsvzm/2fvXZfbOLJ00VfJgHtC",
	"oBoAL5LcPTjhmKFISuaYkjgkbc9MwxtIViWAbBYyqyurSMIKTuxf5wFOzM/zdPMkO3KtlZcqFEBSFmV7",
	"dv/otljIysrLypXr+i2/EXTecb5WIZWLPIPK7ezw/ITApAYjRWHIlQEk9kLAwKRiVOwCsctWEvOBWEOq",
	"8wqoFFcpCGtk2oiOIQE6dJoLCAzXNfdntRTFojMMRxYZ7Qpl32AfLUxmXy2ZNKYSpsegliKK1mAg5MZU",
	"ixxF7QVPBerhLhpTzQLB1HkL3HfsWcJLMdPF8hkU4IRQAtT87XnuUVZ8nSSkMqXg6WO4TuN443DWnu5v",
	"24pFepdFXBWAzeUqFugGmDuE5E50kQ7W2akJ3uv40A4HNURUgx+JAHeOlgPAxLSPRGoVOsRQhi3CpT07",
	"e0NUPljn46ARwavYKwxtjXHjzNuuUHuiWc9l2Roe26rl0BfxC+2J7DACb+h+dISi+wL20KQPu4N+hpvI",
	"pO2s+OhSJJS5LM1qatac3n2Qm8cTZZubRy9sH3m59MYDfPazKHTAEvCGlfUe39p2OXPhg7dsdXseWCnF",
	"rgTj11xmLjnjQcVvm1Ns9aY8bG1iJr0G1sfc717cd+3ueiHF/h6cUDCHoXXKLkriyhwDe7enM+CQO/BQ",
	"MrU4xsqTsuJRic66USKCobT3dCpNnvFlsN7iF81DoTxdjZEx4MKs9ZC7ZsGoiRYSQuCxl6jMeCHLpeM8",
	"dZune3+kwKIZTMlg+mSx5dOBp7oJ43M7QSV40QcRIYA8GrxxsZRRKg0NpLZ6dVlr9zHkfx+eh1++SqWt",
	"60cH8fOt3wxqxBebl5CdAMCpe8vYOwIxMedyNhdF9L3mcqP0YlfTeS4iqZaQNDfaU3/5mtLWjQthF7Vt",
	"WX1JgW+5SjNxyQvDLFfIAGEXIWMx3dX2EJ86L3eQ94WqXw1G6sK9P+eGccCfjssGuJq+kOD58aNd+QE+",
	"wv9YXefubkIZXJTd9vw54DcZdvHhw3vWvdBXQvU/FFIoK4l+AK7G3muUvbYckOkUMgX7X+/8AyXk+ETD",
	"4UhNJpO5n/RIffyIkbEXWiM50KDu7qApjmbfsWL2rchyUZjnzyGgbBLenbA+O4PVMm6mILcvcnvcYPg0",
	"OqBHX2jfdopbaYYjxVifTTC86R0vrkQxYV3LbLaGbD9N2VcEWgR1GQCCGJmVT2sbAjPdoo6sdKLKCetK",
	"VW4N2TH8iazP5Bwwu8OLe+6tVGBlffttJIWtIUPJ1Iicg+UAAxD4ZWVZBYwEwuEmJimqy2/LRYbLsdDX",
	"wrBvL96dsJLPUDESt2XBk9IwNML32WQhUsntCz8WPDcI8f392THqQ2+F+k6WaM1f6JRnzGAGMa7/3+x7",
	"R+Q6xOUupCG/Y6KVE4FMLTHQ7d9rbmQCmzO0NLmOEiYAKh1t5YbWLN69b+BIMtyHb3aopwtaNzvRTT35",
	"jfhm1BmNylHHjaQypV748zpkkwtZZmLI6qcKDBV3d6OReq3TZfPXS50u3XgK7hFHkUZhVF9BUenaQnz8",
	"+M9XYnl35zqD3j9+3LYtobORiikdAyGFccegx05O3gHjWsifRWoZZG55pLwSQzptJc7kWJUYRAm17DT7",
	"Ad00qCmPFK/KuS6G7F+4EuxQi5Gy5PWXr178NGRc9iiodpFFR9hXgnd7DwM9p/wMrA/gcz1nspxXl5Di",
	"WWqt+jgf+Ld99a1mx5aMFu44tb7Js/xKmCuptmca36xp/evJrbV8i0s3HrttfyRTt+chOkQhOdtb8epY",
	"gE77hkoT7Zx9Ykc9IZx1ey1wqUxrZ3SjwEXrsd3RFmK1rqWu2A1XWKrJDiweqbtvunLBZ1bZPj18Y3pM",
	"lMlgy6m9TE9H6q+VKYGpDFht0FChQmGSG+p3qS7zQi9y4sVhRoVY6DKCnkVmP7jnEsC33lkuxqoi+wZ8",
	"Y0lVZOgksxwKKseTZQhmaNy3cFbbwAOj3k4P3zyoL8dMvTWg0AtYoaivC3FbPqQzj3RPQwPcJ+q4lX3a",
	"QeIOA8Oojxz5AzCYYzvH1ZZhxaK27+StSIdsck6wd/aYO2bDPn78Sk4Z/rGul48ft+WUmNGPlrqULl0e",
	"lkh7m+hTGjoXImXcsDzjUiFFrZzdtrluPLcbQzS9xnuPENhiOW6EwxcCEDUqKPcXAMMiBJMgMjuzYzhE",
	"EVtYv0zEFCBFlEOYhitDBeb1HtASHPXwe+gXHe6hwoNjAM+uBeNZIXi6jIy+0RQ0GoRdQRWZgjEcMOtB",
	"vlOp5SDhQwnPsrrPPZgqQM43UqsIvPFBMHLBgxMr+H81Wg3O+M07gvSOZXW5sMKKy0LqDDvA9aWabdu3",
	"Ond3P20Ch+QuKMMwzt5/uAgizYAdej3Yq8bAUunNSJ2hICNnv2Au1IOKZ4Qgj5E6F4Jd2gH0oZs+gB3k",
	"crDki8zByeaZKKn8EBT5gvGEHbVH1p7kI693pgWflmbIJiOyvw7hyagDJx7ERGgm8kIksO/EdeCV8BiM",
	"V/TWm5qaZclTXouUwUmKv+R+gdfqpmSKpdv19vCOM7wOo6F8OGONrsA0Jm5zrtKxqUHz1kPDIhDehShm",
	"AeC0Hk9RC4qDlasUyBSuDDvigsIWQghLhNZb68++CqqgwQiLYQ2jn7rBABngdgq6q6WlwJc76A903bSC",
	"3U55IspPDjt/Y99GcWWVh8GPZOFuFvmbzQoxQxO6jyJckgkcWU7d2AO+MlBmbaciZYpfy1mw/qCyvo5N",
	"3OdfJDm91H6NQ4VJPGnH0+b1w7PMvWePKFq9wGgDMpFGXTUUqWRG/izwel7khb4WLBcFXBNqpeRGcE5W",
	"RRbV0et1EjB6PN4v+TBA3WgrArAuVYhwZr3IajfXhq6PqDAJsC5/wbRzKFjp1lUYqQO9WGgFt1woGgQx",
	"MP1SKK7KYJgB9oAPhzxZiCGxlO+NKPo+Y5u0s1GnMqIY7u69cM181U7ggPVeyZk6dNzG3+eXy7I1GnwF",
	"Q/g3fw0pcD+230NWAsfsFWBUEF9mZSjoBQPuYJ9x1usuIjy5orSk1dzmz3g/UdW4+gYSq/duQbfnVpHA",
	"qljQLJynIcrSezt7L/o7u/2dXXrjgK6SRv/+hilFMlc607MlrKcLsBgK9bibqtHPUvAiDGkHrqqmj/VT",
	"6OyT4C6elCbB1uqCOb3R18PLWT5bg9le5lRX7BeSkNOBkIak/bfVaUa4NaPOkI06JIIXo84dCSsiSz1r",
	"WWl+qdPlsPkOhYWtNLYsZioTyTPYcHtTZ5mcCZUI9ypEQq282CAN1xhDBFdaj0ajDroKsPSD/RtfuY80",
	"a7NBZrFKrECYWIvS6SG/KIfNUWqzwrJIMk4wYaF+vcQgICrF7yOeiZa2azHBQDTOlZBwxQpnSGqmM6Bt",
	"ARKyjMhQzQHbFvtDOIG1lIMVgYNClddLHDS0SN3aoNoNGJUkS2PndkOpG4zUu2akdEIAcpHUApxbyCKS",
	"XbGeHlaxC47zdpFkbIliDGjH9az6cUB7fpRgApbRh2CR+ehwTaLIgL2JlmrsEvDhXpLGxcVfRQhWI0Xe",
	"CMhAxjyTwFRYt1zmVMttd2erMf+9nfbaT8VM1HSHjTGWtRogd72Onk5NG/bH+7ZZmyuZNxyfJJp5B7Pn",
	"pbVInODZgTKSyFhF3e/m2qYVyK418oyCYpr+rrY1gby58eVyExtocb828FaKEmvjkfeKxHDKYm0EAVI3",
	"rGuvMfYNxDYKcIT2GBruv2HcPbIbi6uWg+f03mVj5yuGFij+md1wK/niWl4ua55LCsOvc9hIdqcLl4IW",
	"aohNERfJfWLW5hhuaAVRHoi5e38yYg2bFzBKamTwgPjRcHc7LrvecQv6kf0irtOqq3ekSh3F3kFBGGRd",
	"VBcG64uu7hFxq/aSNt2zszdbAyyOuMlUyKtSL3hJR98bDrFvMFWR/hrbsRCxcKQcmqXnsY75QgoKm6za",
	"+ydNE344nyvxnCQfxLIBFXJshNsSMcMhbQXUfkRcKnoMmPdChAxZP9TaQG/klcxFKnlr5Gl7eJGrympa",
	"M3nxJ7SU+PQfpI1Q8XY17qiIO3148BEFurbF1a0dPEXGrozcXi5QvroxWtK40Ncb8XW7mRydv6vziaNz",
	"PkWgclE7YYLNyEf7uwx5QSDknB7so5jQP39/ZPU2ugaCCXfQaoqFqtSrUABQ/ppqJDI5jY45VotsR0z9",
	"5VaplV0NQ0VxlSb9y6XVdct7FpfpStcJsK2L6SLoHhI4Z+r1EhsxzxcXpy6yOLESrY53wJNnLTJtXa2z",
	"tVzkR3AcEv+Ye3piCSAcFIA43FLnR7dg67vqi/VxSsUWMsukEYlWqWmO9tGVHZsp3HYofg3XhkSeP8xE",
	"TBJlwZUJRT/tgfKJhKBxGtI4EWGH3kIIJzB2obbGwDwNifjstTAlpeMVXM7m5VQXN7xI2ZQC5cJF0rf0",
	"ZknGKoSvC8GvSBm+9XqTtHeuqS77EBqIEc80QhSIBLd3uP8ojYoXMFbjxME+gGGML3lyNWQutpxdFppb",
	"4c0+nhUQ90xnXhamBN+dCpiKdOH4T/n+mRIi9THSt1ghe75MRfSp+TLX5VxgciJXBsK9yJLVIy80ZJSi",
	"IElbEH2NXxrwvW4nWiUidytpYoHXVeOHPQPFh1YXyIbm3+l17NhazewrKW6/EBDA2xk3p3qsjwU/23+7",
	"NioUMMZa8ADsY3swfYISeT7sqi63pzzL7DJ4ScvK65VdTitV3VKtKnzjme/i2WCkjngyZ5lUVyD1IVks",
	"sdeG78Bdl2SzxOilYukENShe67u2PUtIF48+B7AfMMFnvqS3TxCCzX6Q4ABrcSLVVZtOawnsXnCta54F",
	"+fuXpHxhBMSGKJIEw4wqA4nzEC5RiyaxK3dy8s47OUIOEmcUVebekwbSQMhzTA/rxhTb21Rnmb7BSBGE",
	"+kIr28eP3ntwdzdk+0EaQr6TNmKCmUzJuyOy1GAPDTne9mPHYmf3zDQtJy7ZKMoC2xqpf9cVDLoyoj1u",
	"Emv2lZqWTv4sCNjBzrdHTiI7vUzr3FAByxCiZpcnQKYDwS4WvE9BdxFEsw+pPD40kPE1ZC5cK1ooiveS",
	"qf3nVxUGDv9zxk15d9djHz9u4yOImMAAroYm8drhc5RzYUTouucWBTa6BHGMcRIKh1ZxahnNSB3qhEVj",
	"agSk2RbRQEbqB57J1M7wM01uXR6UbFMmmiQWbsnIcDhgwIGQVoApOB7ESapxGql7LkvD9I1C0wiGnzdj",
	"dSNrIyKAZeHTViG2tw0vhQKCKPVMAKfqWh0GgU/gAsZBPTP4pS1K7adkHRjbkP3l4wglMzT45jwXhcEa",
	"4o3Dgg0GgwH+Cn3aZ7s7dz9hz3BxJ9yUK91ifFPjxVc9NhgM7EbVh4Axf2ta06cWGCD0WUbfHMCl1lfU",
	"SdNmYBt8xEHHQ7Ojeijzr+VUIDzIMb63u3oZmKUpxWJ8L5fGdp5BawaladC2AO5f+TNKr/HJtpwMjFEQ",
	"4jatMrZ/zLgxEO5eDtg5vdlkyw2Lt6VFaUTWXr7CcuKxKQvBF/bJqoqn4Iycnx8x3yrWcaOwpH85//De",
	"e8RXQTTaxBd7rNcKMGv08P23TgXBW0Sl8lqmTkRe1rTv4FtvVAa45hnpiA+5y4MSCJ+ItcsNWmE44gN2",
	"MBfJFT7Bl5/5nFCIEARFmiIOwGDJZVYVqED+cmOHDzJ44Jw9ZbkO2xTtGDLiyRCwCvjI/bIwtWulpZVi",
	"ZcGt2ixMLNoAW954gzReK6BQkOLvJZr7y46F0lEPM+CeuvZUVqQ9nLhNxAEvir2oggwC7tf7xriCKkYD",
	"aFnVhyKytNaLewiehyzFI9860HNRPPalH0RRitvmSz+tOrX3WaXQBNwS8LSmpl3kHmhJhKZSY6lQs4Tr",
	"7X+9EepF342kvzP4+vXwze7XrYVT7x6RZ7RCTq2VWlYnEBfVcuX1XdnWEjcI8BXsond6nWtYyFb1uAaP",
	"uBaVkCKyoGWPRRCPIDsXkLFNhurus+dUG4gG5mAcbcNOr/O8jlu4FuTxTJhSW5LxqvLDAi5e8+Sqyr2M",
	"8BN0VRbLdSWyzlqUXbC7O30Pw2BXcWN5cqWn0zFZyaXbPELc2luBgfXtKKUQBy55xqirjWV+XrViEYeg",
	"Zgiw4NnYD6uBgbyzs9Mc0TG+4j7PUpHxFYtfDQN5p90Vy2/HvISM2PpHX/Qe4Fu2q+/frpXd2Ii+TN9d",
	"M90XOy3zdV+/b74tBaxX7y1dlWvOzEFmxUCXERMytm0fQ2/fYl1vhIuNiMst5uMmWFfc5pkGIiR3eYwa",
	"73rquEIHref7POHqO7E00Tlq0j/8AH5uq2hBVCEg7KICRiBoHOISIX5rMFJgr8C/mDRxmIPtA0OHXEfe",
	"w9UGEumtU+NS349Y5zOdKSwbv+Fjt5+V+lmAvwlxIocuQQ9d0l1fvp1VeS4KdqkrlW61gst9aghrJEy2",
	"hLCOlI4DO0vMBQihV1FgFHVvVSsIA0HVCrO3Rh3b7r0wVpGFohm2meWzA56mhTBmkMhyic0cMBi0GSfz",
	"Sl2ZwXP87cgF88OPff/rIMSWYENI9uJZNKjQgrS+MelMTmOlzuz77YG2OBd79Kk21KDkM/NJQba/8RjQ",
	"UjtE1pAajnEk6aZEBETlJOJKA+gfOrqNR5BiVM8a75fpVCaQ55GLou/6Hynff8j8JyxGxsHLjz7Hlji9",
	"1VjPerjbatznXUvgZyPKb1MQaBT455dltYfVwDiKsYPyj3rR5jPiRemkGs/VPAPsBos5oOFiscuAxkPL",
	"ZF8E8dLFaq8GqkNsNuqbI2U/dilmUqkoZTDii0EkwmjpnZ02qcizrnGY24M4puNNDY5pe3nWjLlf5Zhh",
	"STLI6geO2QiJWstAf0mg2eqiOqbJsyyi5viywUuKtQNW2NuVKiw28TJ37pU4St1mg0k30FK4an4pLcG9",
	"WmokJBE+up6E9tpIqE2YcWFWwA/bi8TYp/UASWRpoTwmMIlCAET5kF04J6z3I4N2nnNlWdiVWN7oIjXO",
	"8WdYyGiOA5tIDDoR1yJje64RUhs6JIMHMnJM8lbXJLgib3SVpRHELUFilxEH7n67PDxifYZffdH8ag2V",
	"3QGyx99rF8NEkYsCMzLbbB0bIT3FZe1Fe2E9sEwuftaVyGVdWNSSnR+dnR6dxUWs2TUvtlpxAqmGlhd1",
	"XYknkjl7azRG2rtSu/yD2JnrXlXiBor5gYHbyoYZT+AfZq7znCJaVy9/uRDjXBRSt9iDLuQCMlukdqlJ",
	"Q5Z+k/Jlj918cyPEVY8tvlloVc57bPkNoSO6gQHGvpVEOr3OsuXbq4dn5b5fhW7HPRik4pq91XqWCcrB",
	"h0rTGE0Pm0S6vWGcIhQKxu34FYaulNq9TuAF1Iu9x0fKko0oJbTMCwnAFGC75GZpt7zKKQX73P57+Pz5",
	"SO0O2LmcKVbljJc++9740Y7U3oC9FaWnHjSqcTO/1LxI20s8h9ehsnN7jPb5nBdpOAUNvXpZijFw0Xst",
	"lEuCil0xjkV9tBkdz0td8Jk495E7zTJN5mpcgey3GiUjzRWrMKJKMfsd8yBsKchjzttqH/84R/9TCASc",
	"c8MKkQjIxgSBuN1evzqvCtLwneDaUnzV/xCuig8+UM4lbaTMYEf2blo+8AppGKU3RujVvCpRKBS4k8kY",
	"btVKXNUSs6YWvLhK9Y1yjoVMqmCTCl5wl0TwF1+ZQ6YItZ3IFGXMn+xd2/r7Ljbo+Qd77g2CZFzRX50P",
	"o9VuF5Kw3aTA0itVmEwMaLNhThAeWBtyIczu6kTsUysimb2f7rUgu6G3npClSuD+q/N8O3cMvWlcM0uV",
	"zAut3JZmcHVCDhqksoXQUZASRq4jK8L/yCUav8/4FKIdcm3spZ1YwQDwqrpTbkphyp4XoLATuHxrXZyK",
	"S3uAvvuB4W/QzLsha01D3hPGWP64fxK/JFQhkzkIBPa1CBSART+5rLv60LuGlkNXJmodyUo0AX6lVG1Q",
	"teB/GA1SxqUwZV9Mp7ooWa1zHxPdnfIsM2Dagpx+2wriDuRC6KrsMYMVCHtsoU3JUoRNqoszYXedWOOX",
	"Dlr5aVul/Uq1ZzVfuEDFBk+N6WWtJ7YFGrl08H2BY134zAEIrIFy0mANPKEK368iO2WsOvnMoE+JOj22",
	"r4fYn5Ujg9CPH9chLd/XPUzqHJval+wV+cljjS/Y1bE2+AAM3H8xrFMbX4BRooV93e350GjkS+iFQpHb",
	"JE+3oM3ivK6w1IrC0xp+vy48Fyfh3Ly+GJhzR7gz4e9EexrcUM2VzHOR1h0ZccvNjNct+PqgV5gkOUB+",
	"6ToX2M2vttA0jXtXuizkbCaK2gL7Na+7jKKWn2Wlz/0JbWLdAvp3SF8lh2IwjIcciTROaV/1FtHNFelR",
	"9RxLjPWDZDiXjejs2D6+CfNv29beNyEG8Kl8w+WhBz7U9LMuMA0MBuqzwDCt0a/AX412SMtrEhbUVLua",
	"aWaDRKwZtUTdPW3LktfKOyhdnGFjL9BdgdaxqA+ly2AH44oyEV1OJoofImWXVQlNkSum62xcZZmNUxfl",
	"3ioMpj6SFnJlEfIrDMfMwTIhbnNZiF4o7AV3YJkhUD9c56bki5x1nVN5C3EvDHurwzdIrKRifM/2Xs6f",
	"9dizP6X2/3e//vP8Wd1YF+nW7lPtkwgg+FwqF/sbBmWPx8XFCc4CR1IbJ9E5EM2oM/YvjjqQnxKtYc2r",
	"BJsQFgFqNpZrJnAtCtO6Bz/gDx6sDegTrIRoc1rIWZTeVFPoWnMy7tZyE88IH2beQYlp1ahjUEsdB8a6",
	"8cqv6bQrsn69r1VO+BOM/lpmyy9uo8LPrtioLvZ/OD759wfZqMgbOE71gkvVVuaW3IVFHAHmQnLxncd4",
	"m8iWPkbDYk1FaoNMdyBE+8f9oBGSUTLEwK3yFPeZtdOqYRN95rkV/Gbs4mHu9zK4MfAbhCp1WHp6ynKy",
	"7a3Oj0yLqchdJVunZ15y08xy90UeGLQHPRKaDdkb7qvAEx6UK9cVoTrxFNDj0yE7FCIXRe0FqC1oqboQ",
	"c6HAXO9fjUQUNyzX1+eyELoTcNy0DNIPsmkfP9t/C9a9/eNa+qmLKofCankh+nmhE2GMSBt4Wc5DS8lR",
	"MbK+QzG731JYwuAGiV58kqUw1YkZxH20SQoXoljEOYUtJVEIEr3FWQPlKe6LTYRWDlr9pzVDeOI4ykeM",
	"dN0Io8pNTzbM4HtccECyUlWWobpfQ7FpsjB8BfOa7n9lc99hNJs73GSrpAjGg3m1LvJ0c/5Rpa7QYmHW",
	"XHNVkbWLT9+fnTj5gwYBR0aoFCIDvbxmz8hwezvTCc/m2pTDP+/8eefZ1oAdcMV4ZqBQjb0kryVn++8v",
	"3pz8+/ji6Ozd8cXR2H5DqGtZaAUysMsDqttQWr9Qk3sK2Zoe7C1Cj6oassrzGvY38oljrAiTCoGHBoQ/",
	"mhfCAICtuBbKiopgS9/qufZOagdNkxALhsm0HDJTTafylrBZQYL3nT8zjGJTUKx1H+OXBhIY6Teriw2T",
	"Wk+8EFhjoTJ1h2WUqD1SF1bLRapDAF0jimtqP63KqvCo5WjehWOKyBkU8gAuMMTpbSBatJE1xazG9+hU",
	"3oKWvEqJMDkPpuDCSZnL2oMXsUI3+qIQBb6Paol7GQv1UBfKpRzj32Y7wfNltj/an+626wTohraZ5+Gc",
	"fvqUSzU+ZH62PgAYblf6VRrGWSJUWfAMrlhM3RbFtXSqp/fN+Z6ifOFSioIlgAvhkF2jJVnwHPSdD+/f",
	"/xs9x1JOuliSCt11FSNKzeb6hmFcNrvRxZXZotv4wH0YCn0ZuJf7bIqZPD5U7FakfUA79OO8XBKAP1YB",
	"6V5WMiv7UvWYojG59Qaj9L5aUqFfGDwcLIrOtKPLNE83bnKYGw0bl4WGe7I7ZO/Ews7crhfZUPb6C6mq",
	"UljVEVrtDdmp1dYMyJBk1E95yS35YWicmmVimsnZvGSpcJU4ZACtT6oCSsjKVCiMAigwztGsVMNyDHs9",
	"T4x4HoWdIm/oDF/thFhxR9H6WhQZz8ew7NQmihIP4dm+FEBn2BkhtjmWyo9e3bkLF9ZqrsRjzkB7FHzD",
	"QRhYSJNhqAivJHSF9EzXVlJoY/oIyV5ER2Cr1Wb1qZfk4N5b6oE8pNfxQSotNXVUH4IRIltSHVYAvYzv",
	"tJrpw9d9Uy6hCAUlZw9C/AtBFjn0x1IvEO1mpKjoHanmLONLUfQYFCxQDp+Vp/2FTuV02UdvUMET4cDU",
	"jyEWkavSStUh3qaIoH/ef7hg1zyTKaqcM6sNlpGn2RlB4KoiWFATA0aO1GVVQoViw2T5zLBcGyMJrQaD",
	"95hU8Ik4phFQqaFGB0xepUwoYy+8pa6KyBsI0JYll2qkqNIiWNFlCzDrxw4YDzw86O7eC3vWfFcgt+m8",
	"M+z8QSqrpFGA5h8G1xKjTADctjPchfwYaEhM4pDDcfQvZNyUP0hx4yra1c9Iqw3DA5qCBcNlt3OCOuqB",
	"BZErJw3AdS+VEUVpWg0a8bTWhR1Hq1hqIDAsJWjZnErEQ1PTPOF8yNvMAVVuR/mIOEMiCn9s5JTJEmo6",
	"qmclE7d29F1YADo7DD+xdX9Ool352tpsPNMf8lVNSOePWA6I7r9zdNHchn85//D+lJdzDOq18hpxwVHn",
	"DwMIwbasD0Og/wARzfbfunAB2vhrrQZnRKurZk0k3hWjJtRdsqw+4B11LbG5dYPf/lApI8oeiwl+a8Au",
	"EJszFyoFbHjHvliXQjLhXamS7T8sqqwHRnJ4BJ1B9YiVPdK5O0n3bE577kSdn1a5ZVx+XJElxg6h0+vg",
	"xOw/8Mz/Ia/MHP+bZfa/PE0v9Dk2yWFsdirwH6ngP/zW/qfOCf5QCPActfq3C34tCuPTTtcXdKQ8WJCW",
	"EHeodO+2uIfyNiJz1ZKxE4R6BnTM7g77Jvp7ayMKzz1V8d1RfZxG5zke1BrqyinIhiLd6mxAs71nJK2s",
	"9TU34uuXJFZEvh3kBpvRoR/+6fZDfk7M1PJbiDCO9gH8XuCKsPth2RxZTiER4xsoIhUz4XtxrFdKMD58",
	"5GORzto8afH4ockvmcDGPOx0Jn7BHKBO4fhGWHl+dRaniGngJsGwnWE80+SBgt1rK1/86AJwMKDWeweP",
	"6E+fTt2Bc1RZK/qefYyph/dyC197cAwlCe51QfwgjSwxKQm2G6wXGsWExq37CMYBqh452+6jjkPf+K7X",
	"sdu4zvtLgPhIrpcOIBYMPuwbSCyDF7ce7tV4+IxqJ+Dhbg/bnEkVlIOQovNL1tcqmqvOkbVJlZ5e0EOC",
	"d0SlsABa+ouuCDuSGqxCyCpdN5qVXI7PPZ6YW7jhrBtMxDYoKPwzcgswRbcNZ3VtqJLpkw7n7hdzKOFw",
	"QDe4WzYX310h/sgtE9HRQxWUmsD1ILDQ70FyPOXG3OgiXQu3psTNOKdG9ahoJW7OXyTFi/L0n425+VCk",
	"8Q75V+6NP4r7bxOIvzfoP64Py70ynnMzXycRMScRudbMth6wo9tcG59ACLZNI5IK4IELaa7qZth/eftm",
	"+R97/1i9WwwGg4dU27DKiwsYC938Vc9VqsW9C+Lf7jUm2bY4CP9whKjAj7B6uTSJTFcpw07Y/nETQNiw",
	"rrDUnxfSiP6s4KnYcgUuDJbVIJOii846KESKGfuGdfcPD7YwHKwq52hjxBh2Aow37Hj/HSt0JtjE/r/Z",
	"5jLPeGkXGPRDV6aVkiyDXZfNxEIq2ffj7e/s7Poqoz32YudPeyyVC7PVi7CMo1BgqofHq1Tq7WuZCr3V",
	"7oJN7AoNZrBcUG8RcSL6XG67WOVrYf9KdWK2g3NjeyZK8N30o+TfhrUmlQuhMBLHDrjXyXRC0VGdyvTJ",
	"3L4bYW20TRtFH0sQUP2+s1j2Z0nep2d1+A0CuVgx2CRh28btYr7T453JnydoLAfMJPBny0wM2H49G2f/",
	"8AAIQGnVf3twGjvd1kTphSWpQRX8aa/NQ+NbO2NoswAc6/7p6z/32O6rF1+DYQHoApErVhfy/2G7e3/u",
	"777c+XMDA9u3iq20EbsO2xY7luo7WB987fgVYuaOZTiJ+6fH3tUZ9fSsx56Jyu5d/0aYcnedw/Pthw9v",
	"T47GBycfvj8cn3w42L84/vB+wOLgslq3rZvR4i1bQ4CbbeFr+UsM0eL55JpPtMEReaL/uGl9qSE7PnzA",
	"Wp2effiXo4OLte7hT7Wj4xo0ATI/nVMH5vO0rPpYsebBHakujuasUj329rujHlQtrkrBjtRMKrEV7lUH",
	"Xo/lMMBtxFJx3WNFpUZqMgP2Ch+No3T6Dtgz0zOpJp/xwtgbvOpPM27m/rLY6sW/5YX2f78Y7Ni/P8e9",
	"AEj427hRzVtgPdPnt97L9XLnH79euQb8ZD7hCkBILjvOqoDa8H96ukvhXJTGnbL909OTY2RH44Ozo8Oj",
	"9xfH+yfn7eftF18n/2M5c0Qa92MGYEtAbXTp3wHNALSY9nttPf+PKe+hvP9ejh93+tvk9o1D08K8y0Jn",
	"hhVcpXqhhIEwnZDTxro7g53+3mBna8C+lbO5KFwF2wW/Eq5QOURaYheDjXhXexEWw05bEV+dj6/aNNG8",
	"f+URHqIKRIizYpB1+tyKUufsOx+G47DXmaku0Y9WIn21k5AdQt5WQijJRGVaBoFLtAtL1Dj90dpvXpfd",
	"jevyyCv70yIKiCQD9Z9RNIALW33EtYxIaJlMZMkingwmNbrvTgsBczKyFC7uhYBPD6VJ9LUolnQ52xEM",
	"mbt5iXMbJrB16loLaEwXHM+lsZccgM28Lbgq/UU8dDdx802eLqSaELpHKgybNFtQgAQuoIE/JywXxUIa",
	"gwmgdmrhCnewGn1CGCSu9M8ZL4Up4wu92XLKTdnf2Xn5wKu8doH3eZ73ocCrKPAyp3FThMH+u1/SFxaF",
	"7yfIOeqCgbvtN8/7N6D+4S3/ppZd+ynX/QN1kHvXowUdkrdE8tXuoHs7/Tw3UusifepdpPOxehhmUKKL",
	"9OGYQU2ceygEZgbtCT4P46XN3JcWl/B6eNIbcelSERwxU5FMHj0CTAgPGFjvhQYZhd5YJs1zewwKyUsx",
	"Uq6bfqMLRrk2CVb+dfcgRSbZyxEy+Z3iEW3eD666AGae2003W8Sc3c6fH7nsnV787PgQanMev387Pj/a",
	"Pzv41rWCyL4aMo19Us8DglfP9n84Cg/soZB2uSFuCnNiKXYWot/hv2uC3qWa1bau17ks+LVY297+2Hgh",
	"rZIr+7+ZXptVWSVX9n9vdeNVZKVrC07Ar41XEF9lbRLYKspQr4M5Fuuzz1aSvgILXb4HS29gsyvc1VWl",
	"a/PaiqkoCpGGynVRQUGvZQgFyoWx/z8tntUDYoRapyC0eaNe3Q832kBf90yjJnneCwP2ULBozxhitGjU",
	"uzatV6SZNVergnWqruz/p6KxWlV7XjafilpxwQ1uYhKr7CtuqTze3yd5Mh3OMcFQtKHS7vTWAZLiOw8D",
	"aH0oNHZndU9ag1Bb2LK7Wi0z7LPnz/H0Pn8+bMdlAlW6cLadg/MjhGHawpctV7KvvpNJoY2elszyIvaj",
	"uIzex6Z45G3jTUhSEEQOoFHxZ/Ds23fbcswwObeWVuaGZxmdfQ043sqQAs+zbQJ/Y8cKyh+wfcxuhG+Q",
	"wxcCzilBrI47Qmywh6za8zjPuRxTrvHattgsB3H6xHlQN/SZ+1O2fMs2SqQv9g/mvNyfCVXeA53kldZk",
	"zkvG7RsDdoCp2AgC6stPPDPe+tEbKa6WLMcSrCzJeOGxiU3PBybjMTc9V1EHXK4gXpiSl63QvXH2az2A",
	"Q0Wge+K2hOAiXym3NeAVW49BKkkhfLVdF4XfnIGHBvDp2nKvQ9Mf0/TXRaMYzAKZ27NwKYTyywYjkaa2",
	"Yg+NmcKuz3ORtAXeEoJHy5DQt93Ypbk0kFASCiStI4hH1NkqHZJYy/iIoMY1grq3z7hxVMblnsId5/Vb",
	"G+t3YAGh1FX2iaf18Er7LRMrtc7GAPk+XvA2KMz3ke1RZ4gOz2xTTw0kUdynULgd/qkNocf57AGKA8ng",
	"NTcy2a9QhYUlFVGuNHVhlfXO3R0EM001xmyokifAV9Bx39lX5RT4ash7sfr9TJbz6hI0ew4t0kv6R1sB",
	"U/scwwtSaQ/yJezGlVj2weyHuXjATuponmggYZCHxLRinD1/jnlUgKKVWBpVpjLMtpalSMqqEM+fD0bq",
	"uHRFiZHdXQqMhC8L7vbbZwkZl9idikLZWy/hOb+UmSypAFUqMnltFavlZSFTNzheMpPwDC/5r75iP9pj",
	"/45fCcNoxt8r+bdK4M9fsW/xbSRQvBtfv9t7xf7IfsBJn/tKy/amfOOTHuPs85XkwQcUV8ZvvfNuXNs7",
	"IFRhZR0C3xS3ZY9hOECPQTwAMngICsAujrzX0glExvaFKWg99iEXav+4x/Z/PGevRVro5KrnhI+3YNru",
	"2ZWZFzqXCfb4LS/SG14Itp8kIiPrMIgvx+8Oa2iqhnX3f/i3ve39H/6t/2p3z1LD7Z+/7rH3Rx/e2z/2",
	"z95twXjP3x2x7nnCsdT6O14W8pYd3ZboIEfn3v7ZO7crhxFBHjh6ilYMKe1QGDnDgVF5uIj4ZoWucrQI",
	"O1hyK2FBYHeSVaYUBQ7Npe90tQLcUQY4WrQ/3+pC/myPX8YAkouEvkPbW732dc6LEmhYpIxDIhV2RHTs",
	"Nf5LCCz3llX8TDxfCLHnEGkJG7kPGUeUmwVdIrCcI7JEazsuqzhTdufe6YHDIyyFKulpphM0DNoPvpFK",
	"9N8WHOqDH9ph2ZMFJE5+AkKvswsKaXwJVVgFXDowKhjWJcC5HjbuhSLjvRhkr8f4lUKLqd3c/eP+ezSb",
	"vxFgL6edPdt/C3vp62D5unN9Xs1sTyKN3RUwnHNRXIuify5UyY6u0QFsO3PyqxWy8Gi5MuCuXmyhq9Ln",
	"gfq9XEFFpg1yQesuixOpjpCUfa6mM0B2Ke9ta12WKQ0SFvPIrxTI66Hsa4hHCMW2HEAj9JsJnoqiD7HA",
	"hBTh+w6chZ2JhS6FZQ/UAsjKzzjVNyrTPO1FffSIC1HYWeJ8R/Y4OXZ0eviGxE1ADIFL/fuzE8O69j7a",
	"hktp27zYnsrMLcT5+dkblhfCbpSrSeqQRijNDZacuIClMnv9s6Pb3MoIkM9mJ3eQATD+CcDlS2HchCJ4",
	"lvPD7wyFKPQgUeYcLj8c8OmynFsF3Q4ZGOTpMRjnsHcwGxN0mOdR8A1SECe3fbxW+88njCulSx78Ty4b",
	"nraB8mHOIR8mJBUiTVKKIqbJGNb9g1RJj9JzIBVmK0L5b6QSYv8nUglesHeimAk8PbwUUAgSKx2AzUQX",
	"JVgl0NBK0hd4rzKG0KN0ai5cjaszKHBFpNJSBAunStVRfUZH4d7C3qDMN/PwtDDnw6iWtyvpCKThg58R",
	"0yTn5XwqVeo7u7g4cdU16uQbQVXZMUUw4JAi2QdehaweQ9K7GJ0P+0S/OooLYwUA2b2vGd5ZwBxxHB8Q",
	"4xVuA3aeZ7IsV05UIXjmnPt4kFw72I5wLdiNtcevlAvaz++qS1EoYVf4A2VNwW0OxSB4xiZEeC6lahL4",
	"l5V7HLPI5FQkyyQTbMEVnwksHWE/cFrohSjnojLsneWvCWzLa0oqZwutZAkgMj5fF/daX1rmVluK/xCF",
	"7h/S8Nn3OcT1QHdnOoOhVPTM3YgNARHvaLf4bzJxC5mpx7UThEKRPcHQ9SQUpbzembCulda2emxirxh8",
	"QtIYrMsZfy3Lf7W/Y+F6aFCIDDd5LvNAd3TjIzcmIWriWbCgx5MemzhOLOKHucyFpQz/jHURwzWq4x34",
	"K30M7ByOMWv6JmXkT1jXQ/X7E+YJyU4pLyoF7VyimrP02R8L8gzjfAkfqBB9gghqlT9/kCCfoh/qj3T/",
	"WE2pYOToDmGHsbTbRUGS+jzNqtkM5Jz9mgIwZEfcQA0VnqaOdyBSLiSEQABEIWZWFrLyVGk5FJgtMpkI",
	"imZ3ClCWsTNMIjojWI4VbQhPykDq7UzMeIbA82UW9Cd2Wl1mMmH7p8edCHeuc70z2Bns9FNx/fIlJfMq",
	"nsvOsPNisDN4QfmRoNFtgxXHbAdTSq7bajSBQ/3k5B1kXWN5qSVimmDOdijY3wt56oxAhUHitqy6XqC5",
	"51ToOnZinavORehPpKRQ2A+HEsuK7DADEr2MGyGJqD2SifBr8IAUeeyJDEXcQBlTuNvBHecTWo9TWHLb",
	"CuSxDqrRwpSvdbp0Gq5LYAxRB1iSx6nK9wLwRl/wlom6yk5ZEs6QAju4t7PzNCMIpT3FbbkNy9LHGq/1",
	"DlfqPTTkWSoMi/sJ3eBxGa5sUx3goMfmsjRjSBWEf9MDocCfyo0G/McA79ijnexRsdtxlY9DsbOoWaqV",
	"6GFR1ZaY0xZLA9IHyN4BmL4XVbxForF8pl7l9q7XefkZ9wegdduGeEwICDweahHMW6++zCCcSAY0QAsc",
	"m5IAIiEyIv0FKml6BPtOrPSw/qfrPGC5nxlXRng5jlP27YAc20vmvFzP9A4i+6ZVQ/bf0sqCLdYhRxiP",
	"dexMoKjtYCE10GELqw5fi5GqG7+pvj1kGxZiKpVAnI95oavZPBj3AiLed2LplU7ydT9/Hg+TfYtjAM+O",
	"HyDs+23ppBgPGQwxCSSe2o8d4MfgZQx7hoWmu5OmxLreJOPMLj2yxGwhbnClEizngN05lSeeuv8ElFbP",
	"uX0PUOOvyEGwtNvsTq+HuceLw/d5uFR8IRNGNnIQYpOkWlQk4pPpnKZdM1dHU39D4QMwoMbcrYAL++Am",
	"bweKdbrJLGHKogIBIaUIQ8IuPD9C/oeSH23WpEYAY8fZJ24xlBCpQVB5qfKqZN3EuVc8J7NEQ3ESILBM",
	"qPQceQQmQ1oOHLe3UoeeiOKsvogdEAymazoZOnfbuh6wEiS8O5flBAx/rsp2zcENTZApTYbOJwekCEIi",
	"/Gy58QTMNvXd8dVAoBUwk8mQIbq4TgAvgYAda6++yfSNw4wkNdsAvoSzdjMwtHur1ooHA7Akj6cOPgh2",
	"pLZtIZpn0uqDmFD2LVwBI/XCjyOVJs/4stGd39kem4mSdh/XbKReNiahxI3j68QEiePndihWQNJ+oiP1",
	"auBkc1aIXHDbuyql941JEyqEgKBaF3m8X/CJBJ7I7/iriDtNv+dTCjsN3u+Pfo/Vj2+PNU5jb6RA9nGy",
	"TSS8tOFPr17LB95Z64myhfjByfrF5ZUkHtvvTVqBhXWySousgApMdImjubB2Dz5YUoFfXXTrPXoaV05V",
	"A4kaDGLKCg08C6FQxKfRxI7V8Xh8mUVlQwlSMNgmUd5KsIIgQFAiEgMCQFmdDQwDdKwHweJBH9UFi+ul",
	"UjFXhEScSxPgSCWwQyqiCIjLr+0KkGwAaiJYA7EMS1gJuNkpHQzkc8pY8i+FKgrPDIGQAfjgDLKzguXe",
	"zsfupbOOmBY2CXN9jTvzlOwy/s6vxDHrQyCmuXK00CqE/tVaIa8vzV7cTUnBawjhQRQPgPsG89QxKgRG",
	"9/LpR0d1TXTJprpS6a/L8dzaWIZh2RRVadl6FCcEioA0fzjedKjtwWyynfv5HVbl2aCUAbybYdzV79FT",
	"xGTBYGBdRFUb8NmAQSSzO+30msucAK6CWxL5WWEte4TYa3po866HPSNaaZbRb/giQrgD4Dmw/59NmW4h",
	"XxPuy4mfAflx0YjPFlzJKcQd2oulLHhyhQHjvvAyzmek7D2CJU9kELypd2e3dyCNVJaBnbjnDgkV3PpT",
	"mQmzNKVYDEGREMPt7e2cl/PtUtNWQFrK/oL/rBU7fzFkE/NiuL19WSVXouwrvhCr7e13qbzRubtR4LOT",
	"yWSkProh3m2P1H//1///3//1v//7v/43+4ivj2V613cL4wtyQ0UXxrr0g1+rrVoPsD67d/24q0YX6FTx",
	"W117Hzayv9tv62dQ8mLwsylX2+89uD2229swPtv6v6j1YDCgBVu5cXBtn0oqxyXGb/xaknl9DM6atsrT",
	"iMrWFI4M903bx/zot1/z9GxF/Nz8imOmqAIcPVp4pIE3OJfIRFL6gx4xS6L7cfCG1dglbMBMlO1gnchF",
	"6syG3gtRkS7nInBPd0wHI3VGCq/nkPxSVwTnVeOnviIPzslxrt5I+VI7aHQnDwY5LQYtRG5H/ppm1+v4",
	"FEbEWW3WUycEW+ezhFwqjB6HEpDQy+Cp2V495ck2XyzxBfLl9Gkk21DkrjPEO7DjCqCFhOrmWYtr+DUV",
	"vp+e8Bzi+tud2HQIHSBsoCVHlb/hAwiDXh3xA46c1QvWyydnlWK2RQU4zEyrqCqYPTnOqkjeKKsVei0r",
	"KhhfCoOai++q5/4NQVM8mYeiKoC+goVOXRs4U/YePvOqzMK5y31WAEO/7rgsqnI+cJXIxzJ1dVngVZHa",
	"J1tUXt0KiT2WFyIBZ2uPqTSZ9diiKHpswXP86MnJuz43/b9W6Uy0fRd/QHHKdUw+3p6VQMv5tMqUMKbn",
	"Wbv7a44VaXuQI1Iue2wusjxqXVhFlP6QGNcy/lvF0eu/wmSOcLnEE92ltvtf6QrFT69T0Y48mdx/d34Z",
	"XS0QblNtc2paQBQGc8HWb0dxQnL+FM3pHApFZVqJeAGc/eN+belvPtGklRkdoRHROB7jXCFWHnDH3d3V",
	"4LXC0J5a7T8y9uAKu7BkVPEJCMbgoW/GFjuJHwXbjyPF2KgDHxt1hmzUuZFXMhep5KNOD39sGopsu48j",
	"nDu+c6nT5ZDqIBejzh29CBk+tsXuzkjdkdiMJaRqIQf3DYmw3Y0fkQtZiAaErSicSXoXZSJqlbB8D6RC",
	"2jf/MsIAjrGdxdjHn4w6PzWnsdeYxre1GHGIv75vKjli1ppHLG7G81LnbAY+7bC4rWswl7N5jNNPbzG3",
	"N+sWgIbVNvvYJLg6uLyQiRhiWfS9nZ0dtv/+kEk1NqVOroCbhhEjg6AvBhR06AL/GR2TluXffVVf/h+t",
	"Ku+jk+5beShQG5YdZ5UXYipvsUEpFFflkCcLMXzE9qATuTFVqDxo8JJrXTcsuDhMBfD4liPzqkFr7w8R",
	"dgDiMGCub6x0UWVXznzaA2dUcCM7qyo3jF4G28fkAHlG/2KZi2F8OrZv+yq1yzcZUJo5xCRC1QLbM74+",
	"GqnJ0NkMwgoj47Dr1kKZo87+MfwUqO4vo45YXMIu+0m/umt0meoEtqxtG6L1HHXKqtSF5BkspO9vd+du",
	"na7+NtOXPPtXEvSfzC4cpIxep22l6921OI2+sBH5zPe+1oAcxJEvLoxQtMnvziV1igyZcTYDsmNOwbxH",
	"jCj47DFCBGSdYKgddwVEQ2kezJGrjLMFBIuCDzwtBuwiAsiCWrvQoUghDm/Vr9o9Pz/aoox0nvUhYpfC",
	"zldj9c747CkP3Nn+219JqIcvf25ftZ6yBS+uUn2j/Gb6snaQhQPcGdABrJxjHuJ1Ptt/S9TSHjHnqaYR",
	"MkeuaVlGIVLuNGJy5pfmBXYmv19OYEff9TaA/r5PRHrro+W2HswlsJD+BtsHNjBOpQAXkHdzkI0FgeOo",
	"r4YBlCPwWeltF9jonU5DCJVVs8ZyOoZKPmYyZPuXuoAyP1BDHeqXUXUpnhWCp0ss+mMChhVGPV3JvNbP",
	"+ZXMsal3Cjo7CA6D2BtGNelrUUAey2TIDgu9+U1YCJy+cwa5n6SVm5YqmRda6cqwPmbwehd4WcjZDBPA",
	"w0sUiI+eIBeNJBcLq02VIlsie+VJWVFGKr1JgU4QLYTx6uVcjFQhEq0SmUn8PdM6t2yYtEFeCCzY4YrP",
	"N5gtUcWTeiPoI49iu3tPNoj1plBHsbRrvyOHhBt5CA6tneFL53K61zwaqsW3OiScKwFwJKhG4lzwDGLZ",
	"UoZvO6cusZPINEHxJfT1VWlblFSA/um9U77S/WrIFTE8moy3o7YQw+7TXybfK16Vc10Aykq/gUHsrWpf",
	"jNDeitLfCMbt1b1URR6xQFWrzqIL5zTb6CtywbFI3ZdYAZWheh4qqOWFTsfN6mjwcI3rBjvoxI6aBb89",
	"EWpm12Dv1asWcOt7h1aImbh1mURhcP8LBjJ4Pr7+y07/H3/64x+aA/1flRHFePB83Vixw3WDfbWz0/vs",
	"XqaHVdqwM3fHaqXKxmpiBsvI80TU8Zt3N3lhJyJ5eLCO4LcxZuA9X4g75KWZKMUq/VsJBFZvle+9bMGX",
	"QjTSQuf57+iGAimLovY2r1+vnUm8FeWaNfp8d0ONhNfFfqWi5DIzUcTZ5pV7r8s3GCr2SD5b1j53z5pt",
	"ZJvvI9RptwPAW6jyGbEWT60bXdj3ccafevcGfylxQ7MDhdFld1EsJ0vFVCqJUfU+iIuy9UMIl/NmfG8E",
	"O+DGOTKomDV2P9UFq1QUGGvF6VYTsKoWY5RSwIZct6pehLFOH+InqXf2wpniMVIVjLyKMfvIpdaOiQKj",
	"H1nwaNSetvbkfrB7gZZjxAIiA3VoEDC4Vt4Gc3/a8rjeMe5zo2Ns5IEJIGqeLPhXYnmji3TU+an+wl2v",
	"+XFwr3z279u9QrfBw0dyqdPlEw2k+e34z7vGZvluKBKnL1WfZ1nsjcKZ4Xijrn239A/X88iBJ47DPDyR",
	"2SZ3q34fT6yU2yDT2waZhr7i9HjskIZwt/ZAOXgnj3T08IP1igZb8wfZYbiSjwkveaYp47CRwBy8hI8+",
	"luQG+3LH0vndftXjia6438DpbGz3FzikvdUNAWfkPR9HoMCHf1xVC1HI5HMyieA/rTtNP41VeMK/n1WQ",
	"b28TsyDQjGh9yPmLP9cGHDVxwBArx88hrdJJAwiy2uKPEIWbvp5l/YVUMls02lQFtZiXZT7c3obKPHNt",
	"yuHu7ssXLx1bCwu2wt+++oq9FqZkp5A6nKBk0meHkCXshByAsAHzIvi7Wak9HEOtgn6fnUO9XZQ+xI3D",
	"CMM8GLMAUHJeciNKw7q7/RdgILVC0UJwJdVsWpHeAsqyqavJFGQQOb5rgRTQ14FWBhBsOeJBXeqaHBRh",
	"9BEpwMhqyHht+YkgDQaR/gmsj+ELv5LHB2e3VpPAXIK6DkeJoVnmhV3ACYV1/ST97jE5cVh8P5LPP0XT",
	"jZNAHqWU2CPgLZWfrJ5sUEfa4vCfkgA/IQr/cRbFBkCxX/cokDm44dsKtDWBQ9eF6JPLgoFaxj9TqP4j",
	"tecvHNu/cgAsk111q7XSf4lg6Y8k/6mPA/Zf+UIHwY73qY5Amcy/2AmgOKlNoLsBoa3Gdd2bbXj9GBra",
	"np1hu8Tfw6aR5x0DTYP5xhtR62NG7/Bq3Aa87cBJsHaSNPCtqmgtrdtWbAUqgTr4ruNDTE6j+TyAH6zC",
	"G0tlRPFpS+xfbYU2fgAnqp2M9gCj3z/7ca5/ZAS4ZuhDQxI1CHr8yczJiRKbfDHH1OZLeA3gW5/iNYhl",
	"zWDX/M3uq3chxONe3Uf49dez7a7cGZupaPsj/ONBDg7Y6E47u2/Gz6Ti9nfq4FCEKUiO9wdt7zp3x5oV",
	"+3zqSe3stcUxwT58srvjC7qkZW2ov9nj1Nv0NUnb3fI1f8o+j8CHel4gr88v9kHfrh7Ug6W+NvLjafo7",
	"YgL7aRp4AICyPIADrOGxmdafpEY/kc7QCEhNuDLsSiwhqIdH3jz7pwouvSuxZAVXM8HiaLdyLhaMm5FS",
	"4iaTSvRTQXV+MKC0i6kIW4T+ACGsHsCMYxsUFeGbI2Vnbz8V8NUQFx/rC4o0SMEEV8MuqA53gKgZKVk6",
	"zBkH42dv7OYso1BHu/Dws5s5zrUt0s6u2HdiaZ7oxLnuI13rcZat9lyDBq217lYPU8lhk2Tb9jCO9v1R",
	"B1f/ISHIdi4IscK6cXQ5Ecb/KJnf7t3asxRO0KeI+8hEtj9eieXdepkfGn0nlveFXx3oxYL3DdW7SL0s",
	"Hpmw0QmxUkR7pNaX1bQNLWf3Z3TgsNYR34U8+viRoXMU9zAubtSxTd4LY8cDyMgui2vA07QQxgwSWS6x",
	"mavwBW3GGCY/eI6/HblcLPix738dxNluMBw7A4AhcOMJLUxvTGkSwvSoC/tWLcArHn7PI4jA1raHfOGX",
	"Ok+JI/CImkdtcbOJLtIAiPQ/5mDiwaAzKB+md/+m5MvvRJTaA5tUakaCRet3r8TysyiIC1FgVc/fouxC",
	"AfvyZxRKroTIHaSJVFhjBi14rkwFBOFTrQqWySvBzuc6l9Nlb6ROtSlnhTA9dv4CoBy4WtaLXtCbA7af",
	"Gc2ulL5RjJsh9eoHg/CkI+VqUMFPPctRsTovz+iJ6Cd6sRBFgk0gDuq1Luf0HTIWmVIqtJRBZualcIO6",
	"XGJil137K7EcMDI5WUZcCNG/4UsG2wfM95gsUIhdGtXwwI+Br5EKiCRze0v5Uh/o8kSbFa2u64BfGhDF",
	"Qj8s5zPhMK9cERGqgnGcikWuSypR817jDgHmJbsU5Y0QCl43A3bOpwLLskLOw0ihHq6W0IDJKSI6F1WO",
	"+RD2ez5+DCqY2K7JMWrXzhcEqy37/umxYV1HA+xHrQ/opy3aQJbxK8HELdxiQBY3vBBzDVDJGCJcarcs",
	"U12wTN/0M46ljmquUxrlj/tn74/fv8UVKLHGKrqQlQvEh00j47O+FkWGVYxReDCDkTqHAlT9hDBp7VT3",
	"T4+ZVtmyHcNHCV5AcZcnElqjL/xKHtraCNbhbcDPnxem6jcqiEacEai4tVpPRPkx89uirFEOmgAvkB4/",
	"RWgNuBiP9h87yenpvWaQo/qU3uP/qzLDf/9nByfHQ5n9pqi4Ji+zhf5dQvfj3cc+cfeLCFJRbnnIGAb3",
	"VH0Rfms55wweovIZEC982vJqSjrGEP09L/3veelPlJf+qSzt95TIvpY9fBqPjNLZHy0l+PRtVeovIixQ",
	"fu5TigtPn2Rdj1uJNiAybbnM6U+LNjurZ8j/jhOxnRU3wg74FEk4Wvxf1Y5StdA0qv1YqfSJaBrz8bDp",
	"byV0l0qzVlRG/3+sLojbu1Jo4f6IYAgk34QgAOn0BvREgp7NMigC4QECEN13wM5wuw3j6UIqlosC4CS1",
	"GrQCDn8PX/5cUUt1dmfHh8co5nd/1XOVavEpsXQtlOVJKQoA/TVwBvCjL57+o290cSnTVCjWd1AGq3v9",
	"5cUdPDLsFwR5VUSJ7qhYyoyPxzYS0j0nhOJZfIgbGfqyZQwDIVL42qANTeMAX4Cv/8JjUT8NYXfMgyP9",
	"Tms72gws/cXn6zd+nn4nFAz4HmRPXiWyTRT90f6nJRKwPkLnEIh0gHbqxYbtlPuytXRS4YK4fx0o5Nc8",
	"ZWd17GNH00waj9Ty5SrVwJL8ioVqPpkGcesZX0NyvcewzXvp7K0A9vh66eXiJxIoYfSP4lJ/J9rfGeOk",
	"QmbNIFRPtw0drm2koQkQjCXKU17OT93jzkPhNWAsvgr3TF4LFbaWq5Tl3JgbXaQD9r3fcQURNKzkV8JA",
	"lQCRCpWIwZrkTc+dnyp3036gZtBoIRZIogRXrV/4z5ti9CmHOozsN3QdSbI9QnHacNC3HSWwhTQLXiZz",
	"Ou7/+PSjPNBqmsmkxnwawI9bvyMmUEugfbjA5HegxdDz6UyiaqswSQ4QqNnvtv1B9yS+aT936gb7NCcf",
	"P+Q+suH0vxc3YQ4PP/yfj5Do5n6HOXptQ3SzuM9a9MVZgYrXDiorRhf/32/9xxrJgG3l4Vw86MzXVeh1",
	"CtOZWOjrusIU3mRF5WzMKC2H4h+FoMAqf+FbfbkFbRv6D7r5m0Iv6F7faHK+mFPXwYuL33PGimiUpWaX",
	"toX9UjpYE+TqOthomw6WAV2kojBj70C6LxLSjtc2+uzjvbBf3jTme5w2oZO2KN4WVfc02n4c4m+Grbhi",
	"P+jqC/QTZI941X5DLIfpgp3puLCrpwsUnT11/n54E57smK59teWIRUVWuQeo1jzLog4fp2KfRgzvS2QW",
	"b7I3/l0N/5+uhuc1altD7U+rkO+nqdPG65fLvSdmP03DSC/0E+rZ8SFpkV/DsJ1RzQ4/Tb+okv0AOTuM",
	"c2O+6G9F5f77iX5cSm39+Gy6wbBn+6k2ofUdlwpC3rFJp9epiqwz7GzzXG5f78JZpm4/rsSuyuSKSVWG",
	"3AAYiotZpFD+/dNjh0t7gGH2J/KygHww+5haEVKdYbwqdX+GxTxEys4Pv6PsCtvlh1woGCwxC9iYIWLJ",
	"PX/+Vj9/PmSTmSzn1eUg0QsqU5te0j9c2dqZpn9N8EUrep3DzKCDf2681i/NhHVVvtjC5qfLcq4VNKUG",
	"OTyZsO7p8vQY6qPvZxmOnRcoZfchPwGTa/KynlUDq3V67FNsE50KNvMFTWD53li5okjmshQJ1qDX16K4",
	"luKmx6aCl1WB8fi8kEYrQgeujGAJN4LNKpliNVIjsPDHXxZ2511+IXznp+68LHMz3KZ5D6TeTnVitiAT",
	"goT8mShLqWZjqqDR6XVu+6k0ecbRXwAXDiQMn8ctdGL4tA+cAPW7v3R+nMtkbheJmbmuspQdw3itALXw",
	"ecr/1Ol1vtU3LNXsuOZ+q62cbfXjXNgl4Iods6kEaORUMFKPzD/Z222F+LWSJeQnpQyDNthSV4WjXALv",
	"f2ZWCzoEikbg/2+hgauF4soB0Gu+9okn8hB/e099iCFSHHa0tCRnCUvptF5Fwt+VPMMXUjEreCpSSODR",
	"9jvYsFJRieAqFC6YViqJ369U9MmDQto1zxzUkmF8OhUJFvvF7iTWo7WvQkgkvEYFum9kKvyrtG608lLN",
	"8PDi+rFkLpIrv15DNnl7dMG2cSg/w2E9LfRClHNRGVeH17WiPydQolgXJXu5t7Nje//eAMUb4TumvNzS",
	"LpKjpIUfEcXa4ALzTBQwUammBfew2YP4SLQUeVg9FY5S3jUatRwMT++4HHJqz4PbKemocYlEz0vb1p6D",
	"VE4hctjXH0HaEgZgL2sHKcydSB2WIKxt+2nBE+JLobedlQHDqhVIydgigF8BxWIec6jLQsA57kRhMJn9",
	"A/9lEPscmZZff2++gaMDiTluQDQ+vIeeP4eoZ+zq+XOKeq5MqRdu5OK2FAqk4sFI/TiXmfBwCT3CXYcU",
	"HgIp9WfYiGth2fClUGIqITE73CaQdlfC6TlSBs4MDDLRykiDOW1Uu9YvD779IS/lAkqbANqHVDPbyZsq",
	"y9iFuC3xKYNtBeONVFjZErRZy8vyvNB5Ie3mvs7EtWALTHqj/l+L0pLROWTS2a7tcPv8hhe0FUDsCLtq",
	"XIVWX80a/WR1MNbnzzHRg0YOQ8GJU1Yf3H5OvKeYZx/pSdsebRM7d7scyQcwYQPVhYu01jre0rCXsBtN",
	"rOwNINbtyPJrAKzvga/eCF69HtT9ASDNnwgZ3QRIXgPm/ukDmJeL7J5vWiHynm+CJaLlk2DboEqwqyO8",
	"e9gQH7YyDnvgnpG2Ypbfi1oOVEYQDesmswnmOkKorlFbG1KB7XbKMyNqLT8VPv9uPW794VLxhUwibsW6",
	"k7YRTbAw/uSe8U5Yn31QkHcOqGGIo4F3gNUa2SSs8YR1CwEpyMqquJb9Rbxp657PWSXdfo1QlbLMfwyn",
	"BHA53WkmbqUTl0ymb0QBHa+Cd9BrERc1LJXGMsGUShEjJscHoB7z/PnQ4VJP2ohrgqxN4Uu1aQPOdb2E",
	"R4T5gR3Ym0U9s5rGXBSyZJM1mz9B9SrnVnSwvezbYwj3KnU0XB0jHdWJK2285oz6c8IGg8GdQwInln7k",
	"mTU+/yoaIpzcyUjBWOxQ6B248vCwGFr7pV3qub5BmQ62EjdywN752m8gKWD0QZA8oJW/Hv39jTnh8A7o",
	"eJtx8S0FuTgTfz8BCjgCt0OX9YHc32udlcefmECvVqacsK5tvAVXcng8HtOLpNv+iIUe7DXe56a/1FX/",
	"YTPrhfoW3IyXuiLU+8cOZ29W8IUrcmG370AvLh0Qw1mVCXcQJvb9Cb5vL5QJ6M6LqqzgJFJl8GvBuslc",
	"ayOYVoJxw/JCQoqbHd4W6gjhgWFd7LdHnW6BingJyvIl8BSsucELySFJcuLWr8cmq/OfULHN1R/YH5l/",
	"1XITfUN966qsjZF1wcbB09TQnLdWDwBQ8mSkXmudCQ6WFeIlgb+gqwGWelgTdtru8Tr3T8Wt57gxSv9X",
	"69mEE8j7VqjMGHcnE08RAumvwh0ZggaajJHVQGNAabDCbx//pvImqwLbI++rtqIObnZwp9jV7qNDuJU4",
	"euye3e+xSSbV1WSLobwMo0rR2KLhC3PhNxsn17XXxCQcS6YL+yceC093W4M6c7yA80h7AoI/PfHnpA9K",
	"QVx4KVSQKfWVcPgpqMYqni2NNBDahoRDFQ2sjuNXDErh+67IDjqAj+KJ3PTRby/enbCSz4A/A08NX4Pf",
	"av355eizo1uelH2Is/K8HVYNRv2zSLdCR8eHpmc/Ynos4aWYaSzgP4VSg2aw9nD22VE6E0z17bK7jgtc",
	"iarUDsli0MLZ/F7RTYEfATJgffb92cm2/bfbbZqX/4Tb2K/Ye6xlAvvhjnXYVKp0YrtE3GjDuoQGjYrz",
	"NNPc0olfikRXqjQ9BpVX7M4luhC0BJfYv+3toqjENhx0ds2zymvaX7FDXortC7kQ0TBSXopSLmDF7E+m",
	"5IvcIwT6T2Mc37YL4oEQqh6DHOnQ/1uhTc5Le/zDB2ZCgw3GfuCEl7KsUrGdaTWDfzH4LXwo02jjtdut",
	"dZHae8PNcSa0mXPc3APYv1s2E3pW8HwuEwa/hZ4udWXvZqCWQsxI38eBOvyyMEoPX2Y7/wFLeQRIM6RO",
	"NFyATAqKdrQ1K6WbaFcyfWk7fC2V5Q9gEYi7inqQCz4jwrb/ucQ3wgkCXgHX6bGifHH78Hi6IkRZMbQh",
	"qSLvQw42FYUVIUEGjNXqCZwbJ7KvXigT9t//7//HJpEgtNLUFftBljdy4Obxu6G+z+rrRMNxc//oJy9L",
	"VqVe8FIm7A3QaGQy4O4nEB/gukUzYMDm4xHEHhl4nMl1Mi4d+U+ssHRIByO6wvybvqVx73rIO3gXBX7H",
	"IRY892jd4d50ifooRNnu948jP4jvkOYNs2XvMcn/QCt78pwo/eNcqKjusd/siAKc1c4FSHsVqSEUU52w",
	"ajqVt8ItzWl8v4G+hzeS3WWUsUBjMEwXciZDp1B5CXr4jpgk3X4gjK6VYM/bhddWEfMIzf2Pkq83CLq0",
	"PiSeWnGDxNzA3sNP0RW/egvEzeg66YqWG2lrQ7Uk0MJwqYHJrNzUkfgCLYS9WBlcrGBp75Ps7YjCtvH6",
	"LRjmpJoNo0Pd1EMEmfRa6h3ht1xtoz7bT9P2m7h55Ua+B/IhwDxR3gB5uSlAwHGxMgYIAiytCjTQo1js",
	"ASmny006L/DYXBclVzVRZurZyFdfORw4sHy6mk/BbNmmshBvmfNrweZyNhdFkNcTbUqWVoC3EIjISFMX",
	"iKgLe2KnHGz+XrO9rErS6p0ZPbdyHM9wk+nyalt1YH8xwflR6WtRzAVPm/ceTApvrGhEdaYKOlnqrg+Y",
	"U7wNDf07twIXcAJA8OOGdBlmHO6gH5TlqLQHh47LXlycsK6VSfoXun8ir8VWxOxpPUwYIBO3uSyCCAzh",
	"pPaPWj0OPrULzCOAnTQUUz0MzVam7gINL5dUTX5WQJBcYi+oKmd/1ZesqBQ4DzTqQmd8WrJM8FQUXvQA",
	"Nz87iKu42p/cAwGzvrEMHbM6wBWBQAro4ZiUZTZ2Y560mr1dmULL5jD+x1d6jF/GJnsvQx3IjfZy6uvp",
	"7eVQ/NvVebzXADzqBPtty2fvNpT5a7FufqtvmCzZjS6uDJTf7LNAFEBggkiojtLk1tSHLsgiSAnE4wyL",
	"ZQw6GZdLRkUG0UxQE2BEynhJFVCkVnCpvF4lvaJSxsrixZK92GFGJFqlpoUIEePXziGNTwQU4LPqlDvX",
	"9maQwjC5WIhU8lJkS9a9FFNdCPfNLQ9tiWhChcByLSJl3d2dnZ24/9JSsFwINBXNtA97gKElWhmhTOWV",
	"3wN07dhzcOagkVD8cc5d7tw/ZV1hsStVCp7aEx8v9T2HBLWYDUfkT2ntx6hAI+lFY14+7AzBp57+BMXD",
	"WnOI7E2PjkQqNclLAREKq+cLBu1LYN7nxqi7KlyUF0lj8cAe4mwg9AsgJDqOEXmQ6ErYrnkhAFJVqpqY",
	"b/BiwjZSsbM3By9evPhHhpN3UWqTvZ29V/2d3f7O7sXu3nBnZ7iz8x9o+wvn3xn3AK0bvn0jM4ySYBDk",
	"5tk5aNuOJbzBZVYjZQftSAtg99lbHbEOaIey54sdYxXHcJzh6auFffiKLaSqSrr8917O7cO9l2yuqwKf",
	"/QnMLH9iKV8a1i0pCY8btvv1n+comtp/2Ua77EaIKzfmZiFxZPlRDENrSeLVE7M7X3diMm7KMYfQREsV",
	"YbvpW57L7sJ8iNlOaq9NBgS4i2g/nglohTD82M5KUeAfTpFXY/+EJXshrCxolZoDDsLyAycGt2UYtH1Z",
	"MKFK4Jc0crcVNHbPvunTJ3rGzjRGYD3wqy92akt1omdtEorL/cfPvtiB7feCR020nXOraYhCmlImtNkh",
	"EOG81AWfCTpwlmiDwouBHilzCPj2apgMywnpjIDhj+rsh+7uFgFtA1W+12hvSIURheSZM1cqIVK8QUFm",
	"pjvNJFzBa/+5u7PTt1fKrZeO51zB7yBr1WDz2aVOJR6Md1LJBccQKz4TXuxl3f98scMulyUJqO7VLVwF",
	"DG14A/ehI4s+IxfRlVjSjCxxUfBSkDq7/7mQSaHpxG7RpOUit5qSVhQKQRDH0G3CCQZ5IbMMqD8WVnFE",
	"B7Qir8WcX0td0JDOWi/9riuZaiVGGMEJXP19MFaH0nHdvMBrj6UVRrwKEHrglVd97I7NCp5A+oTUKRMU",
	"13JTyJIMDFjVrhDUQ4ryCYoBqRcOvEBgthh9FnbjZi6yhQe8hBgsR6z1cDFLgVFpQfvlTM9mzpXjSMbF",
	"h9EpOX7/5gPDoET7EdtJLKvHp+ybvZe+mzHAY1/z7JsXO8b1AnsgUlbldMhjAQrsst+83GNRd68WdltL",
	"no2p/Te7L178qeZ4eadTcmbaoa1oBM+f72OtYTh/GlOBYbXs1hIREBs0UWRMXT8ITsn9PM8khCKWheZJ",
	"Ka/t2W3YxEz9wgtpyDhn8M/x4op8714+9Jvtbu2FvqahuwMkyubI7JwWebkkFwCMMcvi80QYeBCiV2rk",
	"IqeFuJa6MtmyZScKseCSBnEw52pmX3VfXL9kStw0BofO9ZtwN3NavVgkblu7ozD6QiQ8S6qMoGPsUMIe",
	"RgZEpIYTuXDYnM4vfZDp5KqJju/j5p8/Rzf9+4tTsI8sVcIS+4ZxgWYughCiR12XeACIB0HU1soqunuE",
	"yq/8Z429UAfukFCENAQBkqMwiSkZAs4uTvz6NdfMuQ2BqKmvINSDQGS7cPKbE9504f75nisdx2auILKt",
	"RmZi5ekHxGUeanYM1xN4YzEq0ccFkj5Et7ulMzeneghz6tydLOE5Bs66hcBZu7DOZ6YW1ZkEZH9vc3NW",
	"RjCvtMZsOrRRcDVEPBPNYVC6PK6quU0VNXs1wHIssjBSCNrocEZ7zmIjr2VaUV0rut+dgwIrlH6oBfsd",
	"TacykQjahZ9l2gEVBat1jSI4M3jhUr4PIh/DyEfKR1dbMS8vyTjpyoQ6a/uVWPbB/cVyLguzVasf2vXO",
	"bBBX3OgPpWVFl5Ul/ouCK8MTP4uVtIVSL2RCXm0ItsaLkZXRix4O3vuydIHu6JHa6+dzbiAsYSFL1t07",
	"PbDXoy51orMBA5s+bxZDZibnyoRVwyhvZ94fqaa1jsCpZWmFf87SaILROAdrbB+7A/aO4uMc/i3PwEMn",
	"DPv25CASvSHSV2QQhhRNFgc4UnsDdhA9JREiGgLVxeihfTOROcRm4IpKMAKbkXoxYPtovoMiomUosCvS",
	"Xu2zuKi1L4zUywE7jXu3t5nSJRpwuOOzeLcgQq7OrqPPvxqwM5FoELkyrXMvEWEn5Lj0RRLAO0rCeDw2",
	"iozHNX+DmRxOuX3+3Pu3XKEPclXunx571s/67K+WIVYY6E5E4s4F9QP06RIInMyGFwNkHmB+AFGfLhi/",
	"1EXJSj0T5RxNRfYih+laLgUB/quzwFWcc5VmImXXksNG+iWia8ezANvLf+7tLIy7gaLQEDxEZePcPX8e",
	"KS41aZxeQLOTGUKplBcJexU6B3PBmr4b48A6L+BsgH2vQGJwfUY34I0uTNmHHJvuynRJh3hb8YKrUvht",
	"jbaAyBVW3NkOushMZLncQp/NyjJjCqzfDNa1Igsa9QC/e9GkQgxZ9FVjokmxbpD464QLLkM+FVuNojCx",
	"4ATFVATKNL6UDVIVUVQMY5MXeiozwf5o5X6Hcr7lPQX9kuKbkHVDZW6w5rhFiqnxdZVdkQfHpQMDb82y",
	"vi76SltZZcaMWHDldFoQq+Baw/Il3UPLyc6XKoEp/t9QBImm8wvqH8nV6kc9X0WgUe+o52/Y9WWONlw2",
	"qHs3aq3gFuR85kIIu2ESV8KemL0BOxf2/sHnUOao1HWJJjBHe4nQokCxoCGrcpyhMyCuTGZD6Sas2fTS",
	"3gy54CWwM2XFNRhFn6laqSbPwGs1m9qOGzneiaa23y3P//UEvODnRydHBxfsOXtz9uGdK9Nk2Iezw6Mz",
	"9vrfmUzZyfG74wsGSveHN2/Ojy7YzmSkGOuvlHY6fN0owVQru4TvnFWKLAAuQnquqyJbbqdcZsst9M1y",
	"f2J8UC0eDHtvwbghZQtwbSHTdG9n72V/Z3fbTWDwV6PVPwGiyTcyxapXUGDzm71XtdFHRJ/wkmd65hJC",
	"CqOLiE7wHZrbpUj0wqe3ANehL6ML0o/6BQMeccKvBKbSFb4gK0TmsO7EnsvtnZ2dXRjzpMf8kz33ZDAY",
	"bOH3USBGtoUUA6c9VMKi+ljY+pRA3/FTUjFYkB4zAtIbSeIB0rpc+nphduB21JeFTK5MC5WkIis54sQE",
	"QrHSe6CU2ho3htgs1oUtMdunVrSL9Bx7S0WvY7C6JfHXLnPKCTu+zhkJO7iJUJwEjGuUvNd3xcxYrZYZ",
	"9lEvjRaqn/WLSjWqnbUII+dYqiMk0vbskS24Su2H0I6MBsovVYOM9KgEqi6qlBGcPjiJMZ4d1TLYkGte",
	"SF0Zb+S0PwlFaaQTS0bD7e3tnJfz7VJv44sQiKchvdOSGdnd+mxiXgy3ty+r5EqU8IptuL/gP2vFzl/Y",
	"7ztk/0ivLMRlJbPU0UiE9c+M4rmZax8fyL6zFOfswSN1KAuRlJGiRrokFawBvBWK83AaZ1AS8QaTBauU",
	"/FuFt1hsBmiWF1i1AsA5/9BosT45c43qBALhlT2qeDZqur/xhwnWxXFzS97EHu/X/RsKIIaGxldb7YuX",
	"gW6KehmGVmsBVS/yDl+S5GoZldNG/G+PXWN45ErMY2+kwhUCaYncSuYUeA+2ByudwME4E4nMC6DCM66u",
	"2BuoO8u6Z2dvvDqO4kAtMBqCkSE6+pyuKPCrY94jlcVZqpLfYm6QvhHFtMpYNHypZnA4wKFcz1KUVhiY",
	"XOp0ObT8oCpFAYZAF7uLm6AL22r//aHl/B/O7P+//3ABDc+gyHfoail4MQQVQuzt7O1gPvO8sDJdaDTq",
	"YCRVDj+MOt4+fE6irJ/qe444ABlXs4qHL9FGrWwLVg6Gl8PehpAFH/rjMnJhClQTysnRcONTl3VLp6tP",
	"HIwRocOFTkXmN+1bpAgcCW7xSFFgmmlElbnvursEp9ZOLS35A7azse1sTCIMOqyBMlyQabS9ztc96rjv",
	"Ru9hhqi9KzhaG7JMziDu1rk23bpF2Qlj2/9YWXWulo1AMZzkVYKp+mrLyFqnWAsKC4GhzOvId+q9Uf4c",
	"wBN2WoipvKVcByznFfHIm7k2Aotq4+1Jhcg90aPhvZFKgh8b59h1x5WSHoKTH+biaARcStA9qELUbnfv",
	"BUYXwF8vX3096jRGDed6pPbzPFsyXju83PI3tv/+0F6oGKLaPjy/o/XdpRSB5bAUyVzpTM+W0FvjJI46",
	"d24ywdkBOhImJQCfsgwZMDNoaCqljcAH3rHq99FN7AiD5KKdcBGZjdl233+4CBPdasxUuH7vnWwq8kIg",
	"RP2HM0IBGAKzuxZpNNeGNcVKMMJZiCihAt3KYKxPnYnbJNoTbcHVlVSzHmWMR0h3oV/Hv8/237IuAafx",
	"rL9fzexqiJS99UgnWxjD27iFVOrAUESIgyZWcHLyjkqir/Cfwn3K9QTNqOaeO1kbKuXF/K9RuE2Kes22",
	"JPhqfIxt+Abc9iEeG25Tn+1jbkTB9meQezlSx56vlK4cm67AyoKH1Qc34o8BIwbW4CDjxlhubsLiGQZE",
	"YjB6wMoaLtoZa7fT4lsxJC/RQ46stlUIiNckBKdzmIVhXXvLemlpi8Ux8seH9LuhG2gr3o6ERo62p57z",
	"bJieG0bPCTF2RWnxjj3N0V1y5mAK2iz0Dq8BWIEVEjFdDZEOAtCB/QD7WwXByJ6/7g6at5YLpA4SyB/9",
	"Db2FYWnANSbNK4gCaxsXzMTbtgbszJFmIVCkI3eh5bTrpSSA6OQZHGTnFwp8pnaVeonA86w9+1U6y4ET",
	"ox1WqESnosBLnHQpSDXy9O0RVoEo+37LPWrEwA7ddu84ygIk0SSpCoza4WpFWojyrXvMaGfcXjDLDskR",
	"3fdxim4oZG0sdc5eQZgISo9NuaD1ep9hMkXGc3Auu1sdzA62xe7ODj0qaDK1WD4itIKC9LKML7gP0ht1",
	"YFYUWyfULOF6+19vhHrRdyvT3xl8/Xr4Zvfr6KUoUKqW17gSGmc38YUjHXZaVAp2km5YXZWgmBNZh41b",
	"slSUhOSDezrjOSgkhkCcFlLJRbUAQ6CZ6yxtR9ZoXdAFhFIJlgleqIAmYZeqUo3VW0g1hhGMgZ/Z33YG",
	"r8Lq8Vv6ecbzcS6KhAInX+wMdlZWo88mjf4mQ/adEDnKKG76/iKDgFhTsn/7B18yTufUDHtr+/xkyM5t",
	"O4jOxuQ7lhY6R+oGov63f/CKG8S1JlUpr0WdjX3FXg7IIH1e2vMwg6vqAHOc5/pmnUhcRHzCJTOjol8U",
	"0wnrUhzx1nCddtV3DCPtoeGV3QjwpLGFNiUAh2H8YGGmE9tLxmH450ApvhNl7/lM/kxX9Y2Qszmtrl0R",
	"h0qULdEIwWWmr0UxwXCFMDc5jXhAuNjA5eGX6pWzCnvZGXntJJYDJy4HPZJcIb4kLwSxjIYsE8kvIwV8",
	"O5Jf6OZxCDiXFPsPmlJBz8tIuhO8IMvN8+e1NB70mVECTriF7KXo7l7a0yHYv8+DlF4zxLJuWLU/enpA",
	"yzfybie9lZopXhT6Bs0JGsNhXmCaoeNiEBnu6d2A+Rq7wXOKPB+Qc3VVZlIUJjatrBQoXbWtOHyge40r",
	"m20fG1XDYPcQprFcaGE4ewNEXsfBat7+tMn322GsMIsOlSDAtdpUXAGEADFHaiJmXz3cmoJdWClyoVOe",
	"NXNBEcXEW0eaaTHljfZ56Zh0A0EjXsKJ5JTrHZ/nHZlW8AMj9frd3itKoW8OnkRyUGkGITMTbAaI34Sh",
	"Mk3IqnrKIZ2cg0bYUEtcrA87j8fuL5k46wXyoWR6639ciMXY3gUeBKEeZ/4Bs+EdMIVrPWFdBw22NWTH",
	"U4CQ6TnUPlxWyz3FQkNd32zJupURoLPrgpUCor226q5++ohdV6dOMZ7NdCHL+WK9aYp1MZ0w2Ka2Wo1T",
	"rLtqnNpasU6x7op1amvVPMW6q+apLZ/Ngrv7zKxmIIdNdmmOpEjYSZXmnjS9VaQIT7T8SimiV0rS/j+8",
	"XXtz2za2/yqYtHdW0hXlZ9KsOp27SuIkbmNb13bSvbPuWJAIS6wpgiUhP+rxd7+D8wDAh/xItvtXYpEE",
	"CeDg4OA8fr8Tv25IYEd5XuibZGlX4WWUKVlYnZzZXWoK4zP65fCwy3BDYPo0DOWqgF/V68EHzbN0bXY/",
	"yiK+loWK5GymUjo2xUlp4GZODAxyhE72D95B/UqxmrmT5c3rVxujg3dDMfryz21UP1/+Gb3c2sb9g2LF",
	"qFnoI0OgtUiMjg+G4nDv6BAePjnYE52TmUwpAc4UyY1H5ekK963glLIS8yYx/2sPR5nh9EN0zsermYpZ",
	"7i+0NnkBGVlZzEnavjD0UIsP489h8op2mea2tbfjz6RfYpWn+jZIfW4plntEM5CAtCgFN3sVvRAnS+w9",
	"2Javd+lnvPmrDX6ZppE1pNNlcH1V0NWFMflwYyO19tlCl2a4tbW7s9ti5Lv6l5iK3Vk/8edNhmKP/ltN",
	"u4SBZZvKSXAZKjuZ1hp1QzEZ8uJyP4lOFTiAP8AacRWsgS4FnlQaT4ZUtA6JvlOXBPvzydHhWJoFe+q5",
	"Aqd25JnAT4zPNqDdj3//fgCw4VN7ciCIHqOWeSqNmgzFR8hHmkprEdGvqFmwdigv9DI3gc2J4S/09PwJ",
	"w/olsd3eCLZfPA5DWMGnJSNqw4ZcxYnesMKhq/sHnBgYaLG2VdA+7iZwTOLVup23ONlZHEtIu7Jmi5eL",
	"qjS4Tf8IZFZ0MPx3AOfubnM5PSDoD4v5k4Sc5Xus81Uqyc9QDsXEN2fnGHzoEfQoYsye5c1UJvRbKou5",
	"cmdhAIref7Qrucpk0tYVAApyYxvtROUScIfoTpkn55eK/K7lZTQYDMKuHHAX2puZiM7Wy51Xcbffcgf2",
	"Q3R2Nn/YbrtDxjLa3Nx2bTiwFa3nqRIflB2yxzo+x7se7/jm5m5wagdEZirFPXuxvI3oJ+8rIbgWjhNE",
	"9pxcyHSrXcH+8Op1UPBVkW1cZCHkCh13cIl5VJ3RryfijYoLPbt8rNdTuq1NdCGuPTCJkVkgZNGV/3IE",
	"jXE9U7I00VbrrK9vzArt2qvb9upML1ShBvi7yuZpUi6iq53GJRikNMnmK5na64yr7Mdu3xXin2Wkv/nk",
	"MZOumMIBzYDOwkMGKC62ddoVn68jA3y5E6crRef0WkcnRs5Vl6tzsQ3vQHTOfJjSKvyUWSjyBeLJK7jY",
	"6nhav9X/9Vs5bNAcMHQj8JUNp6m8kq2bfpga1+vxXkTD2ZnAg5OuG9WyMawAn+P2lU6oWLsOAgZNAqrz",
	"xKWoYn4XijZZBr0e7huQWYRv79N/onyRgKxO5WXtCjyyM2GQY6ueEa0/N9GutvfB/yKzKqb+Tw0fSk+h",
	"bsOn4L/R9mAzukhluYjUTQ4P4e9bg5dWN9V+gTuprVFmFoXOMSV6MkulPXXsRC+jUmeZMtH25vbu1uY2",
	"rkm+qvNVCVc2t7f/PmE8ZVAqzAaAjQ7WNxhdbQ833T51iB61YNl2KB2IlxCgt5NLnEE/YkyVaVWU37JK",
	"tja3n7FMKpvIU7eRxzaShvzjpP+tbAYIrBbDkcAwDxb5snsI9Zqr0ZauQrWijhzquJP4AxUnkmq0PZoS",
	"KsNgwEmV9sO6P5kJl9YsoC4MTDw21a7lrfe37C8x1RNESJbq1a7AQEssOpAi9Pl4vwtCZf8aQm82fs/V",
	"/Mcp3N3HVHT8A0/tnHpIN+fZ0++9VtP8gZvxMz8ff8JsQrLlEDURCSMALnGH/kN5Zk7IR3ZrEZjEKb6w",
	"VfyVDRLCkw8sYhzWdqPtJMhY22cvxpTgOV5oo33Ohn3QQR60DXTy5c3R8fXmLx/mejQajQ5PPi/2Ps9H",
	"NZMP8djocBG9gfPrGM4VIESIUpD8iQ79KtjGTGdXCmSPcYHIOe0lHsWv5Rjzb9oU18WZuGaf3lYZyKG4",
	"u4Phvb8/O8vecvKBuLvjRAS48M63Z68Fzd/fuxf8uzfl6gbK0yJOILnRp5vCgdNKYHNk7Xg7OpSFu/x7",
	"Cbwy81USqw0qdiTEACht5GlpKcefSaiDxuzkoCobcY0oWDP0aA7cuj3o3phq64WaKbtvAPJEpeBdlugY",
	"vjGhywR7Sh2f3N057LT7+8lQ7GMVHnrYIPeSbvsuIXjX+/vBYHB3t5FcwANvOUdFpiLV82TG9yPcQlHI",
	"W37C/oIvMWjzwdWSH1hlqdXaLumFH8Pf6euuVAGFce6l9PQ/QAnf31sVcXf3j0t16/5/kRSlcX+lEv4Y",
	"ik9a5wg6xzkYvd6bVZKaKMnER5XmquB8+62B6PXKWbGafjTLtNcTkSD6QBTgjdLcQjbHvCT8M1PImcGy",
	"cQKALvQSgMtAZCeTiZcj+OXuzrUvFmaZnpNT4/6eH4B/+cWlmKBuxg8g3YyxLrpgP4l/B8B9fB5o1zJ1",
	"nUJaCpagTaGaWKUIpiI6eV/EyVVfLLaixau+SJO+UGaGeevCJ33kqUyoe5iUVigoBYxFoWTsiGAgFtXr",
	"qT9g4PY48OzzqjlLmqe0XDtGVgg76g9myjl7gcXqZy+69/cj+C8JZu1+Kw/WMMeCObidcT5BpsOnSFXs",
	"2G+GjRs++4PKfkmMiLUhDxHu6Whz2OUHVEWNiMzanuDjqyL9CXaZd9LIz8f77sP9ZbNIygHcc74q0pYb",
	"0J9iVRPxG4FWgicGv+dzzPFqPAP7KVe+cGY3PpRn6x6qJ403X0KDJ4QITw6fjz8hlChVsIAUoc0BEKhV",
	"m4dNHpfBsc7sGQwGE5ZJZzeIjcBwEJH4VU3t+8t60pTDD7zNFWc+YGWI8OnxbfnwwvaeVxPZJSISJzsR",
	"SLQBAEVOuu8QcA/dWB/wS3WLgN8wYB6/9C193Ni5E/249XpoLwIQqb7OUi0BdrpQJfjNO8kFlSV0+1V7",
	"wg2sa2n87n2Ju8mNYa2FBYigNLGcpFBZDIk1kjwE7nGrz+zjx7DcUzrE+3bQVDnQfyZpKukupxRQRojm",
	"Dnpc6NTJB/cMd8+80HaCsLKLZ44p8jg/xdo/qOIIcH2hSyOuF4lRaVIaujgukiu79+yPUe3B5u4QT05O",
	"jt8LaYycXZYsWvwpCE0IKUBlsElvbW4evGnca5Kl0qvKjTubrkmYwcCF3mh0e3P3dX7TRwY8mlkWlBOl",
	"hqKdnW2j4tv9jkcoimbk4d8FTQwL7VTrDDUy/OmIk06Pjg4dAtapvlRZdFQkmJ1J4LWHBFHUXave/CsE",
	"KDBEjXRKpf2ySFU2N4sDWVyq4ieEqbbbemZ+2n3s0VjBGKrip7MXZ2emVSFBz94TcIRPBuz1djajV5v/",
	"hUjpGMHCcBLtUbh6fj45OmQJe6sRuIfCFIS+OMQYZQ1egIUSYAWwhwiUAsUCdmf+13c7vw2FTPoU3V+m",
	"vNmfyin4wWk6bOurLPEoDo73g99yVAmfffp0IHJZlOT5E0IcOfcZqq9wxCeiM9U67Q4Br/U7gckygEYB",
	"344Y44GQmmKlnP7FiZoAUHl3CB5HohIUZS5nsMy8eLvH3LxNRAdzzrscG6JDukZkdkNDgTYjxNLFhOZ6",
	"wneUvEb4ZKhXJl+ZYcWGwlC52K+RVXLQ2NU3CuTnGYqfZabEO416r33CGrLm4AmDHQ/k76RCV+nWcUBU",
	"abTOIpxx+D89/UGLfdsnR9HY+rBM80tVXibZxlzjw2fZr87vwYe3PsaEMBaHZr5IAHUudm4UKFQ2CGGW",
	"FMEhOykFo3SpeFDBoN5D1W9HFLZbjucxGSK/0dEG+yhWPfSHmMXYXDYnuHo0o4kFx4N1u1XwzBNwcNR1",
	"wcS2M2/1SLruMLr+HFo7g7qukpS6MKvzUQDivs4JNcfhNE2wcoJCm8KR/BCYOGwWeaFylcWlmHw/mHAM",
	"lsqXmQXp+0FL7BTIF/I0mSUmmDe6Hyh9/rX52wCD5hOn0JIgsmBn2G/+KFVcXS6pomTAyNUUkCXbHxH7",
	"oXjO5QNhracrEKtS9XjWzUpsm0fUFUoloAbAvtljF8pXiogbqr/cUXGojRqGUXe75vQyMZhgT9iS0zpk",
	"P6zpwKHPYYGd17s+Rha4l2GJMmYmu3W+1oH0w6vXrR4i5xj6Jo/PV/uXmzHGZ8ZpHnpzPZ6wJhl77PcZ",
	"DHaIE2VW+de75l/uvGqKJ9HePF02w4D3c0LejaD393dH473D0f75aLx//sve/923jkMrjH2vR7nN3ha+",
	"TkqVAvzYR8RMd5dKl6OJ5QKzWygMcADidOjaoCw4wFgntzrwvjqXWQtlWpiPW9M0IsmMBt7UJJtfrFLK",
	"ESkDOi9cTyWmbN8y/Jq51lFp4BjoRU38t8uQ6Qag+3As6hO2FT1F7CGok4lRF0+jV6V4m+oVAL1R4gaQ",
	"UNjtQud2U9zI7TlndtsXM3tjkBFCaSokkRvlTDK6GpldoYECdfAMoE+b97ULy8bEhoqAXBec0SOvdBKL",
	"64VOlS8AqQB7+qIdtGdsO6OQB+DE5fadQl0O3lbhCthoEplV6QOGuNtuDcQ7rKAMcf2auPjgCWgFXX0Q",
	"tpmG8q8HbuZ0tb+AKbSV8WId3eQToJm3mTopTOm3hkLr8AalsgGgvE/TrQzsukTf9R+zw2UCdnskwg0i",
	"Smv7mvYyYfqsoMIy82wjw1TmLSoPDN42/gWQNke3kjWpGLxJR2wrFCpwVGHdswwRkRDgyjE/JFm+Ar+/",
	"NRORbXdgT7xMfd4HlOX87IV7Ev42OkdBSGVutwB093KppnJMDO8IrgOYphcyz1VWojq41SuHhljgA//D",
	"ACvoHCj5d0R1RZR3QFYTKiuS2cKusH4dpo4wJIJKdEaF9DQLA/FRFepv9kukQTjUXM0Mfph/KaImiQ6x",
	"PLDyytQ1peABsggBg1b8KF0XqR3xU4fqmrLsjRZ7DN15ikiVLkWvpefV7q0bB6+67FHcdreyfKbW1sjG",
	"RyenYgNrMTfu4F8I42zQSG3cwX/gtyeYGBWTYTAYNNf0nvs+N/mV7lBMyQ1HNbSJvUOOrOoEMqJqgB7s",
	"b/agqnXE4iDXcg1iMdTBIm86cotg2MDu5sT2nxd6XqiydKrioHahOuSAVPTUEaeh+6T1pZBGTAAE7Ry/",
	"gTh5/IDy+wB3Gu70ReRFoQsMSzLT4wjkxc+Hy01orZqqvglqqPr1xQlM/SWiOgN085CzjE1xW8eXfi+T",
	"VMVBo+2kKKZIWHOpm1xndqOXKUy8vrh4YDo9eGJtQhkJHNtGVF3fM3tASzJXRmUWKiScB8jF5EKUeqlg",
	"ELCDHk4auhUALrZITmfSlID67N9P0K6DESWnGaITM6M+o1HDqJSqPjmrQglI3gqGuo5jHKJVXSWyvs9C",
	"EIB1GHmOe723ernUGXdTnMxUJotEV6Kc7pAMuEOfM3klkxRBHskPFQw4TUNt4rEGUhVXyUwxMmHp/OO1",
	"fvB+1+HkHJ+91G2tiqKGwItgV8E5+EiGoTASJZYH7QyWRQfEn9FDwzJDuNB14cpjK3OAvAzxfPbiuhAN",
	"STEVBJri1rmGkRqKnMKQ5Mw2urONIfqNTn923Bb+HGNH/o+VNmSqNtO6XXwScvFQQQBFJDBNoBXQD8MV",
	"XdeBTwE4elCPj5jd2ZUqTTKXQSTsmKa4NDqnaPFS3ghp7GnK1KeVZhU3accGCtNa0VW93nuZpnYIuc71",
	"loTwPRT5JCBLsOQhCNR3eKa+ZpTxiOl5O7gXMkX1An80BOd6rYaEuW91Hj6OGkPlQEYVy0cwYyp3uuKz",
	"Yq7OuRNk2VIXqzlFp4ukdJrRATKk1/K2ZHwXrgJmVRekTFv9vPKr2W0uDgodrZkG1PypJiBHUiz14gF7",
	"uip0jo5i3vjRWBGTd3uf9k73HtWXsOKOFVFyO9h1fNVQTFoMnbZGdgaB6QHBrLKxJUVsWBAJuzb2yBcQ",
	"2bKV2akWQXbZhqugvGtm4mJm3fBtZxkDoFFROBw+cTAJ+UDGaiBq+dgdV8jWpUVTxx9uGsCeQAwgvt5g",
	"ytiB/F0XgfnOywuqCmCESmXKPgODUaKZt1WHT7E18WG3XPBPl82JbUbUZkREOmtKBCBCvryl0Dgh2TkU",
	"yEaC3YdC5lSJStXmwOp7evoJUkXhqh9UYILlUQXNBFC1ic7KRZKjp5TRMUwh7ZblwWIG4lNyGYD29AU0",
	"Bwe38izjVNxWujk28XNVINc2sk2Ey8iT5PouiaMru4Oq62ZnELsNwzTWCrMf4WqRg2+EfjIKT0KotARw",
	"lsUEkGu/JFOEV4cQiq4NYHjBsXAO+Gihc86AiALUqnA0EYLPHjSCtLO570M7s407mPBUtVXv6lki03O4",
	"oy4Q37n5f4hCL5gje3fIKKGK8COfTqn3pC8v1ExlBglEGML6YVaxR8nn9mDin0k85/RVhYHuW4nj5AwX",
	"g1gAlrzHfr9UVQ6grl1cmHQBWtF2SZbMIR2S0KFYNwnoGouzfkR8iHmOGn0m65yTq6uywkCJMxP+0uuJ",
	"jvF8F11EYnJ2OJjqNaoTZymRyzCgY3mUEKNJHOgLGSeOXIskiHthvxHV8XO+MVwZqLzCL0W6e03jC58p",
	"jQeTCx52nw3i0pRG0SESqSQTIDeI4xyJd4wdErZG9UvAsOrARUSFSu0ByjU3rwBI4FCvm7xrQpbeWD49",
	"/fSf4GF7kHQNNoTy6/Uopk2eP4ECdKuiZ0/t4hX4NMK4cxM/0txX1BHxtAHBNTzEOFNAH2AHc0S/ivdK",
	"xV/fn2/Rrh4LyEpAKksDtHf2q6GHYaM/Cp3asx3pkTaKtQaJ3LECVOoMGQC/YdJMoWDbPg+27MfIW+tT",
	"x224JLqgrR9FoS4KVS4EwHfbTTwl5CedxpX55UkMz8jfII15cm7H8LlyaM/J8Bzs3XayHpJC8AmkSYwA",
	"elmsr4NjeJLNn8qG57QG75RV7eEBDBjmtkV71Dj1iK+O9nVA7ASOO1SSld20rG6nBKLgmq8T6DmOTdtu",
	"Z6sLIwWtEk9IoSDHsmoOPIlXD1rxAN7PJ8er2l8hLx+Dhnt6vMauv54ij4zy59PjwfQxeVV90tbz5a1n",
	"xUM8DPRf0o3rGPBQbO3kgMHSbSe7c6LXzngX8C4inHxV6NqY71RdmH/XU95az+1J/NyY9Ked5xLgYXeQ",
	"/G5r+wfPfvf67w3yu5e7O9vO0D0gzyhYiSquG+Ww8Z7axysLPRZlYlcrsZ5M1cxOJdUG2HmzSp176PQK",
	"SlBmP/2qrHy689rW2fjCE+ZaEr76SScSbxH+HTwQsB4RHC53yKnKEXq7WI+38ImLKCivQNMZ3RHUFC7x",
	"cSozIWczIImZE3FDQOrQQFFpoeMDd07wVez5YU9ekw1vlKbuFDrTS5D/pcycr28d3d5Db1pDvOccPKp9",
	"aB6gzBu7A3iDhQ7OL6GFa48xiSmFvs5geinDnEgC4jnz2XmuPsr5aLNrRcd+oluM/hmq6jrU4BxQzj4f",
	"BiMKjGfhp5ULWSi/3YS2LpEewG0sUjVWwLcysx+zBIlGVZK1Su4DNIOY8U9yfHg6BiFzAJ4h034r1yC5",
	"qhrJQNa6parcEBWtYtaXT04gcCJ4XvFMrM0m8OYJZRK4VCeyLdl+fUIL/eDyGuOz/gqZWrE4Z7rxb3vF",
	"1mJ9PoQ9ULj8pupJqhrI9+Me+kh0msySxsxAVondeytjPagE2Jz+TfWcPRi/AqI2kMsk80WoegMWJ3oO",
	"FE0MNkso8yK5cC0zk4sUU21MqjI1u6TDLYZkyoUugHKtxlSJ/bEzENmTf8LHG4a9RIO+dMW4XqNSR76o",
	"wq6nuktpSnaHy7bAzASPwQWN8teEMJOgAgtFebsIDFDZmSKxB6GAFn8IoVrW9+IC07pDuEaY+YcJMVGb",
	"PIEQ83G4Rnamo6scndwsfAiymMzaol122lZpLPbtlFQhG8kjD9X9tlWM+YI7yN74VmZEs8ky7t1kxC/m",
	"fE+tgI1HIZsJMpsZjck1fhQ/l6poGTn4+alNWnWV4EnaNzx2P7Y0H1y8/81eNnL+odCr3M7GHTdBUf7x",
	"apomQCXzov/CyDnM2Bw3tXMgAFDxi/4L0tRViWhhTW0yqLQAfzaEC8Y3GLNAqmpfRiMadPG3+9/u/z8A",
	"AP//uoX+H9x7AwA=",
}

// GetSwagger returns the content of the embedded swagger specification file
// or error if failed to decode
func decodeSpec() ([]byte, error) {
	zipped, err := base64.StdEncoding.DecodeString(strings.Join(swaggerSpec, ""))
	if err != nil {
		return nil, fmt.Errorf("error base64 decoding spec: %w", err)
	}
	zr, err := gzip.NewReader(bytes.NewReader(zipped))
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}
	var buf bytes.Buffer
	_, err = buf.ReadFrom(zr)
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}

	return buf.Bytes(), nil
}

var rawSpec = decodeSpecCached()

// a naive cached of a decoded swagger spec
func decodeSpecCached() func() ([]byte, error) {
	data, err := decodeSpec()
	return func() ([]byte, error) {
		return data, err
	}
}

// Constructs a synthetic filesystem for resolving external references when loading openapi specifications.
func PathToRawSpec(pathToFile string) map[string]func() ([]byte, error) {
	res := make(map[string]func() ([]byte, error))
	if len(pathToFile) > 0 {
		res[pathToFile] = rawSpec
	}

	return res
}

// GetSwagger returns the Swagger specification corresponding to the generated code
// in this file. The external references of Swagger specification are resolved.
// The logic of resolving external references is tightly connected to "import-mapping" feature.
// Externally referenced files must be embedded in the corresponding golang packages.
// Urls can be supported but this task was out of the scope.
func GetSwagger() (swagger *openapi3.T, err error) {
	resolvePath := PathToRawSpec("")

	loader := openapi3.NewLoader()
	loader.IsExternalRefsAllowed = true
	loader.ReadFromURIFunc = func(loader *openapi3.Loader, url *url.URL) ([]byte, error) {
		pathToFile := url.String()
		pathToFile = path.Clean(pathToFile)
		getSpec, ok := resolvePath[pathToFile]
		if !ok {
			err1 := fmt.Errorf("path not found: %s", pathToFile)
			return nil, err1
		}
		return getSpec()
	}
	var specData []byte
	specData, err = rawSpec()
	if err != nil {
		return
	}
	swagger, err = loader.LoadFromData(specData)
	if err != nil {
		return
	}
	return
}
