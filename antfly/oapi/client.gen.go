// Package oapi provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/oapi-codegen/oapi-codegen/v2 version v2.5.1 DO NOT EDIT.
package oapi

import (
	"bytes"
	"compress/gzip"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"path"
	"strings"
	"time"

	"github.com/getkin/kin-openapi/openapi3"
	"github.com/oapi-codegen/runtime"
)

const (
	BasicAuthScopes = "BasicAuth.Scopes"
)

// Defines values for AggregationType.
const (
	AggregationTypeAvg              AggregationType = "avg"
	AggregationTypeCardinality      AggregationType = "cardinality"
	AggregationTypeCount            AggregationType = "count"
	AggregationTypeDateHistogram    AggregationType = "date_histogram"
	AggregationTypeDateRange        AggregationType = "date_range"
	AggregationTypeGeoDistance      AggregationType = "geo_distance"
	AggregationTypeGeohashGrid      AggregationType = "geohash_grid"
	AggregationTypeHistogram        AggregationType = "histogram"
	AggregationTypeMax              AggregationType = "max"
	AggregationTypeMin              AggregationType = "min"
	AggregationTypeRange            AggregationType = "range"
	AggregationTypeSignificantTerms AggregationType = "significant_terms"
	AggregationTypeStats            AggregationType = "stats"
	AggregationTypeSum              AggregationType = "sum"
	AggregationTypeSumsquares       AggregationType = "sumsquares"
	AggregationTypeTerms            AggregationType = "terms"
)

// Defines values for AntflyType.
const (
	AntflyTypeBlob            AntflyType = "blob"
	AntflyTypeBoolean         AntflyType = "boolean"
	AntflyTypeDatetime        AntflyType = "datetime"
	AntflyTypeEmbedding       AntflyType = "embedding"
	AntflyTypeGeopoint        AntflyType = "geopoint"
	AntflyTypeGeoshape        AntflyType = "geoshape"
	AntflyTypeHtml            AntflyType = "html"
	AntflyTypeKeyword         AntflyType = "keyword"
	AntflyTypeLink            AntflyType = "link"
	AntflyTypeNumeric         AntflyType = "numeric"
	AntflyTypeSearchAsYouType AntflyType = "search_as_you_type"
	AntflyTypeText            AntflyType = "text"
)

// Defines values for BingSearchConfigFreshness.
const (
	BingSearchConfigFreshnessDay   BingSearchConfigFreshness = "Day"
	BingSearchConfigFreshnessMonth BingSearchConfigFreshness = "Month"
	BingSearchConfigFreshnessWeek  BingSearchConfigFreshness = "Week"
)

// Defines values for BraveSearchConfigFreshness.
const (
	BraveSearchConfigFreshnessPd BraveSearchConfigFreshness = "pd"
	BraveSearchConfigFreshnessPm BraveSearchConfigFreshness = "pm"
	BraveSearchConfigFreshnessPw BraveSearchConfigFreshness = "pw"
	BraveSearchConfigFreshnessPy BraveSearchConfigFreshness = "py"
)

// Defines values for CalendarInterval.
const (
	CalendarIntervalDay     CalendarInterval = "day"
	CalendarIntervalHour    CalendarInterval = "hour"
	CalendarIntervalMinute  CalendarInterval = "minute"
	CalendarIntervalMonth   CalendarInterval = "month"
	CalendarIntervalQuarter CalendarInterval = "quarter"
	CalendarIntervalWeek    CalendarInterval = "week"
	CalendarIntervalYear    CalendarInterval = "year"
)

// Defines values for ChainCondition.
const (
	ChainConditionAlways      ChainCondition = "always"
	ChainConditionOnError     ChainCondition = "on_error"
	ChainConditionOnRateLimit ChainCondition = "on_rate_limit"
	ChainConditionOnTimeout   ChainCondition = "on_timeout"
)

// Defines values for ChatMessageRole.
const (
	ChatMessageRoleAssistant ChatMessageRole = "assistant"
	ChatMessageRoleSystem    ChatMessageRole = "system"
	ChatMessageRoleTool      ChatMessageRole = "tool"
	ChatMessageRoleUser      ChatMessageRole = "user"
)

// Defines values for ChatToolName.
const (
	ChatToolNameAddFilter        ChatToolName = "add_filter"
	ChatToolNameAskClarification ChatToolName = "ask_clarification"
	ChatToolNameFetch            ChatToolName = "fetch"
	ChatToolNameSearch           ChatToolName = "search"
	ChatToolNameWebsearch        ChatToolName = "websearch"
)

// Defines values for ChunkerProvider.
const (
	ChunkerProviderAntfly  ChunkerProvider = "antfly"
	ChunkerProviderMock    ChunkerProvider = "mock"
	ChunkerProviderTermite ChunkerProvider = "termite"
)

// Defines values for ClusterBackupResponseStatus.
const (
	ClusterBackupResponseStatusCompleted ClusterBackupResponseStatus = "completed"
	ClusterBackupResponseStatusFailed    ClusterBackupResponseStatus = "failed"
	ClusterBackupResponseStatusPartial   ClusterBackupResponseStatus = "partial"
)

// Defines values for ClusterHealth.
const (
	ClusterHealthDegraded  ClusterHealth = "degraded"
	ClusterHealthError     ClusterHealth = "error"
	ClusterHealthHealthy   ClusterHealth = "healthy"
	ClusterHealthUnhealthy ClusterHealth = "unhealthy"
	ClusterHealthUnknown   ClusterHealth = "unknown"
)

// Defines values for ClusterRestoreRequestRestoreMode.
const (
	ClusterRestoreRequestRestoreModeFailIfExists ClusterRestoreRequestRestoreMode = "fail_if_exists"
	ClusterRestoreRequestRestoreModeOverwrite    ClusterRestoreRequestRestoreMode = "overwrite"
	ClusterRestoreRequestRestoreModeSkipIfExists ClusterRestoreRequestRestoreMode = "skip_if_exists"
)

// Defines values for ClusterRestoreResponseStatus.
const (
	ClusterRestoreResponseStatusFailed    ClusterRestoreResponseStatus = "failed"
	ClusterRestoreResponseStatusPartial   ClusterRestoreResponseStatus = "partial"
	ClusterRestoreResponseStatusTriggered ClusterRestoreResponseStatus = "triggered"
)

// Defines values for CohereEmbedderConfigInputType.
const (
	CohereEmbedderConfigInputTypeClassification CohereEmbedderConfigInputType = "classification"
	CohereEmbedderConfigInputTypeClustering     CohereEmbedderConfigInputType = "clustering"
	CohereEmbedderConfigInputTypeSearchDocument CohereEmbedderConfigInputType = "search_document"
	CohereEmbedderConfigInputTypeSearchQuery    CohereEmbedderConfigInputType = "search_query"
)

// Defines values for CohereEmbedderConfigTruncate.
const (
	CohereEmbedderConfigTruncateEND   CohereEmbedderConfigTruncate = "END"
	CohereEmbedderConfigTruncateNONE  CohereEmbedderConfigTruncate = "NONE"
	CohereEmbedderConfigTruncateSTART CohereEmbedderConfigTruncate = "START"
)

// Defines values for DistanceUnit.
const (
	DistanceUnitFt DistanceUnit = "ft"
	DistanceUnitKm DistanceUnit = "km"
	DistanceUnitM  DistanceUnit = "m"
	DistanceUnitMi DistanceUnit = "mi"
	DistanceUnitYd DistanceUnit = "yd"
)

// Defines values for DynamicTemplateMatchMappingType.
const (
	DynamicTemplateMatchMappingTypeBoolean DynamicTemplateMatchMappingType = "boolean"
	DynamicTemplateMatchMappingTypeDate    DynamicTemplateMatchMappingType = "date"
	DynamicTemplateMatchMappingTypeNumber  DynamicTemplateMatchMappingType = "number"
	DynamicTemplateMatchMappingTypeObject  DynamicTemplateMatchMappingType = "object"
	DynamicTemplateMatchMappingTypeString  DynamicTemplateMatchMappingType = "string"
)

// Defines values for EdgeDirection.
const (
	EdgeDirectionBoth EdgeDirection = "both"
	EdgeDirectionIn   EdgeDirection = "in"
	EdgeDirectionOut  EdgeDirection = "out"
)

// Defines values for EmbedderProvider.
const (
	EmbedderProviderBedrock    EmbedderProvider = "bedrock"
	EmbedderProviderCohere     EmbedderProvider = "cohere"
	EmbedderProviderGemini     EmbedderProvider = "gemini"
	EmbedderProviderMock       EmbedderProvider = "mock"
	EmbedderProviderOllama     EmbedderProvider = "ollama"
	EmbedderProviderOpenai     EmbedderProvider = "openai"
	EmbedderProviderOpenrouter EmbedderProvider = "openrouter"
	EmbedderProviderTermite    EmbedderProvider = "termite"
	EmbedderProviderVertex     EmbedderProvider = "vertex"
)

// Defines values for EvaluatorName.
const (
	EvaluatorNameCitationQuality EvaluatorName = "citation_quality"
	EvaluatorNameCoherence       EvaluatorName = "coherence"
	EvaluatorNameCompleteness    EvaluatorName = "completeness"
	EvaluatorNameCorrectness     EvaluatorName = "correctness"
	EvaluatorNameFaithfulness    EvaluatorName = "faithfulness"
	EvaluatorNameHelpfulness     EvaluatorName = "helpfulness"
	EvaluatorNameMap             EvaluatorName = "map"
	EvaluatorNameMrr             EvaluatorName = "mrr"
	EvaluatorNameNdcg            EvaluatorName = "ndcg"
	EvaluatorNamePrecision       EvaluatorName = "precision"
	EvaluatorNameRecall          EvaluatorName = "recall"
	EvaluatorNameRelevance       EvaluatorName = "relevance"
	EvaluatorNameSafety          EvaluatorName = "safety"
)

// Defines values for FailedOperationOperation.
const (
	FailedOperationOperationDelete FailedOperationOperation = "delete"
	FailedOperationOperationUpsert FailedOperationOperation = "upsert"
)

// Defines values for FilterSpecOperator.
const (
	FilterSpecOperatorContains FilterSpecOperator = "contains"
	FilterSpecOperatorEq       FilterSpecOperator = "eq"
	FilterSpecOperatorGt       FilterSpecOperator = "gt"
	FilterSpecOperatorGte      FilterSpecOperator = "gte"
	FilterSpecOperatorIn       FilterSpecOperator = "in"
	FilterSpecOperatorLt       FilterSpecOperator = "lt"
	FilterSpecOperatorLte      FilterSpecOperator = "lte"
	FilterSpecOperatorNe       FilterSpecOperator = "ne"
	FilterSpecOperatorPrefix   FilterSpecOperator = "prefix"
	FilterSpecOperatorRange    FilterSpecOperator = "range"
)

// Defines values for Fuzziness1.
const (
	Fuzziness1Auto Fuzziness1 = "auto"
)

// Defines values for GeneratorProvider.
const (
	GeneratorProviderAnthropic  GeneratorProvider = "anthropic"
	GeneratorProviderBedrock    GeneratorProvider = "bedrock"
	GeneratorProviderCohere     GeneratorProvider = "cohere"
	GeneratorProviderGemini     GeneratorProvider = "gemini"
	GeneratorProviderMock       GeneratorProvider = "mock"
	GeneratorProviderOllama     GeneratorProvider = "ollama"
	GeneratorProviderOpenai     GeneratorProvider = "openai"
	GeneratorProviderOpenrouter GeneratorProvider = "openrouter"
	GeneratorProviderTermite    GeneratorProvider = "termite"
	GeneratorProviderVertex     GeneratorProvider = "vertex"
)

// Defines values for GeoShapeGeometryRelation.
const (
	GeoShapeGeometryRelationContains   GeoShapeGeometryRelation = "contains"
	GeoShapeGeometryRelationIntersects GeoShapeGeometryRelation = "intersects"
	GeoShapeGeometryRelationWithin     GeoShapeGeometryRelation = "within"
)

// Defines values for GoogleSearchConfigSearchType.
const (
	GoogleSearchConfigSearchTypeImage GoogleSearchConfigSearchType = "image"
	GoogleSearchConfigSearchTypeWeb   GoogleSearchConfigSearchType = "web"
)

// Defines values for GraphQueryType.
const (
	GraphQueryTypeKShortestPaths GraphQueryType = "k_shortest_paths"
	GraphQueryTypeNeighbors      GraphQueryType = "neighbors"
	GraphQueryTypePattern        GraphQueryType = "pattern"
	GraphQueryTypeShortestPath   GraphQueryType = "shortest_path"
	GraphQueryTypeTraverse       GraphQueryType = "traverse"
)

// Defines values for IndexType.
const (
	IndexTypeAknnV0     IndexType = "aknn_v0"
	IndexTypeFullTextV0 IndexType = "full_text_v0"
	IndexTypeGraphV0    IndexType = "graph_v0"
)

// Defines values for JoinOperator.
const (
	JoinOperatorEq  JoinOperator = "eq"
	JoinOperatorGt  JoinOperator = "gt"
	JoinOperatorGte JoinOperator = "gte"
	JoinOperatorLt  JoinOperator = "lt"
	JoinOperatorLte JoinOperator = "lte"
	JoinOperatorNeq JoinOperator = "neq"
)

// Defines values for JoinStrategy.
const (
	JoinStrategyBroadcast   JoinStrategy = "broadcast"
	JoinStrategyIndexLookup JoinStrategy = "index_lookup"
	JoinStrategyShuffle     JoinStrategy = "shuffle"
)

// Defines values for JoinType.
const (
	JoinTypeInner JoinType = "inner"
	JoinTypeLeft  JoinType = "left"
	JoinTypeRight JoinType = "right"
)

// Defines values for LinearMergePageStatus.
const (
	LinearMergePageStatusError   LinearMergePageStatus = "error"
	LinearMergePageStatusPartial LinearMergePageStatus = "partial"
	LinearMergePageStatusSuccess LinearMergePageStatus = "success"
)

// Defines values for MatchQueryOperator.
const (
	MatchQueryOperatorAnd MatchQueryOperator = "and"
	MatchQueryOperatorOr  MatchQueryOperator = "or"
)

// Defines values for MergeStrategy.
const (
	MergeStrategyFailover MergeStrategy = "failover"
	MergeStrategyRrf      MergeStrategy = "rrf"
	MergeStrategyRsf      MergeStrategy = "rsf"
)

// Defines values for PathFindWeightMode.
const (
	PathFindWeightModeMaxWeight PathFindWeightMode = "max_weight"
	PathFindWeightModeMinHops   PathFindWeightMode = "min_hops"
	PathFindWeightModeMinWeight PathFindWeightMode = "min_weight"
)

// Defines values for PathWeightMode.
const (
	PathWeightModeMaxWeight PathWeightMode = "max_weight"
	PathWeightModeMinHops   PathWeightMode = "min_hops"
	PathWeightModeMinWeight PathWeightMode = "min_weight"
)

// Defines values for PermissionType.
const (
	PermissionTypeAdmin PermissionType = "admin"
	PermissionTypeRead  PermissionType = "read"
	PermissionTypeWrite PermissionType = "write"
)

// Defines values for QueryRequestExpandStrategy.
const (
	QueryRequestExpandStrategyIntersection QueryRequestExpandStrategy = "intersection"
	QueryRequestExpandStrategyUnion        QueryRequestExpandStrategy = "union"
)

// Defines values for QueryStrategy.
const (
	QueryStrategyDecompose QueryStrategy = "decompose"
	QueryStrategyHyde      QueryStrategy = "hyde"
	QueryStrategySimple    QueryStrategy = "simple"
	QueryStrategyStepBack  QueryStrategy = "step_back"
)

// Defines values for RerankerProvider.
const (
	RerankerProviderCohere  RerankerProvider = "cohere"
	RerankerProviderOllama  RerankerProvider = "ollama"
	RerankerProviderTermite RerankerProvider = "termite"
	RerankerProviderVertex  RerankerProvider = "vertex"
)

// Defines values for ResourceType.
const (
	ResourceTypeAsterisk ResourceType = "*"
	ResourceTypeTable    ResourceType = "table"
	ResourceTypeUser     ResourceType = "user"
)

// Defines values for RouteType.
const (
	RouteTypeQuestion RouteType = "question"
	RouteTypeSearch   RouteType = "search"
)

// Defines values for SemanticQueryMode.
const (
	SemanticQueryModeHypothetical SemanticQueryMode = "hypothetical"
	SemanticQueryModeRewrite      SemanticQueryMode = "rewrite"
)

// Defines values for SerperSearchConfigSearchType.
const (
	SerperSearchConfigSearchTypeImages   SerperSearchConfigSearchType = "images"
	SerperSearchConfigSearchTypeNews     SerperSearchConfigSearchType = "news"
	SerperSearchConfigSearchTypePlaces   SerperSearchConfigSearchType = "places"
	SerperSearchConfigSearchTypeSearch   SerperSearchConfigSearchType = "search"
	SerperSearchConfigSearchTypeShopping SerperSearchConfigSearchType = "shopping"
)

// Defines values for SerperSearchConfigTimePeriod.
const (
	SerperSearchConfigTimePeriodD SerperSearchConfigTimePeriod = "d"
	SerperSearchConfigTimePeriodM SerperSearchConfigTimePeriod = "m"
	SerperSearchConfigTimePeriodW SerperSearchConfigTimePeriod = "w"
	SerperSearchConfigTimePeriodY SerperSearchConfigTimePeriod = "y"
)

// Defines values for SignificanceAlgorithm.
const (
	SignificanceAlgorithmChiSquared        SignificanceAlgorithm = "chi_squared"
	SignificanceAlgorithmJlh               SignificanceAlgorithm = "jlh"
	SignificanceAlgorithmMutualInformation SignificanceAlgorithm = "mutual_information"
	SignificanceAlgorithmPercentage        SignificanceAlgorithm = "percentage"
)

// Defines values for SyncLevel.
const (
	SyncLevelAknn        SyncLevel = "aknn"
	SyncLevelEnrichments SyncLevel = "enrichments"
	SyncLevelFullText    SyncLevel = "full_text"
	SyncLevelPropose     SyncLevel = "propose"
	SyncLevelWrite       SyncLevel = "write"
)

// Defines values for TableBackupStatusStatus.
const (
	TableBackupStatusStatusCompleted TableBackupStatusStatus = "completed"
	TableBackupStatusStatusFailed    TableBackupStatusStatus = "failed"
	TableBackupStatusStatusSkipped   TableBackupStatusStatus = "skipped"
)

// Defines values for TableRestoreStatusStatus.
const (
	TableRestoreStatusStatusFailed    TableRestoreStatusStatus = "failed"
	TableRestoreStatusStatusSkipped   TableRestoreStatusStatus = "skipped"
	TableRestoreStatusStatusTriggered TableRestoreStatusStatus = "triggered"
)

// Defines values for TavilySearchConfigSearchDepth.
const (
	TavilySearchConfigSearchDepthAdvanced TavilySearchConfigSearchDepth = "advanced"
	TavilySearchConfigSearchDepthBasic    TavilySearchConfigSearchDepth = "basic"
)

// Defines values for TransformOpType.
const (
	TransformOpTypeAddToSet    TransformOpType = "$addToSet"
	TransformOpTypeCurrentDate TransformOpType = "$currentDate"
	TransformOpTypeInc         TransformOpType = "$inc"
	TransformOpTypeMax         TransformOpType = "$max"
	TransformOpTypeMin         TransformOpType = "$min"
	TransformOpTypeMul         TransformOpType = "$mul"
	TransformOpTypePop         TransformOpType = "$pop"
	TransformOpTypePull        TransformOpType = "$pull"
	TransformOpTypePush        TransformOpType = "$push"
	TransformOpTypeRename      TransformOpType = "$rename"
	TransformOpTypeSet         TransformOpType = "$set"
	TransformOpTypeUnset       TransformOpType = "$unset"
)

// Defines values for WebSearchProvider.
const (
	WebSearchProviderBing       WebSearchProvider = "bing"
	WebSearchProviderBrave      WebSearchProvider = "brave"
	WebSearchProviderDuckduckgo WebSearchProvider = "duckduckgo"
	WebSearchProviderGoogle     WebSearchProvider = "google"
	WebSearchProviderSerper     WebSearchProvider = "serper"
	WebSearchProviderTavily     WebSearchProvider = "tavily"
)

// Defines values for SchemasAntflyType.
const (
	SchemasAntflyTypeBlob            SchemasAntflyType = "blob"
	SchemasAntflyTypeBoolean         SchemasAntflyType = "boolean"
	SchemasAntflyTypeDatetime        SchemasAntflyType = "datetime"
	SchemasAntflyTypeEmbedding       SchemasAntflyType = "embedding"
	SchemasAntflyTypeGeopoint        SchemasAntflyType = "geopoint"
	SchemasAntflyTypeGeoshape        SchemasAntflyType = "geoshape"
	SchemasAntflyTypeHtml            SchemasAntflyType = "html"
	SchemasAntflyTypeKeyword         SchemasAntflyType = "keyword"
	SchemasAntflyTypeLink            SchemasAntflyType = "link"
	SchemasAntflyTypeNumeric         SchemasAntflyType = "numeric"
	SchemasAntflyTypeSearchAsYouType SchemasAntflyType = "search_as_you_type"
	SchemasAntflyTypeText            SchemasAntflyType = "text"
)

// AggregationBucket defines model for AggregationBucket.
type AggregationBucket struct {
	// BgCount Background count (for significant_terms)
	BgCount *int `json:"bg_count,omitempty"`

	// DocCount Number of documents in this bucket
	DocCount int `json:"doc_count"`

	// From Lower bound for range buckets
	From *float64 `json:"from,omitempty"`

	// FromAsString Formatted lower bound
	FromAsString *string `json:"from_as_string,omitempty"`

	// Key Bucket key (term, range name, date, etc.)
	Key string `json:"key"`

	// KeyAsString Formatted key for display (e.g., formatted dates)
	KeyAsString *string `json:"key_as_string,omitempty"`

	// Score Significance score (for significant_terms)
	Score *float64 `json:"score,omitempty"`

	// SubAggregations Results of nested sub-aggregations
	SubAggregations map[string]AggregationResult `json:"sub_aggregations,omitempty,omitzero"`

	// To Upper bound for range buckets
	To *float64 `json:"to,omitempty"`

	// ToAsString Formatted upper bound
	ToAsString *string `json:"to_as_string,omitempty"`
}

// AggregationDateRange defines model for AggregationDateRange.
type AggregationDateRange struct {
	// From Start date (ISO 8601 or relative like "now-7d")
	From *string `json:"from,omitempty"`

	// Name Name of the date range bucket
	Name string `json:"name"`

	// To End date (ISO 8601 or relative like "now")
	To *string `json:"to,omitempty"`
}

// AggregationRange defines model for AggregationRange.
type AggregationRange struct {
	// From Lower bound (inclusive)
	From *float64 `json:"from,omitempty"`

	// Name Name of the range bucket
	Name string `json:"name"`

	// To Upper bound (exclusive)
	To *float64 `json:"to,omitempty"`
}

// AggregationRequest defines model for AggregationRequest.
type AggregationRequest struct {
	// Algorithm Significance algorithm for significant_terms aggregations
	Algorithm *SignificanceAlgorithm `json:"algorithm,omitempty"`

	// BackgroundFilter Background filter for significant_terms aggregations
	BackgroundFilter json.RawMessage `json:"background_filter,omitempty,omitzero"`

	// CalendarInterval Calendar-aware interval for date_histogram aggregations
	CalendarInterval *CalendarInterval `json:"calendar_interval,omitempty"`

	// DateRanges Date ranges for date_range aggregations
	DateRanges []AggregationDateRange `json:"date_ranges,omitempty,omitzero"`

	// DistanceRanges Distance ranges for geo_distance aggregations
	DistanceRanges []DistanceRange `json:"distance_ranges,omitempty,omitzero"`

	// Field Field to aggregate on
	Field string `json:"field"`

	// Interval Fixed interval for histogram aggregations
	Interval *float64 `json:"interval,omitempty"`

	// MinDocCount Minimum document count for a bucket to be included
	MinDocCount *int `json:"min_doc_count,omitempty"`

	// Origin Origin for geohash_grid aggregation (format: "lat,lon")
	// Example: "37.7749,-122.4194"
	Origin *string `json:"origin,omitempty"`

	// Precision Geohash precision (1-12) for geohash_grid aggregations
	Precision *int `json:"precision,omitempty"`

	// Ranges Ranges for range aggregations
	Ranges []AggregationRange `json:"ranges,omitempty,omitzero"`

	// Size Maximum number of buckets to return (for bucketing aggregations)
	Size *int `json:"size,omitempty"`

	// SubAggregations Nested sub-aggregations
	SubAggregations map[string]AggregationRequest `json:"sub_aggregations,omitempty,omitzero"`

	// Type Type of aggregation to compute:
	// - Metrics: sum, avg, min, max, count, sumsquares, stats, cardinality
	// - Bucketing: terms, range, date_range, histogram, date_histogram
	// - Geo: geohash_grid, geo_distance
	// - Analytics: significant_terms
	Type AggregationType `json:"type"`

	// Unit Distance unit for geo_distance aggregations
	Unit *DistanceUnit `json:"unit,omitempty"`
}

// AggregationResult defines model for AggregationResult.
type AggregationResult struct {
	// Avg Average for stats aggregations
	Avg *float64 `json:"avg,omitempty"`

	// Buckets Buckets for bucketing aggregations (terms, range, histogram, etc.)
	Buckets []AggregationBucket `json:"buckets,omitempty,omitzero"`

	// Count Document count for stats aggregations
	Count *int `json:"count,omitempty"`

	// Max Maximum value for stats aggregations
	Max *float64 `json:"max,omitempty"`

	// Min Minimum value for stats aggregations
	Min *float64 `json:"min,omitempty"`

	// StdDeviation Standard deviation for stats aggregations
	StdDeviation *float64 `json:"std_deviation,omitempty"`

	// Sum Sum for stats aggregations
	Sum *float64 `json:"sum,omitempty"`

	// SumOfSquares Sum of squares for stats aggregations
	SumOfSquares *float64 `json:"sum_of_squares,omitempty"`

	// Value Single value for metric aggregations (sum, avg, min, max, count, cardinality)
	Value *float64 `json:"value,omitempty"`

	// Variance Variance for stats aggregations
	Variance *float64 `json:"variance,omitempty"`
}

// AggregationType Type of aggregation to compute:
// - Metrics: sum, avg, min, max, count, sumsquares, stats, cardinality
// - Bucketing: terms, range, date_range, histogram, date_histogram
// - Geo: geohash_grid, geo_distance
// - Analytics: significant_terms
type AggregationType string

// Analyses defines model for Analyses.
type Analyses struct {
	Pca  bool `json:"pca,omitempty,omitzero"`
	Tsne bool `json:"tsne,omitempty,omitzero"`
}

// AnalysesResult defines model for AnalysesResult.
type AnalysesResult struct {
	Pca  []float64 `json:"pca,omitempty,omitzero"`
	Tsne []float64 `json:"tsne,omitempty,omitzero"`
}

// AnswerAgentRequest defines model for AnswerAgentRequest.
type AnswerAgentRequest struct {
	// AgentKnowledge Background knowledge that guides the agent's understanding of the domain.
	// Similar to CLAUDE.md, this provides context that applies to all steps
	// (classification, retrieval, and answer generation).
	//
	// Examples:
	// - "This data contains medical records. Use clinical terminology and be precise about diagnoses."
	// - "This is a software engineering knowledge base. Assume a technical audience."
	// - "This table stores legal documents. Reference laws and regulations accurately."
	AgentKnowledge string `json:"agent_knowledge,omitempty,omitzero"`

	// Chain Default chain of generators for all pipeline steps unless overridden in `steps`.
	// Each link can specify retry configuration and a condition for trying the next generator.
	// Mutually exclusive with 'generator'. Either 'generator' or 'chain' must be provided.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Eval Configuration for inline evaluation of query results.
	// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
	Eval EvalConfig `json:"eval,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// MaxContextTokens Maximum total tokens allowed for retrieved document context.
	// When set, documents are pruned (lowest-ranked first) to fit within this budget.
	// Useful for ensuring LLM context limits are not exceeded.
	// Uses BERT tokenizer for estimation.
	MaxContextTokens int `json:"max_context_tokens,omitempty,omitzero"`

	// Queries Array of query requests to execute. The query text will be transformed for semantic search
	// and populated into the semantic_search field of each query.
	Queries []QueryRequest `json:"queries"`

	// Query User's natural language query to be classified and improved
	Query string `json:"query"`

	// ReserveTokens Tokens to reserve for system prompt, answer generation, and other overhead.
	// Subtracted from max_context_tokens to determine available context budget.
	// Defaults to 4000 if max_context_tokens is set.
	ReserveTokens int `json:"reserve_tokens,omitempty,omitzero"`

	// Steps Per-step configuration for the answer agent pipeline. Each step can have
	// its own generator (or chain of generators) and step-specific options.
	// If a step is not configured, it uses the top-level generator as default.
	Steps AnswerAgentSteps `json:"steps,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results (classification, queries, results, answer) instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`

	// WithoutGeneration When true, skip AI answer generation and return search results only.
	// Useful when you want search quality without LLM cost, such as for
	// quota management or rate limiting scenarios.
	WithoutGeneration bool `json:"without_generation,omitempty,omitzero"`
}

// AnswerAgentResult defines model for AnswerAgentResult.
type AnswerAgentResult struct {
	// Answer Generated answer in markdown format
	Answer string `json:"answer"`

	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0)
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// ClassificationTransformation Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
	ClassificationTransformation ClassificationTransformationResult `json:"classification_transformation,omitempty,omitzero"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance,omitempty,omitzero"`

	// EvalResult Complete evaluation result
	EvalResult EvalResult `json:"eval_result,omitempty,omitzero"`

	// FollowupQuestions Suggested follow-up questions
	FollowupQuestions []string `json:"followup_questions,omitempty,omitzero"`

	// QueryResults Results from each executed query
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`
}

// AnswerAgentSteps Per-step configuration for the answer agent pipeline. Each step can have
// its own generator (or chain of generators) and step-specific options.
// If a step is not configured, it uses the top-level generator as default.
type AnswerAgentSteps struct {
	// Answer Configuration for the answer generation step. This step generates the final
	// answer from retrieved documents using the reasoning as context.
	Answer AnswerStepConfig `json:"answer,omitempty,omitzero"`

	// Classification Configuration for the classification step. This step analyzes the query,
	// selects the optimal retrieval strategy, and generates semantic transformations.
	Classification ClassificationStepConfig `json:"classification,omitempty,omitzero"`

	// Confidence Configuration for confidence assessment. Evaluates answer quality and
	// resource relevance. Can use a model calibrated for scoring tasks.
	Confidence ConfidenceStepConfig `json:"confidence,omitempty,omitzero"`

	// Followup Configuration for generating follow-up questions. Uses a separate generator
	// call which can use a cheaper/faster model.
	Followup FollowupStepConfig `json:"followup,omitempty,omitzero"`
}

// AnswerConfidence Confidence assessment for the generated answer
type AnswerConfidence struct {
	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0). Considers both ability to answer from provided resources and general knowledge.
	AnswerConfidence float32 `json:"answer_confidence"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance"`
}

// AnswerResult Result from answer generation with optional confidence and follow-up questions
type AnswerResult struct {
	// Answer Generated answer in markdown format
	Answer string `json:"answer"`

	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0)
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance,omitempty,omitzero"`

	// FollowupQuestions Suggested follow-up questions
	FollowupQuestions []string `json:"followup_questions,omitempty,omitzero"`
}

// AnswerStepConfig Configuration for the answer generation step. This step generates the final
// answer from retrieved documents using the reasoning as context.
type AnswerStepConfig struct {
	// AnswerContext Custom guidance for answer tone, detail level, and style
	AnswerContext string `json:"answer_context,omitempty,omitzero"`

	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// SystemPrompt Custom system prompt for answer generation
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`
}

// AntflyChunkerConfig defines model for AntflyChunkerConfig.
type AntflyChunkerConfig struct {
	// FullText Configuration for full-text indexing of chunks in Bleve.
	// When present (even if empty), chunks will be stored with :cft: suffix and indexed in Bleve's _chunks field.
	// When absent, chunks use :c: suffix and are only used for vector embeddings.
	// This object is reserved for future options like boosting, field mapping, etc.
	FullText map[string]interface{} `json:"full_text,omitempty,omitzero"`

	// MaxChunks Maximum number of chunks to generate per document.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries. Only used by fixed-size chunkers.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs). Only used by fixed-size chunkers.
	Separator string `json:"separator,omitempty,omitzero"`

	// TargetTokens Target number of tokens per chunk.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`

	// Threshold Minimum confidence threshold for separator detection (0.0-1.0). Only used by ONNX models.
	Threshold float32 `json:"threshold,omitempty,omitzero"`
}

// AntflyType defines model for AntflyType.
type AntflyType string

// AnthropicGeneratorConfig Configuration for the Anthropic generative AI provider (Claude models).
//
// API key via `api_key` field or `ANTHROPIC_API_KEY` environment variable.
//
// **Example Models:** claude-sonnet-4-5-20250929 (default), claude-opus-4-5-20251101, claude-3-5-haiku-20241022
//
// **Docs:** https://docs.anthropic.com/en/docs/about-claude/models/overview
type AnthropicGeneratorConfig struct {
	// ApiKey The Anthropic API key. If not provided, falls back to ANTHROPIC_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The full model ID of the Anthropic model to use (e.g., 'claude-sonnet-4-5-20250929', 'claude-opus-4-5-20251101').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-1.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Anthropic API endpoint (optional, uses default if not specified).
	Url string `json:"url,omitempty,omitzero"`
}

// BackupInfo defines model for BackupInfo.
type BackupInfo struct {
	// AntflyVersion Antfly version that created the backup
	AntflyVersion string `json:"antfly_version,omitempty,omitzero"`

	// BackupId The backup identifier
	BackupId string `json:"backup_id"`

	// Location Storage location of the backup
	Location string `json:"location"`

	// Tables Tables included in the backup
	Tables []string `json:"tables"`

	// Timestamp When the backup was created
	Timestamp time.Time `json:"timestamp"`
}

// BackupListResponse defines model for BackupListResponse.
type BackupListResponse struct {
	// Backups List of available backups
	Backups []BackupInfo `json:"backups"`
}

// BackupRequest defines model for BackupRequest.
type BackupRequest struct {
	// BackupId Unique identifier for this backup. Used to reference the backup for restore operations.
	// Choose a meaningful name that includes date/version information.
	BackupId string `json:"backup_id"`

	// Location Storage location for the backup. Supports multiple backends:
	// - Local filesystem: `file:///path/to/backup`
	// - Amazon S3: `s3://bucket-name/path/to/backup`
	//
	// The backup includes all table data, indexes, and metadata for the specified table.
	Location string `json:"location"`
}

// BatchRequest Batch insert, delete, and transform operations in a single request.
//
// **Atomicity**:
// - **Single shard**: Operations are atomic within shard boundaries
// - **Multiple shards**: Uses distributed 2-phase commit (2PC) for atomic cross-shard writes
//
// **How distributed transactions work**:
// 1. Metadata server allocates HLC timestamp and selects coordinator shard
// 2. Coordinator writes transaction record, participants write intents
// 3. After all intents succeed, coordinator commits transaction
// 4. Participants are notified asynchronously to resolve intents
// 5. Recovery loop ensures notifications complete even after coordinator failure
//
// **Performance**:
// - Single-shard batches: < 5ms latency
// - Cross-shard transactions: ~20ms latency
// - Intent resolution: < 30 seconds worst-case (via recovery loop)
//
// **Guarantees**:
// - All writes succeed or all fail (atomicity across all shards)
// - Coordinator failure is recoverable (new leader resumes notifications)
// - Idempotent resolution (duplicate notifications are safe)
//
// **Benefits**:
// - Reduces network overhead compared to individual requests
// - More efficient indexing (updates are batched)
// - Automatic distributed transactions when operations span shards
//
// The inserts are upserts - existing keys are overwritten, new keys are created.
type BatchRequest struct {
	// Deletes Array of document IDs to delete. Documents are removed from all indexes.
	//
	// Notes:
	// - Non-existent keys are silently ignored
	// - Deletions are processed before inserts in the same batch
	// - Keys are permanently removed from storage and indexes
	Deletes []string `json:"deletes,omitempty,omitzero"`

	// Inserts Map of document IDs to document objects. Each key is the unique identifier for the document.
	//
	// Best practices:
	// - Use consistent key naming schemes (e.g., "user:123", "article:456")
	// - Key length affects storage and performance - keep them reasonably short
	// - Keys are sorted lexicographically, so choose prefixes that support range scans
	Inserts map[string]map[string]interface{} `json:"inserts,omitempty,omitzero"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write
	// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`

	// Transforms Array of transform operations for in-place document updates using MongoDB-style operators.
	//
	// Transform operations allow you to modify documents without read-modify-write races:
	// - Operations are applied atomically on the server
	// - Multiple operations per document are applied in sequence
	// - Supports numeric operations ($inc, $mul), array operations ($push, $pull), and more
	//
	// Common use cases:
	// - Increment counters (views, likes, votes)
	// - Update timestamps ($currentDate)
	// - Manage arrays (add/remove tags, items)
	// - Update nested fields without overwriting the entire document
	Transforms []Transform `json:"transforms,omitempty,omitzero"`
}

// BatchResponse defines model for BatchResponse.
type BatchResponse struct {
	// Deleted Number of documents successfully deleted
	Deleted int `json:"deleted,omitempty,omitzero"`

	// Inserted Number of documents successfully inserted
	Inserted int `json:"inserted,omitempty,omitzero"`

	// Transformed Number of documents successfully transformed
	Transformed int `json:"transformed,omitempty,omitzero"`
}

// BedrockEmbedderConfig Configuration for the AWS Bedrock embedding provider.
//
// Uses AWS credentials from environment or IAM roles.
//
// **Example Models:** cohere.embed-english-v4, amazon.titan-embed-text-v2:0
//
// **Docs:** https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html
type BedrockEmbedderConfig struct {
	// BatchSize The batch size for embedding requests to optimize throughput.
	BatchSize int `json:"batch_size,omitempty,omitzero"`

	// Model The Bedrock model ID to use (e.g., 'cohere.embed-english-v4', 'amazon.titan-embed-text-v2:0').
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service (e.g., 'us-east-1').
	Region string `json:"region,omitempty,omitzero"`

	// StripNewLines Whether to strip new lines from the input text before embedding.
	StripNewLines bool `json:"strip_new_lines,omitempty,omitzero"`
}

// BedrockGeneratorConfig Configuration for the AWS Bedrock generative AI provider.
//
// Provides access to models from Anthropic, Meta, Amazon, Cohere, Mistral, and others.
//
// **Example Models:** anthropic.claude-sonnet-4-5-20250929-v1:0, meta.llama3-3-70b-instruct-v1:0, amazon.nova-pro-v1:0
//
// **Docs:** https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html
type BedrockGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The Bedrock model ID to use (e.g., 'anthropic.claude-sonnet-4-5-20250929-v1:0').
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service.
	Region string `json:"region,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-1.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// BingSearchConfig defines model for BingSearchConfig.
type BingSearchConfig struct {
	// ApiKey Bing Search API key (or set BING_SEARCH_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Endpoint Bing API endpoint URL
	Endpoint string `json:"endpoint,omitempty,omitzero"`

	// Freshness Filter results by freshness
	Freshness BingSearchConfigFreshness `json:"freshness,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// BingSearchConfigFreshness Filter results by freshness
type BingSearchConfigFreshness string

// BleveIndexV2Config defines model for BleveIndexV2Config.
type BleveIndexV2Config struct {
	// MemOnly Whether to use memory-only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`
}

// BleveIndexV2Stats defines model for BleveIndexV2Stats.
type BleveIndexV2Stats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// Rebuilding Whether the index is currently rebuilding
	Rebuilding bool `json:"rebuilding,omitempty,omitzero"`

	// TotalIndexed Number of documents in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`
}

// BoolFieldQuery defines model for BoolFieldQuery.
type BoolFieldQuery struct {
	Bool bool `json:"bool"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
}

// BooleanQuery defines model for BooleanQuery.
type BooleanQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost   Boost            `json:"boost,omitzero"`
	Filter  Query            `json:"filter,omitempty,omitzero"`
	Must    ConjunctionQuery `json:"must,omitempty,omitzero"`
	MustNot DisjunctionQuery `json:"must_not,omitempty,omitzero"`
	Should  DisjunctionQuery `json:"should,omitempty,omitzero"`
}

// Boost A floating-point number used to decrease or increase the relevance scores of a query.
type Boost = float64

// BraveSearchConfig defines model for BraveSearchConfig.
type BraveSearchConfig struct {
	// ApiKey Brave Search API key (or set BRAVE_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Freshness Freshness filter: pd=day, pw=week, pm=month, py=year
	Freshness BraveSearchConfigFreshness `json:"freshness,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// Spellcheck Enable spellcheck suggestions
	Spellcheck bool `json:"spellcheck,omitempty,omitzero"`

	// TextDecorations Include text decorations (bold, italic markers)
	TextDecorations bool `json:"text_decorations,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// BraveSearchConfigFreshness Freshness filter: pd=day, pw=week, pm=month, py=year
type BraveSearchConfigFreshness string

// ByteRange defines model for ByteRange.
type ByteRange = [][]byte

// CalendarInterval Calendar-aware interval for date_histogram aggregations
type CalendarInterval string

// ChainCondition Condition for trying the next generator in chain:
// - always: Always try next regardless of outcome
// - on_error: Try next on any error (default)
// - on_timeout: Try next only on timeout errors
// - on_rate_limit: Try next only on rate limit errors
type ChainCondition string

// ChainLink A single link in a generator chain with optional retry and condition
type ChainLink struct {
	// Condition Condition for trying the next generator in chain:
	// - always: Always try next regardless of outcome
	// - on_error: Try next on any error (default)
	// - on_timeout: Try next only on timeout errors
	// - on_rate_limit: Try next only on rate limit errors
	Condition ChainCondition `json:"condition,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator"`

	// Retry Retry configuration for generator calls
	Retry RetryConfig `json:"retry,omitempty,omitzero"`
}

// ChatAgentRequest defines model for ChatAgentRequest.
type ChatAgentRequest struct {
	// AccumulatedFilters Filters accumulated from previous conversation turns.
	// These are applied to all queries automatically.
	// New filters discovered in this turn will be added to this list in the response.
	AccumulatedFilters []FilterSpec `json:"accumulated_filters,omitempty,omitzero"`

	// AgentKnowledge Background knowledge that guides the agent's understanding of the domain.
	// Similar to CLAUDE.md, this provides context that applies to all steps
	// (classification, retrieval, and answer generation).
	//
	// Example: "This is a technical documentation search. Results should be
	// filtered to only include official documentation, not community posts."
	AgentKnowledge string `json:"agent_knowledge,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator"`

	// MaxContextTokens Maximum tokens for retrieved document context
	MaxContextTokens int `json:"max_context_tokens,omitempty,omitzero"`

	// Messages Conversation history. Include all previous messages to maintain context.
	// The last message should typically be from the user.
	Messages []ChatMessage `json:"messages"`

	// Queries Base query configurations. The chat agent will modify these queries
	// based on conversation context, applying filters and transformations.
	Queries []QueryRequest `json:"queries"`

	// Steps Per-step configuration for the chat agent pipeline. Similar to AnswerAgentSteps
	// but includes tool-specific configuration.
	Steps ChatAgentSteps `json:"steps,omitempty,omitzero"`

	// SystemPrompt Optional custom system prompt for the chat agent.
	// If not provided, uses a default conversational RAG prompt.
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// ChatAgentResult defines model for ChatAgentResult.
type ChatAgentResult struct {
	// Answer Final answer text (if available)
	Answer string `json:"answer,omitempty,omitzero"`

	// AnswerConfidence Confidence in the answer
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// AppliedFilters Filters that have been applied in this conversation
	AppliedFilters []FilterSpec `json:"applied_filters,omitempty,omitzero"`

	// ClassificationTransformation Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
	ClassificationTransformation ClassificationTransformationResult `json:"classification_transformation,omitempty,omitzero"`

	// Messages Updated conversation history including the assistant's response
	Messages []ChatMessage `json:"messages"`

	// PendingClarification A request for clarification from the user
	PendingClarification ClarificationRequest `json:"pending_clarification,omitempty,omitzero"`

	// QueryResults Search results from executed queries
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`

	// ToolCallsMade Number of tool calls made in this turn
	ToolCallsMade int `json:"tool_calls_made,omitempty,omitzero"`
}

// ChatAgentSteps Per-step configuration for the chat agent pipeline. Similar to AnswerAgentSteps
// but includes tool-specific configuration.
type ChatAgentSteps struct {
	// Answer Configuration for the answer generation step. This step generates the final
	// answer from retrieved documents using the reasoning as context.
	Answer AnswerStepConfig `json:"answer,omitempty,omitzero"`

	// Classification Configuration for the classification step. This step analyzes the query,
	// selects the optimal retrieval strategy, and generates semantic transformations.
	Classification ClassificationStepConfig `json:"classification,omitempty,omitzero"`

	// Confidence Configuration for confidence assessment. Evaluates answer quality and
	// resource relevance. Can use a model calibrated for scoring tasks.
	Confidence ConfidenceStepConfig `json:"confidence,omitempty,omitzero"`

	// Tools Configuration for chat agent tools.
	//
	// If `enabled_tools` is empty/omitted, defaults to: add_filter, ask_clarification, search.
	//
	// For models that don't support native tool calling (e.g., Ollama),
	// a prompt-based fallback is used with structured output parsing.
	Tools ChatToolsConfig `json:"tools,omitempty,omitzero"`
}

// ChatMessage A message in the conversation history
type ChatMessage struct {
	// Content Text content of the message
	Content string `json:"content"`

	// Role Role of the message sender in the conversation
	Role ChatMessageRole `json:"role"`

	// ToolCalls Tool calls made by the assistant (only for assistant role)
	ToolCalls []ChatToolCall `json:"tool_calls,omitempty,omitzero"`

	// ToolResults Results from tool executions (only for tool role)
	ToolResults []ChatToolResult `json:"tool_results,omitempty,omitzero"`
}

// ChatMessageRole Role of the message sender in the conversation
type ChatMessageRole string

// ChatToolCall A tool call made by the assistant
type ChatToolCall struct {
	// Arguments Arguments passed to the tool as key-value pairs
	Arguments map[string]interface{} `json:"arguments"`

	// Id Unique identifier for this tool call
	Id string `json:"id"`

	// Name Name of the tool being called
	Name string `json:"name"`
}

// ChatToolName Available tool names for the chat agent.
// - add_filter: Add search filters (field constraints)
// - ask_clarification: Ask user for clarification
// - search: Execute semantic searches
// - websearch: Search the web (requires websearch_config)
// - fetch: Fetch URL content (subject to security controls)
type ChatToolName string

// ChatToolResult Result from executing a tool call
type ChatToolResult struct {
	// Error Error message if tool execution failed
	Error string `json:"error,omitempty,omitzero"`

	// Result Result data from the tool execution
	Result map[string]interface{} `json:"result"`

	// ToolCallId ID of the tool call this result corresponds to
	ToolCallId string `json:"tool_call_id"`
}

// ChatToolsConfig Configuration for chat agent tools.
//
// If `enabled_tools` is empty/omitted, defaults to: add_filter, ask_clarification, search.
//
// For models that don't support native tool calling (e.g., Ollama),
// a prompt-based fallback is used with structured output parsing.
type ChatToolsConfig struct {
	// EnabledTools List of tools to enable. If empty, defaults to filter, clarification, and search.
	EnabledTools []ChatToolName `json:"enabled_tools,omitempty,omitzero"`

	// FetchConfig Configuration for URL content fetching.
	//
	// Uses lib/scraping for downloading and processing. Supports:
	// - HTTP/HTTPS URLs with security validation
	// - HTML pages (extracts readable text via go-readability)
	// - PDF files (extracts text)
	// - Images (returns as data URIs)
	// - Plain text files
	// - S3 URLs (requires s3_credentials)
	//
	// Security features (from lib/scraping.ContentSecurityConfig):
	// - Allowed host whitelist
	// - Private IP blocking (SSRF prevention)
	// - Download size limits
	// - Timeout controls
	FetchConfig FetchConfig `json:"fetch_config,omitempty,omitzero"`

	// MaxToolIterations Maximum number of tool call iterations per turn.
	// Prevents infinite loops in tool execution.
	MaxToolIterations int `json:"max_tool_iterations,omitempty,omitzero"`

	// WebsearchConfig A unified configuration for web search providers.
	//
	// Each provider has specific configuration requirements. Use the appropriate
	// provider-specific config or set common options at the top level.
	//
	// **Environment Variables (fallbacks):**
	// - GOOGLE_CSE_API_KEY, GOOGLE_CSE_ID
	// - BING_SEARCH_API_KEY
	// - SERPER_API_KEY
	// - TAVILY_API_KEY
	// - BRAVE_API_KEY
	WebsearchConfig WebSearchConfig `json:"websearch_config,omitempty,omitzero"`
}

// ChunkOptions Per-request configuration for chunking. All fields are optional - zero/omitted values use chunker defaults.
type ChunkOptions struct {
	// MaxChunks Maximum number of chunks to generate per document.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries. Only used by fixed-size chunkers.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs). Only used by fixed-size chunkers.
	Separator string `json:"separator,omitempty,omitzero"`

	// TargetTokens Target number of tokens per chunk.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`

	// Threshold Minimum confidence threshold for separator detection (0.0-1.0). Only used by ONNX models.
	Threshold float32 `json:"threshold,omitempty,omitzero"`
}

// ChunkerConfig defines model for ChunkerConfig.
type ChunkerConfig struct {
	// Provider The chunking provider to use.
	Provider ChunkerProvider `json:"provider"`
	union    json.RawMessage
}

// ChunkerProvider The chunking provider to use.
type ChunkerProvider string

// ClarificationRequest A request for clarification from the user
type ClarificationRequest struct {
	// Options Optional list of suggested answers for the user to choose from
	Options []string `json:"options,omitempty,omitzero"`

	// Question The clarifying question to ask the user
	Question string `json:"question"`

	// Required Whether the clarification is required before proceeding
	Required bool `json:"required,omitempty,omitzero"`
}

// ClassificationStepConfig Configuration for the classification step. This step analyzes the query,
// selects the optimal retrieval strategy, and generates semantic transformations.
type ClassificationStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// ForceSemanticMode Mode for semantic query generation:
	// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
	// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
	ForceSemanticMode SemanticQueryMode `json:"force_semantic_mode,omitempty,omitzero"`

	// ForceStrategy Strategy for query transformation and retrieval:
	// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
	// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
	// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
	// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
	ForceStrategy QueryStrategy `json:"force_strategy,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// MultiPhraseCount Number of alternative query phrasings to generate
	MultiPhraseCount int `json:"multi_phrase_count,omitempty,omitzero"`

	// WithReasoning Include pre-retrieval reasoning explaining query analysis and strategy selection
	WithReasoning bool `json:"with_reasoning,omitempty,omitzero"`
}

// ClassificationTransformationResult Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
type ClassificationTransformationResult struct {
	// Confidence Classification confidence (0.0 to 1.0)
	Confidence float32 `json:"confidence"`

	// ImprovedQuery Clarified query with added context for answer generation (human-readable)
	ImprovedQuery string `json:"improved_query"`

	// MultiPhrases Alternative phrasings of the query for expanded retrieval coverage
	MultiPhrases []string `json:"multi_phrases,omitempty,omitzero"`

	// Reasoning Pre-retrieval reasoning explaining query analysis and strategy selection (only present when with_classification_reasoning is enabled)
	Reasoning string `json:"reasoning,omitempty,omitzero"`

	// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
	RouteType RouteType `json:"route_type"`

	// SemanticMode Mode for semantic query generation:
	// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
	// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
	SemanticMode SemanticQueryMode `json:"semantic_mode"`

	// SemanticQuery Optimized query for vector/semantic search. Content style depends on semantic_mode: keywords for 'rewrite', hypothetical answer for 'hypothetical'
	SemanticQuery string `json:"semantic_query"`

	// StepBackQuery Broader background query for context (only present when strategy is 'step_back')
	StepBackQuery string `json:"step_back_query,omitempty,omitzero"`

	// Strategy Strategy for query transformation and retrieval:
	// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
	// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
	// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
	// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
	Strategy QueryStrategy `json:"strategy"`

	// SubQuestions Decomposed sub-questions (only present when strategy is 'decompose')
	SubQuestions []string `json:"sub_questions,omitempty,omitzero"`
}

// ClusterBackupRequest defines model for ClusterBackupRequest.
type ClusterBackupRequest struct {
	// BackupId Unique identifier for this backup. Used to reference the backup for restore operations.
	// Choose a meaningful name that includes date/version information.
	BackupId string `json:"backup_id"`

	// Location Storage location for the backup. Supports multiple backends:
	// - Local filesystem: `file:///path/to/backup`
	// - Amazon S3: `s3://bucket-name/path/to/backup`
	//
	// The backup includes all table data, indexes, and metadata.
	Location string `json:"location"`

	// TableNames Optional list of tables to backup. If omitted, all tables are backed up.
	TableNames []string `json:"table_names,omitempty,omitzero"`
}

// ClusterBackupResponse defines model for ClusterBackupResponse.
type ClusterBackupResponse struct {
	// BackupId The backup identifier
	BackupId string `json:"backup_id"`

	// Status Overall backup status
	Status ClusterBackupResponseStatus `json:"status"`

	// Tables Status of each table backup
	Tables []TableBackupStatus `json:"tables"`
}

// ClusterBackupResponseStatus Overall backup status
type ClusterBackupResponseStatus string

// ClusterHealth Overall health status of the cluster
type ClusterHealth string

// ClusterRestoreRequest defines model for ClusterRestoreRequest.
type ClusterRestoreRequest struct {
	// BackupId Unique identifier of the backup to restore from.
	BackupId string `json:"backup_id"`

	// Location Storage location where the backup is stored.
	Location string `json:"location"`

	// RestoreMode How to handle existing tables:
	// - `fail_if_exists`: Abort if any table already exists (default)
	// - `skip_if_exists`: Skip existing tables, restore others
	// - `overwrite`: Drop and recreate existing tables
	RestoreMode ClusterRestoreRequestRestoreMode `json:"restore_mode,omitempty,omitzero"`

	// TableNames Optional list of tables to restore. If omitted, all tables in the backup are restored.
	TableNames []string `json:"table_names,omitempty,omitzero"`
}

// ClusterRestoreRequestRestoreMode How to handle existing tables:
// - `fail_if_exists`: Abort if any table already exists (default)
// - `skip_if_exists`: Skip existing tables, restore others
// - `overwrite`: Drop and recreate existing tables
type ClusterRestoreRequestRestoreMode string

// ClusterRestoreResponse defines model for ClusterRestoreResponse.
type ClusterRestoreResponse struct {
	// Status Overall restore status
	Status ClusterRestoreResponseStatus `json:"status"`

	// Tables Status of each table restore
	Tables []TableRestoreStatus `json:"tables"`
}

// ClusterRestoreResponseStatus Overall restore status
type ClusterRestoreResponseStatus string

// ClusterStatus defines model for ClusterStatus.
type ClusterStatus struct {
	// AuthEnabled Indicates whether authentication is enabled for the cluster
	AuthEnabled bool `json:"auth_enabled,omitempty"`

	// Health Overall health status of the cluster
	Health ClusterHealth `json:"health"`

	// Message Optional message providing details about the health status
	Message              string                 `json:"message,omitempty,omitzero"`
	AdditionalProperties map[string]interface{} `json:"-"`
}

// CohereEmbedderConfig Configuration for the Cohere embedding provider.
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** embed-english-v3.0 (default, 1024 dims), embed-multilingual-v3.0
//
// **Docs:** https://docs.cohere.com/reference/embed
type CohereEmbedderConfig struct {
	// ApiKey The Cohere API key. Can also be set via COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// InputType Specifies the type of input for optimized embeddings.
	InputType CohereEmbedderConfigInputType `json:"input_type,omitempty,omitzero"`

	// Model The name of the Cohere embedding model to use.
	Model string `json:"model"`

	// Truncate How to handle inputs longer than the max token length.
	Truncate CohereEmbedderConfigTruncate `json:"truncate,omitempty,omitzero"`
}

// CohereEmbedderConfigInputType Specifies the type of input for optimized embeddings.
type CohereEmbedderConfigInputType string

// CohereEmbedderConfigTruncate How to handle inputs longer than the max token length.
type CohereEmbedderConfigTruncate string

// CohereGeneratorConfig Configuration for the Cohere generative AI provider (Command models).
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** command-r-plus (default), command-r, command-a-03-2025
//
// **Docs:** https://docs.cohere.com/reference/chat
type CohereGeneratorConfig struct {
	// ApiKey The Cohere API key. If not provided, falls back to COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (0.0-1.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Cohere model to use.
	Model string `json:"model"`

	// PresencePenalty Penalty for token presence (0.0-1.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-1.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// CohereRerankerConfig Configuration for the Cohere reranking provider.
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** rerank-english-v3.0 (default), rerank-multilingual-v3.0
//
// **Docs:** https://docs.cohere.com/reference/rerank
type CohereRerankerConfig struct {
	// ApiKey The Cohere API key. Can also be set via COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// MaxChunksPerDoc Maximum number of chunks per document for long document handling.
	MaxChunksPerDoc int `json:"max_chunks_per_doc,omitempty,omitzero"`

	// Model The name of the Cohere reranking model to use.
	Model string `json:"model"`

	// TopN Number of most relevant documents to return. If not specified, returns all documents with scores.
	TopN int `json:"top_n,omitempty,omitzero"`
}

// ConfidenceStepConfig Configuration for confidence assessment. Evaluates answer quality and
// resource relevance. Can use a model calibrated for scoring tasks.
type ConfidenceStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Context Custom guidance for confidence assessment approach
	Context string `json:"context,omitempty,omitzero"`

	// Enabled Enable confidence scoring
	Enabled bool `json:"enabled,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`
}

// ConjunctionQuery defines model for ConjunctionQuery.
type ConjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Conjuncts []Query `json:"conjuncts"`
}

// CreateTableRequest defines model for CreateTableRequest.
type CreateTableRequest struct {
	// Description Optional human-readable description of the table and its purpose.
	// Useful for documentation and team collaboration.
	Description string `json:"description,omitempty,omitzero"`

	// Indexes Map of index name to index configuration. Indexes enable different query capabilities:
	// - Full-text indexes for BM25 search
	// - Vector indexes for semantic similarity
	// - Multimodal indexes for images/audio/video
	//
	// You can add multiple indexes to support different query patterns.
	Indexes map[string]IndexConfig `json:"indexes,omitempty,omitzero"`

	// NumShards Number of shards to create for the table. Data is partitioned across shards based on key ranges.
	//
	// **Sizing Guidelines:**
	// - Small datasets (<100K docs): 1-3 shards
	// - Medium datasets (100K-1M docs): 3-10 shards
	// - Large datasets (>1M docs): 10+ shards
	//
	// More shards enable better parallelism but increase overhead. Choose based on expected data size and query patterns.
	//
	// **When to Add More Shards:**
	//
	// Antfly supports **online shard reallocation** without downtime. Add more shards when:
	// - Individual shards exceed size thresholds (configurable)
	// - Query latency increases due to large shard size
	// - Need better parallelism for write-heavy workloads
	//
	// Use the internal `/reallocate` endpoint to trigger automatic shard splitting:
	// ```bash
	// POST /_internal/v1/reallocate
	// ```
	//
	// This enqueues a reallocation request that the leader processes asynchronously, splitting
	// large shards and redistributing data without service interruption.
	//
	// **Advantages over Elasticsearch:**
	// - Automatic shard splitting (no manual reindexing required)
	// - Online operation (no downtime)
	// - Transparent to applications (keys remain accessible during reallocation)
	NumShards uint `json:"num_shards,omitempty,omitzero"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema `json:"schema,omitempty,omitzero"`
}

// CreateUserRequest defines model for CreateUserRequest.
type CreateUserRequest struct {
	// InitialPolicies Optional list of initial permissions for the user.
	InitialPolicies []Permission `json:"initial_policies,omitzero"`
	Password        string       `json:"password"`

	// Username Username for the new user. If provided in the path, this field can be omitted or must match the path parameter.
	Username string `json:"username,omitempty,omitzero"`
}

// Credentials defines model for Credentials.
type Credentials struct {
	// AccessKeyId AWS access key ID. Supports keystore syntax for secret lookup. Falls back to AWS_ACCESS_KEY_ID environment variable if not set.
	AccessKeyId string `json:"access_key_id,omitempty,omitzero"`

	// Endpoint S3-compatible endpoint (e.g., 's3.amazonaws.com' or 'localhost:9000' for MinIO)
	Endpoint string `json:"endpoint,omitempty,omitzero"`

	// SecretAccessKey AWS secret access key. Supports keystore syntax for secret lookup. Falls back to AWS_SECRET_ACCESS_KEY environment variable if not set.
	SecretAccessKey string `json:"secret_access_key,omitempty,omitzero"`

	// SessionToken Optional AWS session token for temporary credentials. Supports keystore syntax for secret lookup.
	SessionToken string `json:"session_token,omitempty,omitzero"`

	// UseSsl Enable SSL/TLS for S3 connections (default: true for AWS, false for local MinIO)
	UseSsl bool `json:"use_ssl,omitempty,omitzero"`
}

// DateRangeStringQuery defines model for DateRangeStringQuery.
type DateRangeStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost          Boost     `json:"boost,omitzero"`
	DatetimeParser string    `json:"datetime_parser,omitempty,omitzero"`
	End            time.Time `json:"end,omitempty,omitzero"`
	Field          string    `json:"field,omitempty,omitzero"`
	InclusiveEnd   bool      `json:"inclusive_end,omitzero"`
	InclusiveStart bool      `json:"inclusive_start,omitzero"`
	Start          time.Time `json:"start,omitempty,omitzero"`
}

// DisjunctionQuery defines model for DisjunctionQuery.
type DisjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Disjuncts []Query `json:"disjuncts"`
	Min       float64 `json:"min,omitempty,omitzero"`
}

// DistanceRange defines model for DistanceRange.
type DistanceRange struct {
	// From Minimum distance (inclusive)
	From *float64 `json:"from,omitempty"`

	// Name Name of the distance range bucket
	Name string `json:"name"`

	// To Maximum distance (exclusive)
	To *float64 `json:"to,omitempty"`
}

// DistanceUnit Distance unit for geo aggregations:
// - m: meters
// - km: kilometers
// - mi: miles
// - ft: feet
// - yd: yards
type DistanceUnit string

// DocIdQuery defines model for DocIdQuery.
type DocIdQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost    `json:"boost,omitzero"`
	Ids   []string `json:"ids"`
}

// DocumentSchema Defines the structure of a document type
type DocumentSchema struct {
	// Description A description of the document type.
	Description string `json:"description,omitempty,omitzero"`

	// Schema A valid JSON Schema defining the document's structure.
	// This is used to infer indexing rules and field types.
	Schema map[string]interface{} `json:"schema,omitempty,omitzero"`
}

// DuckDuckGoSearchConfig defines model for DuckDuckGoSearchConfig.
type DuckDuckGoSearchConfig struct {
	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// NoHtml Remove HTML from results
	NoHtml bool `json:"no_html,omitempty,omitzero"`

	// NoRedirect Skip HTTP redirect for bang queries
	NoRedirect bool `json:"no_redirect,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// DynamicTemplate A rule for mapping dynamically detected fields. Templates are checked in order
// and the first matching template's mapping is used.
type DynamicTemplate struct {
	// Mapping Field mapping to apply when a dynamic template matches
	Mapping TemplateFieldMapping `json:"mapping,omitempty,omitzero"`

	// Match Glob pattern for field name (last path element).
	// Supports * and ** wildcards. Example: "*_text" matches "title_text", "body_text"
	Match string `json:"match,omitempty,omitzero"`

	// MatchMappingType Filter by detected JSON type
	MatchMappingType DynamicTemplateMatchMappingType `json:"match_mapping_type,omitempty,omitzero"`

	// Name Optional identifier for the template (useful for debugging)
	Name string `json:"name,omitempty,omitzero"`

	// PathMatch Glob pattern for the full dotted path. Supports ** for matching multiple segments.
	// Example: "metadata.**" matches "metadata.author", "metadata.tags.primary"
	PathMatch string `json:"path_match,omitempty,omitzero"`

	// PathUnmatch Path exclusion pattern. If it matches the full path, the template is skipped.
	PathUnmatch string `json:"path_unmatch,omitempty,omitzero"`

	// Unmatch Exclusion pattern for field name. If it matches, the template is skipped.
	// Example: "skip_*" would exclude fields like "skip_this"
	Unmatch string `json:"unmatch,omitempty,omitzero"`
}

// DynamicTemplateMatchMappingType Filter by detected JSON type
type DynamicTemplateMatchMappingType string

// Edge A typed, weighted connection between documents
type Edge struct {
	// CreatedAt When the edge was created
	CreatedAt time.Time `json:"created_at,omitempty,omitzero"`

	// Metadata Optional edge metadata
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`

	// Source Base64-encoded source document key
	Source []byte `json:"source"`

	// Target Base64-encoded target document key
	Target []byte `json:"target"`

	// Type Edge type (e.g., "cites", "similar_to", "authored_by")
	Type string `json:"type"`

	// UpdatedAt When the edge was last updated
	UpdatedAt time.Time `json:"updated_at,omitempty,omitzero"`

	// Weight Edge weight/confidence (0.0 to 1.0)
	Weight float64 `json:"weight"`
}

// EdgeDirection Direction of edges to query:
// - out: Outgoing edges from the node
// - in: Incoming edges to the node
// - both: Both outgoing and incoming edges
type EdgeDirection string

// EdgeTypeConfig Configuration for a specific edge type
type EdgeTypeConfig struct {
	// AllowSelfLoops Whether to allow edges from a node to itself
	AllowSelfLoops bool `json:"allow_self_loops,omitempty,omitzero"`

	// MaxWeight Maximum allowed edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum allowed edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// Name Edge type name (e.g., 'cites', 'similar_to')
	Name string `json:"name"`

	// RequiredMetadata Required metadata fields for this edge type
	RequiredMetadata []string `json:"required_metadata,omitempty,omitzero"`
}

// EdgesResponse defines model for EdgesResponse.
type EdgesResponse struct {
	// Count Total number of edges returned
	Count int    `json:"count,omitempty,omitzero"`
	Edges []Edge `json:"edges,omitempty,omitzero"`
}

// EmbedderConfig defines model for EmbedderConfig.
type EmbedderConfig struct {
	// Provider The embedding provider to use.
	Provider EmbedderProvider `json:"provider"`
	union    json.RawMessage
}

// EmbedderProvider The embedding provider to use.
type EmbedderProvider string

// EmbeddingIndexConfig defines model for EmbeddingIndexConfig.
type EmbeddingIndexConfig struct {
	// Chunker A unified configuration for a chunking provider.
	Chunker ChunkerConfig `json:"chunker,omitempty,omitzero"`

	// Dimension Vector dimension
	Dimension int `json:"dimension"`

	// Embedder A unified configuration for an embedding provider.
	//
	// Embedders can be configured with templates to customize how documents are
	// converted to text before embedding. Templates use Handlebars syntax and
	// support various built-in helpers.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full document as context
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active user{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// Document with metadata:
	// ```handlebars
	// Title: {{metadata.title}}
	// Date: {{metadata.date}}
	// Tags: {{#each metadata.tags}}{{this}}, {{/each}}
	//
	// {{content}}
	// ```
	//
	// HTML content extraction:
	// ```handlebars
	// Product: {{name}}
	// Description: {{scrubHtml description_html}}
	// Price: ${{price}}
	// ```
	//
	// Multimodal with image:
	// ```handlebars
	// Product: {{title}}
	// {{media url=image}}
	// Description: {{description}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{title}}
	// {{#if author}}By: {{author}}{{/if}}
	// {{#if (eq category "premium")}} Premium Content{{/if}}
	// {{body}}
	// ```
	//
	// **Environment Variables:**
	// - `GEMINI_API_KEY` - API key for Google AI
	// - `OPENAI_API_KEY` - API key for OpenAI
	// - `OPENAI_BASE_URL` - Base URL for OpenAI-compatible APIs
	// - `OLLAMA_HOST` - Ollama server URL (e.g., http://localhost:11434)
	//
	// **Importing Pre-computed Embeddings:**
	//
	// You can import existing embeddings (from OpenAI, Cohere, or any provider) by including
	// them directly in your documents using the `_embeddings` field. This bypasses the
	// embedding generation step and writes vectors directly to the index.
	//
	// **Steps:**
	// 1. Create the index first with the appropriate dimension
	// 2. Write documents with `_embeddings: { "<indexName>": [...<embedding>...] }`
	//
	// **Example:**
	// ```json
	// {
	//   "title": "My Document",
	//   "content": "Document text...",
	//   "_embeddings": {
	//     "my_vector_index": [0.1, 0.2, 0.3, ...]
	//   }
	// }
	// ```
	//
	// **Use Cases:**
	// - Migrating from another vector database with existing embeddings
	// - Using embeddings generated by external systems
	// - Importing pre-computed OpenAI, Cohere, or other provider embeddings
	// - Batch processing embeddings offline before ingestion
	Embedder EmbedderConfig `json:"embedder,omitempty,omitzero"`

	// Field Field to extract embeddings from
	Field string `json:"field,omitempty,omitzero"`

	// MemOnly Whether to use in-memory only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`

	// Summarizer A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Summarizer GeneratorConfig `json:"summarizer,omitempty,omitzero"`

	// Template Handlebars template for generating prompts. See https://handlebarsjs.com/guide/ for more information.
	Template string `json:"template,omitempty,omitzero"`
}

// EmbeddingIndexStats defines model for EmbeddingIndexStats.
type EmbeddingIndexStats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalIndexed Number of vectors in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`

	// TotalNodes Total number of nodes in the index
	TotalNodes uint64 `json:"total_nodes,omitempty,omitzero"`
}

// Error defines model for Error.
type Error struct {
	Error string `json:"error"`
}

// EvalConfig Configuration for inline evaluation of query results.
// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
type EvalConfig struct {
	// Evaluators List of evaluators to run
	Evaluators []EvaluatorName `json:"evaluators,omitempty,omitzero"`

	// GroundTruth Ground truth data for evaluation
	GroundTruth GroundTruth `json:"ground_truth,omitempty,omitzero"`

	// Judge A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Judge GeneratorConfig `json:"judge,omitempty,omitzero"`

	// Options Options for evaluation behavior
	Options EvalOptions `json:"options,omitempty,omitzero"`
}

// EvalOptions Options for evaluation behavior
type EvalOptions struct {
	// K K value for @K metrics (precision@k, recall@k, ndcg@k)
	K int `json:"k,omitempty,omitzero"`

	// PassThreshold Score threshold for pass/fail determination
	PassThreshold float32 `json:"pass_threshold,omitempty,omitzero"`

	// TimeoutSeconds Timeout for evaluation in seconds
	TimeoutSeconds int `json:"timeout_seconds,omitempty,omitzero"`
}

// EvalRequest Standalone evaluation request for POST /eval endpoint.
// Useful for testing evaluators without running a query.
type EvalRequest struct {
	// Context Retrieved documents/context
	Context []map[string]interface{} `json:"context,omitempty,omitzero"`

	// Evaluators List of evaluators to run
	Evaluators []EvaluatorName `json:"evaluators"`

	// GroundTruth Ground truth data for evaluation
	GroundTruth GroundTruth `json:"ground_truth,omitempty,omitzero"`

	// Judge A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Judge GeneratorConfig `json:"judge,omitempty,omitzero"`

	// Options Options for evaluation behavior
	Options EvalOptions `json:"options,omitempty,omitzero"`

	// Output Generated output to evaluate (optional for retrieval-only)
	Output string `json:"output,omitempty,omitzero"`

	// Query Original query/input to evaluate
	Query string `json:"query,omitempty,omitzero"`

	// RetrievedIds IDs of retrieved documents (for retrieval metrics)
	RetrievedIds []string `json:"retrieved_ids,omitempty,omitzero"`
}

// EvalResult Complete evaluation result
type EvalResult struct {
	// DurationMs Total evaluation duration in milliseconds
	DurationMs int `json:"duration_ms,omitempty,omitzero"`

	// Scores Scores organized by category
	Scores EvalScores `json:"scores,omitempty,omitzero"`

	// Summary Aggregate statistics across all evaluators
	Summary EvalSummary `json:"summary,omitempty,omitzero"`
}

// EvalScores Scores organized by category
type EvalScores struct {
	// Generation Generation quality scores (faithfulness, relevance, etc.)
	Generation map[string]EvaluatorScore `json:"generation,omitempty,omitzero"`

	// Retrieval Retrieval metric scores (recall, precision, ndcg, etc.)
	Retrieval map[string]EvaluatorScore `json:"retrieval,omitempty,omitzero"`
}

// EvalSummary Aggregate statistics across all evaluators
type EvalSummary struct {
	// AverageScore Average score across all evaluators
	AverageScore float32 `json:"average_score,omitempty,omitzero"`

	// Failed Number of evaluators that failed
	Failed int `json:"failed,omitempty,omitzero"`

	// Passed Number of evaluators that passed
	Passed int `json:"passed,omitempty,omitzero"`

	// Total Total number of evaluators run
	Total int `json:"total,omitempty,omitzero"`
}

// EvaluatorName Available evaluator types:
//
// **Retrieval metrics** (require ground_truth.relevant_ids):
// - recall: Recall@k - fraction of relevant docs retrieved
// - precision: Precision@k - fraction of retrieved docs that are relevant
// - ndcg: Normalized Discounted Cumulative Gain
// - mrr: Mean Reciprocal Rank
// - map: Mean Average Precision
//
// **LLM-as-judge metrics** (require judge config):
// - relevance: Is output relevant to query? (works on retrieval-only too)
// - faithfulness: Is output grounded in context?
// - completeness: Does output fully address query?
// - coherence: Is output well-structured?
// - safety: Is output safe/appropriate?
// - helpfulness: Is output useful?
// - correctness: Is output factually correct? (uses expectations)
// - citation_quality: Are citations accurate?
type EvaluatorName string

// EvaluatorScore Result from a single evaluator
type EvaluatorScore struct {
	// Metadata Additional evaluator-specific data
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`

	// Pass Whether the evaluation passed the threshold
	Pass bool `json:"pass,omitempty,omitzero"`

	// Reason Human-readable explanation of the result
	Reason string `json:"reason,omitempty,omitzero"`

	// Score Numeric score (0-1)
	Score float32 `json:"score,omitempty,omitzero"`
}

// FailedOperation defines model for FailedOperation.
type FailedOperation struct {
	Error     string                   `json:"error,omitempty,omitzero"`
	Id        string                   `json:"id,omitempty,omitzero"`
	Operation FailedOperationOperation `json:"operation,omitempty,omitzero"`
}

// FailedOperationOperation defines model for FailedOperation.Operation.
type FailedOperationOperation string

// FetchConfig Configuration for URL content fetching.
//
// Uses lib/scraping for downloading and processing. Supports:
// - HTTP/HTTPS URLs with security validation
// - HTML pages (extracts readable text via go-readability)
// - PDF files (extracts text)
// - Images (returns as data URIs)
// - Plain text files
// - S3 URLs (requires s3_credentials)
//
// Security features (from lib/scraping.ContentSecurityConfig):
// - Allowed host whitelist
// - Private IP blocking (SSRF prevention)
// - Download size limits
// - Timeout controls
type FetchConfig struct {
	// AllowedHosts Whitelist of allowed hostnames for fetching.
	// If empty, all hosts are allowed (except private IPs).
	// Example: ["docs.example.com", "api.example.com"]
	AllowedHosts []string `json:"allowed_hosts,omitempty,omitzero"`

	// BlockPrivateIps Block requests to private IP ranges (SSRF prevention).
	// Blocked: 127.0.0.0/8, 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16
	BlockPrivateIps *bool `json:"block_private_ips,omitempty"`

	// MaxContentLength Maximum content length in characters (truncated if exceeded)
	MaxContentLength int `json:"max_content_length,omitempty,omitzero"`

	// MaxDownloadSizeBytes Maximum download size in bytes (default: 100MB)
	MaxDownloadSizeBytes int         `json:"max_download_size_bytes,omitempty,omitzero"`
	S3Credentials        Credentials `json:"s3_credentials,omitempty,omitzero"`

	// TimeoutSeconds Download timeout in seconds
	TimeoutSeconds int `json:"timeout_seconds,omitempty,omitzero"`
}

// FieldStatistics Statistics about a specific field.
type FieldStatistics struct {
	// AvgSize Average size in bytes for variable-length fields.
	AvgSize int `json:"avg_size,omitempty,omitzero"`

	// Cardinality Approximate number of unique values (via HyperLogLog).
	Cardinality int64 `json:"cardinality,omitempty,omitzero"`

	// MaxValue Maximum value for numeric/date fields.
	MaxValue interface{} `json:"max_value,omitempty,omitzero"`

	// MinValue Minimum value for numeric/date fields.
	MinValue interface{} `json:"min_value,omitempty,omitzero"`

	// NullCount Number of rows with null values for this field.
	NullCount int64 `json:"null_count,omitempty,omitzero"`
}

// FilterSpec A filter specification to apply to search queries
type FilterSpec struct {
	// Field Field name to filter on
	Field string `json:"field"`

	// Operator Filter operator:
	// - eq: Equals
	// - ne: Not equals
	// - gt/gte: Greater than (or equal)
	// - lt/lte: Less than (or equal)
	// - contains: Contains substring
	// - prefix: Starts with
	// - range: Between two values (value should be array [min, max])
	// - in: Value in list (value should be array)
	Operator FilterSpecOperator `json:"operator"`

	// Value Filter value (string, number, boolean, or array for range/in operators)
	Value interface{} `json:"value"`
}

// FilterSpecOperator Filter operator:
// - eq: Equals
// - ne: Not equals
// - gt/gte: Greater than (or equal)
// - lt/lte: Less than (or equal)
// - contains: Contains substring
// - prefix: Starts with
// - range: Between two values (value should be array [min, max])
// - in: Value in list (value should be array)
type FilterSpecOperator string

// FollowupStepConfig Configuration for generating follow-up questions. Uses a separate generator
// call which can use a cheaper/faster model.
type FollowupStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Context Custom guidance for follow-up question focus and style
	Context string `json:"context,omitempty,omitzero"`

	// Count Number of follow-up questions to generate
	Count int `json:"count,omitempty,omitzero"`

	// Enabled Enable follow-up question generation
	Enabled bool `json:"enabled,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`
}

// Fuzziness The fuzziness of the query. Can be an integer or "auto".
type Fuzziness struct {
	union json.RawMessage
}

// Fuzziness0 defines model for .
type Fuzziness0 = int32

// Fuzziness1 defines model for Fuzziness.1.
type Fuzziness1 string

// FuzzyQuery defines model for FuzzyQuery.
type FuzzyQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness `json:"fuzziness,omitempty,omitzero"`
	PrefixLength int32     `json:"prefix_length,omitempty,omitzero"`
	Term         string    `json:"term"`
}

// GenerateResult Result of a generate operation. Formatted as markdown by default with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
type GenerateResult struct {
	// Text The generated text in markdown format with inline resource references like [resource_id res1] or [resource_id res1, res2]
	Text string `json:"text"`
}

// GeneratorConfig defines model for GeneratorConfig.
type GeneratorConfig struct {
	// Provider The generative AI provider to use.
	Provider GeneratorProvider `json:"provider"`
	union    json.RawMessage
}

// GeneratorProvider The generative AI provider to use.
type GeneratorProvider string

// GeoBoundingBoxQuery defines model for GeoBoundingBoxQuery.
type GeoBoundingBoxQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost `json:"boost,omitzero"`

	// BottomRight [lon, lat]
	BottomRight []float64 `json:"bottom_right"`
	Field       string    `json:"field,omitempty,omitzero"`

	// TopLeft [lon, lat]
	TopLeft []float64 `json:"top_left"`
}

// GeoBoundingPolygonQuery defines model for GeoBoundingPolygonQuery.
type GeoBoundingPolygonQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost         Boost      `json:"boost,omitzero"`
	Field         string     `json:"field,omitempty,omitzero"`
	PolygonPoints []GeoPoint `json:"polygon_points"`
}

// GeoDistanceQuery defines model for GeoDistanceQuery.
type GeoDistanceQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Distance string `json:"distance"`
	Field    string `json:"field,omitempty,omitzero"`

	// Location [lon, lat]
	Location []float64 `json:"location"`
}

// GeoPoint defines model for GeoPoint.
type GeoPoint struct {
	Lat float64 `json:"lat,omitempty,omitzero"`
	Lon float64 `json:"lon,omitempty,omitzero"`
}

// GeoShape A GeoJSON shape object. This is a simplified representation.
type GeoShape struct {
	Coordinates []interface{} `json:"coordinates"`
	Type        string        `json:"type"`
}

// GeoShapeGeometry defines model for GeoShapeGeometry.
type GeoShapeGeometry struct {
	Relation GeoShapeGeometryRelation `json:"relation"`

	// Shape A GeoJSON shape object. This is a simplified representation.
	Shape GeoShape `json:"shape"`
}

// GeoShapeGeometryRelation defines model for GeoShapeGeometry.Relation.
type GeoShapeGeometryRelation string

// GeoShapeQuery defines model for GeoShapeQuery.
type GeoShapeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost            `json:"boost,omitzero"`
	Field    string           `json:"field,omitempty,omitzero"`
	Geometry GeoShapeGeometry `json:"geometry"`
}

// GoogleEmbedderConfig Configuration for the Google AI (Gemini) embedding provider.
//
// API key via `api_key` field or `GEMINI_API_KEY` environment variable.
//
// **Example Models:** gemini-embedding-001 (default, 3072 dims)
//
// **Docs:** https://ai.google.dev/gemini-api/docs/embeddings
type GoogleEmbedderConfig struct {
	// ApiKey The Google API key. Can also be set via GEMINI_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimension The dimension of the embedding vector (768, 1536, or 3072 recommended).
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1'). Required for Vertex AI, optional for Gemini API.
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the embedding model to use.
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID (optional for Gemini API, required for Vertex AI).
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Url The URL of the Google API endpoint (optional, uses default if not specified).
	Url string `json:"url,omitempty,omitzero"`
}

// GoogleGeneratorConfig Configuration for the Google generative AI provider (Gemini).
//
// **Example Models:** gemini-2.5-flash (default), gemini-2.5-pro, gemini-3.0-pro
//
// **Docs:** https://ai.google.dev/gemini-api/docs/models
type GoogleGeneratorConfig struct {
	// ApiKey The Google API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1').
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the generative model to use (e.g., 'gemini-2.5-flash', 'gemini-2.5-pro', 'gemini-3.0-pro').
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Google API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// GoogleSearchConfig defines model for GoogleSearchConfig.
type GoogleSearchConfig struct {
	// ApiKey Google API key (or set GOOGLE_CSE_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// CseId Custom Search Engine ID (or set GOOGLE_CSE_ID env var)
	CseId string `json:"cse_id,omitempty,omitzero"`

	// DateRestrict Restrict results by date (e.g., 'd7' for last 7 days, 'm1' for last month)
	DateRestrict string `json:"date_restrict,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// SearchType Type of search to perform
	SearchType GoogleSearchConfigSearchType `json:"search_type,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// GoogleSearchConfigSearchType Type of search to perform
type GoogleSearchConfigSearchType string

// GraphIndexV0Config Configuration for graph_v0 index type
type GraphIndexV0Config struct {
	// EdgeTypes List of edge types with their configurations
	EdgeTypes []EdgeTypeConfig `json:"edge_types,omitempty,omitzero"`

	// MaxEdgesPerDocument Maximum number of edges per document (0 = unlimited)
	MaxEdgesPerDocument int `json:"max_edges_per_document,omitempty,omitzero"`
}

// GraphIndexV0Stats Statistics for graph_v0 index
type GraphIndexV0Stats struct {
	// EdgeTypes Count of edges per edge type
	EdgeTypes map[string]uint64 `json:"edge_types,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalEdges Total number of edges in the graph
	TotalEdges uint64 `json:"total_edges,omitempty,omitzero"`
}

// GraphNodeSelector Defines how to select start/target nodes for graph queries
type GraphNodeSelector struct {
	// Keys Explicit list of node keys
	Keys []string `json:"keys,omitempty,omitzero"`

	// Limit Maximum number of nodes to select from the referenced results
	Limit int `json:"limit,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`

	// ResultRef Reference to search results to use as nodes:
	// - "$full_text_results" - use full-text search results
	// - "$aknn_results.index_name" - use vector search results from specific index
	ResultRef string `json:"result_ref,omitempty,omitzero"`
}

// GraphQuery Declarative graph query to execute after full-text/vector searches
type GraphQuery struct {
	// Fields Which fields to return from documents
	Fields []string `json:"fields,omitempty,omitzero"`

	// IncludeDocuments Fetch full documents for graph results
	IncludeDocuments bool `json:"include_documents,omitempty,omitzero"`

	// IncludeEdges Include edge details for each node
	IncludeEdges bool `json:"include_edges,omitempty,omitzero"`

	// IndexName Graph index name (must be graph_v0 type)
	IndexName string `json:"index_name"`

	// Params Parameters for graph traversal and pathfinding
	Params GraphQueryParams `json:"params,omitempty,omitzero"`

	// Pattern Pattern steps for pattern query type
	Pattern []PatternStep `json:"pattern,omitempty,omitzero"`

	// ReturnAliases Which aliases to return from pattern query (empty = all)
	ReturnAliases []string `json:"return_aliases,omitempty,omitzero"`

	// StartNodes Defines how to select start/target nodes for graph queries
	StartNodes GraphNodeSelector `json:"start_nodes,omitempty,omitzero"`

	// TargetNodes Defines how to select start/target nodes for graph queries
	TargetNodes GraphNodeSelector `json:"target_nodes,omitempty,omitzero"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryParams Parameters for graph traversal and pathfinding
type GraphQueryParams struct {
	// Algorithm Graph algorithm to run (e.g., 'pagerank', 'betweenness')
	Algorithm string `json:"algorithm,omitempty,omitzero"`

	// AlgorithmParams Parameters for the graph algorithm
	AlgorithmParams map[string]interface{} `json:"algorithm_params,omitempty,omitzero"`

	// DeduplicateNodes Remove duplicate nodes (traversal)
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information (traversal)
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// K Number of paths to find (k-shortest-paths)
	K int `json:"k,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum number of results (traversal)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`

	// WeightMode Path weighting algorithm for pathfinding:
	// - min_hops: Minimize number of edges
	// - min_weight: Minimize sum of edge weights
	// - max_weight: Maximize product of edge weights
	WeightMode PathWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// GraphQueryResult Results of a graph query
type GraphQueryResult struct {
	// Matches Pattern matches (for pattern queries)
	Matches []PatternMatch `json:"matches,omitempty,omitzero"`

	// Nodes Result nodes
	Nodes []GraphResultNode `json:"nodes,omitempty,omitzero"`

	// Paths Result paths (for pathfinding queries)
	Paths []Path `json:"paths,omitempty,omitzero"`

	// Took Query execution time
	Took time.Duration `json:"took,omitempty,omitzero"`

	// Total Total number of results
	Total int `json:"total"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryType Type of graph query to execute
type GraphQueryType string

// GraphResultNode A node in graph query results
type GraphResultNode struct {
	// Depth Distance from start node
	Depth int `json:"depth,omitempty,omitzero"`

	// Distance Weighted distance
	Distance float64 `json:"distance,omitempty,omitzero"`

	// Document Full document (if include_documents=true)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Edges Connected edges (when include_edges=true)
	Edges []Edge `json:"edges,omitempty,omitzero"`

	// Key Document key
	Key string `json:"key"`

	// Path Keys in path from start to this node
	Path []string `json:"path,omitempty,omitzero"`

	// PathEdges Edges in path from start to this node
	PathEdges []PathEdge `json:"path_edges,omitempty,omitzero"`
}

// GroundTruth Ground truth data for evaluation
type GroundTruth struct {
	// Expectations Context for evaluators about what to expect in the response.
	// Provides guidance for LLM judges (e.g., "Should mention pricing tiers").
	Expectations string `json:"expectations,omitempty,omitzero"`

	// RelevantIds Document IDs known to be relevant (for retrieval metrics)
	RelevantIds []string `json:"relevant_ids,omitempty,omitzero"`
}

// IPRangeQuery defines model for IPRangeQuery.
type IPRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Cidr  string `json:"cidr"`
	Field string `json:"field,omitempty,omitzero"`
}

// IndexConfig Configuration for an index
type IndexConfig struct {
	// Description Optional description of the index and its purpose
	Description string `json:"description,omitempty,omitzero"`

	// Enrichments List of enrichment names to apply to documents before indexing. Enrichments must be defined at the table level.
	Enrichments []string `json:"enrichments,omitempty,omitzero"`

	// Name Name of the index
	Name string `json:"name"`

	// Type The type of the index.
	Type  IndexType `json:"type"`
	union json.RawMessage
}

// IndexStats Statistics for an index
type IndexStats struct {
	union json.RawMessage
}

// IndexStatus defines model for IndexStatus.
type IndexStatus struct {
	// Config Configuration for an index
	Config      IndexConfig           `json:"config"`
	ShardStatus map[string]IndexStats `json:"shard_status"`

	// Status Statistics for an index
	Status IndexStats `json:"status"`
}

// IndexType The type of the index.
type IndexType string

// JoinClause Configuration for joining data from another table.
// Supports inner, left, and right joins with automatic strategy selection.
type JoinClause struct {
	// JoinType Type of join to perform:
	// - `inner`: Only return rows with matches in both tables
	// - `left`: Return all rows from left table, NULL for non-matching right rows
	// - `right`: Return all rows from right table, NULL for non-matching left rows
	JoinType JoinType `json:"join_type,omitempty,omitzero"`

	// NestedJoin Optional nested join for multi-way joins.
	// The nested join operates on the result of the current join.
	NestedJoin *JoinClause `json:"nested_join"`

	// On Condition for matching rows between tables.
	On JoinCondition `json:"on"`

	// RightFields Fields to include from the right table in the result.
	// If not specified, all fields from the right table are included.
	// Fields are prefixed with the right table name in the result.
	RightFields []string `json:"right_fields,omitempty,omitzero"`

	// RightFilters Filters to apply to a table before joining.
	RightFilters JoinFilters `json:"right_filters,omitempty,omitzero"`

	// RightTable Name of the table to join with.
	RightTable string `json:"right_table"`

	// StrategyHint Strategy for executing the join:
	// - `broadcast`: Broadcast small table to all shards of large table.
	//   Best for dimension tables < 10MB. O(small_table) memory per shard.
	// - `index_lookup`: Use batch key lookups via indexes.
	//   Best for selective joins with indexed join keys. Low memory overhead.
	// - `shuffle`: Hash-partition both tables by join key.
	//   Best for large-large table joins. Requires data movement.
	StrategyHint JoinStrategy `json:"strategy_hint,omitempty,omitzero"`
}

// JoinCondition Condition for matching rows between tables.
type JoinCondition struct {
	// LeftField Field from the left (primary) table to match on.
	LeftField string `json:"left_field"`

	// Operator Comparison operator for join condition:
	// - `eq`: Equal (default)
	// - `neq`: Not equal
	// - `lt`: Less than
	// - `lte`: Less than or equal
	// - `gt`: Greater than
	// - `gte`: Greater than or equal
	Operator JoinOperator `json:"operator,omitempty,omitzero"`

	// RightField Field from the right (joined) table to match on.
	RightField string `json:"right_field"`
}

// JoinFilters Filters to apply to a table before joining.
type JoinFilters struct {
	// FilterPrefix Key prefix filter for the table.
	FilterPrefix []byte `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query to filter rows before joining.
	FilterQuery json.RawMessage `json:"filter_query,omitempty,omitzero"`

	// Limit Maximum number of rows to include from this table.
	Limit int `json:"limit,omitempty,omitzero"`
}

// JoinOperator Comparison operator for join condition:
// - `eq`: Equal (default)
// - `neq`: Not equal
// - `lt`: Less than
// - `lte`: Less than or equal
// - `gt`: Greater than
// - `gte`: Greater than or equal
type JoinOperator string

// JoinResult Statistics and metadata about join execution.
type JoinResult struct {
	// JoinTimeMs Time spent executing the join in milliseconds.
	JoinTimeMs int64 `json:"join_time_ms,omitempty,omitzero"`

	// LeftRowsScanned Number of rows scanned from the left table.
	LeftRowsScanned int64 `json:"left_rows_scanned,omitempty,omitzero"`

	// RightRowsScanned Number of rows scanned from the right table.
	RightRowsScanned int64 `json:"right_rows_scanned,omitempty,omitzero"`

	// RowsMatched Number of rows that matched the join condition.
	RowsMatched int64 `json:"rows_matched,omitempty,omitzero"`

	// RowsUnmatchedLeft Number of left rows without a match (for left/full joins).
	RowsUnmatchedLeft int64 `json:"rows_unmatched_left,omitempty,omitzero"`

	// RowsUnmatchedRight Number of right rows without a match (for right/full joins).
	RowsUnmatchedRight int64 `json:"rows_unmatched_right,omitempty,omitzero"`

	// StrategyUsed Strategy for executing the join:
	// - `broadcast`: Broadcast small table to all shards of large table.
	//   Best for dimension tables < 10MB. O(small_table) memory per shard.
	// - `index_lookup`: Use batch key lookups via indexes.
	//   Best for selective joins with indexed join keys. Low memory overhead.
	// - `shuffle`: Hash-partition both tables by join key.
	//   Best for large-large table joins. Requires data movement.
	StrategyUsed JoinStrategy `json:"strategy_used,omitempty,omitzero"`
}

// JoinStrategy Strategy for executing the join:
//   - `broadcast`: Broadcast small table to all shards of large table.
//     Best for dimension tables < 10MB. O(small_table) memory per shard.
//   - `index_lookup`: Use batch key lookups via indexes.
//     Best for selective joins with indexed join keys. Low memory overhead.
//   - `shuffle`: Hash-partition both tables by join key.
//     Best for large-large table joins. Requires data movement.
type JoinStrategy string

// JoinType Type of join to perform:
// - `inner`: Only return rows with matches in both tables
// - `left`: Return all rows from left table, NULL for non-matching right rows
// - `right`: Return all rows from right table, NULL for non-matching left rows
type JoinType string

// KeyRange Key range processed in this request
type KeyRange struct {
	From string `json:"from,omitempty,omitzero"`
	To   string `json:"to,omitempty,omitzero"`
}

// LinearMergePageStatus Status of a linear merge page operation:
// - "success": All records in batch processed successfully
// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
// - "error": Fatal error occurred, no records processed successfully
type LinearMergePageStatus string

// LinearMergeRequest Linear merge operation for syncing sorted records from external sources.
// Use this to keep Antfly in sync with an external database or data source.
//
// **How it works:**
// 1. Send sorted records from your external source
// 2. Server upserts records that exist in your batch
// 3. Server deletes Antfly records in the key range that are absent from your batch
// 4. If stopped at shard boundary, use next_cursor for next request
//
// **WARNING:** Not safe for concurrent operations with overlapping key ranges.
type LinearMergeRequest struct {
	// DryRun If true, returns what would be deleted without making changes.
	//
	// Use cases:
	// - Validate sync behavior before committing
	// - Check which records will be removed
	// - Test key range boundaries
	//
	// Response includes deleted_ids array when dry_run=true.
	DryRun bool `json:"dry_run,omitempty,omitzero"`

	// LastMergedId ID of last record from previous merge request.
	// - First request: Use empty string ""
	// - Subsequent requests: Use next_cursor from previous response
	// - Defines lower bound of key range to process
	//
	// This enables pagination for large datasets.
	LastMergedId string `json:"last_merged_id,omitempty,omitzero"`

	// Records Map of resource ID to resource object: {"resource_id_1": {...}, "resource_id_2": {...}}
	//
	// Requirements:
	// - Keys must be sorted lexicographically by your client
	// - Server will process keys in sorted order
	// - Use consistent key naming (e.g., all start with same prefix)
	//
	// This format avoids duplicate IDs and matches Antfly's batch write interface.
	Records map[string]interface{} `json:"records"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write
	// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`
}

// LinearMergeResult defines model for LinearMergeResult.
type LinearMergeResult struct {
	// Deleted Records deleted or would be deleted (if dry_run=true)
	Deleted int `json:"deleted"`

	// DeletedIds IDs that were deleted (or would be deleted if dry_run=true). Only included if dry_run=true.
	DeletedIds []string          `json:"deleted_ids,omitempty,omitzero"`
	Failed     []FailedOperation `json:"failed,omitempty,omitzero"`

	// KeyRange Key range processed in this request
	KeyRange KeyRange `json:"key_range,omitempty,omitzero"`

	// KeysScanned Total number of keys scanned from Antfly during range query
	KeysScanned int `json:"keys_scanned,omitempty,omitzero"`

	// Message Additional information (e.g., "stopped at shard boundary", "dry run - no changes made")
	Message string `json:"message,omitempty,omitzero"`

	// NextCursor ID of last record in this batch (use for next request)
	NextCursor string `json:"next_cursor"`

	// Skipped Records skipped because content hash matched (unchanged)
	Skipped int `json:"skipped"`

	// Status Status of a linear merge page operation:
	// - "success": All records in batch processed successfully
	// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
	// - "error": Fatal error occurred, no records processed successfully
	Status LinearMergePageStatus `json:"status"`
	Took   time.Duration         `json:"took,omitempty,omitzero"`

	// Upserted Records inserted or updated (0 if dry_run=true)
	Upserted int `json:"upserted"`
}

// MatchAllQuery defines model for MatchAllQuery.
type MatchAllQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost                  `json:"boost,omitzero"`
	MatchAll map[string]interface{} `json:"match_all"`
}

// MatchNoneQuery defines model for MatchNoneQuery.
type MatchNoneQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost                  `json:"boost,omitzero"`
	MatchNone map[string]interface{} `json:"match_none"`
}

// MatchPhraseQuery defines model for MatchPhraseQuery.
type MatchPhraseQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness   Fuzziness `json:"fuzziness,omitempty,omitzero"`
	MatchPhrase string    `json:"match_phrase"`
}

// MatchQuery defines model for MatchQuery.
type MatchQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness          `json:"fuzziness,omitempty,omitzero"`
	Match        string             `json:"match"`
	Operator     MatchQueryOperator `json:"operator,omitempty,omitzero"`
	PrefixLength int32              `json:"prefix_length,omitempty,omitzero"`
}

// MatchQueryOperator defines model for MatchQuery.Operator.
type MatchQueryOperator string

// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
// failover: Use full_text_search if embedding generation fails
type MergeStrategy string

// MultiPhraseQuery defines model for MultiPhraseQuery.
type MultiPhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness  `json:"fuzziness,omitempty,omitzero"`
	Terms     [][]string `json:"terms"`
}

// NodeFilter Filter nodes during graph traversal using existing query primitives
type NodeFilter struct {
	// FilterPrefix Filter by key prefix
	FilterPrefix string `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query to filter nodes (same syntax as search filter_query)
	FilterQuery map[string]interface{} `json:"filter_query,omitempty,omitzero"`
}

// NumericRangeQuery defines model for NumericRangeQuery.
type NumericRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost   `json:"boost,omitzero"`
	Field        string  `json:"field,omitempty,omitzero"`
	InclusiveMax bool    `json:"inclusive_max,omitzero"`
	InclusiveMin bool    `json:"inclusive_min,omitzero"`
	Max          float64 `json:"max,omitzero"`
	Min          float64 `json:"min,omitzero"`
}

// OllamaEmbedderConfig Configuration for the Ollama embedding provider.
//
// Local embeddings for privacy and offline use. URL via `url` field or `OLLAMA_HOST` env var.
//
// **Example Models:** nomic-embed-text (768 dims), mxbai-embed-large (1024 dims), all-minilm (384 dims)
//
// **Docs:** https://ollama.com/search?c=embedding
type OllamaEmbedderConfig struct {
	// Model The name of the Ollama model to use (e.g., 'nomic-embed-text', 'mxbai-embed-large').
	Model string `json:"model"`

	// Url The URL of the Ollama API endpoint. Can also be set via OLLAMA_HOST environment variable.
	Url string `json:"url,omitempty,omitzero"`
}

// OllamaGeneratorConfig Configuration for the Ollama generative AI provider.
//
// Ollama provides local LLM inference for privacy and offline use.
//
// **Example Models:** llama3.3:70b, qwen2.5:72b, deepseek-r1:70b, mistral:7b, llava:34b
//
// **Docs:** https://ollama.com/library
type OllamaGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Ollama model to use (e.g., 'llama3.3:70b', 'qwen2.5:72b', 'deepseek-coder:33b').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OllamaRerankerConfig Configuration for the Ollama reranking provider.
type OllamaRerankerConfig struct {
	// Model The name of the Ollama model to use for reranking.
	Model string `json:"model"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIEmbedderConfig Configuration for the OpenAI embedding provider.
//
// API key via `api_key` field or `OPENAI_API_KEY` environment variable.
// Supports OpenAI-compatible APIs via `url` field.
//
// **Example Models:** text-embedding-3-small (default, 1536 dims), text-embedding-3-large (3072 dims)
//
// **Docs:** https://platform.openai.com/docs/guides/embeddings
type OpenAIEmbedderConfig struct {
	// ApiKey The OpenAI API key. Can also be set via OPENAI_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimensions Output dimension for the embedding (uses MRL for dimension reduction). Recommended: 256, 512, 1024, 1536, or 3072.
	Dimensions int `json:"dimensions,omitempty,omitzero"`

	// Model The name of the OpenAI model to use.
	Model string `json:"model"`

	// Url The URL of the OpenAI API endpoint. Defaults to OpenAI's API. Can be set via OPENAI_BASE_URL environment variable.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIGeneratorConfig Configuration for the OpenAI generative AI provider.
//
// **Example Models:** gpt-4.1 (default), gpt-4.1-mini, o3, o4-mini
//
// **Docs:** https://platform.openai.com/docs/models
type OpenAIGeneratorConfig struct {
	// ApiKey The OpenAI API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (-2.0 to 2.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the OpenAI model to use (e.g., 'gpt-4.1', 'gpt-4.1-mini', 'o4-mini').
	Model string `json:"model"`

	// PresencePenalty Penalty for token presence (-2.0 to 2.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the OpenAI API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenRouterEmbedderConfig Configuration for the OpenRouter embedding provider.
//
// OpenRouter provides a unified API for multiple embedding models from different providers.
// API key via `api_key` field or `OPENROUTER_API_KEY` environment variable.
//
// **Example Models:** openai/text-embedding-3-small (default), openai/text-embedding-3-large,
// google/gemini-embedding-001, qwen/qwen3-embedding-8b
//
// **Docs:** https://openrouter.ai/docs/api/reference/embeddings
type OpenRouterEmbedderConfig struct {
	// ApiKey The OpenRouter API key. Can also be set via OPENROUTER_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimensions Output dimension for the embedding (if supported by the model).
	Dimensions int `json:"dimensions,omitempty,omitzero"`

	// Model The OpenRouter model identifier (e.g., 'openai/text-embedding-3-small', 'google/gemini-embedding-001').
	Model string `json:"model"`
}

// OpenRouterGeneratorConfig Configuration for the OpenRouter generative AI provider.
//
// OpenRouter provides a unified API for multiple LLM providers with automatic fallback routing.
// API key via `api_key` field or `OPENROUTER_API_KEY` environment variable.
//
// **Model Selection:**
// - Use `model` for a single model (e.g., "openai/gpt-4.1", "anthropic/claude-sonnet-4-5-20250929")
// - Use `models` array for fallback routing - OpenRouter tries models in order until one succeeds
//
// **Example Models:** openai/gpt-4.1, anthropic/claude-sonnet-4-5-20250929, google/gemini-2.5-flash,
// meta-llama/llama-3.3-70b-instruct
//
// **Docs:** https://openrouter.ai/docs/api/api-reference/chat/send-chat-completion-request
type OpenRouterGeneratorConfig struct {
	// ApiKey The OpenRouter API key. Can also be set via OPENROUTER_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (-2.0 to 2.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model Single model identifier (e.g., 'openai/gpt-4.1'). Either model or models must be provided.
	Model string `json:"model,omitempty,omitzero"`

	// Models Array of model identifiers for fallback routing. OpenRouter tries each model in order
	// until one succeeds. Either model or models must be provided.
	Models []string `json:"models,omitempty,omitzero"`

	// PresencePenalty Penalty for token presence (-2.0 to 2.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// Path defines model for Path.
type Path struct {
	Edges  []PathEdge `json:"edges,omitempty,omitzero"`
	Length int        `json:"length,omitempty,omitzero"`

	// Nodes Ordered list of node keys (base64-encoded)
	Nodes       []string `json:"nodes,omitempty,omitzero"`
	TotalWeight float64  `json:"total_weight,omitempty,omitzero"`
}

// PathEdge defines model for PathEdge.
type PathEdge struct {
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`
	Source   string                 `json:"source,omitempty,omitzero"`
	Target   string                 `json:"target,omitempty,omitzero"`
	Type     string                 `json:"type,omitempty,omitzero"`
	Weight   float64                `json:"weight,omitempty,omitzero"`
}

// PathFindRequest defines model for PathFindRequest.
type PathFindRequest struct {
	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by specific edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`
	K         int      `json:"k,omitempty,omitzero"`
	MaxDepth  int      `json:"max_depth,omitempty,omitzero"`
	MaxWeight float64  `json:"max_weight,omitempty,omitzero"`
	MinWeight float64  `json:"min_weight,omitempty,omitzero"`

	// Source Source node key (base64-encoded)
	Source string `json:"source"`

	// Target Target node key (base64-encoded)
	Target string `json:"target"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindResult defines model for PathFindResult.
type PathFindResult struct {
	Paths        []Path  `json:"paths,omitempty,omitzero"`
	PathsFound   int     `json:"paths_found,omitempty,omitzero"`
	SearchTimeMs float64 `json:"search_time_ms,omitempty,omitzero"`
	Source       string  `json:"source,omitempty,omitzero"`
	Target       string  `json:"target,omitempty,omitzero"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindWeightMode Algorithm for path finding:
// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
// - max_weight: Path with maximum product of edge weights (strongest connection chain)
// - min_weight: Path with minimum sum of edge weights (lowest cost route)
type PathFindWeightMode string

// PathWeightMode Path weighting algorithm for pathfinding:
// - min_hops: Minimize number of edges
// - min_weight: Minimize sum of edge weights
// - max_weight: Maximize product of edge weights
type PathWeightMode string

// PatternEdgeStep Edge constraints in a pattern step
type PatternEdgeStep struct {
	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// MaxHops Maximum number of hops (>1 = variable-length path)
	MaxHops int `json:"max_hops,omitempty,omitzero"`

	// MaxWeight Maximum edge weight filter
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinHops Minimum number of hops (1 = direct edge)
	MinHops int `json:"min_hops,omitempty,omitzero"`

	// MinWeight Minimum edge weight filter
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// Types Edge types to traverse (empty = any)
	Types []string `json:"types,omitempty,omitzero"`
}

// PatternMatch A single match from a pattern query
type PatternMatch struct {
	// Bindings Map of alias to matched node
	Bindings map[string]GraphResultNode `json:"bindings,omitempty,omitzero"`

	// Path Edges traversed in this match
	Path []PathEdge `json:"path,omitempty,omitzero"`
}

// PatternStep A step in a graph pattern query
type PatternStep struct {
	// Alias Name for this node (reuse alias for cycle detection)
	Alias string `json:"alias,omitempty,omitzero"`

	// Edge Edge constraints in a pattern step
	Edge PatternEdgeStep `json:"edge,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`
}

// Permission defines model for Permission.
type Permission struct {
	// Resource Resource name (e.g., table name, target username, or '*' for global).
	Resource string `json:"resource"`

	// ResourceType Type of the resource, e.g., table, user, or global ('*').
	ResourceType ResourceType `json:"resource_type"`

	// Type Type of permission.
	Type PermissionType `json:"type"`
}

// PermissionType Type of permission.
type PermissionType string

// PhraseQuery defines model for PhraseQuery.
type PhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness `json:"fuzziness,omitempty,omitzero"`
	Terms     []string  `json:"terms"`
}

// PrefixQuery defines model for PrefixQuery.
type PrefixQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Prefix string `json:"prefix"`
}

// Pruner Configuration for pruning search results based on score quality.
// Helps filter out low-relevance results in RAG pipelines by detecting
// score gaps or deviations from top results.
type Pruner struct {
	// MaxScoreGapPercent Stop returning results when score drops more than this percentage
	// from the previous result. Detects "elbows" in score distribution.
	// For example, 30.0 stops when score drops 30% from previous result.
	MaxScoreGapPercent float64 `json:"max_score_gap_percent,omitempty,omitzero"`

	// MinAbsoluteScore Hard minimum score threshold. Results with scores below this value
	// are excluded regardless of other pruning settings.
	MinAbsoluteScore float64 `json:"min_absolute_score,omitempty,omitzero"`

	// MinScoreRatio Keep only results with score >= max_score * min_score_ratio.
	// For example, 0.5 keeps results scoring at least half of the top result.
	// Applied after fusion scoring.
	MinScoreRatio float64 `json:"min_score_ratio,omitempty,omitzero"`

	// RequireMultiIndex Only keep results that appear in multiple indexes (both full-text
	// and vector search). Useful for increasing precision by requiring
	// agreement between different retrieval methods.
	RequireMultiIndex bool `json:"require_multi_index,omitempty,omitzero"`

	// StdDevThreshold Keep results within N standard deviations below the mean score.
	// For example, 1.0 keeps results with score >= mean - 1*stddev.
	// Useful for statistical outlier detection in result sets.
	StdDevThreshold float64 `json:"std_dev_threshold,omitempty,omitzero"`
}

// Query defines model for Query.
type Query struct {
	union json.RawMessage
}

// QueryBuilderRequest defines model for QueryBuilderRequest.
type QueryBuilderRequest struct {
	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// Intent Natural language description of the search intent
	Intent string `json:"intent"`

	// SchemaFields List of searchable field names to consider. Overrides table schema if provided.
	SchemaFields []string `json:"schema_fields,omitempty,omitzero"`

	// Table Name of the table to build query for. If provided, uses table schema for field context.
	Table string `json:"table,omitempty,omitzero"`
}

// QueryBuilderResult defines model for QueryBuilderResult.
type QueryBuilderResult struct {
	// Confidence Model's confidence in the generated query (0.0-1.0)
	Confidence float64 `json:"confidence,omitempty,omitzero"`

	// Explanation Human-readable explanation of what the query does and why it was structured this way
	Explanation string `json:"explanation,omitempty,omitzero"`

	// Query Generated search query in simplified DSL format.
	// Can be used directly in QueryRequest.full_text_search or filter_query.
	Query map[string]interface{} `json:"query"`

	// Warnings Any issues, limitations, or assumptions made when generating the query
	Warnings []string `json:"warnings,omitempty,omitzero"`
}

// QueryHit A single query result hit
type QueryHit struct {
	// ID ID of the record.
	ID string `json:"_id"`

	// IndexScores Scores partitioned by index when using RRF search.
	IndexScores map[string]interface{} `json:"_index_scores,omitempty,omitzero"`

	// Score Relevance score of the hit.
	Score  float64                `json:"_score"`
	Source map[string]interface{} `json:"_source,omitempty,omitzero"`
}

// QueryHits A list of query hits.
type QueryHits struct {
	Hits []QueryHit `json:"hits"`

	// MaxScore Maximum score of the results.
	MaxScore float64 `json:"max_score,omitempty,omitzero"`

	// Total Total number of hits available.
	Total uint64 `json:"total,omitempty"`
}

// QueryRequest defines model for QueryRequest.
type QueryRequest struct {
	// Aggregations Aggregation requests for computing metrics and bucketing results.
	// Each key is a user-defined name for the aggregation, and the value specifies the aggregation configuration.
	//
	// Supports metric aggregations (sum, avg, min, max, count, stats, cardinality),
	// bucketing aggregations (terms, range, date_range, histogram, date_histogram),
	// geo aggregations (geohash_grid, geo_distance), and analytics (significant_terms).
	//
	// Example:
	// ```json
	// {
	//   "price_stats": {
	//     "type": "stats",
	//     "field": "price"
	//   },
	//   "categories": {
	//     "type": "terms",
	//     "field": "category",
	//     "size": 10
	//   }
	// }
	// ```
	Aggregations map[string]AggregationRequest `json:"aggregations,omitempty,omitzero"`
	Analyses     *Analyses                     `json:"analyses,omitempty"`

	// Count If true, returns only the total count of matching documents without retrieving the actual documents.
	// Useful for pagination and displaying result counts.
	Count bool `json:"count,omitempty,omitzero"`

	// DistanceOver Minimum distance threshold for semantic similarity search. Results with distance
	// less than this value are excluded.
	//
	// Useful for excluding near-exact duplicates or finding dissimilar documents.
	DistanceOver *float32 `json:"distance_over,omitempty"`

	// DistanceUnder Maximum distance threshold for semantic similarity search. Results with distance
	// greater than this value are excluded. Lower distances indicate higher similarity.
	//
	// Useful for filtering out low-confidence matches.
	DistanceUnder *float32 `json:"distance_under,omitempty"`

	// DocumentRenderer Optional Handlebars template string for rendering document content in RAG queries.
	// Template has access to document fields via `{{this.fields.fieldName}}`.
	//
	// **Default**: Uses TOON (Token-Oriented Object Notation) format for 30-60% token reduction:
	// ```handlebars
	// {{encodeToon this.fields}}
	// ```
	//
	// **Available Helpers**:
	// - `encodeToon` - Renders fields in compact TOON format with configurable options:
	//   - `lengthMarker` (bool): Add # prefix to array counts (default: true)
	//   - `indent` (int): Indentation spacing (default: 2)
	//   - `delimiter` (string): Field separator for tabular arrays
	// - `scrubHtml` - Removes HTML tags and extracts text
	// - `media` - Wraps data URIs for GenKit multimodal support
	// - `eq` - Equality comparison for conditionals
	//
	// **Examples**:
	// - Basic TOON: `{{encodeToon this.fields}}`
	// - Compact TOON: `{{encodeToon this.fields lengthMarker=false indent=0}}`
	// - Tabular data: `{{encodeToon this.fields delimiter="\t"}}`
	// - Custom template: `Title: {{this.fields.title}}\nBody: {{this.fields.body}}`
	// - Traditional format: `{{#each this.fields}}{{@key}}: {{this}}\n{{/each}}`
	//
	// TOON format produces compact, LLM-optimized output like:
	// ```
	// title: Introduction to Vector Search
	// author: Jane Doe
	// tags[#3]: ai,search,ml
	// ```
	//
	// **References**:
	// - TOON Specification: https://github.com/toon-format/toon
	// - Go Implementation: https://github.com/alpkeskin/gotoon
	DocumentRenderer string `json:"document_renderer,omitempty,omitzero"`

	// EmbeddingTemplate Optional Handlebars template for multimodal embedding of the semantic_search query.
	// The template has access to `this` which contains the semantic_search string value.
	//
	// Use this when you want to embed multimodal content (images, PDFs, etc.) instead of
	// just text. The template is rendered using dotprompt with access to remote content helpers.
	//
	// **Available Helpers**:
	// - `remoteMedia url=<url>` - Fetches and embeds remote images/media
	// - `remotePDF url=<url>` - Fetches and extracts content from PDFs
	// - `remoteText url=<url>` - Fetches and includes remote text content
	//
	// **Examples**:
	// - PDF search: `{{remotePDF url=this}}`
	// - Image search: `{{remoteMedia url=this}}`
	// - Mixed: `Search for: {{this}} {{#if this}}{{remoteMedia url=this}}{{/if}}`
	//
	// When not specified, the semantic_search string is embedded as plain text.
	EmbeddingTemplate string `json:"embedding_template,omitempty,omitzero"`

	// Embeddings Pre-computed embeddings to use for semantic searches instead of embedding the semantic_search string.
	// The keys are the index names, and values are the embedding vectors.
	//
	// Use when you've already generated embeddings on the client side to avoid redundant embedding calls.
	Embeddings map[string][]float32 `json:"embeddings,omitempty,omitzero"`

	// ExclusionQuery Bleve query applied as a NOT condition. Documents matching this query are excluded
	// from results. Applied before scoring.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Excluding drafts: `"status:draft"`
	// - Removing deprecated content: `"deprecated:true"`
	// - Filtering out archived items: `"status:archived"`
	ExclusionQuery json.RawMessage `json:"exclusion_query,omitempty,omitzero"`

	// ExpandStrategy Strategy for merging graph results with search results:
	// - union: Include nodes from both search and graph results
	// - intersection: Only include nodes appearing in both
	ExpandStrategy QueryRequestExpandStrategy `json:"expand_strategy,omitempty,omitzero"`

	// Fields List of fields to include in the results. If not specified, all fields are returned.
	// Use to reduce response size and improve performance.
	Fields []string `json:"fields,omitempty,omitzero"`

	// FilterPrefix Filter results by key prefix. Only returns documents whose keys start with this string.
	// Applied before scoring to improve performance.
	//
	// Common use cases:
	// - Multi-tenant filtering: `"tenant:acme:"`
	// - User-specific data: `"user:123:"`
	// - Document type filtering: `"article:"`
	FilterPrefix []byte `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query applied as an AND condition. Documents must match both the main query
	// and this filter. Applied before scoring for better performance.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Status filtering: `"status:published"`
	// - Date ranges: `"created_at:>2023-01-01"`
	// - Category filtering: `"category:technology AND language:en"`
	FilterQuery json.RawMessage `json:"filter_query,omitempty,omitzero"`

	// FullTextSearch Bleve query for full-text search. Supports all Bleve query types.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Examples:
	// - Simple: `{"query": "computer"}`
	// - Field-specific: `{"query": "body:computer"}`
	// - Boolean: `{"query": "artificial AND intelligence"}`
	// - Range: `{"query": "year:>2020"}`
	// - Phrase: `{"query": "\"exact phrase\""}`
	FullTextSearch json.RawMessage `json:"full_text_search,omitempty,omitzero"`

	// GraphSearches Declarative graph queries to execute after full-text/vector searches.
	// Results can reference search results using node selectors like $full_text_results.
	GraphSearches map[string]GraphQuery `json:"graph_searches,omitempty,omitzero"`

	// Indexes List of vector index names to use for semantic search. Required when using semantic_search.
	// Multiple indexes can be specified, and their results will be merged using RRF.
	Indexes []string `json:"indexes,omitempty,omitzero"`

	// Join Configuration for joining data from another table.
	// Supports inner, left, and right joins with automatic strategy selection.
	Join JoinClause `json:"join,omitempty,omitzero"`

	// Limit Maximum number of results to return. For semantic_search, this is the topk parameter.
	// Default varies by query type (typically 10).
	Limit int `json:"limit,omitempty,omitzero"`

	// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
	// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
	// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
	// failover: Use full_text_search if embedding generation fails
	MergeStrategy MergeStrategy `json:"merge_strategy,omitempty,omitzero"`

	// Offset Number of results to skip for pagination. Only available for full_text_search queries.
	// Not supported for semantic_search due to vector index limitations.
	Offset int `json:"offset,omitempty,omitzero"`

	// OrderBy Sort order for results. Map of field names to boolean (true = descending, false = ascending).
	// Only applicable for full_text_search queries. Semantic searches are always sorted by similarity score.
	OrderBy map[string]bool `json:"order_by,omitempty,omitzero"`

	// Pruner Configuration for pruning search results based on score quality.
	// Helps filter out low-relevance results in RAG pipelines by detecting
	// score gaps or deviations from top results.
	Pruner Pruner `json:"pruner,omitempty,omitzero"`

	// Reranker A unified configuration for a reranking provider.
	Reranker *RerankerConfig `json:"reranker,omitempty"`

	// SemanticSearch Natural language query for vector similarity search. Results are ranked by semantic similarity
	// to the query and can be combined with full_text_search using Reciprocal Rank Fusion (RRF).
	//
	// The semantic_search string is automatically embedded using the configured embedding model
	// for the specified indexes. Use `embedding_template` for multimodal queries.
	SemanticSearch string `json:"semantic_search,omitempty,omitzero"`

	// Table Name of the table to query. Optional for global queries.
	Table string `json:"table,omitempty,omitzero"`
}

// QueryRequestExpandStrategy Strategy for merging graph results with search results:
// - union: Include nodes from both search and graph results
// - intersection: Only include nodes appearing in both
type QueryRequestExpandStrategy string

// QueryResponses Responses from multiple query operations.
type QueryResponses struct {
	Responses []QueryResult `json:"responses,omitempty,omitzero"`
}

// QueryResult Result of a query operation as an array of results and a count.
type QueryResult struct {
	// Aggregations Aggregation results keyed by the user-defined aggregation names from the request.
	// Contains computed metrics or buckets depending on the aggregation type.
	Aggregations map[string]AggregationResult `json:"aggregations,omitempty,omitzero"`

	// Analyses Analysis results like PCA and t-SNE per index embeddings.
	Analyses map[string]AnalysesResult `json:"analyses,omitempty,omitzero"`

	// Error Error message if the query failed.
	Error string `json:"error,omitempty,omitzero"`

	// GraphResults Results from declarative graph queries.
	GraphResults map[string]GraphQueryResult `json:"graph_results,omitempty,omitzero"`

	// Hits A list of query hits.
	Hits QueryHits `json:"hits"`

	// JoinResult Statistics and metadata about join execution.
	JoinResult JoinResult `json:"join_result,omitempty,omitzero"`

	// Status HTTP status code of the query operation.
	Status int32 `json:"status"`

	// Table Which table this result came from
	Table string `json:"table,omitempty,omitzero"`

	// Took Duration of the query in milliseconds.
	Took time.Duration `json:"took"`
}

// QueryStrategy Strategy for query transformation and retrieval:
// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
type QueryStrategy string

// QueryStringQuery defines model for QueryStringQuery.
type QueryStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Query string `json:"query"`
}

// RAGRequest defines model for RAGRequest.
type RAGRequest struct {
	// Chain Chain of generators with retry/fallback semantics. Mutually exclusive with 'generator'.
	// Each link can specify retry configuration and a condition for trying the next generator.
	// Either 'generator' or 'chain' must be provided.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Eval Configuration for inline evaluation of query results.
	// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
	Eval EvalConfig `json:"eval,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// Prompt Optional custom user prompt template for the LLM. If not provided, a default prompt is used.
	// The prompt can reference the following variables:
	// - {{documents}}: Array of retrieved documents with id and fields
	// - {{semantic_search}}: The user's semantic search query (if provided)
	// You can use Handlebars template syntax to customize the prompt, including loops and conditionals.
	// To generate a comma-separated list of document IDs, use: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	Prompt string `json:"prompt,omitempty,omitzero"`

	// Queries Array of retrieval queries to execute. Each query must specify a table and can specify its own limit and document_renderer.
	// Results from all queries are concatenated together (respecting each query's limit).
	// For single table: [{"table": "papers", "semantic_search": "...", "limit": 10}]
	// For broadcast: [{"table": "images", "limit": 5, ...}, {"table": "products", "limit": 5, ...}]
	// For mixed: [{"table": "papers", "semantic_search": "...", "limit": 10}, {"table": "books", "full_text_search": {...}, "limit": 5}]
	Queries []QueryRequest `json:"queries"`

	// SystemPrompt Optional system prompt to guide the summarization
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// RAGResult RAG result with individual query results and generation/evaluation outcome
type RAGResult struct {
	// EvalResult Complete evaluation result
	EvalResult EvalResult `json:"eval_result,omitempty,omitzero"`

	// GenerateResult Result of a generate operation. Formatted as markdown by default with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
	GenerateResult GenerateResult `json:"generate_result,omitempty,omitzero"`

	// QueryResults Results from each query. Check each result's status and error fields for failures.
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`
}

// RegexpQuery defines model for RegexpQuery.
type RegexpQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Regexp string `json:"regexp"`
}

// RerankerConfig defines model for RerankerConfig.
type RerankerConfig struct {
	// Field Field name to extract from documents for reranking.
	Field string `json:"field,omitempty,omitzero"`

	// Provider The reranking provider to use.
	Provider RerankerProvider `json:"provider"`

	// Template Handlebars template to render document text for reranking.
	Template string `json:"template,omitempty,omitzero"`
	union    json.RawMessage
}

// RerankerProvider The reranking provider to use.
type RerankerProvider string

// ResourceType Type of the resource, e.g., table, user, or global ('*').
type ResourceType string

// RestoreRequest defines model for RestoreRequest.
type RestoreRequest = BackupRequest

// RetryConfig Retry configuration for generator calls
type RetryConfig struct {
	// BackoffMultiplier Multiplier for exponential backoff
	BackoffMultiplier float32 `json:"backoff_multiplier,omitempty,omitzero"`

	// InitialBackoffMs Initial backoff delay in milliseconds
	InitialBackoffMs int `json:"initial_backoff_ms,omitempty,omitzero"`

	// MaxAttempts Maximum number of retry attempts
	MaxAttempts int `json:"max_attempts,omitempty,omitzero"`

	// MaxBackoffMs Maximum backoff delay in milliseconds
	MaxBackoffMs int `json:"max_backoff_ms,omitempty,omitzero"`
}

// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
type RouteType string

// ScanKeysRequest Request to scan keys in a table within a key range.
// If no range is specified, scans all keys in the table.
type ScanKeysRequest struct {
	// ExclusiveTo If true, exclude keys matching 'to' from the results.
	// Default: false (inclusive upper bound).
	ExclusiveTo bool `json:"exclusive_to,omitempty,omitzero"`

	// Fields List of fields to include in each result. If not specified,
	// only returns the key. Supports:
	// - Simple fields: "title", "author"
	// - Nested paths: "user.address.city"
	// - Wildcards: "_chunks.*"
	// - Exclusions: "-_chunks.*._embedding"
	// - Special fields: "_embeddings", "_summaries", "_chunks"
	Fields []string `json:"fields,omitempty,omitzero"`

	// FilterQuery Bleve query to filter documents. Only documents matching this query
	// are included in results. Uses the sear library for efficient per-document
	// matching without requiring a full index.
	//
	// Examples:
	// - Status filtering: `{"query": "status:published"}`
	// - Date ranges: `{"query": "created_at:>2023-01-01"}`
	// - Field matching: `{"query": "category:technology"}`
	FilterQuery json.RawMessage `json:"filter_query,omitempty,omitzero"`

	// From Start of the key range to scan (exclusive by default).
	// Can be a full key or a prefix. If not specified, starts from
	// the beginning of the table.
	From string `json:"from,omitempty,omitzero"`

	// InclusiveFrom If true, include keys matching 'from' in the results.
	// Default: false (exclusive lower bound for pagination).
	InclusiveFrom bool `json:"inclusive_from,omitempty,omitzero"`

	// Limit Maximum number of results to return. If not specified, returns all
	// matching keys in the range. Useful for pagination or sampling.
	Limit int `json:"limit,omitempty,omitzero"`

	// To End of the key range to scan (inclusive by default).
	// Can be a full key or a prefix. If not specified, scans to
	// the end of the table.
	To string `json:"to,omitempty,omitzero"`
}

// SemanticQueryMode Mode for semantic query generation:
// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
type SemanticQueryMode string

// SerperSearchConfig defines model for SerperSearchConfig.
type SerperSearchConfig struct {
	// ApiKey Serper API key (or set SERPER_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// SearchType Type of search to perform
	SearchType SerperSearchConfigSearchType `json:"search_type,omitempty,omitzero"`

	// TimePeriod Time period filter: d=day, w=week, m=month, y=year
	TimePeriod SerperSearchConfigTimePeriod `json:"time_period,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// SerperSearchConfigSearchType Type of search to perform
type SerperSearchConfigSearchType string

// SerperSearchConfigTimePeriod Time period filter: d=day, w=week, m=month, y=year
type SerperSearchConfigTimePeriod string

// ShardConfig defines model for ShardConfig.
type ShardConfig struct {
	ByteRange ByteRange `json:"byte_range"`
}

// SignificanceAlgorithm Algorithm for computing term significance:
// - jlh: JLH algorithm (default)
// - mutual_information: Mutual Information
// - chi_squared: Chi-squared test
// - percentage: Simple percentage comparison
type SignificanceAlgorithm string

// StorageStatus defines model for StorageStatus.
type StorageStatus struct {
	// DiskUsage Disk usage in bytes.
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Empty Whether the table has received data.
	Empty bool `json:"empty,omitempty,omitzero"`
}

// SuccessMessage defines model for SuccessMessage.
type SuccessMessage struct {
	Message string `json:"message,omitempty,omitzero"`
}

// SyncLevel Synchronization level for batch operations:
// - "propose": Wait for Raft proposal acceptance (fastest, default)
// - "write": Wait for Pebble KV write
// - "full_text": Wait for full-text index WAL write
// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
type SyncLevel string

// Table defines model for Table.
type Table struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema            `json:"schema,omitempty,omitzero"`
	Shards map[string]ShardConfig `json:"shards"`
}

// TableBackupStatus defines model for TableBackupStatus.
type TableBackupStatus struct {
	// Error Error message if backup failed
	Error string `json:"error,omitempty,omitzero"`

	// Name Table name
	Name string `json:"name"`

	// Status Backup status for this table
	Status TableBackupStatusStatus `json:"status"`
}

// TableBackupStatusStatus Backup status for this table
type TableBackupStatusStatus string

// TableRestoreStatus defines model for TableRestoreStatus.
type TableRestoreStatus struct {
	// Error Error message if restore failed
	Error string `json:"error,omitempty,omitzero"`

	// Name Table name
	Name string `json:"name"`

	// Status Restore status for this table
	Status TableRestoreStatusStatus `json:"status"`
}

// TableRestoreStatusStatus Restore status for this table
type TableRestoreStatusStatus string

// TableSchema Schema definition for a table with multiple document types
type TableSchema struct {
	// DefaultType Default type to use from the document_types.
	DefaultType string `json:"default_type,omitempty,omitzero"`

	// DocumentSchemas A map of type names to their document json schemas.
	DocumentSchemas map[string]DocumentSchema `json:"document_schemas,omitempty,omitzero"`

	// DynamicTemplates Rules for mapping dynamically detected fields. When a document contains fields
	// that don't have explicit mappings and dynamic mapping is enabled, templates are
	// evaluated in order to determine how those fields should be indexed.
	DynamicTemplates []DynamicTemplate `json:"dynamic_templates,omitempty,omitzero"`

	// EnforceTypes Whether to enforce that documents must match one of the provided document types.
	// If false, documents not matching any type will be accepted but not indexed.
	EnforceTypes bool `json:"enforce_types,omitempty,omitzero"`

	// TtlDuration The duration after which documents should expire, based on the ttl_field timestamp (optional).
	// Uses Go duration format (e.g., '24h', '7d', '168h').
	TtlDuration string `json:"ttl_duration,omitempty,omitzero"`

	// TtlField The field containing the timestamp for TTL expiration (optional).
	// Defaults to "_timestamp" if ttl_duration is specified but ttl_field is not.
	TtlField string `json:"ttl_field,omitempty,omitzero"`

	// Version Version of the schema. Used for migrations.
	Version uint32 `json:"version,omitempty,omitzero"`
}

// TableStatistics Statistics about a table used for query planning.
type TableStatistics struct {
	// FieldStats Per-field statistics for query optimization.
	FieldStats map[string]FieldStatistics `json:"field_stats,omitempty,omitzero"`

	// LastUpdated When these statistics were last computed.
	LastUpdated time.Time `json:"last_updated,omitempty,omitzero"`

	// RowCount Approximate number of rows in the table.
	RowCount int64 `json:"row_count,omitempty,omitzero"`

	// SizeBytes Approximate size of the table in bytes.
	SizeBytes int64 `json:"size_bytes,omitempty,omitzero"`
}

// TableStatus defines model for TableStatus.
type TableStatus struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema        TableSchema            `json:"schema,omitempty,omitzero"`
	Shards        map[string]ShardConfig `json:"shards"`
	StorageStatus StorageStatus          `json:"storage_status"`
}

// TavilySearchConfig defines model for TavilySearchConfig.
type TavilySearchConfig struct {
	// ApiKey Tavily API key (or set TAVILY_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// ExcludeDomains Exclude results from these domains
	ExcludeDomains []string `json:"exclude_domains,omitempty,omitzero"`

	// IncludeAnswer Include AI-generated answer summary
	IncludeAnswer bool `json:"include_answer,omitempty,omitzero"`

	// IncludeDomains Only include results from these domains
	IncludeDomains []string `json:"include_domains,omitempty,omitzero"`

	// IncludeRawContent Include raw HTML content of pages
	IncludeRawContent bool `json:"include_raw_content,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// SearchDepth Search depth:
	// - basic: Fast search with standard results
	// - advanced: Deeper search with more comprehensive results
	SearchDepth TavilySearchConfigSearchDepth `json:"search_depth,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// TavilySearchConfigSearchDepth Search depth:
// - basic: Fast search with standard results
// - advanced: Deeper search with more comprehensive results
type TavilySearchConfigSearchDepth string

// TemplateFieldMapping Field mapping to apply when a dynamic template matches
type TemplateFieldMapping struct {
	// Analyzer Analyzer name (e.g., "standard", "keyword", "en", "html_analyzer").
	// Used for text fields to control tokenization and normalization.
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// DocValues Whether to enable doc values for sorting/faceting
	DocValues bool `json:"doc_values,omitempty,omitzero"`

	// IncludeInAll Whether to include in the _all field for cross-field search
	IncludeInAll bool `json:"include_in_all,omitempty,omitzero"`

	// Index Whether to index the field (default true)
	Index bool `json:"index,omitempty,omitzero"`

	// Store Whether to store the field value (default false)
	Store bool `json:"store,omitempty,omitzero"`

	// Type Field type annotations for schema fields
	Type SchemasAntflyType `json:"type,omitempty,omitzero"`
}

// TermQuery defines model for TermQuery.
type TermQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
	Term  string `json:"term"`
}

// TermRangeQuery defines model for TermRangeQuery.
type TermRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost  `json:"boost,omitzero"`
	Field        string `json:"field,omitempty,omitzero"`
	InclusiveMax bool   `json:"inclusive_max,omitzero"`
	InclusiveMin bool   `json:"inclusive_min,omitzero"`
	Max          string `json:"max,omitzero"`
	Min          string `json:"min,omitzero"`
}

// TermiteChunkerConfig defines model for TermiteChunkerConfig.
type TermiteChunkerConfig struct {
	// ApiUrl The URL of the Termite API endpoint (e.g., 'http://localhost:8080'). Can also be set via ANTFLY_TERMITE_URL environment variable.
	ApiUrl string `json:"api_url,omitempty,omitzero"`

	// FullText Configuration for full-text indexing of chunks in Bleve.
	// When present (even if empty), chunks will be stored with :cft: suffix and indexed in Bleve's _chunks field.
	// When absent, chunks use :c: suffix and are only used for vector embeddings.
	// This object is reserved for future options like boosting, field mapping, etc.
	FullText map[string]interface{} `json:"full_text,omitempty,omitzero"`

	// MaxChunks Maximum number of chunks to generate per document.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// Model The chunking model to use. Either 'fixed' for simple token-based chunking, or a model name from models/chunkers/{name}/.
	Model string `json:"model"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries. Only used by fixed-size chunkers.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs). Only used by fixed-size chunkers.
	Separator string `json:"separator,omitempty,omitzero"`

	// TargetTokens Target number of tokens per chunk.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`

	// Threshold Minimum confidence threshold for separator detection (0.0-1.0). Only used by ONNX models.
	Threshold float32 `json:"threshold,omitempty,omitzero"`
}

// TermiteEmbedderConfig Configuration for the Termite embedding provider.
//
// Termite is Antfly's built-in ML service for local embeddings using ONNX models.
// It provides embedding generation with multi-tier caching (memory + persistent).
//
// **Features:**
// - Local ONNX-based embedding generation
// - L1 memory cache with configurable TTL
// - L2 persistent Pebble database cache
// - Singleflight deduplication for concurrent identical requests
//
// **Example Models:** bge-base-en-v1.5 (768 dims), all-MiniLM-L6-v2 (384 dims)
//
// Models are loaded from the `models/embedders/{name}/` directory.
type TermiteEmbedderConfig struct {
	// ApiUrl The URL of the Termite API endpoint. Can also be set via ANTFLY_TERMITE_URL environment variable.
	ApiUrl string `json:"api_url,omitempty,omitzero"`

	// Model The embedding model name (maps to models/embedders/{name}/ directory).
	Model string `json:"model"`
}

// TermiteGeneratorConfig Configuration for the Termite generative AI provider.
//
// Termite is Antfly's built-in ML service for local LLM inference using
// ONNX Runtime GenAI models. It provides text generation with automatic
// model discovery from the `models/generators/` directory.
//
// **Example Models:** onnxruntime/Gemma-3-ONNX (from HuggingFace)
//
// **Features:**
// - Local inference with no external API dependencies
// - ONNX Runtime GenAI for efficient CPU/GPU execution
// - Auto-discovery of models from `models/generators/` directory
// - OpenAI-compatible chat format
type TermiteGeneratorConfig struct {
	// ApiUrl The URL of the Termite API endpoint.
	ApiUrl string `json:"api_url,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the generator model (maps to models/generators/{name}/ directory).
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// TermiteRerankerConfig Configuration for the Termite reranking provider.
type TermiteRerankerConfig struct {
	// Model The name of the reranking model (e.g., cross-encoder model name).
	Model string `json:"model"`

	// Url The URL of the Termite API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// Transform In-place document transformation using MongoDB-style operators. Transforms are applied atomically
// at the storage layer, eliminating read-modify-write races.
//
// **Important:** Transform results are NOT validated against the table schema. This improves performance
// but means it's possible to create invalid documents. Use with care and ensure your operations maintain
// schema compliance.
type Transform struct {
	// Key Document key (must be a string, not an object like inserts)
	Key string `json:"key"`

	// Operations List of operations to apply in sequence
	Operations []TransformOp `json:"operations"`

	// Upsert If true, create document if it doesn't exist (like MongoDB upsert)
	Upsert bool `json:"upsert,omitempty,omitzero"`
}

// TransformOp defines model for TransformOp.
type TransformOp struct {
	// Op MongoDB-style update operator
	Op TransformOpType `json:"op"`

	// Path JSONPath to field (e.g., "$.user.name", "$.tags", or "user.name")
	Path string `json:"path"`

	// Value Value for operation (not required for $unset, $currentDate). Type depends on operator (number for $inc/$mul, any for $set, etc.)
	Value interface{} `json:"value,omitempty,omitzero"`
}

// TransformOpType MongoDB-style update operator
type TransformOpType string

// TraversalResult A single result from graph traversal
type TraversalResult struct {
	// Depth Distance from start node (0 = start node)
	Depth int `json:"depth"`

	// Document Document data (if loaded)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Key Base64-encoded document key
	Key []byte `json:"key"`

	// Path Sequence of keys from start to this node (if include_paths=true)
	Path [][]byte `json:"path,omitempty,omitzero"`

	// PathEdges Sequence of edges from start to this node (if include_paths=true)
	PathEdges []Edge `json:"path_edges,omitempty,omitzero"`

	// TotalWeight Product of edge weights along the path
	TotalWeight float64 `json:"total_weight,omitempty,omitzero"`
}

// TraversalRules Rules for graph traversal
type TraversalRules struct {
	// DeduplicateNodes Visit each node only once
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter edges by type (empty = all types)
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information in results
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth (0 = unlimited)
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum results to return (0 = unlimited)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight filter
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight filter
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`
}

// TraverseResponse defines model for TraverseResponse.
type TraverseResponse struct {
	// Count Total number of results
	Count   int               `json:"count,omitempty,omitzero"`
	Results []TraversalResult `json:"results,omitempty,omitzero"`
}

// UpdatePasswordRequest defines model for UpdatePasswordRequest.
type UpdatePasswordRequest struct {
	NewPassword string `json:"new_password"`
}

// User defines model for User.
type User struct {
	// PasswordHash Base64 encoded password hash. Exposing this is a security risk.
	PasswordHash []byte `json:"password_hash"`
	Username     string `json:"username"`
}

// VertexEmbedderConfig Configuration for Google Cloud Vertex AI embedding models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication. Requires IAM role `roles/aiplatform.user`.
//
// **Example Models:** gemini-embedding-001 (default, 3072 dims), multimodalembedding (images/audio/video)
//
// **Docs:** https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings
type VertexEmbedderConfig struct {
	// CredentialsPath Path to service account JSON key file. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Dimension The dimension of the embedding vector (768, 1536, or 3072 for gemini-embedding-001; 128-1408 for multimodalembedding).
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the Vertex AI embedding model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`
}

// VertexGeneratorConfig Configuration for Google Cloud Vertex AI generative models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication. In GCP environments
// (Cloud Run, GKE, Compute Engine) this is automatic. For local dev, run
// `gcloud auth application-default login`. Requires IAM role `roles/aiplatform.user`.
//
// **Example Models:** gemini-2.5-flash (default), gemini-2.5-pro, gemini-3.0-pro
//
// **Docs:** https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models
type VertexGeneratorConfig struct {
	// CredentialsPath Path to service account JSON key file. Sets GOOGLE_APPLICATION_CREDENTIALS environment variable. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Vertex AI model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// VertexRerankerConfig Configuration for the Google Vertex AI Ranking API.
//
// Uses Application Default Credentials (ADC) or explicit credentials path.
//
// **Prerequisites:**
// - Enable Discovery Engine API: `gcloud services enable discoveryengine.googleapis.com`
// - Grant IAM role: `roles/discoveryengine.admin` (includes `discoveryengine.rankingConfigs.rank` permission)
//
// **Models:** semantic-ranker-default@latest (default), semantic-ranker-fast-004
//
// **Docs:** https://cloud.google.com/generative-ai-app-builder/docs/ranking
//
// **IAM:** https://cloud.google.com/generative-ai-app-builder/docs/access-control
type VertexRerankerConfig struct {
	// CredentialsPath Path to service account JSON file. Falls back to GOOGLE_APPLICATION_CREDENTIALS environment variable.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Model The ranking model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Falls back to GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// TopN Maximum number of records to return. If not specified, returns all documents with scores.
	TopN int `json:"top_n,omitempty,omitzero"`
}

// WebSearchConfig A unified configuration for web search providers.
//
// Each provider has specific configuration requirements. Use the appropriate
// provider-specific config or set common options at the top level.
//
// **Environment Variables (fallbacks):**
// - GOOGLE_CSE_API_KEY, GOOGLE_CSE_ID
// - BING_SEARCH_API_KEY
// - SERPER_API_KEY
// - TAVILY_API_KEY
// - BRAVE_API_KEY
type WebSearchConfig struct {
	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// WebSearchProvider The web search provider to use.
//
// - **google**: Google Custom Search API (requires CSE setup)
// - **bing**: Microsoft Bing Web Search API
// - **serper**: Serper.dev Google Search API (simpler setup)
// - **tavily**: Tavily AI Search API (optimized for RAG)
// - **brave**: Brave Search API
// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
type WebSearchProvider string

// WildcardQuery defines model for WildcardQuery.
type WildcardQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Field    string `json:"field,omitempty,omitzero"`
	Wildcard string `json:"wildcard"`
}

// SchemasAntflyType Field type annotations for schema fields
type SchemasAntflyType string

// SchemasChatAgentResult Result from the chat agent. Contains the assistant's response,
// any pending clarifications, applied filters, and conversation state.
type SchemasChatAgentResult struct {
	// Answer Final answer text (if available)
	Answer string `json:"answer,omitempty,omitzero"`

	// AnswerConfidence Confidence in the answer
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// AppliedFilters Filters that have been applied in this conversation
	AppliedFilters []FilterSpec `json:"applied_filters,omitempty,omitzero"`

	// Messages Updated conversation history including the assistant's response
	Messages []ChatMessage `json:"messages"`

	// PendingClarification A request for clarification from the user
	PendingClarification ClarificationRequest `json:"pending_clarification,omitempty,omitzero"`

	// QueryResults Search results from executed queries
	QueryResults []map[string]interface{} `json:"query_results,omitempty,omitzero"`

	// ToolCallsMade Number of tool calls made in this turn
	ToolCallsMade int `json:"tool_calls_made,omitempty,omitzero"`
}

// UserNamePathParameter defines model for UserNamePathParameter.
type UserNamePathParameter = string

// BadRequest defines model for BadRequest.
type BadRequest = Error

// InternalServerError defines model for InternalServerError.
type InternalServerError = Error

// NotFound defines model for NotFound.
type NotFound = Error

// ListBackupsParams defines parameters for ListBackups.
type ListBackupsParams struct {
	// Location Storage location to search for backups.
	// - Local filesystem: `file:///path/to/backup`
	// - Amazon S3: `s3://bucket-name/path/to/backup`
	Location string `form:"location" json:"location"`
}

// ListTablesParams defines parameters for ListTables.
type ListTablesParams struct {
	// Prefix Filter tables by name prefix (e.g., "prod_")
	Prefix string `form:"prefix,omitempty" json:"prefix,omitempty,omitzero"`

	// Pattern Filter tables by regex pattern (e.g., "^prod_.*_v[0-9]+$")
	Pattern string `form:"pattern,omitempty" json:"pattern,omitempty,omitzero"`
}

// LookupKeyParams defines parameters for LookupKey.
type LookupKeyParams struct {
	// Fields Comma-separated list of fields to include in the response.
	// If not specified, returns the full document. Supports:
	// - Simple fields: "title,author"
	// - Nested paths: "user.address.city"
	// - Wildcards: "_chunks.*"
	// - Exclusions: "-_chunks.*._embedding"
	// - Special fields: "_embeddings,_summaries,_chunks"
	Fields string `form:"fields,omitempty" json:"fields,omitempty,omitzero"`
}

// RemovePermissionFromUserParams defines parameters for RemovePermissionFromUser.
type RemovePermissionFromUserParams struct {
	// Resource The name of the resource for the permission to be removed.
	Resource string `form:"resource" json:"resource"`

	// ResourceType The type of the resource for the permission to be removed.
	ResourceType ResourceType `form:"resourceType" json:"resourceType"`
}

// AnswerAgentJSONRequestBody defines body for AnswerAgent for application/json ContentType.
type AnswerAgentJSONRequestBody = AnswerAgentRequest

// ChatAgentJSONRequestBody defines body for ChatAgent for application/json ContentType.
type ChatAgentJSONRequestBody = ChatAgentRequest

// QueryBuilderAgentJSONRequestBody defines body for QueryBuilderAgent for application/json ContentType.
type QueryBuilderAgentJSONRequestBody = QueryBuilderRequest

// BackupJSONRequestBody defines body for Backup for application/json ContentType.
type BackupJSONRequestBody = ClusterBackupRequest

// EvaluateJSONRequestBody defines body for Evaluate for application/json ContentType.
type EvaluateJSONRequestBody = EvalRequest

// GlobalQueryJSONRequestBody defines body for GlobalQuery for application/json ContentType.
type GlobalQueryJSONRequestBody = QueryRequest

// RagQueryJSONRequestBody defines body for RagQuery for application/json ContentType.
type RagQueryJSONRequestBody = RAGRequest

// RestoreJSONRequestBody defines body for Restore for application/json ContentType.
type RestoreJSONRequestBody = ClusterRestoreRequest

// CreateTableJSONRequestBody defines body for CreateTable for application/json ContentType.
type CreateTableJSONRequestBody = CreateTableRequest

// BackupTableJSONRequestBody defines body for BackupTable for application/json ContentType.
type BackupTableJSONRequestBody = BackupRequest

// BatchWriteJSONRequestBody defines body for BatchWrite for application/json ContentType.
type BatchWriteJSONRequestBody = BatchRequest

// CreateIndexJSONRequestBody defines body for CreateIndex for application/json ContentType.
type CreateIndexJSONRequestBody = IndexConfig

// ScanKeysJSONRequestBody defines body for ScanKeys for application/json ContentType.
type ScanKeysJSONRequestBody = ScanKeysRequest

// LinearMergeJSONRequestBody defines body for LinearMerge for application/json ContentType.
type LinearMergeJSONRequestBody = LinearMergeRequest

// QueryTableJSONRequestBody defines body for QueryTable for application/json ContentType.
type QueryTableJSONRequestBody = QueryRequest

// TableRagQueryJSONRequestBody defines body for TableRagQuery for application/json ContentType.
type TableRagQueryJSONRequestBody = RAGRequest

// RestoreTableJSONRequestBody defines body for RestoreTable for application/json ContentType.
type RestoreTableJSONRequestBody = RestoreRequest

// UpdateSchemaJSONRequestBody defines body for UpdateSchema for application/json ContentType.
type UpdateSchemaJSONRequestBody = TableSchema

// CreateUserJSONRequestBody defines body for CreateUser for application/json ContentType.
type CreateUserJSONRequestBody = CreateUserRequest

// UpdateUserPasswordJSONRequestBody defines body for UpdateUserPassword for application/json ContentType.
type UpdateUserPasswordJSONRequestBody = UpdatePasswordRequest

// AddPermissionToUserJSONRequestBody defines body for AddPermissionToUser for application/json ContentType.
type AddPermissionToUserJSONRequestBody = Permission

// Getter for additional properties for ClusterStatus. Returns the specified
// element and whether it was found
func (a ClusterStatus) Get(fieldName string) (value interface{}, found bool) {
	if a.AdditionalProperties != nil {
		value, found = a.AdditionalProperties[fieldName]
	}
	return
}

// Setter for additional properties for ClusterStatus
func (a *ClusterStatus) Set(fieldName string, value interface{}) {
	if a.AdditionalProperties == nil {
		a.AdditionalProperties = make(map[string]interface{})
	}
	a.AdditionalProperties[fieldName] = value
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a *ClusterStatus) UnmarshalJSON(b []byte) error {
	object := make(map[string]json.RawMessage)
	err := json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["auth_enabled"]; found {
		err = json.Unmarshal(raw, &a.AuthEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'auth_enabled': %w", err)
		}
		delete(object, "auth_enabled")
	}

	if raw, found := object["health"]; found {
		err = json.Unmarshal(raw, &a.Health)
		if err != nil {
			return fmt.Errorf("error reading 'health': %w", err)
		}
		delete(object, "health")
	}

	if raw, found := object["message"]; found {
		err = json.Unmarshal(raw, &a.Message)
		if err != nil {
			return fmt.Errorf("error reading 'message': %w", err)
		}
		delete(object, "message")
	}

	if len(object) != 0 {
		a.AdditionalProperties = make(map[string]interface{})
		for fieldName, fieldBuf := range object {
			var fieldVal interface{}
			err := json.Unmarshal(fieldBuf, &fieldVal)
			if err != nil {
				return fmt.Errorf("error unmarshaling field %s: %w", fieldName, err)
			}
			a.AdditionalProperties[fieldName] = fieldVal
		}
	}
	return nil
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a ClusterStatus) MarshalJSON() ([]byte, error) {
	var err error
	object := make(map[string]json.RawMessage)

	object["auth_enabled"], err = json.Marshal(a.AuthEnabled)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'auth_enabled': %w", err)
	}

	object["health"], err = json.Marshal(a.Health)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'health': %w", err)
	}

	object["message"], err = json.Marshal(a.Message)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'message': %w", err)
	}

	for fieldName, field := range a.AdditionalProperties {
		object[fieldName], err = json.Marshal(field)
		if err != nil {
			return nil, fmt.Errorf("error marshaling '%s': %w", fieldName, err)
		}
	}
	return json.Marshal(object)
}

// AsTermiteChunkerConfig returns the union data inside the ChunkerConfig as a TermiteChunkerConfig
func (t ChunkerConfig) AsTermiteChunkerConfig() (TermiteChunkerConfig, error) {
	var body TermiteChunkerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteChunkerConfig overwrites any union data inside the ChunkerConfig as the provided TermiteChunkerConfig
func (t *ChunkerConfig) FromTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteChunkerConfig performs a merge with any union data inside the ChunkerConfig, using the provided TermiteChunkerConfig
func (t *ChunkerConfig) MergeTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAntflyChunkerConfig returns the union data inside the ChunkerConfig as a AntflyChunkerConfig
func (t ChunkerConfig) AsAntflyChunkerConfig() (AntflyChunkerConfig, error) {
	var body AntflyChunkerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAntflyChunkerConfig overwrites any union data inside the ChunkerConfig as the provided AntflyChunkerConfig
func (t *ChunkerConfig) FromAntflyChunkerConfig(v AntflyChunkerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAntflyChunkerConfig performs a merge with any union data inside the ChunkerConfig, using the provided AntflyChunkerConfig
func (t *ChunkerConfig) MergeAntflyChunkerConfig(v AntflyChunkerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t ChunkerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *ChunkerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsGoogleEmbedderConfig returns the union data inside the EmbedderConfig as a GoogleEmbedderConfig
func (t EmbedderConfig) AsGoogleEmbedderConfig() (GoogleEmbedderConfig, error) {
	var body GoogleEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided GoogleEmbedderConfig
func (t *EmbedderConfig) FromGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided GoogleEmbedderConfig
func (t *EmbedderConfig) MergeGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexEmbedderConfig returns the union data inside the EmbedderConfig as a VertexEmbedderConfig
func (t EmbedderConfig) AsVertexEmbedderConfig() (VertexEmbedderConfig, error) {
	var body VertexEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided VertexEmbedderConfig
func (t *EmbedderConfig) FromVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided VertexEmbedderConfig
func (t *EmbedderConfig) MergeVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaEmbedderConfig returns the union data inside the EmbedderConfig as a OllamaEmbedderConfig
func (t EmbedderConfig) AsOllamaEmbedderConfig() (OllamaEmbedderConfig, error) {
	var body OllamaEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OllamaEmbedderConfig
func (t *EmbedderConfig) FromOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OllamaEmbedderConfig
func (t *EmbedderConfig) MergeOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIEmbedderConfig returns the union data inside the EmbedderConfig as a OpenAIEmbedderConfig
func (t EmbedderConfig) AsOpenAIEmbedderConfig() (OpenAIEmbedderConfig, error) {
	var body OpenAIEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) FromOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) MergeOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenRouterEmbedderConfig returns the union data inside the EmbedderConfig as a OpenRouterEmbedderConfig
func (t EmbedderConfig) AsOpenRouterEmbedderConfig() (OpenRouterEmbedderConfig, error) {
	var body OpenRouterEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenRouterEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OpenRouterEmbedderConfig
func (t *EmbedderConfig) FromOpenRouterEmbedderConfig(v OpenRouterEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenRouterEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OpenRouterEmbedderConfig
func (t *EmbedderConfig) MergeOpenRouterEmbedderConfig(v OpenRouterEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockEmbedderConfig returns the union data inside the EmbedderConfig as a BedrockEmbedderConfig
func (t EmbedderConfig) AsBedrockEmbedderConfig() (BedrockEmbedderConfig, error) {
	var body BedrockEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided BedrockEmbedderConfig
func (t *EmbedderConfig) FromBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided BedrockEmbedderConfig
func (t *EmbedderConfig) MergeBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereEmbedderConfig returns the union data inside the EmbedderConfig as a CohereEmbedderConfig
func (t EmbedderConfig) AsCohereEmbedderConfig() (CohereEmbedderConfig, error) {
	var body CohereEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided CohereEmbedderConfig
func (t *EmbedderConfig) FromCohereEmbedderConfig(v CohereEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided CohereEmbedderConfig
func (t *EmbedderConfig) MergeCohereEmbedderConfig(v CohereEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermiteEmbedderConfig returns the union data inside the EmbedderConfig as a TermiteEmbedderConfig
func (t EmbedderConfig) AsTermiteEmbedderConfig() (TermiteEmbedderConfig, error) {
	var body TermiteEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided TermiteEmbedderConfig
func (t *EmbedderConfig) FromTermiteEmbedderConfig(v TermiteEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided TermiteEmbedderConfig
func (t *EmbedderConfig) MergeTermiteEmbedderConfig(v TermiteEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t EmbedderConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *EmbedderConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsFuzziness0 returns the union data inside the Fuzziness as a Fuzziness0
func (t Fuzziness) AsFuzziness0() (Fuzziness0, error) {
	var body Fuzziness0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness0 overwrites any union data inside the Fuzziness as the provided Fuzziness0
func (t *Fuzziness) FromFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness0 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness0
func (t *Fuzziness) MergeFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzziness1 returns the union data inside the Fuzziness as a Fuzziness1
func (t Fuzziness) AsFuzziness1() (Fuzziness1, error) {
	var body Fuzziness1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness1 overwrites any union data inside the Fuzziness as the provided Fuzziness1
func (t *Fuzziness) FromFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness1 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness1
func (t *Fuzziness) MergeFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Fuzziness) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Fuzziness) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsGoogleGeneratorConfig returns the union data inside the GeneratorConfig as a GoogleGeneratorConfig
func (t GeneratorConfig) AsGoogleGeneratorConfig() (GoogleGeneratorConfig, error) {
	var body GoogleGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided GoogleGeneratorConfig
func (t *GeneratorConfig) FromGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided GoogleGeneratorConfig
func (t *GeneratorConfig) MergeGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexGeneratorConfig returns the union data inside the GeneratorConfig as a VertexGeneratorConfig
func (t GeneratorConfig) AsVertexGeneratorConfig() (VertexGeneratorConfig, error) {
	var body VertexGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided VertexGeneratorConfig
func (t *GeneratorConfig) FromVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided VertexGeneratorConfig
func (t *GeneratorConfig) MergeVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaGeneratorConfig returns the union data inside the GeneratorConfig as a OllamaGeneratorConfig
func (t GeneratorConfig) AsOllamaGeneratorConfig() (OllamaGeneratorConfig, error) {
	var body OllamaGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OllamaGeneratorConfig
func (t *GeneratorConfig) FromOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OllamaGeneratorConfig
func (t *GeneratorConfig) MergeOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermiteGeneratorConfig returns the union data inside the GeneratorConfig as a TermiteGeneratorConfig
func (t GeneratorConfig) AsTermiteGeneratorConfig() (TermiteGeneratorConfig, error) {
	var body TermiteGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided TermiteGeneratorConfig
func (t *GeneratorConfig) FromTermiteGeneratorConfig(v TermiteGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided TermiteGeneratorConfig
func (t *GeneratorConfig) MergeTermiteGeneratorConfig(v TermiteGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIGeneratorConfig returns the union data inside the GeneratorConfig as a OpenAIGeneratorConfig
func (t GeneratorConfig) AsOpenAIGeneratorConfig() (OpenAIGeneratorConfig, error) {
	var body OpenAIGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) FromOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) MergeOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenRouterGeneratorConfig returns the union data inside the GeneratorConfig as a OpenRouterGeneratorConfig
func (t GeneratorConfig) AsOpenRouterGeneratorConfig() (OpenRouterGeneratorConfig, error) {
	var body OpenRouterGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenRouterGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OpenRouterGeneratorConfig
func (t *GeneratorConfig) FromOpenRouterGeneratorConfig(v OpenRouterGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenRouterGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OpenRouterGeneratorConfig
func (t *GeneratorConfig) MergeOpenRouterGeneratorConfig(v OpenRouterGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockGeneratorConfig returns the union data inside the GeneratorConfig as a BedrockGeneratorConfig
func (t GeneratorConfig) AsBedrockGeneratorConfig() (BedrockGeneratorConfig, error) {
	var body BedrockGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided BedrockGeneratorConfig
func (t *GeneratorConfig) FromBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided BedrockGeneratorConfig
func (t *GeneratorConfig) MergeBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAnthropicGeneratorConfig returns the union data inside the GeneratorConfig as a AnthropicGeneratorConfig
func (t GeneratorConfig) AsAnthropicGeneratorConfig() (AnthropicGeneratorConfig, error) {
	var body AnthropicGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAnthropicGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) FromAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAnthropicGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) MergeAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereGeneratorConfig returns the union data inside the GeneratorConfig as a CohereGeneratorConfig
func (t GeneratorConfig) AsCohereGeneratorConfig() (CohereGeneratorConfig, error) {
	var body CohereGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided CohereGeneratorConfig
func (t *GeneratorConfig) FromCohereGeneratorConfig(v CohereGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided CohereGeneratorConfig
func (t *GeneratorConfig) MergeCohereGeneratorConfig(v CohereGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t GeneratorConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *GeneratorConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Config returns the union data inside the IndexConfig as a BleveIndexV2Config
func (t IndexConfig) AsBleveIndexV2Config() (BleveIndexV2Config, error) {
	var body BleveIndexV2Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Config overwrites any union data inside the IndexConfig as the provided BleveIndexV2Config
func (t *IndexConfig) FromBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Config performs a merge with any union data inside the IndexConfig, using the provided BleveIndexV2Config
func (t *IndexConfig) MergeBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexConfig returns the union data inside the IndexConfig as a EmbeddingIndexConfig
func (t IndexConfig) AsEmbeddingIndexConfig() (EmbeddingIndexConfig, error) {
	var body EmbeddingIndexConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexConfig overwrites any union data inside the IndexConfig as the provided EmbeddingIndexConfig
func (t *IndexConfig) FromEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexConfig performs a merge with any union data inside the IndexConfig, using the provided EmbeddingIndexConfig
func (t *IndexConfig) MergeEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Config returns the union data inside the IndexConfig as a GraphIndexV0Config
func (t IndexConfig) AsGraphIndexV0Config() (GraphIndexV0Config, error) {
	var body GraphIndexV0Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Config overwrites any union data inside the IndexConfig as the provided GraphIndexV0Config
func (t *IndexConfig) FromGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Config performs a merge with any union data inside the IndexConfig, using the provided GraphIndexV0Config
func (t *IndexConfig) MergeGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["description"], err = json.Marshal(t.Description)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'description': %w", err)
	}

	if t.Enrichments != nil {
		object["enrichments"], err = json.Marshal(t.Enrichments)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'enrichments': %w", err)
		}
	}

	object["name"], err = json.Marshal(t.Name)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'name': %w", err)
	}

	object["type"], err = json.Marshal(t.Type)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'type': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *IndexConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["description"]; found {
		err = json.Unmarshal(raw, &t.Description)
		if err != nil {
			return fmt.Errorf("error reading 'description': %w", err)
		}
	}

	if raw, found := object["enrichments"]; found {
		err = json.Unmarshal(raw, &t.Enrichments)
		if err != nil {
			return fmt.Errorf("error reading 'enrichments': %w", err)
		}
	}

	if raw, found := object["name"]; found {
		err = json.Unmarshal(raw, &t.Name)
		if err != nil {
			return fmt.Errorf("error reading 'name': %w", err)
		}
	}

	if raw, found := object["type"]; found {
		err = json.Unmarshal(raw, &t.Type)
		if err != nil {
			return fmt.Errorf("error reading 'type': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Stats returns the union data inside the IndexStats as a BleveIndexV2Stats
func (t IndexStats) AsBleveIndexV2Stats() (BleveIndexV2Stats, error) {
	var body BleveIndexV2Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Stats overwrites any union data inside the IndexStats as the provided BleveIndexV2Stats
func (t *IndexStats) FromBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Stats performs a merge with any union data inside the IndexStats, using the provided BleveIndexV2Stats
func (t *IndexStats) MergeBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexStats returns the union data inside the IndexStats as a EmbeddingIndexStats
func (t IndexStats) AsEmbeddingIndexStats() (EmbeddingIndexStats, error) {
	var body EmbeddingIndexStats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexStats overwrites any union data inside the IndexStats as the provided EmbeddingIndexStats
func (t *IndexStats) FromEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexStats performs a merge with any union data inside the IndexStats, using the provided EmbeddingIndexStats
func (t *IndexStats) MergeEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Stats returns the union data inside the IndexStats as a GraphIndexV0Stats
func (t IndexStats) AsGraphIndexV0Stats() (GraphIndexV0Stats, error) {
	var body GraphIndexV0Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Stats overwrites any union data inside the IndexStats as the provided GraphIndexV0Stats
func (t *IndexStats) FromGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Stats performs a merge with any union data inside the IndexStats, using the provided GraphIndexV0Stats
func (t *IndexStats) MergeGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexStats) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *IndexStats) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsTermQuery returns the union data inside the Query as a TermQuery
func (t Query) AsTermQuery() (TermQuery, error) {
	var body TermQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermQuery overwrites any union data inside the Query as the provided TermQuery
func (t *Query) FromTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermQuery performs a merge with any union data inside the Query, using the provided TermQuery
func (t *Query) MergeTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchQuery returns the union data inside the Query as a MatchQuery
func (t Query) AsMatchQuery() (MatchQuery, error) {
	var body MatchQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchQuery overwrites any union data inside the Query as the provided MatchQuery
func (t *Query) FromMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchQuery performs a merge with any union data inside the Query, using the provided MatchQuery
func (t *Query) MergeMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchPhraseQuery returns the union data inside the Query as a MatchPhraseQuery
func (t Query) AsMatchPhraseQuery() (MatchPhraseQuery, error) {
	var body MatchPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchPhraseQuery overwrites any union data inside the Query as the provided MatchPhraseQuery
func (t *Query) FromMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchPhraseQuery performs a merge with any union data inside the Query, using the provided MatchPhraseQuery
func (t *Query) MergeMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPhraseQuery returns the union data inside the Query as a PhraseQuery
func (t Query) AsPhraseQuery() (PhraseQuery, error) {
	var body PhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPhraseQuery overwrites any union data inside the Query as the provided PhraseQuery
func (t *Query) FromPhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePhraseQuery performs a merge with any union data inside the Query, using the provided PhraseQuery
func (t *Query) MergePhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMultiPhraseQuery returns the union data inside the Query as a MultiPhraseQuery
func (t Query) AsMultiPhraseQuery() (MultiPhraseQuery, error) {
	var body MultiPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMultiPhraseQuery overwrites any union data inside the Query as the provided MultiPhraseQuery
func (t *Query) FromMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMultiPhraseQuery performs a merge with any union data inside the Query, using the provided MultiPhraseQuery
func (t *Query) MergeMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzzyQuery returns the union data inside the Query as a FuzzyQuery
func (t Query) AsFuzzyQuery() (FuzzyQuery, error) {
	var body FuzzyQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzzyQuery overwrites any union data inside the Query as the provided FuzzyQuery
func (t *Query) FromFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzzyQuery performs a merge with any union data inside the Query, using the provided FuzzyQuery
func (t *Query) MergeFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPrefixQuery returns the union data inside the Query as a PrefixQuery
func (t Query) AsPrefixQuery() (PrefixQuery, error) {
	var body PrefixQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPrefixQuery overwrites any union data inside the Query as the provided PrefixQuery
func (t *Query) FromPrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePrefixQuery performs a merge with any union data inside the Query, using the provided PrefixQuery
func (t *Query) MergePrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsRegexpQuery returns the union data inside the Query as a RegexpQuery
func (t Query) AsRegexpQuery() (RegexpQuery, error) {
	var body RegexpQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromRegexpQuery overwrites any union data inside the Query as the provided RegexpQuery
func (t *Query) FromRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeRegexpQuery performs a merge with any union data inside the Query, using the provided RegexpQuery
func (t *Query) MergeRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsWildcardQuery returns the union data inside the Query as a WildcardQuery
func (t Query) AsWildcardQuery() (WildcardQuery, error) {
	var body WildcardQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromWildcardQuery overwrites any union data inside the Query as the provided WildcardQuery
func (t *Query) FromWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeWildcardQuery performs a merge with any union data inside the Query, using the provided WildcardQuery
func (t *Query) MergeWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsQueryStringQuery returns the union data inside the Query as a QueryStringQuery
func (t Query) AsQueryStringQuery() (QueryStringQuery, error) {
	var body QueryStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromQueryStringQuery overwrites any union data inside the Query as the provided QueryStringQuery
func (t *Query) FromQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeQueryStringQuery performs a merge with any union data inside the Query, using the provided QueryStringQuery
func (t *Query) MergeQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsNumericRangeQuery returns the union data inside the Query as a NumericRangeQuery
func (t Query) AsNumericRangeQuery() (NumericRangeQuery, error) {
	var body NumericRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromNumericRangeQuery overwrites any union data inside the Query as the provided NumericRangeQuery
func (t *Query) FromNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeNumericRangeQuery performs a merge with any union data inside the Query, using the provided NumericRangeQuery
func (t *Query) MergeNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermRangeQuery returns the union data inside the Query as a TermRangeQuery
func (t Query) AsTermRangeQuery() (TermRangeQuery, error) {
	var body TermRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermRangeQuery overwrites any union data inside the Query as the provided TermRangeQuery
func (t *Query) FromTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermRangeQuery performs a merge with any union data inside the Query, using the provided TermRangeQuery
func (t *Query) MergeTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDateRangeStringQuery returns the union data inside the Query as a DateRangeStringQuery
func (t Query) AsDateRangeStringQuery() (DateRangeStringQuery, error) {
	var body DateRangeStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDateRangeStringQuery overwrites any union data inside the Query as the provided DateRangeStringQuery
func (t *Query) FromDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDateRangeStringQuery performs a merge with any union data inside the Query, using the provided DateRangeStringQuery
func (t *Query) MergeDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBooleanQuery returns the union data inside the Query as a BooleanQuery
func (t Query) AsBooleanQuery() (BooleanQuery, error) {
	var body BooleanQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBooleanQuery overwrites any union data inside the Query as the provided BooleanQuery
func (t *Query) FromBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBooleanQuery performs a merge with any union data inside the Query, using the provided BooleanQuery
func (t *Query) MergeBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsConjunctionQuery returns the union data inside the Query as a ConjunctionQuery
func (t Query) AsConjunctionQuery() (ConjunctionQuery, error) {
	var body ConjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromConjunctionQuery overwrites any union data inside the Query as the provided ConjunctionQuery
func (t *Query) FromConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeConjunctionQuery performs a merge with any union data inside the Query, using the provided ConjunctionQuery
func (t *Query) MergeConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDisjunctionQuery returns the union data inside the Query as a DisjunctionQuery
func (t Query) AsDisjunctionQuery() (DisjunctionQuery, error) {
	var body DisjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDisjunctionQuery overwrites any union data inside the Query as the provided DisjunctionQuery
func (t *Query) FromDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDisjunctionQuery performs a merge with any union data inside the Query, using the provided DisjunctionQuery
func (t *Query) MergeDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchAllQuery returns the union data inside the Query as a MatchAllQuery
func (t Query) AsMatchAllQuery() (MatchAllQuery, error) {
	var body MatchAllQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchAllQuery overwrites any union data inside the Query as the provided MatchAllQuery
func (t *Query) FromMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchAllQuery performs a merge with any union data inside the Query, using the provided MatchAllQuery
func (t *Query) MergeMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchNoneQuery returns the union data inside the Query as a MatchNoneQuery
func (t Query) AsMatchNoneQuery() (MatchNoneQuery, error) {
	var body MatchNoneQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchNoneQuery overwrites any union data inside the Query as the provided MatchNoneQuery
func (t *Query) FromMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchNoneQuery performs a merge with any union data inside the Query, using the provided MatchNoneQuery
func (t *Query) MergeMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDocIdQuery returns the union data inside the Query as a DocIdQuery
func (t Query) AsDocIdQuery() (DocIdQuery, error) {
	var body DocIdQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDocIdQuery overwrites any union data inside the Query as the provided DocIdQuery
func (t *Query) FromDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDocIdQuery performs a merge with any union data inside the Query, using the provided DocIdQuery
func (t *Query) MergeDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBoolFieldQuery returns the union data inside the Query as a BoolFieldQuery
func (t Query) AsBoolFieldQuery() (BoolFieldQuery, error) {
	var body BoolFieldQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBoolFieldQuery overwrites any union data inside the Query as the provided BoolFieldQuery
func (t *Query) FromBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBoolFieldQuery performs a merge with any union data inside the Query, using the provided BoolFieldQuery
func (t *Query) MergeBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsIPRangeQuery returns the union data inside the Query as a IPRangeQuery
func (t Query) AsIPRangeQuery() (IPRangeQuery, error) {
	var body IPRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromIPRangeQuery overwrites any union data inside the Query as the provided IPRangeQuery
func (t *Query) FromIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeIPRangeQuery performs a merge with any union data inside the Query, using the provided IPRangeQuery
func (t *Query) MergeIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingBoxQuery returns the union data inside the Query as a GeoBoundingBoxQuery
func (t Query) AsGeoBoundingBoxQuery() (GeoBoundingBoxQuery, error) {
	var body GeoBoundingBoxQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingBoxQuery overwrites any union data inside the Query as the provided GeoBoundingBoxQuery
func (t *Query) FromGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingBoxQuery performs a merge with any union data inside the Query, using the provided GeoBoundingBoxQuery
func (t *Query) MergeGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoDistanceQuery returns the union data inside the Query as a GeoDistanceQuery
func (t Query) AsGeoDistanceQuery() (GeoDistanceQuery, error) {
	var body GeoDistanceQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoDistanceQuery overwrites any union data inside the Query as the provided GeoDistanceQuery
func (t *Query) FromGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoDistanceQuery performs a merge with any union data inside the Query, using the provided GeoDistanceQuery
func (t *Query) MergeGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingPolygonQuery returns the union data inside the Query as a GeoBoundingPolygonQuery
func (t Query) AsGeoBoundingPolygonQuery() (GeoBoundingPolygonQuery, error) {
	var body GeoBoundingPolygonQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingPolygonQuery overwrites any union data inside the Query as the provided GeoBoundingPolygonQuery
func (t *Query) FromGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingPolygonQuery performs a merge with any union data inside the Query, using the provided GeoBoundingPolygonQuery
func (t *Query) MergeGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoShapeQuery returns the union data inside the Query as a GeoShapeQuery
func (t Query) AsGeoShapeQuery() (GeoShapeQuery, error) {
	var body GeoShapeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoShapeQuery overwrites any union data inside the Query as the provided GeoShapeQuery
func (t *Query) FromGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoShapeQuery performs a merge with any union data inside the Query, using the provided GeoShapeQuery
func (t *Query) MergeGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Query) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Query) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsOllamaRerankerConfig returns the union data inside the RerankerConfig as a OllamaRerankerConfig
func (t RerankerConfig) AsOllamaRerankerConfig() (OllamaRerankerConfig, error) {
	var body OllamaRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaRerankerConfig overwrites any union data inside the RerankerConfig as the provided OllamaRerankerConfig
func (t *RerankerConfig) FromOllamaRerankerConfig(v OllamaRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided OllamaRerankerConfig
func (t *RerankerConfig) MergeOllamaRerankerConfig(v OllamaRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermiteRerankerConfig returns the union data inside the RerankerConfig as a TermiteRerankerConfig
func (t RerankerConfig) AsTermiteRerankerConfig() (TermiteRerankerConfig, error) {
	var body TermiteRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteRerankerConfig overwrites any union data inside the RerankerConfig as the provided TermiteRerankerConfig
func (t *RerankerConfig) FromTermiteRerankerConfig(v TermiteRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided TermiteRerankerConfig
func (t *RerankerConfig) MergeTermiteRerankerConfig(v TermiteRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereRerankerConfig returns the union data inside the RerankerConfig as a CohereRerankerConfig
func (t RerankerConfig) AsCohereRerankerConfig() (CohereRerankerConfig, error) {
	var body CohereRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereRerankerConfig overwrites any union data inside the RerankerConfig as the provided CohereRerankerConfig
func (t *RerankerConfig) FromCohereRerankerConfig(v CohereRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided CohereRerankerConfig
func (t *RerankerConfig) MergeCohereRerankerConfig(v CohereRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexRerankerConfig returns the union data inside the RerankerConfig as a VertexRerankerConfig
func (t RerankerConfig) AsVertexRerankerConfig() (VertexRerankerConfig, error) {
	var body VertexRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexRerankerConfig overwrites any union data inside the RerankerConfig as the provided VertexRerankerConfig
func (t *RerankerConfig) FromVertexRerankerConfig(v VertexRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided VertexRerankerConfig
func (t *RerankerConfig) MergeVertexRerankerConfig(v VertexRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t RerankerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["field"], err = json.Marshal(t.Field)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'field': %w", err)
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	object["template"], err = json.Marshal(t.Template)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'template': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *RerankerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["field"]; found {
		err = json.Unmarshal(raw, &t.Field)
		if err != nil {
			return fmt.Errorf("error reading 'field': %w", err)
		}
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	if raw, found := object["template"]; found {
		err = json.Unmarshal(raw, &t.Template)
		if err != nil {
			return fmt.Errorf("error reading 'template': %w", err)
		}
	}

	return err
}

// RequestEditorFn  is the function signature for the RequestEditor callback function
type RequestEditorFn func(ctx context.Context, req *http.Request) error

// Doer performs HTTP requests.
//
// The standard http.Client implements this interface.
type HttpRequestDoer interface {
	Do(req *http.Request) (*http.Response, error)
}

// Client which conforms to the OpenAPI3 specification for this service.
type Client struct {
	// The endpoint of the server conforming to this interface, with scheme,
	// https://api.deepmap.com for example. This can contain a path relative
	// to the server, such as https://api.deepmap.com/dev-test, and all the
	// paths in the swagger spec will be appended to the server.
	Server string

	// Doer for performing requests, typically a *http.Client with any
	// customized settings, such as certificate chains.
	Client HttpRequestDoer

	// A list of callbacks for modifying requests which are generated before sending over
	// the network.
	RequestEditors []RequestEditorFn
}

// ClientOption allows setting custom parameters during construction
type ClientOption func(*Client) error

// Creates a new Client, with reasonable defaults
func NewClient(server string, opts ...ClientOption) (*Client, error) {
	// create a client with sane default values
	client := Client{
		Server: server,
	}
	// mutate client and add all optional params
	for _, o := range opts {
		if err := o(&client); err != nil {
			return nil, err
		}
	}
	// ensure the server URL always has a trailing slash
	if !strings.HasSuffix(client.Server, "/") {
		client.Server += "/"
	}
	// create httpClient, if not already present
	if client.Client == nil {
		client.Client = &http.Client{}
	}
	return &client, nil
}

// WithHTTPClient allows overriding the default Doer, which is
// automatically created using http.Client. This is useful for tests.
func WithHTTPClient(doer HttpRequestDoer) ClientOption {
	return func(c *Client) error {
		c.Client = doer
		return nil
	}
}

// WithRequestEditorFn allows setting up a callback function, which will be
// called right before sending the request. This can be used to mutate the request.
func WithRequestEditorFn(fn RequestEditorFn) ClientOption {
	return func(c *Client) error {
		c.RequestEditors = append(c.RequestEditors, fn)
		return nil
	}
}

// The interface specification for the client above.
type ClientInterface interface {
	// AnswerAgentWithBody request with any body
	AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ChatAgentWithBody request with any body
	ChatAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	ChatAgent(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// QueryBuilderAgentWithBody request with any body
	QueryBuilderAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	QueryBuilderAgent(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BackupWithBody request with any body
	BackupWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Backup(ctx context.Context, body BackupJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListBackups request
	ListBackups(ctx context.Context, params *ListBackupsParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// EvaluateWithBody request with any body
	EvaluateWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Evaluate(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GlobalQueryWithBody request with any body
	GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RagQueryWithBody request with any body
	RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RestoreWithBody request with any body
	RestoreWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Restore(ctx context.Context, body RestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetStatus request
	GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListTables request
	ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropTable request
	DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetTable request
	GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateTableWithBody request with any body
	CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BackupTableWithBody request with any body
	BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BatchWriteWithBody request with any body
	BatchWriteWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	BatchWrite(ctx context.Context, tableName string, body BatchWriteJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListIndexes request
	ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropIndex request
	DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetIndex request
	GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateIndexWithBody request with any body
	CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ScanKeysWithBody request with any body
	ScanKeysWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	ScanKeys(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LookupKey request
	LookupKey(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LinearMergeWithBody request with any body
	LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// QueryTableWithBody request with any body
	QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// TableRagQueryWithBody request with any body
	TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RestoreTableWithBody request with any body
	RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateSchemaWithBody request with any body
	UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListUsers request
	ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetCurrentUser request
	GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteUser request
	DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserByName request
	GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateUserWithBody request with any body
	CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateUserPasswordWithBody request with any body
	UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RemovePermissionFromUser request
	RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserPermissions request
	GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// AddPermissionToUserWithBody request with any body
	AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)
}

func (c *Client) AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ChatAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewChatAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ChatAgent(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewChatAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryBuilderAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryBuilderAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryBuilderAgent(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryBuilderAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Backup(ctx context.Context, body BackupJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListBackups(ctx context.Context, params *ListBackupsParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListBackupsRequest(c.Server, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) EvaluateWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewEvaluateRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Evaluate(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewEvaluateRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Restore(ctx context.Context, body RestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetStatusRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListTablesRequest(c.Server, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BatchWriteWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchWriteRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BatchWrite(ctx context.Context, tableName string, body BatchWriteJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchWriteRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListIndexesRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequestWithBody(c.Server, tableName, indexName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequest(c.Server, tableName, indexName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ScanKeysWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewScanKeysRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ScanKeys(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewScanKeysRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LookupKey(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLookupKeyRequest(c.Server, tableName, key, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListUsersRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetCurrentUserRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteUserRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserByNameRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRemovePermissionFromUserRequest(c.Server, userName, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserPermissionsRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

// NewAnswerAgentRequest calls the generic AnswerAgent builder with application/json body
func NewAnswerAgentRequest(server string, body AnswerAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAnswerAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewAnswerAgentRequestWithBody generates requests for AnswerAgent with any type of body
func NewAnswerAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/answer")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewChatAgentRequest calls the generic ChatAgent builder with application/json body
func NewChatAgentRequest(server string, body ChatAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewChatAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewChatAgentRequestWithBody generates requests for ChatAgent with any type of body
func NewChatAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/chat")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewQueryBuilderAgentRequest calls the generic QueryBuilderAgent builder with application/json body
func NewQueryBuilderAgentRequest(server string, body QueryBuilderAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewQueryBuilderAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewQueryBuilderAgentRequestWithBody generates requests for QueryBuilderAgent with any type of body
func NewQueryBuilderAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/query-builder")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBackupRequest calls the generic Backup builder with application/json body
func NewBackupRequest(server string, body BackupJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBackupRequestWithBody(server, "application/json", bodyReader)
}

// NewBackupRequestWithBody generates requests for Backup with any type of body
func NewBackupRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backup")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListBackupsRequest generates requests for ListBackups
func NewListBackupsRequest(server string, params *ListBackupsParams) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backups")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "location", runtime.ParamLocationQuery, params.Location); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewEvaluateRequest calls the generic Evaluate builder with application/json body
func NewEvaluateRequest(server string, body EvaluateJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewEvaluateRequestWithBody(server, "application/json", bodyReader)
}

// NewEvaluateRequestWithBody generates requests for Evaluate with any type of body
func NewEvaluateRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/eval")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGlobalQueryRequest calls the generic GlobalQuery builder with application/json body
func NewGlobalQueryRequest(server string, body GlobalQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewGlobalQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewGlobalQueryRequestWithBody generates requests for GlobalQuery with any type of body
func NewGlobalQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/query")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRagQueryRequest calls the generic RagQuery builder with application/json body
func NewRagQueryRequest(server string, body RagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRagQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewRagQueryRequestWithBody generates requests for RagQuery with any type of body
func NewRagQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/rag")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRestoreRequest calls the generic Restore builder with application/json body
func NewRestoreRequest(server string, body RestoreJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRestoreRequestWithBody(server, "application/json", bodyReader)
}

// NewRestoreRequestWithBody generates requests for Restore with any type of body
func NewRestoreRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/restore")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetStatusRequest generates requests for GetStatus
func NewGetStatusRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/status")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListTablesRequest generates requests for ListTables
func NewListTablesRequest(server string, params *ListTablesParams) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "prefix", runtime.ParamLocationQuery, params.Prefix); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "pattern", runtime.ParamLocationQuery, params.Pattern); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropTableRequest generates requests for DropTable
func NewDropTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetTableRequest generates requests for GetTable
func NewGetTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateTableRequest calls the generic CreateTable builder with application/json body
func NewCreateTableRequest(server string, tableName string, body CreateTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewCreateTableRequestWithBody generates requests for CreateTable with any type of body
func NewCreateTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBackupTableRequest calls the generic BackupTable builder with application/json body
func NewBackupTableRequest(server string, tableName string, body BackupTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBackupTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBackupTableRequestWithBody generates requests for BackupTable with any type of body
func NewBackupTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/backup", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBatchWriteRequest calls the generic BatchWrite builder with application/json body
func NewBatchWriteRequest(server string, tableName string, body BatchWriteJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBatchWriteRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBatchWriteRequestWithBody generates requests for BatchWrite with any type of body
func NewBatchWriteRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/batch", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListIndexesRequest generates requests for ListIndexes
func NewListIndexesRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropIndexRequest generates requests for DropIndex
func NewDropIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetIndexRequest generates requests for GetIndex
func NewGetIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateIndexRequest calls the generic CreateIndex builder with application/json body
func NewCreateIndexRequest(server string, tableName string, indexName string, body CreateIndexJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateIndexRequestWithBody(server, tableName, indexName, "application/json", bodyReader)
}

// NewCreateIndexRequestWithBody generates requests for CreateIndex with any type of body
func NewCreateIndexRequestWithBody(server string, tableName string, indexName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewScanKeysRequest calls the generic ScanKeys builder with application/json body
func NewScanKeysRequest(server string, tableName string, body ScanKeysJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewScanKeysRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewScanKeysRequestWithBody generates requests for ScanKeys with any type of body
func NewScanKeysRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/lookup", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewLookupKeyRequest generates requests for LookupKey
func NewLookupKeyRequest(server string, tableName string, key string, params *LookupKeyParams) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "key", runtime.ParamLocationPath, key)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/lookup/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "fields", runtime.ParamLocationQuery, params.Fields); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewLinearMergeRequest calls the generic LinearMerge builder with application/json body
func NewLinearMergeRequest(server string, tableName string, body LinearMergeJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewLinearMergeRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewLinearMergeRequestWithBody generates requests for LinearMerge with any type of body
func NewLinearMergeRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/merge", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewQueryTableRequest calls the generic QueryTable builder with application/json body
func NewQueryTableRequest(server string, tableName string, body QueryTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewQueryTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewQueryTableRequestWithBody generates requests for QueryTable with any type of body
func NewQueryTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/query", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewTableRagQueryRequest calls the generic TableRagQuery builder with application/json body
func NewTableRagQueryRequest(server string, tableName string, body TableRagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewTableRagQueryRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewTableRagQueryRequestWithBody generates requests for TableRagQuery with any type of body
func NewTableRagQueryRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/rag", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRestoreTableRequest calls the generic RestoreTable builder with application/json body
func NewRestoreTableRequest(server string, tableName string, body RestoreTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRestoreTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewRestoreTableRequestWithBody generates requests for RestoreTable with any type of body
func NewRestoreTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/restore", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateSchemaRequest calls the generic UpdateSchema builder with application/json body
func NewUpdateSchemaRequest(server string, tableName string, body UpdateSchemaJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateSchemaRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewUpdateSchemaRequestWithBody generates requests for UpdateSchema with any type of body
func NewUpdateSchemaRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/schema", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListUsersRequest generates requests for ListUsers
func NewListUsersRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetCurrentUserRequest generates requests for GetCurrentUser
func NewGetCurrentUserRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/me")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDeleteUserRequest generates requests for DeleteUser
func NewDeleteUserRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserByNameRequest generates requests for GetUserByName
func NewGetUserByNameRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateUserRequest calls the generic CreateUser builder with application/json body
func NewCreateUserRequest(server string, userName UserNamePathParameter, body CreateUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewCreateUserRequestWithBody generates requests for CreateUser with any type of body
func NewCreateUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateUserPasswordRequest calls the generic UpdateUserPassword builder with application/json body
func NewUpdateUserPasswordRequest(server string, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateUserPasswordRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewUpdateUserPasswordRequestWithBody generates requests for UpdateUserPassword with any type of body
func NewUpdateUserPasswordRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/password", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRemovePermissionFromUserRequest generates requests for RemovePermissionFromUser
func NewRemovePermissionFromUserRequest(server string, userName UserNamePathParameter, params *RemovePermissionFromUserParams) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resource", runtime.ParamLocationQuery, params.Resource); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resourceType", runtime.ParamLocationQuery, params.ResourceType); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserPermissionsRequest generates requests for GetUserPermissions
func NewGetUserPermissionsRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewAddPermissionToUserRequest calls the generic AddPermissionToUser builder with application/json body
func NewAddPermissionToUserRequest(server string, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAddPermissionToUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewAddPermissionToUserRequestWithBody generates requests for AddPermissionToUser with any type of body
func NewAddPermissionToUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

func (c *Client) applyEditors(ctx context.Context, req *http.Request, additionalEditors []RequestEditorFn) error {
	for _, r := range c.RequestEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	for _, r := range additionalEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	return nil
}

// ClientWithResponses builds on ClientInterface to offer response payloads
type ClientWithResponses struct {
	ClientInterface
}

// NewClientWithResponses creates a new ClientWithResponses, which wraps
// Client with return type handling
func NewClientWithResponses(server string, opts ...ClientOption) (*ClientWithResponses, error) {
	client, err := NewClient(server, opts...)
	if err != nil {
		return nil, err
	}
	return &ClientWithResponses{client}, nil
}

// WithBaseURL overrides the baseURL.
func WithBaseURL(baseURL string) ClientOption {
	return func(c *Client) error {
		newBaseURL, err := url.Parse(baseURL)
		if err != nil {
			return err
		}
		c.Server = newBaseURL.String()
		return nil
	}
}

// ClientWithResponsesInterface is the interface specification for the client with responses above.
type ClientWithResponsesInterface interface {
	// AnswerAgentWithBodyWithResponse request with any body
	AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	// ChatAgentWithBodyWithResponse request with any body
	ChatAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error)

	ChatAgentWithResponse(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error)

	// QueryBuilderAgentWithBodyWithResponse request with any body
	QueryBuilderAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error)

	QueryBuilderAgentWithResponse(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error)

	// BackupWithBodyWithResponse request with any body
	BackupWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupResponse, error)

	BackupWithResponse(ctx context.Context, body BackupJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupResponse, error)

	// ListBackupsWithResponse request
	ListBackupsWithResponse(ctx context.Context, params *ListBackupsParams, reqEditors ...RequestEditorFn) (*ListBackupsResponse, error)

	// EvaluateWithBodyWithResponse request with any body
	EvaluateWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*EvaluateResponse, error)

	EvaluateWithResponse(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*EvaluateResponse, error)

	// GlobalQueryWithBodyWithResponse request with any body
	GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	// RagQueryWithBodyWithResponse request with any body
	RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	// RestoreWithBodyWithResponse request with any body
	RestoreWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreResponse, error)

	RestoreWithResponse(ctx context.Context, body RestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreResponse, error)

	// GetStatusWithResponse request
	GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error)

	// ListTablesWithResponse request
	ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error)

	// DropTableWithResponse request
	DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error)

	// GetTableWithResponse request
	GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error)

	// CreateTableWithBodyWithResponse request with any body
	CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	// BackupTableWithBodyWithResponse request with any body
	BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	// BatchWriteWithBodyWithResponse request with any body
	BatchWriteWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchWriteResponse, error)

	BatchWriteWithResponse(ctx context.Context, tableName string, body BatchWriteJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchWriteResponse, error)

	// ListIndexesWithResponse request
	ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error)

	// DropIndexWithResponse request
	DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error)

	// GetIndexWithResponse request
	GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error)

	// CreateIndexWithBodyWithResponse request with any body
	CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	// ScanKeysWithBodyWithResponse request with any body
	ScanKeysWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error)

	ScanKeysWithResponse(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error)

	// LookupKeyWithResponse request
	LookupKeyWithResponse(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error)

	// LinearMergeWithBodyWithResponse request with any body
	LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	// QueryTableWithBodyWithResponse request with any body
	QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	// TableRagQueryWithBodyWithResponse request with any body
	TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	// RestoreTableWithBodyWithResponse request with any body
	RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	// UpdateSchemaWithBodyWithResponse request with any body
	UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	// ListUsersWithResponse request
	ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error)

	// GetCurrentUserWithResponse request
	GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error)

	// DeleteUserWithResponse request
	DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error)

	// GetUserByNameWithResponse request
	GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error)

	// CreateUserWithBodyWithResponse request with any body
	CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	// UpdateUserPasswordWithBodyWithResponse request with any body
	UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	// RemovePermissionFromUserWithResponse request
	RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error)

	// GetUserPermissionsWithResponse request
	GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error)

	// AddPermissionToUserWithBodyWithResponse request with any body
	AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)

	AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)
}

type AnswerAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *AnswerAgentResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AnswerAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AnswerAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ChatAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ChatAgentResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ChatAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ChatAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type QueryBuilderAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryBuilderResult
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r QueryBuilderAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r QueryBuilderAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BackupResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ClusterBackupResponse
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BackupResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BackupResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListBackupsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *BackupListResponse
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListBackupsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListBackupsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type EvaluateResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *EvalResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r EvaluateResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r EvaluateResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GlobalQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GlobalQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GlobalQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RestoreResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON202      *ClusterRestoreResponse
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r RestoreResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RestoreResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetStatusResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ClusterStatus
	JSON401      *Error
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetStatusResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetStatusResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListTablesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]TableStatus
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListTablesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListTablesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *TableStatus
	JSON404      *NotFound
}

// Status returns HTTPResponse.Status
func (r GetTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
}

// Status returns HTTPResponse.Status
func (r CreateTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BackupTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *struct {
		Backup string `json:"backup,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON404 *NotFound
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BackupTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BackupTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BatchWriteResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *BatchResponse
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BatchWriteResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BatchWriteResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListIndexesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListIndexesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListIndexesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r CreateIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ScanKeysResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ScanKeysResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ScanKeysResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LookupKeyResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *map[string]interface{}
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LookupKeyResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LookupKeyResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LinearMergeResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *LinearMergeResult
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LinearMergeResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LinearMergeResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type QueryTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r QueryTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r QueryTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type TableRagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON404      *NotFound
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r TableRagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r TableRagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RestoreTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON202      *struct {
		Restore string `json:"restore,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r RestoreTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RestoreTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateSchemaResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r UpdateSchemaResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateSchemaResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListUsersResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]struct {
		Username string `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON403 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r ListUsersResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListUsersResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetCurrentUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *struct {
		Permissions []Permission `json:"permissions,omitempty,omitzero"`
		Username    string       `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r GetCurrentUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetCurrentUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserByNameResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *User
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserByNameResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserByNameResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *User
	JSON400      *Error
	JSON409      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateUserPasswordResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateUserPasswordResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateUserPasswordResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RemovePermissionFromUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RemovePermissionFromUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RemovePermissionFromUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserPermissionsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]Permission
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserPermissionsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserPermissionsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type AddPermissionToUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AddPermissionToUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AddPermissionToUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

// AnswerAgentWithBodyWithResponse request with arbitrary body returning *AnswerAgentResponse
func (c *ClientWithResponses) AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

func (c *ClientWithResponses) AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

// ChatAgentWithBodyWithResponse request with arbitrary body returning *ChatAgentResponse
func (c *ClientWithResponses) ChatAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error) {
	rsp, err := c.ChatAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseChatAgentResponse(rsp)
}

func (c *ClientWithResponses) ChatAgentWithResponse(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error) {
	rsp, err := c.ChatAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseChatAgentResponse(rsp)
}

// QueryBuilderAgentWithBodyWithResponse request with arbitrary body returning *QueryBuilderAgentResponse
func (c *ClientWithResponses) QueryBuilderAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error) {
	rsp, err := c.QueryBuilderAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryBuilderAgentResponse(rsp)
}

func (c *ClientWithResponses) QueryBuilderAgentWithResponse(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error) {
	rsp, err := c.QueryBuilderAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryBuilderAgentResponse(rsp)
}

// BackupWithBodyWithResponse request with arbitrary body returning *BackupResponse
func (c *ClientWithResponses) BackupWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupResponse, error) {
	rsp, err := c.BackupWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupResponse(rsp)
}

func (c *ClientWithResponses) BackupWithResponse(ctx context.Context, body BackupJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupResponse, error) {
	rsp, err := c.Backup(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupResponse(rsp)
}

// ListBackupsWithResponse request returning *ListBackupsResponse
func (c *ClientWithResponses) ListBackupsWithResponse(ctx context.Context, params *ListBackupsParams, reqEditors ...RequestEditorFn) (*ListBackupsResponse, error) {
	rsp, err := c.ListBackups(ctx, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListBackupsResponse(rsp)
}

// EvaluateWithBodyWithResponse request with arbitrary body returning *EvaluateResponse
func (c *ClientWithResponses) EvaluateWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*EvaluateResponse, error) {
	rsp, err := c.EvaluateWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseEvaluateResponse(rsp)
}

func (c *ClientWithResponses) EvaluateWithResponse(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*EvaluateResponse, error) {
	rsp, err := c.Evaluate(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseEvaluateResponse(rsp)
}

// GlobalQueryWithBodyWithResponse request with arbitrary body returning *GlobalQueryResponse
func (c *ClientWithResponses) GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

func (c *ClientWithResponses) GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

// RagQueryWithBodyWithResponse request with arbitrary body returning *RagQueryResponse
func (c *ClientWithResponses) RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

func (c *ClientWithResponses) RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

// RestoreWithBodyWithResponse request with arbitrary body returning *RestoreResponse
func (c *ClientWithResponses) RestoreWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreResponse, error) {
	rsp, err := c.RestoreWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreResponse(rsp)
}

func (c *ClientWithResponses) RestoreWithResponse(ctx context.Context, body RestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreResponse, error) {
	rsp, err := c.Restore(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreResponse(rsp)
}

// GetStatusWithResponse request returning *GetStatusResponse
func (c *ClientWithResponses) GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error) {
	rsp, err := c.GetStatus(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetStatusResponse(rsp)
}

// ListTablesWithResponse request returning *ListTablesResponse
func (c *ClientWithResponses) ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error) {
	rsp, err := c.ListTables(ctx, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListTablesResponse(rsp)
}

// DropTableWithResponse request returning *DropTableResponse
func (c *ClientWithResponses) DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error) {
	rsp, err := c.DropTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropTableResponse(rsp)
}

// GetTableWithResponse request returning *GetTableResponse
func (c *ClientWithResponses) GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error) {
	rsp, err := c.GetTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetTableResponse(rsp)
}

// CreateTableWithBodyWithResponse request with arbitrary body returning *CreateTableResponse
func (c *ClientWithResponses) CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

func (c *ClientWithResponses) CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

// BackupTableWithBodyWithResponse request with arbitrary body returning *BackupTableResponse
func (c *ClientWithResponses) BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

func (c *ClientWithResponses) BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

// BatchWriteWithBodyWithResponse request with arbitrary body returning *BatchWriteResponse
func (c *ClientWithResponses) BatchWriteWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchWriteResponse, error) {
	rsp, err := c.BatchWriteWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchWriteResponse(rsp)
}

func (c *ClientWithResponses) BatchWriteWithResponse(ctx context.Context, tableName string, body BatchWriteJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchWriteResponse, error) {
	rsp, err := c.BatchWrite(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchWriteResponse(rsp)
}

// ListIndexesWithResponse request returning *ListIndexesResponse
func (c *ClientWithResponses) ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error) {
	rsp, err := c.ListIndexes(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListIndexesResponse(rsp)
}

// DropIndexWithResponse request returning *DropIndexResponse
func (c *ClientWithResponses) DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error) {
	rsp, err := c.DropIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropIndexResponse(rsp)
}

// GetIndexWithResponse request returning *GetIndexResponse
func (c *ClientWithResponses) GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error) {
	rsp, err := c.GetIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetIndexResponse(rsp)
}

// CreateIndexWithBodyWithResponse request with arbitrary body returning *CreateIndexResponse
func (c *ClientWithResponses) CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndexWithBody(ctx, tableName, indexName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

func (c *ClientWithResponses) CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndex(ctx, tableName, indexName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

// ScanKeysWithBodyWithResponse request with arbitrary body returning *ScanKeysResponse
func (c *ClientWithResponses) ScanKeysWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error) {
	rsp, err := c.ScanKeysWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseScanKeysResponse(rsp)
}

func (c *ClientWithResponses) ScanKeysWithResponse(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error) {
	rsp, err := c.ScanKeys(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseScanKeysResponse(rsp)
}

// LookupKeyWithResponse request returning *LookupKeyResponse
func (c *ClientWithResponses) LookupKeyWithResponse(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error) {
	rsp, err := c.LookupKey(ctx, tableName, key, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLookupKeyResponse(rsp)
}

// LinearMergeWithBodyWithResponse request with arbitrary body returning *LinearMergeResponse
func (c *ClientWithResponses) LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMergeWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

func (c *ClientWithResponses) LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMerge(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

// QueryTableWithBodyWithResponse request with arbitrary body returning *QueryTableResponse
func (c *ClientWithResponses) QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

func (c *ClientWithResponses) QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

// TableRagQueryWithBodyWithResponse request with arbitrary body returning *TableRagQueryResponse
func (c *ClientWithResponses) TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQueryWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

func (c *ClientWithResponses) TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQuery(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

// RestoreTableWithBodyWithResponse request with arbitrary body returning *RestoreTableResponse
func (c *ClientWithResponses) RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

func (c *ClientWithResponses) RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

// UpdateSchemaWithBodyWithResponse request with arbitrary body returning *UpdateSchemaResponse
func (c *ClientWithResponses) UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchemaWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

func (c *ClientWithResponses) UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchema(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

// ListUsersWithResponse request returning *ListUsersResponse
func (c *ClientWithResponses) ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error) {
	rsp, err := c.ListUsers(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListUsersResponse(rsp)
}

// GetCurrentUserWithResponse request returning *GetCurrentUserResponse
func (c *ClientWithResponses) GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error) {
	rsp, err := c.GetCurrentUser(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetCurrentUserResponse(rsp)
}

// DeleteUserWithResponse request returning *DeleteUserResponse
func (c *ClientWithResponses) DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error) {
	rsp, err := c.DeleteUser(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteUserResponse(rsp)
}

// GetUserByNameWithResponse request returning *GetUserByNameResponse
func (c *ClientWithResponses) GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error) {
	rsp, err := c.GetUserByName(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserByNameResponse(rsp)
}

// CreateUserWithBodyWithResponse request with arbitrary body returning *CreateUserResponse
func (c *ClientWithResponses) CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

func (c *ClientWithResponses) CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

// UpdateUserPasswordWithBodyWithResponse request with arbitrary body returning *UpdateUserPasswordResponse
func (c *ClientWithResponses) UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPasswordWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

func (c *ClientWithResponses) UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPassword(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

// RemovePermissionFromUserWithResponse request returning *RemovePermissionFromUserResponse
func (c *ClientWithResponses) RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error) {
	rsp, err := c.RemovePermissionFromUser(ctx, userName, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRemovePermissionFromUserResponse(rsp)
}

// GetUserPermissionsWithResponse request returning *GetUserPermissionsResponse
func (c *ClientWithResponses) GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error) {
	rsp, err := c.GetUserPermissions(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserPermissionsResponse(rsp)
}

// AddPermissionToUserWithBodyWithResponse request with arbitrary body returning *AddPermissionToUserResponse
func (c *ClientWithResponses) AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

func (c *ClientWithResponses) AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

// ParseAnswerAgentResponse parses an HTTP response from a AnswerAgentWithResponse call
func ParseAnswerAgentResponse(rsp *http.Response) (*AnswerAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AnswerAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest AnswerAgentResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseChatAgentResponse parses an HTTP response from a ChatAgentWithResponse call
func ParseChatAgentResponse(rsp *http.Response) (*ChatAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ChatAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ChatAgentResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseQueryBuilderAgentResponse parses an HTTP response from a QueryBuilderAgentWithResponse call
func ParseQueryBuilderAgentResponse(rsp *http.Response) (*QueryBuilderAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &QueryBuilderAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryBuilderResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseBackupResponse parses an HTTP response from a BackupWithResponse call
func ParseBackupResponse(rsp *http.Response) (*BackupResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BackupResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ClusterBackupResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListBackupsResponse parses an HTTP response from a ListBackupsWithResponse call
func ParseListBackupsResponse(rsp *http.Response) (*ListBackupsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListBackupsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest BackupListResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseEvaluateResponse parses an HTTP response from a EvaluateWithResponse call
func ParseEvaluateResponse(rsp *http.Response) (*EvaluateResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &EvaluateResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest EvalResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGlobalQueryResponse parses an HTTP response from a GlobalQueryWithResponse call
func ParseGlobalQueryResponse(rsp *http.Response) (*GlobalQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GlobalQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRagQueryResponse parses an HTTP response from a RagQueryWithResponse call
func ParseRagQueryResponse(rsp *http.Response) (*RagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseRestoreResponse parses an HTTP response from a RestoreWithResponse call
func ParseRestoreResponse(rsp *http.Response) (*RestoreResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RestoreResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest ClusterRestoreResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetStatusResponse parses an HTTP response from a GetStatusWithResponse call
func ParseGetStatusResponse(rsp *http.Response) (*GetStatusResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetStatusResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ClusterStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListTablesResponse parses an HTTP response from a ListTablesWithResponse call
func ParseListTablesResponse(rsp *http.Response) (*ListTablesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListTablesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropTableResponse parses an HTTP response from a DropTableWithResponse call
func ParseDropTableResponse(rsp *http.Response) (*DropTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetTableResponse parses an HTTP response from a GetTableWithResponse call
func ParseGetTableResponse(rsp *http.Response) (*GetTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	}

	return response, nil
}

// ParseCreateTableResponse parses an HTTP response from a CreateTableWithResponse call
func ParseCreateTableResponse(rsp *http.Response) (*CreateTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	}

	return response, nil
}

// ParseBackupTableResponse parses an HTTP response from a BackupTableWithResponse call
func ParseBackupTableResponse(rsp *http.Response) (*BackupTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BackupTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest struct {
			Backup string `json:"backup,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseBatchWriteResponse parses an HTTP response from a BatchWriteWithResponse call
func ParseBatchWriteResponse(rsp *http.Response) (*BatchWriteResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BatchWriteResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest BatchResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListIndexesResponse parses an HTTP response from a ListIndexesWithResponse call
func ParseListIndexesResponse(rsp *http.Response) (*ListIndexesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListIndexesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropIndexResponse parses an HTTP response from a DropIndexWithResponse call
func ParseDropIndexResponse(rsp *http.Response) (*DropIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetIndexResponse parses an HTTP response from a GetIndexWithResponse call
func ParseGetIndexResponse(rsp *http.Response) (*GetIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateIndexResponse parses an HTTP response from a CreateIndexWithResponse call
func ParseCreateIndexResponse(rsp *http.Response) (*CreateIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseScanKeysResponse parses an HTTP response from a ScanKeysWithResponse call
func ParseScanKeysResponse(rsp *http.Response) (*ScanKeysResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ScanKeysResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLookupKeyResponse parses an HTTP response from a LookupKeyWithResponse call
func ParseLookupKeyResponse(rsp *http.Response) (*LookupKeyResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LookupKeyResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest map[string]interface{}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLinearMergeResponse parses an HTTP response from a LinearMergeWithResponse call
func ParseLinearMergeResponse(rsp *http.Response) (*LinearMergeResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LinearMergeResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest LinearMergeResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseQueryTableResponse parses an HTTP response from a QueryTableWithResponse call
func ParseQueryTableResponse(rsp *http.Response) (*QueryTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &QueryTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseTableRagQueryResponse parses an HTTP response from a TableRagQueryWithResponse call
func ParseTableRagQueryResponse(rsp *http.Response) (*TableRagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &TableRagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseRestoreTableResponse parses an HTTP response from a RestoreTableWithResponse call
func ParseRestoreTableResponse(rsp *http.Response) (*RestoreTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RestoreTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest struct {
			Restore string `json:"restore,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateSchemaResponse parses an HTTP response from a UpdateSchemaWithResponse call
func ParseUpdateSchemaResponse(rsp *http.Response) (*UpdateSchemaResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateSchemaResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListUsersResponse parses an HTTP response from a ListUsersWithResponse call
func ParseListUsersResponse(rsp *http.Response) (*ListUsersResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListUsersResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []struct {
			Username string `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 403:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON403 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetCurrentUserResponse parses an HTTP response from a GetCurrentUserWithResponse call
func ParseGetCurrentUserResponse(rsp *http.Response) (*GetCurrentUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetCurrentUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest struct {
			Permissions []Permission `json:"permissions,omitempty,omitzero"`
			Username    string       `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteUserResponse parses an HTTP response from a DeleteUserWithResponse call
func ParseDeleteUserResponse(rsp *http.Response) (*DeleteUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserByNameResponse parses an HTTP response from a GetUserByNameWithResponse call
func ParseGetUserByNameResponse(rsp *http.Response) (*GetUserByNameResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserByNameResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateUserResponse parses an HTTP response from a CreateUserWithResponse call
func ParseCreateUserResponse(rsp *http.Response) (*CreateUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 409:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON409 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateUserPasswordResponse parses an HTTP response from a UpdateUserPasswordWithResponse call
func ParseUpdateUserPasswordResponse(rsp *http.Response) (*UpdateUserPasswordResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateUserPasswordResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRemovePermissionFromUserResponse parses an HTTP response from a RemovePermissionFromUserWithResponse call
func ParseRemovePermissionFromUserResponse(rsp *http.Response) (*RemovePermissionFromUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RemovePermissionFromUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserPermissionsResponse parses an HTTP response from a GetUserPermissionsWithResponse call
func ParseGetUserPermissionsResponse(rsp *http.Response) (*GetUserPermissionsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserPermissionsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []Permission
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseAddPermissionToUserResponse parses an HTTP response from a AddPermissionToUserWithResponse call
func ParseAddPermissionToUserResponse(rsp *http.Response) (*AddPermissionToUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AddPermissionToUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// Base64 encoded, gzipped, json marshaled Swagger object
var swaggerSpec = []string{

	"H4sIAAAAAAAC/+z9i3YbOZYuCL8Kflb9y5KHpCTbWVnFs2p1yddUp29t2ZWnJ+lFgREgiVIEEAkgJDG9",
	"NM8wLzIvNU8yC3sDCAQDIVKSnXn6dJ6zOsti4H7Z2NdvfxlksqykYMLoweTLoKKKlswwBX990ky9pSV7",
	"T83qvf9iP+RMZ4pXhksxmAw+rhipNVOClmw8GA64/bGiZjUYDuxvg8mgdi0NhgPFfqm5YvlgYlTNhgOd",
	"rVhJbavsipZVYYv/S65ELm1ps67sD9ooLpaD6+tr24CupNAMhviU5h/YLzXTxv6VSWGYgH/Sqip4Ru0Q",
	"D/6l7Ti/RF39WbHFYDL400Ez/QP8qg9eKCUVdtWe51OaE+U6ux4OToSxcy5OmbpgCmt98zH4TomGXgnD",
	"gsPBW2leylrk334IH5iWtcoYEdKQBfRpC7l6ttnj5VKxJXT6tM7OGYykUrJiynDct/lylskax7i5ytn5",
	"UtlmCZQgewupiOZLwRc8o8LMDFOl3m8OBxeGLZkaDAdXo6Uc2V9H+pxXIwlt0mJUSVtGDSYLWmhmZySz",
	"vv7f1uWcKSIXJJdZXdo1IVwQs+KazHE2nZ6vh4OFkmW3sdfykikyh9nYaSgqlsw1owfDwUKqkprBZLAo",
	"JI0aFjCIeEa+zF+e3GaedlQzqmfu/nTG9xL6NywnRTPSzrW7RYfnbJ3YUpgvOWdrsmc3b+jWwRKHIcmp",
	"YUPCTDbe7154aHG3Gdjm7RrnXFcFXZM9Nl6Oh2QRCtiO9P59ZqczqVh3DKfhcGaMQJkbDu233nJdz2e0",
	"uYBw22iecyz/vnULb7r/0SX+wHRdAM3rUIK6MNreFcG0XWJdz0etzsP05PxfLIM2jOyu4Keq+l3viZG7",
	"nbG6Gefdz9F1/Aj+DFcmpkifE2sWbcZzatgHuzxdopqmQaeGKgOHn+ydnL4jf/3L4RGxa8wKavgFIwU/",
	"Z2Q6EPJy9H0+HdzrhuB736GptGT2lJgVw4HE+5u69Kkz8kLku83iXlPY2ByYz5YdudVuxC/CHhdZUWt+",
	"wX4LwrB9a+6yK/HN3WNXv9l87rJPDaPY3ilaLKXiZlXiH8W7xWDy883UMSb5x6H69efhTU9D6IckXwey",
	"QTl33tl5YJlmC144Hn23efxHzdR6cD380toNyymOP9DLN0xrumStsfCykgoX0bL4kwETmcy5WCJ/ed1d",
	"g4ijw+HtMv3r4SCjBRM5VTOY7gUtdp/WM1f1xNfsjsoXGdFLqhjxfSALQQ2brbg2cqloeed9gWbgUunu",
	"xXke6KBu+sQbuNEfN6y8zXPdvBDX4UJQpegaXnCujT2M/eNyBeKxLZmc+Yp3Gp1vtHdYC86KPPHy2p+J",
	"kaFTRqRIkab4iGw2ccXy9vb27uy3JsElF7MbRI83XPCyLoPg4QQgO2TqyLJdi7k9rVlR58wyIUFqPrqP",
	"QCQVX3LRHdI7+N0fghXVq9lS8TxeOOB1S2omZDooqBkWUkwH+1PxAgdmf378/fj775/8bTg6evRo/OTo",
	"b0+mg6m4D5tRKZZxzWVixK9wmCQUIXtHo6NH+zfOQd9Lmuy7Sh+aG/RVLnbv7dH818TT/oZewXESQaJ1",
	"DLU9RIqZWuHeuZ+5WLYGuN86XIf3WaBvIpMERcwGQ3MLSQR+2LnLj7b49XBQC252f4o86ftka3WfoUBu",
	"batbie3dmCOYp6exW5kkkPW6PNJFQjA6vmCKLhm+54Ya/VsTVC8h9qgc8O6ljzeqIrTTRQybR6HRRdz2",
	"fjplV+KC9hD8511Cn1zGu9+8kl71E4YLWtS/4+aVqQfHv4G/89i0yWc5u+DUJB+ZU0Mt75iTUOZ3HGqd",
	"Evrr8ncd0UwuZvqXmqrUu2gHJxfEff/9xglnLKXOE8uCRSewZEbxbIN66LocEnqxHJKSiyEp6dUQr/GQ",
	"ZFTlXNCCm/X+bzINxe1j0Z3JP92X32uJr29+az6693fDnLSuQCMRs5hGEkt6a8MmUzEib2BD9ITcsAm6",
	"Lt0BG+LUW/tiW3nq34UJaT8FjSjWehbaUqFt4RWTkxZPOWy93rbIsaDF2uBgNyVe4IGZsPf3Z7jGQ3hm",
	"kTIi7fZPB1wqf6EseaKgF41mZPfONjpw/Ogglj8Hw0EYuP8Q/xDPAf8Mk7C9bQ48YiIaEQxm6sxybd6h",
	"ysDa5GrMpSwYFfBMasFSXzrn5ha3wQ+jj5Fxgwlv+51uQOKJ93P5yg3fbyn0JVPHSyZMv+7Lfp2dC3lZ",
	"sHzJbrTHhVLErKghy5rnTIPmEFp5oEktcqbsucktu+U1vrKkXIyn4pSXvKDK3uZnr48/PX8xLvMhWtYq",
	"JS+gNbBdXhnsAayXDOQVWhREG1bpqdjLCqo1HEg7xqGVZRRnF7QYEipyQmHaZMkEU1BifzwVQR7VQEGm",
	"g4+225waCl1SLjQpWc4zWhDFMqlyPSafNCNZwQX8ak8+F7KQyzV0M2dOxmSEzmVtSM7pUkjN9NiKt6EP",
	"rgklWi4M6JmYWHLBmL000XrOqWZjcqx1XTJCiWHZCjuldc6ZyFi7SUPnBSPaSPt8FmxJi8ZYOSYf2IIp",
	"W4kU9FLDWBVb1oV7uWiW1YoaVqzHSTHcsqsrmuLNnrMFrQtD4LPdXbfEUuEjbveo4hUruGC4WaQWBdOa",
	"yAumFM9zJggX5Ay+nY2n4gXNVqTg4pxkVBBdsYwv1rCfa7stC76scQtxY+1vKDVCf0at7TLaMybsmQnD",
	"GU/Fm9rUtCjWJOikySU3K/IgFHowJi+4WTEV/0akIg9gfg9IWWuDuwxnMx/DYu0kFDyzLbzm4jxFKZjT",
	"U91ofb+gxTNYAFsjjG9btVe+YFO3pFczd6lmRp4zofsFAiONPehQyu6mvGTOHoc3jOWxbgraHE/FTysm",
	"iGZmGFnM7VGvVC1YTvZsM9qMFBXntjmutNm3V3rBDexJY13Pl8w2+EmzRY2qOiZ0DXfl9es3gTYUvOSu",
	"DyGN3WHGcH8+aabJ0xcfPuIk+K9O2cy04SUcJNzESK9h/x+8uHYFUlq06+Hgl5opnuJkj+2e2ptgS6y9",
	"dwgQLHbFstqwMfm4Yu4zDP6SF4U9VUZRoe0b4ZZYs5IKwzOiGVXZairsia9kZe8tKjAlnHRfboblCEj1",
	"dgjM3iXoaBzP8OcvAy5ydmWH//OAlXOWW+I84/mVfcZhLZ1+x1KVwcQ+EHmdGQ1mgR3qftdUVeyCs0sN",
	"eo6dLgrYHyJdTsnFCdY76l4cmFzCBKWZeqCJoKZWtCAFFcuaLsOig8LUPxksB0rCS3up2/rTwU/w5CgG",
	"yzxn2pAlLe3ZK2hlZOVeN/LnR4eHh/+WIpuKgVdO65oBxRxMnsAp22B08Z6BMg4q4jlYa8NKS3TKygy7",
	"jxm+cRIIlyWrK0btyT+t50bRzB6VhZIl6V5721HO8BVjhF5QXsAz4m9VuH6OzEMFO27CF6nmuLaXfuM+",
	"PWnfpsPUbQLqv1Wt0vAup1D+ejiwxGKmjWKwLa31RV+yTYMxzO/09AUJlexFUc5tocNHuGs+9CX86u8T",
	"LrRhFK7Zv5++e0u8D1pzCiKu1g5T1mbW7FlrqMCdbY4VaChMglimjhyfdHfeveSgt3WX309FCvuae8J5",
	"aRtby5pcUmF80V9qEBOIG50jqBokpWxFKDzhU/FLLQ0lJRV0yYDOg/LaMCS6dgV1xgRVXOpxzDzEvHus",
	"e8Q725DQpPox5lM9176bdhWrBgeVDn3GNQT21C0WsgE9LGT0wGm8aG75mWcrgZW0JL3dwiyQc9yqwFNW",
	"io0Cf0oUo1oKu4p7fEEYHNCcXHA6FXArxu1Wx3DiQ6V9+5hwHbViecvaSNtpBtxORbVmOTFyKoAv75wh",
	"2w3QGTtCLmp7JIBPl/Vy5W5zW0K4caJbGaFW5Y+tuo1bkV2bmQpbv40xairC6XI1UwYYdz2AIsL76F7l",
	"nPhzeZtXyve6RUK7/tw+06ee3rUH956pEexGm9EFxrbZOjy6nqseE+CYsRoVZEUv2FRYZkheiob/JXt2",
	"g7tc+j4caVt7hLw2zwiKj/YynyysoGKb5hoYKz8wlg8JN6TWTtozshoV7IIVUY9UE0fhUmcIJ7MbzbfL",
	"1bCv7dN3u+O20ZL9V86couzGVkLJdgsLaVniutpW/6UrF9e+7qV7z1rj2nBSCN+IvdhaA0n2R2STNvUs",
	"+yy7oYd3F0xZua0pg96u4QDuHY4PLSdwND7cH5NnUmhuZXwyl2ZF6JzDo2IFdCwOV81LTJbkgq+wjmhp",
	"0ci945QGskRhBDjABCPh1Ce4ocCPKFawi7QC9IP/5HURiZE5vhpYUDAXRxO+x/g23sHuVqQm0P86Ng9j",
	"isThsnepPbx1XkEU7zEFR0t7TEd1Feaub7i4m1b29tGzh6ak6jy3dMgt2R3s+5YDuh5+9XN7923cfcz/",
	"S5/G3afhadysORMJ+81yiVb29BEKb2rXgzB+OXcdVPIm3XBVIrKbJqh9b+0Gm+S4LXgRPanFB3DBBS2s",
	"hN6QvAQDSWrt1VMNx0Z1pDm5gWDbEonh19rIEjSvwa7jRmGkYEMr4FFeEHidh+61XxesJec+BZkPFZci",
	"b5SNY3KCbkUkkzkjroK24oSyU4DDa8a3UBg+SygK7QFXa3tZpcqZGpNdNHVfRe92Hy0aSuUzlMp796Ul",
	"u8ebE4mC3Zim5EE2i2L9bFWLc6aas7yj86Ot9q7yfpQdv+S6KGb+eKW9cFLSdPfm2IZGoDoAJZGTrjPb",
	"O4TMPLWn0OsHK8W05V322AUTxAo/ZWXW+0Nf3qvFQKmd4wmYZAszIbpeLPgVqm1AGZWHxh9oMnP1QQ3m",
	"O6Nz21dou9aMTLJWS1QxEJrtN9S/XbDM8rFByWU5Yrj/uCsE5C5Q0+Ru9qa2jeA6o/v5XEptZeSh08qV",
	"tKrgT2ayDUXJl+62JwSJ4U7kq5AZLQieGZyz3Qv3uHiJtTGyKKJqoZuCOVcsM8W6UcbiNtAlI8JSgkrJ",
	"jGk9nAqvPEB6DPRMEHblYtI+MlVywyA2jWdsTE6c0KC5nTRZ8CuWjzT/lU1F0M+O5tRuQRgN7LyQJKPZ",
	"Co5Uo+OaiocPP2mG2uLLFROThw+nYkQ+1AJoqwbD/QjGnLOqkGukw3v6kqqSlDJn+7b8f8qa5FI8MEQw",
	"ljdbfgCDCD3TTEmtYQm0rwYaFXhnIQbP1BUYpgt2BUZlP0K/El5vlBhsWReG41gt2TOWp0ZK6/tXLK8z",
	"MIlpEwYAI3739u3/HNEsY4VjwsLq2TkW7dFWTGmuDejsbbGDMF/oiemNg4kWA7g5g8l3h8OB3YGCVkGt",
	"aX/zR8nSVzh3g+FAs4o6+jqwS2FJHVVLZqKah9eBunnrfzCAg55qRvVsLeuZ81k7Z+tLqSDYxlKs4WBl",
	"ymIwtHwNUzxztmzDIbTU66CGg8I+AWDHBlYC/6lXFNoM87dVCjnvsWablZIVzzYfgx1ZilA/0P4LRo5P",
	"mju496yg9q3FHUMT5fH7Ewhju+CUnNGKz87Z+sxr+BU5O3778YcP796fPJsdvz+Z/fjiP88IExdcSQFy",
	"ITiCzAvmroozeJI30MPk4UOSQZcjLYVgZvRk9N3o0eGj7w7/9uhvZM9J75YiYylZ1TqUOTo6PApfHo++",
	"G60oP6/tpydHh48eYYfPZQbdrIyp9OTgIJeZHlO/EONMlgdMwK8HYDEdYXsHuAQH9pxdcHaZOo/+BD05",
	"/NtfhgOoMJgM+ucz2DyiOAY4R2Vl96NWbDA5HH9/3eHBcN3Tcc7Ntrq9GpOTBShLPC8/JAtaFJrMaXZu",
	"mZ3OnqW3LMVVxRPf7tzbaPk9s+olIq+tHicjV91iRhrqm9e1uyiWEcBzTE6ee9mmWSn8YiS8wy4q80F/",
	"Fw+ar50j+GC/Zdu6eaBd6SPe+sQ1NkoWmigqclkKpoGJiWQCK4qNUA3yA1+umEIXMU1Kes6IrE1VG1JK",
	"xVwT99NuGFnNzhOHUFajc6LtAsAj78Pyx+SdZWc0XnkQSZyqjvwYmBQwhYICsZ5r9kttTyAcm/TJsEOo",
	"UhHSWcFqnRhEvETHBXAFQPcsz9+s/f3WpVZF+mp++vC6e/bsLWUih1eA7HkBc4hsiTvwlhu1N9ipRFm+",
	"3xphrXiSaY9lUrxDKZH0Kc3O6+pELGTC9wbewdmFfaBTXqaOo3Pf0SUmUwxefLBRQtutC3FxND4cH6YO",
	"Pxae8Ty9eviZ8JwJYxdBbdwz4FBGWAou2ejwaHT0Xaony472uc0iV+lL+P1KTEQ/nhwclGv03T7AlXLd",
	"6wM3nIObxwFG6QTp/Ai/hxgaTyW7g/gZcCucUgxN4p931m7Yv3nJtKFl4g6hva9Z90uq/da2lqGZ4cej",
	"w8njw8nh4f8ZH07L/Ywc+3PzEW32Px5YWKVo2/qP8WuuzQdv+uxiOuDuJGJeuTbg0Rlszr7ojmJ9dIlS",
	"5pfuNPUNk+h1hbvhhnwS/JeaRbfD8Xlcu6mAr1iOtnzvfRVtL/rQgGxLZOUeFCthPltJqRmhpGTUigWL",
	"ugBYBLzs7oiCnxo78HSAi2BC2xAqB537Obp4dM8r6hlaP8/TuqqkMhoFmMptJhM5Ota9Bll0wQuGypAJ",
	"ObN/TA4ODipqVgdGHmBLZ+AdW9JfpSCnjyfkDG483veRXYJueTS8ekrl14YWhXOIy6mhQ6ckcObbkhkK",
	"Tn5+GoHIY53NBbyR7AA1GEG9G0nPDTdvyyUz2So6npuOmCZbWYmSKTMkOSuYYTjJYJKNzpalatRJxN4v",
	"yckFx0aWPONm/fAhbNnDh87jXa+oyh8+nJB3TTNUMUKhglcPQCmM+KaKo2j88OEbfxrgs7atgDNWzu2q",
	"zMHm+mhUrahmVmIuuSF7j94/w7A81wHI2yNs/1JxY9u2A/5BXrbagfnSDAd4KdU5TORoTN743XboOLSA",
	"9Waa/PD6GQlUD/WirGCZsdK1BB9qIxWOfSoejcmz6FccStyr8xAdWs7H8IxXVBiN5SDSVFh5/fGYHC8M",
	"jsL/SnSdZcwKCXG3uB6tHqbiyZi8j1t33m7Oh0mvRbZSUshaF2vnQiSLi6j778bkA8usTLUmhZQVutIx",
	"7RrJ3P6i9sIwAno5CgOOx7agvKgVw414zxSQHpExd3bw5Lg9m9sTyvSETOvDw8cZ+a7UpKCGiQz87Z9F",
	"2xtv4YT8X48O20VPYBY4qdoWCm0+PiSaZVLksPPajDJ7ovasxKzi6e7jiF/VVFFhGNNuwMdF4TfU7QVx",
	"nqt2pmSP+svh1T/geAxnGnRHz7prg6pB6BvI0J5gl6RgFDRtTNfl5qJDQyc5Kyu5MU2yl9cI2MQ29slu",
	"v6YL5ub1lAm24MbP6oNTFQlm7H0ISjPYXqrwZeIi5xc8r8EPBR0VIZjCPkpsseAZt4MJuty9ugLEHOga",
	"tzaHkR97j5MbLqVlbyJipCvqCIf2ZBwJGbZeV/jvEWFXHDSoVrTGb3YqdsMME0NiVzZ8cfzSpmJ1gKRR",
	"e/5t8v1frTQI/5RFPqNZwFlxY7CV4PPRo8fOJ34weXw4HLCS8sLhkf3D9TDOZNkAm/27XAnyHKHK6BL6",
	"zMAW4KzxrOR1Ofh87fp/8t1fQgePvos6oIL1dEAFI6clBzS1ThefAZ+rzcaE6fc6qwYf3pPnzivQ1hiT",
	"5y33XcVKeeHdCZGGwcMKr8hbaZwn/VspRrBrtsGwN5oXTJhiTfhSSMVyW/K57SYcZqdUZjmZs4VUzYHw",
	"GmjLBcGxs3V/9A1XzNIfbLs1Qq+xbuwEG4rN7adhZ8Y+Ojd9Ycw9gZ7OmABKbqrm3Ciq1qjh06S0s7WH",
	"fy1r5Z38gQUep8KXNxVCVXJv2z1r50F0ztaWbNmFrnt4Wxbqwo4/ZdqQStkbnrmth/AIKXSz+ZZ3RR/B",
	"FbNkz2l7puF6TQf2L3jXCmavA0AFwP6SgomlXZbFAh7meEOr5uEhI3LOWGUHWDq7Kp0Xa6JXUpnWUdFS",
	"AbIZu+KZXCpardBJbki0JBky3pViC34FZl1qiEbe1kXr64yKjnL8vyydSBwgy0TMwFS8TQA7XYvsNRS0",
	"7Xh28yYak+RJ7cHiYlQVNGtOF/HvDJrL30ixlM+fjsBu7SpLhVTnY6pRiFMAd1cjSSlzvlhHNvjGYkXz",
	"EX4dIaOmqD/Hm+wuRB3ljisF07R0NAnYSng0PbsbDaRiqplU3JBlmkHbhiGBQYJyRoy4jb0/c5ENyZ/L",
	"utgfEoqrGX+uar0akj9XdQEFrIgjkT17JstSClCyWp4Ip3YiMsWaEHOmtOWV2KUegsVSD8mFpeRwBz/B",
	"PjRssu0uq5ViwjynBk1nb8AxGAemyR7N8wOkwsSeuSEBGhq35oDhHIXzu+Efde8fYUmPao7EBuH+grCC",
	"gWzY6zccNMsCRWQ1mAzs6tn7hMhEfx5jNEKI9D26HvqC0cTiCgXV5p+cXbIc3Dh9z+FS9nRrdyVuBi5g",
	"6HZwwSvb3K5BEeGY7+JsGsTGPrUMvu75bkiXwBNrvajtqfc1U7phfALv1GyomtQ5N2Exd2g6rt1tPbl4",
	"LFcyO38BNkF2WyPfT6fENdBYkduGdxCCbblMMXhhaeH9kSMzkFTk5PgNUbJw/FXSeidXTLExdDRiYllw",
	"vRpdPBkSClqUseGGihF+NuzKjC4eTQ5vssxd6rGrmsnyYI4TObBimDag7IAIT2eeG7nHkeVjZ4ONTXTe",
	"IJceYtsa5zoCLOAlLm+tR4xqMzoadNhZYAFnDcKNs1EdDZNKbJOtiC2Lpo6wJXFglqwML20Rs1KyXq6q",
	"2mw1jG125Dc9GL02rVvpdXgwJA9u2qyOeat3OROxR8ukPu+jO6b4PZxcPwHnqhEGHjZicyjNDiU6t/+q",
	"ZoJdzgoumN4p3AUCmIwkUBcEO6jbmK64qGqDMXNOQgj7Od4ed3KDRQanfle7fnTl05Z9uL/vfTwzBerk",
	"WBPm734wUA1BZzV0itAheQY7PiRvrGTtA5oh2KufLkQW9l5z6OjiaHI4BHXouChoSR+PHo++P5yPuNBG",
	"1ZlxBdzpFPKCjiol4ddvRUIS/o/3tXh/9Yu889pu3pedK379yzz+prbv39So/XXM0uOv58Z/A1nhYnkK",
	"Lky39df8ic1bFbsum70uKbZTgpW9QwrE/mhmyNOTt69mpy+OPzz7IXY9IRdUJYG2vZm87Qrirzut+Hhu",
	"SW/JMyW1XBi48Rffjw8P0HOr4xoCg2sZ4D99eL3Vsj4cLBTTK3sGU2COgB/qwx7na9IUbqBUnoNz+U+M",
	"WR7jjRRmlXDxupO35Rs/eQKT+4nNo9V3BPqUmboCZ7+jMXkGOkpy/Gtt5UHUNRFqAhW15JAWY2q/2wVF",
	"4wNWoiTeXh8iAIaFV8yE/Xbu5w6U/5yt9Q0Eu717TIxqfWC31e3hiFYcfxhdsvkIf2w7ZnUPfsEu2InI",
	"2dU/HzVHf4Ous3ImRbFOGsI9J2DpbslKqdYjcM11CqDuW3+LwIEbR3sKKDpdgYnr81kNwLcJbKhfQ/QG",
	"aBktnZyvDWuBKdVcIE7S7YHbXBgG8+kkNkKa7c+kRFhewhcO1CmTdZGDD8ucNZEI9wjAUWxe8yJPoqGH",
	"HWuWQBMnToNSNlS988ZZGm9oMXP+3rdI0uCG9DU3I3mKpCwAm/Y/PCTBhtAiZZGGPAIX8a3+DlAohsXd",
	"YmG23X3uGSejon+UtxqLh5beBVB6UNbb234mxb9qATajVr2ZkGYHSOFOXb2yF+H2NXu2WJubRc5jAsyE",
	"pZb4vjnWtHauIDnLFKOaEVB7un+jQ6YPBINsEZBBgTbYHY13j6znELwj6qJAiA0MzegwVk8VvWC/Pfth",
	"e+3lPz4c//PFTpzHTQ++/+Sgwyekyv+e0/WQVJd/v2TsfEiq8u+lfeOHpFr/fc2oijiByhLB6tL+p7T/",
	"WSd9vXXFiiJbsex8V0yJpgbRGAzXRuqMMc7YlZnlLJOKRuF0NwnHPgoLRN+oJtmbywJCsWnBMwi3ZCpO",
	"aNKPn7YLb7O5mWj1iX8MIF2V4hc0W48WMoOz7iAmwKrlg9EtHa6YyINNOcUenfKlIHUVc0Rz2yNwJ477",
	"oBU/ALaow/TkVK/mElw2UgyPZVmxjXHTKK2qA/9mUPS0SDI16yjLRhfSzb74PR7bDr7mUYxl86hrQuwg",
	"1HeFsjsD1PvTX3JRwzhXslYQKmH54kvki+HOADAHVQaeQ7g7qfsBUXXPPPRWWz6QYoa8SuKA7QLVZZ9t",
	"iB4EcwUtLulaT8gx/C8ECkJxOzuVI5TYgsjaZLIEW4rvfkI++rIAlLLGzFhNWIMrbHjJZG1axZ19B79g",
	"Pe2KK7vOgHySqNHAooRK0eLjVAbDeIWaAeAfTfP96w7RjF07m3ftAvA08PVqlhSRH9qx34ipRiGrlt/I",
	"DtJHvMVbwyybA3HP2EoY2rZ6H2yhCEwhZn+azlM80LMVNVswELOsLhFnyyXQ6BU9ET7PFfZgB+yCyxri",
	"ei+Y0g6xtFYCQwiZZi1roAMzdIA4bfyW8VS8ZZfurQPnOXAr8k7KXEO7IViS5jk2CJ8Krk0n5GN3zDqc",
	"4GnFspTLw387nMhJC7+xQWRsPR7u5RsTjzSDHCiZs6nATcT9AZLhPFaJBF+rzaaGDnKlLGvBzZpUUhvd",
	"i9D42yECgor1ZgzA2wPqOQlWJ1WRzSWCF06tm8B0QJj09803Asp1ygFwKQqu/7hipKDaBHHZ7Y1ZV86q",
	"P48CZWoNmvsNu3PIpDh4ycGbmDgbtHaYnyXEajJSMKoEyrxKFj7lJfDSTRsnmC6RaAbgFdvaGpOfYMBr",
	"WWN4cckQNhF0YPM1qeq5T+4IHMG/Nb3bg2/vl9kYwn8yPcTTGGYOa+T45tbYP+8edG98pqDrNGpf0inq",
	"qRWHEKSvBYGkETMxg5sN8EdA75xrhwGC6hqdCoweRsSt5uC4UzAEygCchyepLX/p4IbfD5jolm7WBI2m",
	"QRP9Xn4j6MOdMPPCSxcQ87bAFrwLyDB9+AWmtREIEtWOdoRIKhpiqeJtoAX5cPzKNTdOE7Kvi+m3g13Q",
	"U56Yht4MTxcxELcDp3P/O9psoItT96w56y2UuvhMawOJMo2UBbH0y0U4BA5vA5/OcwBkUchLgrKYthfl",
	"0unvsoKq8DgC5BegqKIn/cmCnNkaXCxnrYJnBF5hhgALcDwK8Bt21NVn34xBbKaCEBjrJXU5TiyBcQZe",
	"Z9st6TnCCSCyZROx8AgHg7NL9L7JdIE20jm1j0FZfuY4L8/bndmxXqJndyALGZhxQ1RP3OzvBIq3Bdvu",
	"tI0AiS4lMbodZ/ob4ttt0JrbottFxL3Btov4vk34vKmY11E8lL0EDYRdq4v/feHn7KR3egM+2oI3Ac/F",
	"L3ZCtAz2BdG9Yo4lS8mOPuf0hm3Xcunuq+f0y5BXsGv6lgW7BcPxwRZ3azMDqpiyLnuKSUqaM8s5gSzi",
	"WSSyhwwRoBj63+w49m8BOwSL/owWRTIQ1I5uN5RKIO94j1HnF8YGX+40rBtudvw0wtIPw05+vvngfJBF",
	"CuJMFmxjl4lmgJucOE2RugRYzmHEt3rmZYDL16cgadY9cZDDW5ne+C6dUEs0Jt0OGunYV2vgV13wvSwI",
	"1eScrUeYTaaiXCVTkd0y6DRMLHWFtid6hepzhhAwRZEwFW6eDQheFJjBv1mlviNi9+RtchTHIQQYxmBb",
	"1GlGc0Ro7p/sCTnOg5bZP9l7iIuSSaGNsuIf+h1Tfd7mWCbkWJ8jxwG4t/E3WwGbnZAX+HhuArFjgOMl",
	"m/ty7uG1A75kc7Lnlkk3ZRC4cAnDWTBjK720/wMQBZ4U7ukaY0GMJJpltbJCf+YccfbbqsSwEHBDNuYH",
	"yDvOASMMYTAcQM83XptdMCUdKbKsWevUtS/OrubqNnWDALrU4QModc9q73wN3bAx3LcBwIh7TOcjd09H",
	"MvK7ATRpiIlBEGaN8o5CTju3t3LrPWp1FqZ50z3Su/snRkwV8AogC1jm2QFNz+BX4KEBfe1AltwYK8Tl",
	"DeT7JLp3w+5tGnqVl237pd1ddGsEPRyCavkomgD+4dYNggrRr+4d+CDuD6eCOvHQwYAtaFEAcg7XaEYF",
	"OQhdFGtlJX2EWamo0lwsU8xea7L9YATwGRI1QHmQMmBVWqtB/EJsLAJGELuFaEeZtW5r4mZ+vuXrDYQ0",
	"lTLX3m9Harbqdm3ZtgYQTiI3LGWW/G64g++lvw1NGxABY2Ww8VS8V+zCuWUsuOCGQVQuemm0riSuX/DG",
	"e7RVd7hJZrfNvWPfTnPEEWZiUphxEmlCnvHga2MILnaRLjRgA9KCjMivTEl/3TxsEETqIMRjOHLjpEus",
	"R2Pb7hLrEA9jEKg4LCntULkJ8NbvbdN43Lo6ZM7MJWOgcdOwoxduUnpMfmBFpTuqWR9YjWB7DY6AQzCC",
	"Wz9fR2CBfpF0evQR7FxXRnafCJJjTLBRFdyYiBg9mE7FdCoewFdbAWIF9f6tBhTDzrQw77roM/Zz14vZ",
	"bhO02+P0ulJMr2QqSbZPmRlBIYfSLrWMX4acGZZtglm1Zvnu7dv/6Wj6eHt+wP67lIYtlYLtoDdz6Int",
	"dq6H26T3LmQqhnBt5H8LgSg7oKgy9d4X33zJQzufu84Vx6QWCNTQpRY0gdCZDqaBAzfYir9ocLV60RY3",
	"J5L0Ku+MyTlkjmN3AgzaafpzyI9JFjN+LnshTY69nq/LmbctMx2qKPtIdVBpF+6d1wGsGrVAjbgBIoEJ",
	"ocC2w8FtosC9erNnRWE2YHsIYN5GWoYqnlWC8fVHbOcYmtBZpMv1zXj1KkTbs7RXZiJli+7FqOlVce0Y",
	"P9NWqHVwtqmgxfpXZy0GDehwKjxUi/0NorecPwPmVLHSn2HLdTtfi27kuKS5Z0N79V8Bv3ohVcZmIf+X",
	"JRNb47ZdYVDwvrEVmnbcsu2kGz71he9req4Lw2fVSlHNZlFSbHfOHw97OQ8awQmizRBa4WLZ4nZagR3b",
	"WclWep3dPfP6kvqwq6qgXLg7D/42tFhrrh0SOy6igx5qiaM3uO5t3rmkvaBzdP8D7art29Y1fjZibDnH",
	"gXvflDVhYkVFxrx3tZ06YDt0puGkIXfdXHwl7XMx6k920h5sxM781kkQfHq4WU/GOfe6+TRCDs4DnHE8",
	"k5sEfyd7q7qkYqQYza3QuX8PF/34KqWAGKL70twUp8rAUUOI7FVFBWag8McZgYxAO/+VEznYZ6Z111oy",
	"1le6U05j7vHmAYkI7vmGya6VRMvpDO6zH0rWhiFs9TZXNlsS0K9BerkvOQ8t9BzWdy7eOY+2HcHuDzZU",
	"nZDeB5STCL4RGY1bw5wQB8uNvNQDxQBR48GQrNaVNCtmMHetS49hi8QfHtxjlS2TMJvT7Lxvtk+VBOCt",
	"eeOO1kzbX87EEQkHiWvyIPTyYP9eY73jC6vr+U3pV54zaAQcr+v5KJTcOq3cV3yw/82ztETXoUNPO2d2",
	"8xpEa9cynKYZUsCC/d8f2/NbYfD+7wHweSsgz1vgB8/ARLWDnIk4upBu1i3kyYIEBXuYg4fTy85ZTupq",
	"nMIouyvi8F1xRzeu0M34vr8FgrQ21NS6P+mX68oVazQU3u8Hon6oMpwWll1EK9PnNrJGU3Jn4OhT6C/k",
	"WjYRlPGuAh5gT+NCY2u32sWA1exmfsNm/sBoYVb9S7iC724JPV/oNik2y4tzIS/tGcUKliDXovl3zpaK",
	"5ghaDTbAtDIImv2ARPLr0OgWcrgDQAUSvFCy/K1IJ+ZricbBtUtg9A3IkZtgYBSbGBx7wGd8MQMYRt2J",
	"xPlBXtoFWlGRF6xB2MTDBDT9rN3C2YQcz6UCYHwq1u6g08KKLWtsQLcja84sZ9Bq4PScV5t9DZt3EhBN",
	"oKaHAmNnE/JcycplOUZwz80WWmbxzrTbg3CaU2i7ffk75b4a6Xfz66X9Lah5h7KZPDC/60MQLmrfS7CN",
	"Pvtt7hBoo/hyydQOBDoueT8C7QZzKwrtVmBHEn0LsnwaVu4mv4YNr6TarGZOQk04KIicI8a1d+y15S2d",
	"bLTBPtF0o4T1dD4RoG/P7a9MSacDu/akf7vzY/zwNEEeN1wg7xmCRgfIRQb5C31EhB1r66Ha6l/hhprc",
	"AYBWuhvQG9btw3jblrbp2bsfXnx4ccecTRvgX4/Hh4H0DsnR4aMnJOel3h+6gsC0F1wsa1pA6RvAQBy8",
	"WCbLgyDZYHawtkEKHLVnfuHR9u4tyoMmG1N3pG3cN+xucLuES27lQ7alZ1QQWmgJuQKZgTVvr+/u+ZXi",
	"ecXvaXeKG2TG5RBw2bDXFTjWoTu7PTEyaFyibIIRFey2737x0vCG1/HQMzAu/KQbdtxN4ZTcjO7yisgr",
	"sHPI48RNbXSrZOtdMq1qYUlTe2Qv3j7fwqLASmpSSLEE+xbFV7OkV2gsd0jB8ZK+fff2xWA4OP14/OHj",
	"YAh9fL570h5ciTsixLll7E37JssSYVt3z/t2LwKSYYcjNaqKWrcSvfkvzT/p6PAx8Me3JRvZippbJG5r",
	"jSlJJu6bqW2TcGxJ03ZXGrJQiOy7nlVM0MKsU95D8ME5cdvzGyp9LVy13y9T3OZG7kRi+glLp73OgqN6",
	"M2O3WW9f56vB2P2RSO6/eiK5W74FH5iibaemWzwFCir/tmwj9pnmG/eH/vO9uUVsJ+2/lBjC/+IMYeNr",
	"OauYsgzaLXwuW/Dv9gRY/qX5BXibNnbtzaQ1vXw70dfmwPVT2nTzXR5OVjNxk0toKbUJyeEjODbQhoAz",
	"sH96Q+qtofuCqv02Vr9DxBqn4bt3vbKJALpd/OcbjwOqNdMaXGbJC0udMRMOWjR/qWkBGYJEPhUBeTGA",
	"euGZrNH0A+uf0YLPMVMz+GNmUqFOS5//13VH8uAPfcnwlzXPAeOsd2kJrSolKfjHNwfzKSYVYeoCaf4I",
	"8QqW9t8rvlzFbfFFQL7UTR5zmucKQJejGOQ04mmkU7nJ78dFnUcduy1MIn7d3UHqOn2Y22h194Txy1x7",
	"uoVstROk341KsKbd5JUEda7TrfXo/1tr3qszanvQkKhUCNRBdbXIAYusqlUlAQjnk2aL2uFntUBcwC2K",
	"0ZJksijoXKqk/fWTZso+4GD6xDvViPfOz7rlToHMyGuQVcEbN6mCcEgT/ZmEbtoaADJt3OuSGYEQoxMN",
	"z9L91Y6YJic4CqcnJDlfwPtuPDoHreicF9yOCOwFL+uiANR6b4tFALk3j75zU7eF/gk+Jq0SzQJhpDfk",
	"zHfJVEqZ06JVmpd0yfQBrXMuDyzPIC138p+yJpl98/O8sVD7akaG6KPNSVTUWD5Sd9KFhU1EuFFEgC2Z",
	"wJy8j//6xGeMR99pz93QohhZ/rIo20yNhNCm+LqcCzG7OERXHVDzhH5ciUVdFDOA47HFUkRA1OUM06fd",
	"9BRjCXBpRuuJ50Mx1SV5Tg0FAAWqDBw1lvtgDFc1oKlYvhSyIHnY+VP+q32yXtU8h2h9DRB+I3JawhtO",
	"DdXMaLKHafqODg9/tJdM70/I0ehxSP02Im9YzusyqmCLjo7e+NKPR0eHUfHXVC3ZZvOsKX50+H9EeeUg",
	"lZ2bijvLc2a3HSSLomAF1yVxSAIOmtNlyhsT564RloBdVSyzTzZmlOS/Ik3pnCa7OpjOV0KYKgziFAYB",
	"azQVLo+z9o4VDx9KYdfQpdJUzOWp5FI8fBhy5OTyUhhesjG0WkZTu1wx4bL7hIx+ftZXkNJQu/wWGASi",
	"yV648PMCE/mgf6hLuRiWQ5O8BjJRwLrj+GxjkOmNgT95Zz0XPkfmaMXoxRoychaS4pZ8cpCn4Cpk6ffZ",
	"QZgvO2ugwYGPAZNPg4jm+/cBO5OpODs7m1O9mor3704/koOZb/bg4ihqF8qhOwlYP36pWQ0oNfFSh9gD",
	"cMcBJCTM2egz0+mNNJvDZiRTES2QdibLkA0RDBn20Pit9Fk2YLSqrtzzAslYc8s3A4yVPYrkRUG14ZkL",
	"NsY7dty3IGRPSFJSgSkdQ+ZG/yzDRr/DoxY8k6COP1tQAhyKK6pQiEcwNZ92cg8y+ilWWs4Tc1lweCJq",
	"hT0167nfJqyPNyCY07Fb8I7tZJI7xaJpHgnInX2ge5kLLrjhtJhVsuAZ38ms66pAykGudVB8BLiwXdno",
	"96EBpOVJLN/AV1dU60upgC2NHQgy9di8/4fWl+9UHis+QvkEe2GHmYYD+OS+hBkJdomzsuKa15J6vWBF",
	"zcoh8LmoeyqswO0jGqUiZa0NZjAMNdoZGJq5/EuuRC63pywPM+vhKH0+pSSiI9N6ds7WSXeS459OfWIW",
	"+9CdPI+83uyBR+P1Whh65fiWTDFDCinBsetlS3N8/NPp7PjZsxenp7MfX/zn7OR5Ut9gRRUQgplpL8Za",
	"1mqEgxmds/WI59uTM7SMUY9HkOTVwL0M9NTHNurHLkELvdTjTJYP7F49sHe2WEltJn87PDx84HIbiJN3",
	"+xteK+3KA1CpeY72KOW5BSs1a9Y/vfhuQZs9uO8GnL549uHFx2gf7rAJ2Em0F0nXNAYXGbXtNxARnCWU",
	"9Up/e9FYWUlI+RmlA7vV3FPDhl5GOKI0EZhpXeyOrfb64OPrU+j79LEVFQRzaX29AnFCbH0ocfzTKZhS",
	"NHM6r4wWzVHaJbrlOXVQy6cw4q8i5ObUMPu+zSqqNPLtqSvVwnS2dUa2UtLM0wPEbyU4p2aZuQZ76Huk",
	"IGiqaEOV2a1SKLrLgJPrvAl7f981du3dW5EARKU9M497f7PSvhnB5/R8DRVZA+PdniyEe/bGUueuMtkL",
	"m7W/PRw68pX3ZSDzxFYPeu9psx26JwwMc9SiQ2Facduvu25mF5SE3352G5sHU71p3z4Jnnju/FdSC4cl",
	"uGSyBYAOklE5IcB4gBB5Xk7IOS9k80vJJ6TkBWL7LMyELBiD5MHrfELWKE7Gkc+D4eAcXz+7THZp1nnS",
	"E+O5zE7yr3K9eN6+WLdz+bO1k4vrFF+ngfHejC1ZQBY+yHbrUVcwPUWwZLigjlso745TarpWe0lzTCMd",
	"3AKLi1zQgufk30/fvSU4S5LbSXn4ed/tA91McOwkRQ86A3qyBVNNMnxVg+u+cJlsYcx6nModkCS9dXZu",
	"/++V/FYpOoScQVbObW/8B0zW+8PHN69D4qge4NShbdRKtcrOYlvD4O/7w8eP74mvApdzTl3cHqJRfpVE",
	"Fc1qkhOBaH0I3RiyVkQlAmA4YPYCZjtjccIKTA5tbw7ijwbLokt5DiwYB+uqm8f/ICVdAx+JZqwGg1Mq",
	"xB93wGFOxH8rDZs8fIhR7gCXa89hd+jkcsWzFVlRN9gQSPRSglIirzHAsdZsiHnXc6bQlToYln2fHQtu",
	"nZ3b/1tKlwWDp/NePF8LWvLsIyurInhubUA21AXyeiWtKlB1YB2KKYMNKs0QBmdMfEsY9wIpU1CsBHPV",
	"VIDufcXIgisvP8JNddUe6NCNu5zjZNpIKLJVj+AahcxNb1wdMPuaLBEq8aqQc6/ogwnj1QepeQ9Qs0HI",
	"ZQWESO+PpyLw8Q+BVIAyr8gz+56MSYQr/xC0vdMBzpdpMh0Ybgrmfh6S6WAu87X7Mw2cDFVnbuaRE2Mi",
	"Xd482hegi46CB39EH9kYHvrGHzjHoHp3Qj7vDDcYBKFOXB0Lm0v26sgkw+b1csnFMpkiyK70bNd9gvNU",
	"g2kZtBO2ciRkPXzojq87a8GKoNkSDNHjVhKAEGH28GFrx8LvtDYrqXDbwo+GLvW4Urykat23hTCpWvRM",
	"6z0cLuTPpPATBPUMN2EcYa5eRRMtL9fEcmQVy5PPa2/PLzY73Tj9G2Po77W1jhB1YZfwEoCiYWY583hZ",
	"AHDvCpkV1+k1Sz2uL/I0iq0tmA/JJePLlcHIfCfIBtCq4HrQtcCDRjGfUZNMgIdaMUhxcUm1M7e0tHL9",
	"wtktQvzdYbodBxRuHgwvtLG5creIYwb7ehq//y9PRkxkMmc5cW4Qga1DBcrNKZNukRAQsI22DgKLfbNB",
	"JKnsC8h0sq5C1uDpIOOGaaQIztQ5MxL/RmrB8tl8PR3cJ7y8rvJbHFF4r1yVr31O8Yr1LAx+PNgBzaNH",
	"6r9jALo7teHkuGbDaD/f/ULYeT0HHrebDqvuhguEohCYlLuMJWBHBFkV8lG9q81SAt4FFAh+l0LmYHzj",
	"YkJORCbLpoxDGfYl5tKsJuSpNCvbIjYGThCtWi25FkfLBbz4qSy5t1uTj+uK7e5tRUkAcGf+BnURmYtC",
	"Xs40KxYzwI/cKodE+WShbryeFNYKpDtjm7xPgtKSXs3ic9+XI9KrXGAwLHcXEit+vbMPKrTUeA6HPQqu",
	"bz2eNFfYkErkop2RAsjlgyF50BDLB/s3oaPN4qdxU8J1yGe+iOcwAqpDfNruqF7pVV7ZCer+wMkI8qrt",
	"i21oEXmU4plF6TKOgIwsp1BkZ80r8Eg7ZHYYDrrxcbdFb3wl5bLYjLPbht74T6YMu7plJUQRvm2lionj",
	"kztUAtgedcuKLjX/LWslQxW3VXKomZu17gGB6Zv6+hiYoi+U0nepvYXZV/ZQ0CboE4x0aYv4r4ys5GXk",
	"SEwVmwpMNGAcHD+7CqlmQtexdqLWjPwA4WdzqrS3v4GHr/cou6AK8o7Na16YERdkxYqqUbn4tsgp4qKg",
	"78bDh6fQ1MOHk7h9Nw3w4fA6mlX4/C+wth5A4ryDfWzmGWQHW9p22jqVVgJBktFs5dcqdvohHz++jux3",
	"3xFMDqp96+jM225dsYxB1EUjTzu2moYEfDj3p35JfsAlcY5PR2Py8KHOVD3/wZTFw4dkRJwCEk/KAeJM",
	"WVkZWBV2ZRTNDMnsY4x7Bg/3Dx/fvIYkQmdnZ80qwS9fvoT2ycqUxczh619f+wrwv75jTc7QQw0HgO5k",
	"Z9C5/2CH5H+3I3P1j/NcE8EuwfmN0AUoVgqZnXsFkCZ71ZDk/GJIVkej1V+GpOBDwkw23g9DQK93ADTD",
	"6cE+QXiSugAUNpqjq+Xart8ju37sF1i4F97rHKz9iuvGad1Lhrp3jf7EF2SP/eLhPqYDzHc0HexfXx9j",
	"6qNaM/XlywFfuJVrKv3jnK2tIGO5NVpAnVP8Nz6tcS3nd/XYDrxkOacw9ldM/MitVGZcajH45By2fd6l",
	"svECdXvYOx2sXqvi7+Aj+pwa+unDSRh489m+92MoM6tVkSgwHfjb56zqcPGgxvhf1XI6SNYBNA/vauEg",
	"jVylSvRV2kRJ6nbiFo8QSzWQ6LAckkaAIcP5XMJROrOczeSMjAgKwMQLwMDxfPpwoj1zhSWhs4N/VWz5",
	"P+ZQYTgej8/8wTyzizA5ODgjB/hvDX+MyE9sbvt37s6NY55PYgGsXACV9q25mdoGNtGiQE3lrxQiQtli",
	"bScW7XBW9pAd9dBRmwt+ztZ2Bm7BGic5D2L3Hv34uFg26/bw4Ql4FVtC91xeikLSHANSNARs7/GFy4MG",
	"8bHRCxIWNrT0/vlLjQTzynjShb5QqMyu7BwUJL9huSWZsAmhuiVqtvoH78pu2u3UduTkjfyVFwV1pQJl",
	"wDPi04b4kEM/Tz8zfCAqJZ3yd74OOxdSjmgGroSa7GnGSFtM++DjvPYnngo6sWEltSGXK25YwbVxH98r",
	"fmEfwJP3SBnhdat8IoDT0w8vCTWGZufaHzw/UHRYBatH7GVydHj45mmnrEuhHBd8fBiahP0lwYO72+ij",
	"wyd/ra6GcJpHbt/9MTplbNLkDwe33TGXEP920GJj/uTXbzTKIPPzVDwBYg3X8KMET94ReQF/4tnhgnx8",
	"9+4twUNN9j7KcyZG7xRnwu7NO8wG81Ya703ZQ/yaLkCcGaN4E0hO+rMLmX8DOeP/jv46HJKz//3Jtqo5",
	"Q9uZ+vt0MJ2aJLn6CSDtNMzw39wphNlC9ly425kZbgZvuKXImeZL4YKjKgpXNs75ActnJHn9+o1ltggh",
	"J6Yx7D18+Phw9JfD/79zs1LM2ckw9L2iLgUvGD4uV7xgISOB7QYiil6/fgPN2vKKrdzJoVlWK5qtx2GW",
	"P7I1eckg9jSixc9wdp5nxHt7NjmD6WzkfvLXyApgbk98Iv8JObPsxs9/evx5QigfohVxWBaeg/lI53VB",
	"lV81yKMouP3Luaj7FfO9NMiftuzr12982hTgd1o5mF2NN25lNO7UJj8Ci/CUCbbgRsdE9bX0NsxMaqMd",
	"p5fXGay93ZYagF5KRoUmBZS24wk1QksvqTaQ/xFFaGzqNURzhah156Ad6oDHfeY5WDIiL7mLn27HFnLv",
	"ioc0IczI5f2IXtf4tpyRvbmUxT4mofqT5dYW/AoUTLCLINM7A8aZ3b2zDT+58MrihTsje1yY/QlE3YQ8",
	"0hXNfIIKgXD1KJO3KFdoKVzJM7KHKov9CQGzZpTsARQe7szAUOO2hBQMkreSM3erz3wF3TyqPq4YY9L9",
	"AnmmGmyWdh6mMU4b6QN/Tl0kECEEdd4T8u9UMPJc4huYPuzwyatu8NUhhCGHOyGP3A/2adUT8uS7ww4l",
	"eu4S0XJBPhy/Aru7o0Pg/eG+RncoCDX4VIOpGep6e39z/8N7GJ0VaN0hwviEY/4FWXKzqufAUhopxQh7",
	"hX+72q8kObErHILRkpVpUZ0zfc7FwVJi5ZbA6XbJS13exweZtmgtN16Tj7h9lkv1Rkv7i6Xuz6lpf8mp",
	"gQ8f6VLbD3+C6P+WtfP6+ssX+2xcXw/Jly8HtoCtMRVfvkQymdsqcEDxvIjjeezsO4N8j0fL9iloiYNr",
	"9AyTlvwXKSDAG8YWfq94xibkz1++VPZf0RCiqDNYKODObhxAWJ6OBJIYVjSYqNNnjbTmzmAT2BL32urM",
	"CmJ4ha6vn65t4/6vIHo10lpGDVtKZSW2SrGS1yVIbP/v//N/k/f4t2eQo8pzma+jUT58+CLynv6n8572",
	"IV9nr168OXl70gATjLzPDNwn1P+R4xMo++79i7fHvWVRGRcXfHp8+mL26cNrL9qA+NMUjcWE4/cnCCH4",
	"7vXr4zfHsx/enX601VAtCEE3TEF9Jwo5Kadxfj86evL4yT7O+KS08pa9/e8Vg24gk+6LEOLpbpePP+RQ",
	"vgEojGJB90BpgQMeupj8IQG91zqou/YtNx5Q9afCrFjZhDBzQdayVtEDhmyFpWFnTTJy7fAiXAqN+RoS",
	"UAKpm4pGxRZhj7gsGzlGbGmHBB4FTzurEni++dg/wyqc/tGYYKxNU8YJO6icWzGM6a4Ut4UCFw6qjJ9s",
	"j5vh/vFkJuQLmQ5QDQNtv6WlU8VMBxPy83g8xo+hCn4cj8efyfVZCwoDhnt2dvYvbXv/Ysmtc7KxTU0H",
	"b9bE08npYIifvdoBCgQqarkK27MvFQ3YlvyCT9J0UK5nuJgY3wkjPhwfDcnh+JH9z+MhsQO1xa+nIr5s",
	"nzQjz6gOF+wNXyrUDaLZyuXExtaB17MyvAtB7p4/28QnvXEmPdIPCIHsygXjoVAONZrzX8XnP3GK2x5n",
	"Gx0/hQigKoje8RjkYgGxaE4Py8UyxOYn4EPsuo9C7dHjkS5D6skQbFsxQTnopTvK6iR6SFftnEh0tGQl",
	"F3wwHID0fzUY+qDeoe8Q/wEY5+AuhVp+ACt34FUbyZJSjlOBtMRR3F2TEaZv2jFdVRQL3sQwby6EY9Ca",
	"EtvypMTxz7sYDJpRhLiJTcc0cKKVQeMbR9JjHqa7O82UMymKddIpwpuGaxB/RyUr7UsJ+BJO6XQfm7Cu",
	"y5Iq/iu7S2oc0+ty2TUbMOf4jlQdD3NZGT0mp4yRLfYEVLbiBWzA5ltxRT+wopDDSAUMEQjTwb/LlQBu",
	"wv6DmhUVX74w8O3/8uUtcGeOp/j/EftMUsXIly/Hlj0ia2bHL4uEK9odHTya4/u5147pL9epoSYRJphz",
	"fT6r0yClp/zXEHSBDx0XZL424MfcimyFIIiNS7P7odk1da62U7DCZpGD7/Gc+ZwtCYzcW7g0SUMLfLFS",
	"6LINuIBnFFxEKGIYfNWVwKEImTO93UQOxb7ZYJKWcb9RPamPm+tzLAiLt29roOsmdHrU6QUtdnep4Rjr",
	"zRCwyHkcIWCB81EfT8VxDpT3w/ErFyw9RDCA8JdUzin9eMmEcT8nM+1iP1LdkGa3KQOIULXYNWj6ha/Y",
	"l/8Ws7vMjKq3YxO/grIfoej1cPCv2vmM3pJGR1kHtw3d55LtHqVb+FRF7fQ4WDsovmbD52xFL7jsZkw8",
	"b/spdRyDfkQQQmjvHz9a0V7xTIP+PuOWzP7jfEgUy2hR2H+JPFv+43y/nW9ta8I1K57MNlKZek+lcSfr",
	"8Gkm1WYuU9vCwYLyAsxOquTCY+TeAyERDQozzTIp8raP2ePOQn3E0psLzwXx9aOuH29bk+ueS9+bM/PU",
	"UJHTQrbveZxHE6ExII2WN5m10Y8McyJDczdDJEwtMAscko0kOFkf7tcH/xw1Mt6BL9z1tIoSsG9c7D/I",
	"yg5kZThAnWwiHCJIeg5J1LLZDsKO7IWc1Ji2yOVbG1kWOOlx15dUTPElt83A9wPEvo46SjvvufMx4ykc",
	"o5PngNyvuqcIDMFRhjpHm/bv7r8XHbHP96PPffkXn7kEM+1LCmU7oZPuCZ+VvXxP1IgvbQlOyYuCN1Qn",
	"ha8iFdvpYJ1iySDFrHeq5Ir2UrHT0H+Csmsi1ZIKMFDN10Fx2VmfRnt1V5i0cOmh3y5S2qtGP+a9bHDl",
	"yN6CcrNa1IVgGvKXOIxH59iTCqEL5/RbjfbDxkUIY8XXeUjCk43PdO9Ye3etOQEbPn0uzBoze3AAKvII",
	"YrQoIqrcdeTGpJIzGGuiZfyMU+ltcls28pBK5AY5Jn45VtQQV6OPW7ldY65GGgPZ0GIH19+mRXzVdmUY",
	"mkctsbiUA7pE0zoGME9Q/7h5oPTDh/YwAbkk8Xs49jivloLvQ/ACnrkJ+eA4QzIiC2fMQWreAMPqhrbb",
	"muGUTsj7hsfs1I9eA7fImDYH27UN2TM+IW/t2SiAmDznGoyyLCfP6rIuEEf0FeUCYv+VmpA3jAo7Zl4p",
	"8FD6QMU5fKSV++hPZBgbrtXr129GVI/gqU8tF35AXxG/Qo5mTMiJ9m9yWBcfCfJvZO9SqnNIttl+lomR",
	"Erw0Y1IUt4U7hFG1jt/6N1ve5zjD8s8lCzUWdRHBpGL/WGOF9s24+UtWFKPGGwMKarpgZh2Xsr8cRLp/",
	"KLZiRZUYMEZ9uh6VYpnZLLGgmUOxdQX+DWJFtQPlw8hoWJTMxUnPHOGekGPFwq/aOXHAeCINL55aIFJu",
	"dwfDgT1HlndXCjj4amBpuds7zFIUlh80vc3qBsUvlsTVgZxpYf5QJMzV/rUx8LSKuP0UJFhuyN7sols0",
	"F8v4knfjpO8UUHgcSjZNj0LsTjK40BHPG3SwqxZnhHQT40iDdJiCJMCsvQkdaduxCJIGCxrDTQTmKwEz",
	"kVzbt3XJwutK9g5HR/v3w5vvLNFLeHreVRF306Nb6qIOpcGIZNxWyOFXaaYwLM0e2HRilO7gmImBKrap",
	"nj59aOz5C4aR1WMHAKlJwecHOlO08j4uuXPm885IjcGoCdQG6vnDx4/vD+x/TiNH1OC8CFgfFH1PR4hq",
	"Aa4hZM8ZFjRRLffKC07JUo4ivyagIu+fv0Qn1aiiLb+PljFsMoCW68YZFGs3/twLDypz+hjH6x8GTfTj",
	"WQT6BVbn4MC5cE5lznQcL9fYWet92WfR09LnjdnjigkemM4fE10M0x6YAArptByZcy1NKAJcCNnM9p68",
	"6m48mL6/GSmk1cOQ8uagnCwIKyuzxnR50CRGN7iKe+wqY5UhVZgY5M4J8eU/TweQpSBy43bxthVv//h5",
	"Km4hOA4HsH4z1++M7xCD+BTCApxKxnmshe1AVN3uZoynAuqxfEKOHn0/PrT//+CvQ3J0GP37+0fjo7/A",
	"X0ePhuTob/bPv+Lff4kD5m9hvPLYU5D8AM/arHAQf9FEvzs8PDzsi270N995NFpGZEXBj1lpsufzQOWE",
	"LxxCbSvXepwHgV7NPG2Y2SM5Q5NLW3f55K/fff+X/tHkrTPtzTYdv+K0xNy6pVutrlHRWysSNx2a2yrE",
	"Xfh+MKOeBlEsnRDRi2mQUS8KukXHkYSgtoSFv0FGa60qpJN3HkIjt/8O/CW5wBlVORfI8nS7sAzkFS/t",
	"XWlkohqzv7okOXuWhv+wrph6LZev5bKdy6fH8OOOFjTRj4vWaMAFPv4HORhb3XRcmG1fIy6ydnsjoi6K",
	"WU8oaCNbKnnpnjtb3s8+RLGG7ds69fTJKQxTpxXLUtAZC8SN0bFXo4cGBg8hh5/UADttYOvdZPX3SPSu",
	"k3RqBmRkUoZRh2njC8A7yH6ZYHwUPF2CWWnQEBZ+WZqDpWET8gp8l1xKuT2psAi8g4U5KGwRdDXufrcU",
	"jnKhJ+A9By7Sup7jgJ00u+BXE3JqqHK+TSD8WWo/IU8d4Ii5lM0xhnOiV2DRnTPnTfxzycWQlPTq874P",
	"+/8nFOQCgYnT9fZb4g37xYozVhRZGviP/ScwvwX8008GBaAFv7KiDsAkAhpAShLpOfRuN3BMzhV56K7u",
	"kLhXCH3fYHqgyLU9HXAR9lDvdxS0eIKic+BHkDKSvpSWSair22V7idwnFtDAqK5CuhANSf+1pZfoT82a",
	"pCtTYYVHh9aVhVQv2YrRiqmDBXqwgxvTf4/kLt3lIwuZ1RjTCfGULe+Sl/BNggtl5Pnc5H4VDpYgo5ol",
	"c8BFtNO/rsNeOprY3Dj1XduCudUT6pYpYxJLE6mzv332mJf1r79y0DjYp12sXfx+/GY8fpR6LhvxkdZG",
	"JkjC51QuqoXvzkvdaEWEhEiWVAnierAUAbBw5HQw9gNdfxXgzH6o3kW8GDe11azataeQEUu8ffHA7S8x",
	"hM280bZUiqB5E16fccmpfQCWM6RwDLL/mLxEz3KMOiypOrccMcLAYfgDOryjt0iUwMpHNzhn45/9pxnP",
	"iXPLzdHl9rPdwOT3IywwDD888jVw3bocZ5rQ2OPUOK26ZDPNZFwAx7aJQFROa5yK6aPu6O2vEAX66PNW",
	"bx0Y7w3bJu8NntG1Ee+CnnHbWugnf9taDmbi1p2BH/FdaiHuxm1rOuCN21Y7FmalZMWz21ZMpwy+D/pG",
	"aOvrw2/0JCcGfd2rhv3ogeBA1A3vc+oDEzxqxAaoxlQkUTXINlANx1j4CBmoA1q3kgpegU0n5FD5b4C8",
	"4fgxXAKvLcdIjYgv/QOK4xtBcUCdyIMKVsUeoUs2D8ovF9bgvcCdWvo3RfH4SgAefrr2xT2Ddq6vz3CJ",
	"9eZwSSGXPItDoRUgZa9jYXfhZWkXSPwHPsgf+CB/4IP8gQ/yBz7IH/ggf+CD/IEP8gc+yB/4IH/gg/xG",
	"+CB26C0hBbm3aJ5hFh1ciqc+O65ZMR3dn6Gnt46aOyp54cWh9QSRQBA3JFQD3AzfL8KHjHl+fT2xZRtp",
	"En6PpEn7NQIY+Sdk/AnjP3keQZREXUXtf/nyp1oUlmr8o6DaOMgS/AmCWH3jt4btsDIXsrIzlGWur51W",
	"wsrH7Q9B7gIvKYVheLYcaM39RG2LjnjZn5y+YNKsZvRxRDwGS2uJQkdd6BMncDUIKIlNPxa0WENCYa4D",
	"TEpHyvIS1FR4A4+dChiCZlQxGvV/uvF2A2ORXFBYl/eYdB06jXiQWjM1c6wTcCqP2lwMRnLa/t4XkOuZ",
	"xvNwmdzHEQ7DM1mWUpBNOIaHD+2N2Qte0qPjGvKEsJw0gQP7llVHvXsyhAXVQt4t1emn4kto6z8DZUsL",
	"GwdNaD4Rl7u2zDWASZyfFZYl8tQlGoejT20cIEzLhFmcs1ZNbLM5G7alE4FZOrq52C0RdCpArAjZxV+G",
	"ywHzQQEpxau13PKc5oppK5TRzPAsLP6PjFUR6K/LxOSdm69Q+0DmrJBWRuEiTl9MMgeNb3c0KxhVwwYj",
	"6IJFGU105DsNnoRwBAlk7bWvLjK6S0Uzhr7Te6aFHDwduKLnbP33X5mS00FkbsEsy5BqOtSCPVEM9E1A",
	"2i+cGOC0SO18TxsIGfQK84/qwcRKK8OAmbGszOjJ+CgJkoEQA/a41ooNJofj769jm8XNuBlphfHXxc6g",
	"Xvce42h4AA2HqJFyTXjF5FNZA5v6VF59FRviXBojy5lK57X4uZBiSApqPse29q3ZK8HQfILFH4Ghuflj",
	"0/7eb8Q0spoVbPF7DGvTDuZHsrFeadNY2KP3slgvv1IO0v5lqrCXGWiEdgfKf8Xke8izvC2CcKP9njn7",
	"bJVfK+EqNNYGGzg6PC9vl7HWJ2z//U9QGEk0uZ6VfO+zX7dXsKBmxyEWcuccs6n+T1e0SqaZesUkqA60",
	"LeCEMgfHBboNeLHQEheTe4Rc2YysluAb6RxeN2mCzz60xTqNiS3itj7fMKVXTJbMpA6nYkUnlABchrUV",
	"O9teZCg9J6mz9gu35drhAney+MCvw2YwN83lG5OUZbRUu0wmLO3mpEJDycmk0mfs4M5mpdcAvUf2XsE7",
	"vN+XZ8GD8F1wSs5oxWfnbO2w5IhUXYi/VDb1cQtwjbyxPAgknUQeIMLuOjw8CqqFIXl8+P0jkvNS76dz",
	"VVI+XsJExjm7OHCN0YqjmrVBimozRW4SIaN+xV0K9wgIy/YcMUuJYbY5J8fMXHd8pH1fKVbJb4JLIwq+",
	"T7TQkswZ0QxDUNrLm17dFFHfAPUKruV2Wt2RNEpu543VHAaHJbf3/V/+OiRH3z3+C/hows4olsmyZCJn",
	"+X7ahbv/AYnm/6yQdU580ZDqp9ajjAmjaHH0YH9MQrYee4TRjYUcnwxJC6YAzzJkd01mwsT9jNNw9Wxt",
	"d7AiSq3drA60GDO34bXtabjLfihpL/SM5zsskitMTp5v4DM0Ex8SlVyp/XRmR1Wku/304bWfbXRMveGs",
	"6X2IeWq9NowvAHLK+YO7c9GALSm+1WcK96if3iVcp25B8HqkE08EtxGqR+PvRouC6lUgUvvD+FulZPj7",
	"8fjQ/n0XygVrkAykugU5SW3317uP6USzjbTZFzjRxGo0WnjvvJemIf2XNuzG1gsbbXt8Y8PcNht80P6t",
	"UjL6xW0sLkLnwseD+lqXPbnaLRk9cQnAjksUFbkswdGWxx7FkFtx9Gh82L6hnVjVR9sQkWQ1O0+BFVSj",
	"c6Lt2gBHQRWFnPrjHsSDalalIlyygtW6p5m7ozjdkeh9dVL2rVK891KJNoWAuBXLZ7x69+7V6xezZ6cv",
	"Yj7D8hdJoJ9Ms+QBdg7/ODjyQiy5YPhSdbo5eX5jDzk1bKaY/SFLOzXDl5BOfb4mEDnlr3P+/QMg/JDK",
	"9HuS07UekgflUfRrKYVZ7bcucJl8n9GeFKXN9kToks27dGddAc1xUU9Gkoope2YivRfWAzXpTgHWO+S5",
	"92SjtQE+xf0HH1ZMSXKH9p6dvti3Q207cHLRpkbPpNAysPKnzNTVBtAzDRSLmvDQZa5aZhvxb14mS3B2",
	"c6EPnXGD21doNTnquAvNWg0/GZNXzIRTTkVOnp2+ICfPexLeswtWSEjP1rRygK6rI9zIg4ujA3nB1AVn",
	"l+ls+K8UrVYAIPrPw1sEFtlas4tDBxuazGvK8iWD03cTxpnPU6kDujZXbXdevTPsWTs9ayLixz7zkFRy",
	"VjE184aLXZ58zFZZschUundI/k5qgUboVKjvfYA4410JwK69ca/dHdmyGX2QTVvBRa+7V7oWpr1Cce7R",
	"zsT+l4CCDYlFd0lR6vBXYX2/Nf4qbPtbmbNTVoD02h3kc7YAl+CVvMQoVVvQLpcyBy4zOOLGhkPRG8J6",
	"ztY6lRm/KnjGDfG4BpBQGMruDCmw+4bA9dnlBuKkmhmH7NHBlJ/7V/U+AL22mxmG7W6jN3afMDYUUVts",
	"3zMo33323RCjuGLPATh+nmqcIcT6Tgd/XtRFMTPsyrYIBacDMoKS9ssI/CTbLbmK9FwIX2cMtGBm5YlQ",
	"3WlFNkYBqxnC5hHcX9wHxfqueINwA/4jDcj4nGUFdcJQc7LXiLHOstq+ueAoH5booDXbvijuNLBH5mP8",
	"0ZRraiVwmYLB+1vcB8yWwWZNJ914ZGbs2OJkpfFt71yC24O8+0H00ElvMAdC7yNawf2dZis4xvfr3J/Z",
	"hBgAM0SeA7Nrl7WGxyE8f7aH/Xu8ECCpbbehhWP6HstDTWOYSmgo3uMHyEuinYMn/uLO70ae7ps6dm2d",
	"Glbd45ThcZ7RgkP4cc/xd583z3978HsAaUP+TmhR7H+LGwFPWwOZvnVXWs+n7RYexfs0sN7BuBPOg+VA",
	"+wxW0dH+/DVI5PtwVjcPnNM2xHTBKHrBlKYFglFRs1pwMFYnQI+WUnGzKvsuYCjggImD+FrRJVNUnD8Y",
	"kgdzxIMQTOsH97mQobNZczV3B3bbWIrAyTVzGNx9J3KW1+iJw/ow/V0AWijn+Ji9sBv796GVLnoI1aLb",
	"ZKPnobDLrd8nnDnAi/k6Es++5VsH8TD9z4z9HOfx+FqLd34TMg2MCSFcRE72zkd6JZVh2ozgy/59eEwA",
	"gGKVB59K8b3NZcWC9+zN8wQ78NmeI0wu8t16v2RpHyPfOZwyV2i41XvhFn1z0d+3QzL6Vn3fWY7AscxK",
	"y0Vt5wVWP0HxN7b012G7b8Zj0A6QoeG+uwCc1ACr3csGuQKIeB4zE5y18c534IPe2LbuQYJ6qTaAT+DX",
	"HUcES4gV38J23HlQPfTQDQopk188/4jfZQHvs3BGygT9RGddFMYgEoKXbAf4rqjbwQQQ5sbP64Afcyvd",
	"znatzldQEnw9jhDH/FWYwY/rlPOW1+un5eVIue/IPQNULb5czRGO3D978EgPhoPzWesXkKid3PP57jze",
	"5t1J+KCBFoqL1kSardzINpB+XL2notN2WLliQ1q9/VGIHRY3ZCigzCwnocjXfF9i5fXu3PDLWGkAgb4d",
	"fQOEFOzfgynuURo8k0JgBC6qVfcuV0yQlqYhdL2zuv8eBCxpZgxxOuhWdXcdQur4/cjWoE0GfjY6goBx",
	"wbU/il+dzbb99alyXngV966D2vak3GtXNmik3YR7kcYmc01CkLUfCUD+kxAz0sB1dw0oESp72msB8EOa",
	"RqTygKSXK4qJY6AJb1Dw4Z1jyL+McbwtyLnXr98g1H7AMZgOThESsURAXVIpDiGThjOlp4P98VSks9I0",
	"KQ1uOPQnzzU5F/JSOJtqAPD/KrlpOsaOk/cfqFh+HY/WjOdpEPE+V9eNowb1U/4OG3lLt9lFAf0N7W+7",
	"gWE9LdgFQ0Pfox1hmJI5VbdVSph5rz93381odulkbLSVgrydPJKKnHCjSVWrSupkfiQmFM9WPYrtYBQO",
	"hVzgUgzL2qi8Q4rdnF0BqPqLpnHi9cI5mMtyYm/gihEDZnu75kXLB+rngWYlFYZnM0hGC6yPSxHz+RvQ",
	"5LR6+23k+OWPUU+PN+82bHSS74SOXSO95303i/O9zjp2cbujvludrun8+saJ1omkqVm48FtXufE20Cuq",
	"8pkOTd4lL1Jrnt1BN43v2sgmncPRhpY2Rt27UD3CxQq1g60zG0fKNVbMi8PBcAC2SfiXN9ckwyn+XXLx",
	"rKC1ZruQ3H9JRLHARzxOJm6cB79PtkC4EEwNScEWZgjUCoK5oIUOvI82ihq2XDt7MyKxdbgCW3W2y420",
	"c8ILaeUrbVg+s3V3d56LFqXrWBVos8NNsE03gFKjS7rGSY6nAhxMo1IIqcm0C3h3MpXf0axWytJhWxTn",
	"L+oC8ix5AePW3JnH4t+utIYp+6h04GNANdZns30ZrLVOqoh8BGCfkfjzeJ6YlaHl+I3ZGZzpN9kChVcH",
	"usjHU+H6RZghtuBXHiFvsx5YLDe7b79CjjyzkvLCkmnO1C3en2iJCsOU3mWBX7qioa7B3b3pbcLpGIkn",
	"yM617VCMLmhMJYGN/cWarVy027YRnroKHWIWjxfOU4p8tQ9Rip7gJ7wuFJN1IDD93COa2x50N5bN0pHZ",
	"jTjw4fjYomSvUtxyFPvNAkKHZDM3uV+/Gc+3AcdvW7x3vmz7+mwdMJ7bPbvBLN864NQ4N+Mgm8Vqj6Rv",
	"0142ZzhlnmpzhdSN0PGE7k0YJ/w9bN2ZQ4RPiege28ZB93ujofHxSkGFM1+nU4C6LkJS0d3IO0pBlreJ",
	"VaH/0lKMP9DLNyHJdkNeeWkfNeBdQN0w8AgTB7bW4Lr7SgD/1egA3QzdUW+v2208s6CBLtXlulm0XdI1",
	"tE5ry18ZoP67qUcdtKS/DYEZaJAbwZnqjP1y5lInNLEv8EHAl5BGAX4rzFmUIMH9xOLfiMd5hI9LWz7O",
	"ueB+ZRs/R7W6SQx+aacuCAkN+pijPhtNnApF5A0cBqohYG2Cbn7cw8vwkqWTtPKS2UdSGN+GWMLNgGY3",
	"ErXumK4EaII9PjOdUSFuzkMJx8yV2yCs3cvZ3yeSnvt1Gj3qu/Zq+0PD1/b+IAOkK9wscTjVt+myFq6d",
	"HjyFpmdYyJCPBfPoILEH7Y/9fAA+Z8BI7t9tED1gE9H8YWX7hwHf7zCOwHTULtvprZiOJK0KJRLX0IkO",
	"oA3sXBakSnMlaZ5RbenHU/9vokvLfIbX1v4BAhrYXQuqlixINYQ89dnQmyBYZFUcLj05OnzzdEze7UGr",
	"yCjtk5KVUq3BUxuaHsNw0DWpkPK8rs4mgCYzh2U/Z2uCP2sI64WCTLcH4GSkCxbLUljSiRnnbK3H5LW8",
	"9P3LC6ZWjLru9apeLApLNH+gejWqqDLIlc2lZaRxVvN1aKvdPSzMKFoeJ+2QEEGCsNryAkDGxi0aHDYi",
	"OGjhdEE2hlH10uGPndAakDB7g2tg9E1ozcStvGDqbELeiWLt/eyavEjeWM5bS4HvElvYw4Mwz3BUoBpm",
	"1wtkcUjefnr9GkH1pBg1HG64adAY/NnXWkTv+poL5KO1tn45HITKJnZKs5o/sjUog9MsGWTT8ZCHGOED",
	"/IVLP9fl8pQse4Bl0qrgzgV/zQWj6g1TS/aeLlmjJ+o+uLXziSigCiltHcS9DdkqnFO3rjPAbBxMyLFd",
	"X5ZJe7Pt1sJVayboSgIOE9aFG0ELW7fB9CXayKpC7SbcZTKXtcipWg9JVnDAuEWDgWJGrV2mLXZlZlmt",
	"tFTYNIRk2IZfUsjDDqEYMgPRPx8SIcNI+wYY7bj7AGZhGPHAx3yktj1a5g9uLxNa4Whdw5Ii2VkLMH9o",
	"RIn2w4Qzy64MU4IWBBNgWIJliRrypZKcM1aRY0C3hZx0a5E5DZBoqlqqMaeaWeYN4UWhLRdJ9oO8JNwQ",
	"SGnsA8pOmciTw1nLWm2OCSLJTpm6YIpgAlMdKgEPwK64BnsR1IZDAgFmrg7mOtV+GtF5sk/Nebg4IaM0",
	"nWvIXRoG5Jp8MiYni5sOU61ZfG4cROeV8TcQF+Sn4w9vT94C3qRlqjVdMI+k7vVIYf8cebOvQEEryJka",
	"BqxTmrZcrWeqFtuzEp0sAHF0SHwuUzC/XfpUYrhoeWAvSgoYzdnK94znBPIywb39J+ZfZXhG5mxFLzjA",
	"yy0QcrUsOYDB2bLPViw7d1mz/HZc8qJAa5p9f/KAk9bsj1tngLybWuYe7IJentJ+yDMOWiZF1wRs525F",
	"wGq+oUhyC9PNvFRQbWZwlfJkJOzJc2Q0tHHjdy7fil1ACgu8hW7X4el+CTjf7hdkHNAjHG85mQ6mA0gW",
	"W8+1LSRCYY2lW+eq1Zm3kEIOVxf2hLi5sGJ2pNEhjzBxpwKwiTCRlbbEmIuGaiCfYO+zZkZvrNzAgdJN",
	"Dg8fp02psKu3c7t4QyvneYTJe06eo0+9+xOfnQn5Mh1E+XpmR5YmfxmPx9dD0v7yKHy5juJkwfA1QUDB",
	"dWMBc9SoYFc8k6B3d8k85mskAvhSwB4hXYET6xYTGDegkNgMJGkLeINSaK6Nc5gggpYAd47GauBdwZcA",
	"8xnT0utH98MOOQhaeiHt2W6cpE+eOwnWcT9I4R5o91BeKm4YpNlSC5ptHv4v0R4e2T/R2DZ4TSsjKyAs",
	"PGODyd/+9rfx3/6G2Aau+KOo+BuJoISu9KNO4cdR4R/Zei6pypvy30P5pBFnLbIZmCC3CSKna5G9hoId",
	"1ac7hp9v5l0aRcGmoRcoSsrHEImWp5JSdSnnHl+0aM9+T5hoIFopMuNeuEumooZTvW12NkZG2evfN7+P",
	"b5X3eAHZyXdGzttMZp5o8ZytZ8pzsje1FTherHSDNmLTgRFuZEsn4RiAvAaKi/TQO+cmYEmcMrHrZNck",
	"wW+523vnk14GAbNQ52oNwSAjyzK695SUNGfTQRIrISL8uzxEnulHErAHoZAbbEiyG33O7aj7z7orQOYs",
	"o7VmAZZ2RfUqqGH2aoFT6knqvJtlNi1WRO609/GUvR66NPg3TZYLLGFvdl3lkHhu75DscKU3Ueu8ATn0",
	"Ge78oFn09i6nqBV4cB8XxVdxA4LdmtGiiG6/72oT4iQU7R3VWynYVxyWkILtOi4o2zuw9ytFdd/QHAJ0",
	"2h3q900ziXOrYPTbfbJapXvX4r/oKiTbiw17XqCGvMBU5En5+fZ5O1NrnF5cS6TaOk6v5FJq0VFxQfHG",
	"aQLFvnKOrhmtKHMrmwZnKxeGbnm9xlcEfxxPhVKLCfnAMm6ZUVqQD1Sck5c1aDpHrn1m30KpQkJP1RRX",
	"trhdkbqgU6E0NFZg/PiprdO0Jey6FfzXprX5mpRcHJT0yufNoOSSi1z+f+y963IbObYm+ioIVk9Y8iYp",
	"yZfqap6omC3Lsktdsq2RVFWzp1lDgpkgiVYSyE5kSmI5HDG/zgOc2D/P0+0nOYG1FpDICy+SJZerT//o",
	"LouJROK6sLAu33cDrfUfv3Fh3vjeUFmdwl5r8XZT75WVtCUIX4BqZV+rGs9wmDNj/99V2roKAM58rUz4",
	"fRd8LrJFFZ54ew1tPTozVNy2eoOcqlXpjZiISTpTPUUW1xLYX1xyzZKlmVxIu3rMXf3KZUbllfcwf0Z8",
	"ecPFvPVNtN0FTDmpcEVz/JXGQUSEH7t/XsBn5Ka9LxYik9HDBQuvXt9wqzDyWowWHKZxRbRTYFEJXsFw",
	"rs2vUN3NZJAVrwYY1FLd6822ayhS494PhBffXQW8i4R3JYgtQh5k8ppHCGqlp1NgMy6M6AN0HUD0FlkS",
	"wvN+OD09fHc4+uHDxeXYYa6tRLlUeiEjhCxFbJSdP3/7HQLwdtnidsIJz5ScRDsH+89euMc8SXoLqWSy",
	"YDvPv3uxDrYXcf4BZgt3x3+Pvvf9rBEYEAJvvWU13gJHHADIfh3iIEzsAM61yQcHBy+ev2iC8wbIkuvA",
	"I2maWoEj6+160mVPGgNVR4ps6cxqYFanLqzoVHc9jCG1vQJj2IozHKyTlSDDZQ9WNuaB8BHbCafvtq3W",
	"MBdTCU/8Bv2ATBGpHMbQut22av9Atc/7zwd/3p902T9uhHrWfzn487NJl8VCpEaIq152gE8X0qp5yeDP",
	"k65975oPnr+YbNwviZxkPFu2WPYfHXz1vlskHBS7PYJhsX/6gYl0LLLB8+eT+nYJK/gXEOqXBkJtkyAP",
	"vdHPAe7knsdnBi9Xjs/OA0p6TNqiT9wbQ/uRRxEo8++phMC790X//3B2/P5wM/q/zx3Ar4UUvYdnJ6au",
	"uawUsPa0DCDVn/cw0qdkDDh4+fxbp5E0CpPWsolVIE14biemjzREIHcBlhu43rfhFTBXvX6/3ykJBNrb",
	"3Uq+dDcKAZq9tRQC1Tm6B4VAy4nyAWgcg5Apt5zKdbQDwPDvzk9rwVWeVhVA/T2DwIA9e/ltl708eNZl",
	"Vq+skQ1sjQ2+cqg3bH0cyNV4/ivr3U51A9D3VAZraqPqVk5tqboRJyWc3FjgiQGkX5j55qS/Orw4HtlK",
	"t9PpWlv5oELqvjodDsYana4VtR9Jzipg/fgTXFW6TD/vMv0C/rijLLgfRH9tu7YGvoMXRkXLkf1ikrfU",
	"dIYPcHCAhta/xHasKmNXx900mt6zdq6mL4Tn78no7rxJSwh/rONJ+U+YVvs3zXADsN9/tc0ibOwt4C5z",
	"4N550Cn4enTbr00tbZGODyurzoF38P5KFb6/SrEKSvhrKAcWbili6JZPPLQyrcY4Q06AWE7huuo5zDPT",
	"305nO//w0+Xx+T1Zm1AW7m1Qxna7KwuCItYdKsRb32ujysHr8579v+fBk+9WXZE9UWSfE4kKT+WeRzXe",
	"TmnTWU1vW9vTpvpGVJV3V+FoJWxU46rT9uVUOTllBlV4EbPJEh7DGO1uLeM3DeXagUGJL2OhcrtBMi/1",
	"19YKZ8HqJVY/Dza18POFyWcoPzQQ64xad5MoQOLvpEY9bXvKk2TCoytmV7S99z64VAFpwi5cVjhx+P5k",
	"BBvDSCKHPGdGqlniWHt8DA1NFZ3gGDjjSWH3ooQXsegZrZTIey96L3vP9p+93P/Ls78MO7vVz5gxxYLa",
	"r9V7zXrh0OfAkEziVyqM4WOFymXCtBIYzC1is0FqUpu7bJv2dll1/Xpyoe5QLUTOe2BW2IP/7z3vP+/9",
	"eX/SkwpZlO8kKXkqe6W0jOY83zNCxT37rx5SKNt56vlQ5dVEwy/2//JtQ4Su5Bv29L4NzuGvTor+E6nm",
	"Dfiku1h/L8I9uVooO418t8+OJUBJ4Bs6c7vIBdfSkohb5fEaNR2raQnBgy2tp40mmtZ93m9uc8Bgp7eV",
	"C9dt7vXte1aHKGh0bhtx0Ol2VsiDu8Eb/PNdb9gPcmbn4ZonBcRLXgmmUbFZ6ExQFV/4FoTtO4D2HSaQ",
	"tAInd65Z0PHPuSu1eaTPCDavyVyzPbn1Z2PQdTtlNNVnsYi0Kax2N4q4yazCdibciG9f9CCHH2NMHxxz",
	"CrlvSkDkhwKj/IzQDj9bjVl3ueubwlvu+2VMpmgO7x2GE3gFPquGVrLr7d//6qbyjVRxkMdXyzl4ZKx6",
	"z17zuKD1V5XL4UEo8Pb3A5F38HAA8e5b+8HHXj7ktx5+IdXB1x+u3nLj1lQ7zKVyIrVNon7+Tq9p7yXd",
	"1kN/8o4o8Hbj1ZDgK7H6OGa+J78+xDZvzyzy2OVfAoQcPjaa6kLFn3VcO6bMEvvkMdbr73fQfP5q+tzl",
	"ElRXsa1ZKTHXqWmY0Q49xYwDumeEdA8Zju69AbsgOHIsM1myuU5ZBKyEO5NM8Dif96aQo4qz3GVypiDC",
	"G0fFgF2llIIDZtvswBfwPko5f56wkt5kOybPtJrZr0cIb211+2jOpdp1rWyplagnTLFo1pjoG6zO5HDJ",
	"g1QcFxEejFYgtiuy9jNA2Gt0Em38DXNqqL0s8MYMtU8QMG3I30SdWLE+QL5cy7jUpwgMBbbsipmpxNGH",
	"o1YOVGUIP2/U7P3IKi1AytUKsQ2ZsnnGpQIUSsY974Wx73QfTFWyfYK+1pSUTXYW+w7bAdgYccC+99ak",
	"Hl6GYHp3O4+icmzkhKEI9AenhtlinGin1sfJjhDOEbTz4QbmboQ1jzEwK9Ts45KnN9cuT0IE5G9q+Qh3",
	"1s87eEp+mBY6CWedh2RSRI2tEts1NuUEpdu9oX1b+GFaUQKAdc9DLYq4RlFx55FoJyNA4H83kWV2LSaE",
	"fUHA/8+c4HaZewhyFSUtpvasn1sY8xWYp+jLIioEtpMJoGuFSYIst2WUAAsmCuHPUfpFPBNb8h754+b+",
	"VFOfM/YiW0hj6ICqDqXDqWjlL6I7GjB3osm9RMa1/4b7VGFEhj/ojD15itT3s0RPeFL3e2axyIxHgG0B",
	"6yDMjG0Qml3zHErzNu+UA9EKtu7Hot6UNQDstSpXEvqkvlwIuG0V3k63AwAZnW6HxwsJsLjlmFGJxlj9",
	"ofIHN7NNbJcmeAaZeI/c6TIpcL0fnsq1t7NQbamMTa97mhWQclvjd55wK+S1wixV9o+CJzJf9ofqB5Gk",
	"xuUB6iJnib7pEfFHJPz7UrHzw7cslalIIO11snQyT82GCmud8dQAVJa4lgTyhBm/OnUV9Vfkf0AFoxlP",
	"R6nIolZS/gusJi+ySk4xQCHh9+PMamfgNQHIVZDaVB+fiaHy+cchxFCRQHSq7Ythw45IJvrGDDuAeYPV",
	"Sjthk4Iw4N8AqCNspy57vt/fB+CsloY83/9vTUCjJuj38/2HVmz5xOikyAWOanMkf+BZXN5CIxyvTJi5",
	"TuI+c0R/iNpDydAi0Tc4nuCnGiqeCSZuCYMlEzOexYkwAIWH4PvlQgR0rDrO0n5//+Ch+42LCDZDG46g",
	"SJlGjMV6BxEvU3zP/FJkT1mtxvrM7/dfAoic8fXZwnAxzlkiuMnZnCdTD5nu90B/qA7TNJEi9mzlELxE",
	"rzfG6eVDDhPJmxEE04yQvmMjohoA7gBgnietB0S5NBU8A+hfF5pD4KBsB7AqPQ37UHEVV5nnd/vsJyOm",
	"RQJSS6ooE9xgrKGIJAzIZMmwuSBi+CwTAHHlYdnLGMIKNdFcx6bCg3R3ZliTx6NYXI/8rlixnMKVJBV7",
	"z0zOVWx3VyAC3d4RbCE4SYj6Yjro79cWU9vitK/32MFTk8exuEZAQzeCxkE/88SK8UQCPiAppXaOiNeh",
	"BfLs4CGXWJtf15+v29HEXIpsUcKhrysZAIBsVTTUcTa9cJeyDQCGTS9Y9Wa5ZTsCFWVT2XMxE7fpdmV/",
	"kUkc8SzerjSUugC9ZbsXmkn7m96w036H4q95LqD4XVr1CkXBdoWPtPp7oWADbdkkae72QhX7aKvSJSbR",
	"xtbo6CTefliA/2G74hXito10TEK/0gWYTl7p263fcVydd/7ImU6Ws20n4K3QF3Oeuq/86oTVq0ImschW",
	"+rJnLhx2o9GnFjcLgBF5q377nudFxhOWcDUr+Ey08aw5DBmsIrzWvZEqBsjFtJgk0sytdpHlMkqEYyFc",
	"8GgulbC6CWrQJYa+VVaWgmet8GnQk5WkO46zDVsGl3mMrPXMbQASGYuszz5ciyyD6F689WPVTE7bw+j+",
	"1sllDkcRIbKFtFW+myOe3y2E7C78NhO7DgguZaozgMl1bQVU3FpXIEYPuh8hIWTVXuFmZGNINk3wr6sO",
	"U78+252wwPIVi1ZaWgjrfWJYWcZFVLoIS9dhHwNW1Ue/a9UWtk6REbdpwhGNteVmUiy46mWCxzCqQVk7",
	"NcijOXf4NbEWiBJ6M18CEDM3DOOHiwyIE6RhN2CMLGfgApapQNPdk/qWeMKQZwHg/3AeD9+/Ji1UGIar",
	"j9gxxS2P8mTJnvil+KRt/9wDpOetnwja79hfeyGVizTBsPjXF6cEn9ofKkqhLAzQDWcCGiYVI0Z3ROtt",
	"QFHBYi3BfRowqlzFoKyRaSPYhgRh1qkPIAhcV9zv1Vxki86g3LIoaBsr+wbraIuKVUsmjSmE6TKgpUHV",
	"GgyE3JhikaKqveCxwHu4C7Uk2gVn9Q1kC/IdPYl4LmY6Wz4BEjAIJcCbv93PXcKBqi4JqUwueHwXqVPb",
	"3ticlbv7hzbeHe+yCKmv2Vw20e/XADtj4HSks7i/yk5NgLYnr21z8IaI1+A7Yh5foOXAMzlg+g0ShcIU",
	"4dCen7+hVd5f5eOgFsGrWCs0bYVx49zbrvD2RL2ey7w1XLX1lkNfxC9UITfhvW9fYAu8ofvOEYruC1hD",
	"fX0g7xf1cN0yadsrProUF8pc5i3UZXN6dys3j1+UbW4evbB1pPnSGw/wt99EpkuyP29YWe3xrUyXMxdu",
	"PWXN6UFq/Y1ounYkGL/mMmnQ+RRrQFjrXWz1pmw3NqGQbgGynM0yMSt5p+/jejws63DfaXgfgzIeoN3B",
	"OKaYVES8z3DmToroSuSBIbY/VMec+GIk5G8ZkfUc/a4qPWmCBV1CGk77I9gVPQujqRdEfcWZuiEVy0Nz",
	"YLvC0obtmGLRZfx61mULqbpswW+7GBbUhWPcdJm9/UoFhvDd7lCVPapWBN6DLqIqd1nMczGif8+lyfUs",
	"4wv62f9tq5sJXatoJvScm/lolsm4y2ZCj2K65OziMABmKbB37Rg5U3IqI67yETRgF7pMuVmDoRqPx383",
	"Wg3Vx6FibIio40DjCvwi8Kv93S5K+8OwQ8+67gkcZvgIXh527JNPXayPzkUpVlUHrWqvzp2pwVMjf4P3",
	"DvbhI0P1CboQmulK6QbjYLZY1q7cJ3tFKNouVQ0yCLAAo0HWygEMFNPTkvmx5Jd2DBFkXXS6BI/ygidl",
	"uaodLuAasFMaS5MmfFnuE/yi2Zavwa2QEYB/rgwKccVKOz7RMiHMqtUbZcIzmS/dYVs187v3hyrxNHel",
	"tZ+Fxn7HkOE6jL/bDirBsx5oxSWSv0ElE27m9ivUkMroVa8XB3eR+Js4Zv3wFSpuHT86ex5u/GYh59+q",
	"IWSnwGLh3jJWLULigzkmA5Xfqw83Kux2NJ2zLrjIEV3CWhfC548pTd0oE3ZQ24bV0xH/wFWciAnPDOQN",
	"JUCjgrwgiE5lawh3nVe1yeFodRgJPbp078+5YRxIhkI6eEfYC0m+Hz/ake/jT/gfe73/9GlMObwERvP0",
	"KYD0Gnb54cN7tnOpr4TqfcikUPby9QEEEnuv8bqx69gqpgDs0/t2/79RgpnHBUK5PPedHqqPHzEY/FJr",
	"XA7UqE9O/tnWHDrtg/0gklRk5ulTYq70745Zj53DaBnXU7iqLlK73aD51DpYj/6wtJXiVJqBlbxAG6Zm",
	"+fwdz65ENmY7VtjsDthhHLNvHPdprim3GIWVB0YYgDDdpYqsQq7yMduRKt8dsBP4E0WfSTkQM5UvPnNv",
	"xQJucPBtXAq7A4aXMSNSXlJ55nxSWFEBLUGSMhNlxeSHfJHgcCz0tTDsh8t3pyznM9RLxG2e8Sg3DP1O",
	"PTZeiFhy+8IvGU+JCe6n8xNUbt4K9aPM0YG10DFPHFqAYw5lPaQOtVs/KklHidbIqWLV1Gk3f6+4kRFM",
	"zsCuyVUrYQzMQcFUrinNwtn7HrYkw3n4fp9quqRxsx1dV5OfiO+HneEwH3ZcS4B82O/XARtfyjwRA1bd",
	"VWCb+/RpOFSvdLysP53oeOnak3FPK4FrFFr1DSSqVgbi48d/vxLLT59cZVD7x497tiRUNlThSsfYX2Hc",
	"Nuiy09N3ILgW8jcRuyzKRF6RwjRUOfbkROUYNwyUiZr9jJ5JNA4NFS/yuc4G7K9cCfZai6Gyy+tv3zz/",
	"dcC47FIc+SIJtvC5S0B3cw8NvaCUJCSB84nsM5nPiwkgMuVaqx72B/5tX32r2YldRgu3nVrf5El6JcyV",
	"VHszjW9WDF2rl1ubkcqDRozctN9RqHuABtxEJQCHN1xXAd+dwenSamLtkn1sWz0mMi17LHCpTGtldKLA",
	"QesJvND8NxdAnsZuuMptpdCwsKXuvNmRCz4TpsvOXr8xXSbyqL/rLD1MT4fq74XJQaj0WaXRQEOoMK8T",
	"TRqxztNML1KSxWWPMrHQecAvgsK+v+EQwLfeWSnGiiz5Hrk9iyxBv7CVUG8E0iSBALQ9NO5b2Ks9kIFB",
	"bWev32xVlxOm3gCW6QWMUFDXpbjNt6nM05lR0wCmmSpuFZ+2kTjDIDCqLUf5AALmxPaxWbIcsaDsO3kr",
	"4gEbXxC2ud3mTtiwjx+/kVOGf6yq5ePHPTklYfSLXV1K5/7WGnfXrU9paF+ImHHD0oRLhSuqsXfb+rp2",
	"3641DXgjzwYlsMVZUssAyUQPzQEiDvG9A8DRUmV2lvZyEwViYfUwkVCArGgOkUkUVoIeJbwpU7K8e17W",
	"izEmJY2fEwBPrgXjSSZ4vAz8HEEXNPpAHGumjJF/91rLGPQ7FVsJUn4o4klSDTMp76+g5xup1ddOAs9d",
	"HJJhnL3/cBlwTLPX/h7sr8YgUunN4DpDcXXODsRcdBMxJJZxTUN1IQSb2Ab0oJoeYEmksr/ki8QbmxKR",
	"Y64BA+sRtKecUbtl7U4+9vfOOOPT3AzYeEguhwH8MuzAjgc1EYqJNBMRzDtJHXil/BnstfTWm8o1yy5P",
	"eS1iBjsp/JJ7Aq9VvScUPnrgXUDeLjIImvLhnNWqAmuwuE25ikdmO47phchmJYtFNYSoEgcKI1co0ClO",
	"iK4fyR9gCiFqK6BkqdRnX4WroCHgowoRG1WDMWEg7ZCwuJKJBV/uoAvcVdPKaLLJ20wqbK7950tUGFyE",
	"J9O6ZOZJ4t6zqxcNQmDPAHVB4zWuBJZhRv4m8ORapJm+Fo622V7ZG6gozlVdZEmn2zHFYsHB4xSBPeDu",
	"XurtCEV8eG9ILNIPqaRNaNCaa0OSNSBmhF3tZW/75oWRbh2FoTrSi4VWcACUpKkQEdXLheIqL20WsHPw",
	"xwGPFmJAu+0nI7Kez9+ni8uwUxiRDQ6ePXfFnEhC4VCtlVzrA7cR/VE3WeatuQENDpWvXkIrcEa3i2ir",
	"nGIuE7KEzwVbWPUCasHwS5hn7PUqGQ3CZCJyQGKrTfMDim5iza5OIElB7yR2c251bGQFhmLlfhqgmvls",
	"/9nz3v5Bb/+A3jgiKVur3wvfXERzpRM9W8J4unCbgVB3E+K1epaCZ2WT9kGK1z3u91ln9wI/edQ1CWZI",
	"F9rr7aHeG2PlbIVmaJkSr/JnLiF3PcA1JMERwsYfhzg15HpA7TQbdj7ROS6S2IuWRvGJjpeD+jsUJNgo",
	"bEXMVEaSJzDh9hBLEjmzt373KsTFNV6sLQ1XGANGG6WHw2EHrehIfWf/xlc2Lc1Kb1BYNBcrLEw42EdO",
	"Rf+sjEa3UmsL5rWIEk54j6hGkCkXbuG3Iipy4ePfaS3tVSLEYdE4K3vEFfMgf/XkFrx2Q3qeAVhGnRkw",
	"+7A/lTuwkoDSUNkpcH21xkFNC24ia249fUaUzHEY6lC77/SH6l09bj4iKPRAa0H3qMwCtQ75xJHFuwyj",
	"aFdJRnZRjIC3p4qxMCp5i+6kmPxdy41p6X/VUh0lvDCQSAdmxm3A/nx2gSblpc/eBIM7cgAOcJJJ4/Iq",
	"rgL05qEi0z5ksGOeUimG2E6+TIn9+mB/tzZiz/bb2XKzmago4mtjdCusiZ+6HT2dmjbsmPdtvTZXMq15",
	"EUmZ8wEKXvpWIrlKNwkQ73vA22lz+FhcgLZbWdBBUFXdedQ2JpB3OZos1wmOFl9mDa8nywmJFF1BpLhT",
	"FnQtiJSqYTv24GPfQ2ysAK9il6EV/HvG3U92YnHUUnBDbhw2dtGwWtgrAk9uuNWVPXhw6AakNI6qTA60",
	"fTqiKeilgvgVyJ3UJ/atzwGAUhAlhHwzm5NZK7w0gHFTWQZbxB+Xp72Ty6u9oByRCq9onJp+06HKdRC7",
	"CRSaKOyISTPG20hjjki+tZOA7pyfv8HIiMu1djePDwxb31vhsG6w+5DDLDQKISLmULmwFS+VnbjuIxxv",
	"03g+rtvDy/3ZiAcmjSLUJoj6vhauTYsZA4HayKTuENeM5nfmTfplhrVvaqWhN/JKpiKWvDVyuT087Zzu",
	"0aY1ExwfodnBp4/h2tCOX70lbi0LK90+eI0CpdviMlc2niKrGy23h4ueMl5vLd3RuENwdXIdInvQk9rs",
	"z4NHd7l+rgvuwnZdiWUJiV4J1grDrlAC+1QBigzr22s/eWS8QdiFh9k7JMRSGRaLFEWys6+GVduR72+O",
	"ALrXkND7K8cDnssy3Q60xbOjQ9S3ehfvj+0FmE7H0kzcbzX3Zlkbg/2x/ZkR2T6T00D6TblMRNyK1Iya",
	"OTXr8xXzVQNwHjIyx6t09dbuutDRbSJGjdMYqUfbKI5lk0tO/VqWwOXlmYvFj6zWr8PB9RuyEsu5ig97",
	"pdz8BfyOJDHnfqmwCCIZM+AXaspgovGv3YVcgn6lnVKxhUwSaUSkVWzqrb0z+38d9MA2xY/hyiDii+0s",
	"zKRDZ1wZbKQLcPOpt3ArN3QrR0wqegtBz8AgiDdaBtZtgK5gr4TJKYE143I2z6c6u+FZzKYUZ1cenT27",
	"UO2asZfmV5ngV2QwuPV3S2m1DFNMeiClMEeAWogqoOBWa/EfpVbxDNpqnALcA/iY0YRHVwPmsjHYJNPc",
	"qqv251kGmQK0nWVmcnD9qRKFlI5Y/ylfP1NCxD6rALx/PTZfxiL41HyZ6nwuMJ2XKwPRYmTt65ITG3Kw",
	"UXWmKQi+xicGXLd7kVaRSN1ImlDFJ6M8zhlcDml0YdlQ/zvdjm1bq5W+kRT6mRAa3ha7PjlqdfbE+eHb",
	"lXHUgMrXgqBhf7Yb06f0kePEjupyzwOuO93S3lAKO5xWj7wl6md844mv4okLhk6kugI9F5fFEmutxjJ7",
	"BYHsuhj8lC2daqrEbV62ztaMwO3B5wAoBzr4ZAV++1aqEozFqVRXbfd+u8A2wtFd86S8cXxOkiQGUKwJ",
	"QokwSsnqLYyiLSrBKHbkTk/feUdQmbXHGQWlufekgcQpcjzTj1WDk61tqpNE32CgCYLjoSXy40fvYfn0",
	"acAOS/0P5U5cCylmMoYpR18U1lC7udh6Lkkre2Lq1iWXnhfkTe4O1X/oAhpdGNEedom87rmmoZO/CYJC",
	"sf3tkiPNdi/ROkW1NYxws8MTsDDYBbtY8B7F7AWg5j4i8+S1gRzJAXPRXsFAUbiYjO0/vykw7vjfE27y",
	"T5+67OPHPfwJAi4w/qt2d3rlEG3yuTCirLrrBgUmOgdNCyPrjbQTNlQtrRmq1zpiQZtq8Wy2RNCQofqZ",
	"JzK2PXygzq3KHJRiHUlEiXvRNK72GUggXCsgFJwM4qTVuDu4+13mhukbhcYgjF6vh/oGFlnEzEvKT/MM",
	"rtERz4WCBZHrmQBJtWNvbQgVhPQU0KgnBr+0S2AYlN4GbRuwv30comZGGQo8FZlBupzaZsEC/X4fn0Kd",
	"mGrw6VesGQ7uiJu8US2GR9VefNll/X7fTlS1CRgyuKI0fWqB8UUP0vp6AyZaX1EldSsJ5Ghgo8Om2VZt",
	"K/wrWUgIqHOC7x00DwOzNLlYjDZKaSznBbRmQESL1hRwkcvfUHsNd7aVZGB+gwi5aZGwwxPGjYFo+bzP",
	"LujNuliueQXsWpRGJO1klVYSj0yeCb6wvzRvbwr2yMXFMfOlwlt9ENX014sP733UQBN2pk19sdt6pQKz",
	"wvJw+NZdQfAUUbG8lrFTkZcVe0PJNLJnxUNB148ij/RCNIwQtsiWFzR7wpcXNHcabPmyU2/LCqDl4W13",
	"zS21lBx9djQX0RX+gi8/8cnZELcIV28K9kDeHJkUGV5oH8dqFEKvPBqSXAYf2awhU7nWFdYgLC8d0tVG",
	"+2bUI0+cYR4PG7hmkB3B6zmbqcdLLq3tDNlnrjxx77THKLcpPuBNssdXqZmA43pTGxvofNSAllHdFtmo",
	"lTN+G1wcaTfNnd460nOR3fWln0WWi9v6S782wwEOPTtf1EAgXMVrH7hJWgAFiHMtFmoWcb33P4A907Wk",
	"t9//9tXgzcG3NRI2GE67IrZOXmosp1ZKtmYHQmJtujfT1xHeAOE2Ixj0TrdzDQPZemmuwIyuRPekWDYo",
	"2WUBVCpo1BkgH5DBfufJU+KDpIY5OFRbsNPtPK3if64ESz0XJtd2yfgL9HahKq94dFWkXnP4FarKs+Uq",
	"psjzlisw+B/cLRBja5v4yzy60tPpiLwF0k0eIdc9a8Ap+3KUp4gNlzxhVNVa+qqXrZjeZaQ0hKbwZOSb",
	"VcMS39/fr7foBF9xn2exSHjDDljBEt9vd0nz2xHPIbO8+tHn3S187Hb0/dsV+pq1KOb03RXdfb7f0l/3",
	"9U39rX+p9XzVRb5izxwlVjl0aTYl8oGtY+CtXmzHm+ZC0+Jyl/mIE7YjbtNEwyKksIGQfcHV1HGEIa37",
	"+yLi6kexNME+qq9/eAD+fnv9gnhMQKrGaxmBCXKI6ITIt/5QgRUD/2LShAEitg4MunIVeU9fG9iqt1mN",
	"cr0Z+dGnT1OsN37DB4Q/yfWT0DfkImxeu6w/dM3vgG0BDGVFmoqMTXSh4t1WkMb7Bv8GumBL8O9Q6TAk",
	"NscEgzJoLQgpo+ohxV3m9u4FFK2QEjbs2HLvhbHXWyCfscWsnO3zOM6EMf1I5kss5gD2oMwomhfqyvSf",
	"4rNjlyEAD3v+ab+MysGCkEHGk6BRZQm6C47oJuXusVSZfb89RBn7Yrc+caz1cz4z9wpP/sqjZ3PtkI3L",
	"fHOMp4nXZTcgui0trrgEz0SHv/FIbCyRk4xTjISYTmUEySOpyHqu/qHy9ZdwAoRpyjhEO6CTsSXCsRkl",
	"Ww0UbEbMfmoJma3FR64Lnw1CJv2wNGtohhRSdCLwzOpFmyeJZ7nTarxU8wJwp7SjA6o0crCXqFY0TPZF",
	"UC9dlHszxB+i2vG6OFT2YxMxk0oFeYiBXCxVIowz399v04q86BqVfdtKYjrZVJOYtpYn9WyFpsQshyQB",
	"qACQmLXQsJUC9HMC7pqD6oQmT5JgNYeHDR5SrB0Fw56uxC9ax53d36hx5LrNMhOvWUvlUfO5awnO1Vzj",
	"QhLlR1cvoWdtS6hNmXHhZiAP28mW7K/V0FIUaaVlB4REJgDqf8AunWvWe5fhdp5yZUXYlVje6Cw2zh1o",
	"WJkmHQZ4kRp0Kq5Fwp65Qrja0E1Z+iUDdyVvdViCg/JGF0kcQEUTtHweSOCdH5avj1mP4Vef179aYTdw",
	"xAbh99rVMJGlIsM0zzZbx1poXDGpvGgPrC0JvfGzjsib7cCg5uzi+PysytvNrnm224q3SVx0XtV1VGmk",
	"c3ZX3Bhp7nLtMjdCF697VYkbIMUEs7fVDRMewT/MXKcpxQI3D3+5EKNUZFK32IMu5QJygqSO6awasPj7",
	"mC+77Ob7GyGuumzx/UKrfN5ly+8JZdQ1DLgqrCbS6XaWLd9ubp7Ged+kQMA56Mfimr0FzmlK7LezQnkI",
	"MEl0tzfA1W/3ccZ4leuYXidEBKrFnuNDZZeNyCWUTDMJaBdgeuRmaae8SCmv+8L+e/D06VAd9NmFnClW",
	"pIznPqXf+NYO1bM+eytyv3rQqMbNfKJ5FreT4pevAyN+ezjVxZxncbkLavfqpUO02mihXBLkcsM4FtTR",
	"ZnS88GhWkfDEfi1+rQqjXIk7lotswUxQB4i+vyfzAfvr6Q8BEZ2DG0HyPXDTj6TyASsDct2zk/I3WzKa",
	"y5H5R8EzEQ/Y0Vz26A+WCwNAICWHxMDdEsqfAliQirD6e2J3XLMVnW4n+KDdhL6qdkmW64zPxIUPhqpz",
	"xZmrUQGKczPwSJorVmD8mWJ2ksxWAHeQWZ62sav/MkeXXhlNOueGZSISkB8Lt4l2F0hzURQAjOC0/hYG",
	"aP+gPGc/+GhLlysUI6W9MfZgX255/i5VBKdNVcLa72P4S02oL1U0z7SiM4klcFBBrhyk3JUBq7Awh64i",
	"qzD/wiWams/5FCIOUm3sERnZYxggp3am3NiF1mXh6h0ih0+lijMxsSP+488Mn0Ex7wqsFC3zszCE8ZfD",
	"0/AloTIZzeH4ta8Fef0seOSyA6tN3zE0HLowQelAM6EO8CulKo2qpBxAa9CVNREm74npVGc5q1TuI7F3",
	"pjxJDBiSIC3flgLfv1wIXeRdZpA3s8sW2uQsRuSjqvJQzq5TIvzQQSnfbXtFvlLticmXLliwtgnD9bLS",
	"G9oC6J070MlyiV/6fAUIbgESdLC9nRIv/cvAKhheVHwG031CRk/s62X8TWPLIGDpx1X44Juqh05dYFH7",
	"kj2Q7t3W8DhrtrV2NEHD/RfLcWo7p6CVaM9eJW63DfadQC0U6dum57kBrVNKOzq0xvWiNeh/VYgsdsL5",
	"RD2FnTP+uz3hhajdDa6p5kqmqYirboOw5HpHmRvw1YGn0ElyN3zuOGdYze820NSNjSOdZ3I2E1llgP2Y",
	"Vx00QckHGekLv0PrCM2AWV+m2ZL7rjRDl5kZcZh63/TN0MkV3FqquaAYbwcpeC5r0lmNfYwR5gm3jb0v",
	"QgLgvnLD5cuXcqju1Vxg8hk01OeeYfqlH4G/G+3wwdsD5OOl4gsZ+WygtlVTJIRBv+Bw72L0EsSVIm+P",
	"cCGCfQZAQ7wKkgi5Fy6GEK7asVZPcjbn1wicLyOZu+oxLIK+4b8p7fltJzvuenc5xHENFUWNoPUTs/Ry",
	"DQ3LFlIJNgdKI22cuZyZOVz0Jy6X9S5xp6+xXQ7hsTX61OrPxJ5o1qilmlFJRkPSgpCglXexuvjJ2vpG",
	"hwva94I6lM5LSx5XlFPq8nFRpRMxmxQ5FK0MRNNKl+fJKHbR+61u6NhHCEOeNCKhlc2hIRe3qcxEt6T4",
	"A70iT5CyA1Qkk/NFynacW3wXMU8Me6vLbxCoHtFyPnn2Yv6ky578Obb/f/Dtd/MnVXNjYB1wn2rvREmH",
	"waVyMc1lo+weuLw8xV5gSyrtJNkBG3HYGfkXhx1IqQnGsOIXg0koBwHYW/MVHbgWmWmdg5/xgcewg+UK",
	"dk60mi3kLEhUq9yqWnNNPq2U0I68y7Qaz+kZ8bg4AV24ZqDBL004WLqbOWYwBAgNfV/JCT6BoJVNZDCR",
	"9XCoTdnesnGhSa9VZibc5KMija3Iad3eLs43qP5GZMRd41LQKtNg6+rZ9dLKDKtvRisgow/TNNO3csHz",
	"kLI+0zc15+oW+TpWb5C/iRHcvNd/CcCGKmmarTf2VR9au7QKs73tEy84TYunQSvEqNSD1mroFZtFXW+p",
	"1dVUXH6F1l/LZPnFDbj42YYB9/Lw55PT/9jKgEuu8lGsF/aMbtFhyZeehdGNLood37mLK5YcTSO0ulcs",
	"Gm28HA726/CkVwLhkcW+hK1qHlfuMyu7VUEDe+C+Zdxu14A4a60LzrWB3yA4sEOv1FOWkuG72T+yu8ci",
	"dXTpziw04aYOnuGZhBiUB7MPFBuwN1YgmdJUXHJCBjhqPAaKknjAXguRiqzyAhDY2lWdiblQ4MvyrwY3",
	"CtcsV9dDmc/dDjipm83pgaw7j84P34J6eXhSyVF3iRjA3plmopdmOhLGiLiGUOfCFyifMKRvcbiBm83o",
	"OTSuH+nFvczosY5MP6yj7ZByCiqchu9QiV4VIOt07FzDoCwRCIZ7HdyHpxJmezMzXPFk+VtbhOIhPanw",
	"qEM4AKwzjAIhjx/+IRT+d54vkpGreNghPRBnEWNifWiN3TOZThDh3Bk+7QQpexQl7ixv16hiHY0QonPz",
	"bq2o7nDwxTpyAJ/gANVZLtVsb8ojoOdYK52kGvEkudNXawiCI48TiF6ITBvjVBvnRmv7fp1Jt032Vr4a",
	"i1tMYIC6nesCEdbbJVTu+XO27BqaJsqPIBWB/xS83v6tbcjv6b+9Q5VPk6UnwG/ZNo7P9dEC45FhbFNY",
	"PJT6dUULA0rLR2tmGUyy4LBaVJEkaFGuALrVFza+gumrm19ZX3fZmvUVrvOfUEj60bxYlUqwPs20UFdo",
	"FDcrVLMiS9pvkz+dnzotmRoBYl6oGEK9/fXVyvXB3l6iI57MtckH3+1/t/9kt8+OuGI8McDgZxW7a8nZ",
	"4fvLN6f/Mbo8Pn93cnk8st8Q6lpmWoFJwKV7Vs30rV+oXAMz2Yo76Z0Od6JTa57TNRcPBTlh8J8VZhAI",
	"1yeU6jQTBmDOxbVQ9uYM/r3drivvjBggMQiKZxBN8wEzxXQqbwnBGwwavvInhlGwIcoX9zE+MZCnTs8K",
	"I9ggqtTEM4FMPP4SS76hAGpjqC7nVtdAFg4EYBDZNZWfFnmReW4LxO+AbYqQUOEZjGjuNaimtmVNSQih",
	"7jeVt2CIba5E6JxHCXL5AcwlZ8OLT/AAQ48xnKQ9tNK4l5HBkKpQDlkC/zZ7Ee4vs/fRPvq0V12Armnr",
	"ZR726df7KILhJvO99RkdoBHSU+D7ioTKM6sZiJghQofIrqWzxPlgC19TAAuRS5GxCACPHP53MCQLnoJK",
	"8uH9+/9JvyPHpc6WZKXdcbxCuQbTJCbasBudXRFz1tOnR+7DwIBqQJfssSkmbPrY31sR9+Au7ts5WRLN",
	"C3JF7UwKmeQ9qbpMUZvceIPf81AtmYY1AI2HjUXh9rZ1iebx2kku+0bNxmGh5p4eDNg7sbA9t+NFZvpn",
	"vYVURS7Y5eUplHo2YGciM9LAvYf8xjHPuV1+GOusZomYJnI2z1ksHF+TLKlNoiIDbn0ZC4VhXY4VrkET",
	"6gT2apkYyDzKI0DZ0Bm83C+Tf9yK1tciS3g6gmGnMkHaT5lv4wljOoPOEKMvcp7NRB68uv+pPLCOEfgr",
	"W5Wasn4PlO7oVZsANaEnhrk1wt6d+m1gq4ORCWHnEYGsXNlgeg52S/nN0r2+auewnQWujH9jqZ98t/rf",
	"CG4Fplv2p9AQ+12SSG0fwgXHFo31VqEX8msu+Gp9yeHLn7/wApaIchuzyUxAL3pC9a4P+i/Zzp+//Y7F",
	"cmF2Afa7904qefqud/pt7/oZ23n+3Qt8aOvDWuBAsltTxKVnakw7lODiyi06Lvdo/y5b4VmQ6FZvc6d1",
	"iX/qPqBy9MjKz7MtlJ/ghK03vga7R5dbJ/tXTUU5E7vVFraM7/0OSi886igld5QebltdC3Z48rkS5PT0",
	"HZPKoZOAEBkqkCLnhcrlQrC3Qh2eOJnCQpGSB3gyXpp4gMShciesiawcXjb3Q4mUU9kJq3anVuo2w1bt",
	"vRWLBe8970FTd6DmH4rZTKrZGx6J3TWiquwttFdB6rHIFE9gjSPQnFCRFGBgaxmLapLG0dlPe2/PfiK0",
	"DBJ2h0Wue2XP9ZQGEMdgff/hq6n9EoRS8VxaARgRSNOC5y3JWJ+1m7fZbvzWn4SbswGwJKA0kGG43+rS",
	"WLOJVQA2WeZz4oqq7+VgGDdt5lVLqNUdKRYQjle0cQ0foVXLsIyrWC+UMHBVCnYDkN4/6+/v9tdmhz7b",
	"wHKf63R01UY+nPaufD5EgFvcjkyn01HaBh0cJaIwK6pZ3eb1zPx3FYdNIIG7SMP2FPFaAOh266ysitYZ",
	"mgDQcIckaFlwpuy2hpg83i7cflxdBkcLi63qQaR+EKZQReJDNfKdVjP9+lXP5EugfaTt1S+TQwjX2JFK",
	"5JpCToaK5+jjRtccS/hSZF0GFIGKE88zj3sLHcvpsofBmxmPhKMvO4FEPa5yK/LLZJQswAd+/+GSXfNE",
	"xuhymnGpTB44PJ1/Ha79xDZiQh6KoZoUOVsIrgyT+RPDUm2MJEhbzGxjUsEnwoQ/4IECtRU6r2ImlCky",
	"wZa6yILgXWDMyLlUQ4VNwRhj2cL38rEDzkPPOnLw7Lm9t/iqwAam086g8yepIruyMXvxT/1riSkYYIrt",
	"DA4APAIKkt77msPVxr+QcJP/LMWNiNEvWt0jrT5Mz5MCHkwHCMcJD7kLwSlcOcsKmE6kMiLLTatDM+zW",
	"qpzcYBS9x0MqZqzmriKxbSSQXzgf0jZ3YJHaVt4hCY8Whd82cspkzmItjHqSM3FrW78DA0B7h+EndjfD",
	"+NiRr4zN2j39IW1alXV6h+FA87pbF/Vp+OvFh/dnPJ9jxiv4E5xb6E99yE+2og+dQH+CdF/7b5257GV8",
	"uls5dMu12oyYwcXbiJcB94IV9SUo8o5dbG7c4NmfCmVE3mXhgt/ts0uk/LBqHLCxOfHFdkhDgXelivb+",
	"tCiSLsRfwU9QGfA1NuZIp24nbZicdmCBqjzF6BTfrsATa5vQ6XawY/YfuOf/lBZmjv9NEvtfHseX+gKL",
	"pNA22xX4j1TwH35r/1OVBH/KBAR6toajZ/xaZMZjMjV9hQ5WjaCjQJFFjN/cvdsSzZm2LbLXjiQbKkEG",
	"KSDd2Nln3wd/764Frl2F0EII+W6r3s067iUesPvuyCld5nc7a0hyNrSkVbS+4kZ8+4LUiiBsEKXBetKp",
	"7T/dvskvSJhaeQvpt8E8QJgqRLnZ+bBijhyigFLwvXMqNpkgV9FjVUTv3Vo+EvGsLdwpbD8U+ZwOrAUp",
	"i2fiM/qQ65wnoxshZ/OWHXWGMICuEwzLGcYTTcGNMHthIJouKpA721OuQ4Nazx3cor/ef3WXkqNI1kco",
	"b5YWnu1/BCSAG93gP0sjc0TsgOkGT5BGNaF26t5BcMDdkeI4N62O177wp27HTuOqwGLi2cPlOnEsMuA8",
	"Y98D6gq8uLt9VNP2ParsgO3DnmxxFuQbBvgVnzO+C37bEhy1EnHIrxeMkMIzolBIOR5/1hFhW1KBDCwh",
	"l1a1pgF08NDtCaWFa86qxgRigzKmH1BawB2/rTnNsUFbwOM259NnSyjhyEJaIL3bA3gvrfxuoly0mliC",
	"dbTtBaWicG2FDfkTaI5n3JgbncUrEcqVuBmlVKia9arEzcXzKHuen/27MTcfsjicIf/KxnShsP42hfgn",
	"g+Fm1Wa5V0ZzbuarNCLmNCJXmtnSfXZ8m2rj0XXAT2xEVACHUCbNVdXO99e3b5b/69lfineLfr+/DYmn",
	"vby4/K6ymr/ruYq12Dgg/u1urZNtg4PYiHf3IDoMgUQXMcNK2OFJ3d1h2I6wqz/NpBG9WcZjset4Mw2y",
	"dZKXzCVTHWUiRjg7w3YOXx/tYvZWkc/RbYbkYcRDZ9jJ4TuW6USwsf1/s8dlmvDcDjDcD8crzfczsZBK",
	"9nx7e/v7Bz6ErMue7//5mXO1lYRHQeYuMdDzIpZ671rGQu+2h2BGdoT6MxiufqQXewii2ONyr/Sd2L9i",
	"HTlPkFQzszcTOcTB9AJkrJq1JpYLoTDJwza420l0RIk3ncL0KHThIPDPtXUbVR+7IEYy7gw6i2VvFqU9",
	"+q3qwSMEyIbBJiqnbdSu5rt7vPP68AgDDwBmGOJZZSL67LAKVXH4+ggWgNKq9/boLPThrUiqK4ekguP3",
	"52dt0S6+tDOG1inXwefaZQcvn38LhgVYFwjr2BzI/4sdPPuud/Bi/7saUZYvtdtuES+nLQzSqc5gtfGV",
	"7ZeJmduW5U48PDvxYWNBTU+67Iko7Nz1boTJD1YFj7398OHt6fHo6PTDT69Hpx+ODi9PPrzvszBvqVJt",
	"f4Nf1HVqxQJcbwtfKV9C/FIvJ1d8og2r1y/6j+vGlwqyk9dbjNXZ+Ye/Hh9drvQ239eOjmNwD2/tCkkd",
	"OG4fVVSfKFbfuEO1g605L1SXvf3xuMuOCKbhWM2kErvlueocuMiZiW7iWFx3WVaooRrPQLzCR8Mo/Z6L",
	"BU70TKrxAx4Yz/ove9OEm3mJytINn6WZ9n8/7+/bvx/iXAC6vD2cqPopsFroB37SF/t/+bZxDPjO3OMI",
	"qLkk9/t/frxD4ULkxu2yw7Oz0xMUR6Oj8+PXx+8vTw5PL9r322cfJ/+0kvkzXegB1B/cYja61GvyP1x5",
	"28r+jRI/rPTrlPYP6MdnP8jZXGQupWTBrwTTRZ4WOWZaYRVf1t2PIKQGRacPsMl1yn70Ic2OroyZYoJ+",
	"tBzX1wMFC+AQHcAQ1XZ/MPZfJKSgFXd+y4gCWpLl6j+naACXtnaHYxlhwhE5IZDJYFKj8+4sE9AnI3Mf",
	"oURcIa994BAezrYFA+ZOXpLcxmc5udICCtMBx1Np7CEHSKxvM65yfxAP3Elcf5PHC6nGBH0ZC8PG9RIU",
	"IIEDaODPMUtFtpDGIF6T7Vp5hDvMyR7B75NU+ncAiMjDA71ecspN3tvff7HlUV45wHs8TXuTQiaxyPAw",
	"p3ZThMHhu8+piwNIWI/y2qqKgTvt1/f7K7j+4Sn/pgKGdZ/jfss7yMbxaKFO4C1ZEZUzaGOlD3MitQ7S",
	"fc8inY7UdoC6kc7i7QF169RwwBZu+u0J/tvJ0nrue4tLeDV3x42YuFRkt5gxwAe4xDwZxpybkuiyWgs1",
	"Mgi9Adrf1G6DTPJcDJWrplerglGufaQXCwgAwHOQIpPs4QjAe+7iEUzez46QD4Hi7KSbXRLObuYvjl32",
	"fjf87eS1LfTq5P3b0cXx4fnRD64UBKtXYFvtL1UcAHj1/PDn4/IHuymkHW6Im0IIq0WZKjyB/65IIJRq",
	"Vpm6bmeS8Wuxsrx9WHshLqIr+7+ZXgm2U0RX9n9vde1VFKUruZvgae0VBB9dCQLRhODtdjDHejX6RAP0",
	"oRShy/dg6S3FbEO6Our6Nq+tmIosE3FJb4/8P+gXcrcMoeByYez/T7Mn1YAYoVZdENq8US83c3HUCMu8",
	"0KhonhsxsrdlUvKCIaRSwnvXuvEKbmb10SpgnIor+/+xqI1W0Q6jxqeCOOs2uolJrbKvuKHyYPj38mQ6",
	"EiBCjWyjbNnvrmLrwHe2Yy/Zljeq05yT1iDUFrHsjtYhBK4/fYq79+nTQTtoMVylM2fbObo4RoziXXzZ",
	"SiX76jsZZdroac6sLGK/iEnwPhbFLW8Lr4NZhoQ8QFQOP4N7377bhjGBuE8VWAnXPCvo7Gsg8RpNKmWe",
	"LVPKN3aigDGQHSK6CXyDHL6QvEcAEVWYUBKDXRTVXsZ5yeWEckXWtsVmOf6PR84pv6HPbE5/9yXbVmJL",
	"Mv8KZAsIgeBK6ZyXF1UKmCXqlgD2ENFV5/nCqtwEStHp2iuiyAC+pNy/Mc8F4TXNhIZdi/80c54ClqIz",
	"VNvXEj3pdDuJVFeej2fEzWipC0QhbJsS18mjOc8PZ0LlK8kWg2i5fE5pHNy+0WdHDnwPFBtHS/nEeBNP",
	"d6i4WrJUKKT5Tnjm2YlM10dfoyyzPyDTLviVQYcyOc9byXtCiJ/qxKgAdl/c5hBBxa+5hMz+1qheLD0C",
	"1SuGGN32Czc8c1YsasD9TQLdDnV/RN1fFXJjMG0Y0AwnQig/bNASaSojtm1gGFZ9kYqoLbqYUEVbmoQO",
	"/NoszaWBDOSSOHnVgrgD/3bu4LBb2kcLalRZUBvrDAsH9K4bmDcvqqoJEnAisXDsGH/Dbq0L1WzImnrH",
	"cq2TEZC+jRa8jQzjfWBg1QnywzFb1K8GUps23ZrcDP/ahhrsAhMAHhSXwStuZHRY4D0dhlQEgFBUxTzP",
	"086nTxCxNdUYmKJyHoFcweiEDorVDiWadJwRYybzeTEB8wWHEvGE/tGCTgq/YwxFLO1GnsBsXIllD4Fd",
	"EO7FipMqnwdagTClkGnFOHv6FNOHAdk7smtUmcIwW1rmIsqLTDx9iqnIkV5MpCLWo4nAcP88426+fY6v",
	"cehVsciUPdojnvKJTGROxNSxSOS1vT0uJ5l0aDr2emcinqAm88037Be77d/xK+GSIdlPSv6jEPj4G/YD",
	"vo0LFBWAV++evWT/xn7GTl8gFIDMQdN441EyQoitBtoEZdCci0imGfjOzrm6Ym+ApIvtnJ+/IV3knfdV",
	"29oBNRtG3NFviNu8yzDmocsg6AEFPEQ+YBXH3jXrtD5j60LMgi4lEXbZ4S8X7JWIMx1ddZ2G9Rbs9107",
	"MvNMpzLCGn/gWXzDM8EOo0gkZAIHHe3k3esK+KJhO4c//89ne4c//8/ey4NndjXcfvdtl70//vDe/nF4",
	"/m4X2nvx7pjtXEQcDhD2jueZvGXHtzlGAaAH8/D8nZuV18GCPHLrKRgxXGmvhZEzbBjRxgeLb5bpIiVQ",
	"XCIms2okRK9HSWFykWHTXI7SjlbAw8AA25vm5wedyd/s9ksYwISTZvva1uZ9pICym/IshzUsYsYhWwwr",
	"Mi057pnw5mP8TNhfyCPgEE4KE3kIaVWUgAZVIti9W2SR1rZdPNcZJd8/OztypM65UDn9mugIrZ/2g2+k",
	"Er23GZe2ua9ts+zOgiVOzhBC1LcDCkn40ZJsSksVoeXEsB0Cwe9i4S7zyAzdEPi/y/iVQrOwndzDk957",
	"9A241Fxs0/nhW5hLz4/t+eh7vJjZmkTcyDS+ENm1yHoXQuXs+Bq93LYyp6RbJQu3Vi6SRNo/HcG1RjqQ",
	"asJygxeJJshF5jvYD1x1xKXkwT2clXWHkvt2V4ErUCNhMI/9SMGlhEdXdu2qEEQB1mnIcI71JoLHIutB",
	"wDPB4fm6S8nCzsVC58KKByoBy8r3ONY3KtE87gZ1dEkKUWxd5Bxkdjs5cXT2+g2pmwCLCIf6T+enhu3Y",
	"82gPDqU983xvKhM3EBcX529Ymgk7UQ4BzsEpUi4fDDlJAbvK7PHPjm9TqyNA0p7t3FECWdenQJgnhXEd",
	"CjAoL17/aCgOowvZQBdw+GGDz5b5XCtsMgjIsxOwQGLtYBsnOHMvo+AbdAse3/bwWO09HTfuLg4+iaaB",
	"kn4uIOmnzJzENUl5mJgLZNjOn6SKupSDBPk+uwHPXy1fEus/lUrwjL0T2Uzg7uG5SMCBCSmUYBjSWQ6m",
	"F7Qmk/ZF6e5ICky7xkESsnOguKal0kKDjV2NcDh82krm3sLa3kKov+dYgT6/FlbfxO1Pih8uDR/hjcCN",
	"Kc/nU6liX9nl5anj16wu3wDq2bYpIAKDPNAeyCoU9Rh3v4MpCDBP9NStuLKtbFjs7z/7luGZBcIR2/FB",
	"JVb7gdOAXaSJzPPGjsoET1wEA24kVw6mozwW7MTa7WfvqVj9j8VEZErYEf5AqWFwmgPSAE/YmBaeyxsb",
	"l/LL6j1OWCRyKqJllAi24IrPBJJH2g+cZXoh8rkoDHtn5WsE0/LK4UMstJI5IGX6pGScaz2xwq0yFP9L",
	"ZLr3mprPfkoheAmqO9cJNKWg39yJWFMQ8Yx2g/8mEbeQfntS2UGoFNkdDFWP/Rkzut4fsx2rre122dge",
	"MfgLaWMwLuf8lcz/h30Ok44FMpHgJM9lWq47OvFRGpMSNfYiWNDP4y4bO0kswh9TmQq7MvxvbAd5ZSal",
	"QC/lK30MjDlOMGv6JkE4jdmOJ+vzO8wvJNulNCsUlHPZeM6caR9m5P7G/hIIaiZ6hIPaqn/+LEE/RWfb",
	"vzEHj8J0xsibX8ZWhtruDiqSVOdZUsxmoOccVi4AA3bMDbCo8jh2soOAK+3sQpRHJmZWF7L6VG4lFJgt",
	"EhkJCtl3F6AkYeeYKXVOOG6N2xDulL7Ue4mY8QSp5/KkvD+xs2KSyIgdnp10Atz2zvUBT9I5P6BsZcVT",
	"2Rl0nvf3+88pARRuc3tgwTF7pRkl1W0MzRAxcHr6DtLKkVx6iQB4mJQOVyFQO7plIj4jkiPQtq2YdksB",
	"bwZdd32u8g5UJepclPUB/dgtHX8+mogrssH0Se0yroWknnZJH/K4Jl13iceayEjEDbu4OGZwroO/0Wfs",
	"nsQw3LYU6GIdvEILk7/S8dLdbl2GZhlWgYS87pq8kRAo+IK3SlSv65QG4owoMIPP9vcfpwWYzAFhR7f5",
	"HgxLz8AAVytssD3WdFmGL+F8QjW4VQaNaaoiOHTZXOZmBLmQ8G/6QShwGHOjgTuhpEbo0kx22VQnib4Z",
	"FemopDoPisVaiS5DOp1mUG2LlQHXB+jdJbNalzoGxwz2VGcYk+CtXJ+6nRcPOD9A9dPWxBOCeOBhU7PS",
	"tPXyyzTCqWOwBmiAQzMSYEAEBqS//frp127HQaz7kYYFyHr3v++Aa2JmiKE+W45CTALbICf2ojnPVwu9",
	"o8C2aa8gh29pZMEO66AxjOdecuZPvOkgjTrcXzN7Fb4WQ1U1fENBYuPOxFQqgUAm80wXs3lp2Cshv38U",
	"S1bDgnr6NGwm+wHbAK4r30CY99vcaTCewgiCLkg1tR87wo/ByxjXjchSeG5Sl9iON8c4k0uXrDC7yGNU",
	"qAj5CLE6d90Ju+4/wSKuWMrte8Bid0XOgaWdZrd7Pe0eHhy+TmLJYWQfBwU2iopFQeo9mc2p2xVTddD1",
	"NxQfAQ2q9d0qtzAPrvO2oWmmF6kzSZg8K0A5iCmEksDZL45R/qHWR5M1riyAkZPsYzcYSojYIMmdVGmR",
	"sx3Pa+QlmV00FAgCysqYiOfJGzAe0HBgu72FeidgSILH9q6IFZCryBUdD5w/cVUNsKnw3bnMx2D0k9cy",
	"LmDzB2ZyKIJCaTxwTkdYiqAgwmMrjcdgsqnOjqezhFIgTMYDhmxnOgJACEKur7z6JtE3DhSfrtgGADSc",
	"pZuBkd1btBreCwDLP5k6fCSYkcq0leFK41b/w5jSi+EIGKrnvh2xNGnCl7Xq/Mx22UzkNPs4ZkP1otYJ",
	"JW6cXCchSBI/BbC3GMDEqKND9bLv9HKWiVRwW7vKpfeLSePVqBiU1KrK432Cj6TwBD7H30Xdqfs8H1PZ",
	"qcl+v/W7rLp9u6y2G7tDBbqP020C5aWNaaB5LB95R61flC2LHxysX1xficK2/dG0FRhYp6u06Ap4gQkO",
	"cTQVVs7BrTUVeOrCdzfc07hyVzXQqMEYpqzSwJMy1ovkNJrXkRufh4cZwJmjpCf86dIuifqWPbknRLqF",
	"UBOIcGXvbGAUoG3dL60d9FGduVWPNRGpHwB/zoGCj7DrJYjDaQHUwkAp88qOAOkGcE0ESyDSwpYjASc7",
	"5buBfk4pWf6lktXxiaFIDUC7nEH6WWm1t/2xc+ksI6ZFTEJfX+HMPKa4DL/zO0nMahNIaDa2FlqE0Lda",
	"YaL+0uLFnZQUnYcYJbTigazOYCI+RoRA6148fuuIZ1XnbKoLFf++Es+NjRUYEfC8AP/q7p0kIawIwDGA",
	"7U2b2m7MutjZLO+QJXjNpQzw6wzjjk9YTxF0BqOddRYwHuJvfQah2m6302suNQSkCk5J4GOFsewSvYPp",
	"or27GteN0PZJQs/wReSoAkYnEP+/mTzeRbkm3Jcj3wPy4aIBny24klMIrLQHS57x6Aoj4qmprj9DZc8R",
	"pGCVpeJNtTubvUOhJN45wAxGQvYQQ3gqE2GWJheLAVwkxGBvby/l+Xwv1zQVkHdzuOC/acUung/Y2Dwf",
	"7O1NiuhK5D3FF6JZ3n6X6JYv3IkCnx2Px0P10TXx095Q/dd//r//9Z//57/+8/+wj/j6SMafem5g3Iz0",
	"gWGWsR164Mdqt1IDjM/Bp15YVa0KdKj4qa68DxPZO+i11dPPedb/zeTN8s+2Lo/lnq1pny39n1S63+/T",
	"gDVOHBzbx9LKcYjxG7+XZl5tg7OmNWUarTJPxb3qvGn7mG/93isenzfUz/WvOGGKV4DjOyuP1PCa5BIJ",
	"shzjT4GwpHU/Kj1hFXEJEzATeTsaKUqRqrCh98qISJdUUkpPt037Q3VOF14vIZF3FXIxK/LUs9lin5zk",
	"6g6Vp6lFozt5L8hh0W9Z5Lblr6h33Y7P0UQg2TohLEH0On8lJItheLzOXF/7jy32qjldtvhiiS+QH6dH",
	"LdkD0v3OAM/AjiNkLzPG63utG+yb+oXv10fchzj+dibWbUKHeFuuJbcqv+INCI1utniLLWfvBav1k/NC",
	"MaIK1xnAtpaM2nbnOKsieaPsrdDfsn7ydx2WC4M3F19V1/0bAqZ4NC9ZIwFeZgJM3q4M7Cl7Dp/7q8zC",
	"ucp92gNDn+4oz4p83icXaz6SsSOehFdFbH/ZBUUpE1ZJ7LI0ExE4WrtMxdGsyxZZ1mULnuJHT0/f9bjp",
	"/b2IZ6Ltu/gA1SlXMfl3u1YDzefTIlHCmK4X7e6vOXIedCEJJl922VwkaVA6sxdR+kNiTMvoHwVHj39D",
	"yBwTqfsjnaW2+t/pCMVPr7qiHftlsvns/DJ3tXLh1q9t7ppWQiaDuWD367k44XK+z83pAhhKE61EOADO",
	"/rH5tvQPn0nTKoyO0YhonIxxrhCrD7jt7s5q8FphWE+FN5+MPTjCLiQZr/iEdEMsRPW4Yqfxo2L7cagY",
	"G3bgY8POgA07N/JKpiKWfNjp4sO6ociW+zjEvuM7Ex0vB8Rtng07n+hFSGGyJQ72h+oTqc3IkVsJOdjU",
	"JAKvN75FLmQhaBCWolAm6V2UkahQ/foa6App3/zbEIM3RrYXIx97Muz8Wu/Gs1o3fqjEh0Ps9aaupAjK",
	"a+4wuAlPc52yGfi0y8FtHYO5nM1DIgJ6y/HOZ6sGgJrV1vvQJNhsXJrJSAyGxf7+8+jZ/v4+O3z/mkk1",
	"MrmOrkCali1GAUFfLGHeoQr8Z7BNWob/4GV1+H+xV3kfmbRp5AsTdp96lWZiKm+xQC4UV/mARwsxuMP0",
	"oBO51lWgVjd4yLWOGzLKD2IBMr5ly7ysrbX3rxFXAeIwoK9vrHZRJFfOfNoFZ1TpRnZWVW4YvQy2j/ER",
	"yoze5TIVg3B37N32VGyHb9ynPHqIRwRaBlszvj4cqvHA2QzKEUbBYcetZWUOO4cn8KhcdX8bdsRiArPs",
	"O/3yU63KWEcwZW3TEIznsJMXuc4kT2AgfX0H+59W3dXfJnrCk/9Biv6j2YVLLaPbaRvpanUtTqMvbEQ+",
	"97WvNCCX6sgXV0Yo2uQP55I6Q4HMOJvBsmPugrlBjcj47C5KBGScYKgdp5j+Zck9hPlxhXG2gNKi4INO",
	"sz67DBDAmHSOUxFDHF7Tr7pzcXG8Syn3POlBtC6FnDdj9c757DE33Pnh299JqYcvP7SvWk/ZgmdXsb5R",
	"fjI9BzJk4IB0BvgDq+eYbbzO54dvabW0R8z5VVMLmSPXtMyDECm3GzEx80vLAtuTP64ksK3f8TaA3qFP",
	"Qnrro+V2t5YSwvPtr7B9YAHjrhTgAvJuDrKxIDIe1VUzgHJEdsu97QILvdNxGUJlr1kjOR0BVZEZD9jh",
	"RGfAY8TVkiHZLdFn8SQTPF4iq5EpQbow6ulKppV6Lq5kikW9U9DZQbAZJN4wqklfiwxyWMYD9jrT69+E",
	"gcDuO2eQeySt3rRU0TzTSheG9TB717vA80zOZpj8Xb5EQfjoCXLRSHKxsLepXCRLFK88ygvKRqU3KdAJ",
	"ooUwVj2fi6HKRKRVJBOJzxOtUyuG6TbIM4GMJCJus9PSJD2uN4I+ciex++zRGrHaFOpWLM3aH8gh4Vpe",
	"BodW9vDEuZw2mkfxwrHSIeFcCYAhQbzGc8ETiGWLGb7tnLokTgLTBMWX0Neb2rbIL/D7j++dog+1hVyR",
	"wKPOeDtqy2I4ePzD5CfFi3yuM4CR6dVAlr1V7YsttLci9yeCcXO1cVWRR6xcVU1n0aVzmq31FbngWFzd",
	"E6TLZ3g9Lyni0kzHozr9G/y4wnWDFXRCR82C354KNbNj8Ozlyxb07o1Ny8RM3LosorJx/xsa0n86uv7b",
	"fu8vv/7bn+oN/d+FEdmo/3RVW7HCVY19ub/ffXAv03ZUIrbnbls1aESaiRksIc8TrY6v3t3klZ1gycMP",
	"qxb8HsYMvOcL8QllaSJy0Vz/VgOB0WvKvRctAFoIt5rpNP0DnVCgZVHU3vrx67YLibciXzFGD3c2VJbw",
	"qtivWORcJiaIOFs/cu91/gZDxe4oZ/PK5zaM2Vqx+T6A1XYzALKFqN1ItPjVutaFvUky/trdGPylxA31",
	"Di6MLrvLoW7FYiqVxKh6H8RFmfplCJfzZvxkBDvixjkyLgCojaqf6owVKgiMtep0qwlYFYsRailgQ65a",
	"VS/Ltk638ZNUK3vuTPEYqQpGXsWY/cml1Y5oBQYPWenRqPzaWpN7YOcCLceIA0QG6rJAib/VeBvM/XHL",
	"z9WKcZ5rFWMhD0oAUfNkwSeMtGHn1+oLn7r1j4N75cG/b+cK3Qbbt2Si4+UjNaT+7fDPT7XJ8tVQJE5P",
	"qh5PktAbhT3D9gZV+2rpH67moUOHHJX98IvMFvnU9Pv4xUq5DTK+rS3Tsq4wNR4rpCZ8WrmhHLSTRzna",
	"fmO9pMZW/EG2GY7TMuI5TzRlHNYSmEsv4Z23JbnBvty2dH6333V7oivuK9idten+Apu025wQcEZu+DiC",
	"BG7/cQKRfEghUfpPq07T+4kKv/A3iwry7a0TFgSYEYwPOX/xcaXBQREHCtHYfg5KlnYawI9VBn+IMOP0",
	"9STpLaSSyaJWpsioxDzP08HeHlAPzbXJBwcHL56/cGKtHLCGfPvmG/ZKmJydQepwhJpJj72GLGEPLaoz",
	"FoF5EfzdLNcejiHwzANqNxAKo/Yhbhw+GOGULgB1nefciNywnYPeczCQWqVoIbiSajYt6N4Cl2VTvSZT",
	"kEHg+K4EUkBdR1oZgOjliAU10RU9KMDno6UALaug4rXlJ4I2WKr0j2B9LL/wO3l8sHcrbxKYS1C9w1Fi",
	"aJJ4ZRcwQmFc73W/u0tOHLQn1M/vc9MNk0DudCmxW8BbKu99PVlzHWmLw3/MBXiPKPy7WRRrCMx+3INA",
	"5tIN38ZAVwcNXRWiTy4LBtcy/kCh+ne8PX/h2P7GBrBCtulWa13/OaLB33H5T30csP/KF9oIeTT/JZP5",
	"4+2DPJo/4jbY4tvrklAqI94euPLHX9bOpYwLTCojshx9M2iVNAike+9F746odTb+EyrzJazR8K37WKND",
	"Haa0l3218+pN02G7m/MIT38/m2FDFq1fRXsf4R9bGc5hojvtEqQelxGL2z+o4VwRTh05dLea3lVm9BUj",
	"9nBqb2XvtcXHwDzc24z+BV2dstLUr3Y7ddd9TdJ0t3zN77KHUSTw/lAur4fXJKBuR6S0tSLRtvx4HP+B",
	"hMBhHJcyAMA+tpAAK2RsovW9rmePpIvWAh0jrgy7EksIFuGBl8j+qUpX0ZVYsoyrmWBhFFU+FwvGzVAp",
	"cZNIJXqxIIIcDFTcwRD3XUIVgNBID4zFsQxehuCbQ2V7bz9V4nYh1joS84m4BEYlGBR2SQTWJfTJUMnc",
	"YZk4eDh7Ytd7GYTQ2YGHx67n2Ne2CC47Yj+KpXmkHeeqD9T3u1lM2mPYa2utdba6mKIMkyTbpodxtBsP",
	"Ozj624S22r4gdAfbCaOWaWH8U+n8du5W7qVyB91H3UchsvfxSiw/rdb5odCPYrkprOdILxa8Z4hDIfa6",
	"eGAaReN2g316qFbzUdqCVrL7Pdp3+N2IG0KeYvzIwDkguxhvNezYIu+Fse0BxF2XHdTncZwJY/qRzJdY",
	"zFFjQZkRhl/3n+KzY5fjAw97/mk/zKKC5tgeQHq7a09ZwnRHFH4vTJeqsG9VAofC5nc9MgVMbXsokWe3",
	"erz89Dvw6LTFY0Y6i0ugnX+ajYkbg/ag3O7e/VXplz+KIGUEJinXjBSL1u9eieWDXBAXIkM6zK9Rd6FA",
	"cPkbKiVXQqQOKkMq5C1BaEFHfQDB3cR/wBJ5JdjFXKdyuuwO1Zk2+SwTpssungNEAFfLKpECvdlnh4nR",
	"7ErpG8W4GVCtvjEIezlUjtcIHnWtREVaW57QL6IX6cVCZBEWgfiaVzqf03fIWGRyqdBSBhl/E+EaNVli",
	"wpAd+yux7DMyOVlBnAnRu+FLBtMHwveELFCIiRnwQuDHwIdFpBTR3J5Snj4CXWlos6LRdRXwiQFVrKyH",
	"pXwmHJaSI6YgZoWTWCxSnRPtyXuNMwRYimwi8hshFLxu+uyCTwXymUIs/VDhPVwtoQCTU0QKzooU4+zt",
	"93xcErBi2KrJ4WbHzpNMVYb98OzEsB23BtgvWh/Ro12aQJbwK8HELZxisCxueCbmGiB4MfQ0125Ypjpj",
	"ib7pJRzpcyouOWrlL4fn70/ev8URyJGcFF2TygV4w6RROpG+FlmC9L+oPJj+UF0AqVEvIqxT29XDsxOm",
	"VbJsx4ZRgmdAGPJISmvwhd/J81dpwSocB3j8sPBHX6kiGkhGWMWtDDDByg+F3y5lI3K4CfAM1+N9lNYS",
	"b+HOfkmnOT2+NwZyHx/TK/n/q4zjP/7ewc7xkp++riquyPdrWf8uUfjubkmfEPpFFKkgZ7nMRAX3VHUQ",
	"vrZcZgY/4uWzRFLw6bDNVGeMTflXvvO/8p0fKd/5viLtj5QgvVI83E9GBmnSd9YSfFqwyvUXURYo7/Mx",
	"1YXHT96tRjEFExCYtlxG7v2imM6rmdd/4ARfZ8UNctLvowkHg/+72lGKljWN135kv3ykNY15Xlj0awkJ",
	"JbrPgqjZ/2nvgji9DQD/zZGmEKC8LjMd0rQN3BMJ0jRJgFzAJ54jamyfneN0G8bjhVQsFRnAFGrVbwWy",
	"/Qm+/FBRS1VxZ9uH2yiUd3/XcxVrsY202xzbdOGXUhBY+Hvkr+NHnz/+R9/obCLjWCjWcynyzbn+8uoO",
	"bhn2GUFeBa1Et1Xsygy3xx4upA07hOJZfIgbGfqSZQgvIGL4Wr8NpeEIX4Cvf+a2qO6GcnbM1pF+Z5UZ",
	"rW6G7ufvr698P/1BVjDgRpA9ubnI1q3oj/Y/LZGA1RY6h0BwB2hfvViwfeW+aKXkyShC9neC2H3FY3Ze",
	"xdR1a5pJ4xFAvhwDCgzJ70iAcu81iFPP+Iol172L2Ny4zt4KEI+vll4vfiSFElp/Jyn1r0X7BxOcRJBV",
	"D0L167Z2h2traVkEFoxdlGc8n5+5nzvbwjZAWzy780xeC1VOLfLmG3Ojs7jPfvIzriCChuX8ShhAnxex",
	"UJHor0gK9NL5sXIC7QcqBo2WxQLJeeCq9QP/5bJWVm3qsmVf0XEkyfYIpKflRt9zK4EtpFnwPJrTdv/L",
	"47fySKtpIqOK8KkBCu7+gYRAJTFze4XJz0CLoef+QqJoYy4kBwhwwbtp3+qcxDft585cYx9n5+OH3EfW",
	"7P734qbsw/ab/+EWEp3c75AJtq2JrhebrEVfXBSocOyAsS84+P916t/VSAZiKy33xVZ7vnqFXnVhOhcL",
	"fV29MJVvsqxwNmbUlktSiUxQYJU/8O19uQXFGeov7+ZvMr2gc32tyflyTlWXXlz8njNWBK3MNZvYEvZL",
	"cX9FkKurYK1turQM6CwWmRl5B9KmSEjbXlvowdt7ab+8rs0bnDZlJW1RvC1X3bNg+rGJX41YcSQy6Oor",
	"10+pe4Sj9hWJHKYzdq5DwlC/LlB19qvzjyObcGeH69qz+AYiKrDKbXG15kkSVHi3K/ZZIPC+RGbxOnvj",
	"v67h/+zX8LSy2las9se9kB/GsbuNVw+XjTvmMI7Lll7qR7xnh5ukRX8tm+2Marb5cfxFL9lb6NllO9fm",
	"i34tV+5/7ei7pdRWt8+6Ewxrtp9qU1rfcakg5B2LdLqdIks6g84eT+Xe9QHsZar2YyN2VUZXTKq8zA2A",
	"priYRQrlPzw7cXinRxhmfyonGeSD2Z+pFCGgGcaLXPdKyv+L1z9SdoWt8kMqFDSWhAVMzAAxyp4+fauf",
	"Ph2w8Uzm82LSj/SC6E/jCf3D0aHONP1rjC9a1esCegYV/HvttV5uxmxHpYtdLH62zOdaQVEqkMIvY7Zz",
	"tjw7Ad7twyTBtvMMtewe5Cdgck2aV7NqYLTOTnyKbaRjwWaeKAOG743VK7JoLnMRIbe5vhbZtRQ3XTYV",
	"PC8yjMfnmTRaEepsYQSLuBFsVsgYWS6NQEKJvy3szLv8QvjOrzvzPE/NYI/63Zd6L9aR2YVMCFLyZyLP",
	"pZqNiJmh0+3c9mJp0oSjvwAOHEgYvghL6MjwaQ8kAd7v/tb5ZS6juR0kZua6SGJ2Au21CtTC5yn/9063",
	"84O+YbFmJxX3W2XkbKlf5sIOAVfshE0lQO7GgtH1yPx3e7o1Fr9WMof8pJhh0AZb6iJzK5dA4Z+YJlFA",
	"uaIRUP4HKOA4NhzMPL3mOTX8Ii/jbzfwDgxwxWFFS7vk7MJSOq6yE/izkif4QixmGY9FDAk82n4HCxYq",
	"oJ4tSkD8aaGi8P1CBZ88yqQdc+ToL6CB06mIkEQWq5PIc2pfhZBIeI2In29kLPyrNG408lLNcPPi+LFo",
	"LqIrP14DNn57fMn2sCm/wWY9y/RC5HNRGMfv6krRn2OgvtVZzl4829+3tf9kYMUb4SumvNzcDpJbSQvf",
	"Ioq1wQHmicigo1JNM+7hmPvhlmghD2juCrdS3tUKtWwMv95xOOTU7gc3U9KtxiUuep7bsnYfxHIKkcOe",
	"1wLXljAAp1jZSGXfaanDEJRj275bcId4iu22vdJnyIaAKxlLOBlDKxbzmEu+DwLOcTsKg8nsH/gvg5ja",
	"KLT8+HvzDWwdSMxxDaL24Tn09ClEPWNVT59S1HNhcr1wLRe3uVCgFfeH6pe5TISHS+gSnjek8BD4pd/D",
	"RlwLK4YnQomphMTs8jSBtLscds+xMrBnoJGRVkYazGkjTlQ/PPj2hzSXC6DMALQPqWa2kjdFkrBLcZvj",
	"rwymFYw3UiFjItxmrSxL00ynmbST+yoR14ItMOmN6n8lcruMLiCTzlZtm9vjNzyjqYDFjnCexjF/epZk",
	"9JNVQT6fPsVED2o5NAU7Tll9cPo59Z5inn2kJ017ME3sws1yoB9Ahw2w1mZxpXQ4peVcwmzUMZjXgCO3",
	"I5avAEbeAIu8FhR5NVj4FuC/94QirgPvrgAJv38D5vki2fBNq0Ru+CZYIlo+CbYNYhhttvDTdk3cbmQc",
	"9sCGlrZiYW9Ew4ZVRhANqzqzDj45QD6urLY2pAJb7ZQnRlRK3heW/dNqPPTXS8UXMgqkFdsZt7VojITr",
	"4w3tHbMe+6Ag7xxQwxBHA88Ae2tk43KMx2wnE5CCrOwV14q/QDbtbvicvaTbrxGqUpL4j2GXAC5nZ5qI",
	"W+nUJZPoG5FBxU3wDnotkKKGxdJYIRgTxS1icnyA1WOePh04vONx2+Iao2hT+FKl24CfXKWGCDA/sAJ7",
	"sqgn9qYxF5nM2XjF5I/xepVyqzrYWg7tNoRzlSoaNNtIW3XsKHNX7FG/T1i/3//kEKZJpB97YY2/fxM0",
	"EXbueKigLbYp9A4cebhZDI390g71XN+gTgdTiRPZZ+88pxhoChh9UGoeUMofj/78xpxweAfueOvx1u0K",
	"cnEm/nwCdGkEBIcqqw3ZXGtVlIefGEOtVqccsx1beBeO5PLn0YhepLvtL0ggYI/xHje9pS562/WsW/Im",
	"cDNa6oLQ1O/anGezjC8ceYKdviO9mDgghvMiEW4jjO37Y3zfHihjuDsviryAnUiM09eC7URzrY1gWgnG",
	"DUszCSlutnm7eEcofzBsB+vtUqW7cEWcwGV5AjIFuRx4JjkkSY7d+HXZuNn/MZE4Nh+wf2P+VStN9A3V",
	"rYu80ka2AzYOHseG+rzb3ACwksdD9UrrRHCwrJAsKeULuhpgqAcVZaftHK9K/1jceokbor9/s1pMOIW8",
	"Z5XKhHG3M3EXIUB7E+7IEDTQeISiBgoDSoNVfnv4N9FmNBW2O55XbWQBrndwptjR7qFDuHVxdNmG2e+y",
	"cSLV1XiXob4MrYrR2KLhC3PhJxs7t2OPiXG5LZnO7J+4Lfy62+1XheMl7EeaE1D86Re/T3pwKQgJfUpm",
	"klxfCYefgtdYxZOlkQZC23DhEFK+veP4EQOKdV8V2UH78FHckes++sPlu1OW8xnIZ5Cp5dfgWaU+Pxw9",
	"dnzLo7wHcVZetsOoQat/E/FuWdHJa9O1HzFdFvFczDQSwyPbvemv3Jw9dhzPBFM9O+yu4gxHosi1Q7Lo",
	"t0g2P1d0UuBHYBmwHvvp/HTP/tvNNvXLf8JN7DfsPXJkwHy4bV1OKjFo2CrfA/mGYTtwTbf/sq9ME83t",
	"OvFDEelC5abLgNHDzlykM0FDMMH6bW2XWSH2YKOza54U/qb9DXvNc7F3KRciaEbMc5HLBYyYfWRyvkg9",
	"QqD/NMbx7bkgHgih6jLIkS7rfyu0SXlut3/5gZnQYIOxHzjlucyLWOwlWs3gXwyelR9KNNp47XRrncX2",
	"3HB9nAlt5hwn9wjm75bNhJ5lPJ3LiMGzsqaJLuzZDKslEzO672NDHX5Z2UoPX2Yr/xkpIkpIM1ydaLgA",
	"nRQu2sHUNCiBaFYSPbEVvpLKygewCIRVBTXIBZ/Rwrb/meAb5Q4CWQHH6YmifHH748m0oURZNbSmqaLs",
	"Qwk2FZlVIUEHDK/VY9g3TmVvHihj9l//9//DxoEi1CjqSGRQ5A07tJzDd0vemObrtIbD4v6nX70uWeR6",
	"wXMZsTewRgOTAXePQH2A4xbNgCU2Hw8g9sjA40yu41Hulv/YKkuvaWMER5h/05c07l0PeQfvosLvJMSC",
	"px6tuzw3XaI+KlG2+sOTwA/iK6R+Q2/Ze0zyP9LK7jynSv8yFyrg0/WTHawAZ7VzAdL+ilRTiol/qphO",
	"5a1wQ3MWnm9w38MTyc4y6lhwYzBMZ3Imy0qB0Qdq+JGEJJ1+oIyu1GAv2pXXVhXzGM39d9Kv1yi6ND6k",
	"nlp1g9TcUryXj4IjvnkKhMXoONkRLSfS7hoWHriF4VCDkGmc1IH6AiWEPVgZHKxgae+R7u0WhS3j77dg",
	"mJNqNgg2df0eIsik18Kjg99ynDk9dhjH7Sdx/cgNfA/kQ4B+or4B+nJdgYDtYnUMUARYXGRooEe12ANS",
	"Tpfr7rwgY1Od5VxVVJmpFyPffONw4MDy6biESrNl25WFZMucXws2l7O5yEp9PdImZ3EBeAvlIjLSVBUi",
	"qsLu2CkHm7+/2U6KnG71zoyeWj2OJzjJdHi1jTqIv3DB+Vbpa5HNBY/r5x50Ck+soEVVoQp3stgdH9Cn",
	"cBpq9+/UKlwgCQDBjxu6yzDjcAd9o6xEpTl47aTs5eUp27E6Se9S907ltdgNhD2NhykbyMRtKrNSBYZw",
	"UvuHnoYuiakdYB4A7MQlSefrslij6y7QcLIklvJZBkFykT2gipT9XU9YVihwHmi8C53zac4SwWORedUD",
	"3PzsKGQHtY/cDwJ6fWMFOmZ1gCsCgRTQwzHO82Tk2jxuNXs7+jsr5jD+xzMIhi9jkWcvSn7BtfZyquvx",
	"7eVAKu34AzcagIed0n7b8tlPa+jjWqybP+gbJnN2o7MrA7SOPVYuClhggpZQFaXJjakPXZBZqSWQjDMs",
	"1DFoZ0yWjMjr0ExQUWBEzHhODChSKzhUXjWXXlYoY3XxbMme7zMjIq1i07IIEePX9iEOdwQQu9nrlNvX",
	"9mSQwjC5WIhY8lwkS7YzEVOdCffNXQ9tiWhCmUC6FhGznYP9/f2w/tyuYLkQaCqaaR/2AE2LtDJCmcJf",
	"fo/QtWP3wbmDRkL1xzl3uXP/5NULix2pXPDY7vhwqDdsErzFrNkif44rDwPiP7oXjXi+3R6CTz3+Dgqb",
	"tWIT2ZMeHYlEYchzAREKzf0FjfbUipvcGFVXhYvyIm0sbNg2zgZCv4CF9P+R9+3PjdtI/v8KarJbK3lF",
	"WZY8k6y2pu48fky88WttT3bve9qyYBKWGFMEQ0L2KFPO3/4t9AMAKcr2JLf3y/2SeEQCxKPR3ejHp+k4",
	"BuRBqithuxalAkjVNK+p+RUKJnwnzcXl0f5oNPqLwMlzlNp0OBi+jQY70WDnemc4HgzGg8H/Q9ufP/9s",
	"3AO0bvj2Y5phlISAIDfHzuG2zSzhCJc5n+R20ExaALsvPuqAdcB7qHuOBpW9OPrjDL++Xdgf34pFmi8N",
	"Cf/h7tz+ONwVc70s8bdvwczyrUjkqhIdQ0l4shI7776bo2pq/7Iv7YhHpe55zM0C1cjygxiG1lK36ydm",
	"Z77pxGSyMjcSQhMtVfjtpm85LrsD8yFmO601m/YJcBfRfhwT0DnC8ON7VosC/3CCvBr7JyzZa2V1QXup",
	"2ZegLL9yYiAt/aBtYyVUboBf0sh5K2jsjn3Tp0/0TFxqjMB65VdHg9pSnehZm4bCuf/42dEAtt8pHjXV",
	"di7tTUOVaWXSmDbbByJcGV3KmaIDZ4nWX3gx0CMRjIBvRcN0bKZ0ZwQMf7zOnnd2ugS0DVR5ptHekKhK",
	"lanM2FyZK5WgBAWdmWRaFcscmv26MxhEVqR8dtrxXObwHHStGmy+uNVJigfjNM3ThcQQKzlTTu0VnV9H",
	"A3G7MqSgctMurgKGNhyBPGSyiAS5iO7VimZkiYuCl7zW2fl1kcalphPbpUmni8LelHROoRAEcQzdxpJg",
	"kBdplgH1h8oqjmifVuSDmsuHVJc0pMtWod9xdedvM3SOnIDoj8BY7UvHdYoSxZ5IlhjxqkDpgSZvI+xO",
	"zEoZQ/pEqhOhKK7lsUwNGRiwDGipqIcE9RNUAxKnHDiFoOoK+izsxuNcZQsHeAkxWEys9XAxS4E+gAS+",
	"nOnZjF05TDIcH0an5Pjs6FxgUKL9iO0k1NXDU/Z+uOu6uQF47AeZvR8NKu4F9kAlYlnQIQ8VKLDLvt8d",
	"iqC7twu7rUZmN/T++53R6Nua4+VUJ+TMtENbuxFsbe1hDVs4fxpTgWG17NYSERAbrILImPr9wDsl94oi",
	"SyEU0ZRaxiZ9sGe3YROr6gLPpyHjnME/J8t78r07/dBtNkvthX6gofMBUqY5MjunRWFW5AKAMWZZeJ4I",
	"Aw9C9IxGLnJRqodUL6ts1bITpVrIlAaxP5f5zDblL25eslw9NgaHzvVHL5slrV6oEret3aEffalimcXL",
	"jKBj7FD8HgYGRKSGk3TB2Jzsl97PdHzfRMd3cfNbW+imP7u+APvIKo9FbFtUHGjGEYQQPcpd4gEgHgRR",
	"W2uryHKEyq/8WmMv1AEfEoqQhiBAchTGISVDwNn1iVu/5pqx2xCImvrySj0oRLYL1t9YedMl/3kmcx3G",
	"Zq4hsq1HZmJF41fEZR5ocQziCbyxGJXo4gLpPkTS3dIZz6kewpywu1PEssDAWV4InDWHdf6pqkV1xh7Z",
	"39nc2MoI5pXWmE1GGwVXQ8Az0RwGJbHDqprbVFGzVwMsxyILkxxBGxlntMcWm/QhTZZU14rkOzsosELp",
	"eS3Y7/DuLo1TBO3Cz9rtww97q3WNIqSoUOBSvg8iH8PIJ7mLrrZqXmHIOMllQtnafq9WEbi/RCHTsurW",
	"6od2nDMb1BUe/UFqWdHt0hL/dSnzSsZuFmtpC0Yv0pi82hBsjYJRmKChg4N3vixdojt6kg+jYi4rCEtY",
	"pEZ0hhf7Vjxqo2Od9QXY9GWzyK6oCplXftUwypvN+5O8aa0jcOrUWOVfiiSYYDDO/gbbx05fnFJ8HOPf",
	"ygw8dKoS35/sB6o3RPqqDMKQgsniACf5sC/2g19JhQiGQHUxemjfjNMCYjNwRVMwAleTfNQXe2i+gyKi",
	"BsGWl3GsVNKrfRYXtfaFSb7bFxdh71aa5dqgAUcyn0XZggi5OnsIPv+2Ly5VrEHlyrQunEaEnZDj0hVJ",
	"AO8oKePh2CgyHtf8CDM5+HK7teX8W1zog1yVexfHjvWLSPxkGeISA92JSPhcUD9An5xAwDobCgbIPMD8",
	"AKI+XQp5q0sjjJ4pM0dTkRXkMF3LpSDAf30WuIpzmSeZSsRDKmEj3RKR2HEswPby63CwqFgCBaEheIhM",
	"49xtbQUXl5o2Tg3Q7FSNoVTKKBZvfedgLtjQd2McWOcFnA2w70vQGLjPQAI+6rIyEeTYdNamS3eIj0tZ",
	"ytwot63BFhC5woqz7aCDzCQ1qy76bNaWGVNg3WaIjlVZ0KgH+N2LJhViyKKrGhNMSnS8xl8nXHAZyjvV",
	"bRSFCRUnKKaiUKdxpWyQqoiiQhibotR3aabEn63ezyjnXecpiAzFNyHrNnNp0JrDixRS44dldk8eHE4H",
	"Bt6aZZEuo1xbXWUmKrWQOd9pQa0CsYblSzoHlpNdrfIYpvh/oQgSTed31D9K16sf9VwVgUa9o56TsJvL",
	"HD0jbPDu3ai1gltQyBmHEHb8JO6VPTHDvrhSVv7g71DmyOi6RuOZoxUitChQLGgslgXOkA2Ia5N5pnQT",
	"1mzatZKhUNIAO8utugajiEReK9XkGHitZlPbcSPHO9HU9unq6u8n4AW/Ojw53L8WW+Lo8vyUyzRV4vzy",
	"4PBSfPgvkSbi5Pj0+FrApfv86Ojq8FoMppNciGittNPBh0YJplrZJWxzuczJAsAR0nO9LLPVdiLTbNVF",
	"36x0J8YF1eLBsHILxg0pW4BrC5mmw8FwNxrsbPME+j9VOv8PQDR5nyZY9QoKbL4fvq2NPiD6WBqZ6Rkn",
	"hJSVLgM6wTY0t1sV64VLbwGuQ19GF6Qb9UgAjziR9wpT6UpXkBUic0Rnas/l9mAw2IExT3vC/TLkX/r9",
	"fhe/jwoxsi2kGDjtvhIW1cfCty8I9B0/leYCFqQnKgXpjaTxAGndrly9MDtwO+rbMo3vqxYqSVRmJOLE",
	"eEKx2runlNoaN4bYLNaFb2K2T61oF91zrJQKmmOwuiXxD5w5xcqOq3NGyg5uIhQnAeMaJe9FXMxM1GqZ",
	"YR/10mi++llULvNGtbMWZeQKS3X4RNqePbKlzBP7IbQjo4Hyf6sGGd2jYqi6mCeC4PTBSYzx7Hgtgw15",
	"kGWql5UzctpHKqc00qklo/H29nYhzXzb6G1sCIF4GtI7LZmR3S0S02o03t6+Xcb3ykAT++LeQv6ic3E1",
	"st9nZP/gXlmq22WaJUwjAda/qHJZVHPt4gPFD5bi2B48yQ/SUsUmuKjRXZIK1gDeCsV58I3TXxJRgqWl",
	"WObpz0uUYqEZoFleYN0KAOf8vPHG5uTMDVcnUAjv7VHFs1G7+1fuMMG6MDe35E3s8eW7f+MCiKGhoWir",
	"ffHW001ZL8PQai2g6kXO4UuaXC2j8q4R/9sTDxgeuRbz2JvkXoRAWqK0mjkF3oPtwWoncDAuVZwWJVDh",
	"pczvxRHUnRWdy8sjdx1HdaAWGA3ByBAdfUUiCvzqmPdIZXFWuZGfMTdIP6rybpmJYPhpPoPDAQ7lepZi",
	"apWB6a1OVmPLD5ZGlWAI5Nhd3ARd2rf2zg4s5z+/tP89O7+GFy+hyLfvaqVkOYYrhBoOhgPMZ56XVqfz",
	"L03eYCRVAQ8mb5x9+IpUWTfVM4k4AJnMZ0vpv0QbtbYtWDkYGvu99SELLvSHM3JhClQTivVokPjUZd3S",
	"yfWJvTHCd7jQicrcpn2PFIEjwS2e5BSYVjWiyvi7LEtwau3U0pI/YDu7sZ3dkAqDDmugDA4yDbaXfd2T",
	"N/zdoB1miFpZIdHakGXpDOJu2bXJ6xZkJ9zY/m9ye52rZSNQDCd5lWCqrtoystY7rAWFhcBQ52XyvXPe",
	"KHcO4BdxUaq79DPlOmA5r4BHPs51pbCoNkpPKkTuiB4N741UEvzYTYFdv+FS0mNw8sNcmEbApQTdw1WI",
	"3tsZjjC6AP61+/bd5E1j1HCuJ/leUWQrIWuHV1r+JvbODqxAxRDV9uG5Ha3vLqUIrMZGxfNcZ3q2gt4a",
	"J3Hy5okn450dcEfCpATgU5YhA2YGDS1PaCPwB+dYdfvIEzvEILlgJzgiszHbztn5tZ9otzFTxf2+ONlE",
	"FaVCiPrzS0IBGAOze1BJMNeGNcVqMIotRJRQgW5lMNYnbOKuYu2ItpT5fZrPepQxHiDd+X6Zf1/ufRQd",
	"Ak6TWbS3nNnVUIn46JBOuhjD25BCecJgKMrHQRMrODk5pZLoa/yn5E9xT/Aa1dzjk/VMpbyQ/zUKt6Wq",
	"XrMt9r4aF2PrvwHS3sdjgzR12T7VoyrF3gxyLyf5seMrhsux6SVYWfCwuuBGfOgxYmAN9jNZVZabV37x",
	"KgFEUmH0gNU1ONoZa7fT4ls1pDDoIUdW26oEhGvig9MlzKISHStlnbbUFWGM/PEBPa9IAnXD7Yhp5Gh7",
	"6rFno+rxMHqsxNgVpcU7djRHsuSSYQraLPSM1wCswCqJmK6GSAce6MB+QPy8hGBkx193+k2pxYHUXgP5",
	"s5PQXQxLA64xbYogCqxtCJips231xSWTZqlQpSN3oeW0m7UkgOiUGRxk9gt5PlMTpU4jcDxraL9KZ9lz",
	"YrTDqjzWiSpRiNNdClKNHH07hFUgyshtuUON6Nuh2+6ZoyxAE43jZYlROzJf0xaCfOueqDQbtxfCskNy",
	"REcuTpGHQtZGowvxFsJEUHts6gWt4n2GyRSZLMC5zFIdzA72jZ3BgH4qaTK1WD4itJKC9LJMLqQL0pu8",
	"gVlRbJ3KZ7HU239/VPko4pWJBv13H8ZHO++CRkGgVC2vcS00zm7iiElHXJTLHHaSJKxeGriYE1n7jVuJ",
	"RBlC8sE9nckCLiQVgTgt0jxdLBdgCKzmOkvakTVaF3QBoVRKZEqWuUeTsEu1zBurt0jzGxjBDfAz+2zQ",
	"f+tXT36mxzNZ3BSqjClwcjToD9ZWIxLTRn/TsfhBqQJ1FJ6+E2QQEFsZ8c8/upJxuqDXsLe2z0/H4sq+",
	"B9HZmHwnklIXSN1A1P/8o7u4QVxrvDTpg6qzsW/Ebp8M0lfGnocZiKp9zHGe68dNKnEZ8AlOZsaLflne",
	"TUWH4oi74023q4gZRtJDw6t4VOBJEwtdGQAOw/jBsrqb2l4yCcO/AkpxneRWzmfpLySqH1U6m9Pq2hVh",
	"VKJshUYImWb6QZVTDFfwc0vvAh7gBRu4PNxSvWWrsNOdkddOQz1wyjnogeYK8SVFqYhlNHSZQH+Z5MC3",
	"A/2FJA8j4NxS7D/clEr63QTanZIlWW62tmppPOgzowQcL4WsUGTZS3s6Bvv3ldfSa4ZY0fGr9mdHD2j5",
	"Rt7N2pvRIpdlqR/RnKAxHGaEaYbMxSAy3NF7BeZr7AbPKfJ8QM7VS5OlqqxC08pagdJ12wrjA71oXHne",
	"9vHs1dDbPVTVWC60MFweAZHXcbCa0p82+WU7jFVm0aHiFbhWmwoXQPAQc3RNxOyr11tTsAurRS50IrNm",
	"LiiimDjrSDMtxjxql5eOSTcQNOI0nEBPeRi4PO/AtIIfmOQfTodvKYW+OXhSyeFK0/eZmWAzQPwmDJVp",
	"QlbVUw7p5Ow3woZa4mJd2Hk4didkwqwXyIdKk8/u4UItbqwscCAI9Tjzc8yGZ2AKfnsqOgwN1h2L4zuA",
	"kOkxah8uq+WeaqGhrm+2Ep1lpeDOrkthFER7deuufvqIXVe+TgmZzXSZmvlis2lKdDCd0Numuq3GKdFZ",
	"N05116xTorNmnequm6dEZ9081XXZLLi7f6rWM5D9JnOaI10k7KRM9UKa3jpShCNaeZ/nRK+UpH3lzw0R",
	"7F5RlPpzurCn8D7KlSwtT86tlLqF9dn74eysy3BDoPqsKcp1An9o5oP31+/Sjd39XpbJoyxVJONYZXRt",
	"StLKwMscGBjECF0dnx5A/kq5jN3N8vN377b3Tg/GYu/Hfw6R/fz4z+jtzhDlB/mKkbPQIEOgtUjsXZ6O",
	"xdnh+Rk0vjo9FJ2rWGYUAGfK9LNH5ekKN1YwSlmK+ZCav9vLUW44/BCN88kyVgnT/Z3WpighIitPOEjb",
	"J4aeafHx4lMYvKJdpLntbf/iE/GXRBWZXgWhzy3Jci9wBiKQFqbgdq/GF5J0gbMH3fK7XfoZX/7NCr/M",
	"ssgq0tkieL4s6encmGK8vZ1Z/WyuKzPe2dkd7bYo+S7/JaFkd+ZPPLzpWBzSn/WwS1hY1qkcBVchs5NZ",
	"o1O3FNMxHy73k+jUgQN4AFaJq2ENdMnxpLJkOqakdQj0vXVBsH+7Oj+7kGbOlnrOwGlceabwE+Oz9Un6",
	"8e9/6ANs+K29ORBEj1GLIpNGTcfie4hHupVWI6JfkbNg7lBR6kVhAp0T3V9o6fkFlvXH1E57OxC/eB0G",
	"t4IPS0bUhm25TFK9bYlD1+UH3BgYaLEhKkiOuw28IPJqFectRnYmxwrCrqza4umiTg1O6J8DzYoOuv9O",
	"4d7dXT9OzxD682T+KiJn+r7QxTKTZGeoxmLqu7N7DDb0CGYUMWbP4vOtTOm3TJYz5e7CABR9/OJUCpXL",
	"tG0qABTk1jYaRdUCcIfoTVmkN/eK7K7VfdTv98OpnPIU2ruZis7O29G7pNtreQPnITqjwbfDtjdkIqPB",
	"YOj6cGArWs8yJT4qu2QvTXyGb7088cFgN7i1AyIzpeJO3ixWEf3kbSUE18J+gsjek0uZ7bQz2G/ffRck",
	"fNVoGw9ZCLlC1x08Yh5VZ+8fV+KDSkod378061t6rY10wa/dN6mReUBk0YMfOYLGuJkpWZlop3XXN3dm",
	"iXbj06F9Guu5KlUff1f5LEurefQwWnsEi5Sl+WwpM/uccZX92h27RPxJTvybbx6xdMkUDmgGeBZeMoBx",
	"sa7Tzvh8Hhngy105Xik61486ujJyprqcnYt9eAOiM+bDltbhp8xckS0Qb17Bw1bD02ZR/+8X5SCg2WHo",
	"VuA3dpxl8kG2Cv0wNG5ri2URLWdnCg2nXbeq1dqyAnyOkyudkLF2HQQMqgSU54lHUSX8LSRt0gy2tlBu",
	"QGQRfr1Hf0TFPAVavZX3jSfQZDRlkGPLnhGtvzDRrrbvwV+RWZa3/p8aBkqtkLdhK/gzGvYH0V0mq3mk",
	"PhfQCH/f6b+1vKnxC7xJfe3lZl7qAkOip3Em7a1jFL2NKp3nykTDwXB3ZzDEM8lPdbGs4MlgOPzLlPGU",
	"galwNQDstL+5w+hhOB44OXWGFrXg2HYoHIiPEKC3k0mcQT8SDJVpZZS/55TsDIZfcUxqQuS1YuQlQbJG",
	"/7jpf6rWHQSWi+FKoJsHk3zZPIR8zeVoS5ehWmNHDnXcUfypSlJJOdoeTQmZYbDgxEp7Yd6fzIULaxaQ",
	"FwYqHqtqj3Ll7S3HCwz1BBKSlXq3K9DRkogOhAh9ujzuAlHZf41hNts/FWr211t4u4eh6PgPvLVz6CG9",
	"XOSvf/dR3RbPvIzD/HR5gtGEpMshaiIWjAC4xBH9QXFmjsj3rGgRGMQpfmSt+Dd2SAhP3rGIflg7jbab",
	"IGNtT95cUIDnxVwb7WM2bEMHedC20OmPH84vHwc/fJzpvb29vbOrT/PDT7O9hsqHeGx0uYg+wP31Au4V",
	"QESIUpD+ggb9OthGrPMHBbTHuEBknPYUj+TXco35HxKKm/xMnLNPX6st5Fh8+QLL+/Q0meT7HHwgvnzh",
	"QAR4cOD7s8+C7p+e3Af+p4VyXYDytogrCG704aZw4bQUuL6ydr1dOZS5e/xTBXVlZss0UduU7EiIAZDa",
	"yNvSko4fS8iDxujkICsbcY3IWTP2aA7cu73ofjb13ksVKys3AHmilvAuKzQMfzahyQRnShOffvnisNOe",
	"nqZjcYxZeGhhg9hLeu2blOBdn576/f6XL9vpHTTY5xgVmYlMz9KY30e4hbKUK25hf8GPGNT54GnFDZZ5",
	"Zrm2C3rhZvg7je5BlZAY5z5Krf8TmPDTk2URX778571aub/v0rIy7l+ZhH+MxYnWBYLOcQzG1taHZZqZ",
	"KM3F9yorVMnx9jt9sbVVxeXy9nuzyLa2RCSofCAS8HZlVhDNMasI/8yUMjaYNk4A0KVeAHAZkOx0OvV0",
	"BL98+eL6F3OzyG7IqPH0xA3g//zhSkyRN+MAiDejr4se2CHx7wC4j+2h7FquHjMIS8EUtFvIJlYZgqmI",
	"TtETSfrQE/OdaP6uJ7K0J5SJMW5d+KCPIpMpTQ+D0koFqYCJKJVMXCEY8EVtbamfYeEO2fHs46o5Spq3",
	"tNq4RpYIO+pnrpQzeYPJ6pM33aenPfiTCLPxvqUHq5hjwhy8zjifQNNhK2IVIztmENww7I8q/yE1ItGG",
	"LEQo01HnsMcPShWteWQ2zgSbL8vsPUiZA2nkp8tjN3D/2MzTqg/v3CzLrOUFtKdY1kT1jYArQYv+T8UM",
	"Y7zW2oA85cwXjuzGRkW+qVEzaHz9I7R4Qojw5vDp8gShRCmDBagIdQ6AQK3rPKzyuAiOTWpPv9+fMk06",
	"vUFsB4qDiMQ/1K39ftUMmnL4gatCceQDZoYIHx7fFg8v7Oz5NJFeIiJxNYqAog0AKHLQfYeAe+jF5oLf",
	"qxUCfsOCefzSfRrchTMn+nXb2kJ9EYBI9WOeaQmw06WqwG7eSe8oLaHbq+sTbmFdTxcHRxVKk8+GuRYm",
	"IALTxHSSUuUJBNZIshC45paf2eaXcNwzusT7flBVOdW/pFkm6S3HFJBGqMwdzLjUmaMPnhlKz6LUdoMw",
	"s4t3jkvkcXyK1X+QxRHg+lxXRjzOU6OytDL08KJMH6zsOb5AtgfC3SGeXF1dHglpjIzvKyYtHgpCE0II",
	"UBUI6Z3B4PTD2rsmXSi9rL04GrguYQcDE/pap8PB7nfF5x5WwKOdZUK5Umos2quzbddsu9/wCkVRTBb+",
	"XeDEcNCutc6RI8M/XeGk6/PzM4eAda3vVR6dlylGZxJ47RlBFHU3sjf/CQEMDFEjHVNpfywylc/M/FSW",
	"96p8jzDVVqzn5v3uS00TBWuoyveTN5OJaWVIMLMjAo7wwYBbW6NB9G7wR0RKRw8WupNIRuHp+dvV+RlT",
	"2L5G4B5yUxD64hh9lA14ASZKgBXAGSJQCiQLWMn839+M/jUWMu2Rd3+RsbC/lrdgB6ftsL0v89SjOLi6",
	"H/yV85r77OTkVBSyrMjyJ4Q4d+YzZF/hik9F51brrDsGvNZvBAbLABoFjB0xxgMiNeVSOf6LGzUFoPLu",
	"GCyOVEpQVIWM4Zh58nbN3L5NRQdjzrvsG6JLukZkdkNLgToj+NLFlPZ6ym9UfEb4ZqiXpliacU2HQle5",
	"OG4Uq2SnsctvFFifZyz+JnMlDjTyvfYNW6M1B08YSDygv6tauUp3joNClUbrPMIdh7+p9Uctju2cXInG",
	"1sYyK+5VdZ/m2zONjSf5P5zdgy9vPfQJoS8O1XyRAupc4swokKhsEMIsLYNLdloJRulSSb+GQX2IrN+u",
	"KIhb9udxMUT+oisb7L1YTdcfYhZjd/mM4OpRjaYqOB6s252Cr7wBB1dd50xsu/PWr6SbLqOb76GNO6ib",
	"KlGpc7M6GwUg7uuCUHMcTtMUMyfItSlckR8CEwdhUZSqUHlSiekf+lP2wVL6MldB+kO/xXcKxReKLI1T",
	"E+wbvQ8lff578K8+Os2njqGlgWfB7rAX/khVnF0uKaOkz8jV5JAl3R8R+yF5zsUDYa6nSxCrl+rxVTdr",
	"vm1eUZcolQIbAP3mkE0ov5FE3FL92w0VZ9qoceh1t2dOL1KDAfaELXnbhOyHMx0Y9NktMPpu1/vIAvMy",
	"HFHGzGSzzm81IH377rtWC5EzDP0ui89vti+v+xi/0k/z3Jeb/oQNwdgXXs6gs0NcKbMsfrtp/u3o3Tp5",
	"Utmb19Nm6PD+Gpf3mtP7D1/OLw7P9o5v9i6Ob344/K+n1nVohbHf2qLYZq8LP6aVygB+7HvETHePKhej",
	"iekC8QoSAxyAOF26tikKDjDWyawOdV+dyaylZFoYj9vgNCLNjYa6qWk+u1tmFCNSBeW88DxVGLK9Yvg1",
	"86ijysA10JOa+LOLkOkGoPtwLeoRthW1ouohyJOpoi7eRh8qsZ/pJQC9UeAGFKGw4kIXVihuF/aeE696",
	"IrYvBhEhFKZCFLldxZLR1UjtChUUyINnAH0S3o/OLZtQNVQE5LrjiB75oNNEPM51pnwCSA3Y0yftoD5j",
	"+9kL6wBcudi+a8jLwddqtQK21wuZ1csHjFHa7vTFAWZQhrh+67j4YAloBV19FraZlvLfD9zM4Wr/hkqh",
	"rRUvNpWbfAU085BLJ4Uh/VZRaF3eIFU2AJT3Ybq1hd0U6Lt5MCNOE7DikQpuUKG0ttG0pwnTsIIMy9xX",
	"GxlnsmhheaDwttVfAGpz5Vby9VIMXqWjaivkKnClwrqTHBGREODKVX5I82IJdn+rJmK13b698XLp8x6g",
	"LBeTN64l/NvoAgkhk4UVAWju5VRN5SoxHBBcB1SansuiUHmF7GCllw4NscQG/8EAK2gcqPh3RHVFlHdA",
	"VhMqL9N4bk9YrwlTRxgSQSY6o0L6Mgt98b0q1Z/sSKRBONRCxQYH5j+KqEmiQ1UemHnl6pFC8ABZhIBB",
	"a3aUrvPU7nGrM/VIUfZGi0OG7rxGpEoXotcy8/r0Nq2DZ132Km6nWzs+t1bXyC/Or67FNuZibn+B/4Mb",
	"Z5tWavsL/AG/vULFqKkM/X5//UwfuvG5za9Nh3xKbjnqrk2cHdbIqm8gI6oG6MH+ZQ+q2kQsDmItNyAW",
	"Qx4s1k3H2iLoNrDSnKr9F6WelaqqHKs4bTyoLzkgFb12xWnpTrS+F9KIKYCg3eAYqCaPX1D+HuBOw5s+",
	"ibwsdYluSa70uAf04vfDxSa0Zk3VvwQ5VL3m4YRK/RWiOgN085ijjE25auJLH8k0U0nQaXtRFFOmzLnU",
	"50LnVtDLDDZe3909s50ePLGxoYwEjn0jqq6fmb2gpblLozJzFRacB8jF9E5UeqFgEXCCHk4aphUALrZQ",
	"Tme6TgHN3X+aol4HK0pGM0Qn5or6jEYNq1Kp5uYsSyUgeCtY6iaOcYhW9ZDKppwFJwDzMLIcb23t68VC",
	"5zxNcRWrXJaprnk53SUZcIc+5fJBphmCPJIdKlhw2obGxmMOpCof0lgxMmHl7OONebC863Bwjo9e6rZm",
	"RVFHYEWwp+AGbCTjkBipJJYH7QyORQfIn9FDwzRDeNB17spLS3OAvAz+fLbiOhcNUTElBJpy5UzDWBqK",
	"jMIQ5Mw6utONwfuNRn823Jb+HmNX/uelNqSqrod1O/8kxOIhg4ASkVBpArWAXuiu6LoJnATg6EE+PmJ2",
	"5w+qMulMBp6wS9riyuiCvMUL+VlIY29TprmttKsopF01UNjWGq/a2jqSWWaXkPNcV0SER5DkkwItwZEH",
	"J1DP4Zn6nFHGI6b2dnHvZIbsBf6xRjiPGzkk7H2r8fBl1BhKBzKqXLyAGVN70yWflTN1w5MgzZamWI8p",
	"up6nleOMDpAhe5SrivFdOAuYWV0QMm3589KfZidcHBQ6ajNrUPPXmoAcibE0kwfs7arUBRqKWfCjsiKm",
	"B4cnh9eHL/JLOHGXikpyO9h1/NRYTFsUnbZORv1A9QBnVrUmkiJWLKgIuzb2yhcUsmUts1NPguyyDldD",
	"eddciYsr64Zfm+QMgEZJ4XD5xMUk5AOZqL5oxGN3XCJblw5NE394XQH2BcQA4usDhoydyp90GajvfLwg",
	"qwBWqFKm6jEwGAWaeV11/BpdExu744L/dNGc2GdEfUZUSGdDigB4yBcrco0Tkp1DgVwLsPtYyoIyUSnb",
	"HKr6Xl+fQKgoPPWLCpVgeVWBMwFUbarzap4WaClldAxTSiuyPFhMX5yk9wFoT09Ad3BxqyY5h+K2lptj",
	"Fb9QJdbaxmoT4THyRXL9lMT5g5Wg6nF9Mojdhm4aq4XZQbhc5GCMME9G4UkJlZYAzvKEAHLtSHJFeHUI",
	"oej6gAovuBbOAB/NdcEREFGAWhWuJkLw2YtGEHY283Nor2zjLia8VW3ZuzpOZXYDbzQJ4hu3/8+V0Av2",
	"yL4dVpRQZTjI15fUe9XISxWr3GABEYawfr6q2IvF5w5h47+y8JzjV7UKdL+3cJyM8TCIOWDJe+z3e1Wv",
	"AdS1hwuDLoAr2inJimtIh0XokKzXC9CtHc7mFfG5ynPU6VdWnXN09VDVKlDizoS/bG2JjvH1LrqIxOT0",
	"cFDVG6VOnKZEJsOgHMuLBTHWCwf6RMapK65FFMSzsGNEdvw1YwxPBjKvcKRY7l7T+sIwpfFgckFjN2wg",
	"l3VqFB0qIpXmAugGcZwjccDYIWFvlL8EFVYduIiolVJ7puSa21cAJHCo1+t114SsvLJ8fX3yv1GH7dmi",
	"ayAQqt/ORzFs8uYVJUB3anz22h5ega0Rxp27+CvtfY0dUZ02KHANjRhnCsoH2MXco1/FkVLJb5/P7+Gu",
	"HgvIUkAmKwNl7+yoYYZhp38VOrN3O+IjbSXW1orIXSpApc6xAuDv2DRTKhDbN4HIfql4a3PruA8XRBf0",
	"9VdRqrtSVXMB8N1WiGeE/KSzpLa/vInhHfl3UGOR3tg1/Fo6tPdkaAey227Wc1QINoEsTRBAL0/0Y3AN",
	"T/PZa6vhOa7BkrLOPTyAAcPctnCPRk09qldHch0QO6HGHTLJmjSt6uKUQBRc980Ceq7Gpu23s9OFlYJe",
	"qU5IqSDGsq4OvKquHvTiAby/vjheXf8K6/IxaLgvj7cm9TeXyCOl/OvL48H2cfGq5qZtrpe3uSoe4mGg",
	"/ZJe3FQBD8nWbg4oLN32YneO9Nor3gV1FxFOvk50bZXvVJOYf9K3LFpv7E38xpjs/ehrC+DhdLD43c7w",
	"W1/97ru/rBW/e7s7GjpF95Qso6AlqqSplIPgvbbNawc9EVVqTytVPblVsd1Kyg2w+2aZOs/Q8RWkoNwO",
	"/aGqDd1ZbZvV+MIb5sYifM2bTiT2Ef4dLBBwHhEcrnDIqcoV9Ha+Hq/hUy2iIL0CVWc0R1BXeMQvMpkL",
	"GcdQJGZGhRuCog5rKCot5fjAnBOMii0/bMlbr4a3l2XuFhrrBdD/QubO1rep3N5zX9pQeM8ZeFT70jxT",
	"Mu/CXcDXqtDB/SXUcO01JjWV0I85bC9FmFORgGTG9ex8rT6K+WjTa0XHDtEdRt+GsrrONBgHlNPPx8GK",
	"QsWzcGjVXJbKi5tQ16WiB/Aak1SjKuC+zO1gFkDRyEryVsp9pswgRvwTHZ9dXwCROQDPsNJ+a61BMlWt",
	"BQNZ7ZayckNUtJpaX706gMCR4E3NMrExmsCrJxRJ4EKdSLdk/fUVPfSCxxuUz+YnZGbJ4obLjf++T+zM",
	"N8dD2AuFi2+q36Tqjny/7qGNRGdpnK7tDESVWNlbW+t+zcHm+G+mZ2zB+AcgakNxmXQ2D1lvUMWJ2gGj",
	"SUBnCWlepHeuZ67kIsWtNiZTuYrv6XKLLplqrksoudaoVInzsTsQ2Zt/ytcbhr1Ehb5yybieo9JEflSl",
	"PU9Nk9It6R0u2gIjEzwGF3TKowlhJoEFloridhEYoCaZInEIroAWewihWjZlcYlh3SFcI+z88wUxkZu8",
	"oiDmy3CNbExHUzkauZn4EGQxjdu8XXbbllkiju2W1CEbySIP2f22V/T5gjnIvrgvcyqzyTTuzWRUX8zZ",
	"nloBG8/DaiZY2cxoDK7xq/ipUmXLysHPr+3SsqsUb9K+4wv3Y0v3wcOnf9nHRs4+lnpZ2N34wl2Ql/9i",
	"eZulUErmTe+NkTPYsRkKtRsoAKCSN703xKnrFNFSNXW9gkoL8OcaccH6BmsWUFVjZLSiwRT/9fSvp/8f",
	"AAD//xEoHfIyzgMA",
}

// GetSwagger returns the content of the embedded swagger specification file
// or error if failed to decode
func decodeSpec() ([]byte, error) {
	zipped, err := base64.StdEncoding.DecodeString(strings.Join(swaggerSpec, ""))
	if err != nil {
		return nil, fmt.Errorf("error base64 decoding spec: %w", err)
	}
	zr, err := gzip.NewReader(bytes.NewReader(zipped))
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}
	var buf bytes.Buffer
	_, err = buf.ReadFrom(zr)
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}

	return buf.Bytes(), nil
}

var rawSpec = decodeSpecCached()

// a naive cached of a decoded swagger spec
func decodeSpecCached() func() ([]byte, error) {
	data, err := decodeSpec()
	return func() ([]byte, error) {
		return data, err
	}
}

// Constructs a synthetic filesystem for resolving external references when loading openapi specifications.
func PathToRawSpec(pathToFile string) map[string]func() ([]byte, error) {
	res := make(map[string]func() ([]byte, error))
	if len(pathToFile) > 0 {
		res[pathToFile] = rawSpec
	}

	return res
}

// GetSwagger returns the Swagger specification corresponding to the generated code
// in this file. The external references of Swagger specification are resolved.
// The logic of resolving external references is tightly connected to "import-mapping" feature.
// Externally referenced files must be embedded in the corresponding golang packages.
// Urls can be supported but this task was out of the scope.
func GetSwagger() (swagger *openapi3.T, err error) {
	resolvePath := PathToRawSpec("")

	loader := openapi3.NewLoader()
	loader.IsExternalRefsAllowed = true
	loader.ReadFromURIFunc = func(loader *openapi3.Loader, url *url.URL) ([]byte, error) {
		pathToFile := url.String()
		pathToFile = path.Clean(pathToFile)
		getSpec, ok := resolvePath[pathToFile]
		if !ok {
			err1 := fmt.Errorf("path not found: %s", pathToFile)
			return nil, err1
		}
		return getSpec()
	}
	var specData []byte
	specData, err = rawSpec()
	if err != nil {
		return
	}
	swagger, err = loader.LoadFromData(specData)
	if err != nil {
		return
	}
	return
}
