// Package oapi provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/oapi-codegen/oapi-codegen/v2 version v2.5.1 DO NOT EDIT.
package oapi

import (
	"bytes"
	"compress/gzip"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"path"
	"strings"
	"time"

	"github.com/getkin/kin-openapi/openapi3"
	"github.com/oapi-codegen/runtime"
)

const (
	BasicAuthScopes = "BasicAuth.Scopes"
)

// Defines values for AggregationType.
const (
	AggregationTypeAvg              AggregationType = "avg"
	AggregationTypeCardinality      AggregationType = "cardinality"
	AggregationTypeCount            AggregationType = "count"
	AggregationTypeDateHistogram    AggregationType = "date_histogram"
	AggregationTypeDateRange        AggregationType = "date_range"
	AggregationTypeGeoDistance      AggregationType = "geo_distance"
	AggregationTypeGeohashGrid      AggregationType = "geohash_grid"
	AggregationTypeHistogram        AggregationType = "histogram"
	AggregationTypeMax              AggregationType = "max"
	AggregationTypeMin              AggregationType = "min"
	AggregationTypeRange            AggregationType = "range"
	AggregationTypeSignificantTerms AggregationType = "significant_terms"
	AggregationTypeStats            AggregationType = "stats"
	AggregationTypeSum              AggregationType = "sum"
	AggregationTypeSumsquares       AggregationType = "sumsquares"
	AggregationTypeTerms            AggregationType = "terms"
)

// Defines values for AntflyType.
const (
	AntflyTypeBlob            AntflyType = "blob"
	AntflyTypeBoolean         AntflyType = "boolean"
	AntflyTypeDatetime        AntflyType = "datetime"
	AntflyTypeEmbedding       AntflyType = "embedding"
	AntflyTypeGeopoint        AntflyType = "geopoint"
	AntflyTypeGeoshape        AntflyType = "geoshape"
	AntflyTypeHtml            AntflyType = "html"
	AntflyTypeKeyword         AntflyType = "keyword"
	AntflyTypeLink            AntflyType = "link"
	AntflyTypeNumeric         AntflyType = "numeric"
	AntflyTypeSearchAsYouType AntflyType = "search_as_you_type"
	AntflyTypeText            AntflyType = "text"
)

// Defines values for BingSearchConfigFreshness.
const (
	BingSearchConfigFreshnessDay   BingSearchConfigFreshness = "Day"
	BingSearchConfigFreshnessMonth BingSearchConfigFreshness = "Month"
	BingSearchConfigFreshnessWeek  BingSearchConfigFreshness = "Week"
)

// Defines values for BraveSearchConfigFreshness.
const (
	BraveSearchConfigFreshnessPd BraveSearchConfigFreshness = "pd"
	BraveSearchConfigFreshnessPm BraveSearchConfigFreshness = "pm"
	BraveSearchConfigFreshnessPw BraveSearchConfigFreshness = "pw"
	BraveSearchConfigFreshnessPy BraveSearchConfigFreshness = "py"
)

// Defines values for CalendarInterval.
const (
	CalendarIntervalDay     CalendarInterval = "day"
	CalendarIntervalHour    CalendarInterval = "hour"
	CalendarIntervalMinute  CalendarInterval = "minute"
	CalendarIntervalMonth   CalendarInterval = "month"
	CalendarIntervalQuarter CalendarInterval = "quarter"
	CalendarIntervalWeek    CalendarInterval = "week"
	CalendarIntervalYear    CalendarInterval = "year"
)

// Defines values for ChainCondition.
const (
	ChainConditionAlways      ChainCondition = "always"
	ChainConditionOnError     ChainCondition = "on_error"
	ChainConditionOnRateLimit ChainCondition = "on_rate_limit"
	ChainConditionOnTimeout   ChainCondition = "on_timeout"
)

// Defines values for ChatMessageRole.
const (
	ChatMessageRoleAssistant ChatMessageRole = "assistant"
	ChatMessageRoleSystem    ChatMessageRole = "system"
	ChatMessageRoleTool      ChatMessageRole = "tool"
	ChatMessageRoleUser      ChatMessageRole = "user"
)

// Defines values for ChatToolName.
const (
	ChatToolNameAddFilter        ChatToolName = "add_filter"
	ChatToolNameAskClarification ChatToolName = "ask_clarification"
	ChatToolNameFetch            ChatToolName = "fetch"
	ChatToolNameSearch           ChatToolName = "search"
	ChatToolNameWebsearch        ChatToolName = "websearch"
)

// Defines values for ChunkerProvider.
const (
	ChunkerProviderAntfly  ChunkerProvider = "antfly"
	ChunkerProviderMock    ChunkerProvider = "mock"
	ChunkerProviderTermite ChunkerProvider = "termite"
)

// Defines values for ClusterBackupResponseStatus.
const (
	ClusterBackupResponseStatusCompleted ClusterBackupResponseStatus = "completed"
	ClusterBackupResponseStatusFailed    ClusterBackupResponseStatus = "failed"
	ClusterBackupResponseStatusPartial   ClusterBackupResponseStatus = "partial"
)

// Defines values for ClusterHealth.
const (
	ClusterHealthDegraded  ClusterHealth = "degraded"
	ClusterHealthError     ClusterHealth = "error"
	ClusterHealthHealthy   ClusterHealth = "healthy"
	ClusterHealthUnhealthy ClusterHealth = "unhealthy"
	ClusterHealthUnknown   ClusterHealth = "unknown"
)

// Defines values for ClusterRestoreRequestRestoreMode.
const (
	ClusterRestoreRequestRestoreModeFailIfExists ClusterRestoreRequestRestoreMode = "fail_if_exists"
	ClusterRestoreRequestRestoreModeOverwrite    ClusterRestoreRequestRestoreMode = "overwrite"
	ClusterRestoreRequestRestoreModeSkipIfExists ClusterRestoreRequestRestoreMode = "skip_if_exists"
)

// Defines values for ClusterRestoreResponseStatus.
const (
	ClusterRestoreResponseStatusFailed    ClusterRestoreResponseStatus = "failed"
	ClusterRestoreResponseStatusPartial   ClusterRestoreResponseStatus = "partial"
	ClusterRestoreResponseStatusTriggered ClusterRestoreResponseStatus = "triggered"
)

// Defines values for CohereEmbedderConfigInputType.
const (
	CohereEmbedderConfigInputTypeClassification CohereEmbedderConfigInputType = "classification"
	CohereEmbedderConfigInputTypeClustering     CohereEmbedderConfigInputType = "clustering"
	CohereEmbedderConfigInputTypeSearchDocument CohereEmbedderConfigInputType = "search_document"
	CohereEmbedderConfigInputTypeSearchQuery    CohereEmbedderConfigInputType = "search_query"
)

// Defines values for CohereEmbedderConfigTruncate.
const (
	CohereEmbedderConfigTruncateEND   CohereEmbedderConfigTruncate = "END"
	CohereEmbedderConfigTruncateNONE  CohereEmbedderConfigTruncate = "NONE"
	CohereEmbedderConfigTruncateSTART CohereEmbedderConfigTruncate = "START"
)

// Defines values for DistanceUnit.
const (
	DistanceUnitFt DistanceUnit = "ft"
	DistanceUnitKm DistanceUnit = "km"
	DistanceUnitM  DistanceUnit = "m"
	DistanceUnitMi DistanceUnit = "mi"
	DistanceUnitYd DistanceUnit = "yd"
)

// Defines values for DynamicTemplateMatchMappingType.
const (
	DynamicTemplateMatchMappingTypeBoolean DynamicTemplateMatchMappingType = "boolean"
	DynamicTemplateMatchMappingTypeDate    DynamicTemplateMatchMappingType = "date"
	DynamicTemplateMatchMappingTypeNumber  DynamicTemplateMatchMappingType = "number"
	DynamicTemplateMatchMappingTypeObject  DynamicTemplateMatchMappingType = "object"
	DynamicTemplateMatchMappingTypeString  DynamicTemplateMatchMappingType = "string"
)

// Defines values for EdgeDirection.
const (
	EdgeDirectionBoth EdgeDirection = "both"
	EdgeDirectionIn   EdgeDirection = "in"
	EdgeDirectionOut  EdgeDirection = "out"
)

// Defines values for EdgeTypeConfigTopology.
const (
	EdgeTypeConfigTopologyGraph EdgeTypeConfigTopology = "graph"
	EdgeTypeConfigTopologyTree  EdgeTypeConfigTopology = "tree"
)

// Defines values for EmbedderProvider.
const (
	EmbedderProviderBedrock    EmbedderProvider = "bedrock"
	EmbedderProviderCohere     EmbedderProvider = "cohere"
	EmbedderProviderGemini     EmbedderProvider = "gemini"
	EmbedderProviderMock       EmbedderProvider = "mock"
	EmbedderProviderOllama     EmbedderProvider = "ollama"
	EmbedderProviderOpenai     EmbedderProvider = "openai"
	EmbedderProviderOpenrouter EmbedderProvider = "openrouter"
	EmbedderProviderTermite    EmbedderProvider = "termite"
	EmbedderProviderVertex     EmbedderProvider = "vertex"
)

// Defines values for EvaluatorName.
const (
	EvaluatorNameCitationQuality EvaluatorName = "citation_quality"
	EvaluatorNameCoherence       EvaluatorName = "coherence"
	EvaluatorNameCompleteness    EvaluatorName = "completeness"
	EvaluatorNameCorrectness     EvaluatorName = "correctness"
	EvaluatorNameFaithfulness    EvaluatorName = "faithfulness"
	EvaluatorNameHelpfulness     EvaluatorName = "helpfulness"
	EvaluatorNameMap             EvaluatorName = "map"
	EvaluatorNameMrr             EvaluatorName = "mrr"
	EvaluatorNameNdcg            EvaluatorName = "ndcg"
	EvaluatorNamePrecision       EvaluatorName = "precision"
	EvaluatorNameRecall          EvaluatorName = "recall"
	EvaluatorNameRelevance       EvaluatorName = "relevance"
	EvaluatorNameSafety          EvaluatorName = "safety"
)

// Defines values for FailedOperationOperation.
const (
	FailedOperationOperationDelete FailedOperationOperation = "delete"
	FailedOperationOperationUpsert FailedOperationOperation = "upsert"
)

// Defines values for FilterSpecOperator.
const (
	FilterSpecOperatorContains FilterSpecOperator = "contains"
	FilterSpecOperatorEq       FilterSpecOperator = "eq"
	FilterSpecOperatorGt       FilterSpecOperator = "gt"
	FilterSpecOperatorGte      FilterSpecOperator = "gte"
	FilterSpecOperatorIn       FilterSpecOperator = "in"
	FilterSpecOperatorLt       FilterSpecOperator = "lt"
	FilterSpecOperatorLte      FilterSpecOperator = "lte"
	FilterSpecOperatorNe       FilterSpecOperator = "ne"
	FilterSpecOperatorPrefix   FilterSpecOperator = "prefix"
	FilterSpecOperatorRange    FilterSpecOperator = "range"
)

// Defines values for Fuzziness1.
const (
	Fuzziness1Auto Fuzziness1 = "auto"
)

// Defines values for GeneratorProvider.
const (
	GeneratorProviderAnthropic  GeneratorProvider = "anthropic"
	GeneratorProviderBedrock    GeneratorProvider = "bedrock"
	GeneratorProviderCohere     GeneratorProvider = "cohere"
	GeneratorProviderGemini     GeneratorProvider = "gemini"
	GeneratorProviderMock       GeneratorProvider = "mock"
	GeneratorProviderOllama     GeneratorProvider = "ollama"
	GeneratorProviderOpenai     GeneratorProvider = "openai"
	GeneratorProviderOpenrouter GeneratorProvider = "openrouter"
	GeneratorProviderTermite    GeneratorProvider = "termite"
	GeneratorProviderVertex     GeneratorProvider = "vertex"
)

// Defines values for GeoShapeGeometryRelation.
const (
	GeoShapeGeometryRelationContains   GeoShapeGeometryRelation = "contains"
	GeoShapeGeometryRelationIntersects GeoShapeGeometryRelation = "intersects"
	GeoShapeGeometryRelationWithin     GeoShapeGeometryRelation = "within"
)

// Defines values for GoogleSearchConfigSearchType.
const (
	GoogleSearchConfigSearchTypeImage GoogleSearchConfigSearchType = "image"
	GoogleSearchConfigSearchTypeWeb   GoogleSearchConfigSearchType = "web"
)

// Defines values for GraphQueryType.
const (
	GraphQueryTypeKShortestPaths GraphQueryType = "k_shortest_paths"
	GraphQueryTypeNeighbors      GraphQueryType = "neighbors"
	GraphQueryTypePattern        GraphQueryType = "pattern"
	GraphQueryTypeShortestPath   GraphQueryType = "shortest_path"
	GraphQueryTypeTraverse       GraphQueryType = "traverse"
)

// Defines values for IndexType.
const (
	IndexTypeAknnV0     IndexType = "aknn_v0"
	IndexTypeFullTextV0 IndexType = "full_text_v0"
	IndexTypeGraphV0    IndexType = "graph_v0"
)

// Defines values for JoinOperator.
const (
	JoinOperatorEq  JoinOperator = "eq"
	JoinOperatorGt  JoinOperator = "gt"
	JoinOperatorGte JoinOperator = "gte"
	JoinOperatorLt  JoinOperator = "lt"
	JoinOperatorLte JoinOperator = "lte"
	JoinOperatorNeq JoinOperator = "neq"
)

// Defines values for JoinStrategy.
const (
	JoinStrategyBroadcast   JoinStrategy = "broadcast"
	JoinStrategyIndexLookup JoinStrategy = "index_lookup"
	JoinStrategyShuffle     JoinStrategy = "shuffle"
)

// Defines values for JoinType.
const (
	JoinTypeInner JoinType = "inner"
	JoinTypeLeft  JoinType = "left"
	JoinTypeRight JoinType = "right"
)

// Defines values for LinearMergePageStatus.
const (
	LinearMergePageStatusError   LinearMergePageStatus = "error"
	LinearMergePageStatusPartial LinearMergePageStatus = "partial"
	LinearMergePageStatusSuccess LinearMergePageStatus = "success"
)

// Defines values for MatchQueryOperator.
const (
	MatchQueryOperatorAnd MatchQueryOperator = "and"
	MatchQueryOperatorOr  MatchQueryOperator = "or"
)

// Defines values for MergeStrategy.
const (
	MergeStrategyFailover MergeStrategy = "failover"
	MergeStrategyRrf      MergeStrategy = "rrf"
	MergeStrategyRsf      MergeStrategy = "rsf"
)

// Defines values for PathFindWeightMode.
const (
	PathFindWeightModeMaxWeight PathFindWeightMode = "max_weight"
	PathFindWeightModeMinHops   PathFindWeightMode = "min_hops"
	PathFindWeightModeMinWeight PathFindWeightMode = "min_weight"
)

// Defines values for PathWeightMode.
const (
	PathWeightModeMaxWeight PathWeightMode = "max_weight"
	PathWeightModeMinHops   PathWeightMode = "min_hops"
	PathWeightModeMinWeight PathWeightMode = "min_weight"
)

// Defines values for PermissionType.
const (
	PermissionTypeAdmin PermissionType = "admin"
	PermissionTypeRead  PermissionType = "read"
	PermissionTypeWrite PermissionType = "write"
)

// Defines values for QueryRequestExpandStrategy.
const (
	QueryRequestExpandStrategyIntersection QueryRequestExpandStrategy = "intersection"
	QueryRequestExpandStrategyUnion        QueryRequestExpandStrategy = "union"
)

// Defines values for QueryStrategy.
const (
	QueryStrategyDecompose QueryStrategy = "decompose"
	QueryStrategyHyde      QueryStrategy = "hyde"
	QueryStrategySimple    QueryStrategy = "simple"
	QueryStrategyStepBack  QueryStrategy = "step_back"
)

// Defines values for RerankerProvider.
const (
	RerankerProviderCohere  RerankerProvider = "cohere"
	RerankerProviderOllama  RerankerProvider = "ollama"
	RerankerProviderTermite RerankerProvider = "termite"
	RerankerProviderVertex  RerankerProvider = "vertex"
)

// Defines values for ResourceType.
const (
	ResourceTypeAsterisk ResourceType = "*"
	ResourceTypeTable    ResourceType = "table"
	ResourceTypeUser     ResourceType = "user"
)

// Defines values for RouteType.
const (
	RouteTypeQuestion RouteType = "question"
	RouteTypeSearch   RouteType = "search"
)

// Defines values for SemanticQueryMode.
const (
	SemanticQueryModeHypothetical SemanticQueryMode = "hypothetical"
	SemanticQueryModeRewrite      SemanticQueryMode = "rewrite"
)

// Defines values for SerperSearchConfigSearchType.
const (
	SerperSearchConfigSearchTypeImages   SerperSearchConfigSearchType = "images"
	SerperSearchConfigSearchTypeNews     SerperSearchConfigSearchType = "news"
	SerperSearchConfigSearchTypePlaces   SerperSearchConfigSearchType = "places"
	SerperSearchConfigSearchTypeSearch   SerperSearchConfigSearchType = "search"
	SerperSearchConfigSearchTypeShopping SerperSearchConfigSearchType = "shopping"
)

// Defines values for SerperSearchConfigTimePeriod.
const (
	SerperSearchConfigTimePeriodD SerperSearchConfigTimePeriod = "d"
	SerperSearchConfigTimePeriodM SerperSearchConfigTimePeriod = "m"
	SerperSearchConfigTimePeriodW SerperSearchConfigTimePeriod = "w"
	SerperSearchConfigTimePeriodY SerperSearchConfigTimePeriod = "y"
)

// Defines values for SignificanceAlgorithm.
const (
	SignificanceAlgorithmChiSquared        SignificanceAlgorithm = "chi_squared"
	SignificanceAlgorithmJlh               SignificanceAlgorithm = "jlh"
	SignificanceAlgorithmMutualInformation SignificanceAlgorithm = "mutual_information"
	SignificanceAlgorithmPercentage        SignificanceAlgorithm = "percentage"
)

// Defines values for SyncLevel.
const (
	SyncLevelAknn        SyncLevel = "aknn"
	SyncLevelEnrichments SyncLevel = "enrichments"
	SyncLevelFullText    SyncLevel = "full_text"
	SyncLevelPropose     SyncLevel = "propose"
	SyncLevelWrite       SyncLevel = "write"
)

// Defines values for TableBackupStatusStatus.
const (
	TableBackupStatusStatusCompleted TableBackupStatusStatus = "completed"
	TableBackupStatusStatusFailed    TableBackupStatusStatus = "failed"
	TableBackupStatusStatusSkipped   TableBackupStatusStatus = "skipped"
)

// Defines values for TableRestoreStatusStatus.
const (
	TableRestoreStatusStatusFailed    TableRestoreStatusStatus = "failed"
	TableRestoreStatusStatusSkipped   TableRestoreStatusStatus = "skipped"
	TableRestoreStatusStatusTriggered TableRestoreStatusStatus = "triggered"
)

// Defines values for TavilySearchConfigSearchDepth.
const (
	TavilySearchConfigSearchDepthAdvanced TavilySearchConfigSearchDepth = "advanced"
	TavilySearchConfigSearchDepthBasic    TavilySearchConfigSearchDepth = "basic"
)

// Defines values for TransformOpType.
const (
	TransformOpTypeAddToSet    TransformOpType = "$addToSet"
	TransformOpTypeCurrentDate TransformOpType = "$currentDate"
	TransformOpTypeInc         TransformOpType = "$inc"
	TransformOpTypeMax         TransformOpType = "$max"
	TransformOpTypeMin         TransformOpType = "$min"
	TransformOpTypeMul         TransformOpType = "$mul"
	TransformOpTypePop         TransformOpType = "$pop"
	TransformOpTypePull        TransformOpType = "$pull"
	TransformOpTypePush        TransformOpType = "$push"
	TransformOpTypeRename      TransformOpType = "$rename"
	TransformOpTypeSet         TransformOpType = "$set"
	TransformOpTypeUnset       TransformOpType = "$unset"
)

// Defines values for WebSearchProvider.
const (
	WebSearchProviderBing       WebSearchProvider = "bing"
	WebSearchProviderBrave      WebSearchProvider = "brave"
	WebSearchProviderDuckduckgo WebSearchProvider = "duckduckgo"
	WebSearchProviderGoogle     WebSearchProvider = "google"
	WebSearchProviderSerper     WebSearchProvider = "serper"
	WebSearchProviderTavily     WebSearchProvider = "tavily"
)

// Defines values for SchemasAntflyType.
const (
	SchemasAntflyTypeBlob            SchemasAntflyType = "blob"
	SchemasAntflyTypeBoolean         SchemasAntflyType = "boolean"
	SchemasAntflyTypeDatetime        SchemasAntflyType = "datetime"
	SchemasAntflyTypeEmbedding       SchemasAntflyType = "embedding"
	SchemasAntflyTypeGeopoint        SchemasAntflyType = "geopoint"
	SchemasAntflyTypeGeoshape        SchemasAntflyType = "geoshape"
	SchemasAntflyTypeHtml            SchemasAntflyType = "html"
	SchemasAntflyTypeKeyword         SchemasAntflyType = "keyword"
	SchemasAntflyTypeLink            SchemasAntflyType = "link"
	SchemasAntflyTypeNumeric         SchemasAntflyType = "numeric"
	SchemasAntflyTypeSearchAsYouType SchemasAntflyType = "search_as_you_type"
	SchemasAntflyTypeText            SchemasAntflyType = "text"
)

// AggregationBucket defines model for AggregationBucket.
type AggregationBucket struct {
	// BgCount Background count (for significant_terms)
	BgCount *int `json:"bg_count,omitempty"`

	// DocCount Number of documents in this bucket
	DocCount int `json:"doc_count"`

	// From Lower bound for range buckets
	From *float64 `json:"from,omitempty"`

	// FromAsString Formatted lower bound
	FromAsString *string `json:"from_as_string,omitempty"`

	// Key Bucket key (term, range name, date, etc.)
	Key string `json:"key"`

	// KeyAsString Formatted key for display (e.g., formatted dates)
	KeyAsString *string `json:"key_as_string,omitempty"`

	// Score Significance score (for significant_terms)
	Score *float64 `json:"score,omitempty"`

	// SubAggregations Results of nested sub-aggregations
	SubAggregations map[string]AggregationResult `json:"sub_aggregations,omitempty,omitzero"`

	// To Upper bound for range buckets
	To *float64 `json:"to,omitempty"`

	// ToAsString Formatted upper bound
	ToAsString *string `json:"to_as_string,omitempty"`
}

// AggregationDateRange defines model for AggregationDateRange.
type AggregationDateRange struct {
	// From Start date (ISO 8601 or relative like "now-7d")
	From *string `json:"from,omitempty"`

	// Name Name of the date range bucket
	Name string `json:"name"`

	// To End date (ISO 8601 or relative like "now")
	To *string `json:"to,omitempty"`
}

// AggregationRange defines model for AggregationRange.
type AggregationRange struct {
	// From Lower bound (inclusive)
	From *float64 `json:"from,omitempty"`

	// Name Name of the range bucket
	Name string `json:"name"`

	// To Upper bound (exclusive)
	To *float64 `json:"to,omitempty"`
}

// AggregationRequest defines model for AggregationRequest.
type AggregationRequest struct {
	// Algorithm Significance algorithm for significant_terms aggregations
	Algorithm *SignificanceAlgorithm `json:"algorithm,omitempty"`

	// BackgroundFilter Background filter for significant_terms aggregations
	BackgroundFilter json.RawMessage `json:"background_filter,omitempty,omitzero"`

	// CalendarInterval Calendar-aware interval for date_histogram aggregations
	CalendarInterval *CalendarInterval `json:"calendar_interval,omitempty"`

	// DateRanges Date ranges for date_range aggregations
	DateRanges []AggregationDateRange `json:"date_ranges,omitempty,omitzero"`

	// DistanceRanges Distance ranges for geo_distance aggregations
	DistanceRanges []DistanceRange `json:"distance_ranges,omitempty,omitzero"`

	// Field Field to aggregate on
	Field string `json:"field"`

	// Interval Fixed interval for histogram aggregations
	Interval *float64 `json:"interval,omitempty"`

	// MinDocCount Minimum document count for a bucket to be included
	MinDocCount *int `json:"min_doc_count,omitempty"`

	// Origin Origin for geohash_grid aggregation (format: "lat,lon")
	// Example: "37.7749,-122.4194"
	Origin *string `json:"origin,omitempty"`

	// Precision Geohash precision (1-12) for geohash_grid aggregations
	Precision *int `json:"precision,omitempty"`

	// Ranges Ranges for range aggregations
	Ranges []AggregationRange `json:"ranges,omitempty,omitzero"`

	// Size Maximum number of buckets to return (for bucketing aggregations)
	Size *int `json:"size,omitempty"`

	// SubAggregations Nested sub-aggregations
	SubAggregations map[string]AggregationRequest `json:"sub_aggregations,omitempty,omitzero"`

	// Type Type of aggregation to compute:
	// - Metrics: sum, avg, min, max, count, sumsquares, stats, cardinality
	// - Bucketing: terms, range, date_range, histogram, date_histogram
	// - Geo: geohash_grid, geo_distance
	// - Analytics: significant_terms
	Type AggregationType `json:"type"`

	// Unit Distance unit for geo_distance aggregations
	Unit *DistanceUnit `json:"unit,omitempty"`
}

// AggregationResult defines model for AggregationResult.
type AggregationResult struct {
	// Avg Average for stats aggregations
	Avg *float64 `json:"avg,omitempty"`

	// Buckets Buckets for bucketing aggregations (terms, range, histogram, etc.)
	Buckets []AggregationBucket `json:"buckets,omitempty,omitzero"`

	// Count Document count for stats aggregations
	Count *int `json:"count,omitempty"`

	// Max Maximum value for stats aggregations
	Max *float64 `json:"max,omitempty"`

	// Min Minimum value for stats aggregations
	Min *float64 `json:"min,omitempty"`

	// StdDeviation Standard deviation for stats aggregations
	StdDeviation *float64 `json:"std_deviation,omitempty"`

	// Sum Sum for stats aggregations
	Sum *float64 `json:"sum,omitempty"`

	// SumOfSquares Sum of squares for stats aggregations
	SumOfSquares *float64 `json:"sum_of_squares,omitempty"`

	// Value Single value for metric aggregations (sum, avg, min, max, count, cardinality)
	Value *float64 `json:"value,omitempty"`

	// Variance Variance for stats aggregations
	Variance *float64 `json:"variance,omitempty"`
}

// AggregationType Type of aggregation to compute:
// - Metrics: sum, avg, min, max, count, sumsquares, stats, cardinality
// - Bucketing: terms, range, date_range, histogram, date_histogram
// - Geo: geohash_grid, geo_distance
// - Analytics: significant_terms
type AggregationType string

// Analyses defines model for Analyses.
type Analyses struct {
	Pca  bool `json:"pca,omitempty,omitzero"`
	Tsne bool `json:"tsne,omitempty,omitzero"`
}

// AnalysesResult defines model for AnalysesResult.
type AnalysesResult struct {
	Pca  []float64 `json:"pca,omitempty,omitzero"`
	Tsne []float64 `json:"tsne,omitempty,omitzero"`
}

// AnswerAgentRequest defines model for AnswerAgentRequest.
type AnswerAgentRequest struct {
	// AgentKnowledge Background knowledge that guides the agent's understanding of the domain.
	// Similar to CLAUDE.md, this provides context that applies to all steps
	// (classification, retrieval, and answer generation).
	//
	// Examples:
	// - "This data contains medical records. Use clinical terminology and be precise about diagnoses."
	// - "This is a software engineering knowledge base. Assume a technical audience."
	// - "This table stores legal documents. Reference laws and regulations accurately."
	AgentKnowledge string `json:"agent_knowledge,omitempty,omitzero"`

	// Chain Default chain of generators for all pipeline steps unless overridden in `steps`.
	// Each link can specify retry configuration and a condition for trying the next generator.
	// Mutually exclusive with 'generator'. Either 'generator' or 'chain' must be provided.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Eval Configuration for inline evaluation of query results.
	// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
	Eval EvalConfig `json:"eval,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// MaxContextTokens Maximum total tokens allowed for retrieved document context.
	// When set, documents are pruned (lowest-ranked first) to fit within this budget.
	// Useful for ensuring LLM context limits are not exceeded.
	// Uses BERT tokenizer for estimation.
	MaxContextTokens int `json:"max_context_tokens,omitempty,omitzero"`

	// Queries Array of query requests to execute. The query text will be transformed for semantic search
	// and populated into the semantic_search field of each query.
	Queries []QueryRequest `json:"queries"`

	// Query User's natural language query to be classified and improved
	Query string `json:"query"`

	// ReserveTokens Tokens to reserve for system prompt, answer generation, and other overhead.
	// Subtracted from max_context_tokens to determine available context budget.
	// Defaults to 4000 if max_context_tokens is set.
	ReserveTokens int `json:"reserve_tokens,omitempty,omitzero"`

	// Steps Per-step configuration for the answer agent pipeline. Each step can have
	// its own generator (or chain of generators) and step-specific options.
	// If a step is not configured, it uses the top-level generator as default.
	Steps AnswerAgentSteps `json:"steps,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results (classification, queries, results, answer) instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`

	// WithoutGeneration When true, skip AI answer generation and return search results only.
	// Useful when you want search quality without LLM cost, such as for
	// quota management or rate limiting scenarios.
	WithoutGeneration bool `json:"without_generation,omitempty,omitzero"`
}

// AnswerAgentResult defines model for AnswerAgentResult.
type AnswerAgentResult struct {
	// Answer Generated answer in markdown format
	Answer string `json:"answer"`

	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0)
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// ClassificationTransformation Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
	ClassificationTransformation ClassificationTransformationResult `json:"classification_transformation,omitempty,omitzero"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance,omitempty,omitzero"`

	// EvalResult Complete evaluation result
	EvalResult EvalResult `json:"eval_result,omitempty,omitzero"`

	// FollowupQuestions Suggested follow-up questions
	FollowupQuestions []string `json:"followup_questions,omitempty,omitzero"`

	// QueryResults Results from each executed query
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`
}

// AnswerAgentSteps Per-step configuration for the answer agent pipeline. Each step can have
// its own generator (or chain of generators) and step-specific options.
// If a step is not configured, it uses the top-level generator as default.
type AnswerAgentSteps struct {
	// Answer Configuration for the answer generation step. This step generates the final
	// answer from retrieved documents using the reasoning as context.
	Answer AnswerStepConfig `json:"answer,omitempty,omitzero"`

	// Classification Configuration for the classification step. This step analyzes the query,
	// selects the optimal retrieval strategy, and generates semantic transformations.
	Classification ClassificationStepConfig `json:"classification,omitempty,omitzero"`

	// Confidence Configuration for confidence assessment. Evaluates answer quality and
	// resource relevance. Can use a model calibrated for scoring tasks.
	Confidence ConfidenceStepConfig `json:"confidence,omitempty,omitzero"`

	// Followup Configuration for generating follow-up questions. Uses a separate generator
	// call which can use a cheaper/faster model.
	Followup FollowupStepConfig `json:"followup,omitempty,omitzero"`
}

// AnswerConfidence Confidence assessment for the generated answer
type AnswerConfidence struct {
	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0). Considers both ability to answer from provided resources and general knowledge.
	AnswerConfidence float32 `json:"answer_confidence"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance"`
}

// AnswerResult Result from answer generation with optional confidence and follow-up questions
type AnswerResult struct {
	// Answer Generated answer in markdown format
	Answer string `json:"answer"`

	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0)
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance,omitempty,omitzero"`

	// FollowupQuestions Suggested follow-up questions
	FollowupQuestions []string `json:"followup_questions,omitempty,omitzero"`
}

// AnswerStepConfig Configuration for the answer generation step. This step generates the final
// answer from retrieved documents using the reasoning as context.
type AnswerStepConfig struct {
	// AnswerContext Custom guidance for answer tone, detail level, and style
	AnswerContext string `json:"answer_context,omitempty,omitzero"`

	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// SystemPrompt Custom system prompt for answer generation
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`
}

// AntflyChunkerConfig Per-request configuration for chunking. All fields are optional - zero/omitted values use chunker defaults.
type AntflyChunkerConfig = ChunkOptions

// AntflyType defines model for AntflyType.
type AntflyType string

// AnthropicGeneratorConfig Configuration for the Anthropic generative AI provider (Claude models).
//
// API key via `api_key` field or `ANTHROPIC_API_KEY` environment variable.
//
// **Example Models:** claude-sonnet-4-5-20250929 (default), claude-opus-4-5-20251101, claude-3-5-haiku-20241022
//
// **Docs:** https://docs.anthropic.com/en/docs/about-claude/models/overview
type AnthropicGeneratorConfig struct {
	// ApiKey The Anthropic API key. If not provided, falls back to ANTHROPIC_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The full model ID of the Anthropic model to use (e.g., 'claude-sonnet-4-5-20250929', 'claude-opus-4-5-20251101').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-1.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Anthropic API endpoint (optional, uses default if not specified).
	Url string `json:"url,omitempty,omitzero"`
}

// BackupInfo defines model for BackupInfo.
type BackupInfo struct {
	// AntflyVersion Antfly version that created the backup
	AntflyVersion string `json:"antfly_version,omitempty,omitzero"`

	// BackupId The backup identifier
	BackupId string `json:"backup_id"`

	// Location Storage location of the backup
	Location string `json:"location"`

	// Tables Tables included in the backup
	Tables []string `json:"tables"`

	// Timestamp When the backup was created
	Timestamp time.Time `json:"timestamp"`
}

// BackupListResponse defines model for BackupListResponse.
type BackupListResponse struct {
	// Backups List of available backups
	Backups []BackupInfo `json:"backups"`
}

// BackupRequest defines model for BackupRequest.
type BackupRequest struct {
	// BackupId Unique identifier for this backup. Used to reference the backup for restore operations.
	// Choose a meaningful name that includes date/version information.
	BackupId string `json:"backup_id"`

	// Location Storage location for the backup. Supports multiple backends:
	// - Local filesystem: `file:///path/to/backup`
	// - Amazon S3: `s3://bucket-name/path/to/backup`
	//
	// The backup includes all table data, indexes, and metadata for the specified table.
	Location string `json:"location"`
}

// BatchRequest Batch insert, delete, and transform operations in a single request.
//
// **Atomicity**:
// - **Single shard**: Operations are atomic within shard boundaries
// - **Multiple shards**: Uses distributed 2-phase commit (2PC) for atomic cross-shard writes
//
// **How distributed transactions work**:
// 1. Metadata server allocates HLC timestamp and selects coordinator shard
// 2. Coordinator writes transaction record, participants write intents
// 3. After all intents succeed, coordinator commits transaction
// 4. Participants are notified asynchronously to resolve intents
// 5. Recovery loop ensures notifications complete even after coordinator failure
//
// **Performance**:
// - Single-shard batches: < 5ms latency
// - Cross-shard transactions: ~20ms latency
// - Intent resolution: < 30 seconds worst-case (via recovery loop)
//
// **Guarantees**:
// - All writes succeed or all fail (atomicity across all shards)
// - Coordinator failure is recoverable (new leader resumes notifications)
// - Idempotent resolution (duplicate notifications are safe)
//
// **Benefits**:
// - Reduces network overhead compared to individual requests
// - More efficient indexing (updates are batched)
// - Automatic distributed transactions when operations span shards
//
// The inserts are upserts - existing keys are overwritten, new keys are created.
type BatchRequest struct {
	// Deletes Array of document IDs to delete. Documents are removed from all indexes.
	//
	// Notes:
	// - Non-existent keys are silently ignored
	// - Deletions are processed before inserts in the same batch
	// - Keys are permanently removed from storage and indexes
	Deletes []string `json:"deletes,omitempty,omitzero"`

	// Inserts Map of document IDs to document objects. Each key is the unique identifier for the document.
	//
	// Best practices:
	// - Use consistent key naming schemes (e.g., "user:123", "article:456")
	// - Key length affects storage and performance - keep them reasonably short
	// - Keys are sorted lexicographically, so choose prefixes that support range scans
	Inserts map[string]map[string]interface{} `json:"inserts,omitempty,omitzero"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write
	// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`

	// Transforms Array of transform operations for in-place document updates using MongoDB-style operators.
	//
	// Transform operations allow you to modify documents without read-modify-write races:
	// - Operations are applied atomically on the server
	// - Multiple operations per document are applied in sequence
	// - Supports numeric operations ($inc, $mul), array operations ($push, $pull), and more
	//
	// Common use cases:
	// - Increment counters (views, likes, votes)
	// - Update timestamps ($currentDate)
	// - Manage arrays (add/remove tags, items)
	// - Update nested fields without overwriting the entire document
	Transforms []Transform `json:"transforms,omitempty,omitzero"`
}

// BatchResponse defines model for BatchResponse.
type BatchResponse struct {
	// Deleted Number of documents successfully deleted
	Deleted int `json:"deleted,omitempty,omitzero"`

	// Inserted Number of documents successfully inserted
	Inserted int `json:"inserted,omitempty,omitzero"`

	// Transformed Number of documents successfully transformed
	Transformed int `json:"transformed,omitempty,omitzero"`
}

// BedrockEmbedderConfig Configuration for the AWS Bedrock embedding provider.
//
// Uses AWS credentials from environment or IAM roles.
//
// **Example Models:** cohere.embed-english-v4, amazon.titan-embed-text-v2:0
//
// **Docs:** https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html
type BedrockEmbedderConfig struct {
	// BatchSize The batch size for embedding requests to optimize throughput.
	BatchSize int `json:"batch_size,omitempty,omitzero"`

	// Model The Bedrock model ID to use (e.g., 'cohere.embed-english-v4', 'amazon.titan-embed-text-v2:0').
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service (e.g., 'us-east-1').
	Region string `json:"region,omitempty,omitzero"`

	// StripNewLines Whether to strip new lines from the input text before embedding.
	StripNewLines bool `json:"strip_new_lines,omitempty,omitzero"`
}

// BedrockGeneratorConfig Configuration for the AWS Bedrock generative AI provider.
//
// Provides access to models from Anthropic, Meta, Amazon, Cohere, Mistral, and others.
//
// **Example Models:** anthropic.claude-sonnet-4-5-20250929-v1:0, meta.llama3-3-70b-instruct-v1:0, amazon.nova-pro-v1:0
//
// **Docs:** https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html
type BedrockGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The Bedrock model ID to use (e.g., 'anthropic.claude-sonnet-4-5-20250929-v1:0').
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service.
	Region string `json:"region,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-1.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// BingSearchConfig defines model for BingSearchConfig.
type BingSearchConfig struct {
	// ApiKey Bing Search API key (or set BING_SEARCH_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Endpoint Bing API endpoint URL
	Endpoint string `json:"endpoint,omitempty,omitzero"`

	// Freshness Filter results by freshness
	Freshness BingSearchConfigFreshness `json:"freshness,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// BingSearchConfigFreshness Filter results by freshness
type BingSearchConfigFreshness string

// BleveIndexV2Config defines model for BleveIndexV2Config.
type BleveIndexV2Config struct {
	// MemOnly Whether to use memory-only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`
}

// BleveIndexV2Stats defines model for BleveIndexV2Stats.
type BleveIndexV2Stats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// Rebuilding Whether the index is currently rebuilding
	Rebuilding bool `json:"rebuilding,omitempty,omitzero"`

	// TotalIndexed Number of documents in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`
}

// BoolFieldQuery defines model for BoolFieldQuery.
type BoolFieldQuery struct {
	Bool bool `json:"bool"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
}

// BooleanQuery defines model for BooleanQuery.
type BooleanQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost   Boost            `json:"boost,omitzero"`
	Filter  Query            `json:"filter,omitempty,omitzero"`
	Must    ConjunctionQuery `json:"must,omitempty,omitzero"`
	MustNot DisjunctionQuery `json:"must_not,omitempty,omitzero"`
	Should  DisjunctionQuery `json:"should,omitempty,omitzero"`
}

// Boost A floating-point number used to decrease or increase the relevance scores of a query.
type Boost = float64

// BraveSearchConfig defines model for BraveSearchConfig.
type BraveSearchConfig struct {
	// ApiKey Brave Search API key (or set BRAVE_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Freshness Freshness filter: pd=day, pw=week, pm=month, py=year
	Freshness BraveSearchConfigFreshness `json:"freshness,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// Spellcheck Enable spellcheck suggestions
	Spellcheck bool `json:"spellcheck,omitempty,omitzero"`

	// TextDecorations Include text decorations (bold, italic markers)
	TextDecorations bool `json:"text_decorations,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// BraveSearchConfigFreshness Freshness filter: pd=day, pw=week, pm=month, py=year
type BraveSearchConfigFreshness string

// ByteRange defines model for ByteRange.
type ByteRange = [][]byte

// CalendarInterval Calendar-aware interval for date_histogram aggregations
type CalendarInterval string

// ChainCondition Condition for trying the next generator in chain:
// - always: Always try next regardless of outcome
// - on_error: Try next on any error (default)
// - on_timeout: Try next only on timeout errors
// - on_rate_limit: Try next only on rate limit errors
type ChainCondition string

// ChainLink A single link in a generator chain with optional retry and condition
type ChainLink struct {
	// Condition Condition for trying the next generator in chain:
	// - always: Always try next regardless of outcome
	// - on_error: Try next on any error (default)
	// - on_timeout: Try next only on timeout errors
	// - on_rate_limit: Try next only on rate limit errors
	Condition ChainCondition `json:"condition,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator"`

	// Retry Retry configuration for generator calls
	Retry RetryConfig `json:"retry,omitempty,omitzero"`
}

// ChatAgentRequest defines model for ChatAgentRequest.
type ChatAgentRequest struct {
	// AccumulatedFilters Filters accumulated from previous conversation turns.
	// These are applied to all queries automatically.
	// New filters discovered in this turn will be added to this list in the response.
	AccumulatedFilters []FilterSpec `json:"accumulated_filters,omitempty,omitzero"`

	// AgentKnowledge Background knowledge that guides the agent's understanding of the domain.
	// Similar to CLAUDE.md, this provides context that applies to all steps
	// (classification, retrieval, and answer generation).
	//
	// Example: "This is a technical documentation search. Results should be
	// filtered to only include official documentation, not community posts."
	AgentKnowledge string `json:"agent_knowledge,omitempty,omitzero"`

	// Chain Chain of generators with retry/fallback semantics for the chat agent.
	// Each link can specify retry configuration and a condition for trying the next generator.
	// Mutually exclusive with 'generator'. Either 'generator' or 'chain' must be provided.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// MaxContextTokens Maximum tokens for retrieved document context
	MaxContextTokens int `json:"max_context_tokens,omitempty,omitzero"`

	// Messages Conversation history. Include all previous messages to maintain context.
	// The last message should typically be from the user.
	Messages []ChatMessage `json:"messages"`

	// Queries Base query configurations. The chat agent will modify these queries
	// based on conversation context, applying filters and transformations.
	Queries []QueryRequest `json:"queries"`

	// Steps Per-step configuration for the chat agent pipeline. Similar to AnswerAgentSteps
	// but includes tool-specific configuration.
	Steps ChatAgentSteps `json:"steps,omitempty,omitzero"`

	// SystemPrompt Optional custom system prompt for the chat agent.
	// If not provided, uses a default conversational RAG prompt.
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// ChatAgentResult defines model for ChatAgentResult.
type ChatAgentResult struct {
	// Answer Final answer text (if available)
	Answer string `json:"answer,omitempty,omitzero"`

	// AnswerConfidence Confidence in the answer
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// AppliedFilters Filters that have been applied in this conversation
	AppliedFilters []FilterSpec `json:"applied_filters,omitempty,omitzero"`

	// ClassificationTransformation Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
	ClassificationTransformation ClassificationTransformationResult `json:"classification_transformation,omitempty,omitzero"`

	// Messages Updated conversation history including the assistant's response
	Messages []ChatMessage `json:"messages"`

	// PendingClarification A request for clarification from the user
	PendingClarification ClarificationRequest `json:"pending_clarification,omitempty,omitzero"`

	// QueryResults Search results from executed queries
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`

	// ToolCallsMade Number of tool calls made in this turn
	ToolCallsMade int `json:"tool_calls_made,omitempty,omitzero"`
}

// ChatAgentSteps Per-step configuration for the chat agent pipeline. Similar to AnswerAgentSteps
// but includes tool-specific configuration.
type ChatAgentSteps struct {
	// Answer Configuration for the answer generation step. This step generates the final
	// answer from retrieved documents using the reasoning as context.
	Answer AnswerStepConfig `json:"answer,omitempty,omitzero"`

	// Classification Configuration for the classification step. This step analyzes the query,
	// selects the optimal retrieval strategy, and generates semantic transformations.
	Classification ClassificationStepConfig `json:"classification,omitempty,omitzero"`

	// Confidence Configuration for confidence assessment. Evaluates answer quality and
	// resource relevance. Can use a model calibrated for scoring tasks.
	Confidence ConfidenceStepConfig `json:"confidence,omitempty,omitzero"`

	// Tools Configuration for chat agent tools.
	//
	// If `enabled_tools` is empty/omitted, defaults to: add_filter, ask_clarification, search.
	//
	// For models that don't support native tool calling (e.g., Ollama),
	// a prompt-based fallback is used with structured output parsing.
	Tools ChatToolsConfig `json:"tools,omitempty,omitzero"`
}

// ChatMessage A message in the conversation history
type ChatMessage struct {
	// Content Text content of the message
	Content string `json:"content"`

	// Role Role of the message sender in the conversation
	Role ChatMessageRole `json:"role"`

	// ToolCalls Tool calls made by the assistant (only for assistant role)
	ToolCalls []ChatToolCall `json:"tool_calls,omitempty,omitzero"`

	// ToolResults Results from tool executions (only for tool role)
	ToolResults []ChatToolResult `json:"tool_results,omitempty,omitzero"`
}

// ChatMessageRole Role of the message sender in the conversation
type ChatMessageRole string

// ChatToolCall A tool call made by the assistant
type ChatToolCall struct {
	// Arguments Arguments passed to the tool as key-value pairs
	Arguments map[string]interface{} `json:"arguments"`

	// Id Unique identifier for this tool call
	Id string `json:"id"`

	// Name Name of the tool being called
	Name string `json:"name"`
}

// ChatToolName Available tool names for the chat agent.
// - add_filter: Add search filters (field constraints)
// - ask_clarification: Ask user for clarification
// - search: Execute semantic searches
// - websearch: Search the web (requires websearch_config)
// - fetch: Fetch URL content (subject to security controls)
type ChatToolName string

// ChatToolResult Result from executing a tool call
type ChatToolResult struct {
	// Error Error message if tool execution failed
	Error string `json:"error,omitempty,omitzero"`

	// Result Result data from the tool execution
	Result map[string]interface{} `json:"result"`

	// ToolCallId ID of the tool call this result corresponds to
	ToolCallId string `json:"tool_call_id"`
}

// ChatToolsConfig Configuration for chat agent tools.
//
// If `enabled_tools` is empty/omitted, defaults to: add_filter, ask_clarification, search.
//
// For models that don't support native tool calling (e.g., Ollama),
// a prompt-based fallback is used with structured output parsing.
type ChatToolsConfig struct {
	// EnabledTools List of tools to enable. If empty, defaults to filter, clarification, and search.
	EnabledTools []ChatToolName `json:"enabled_tools,omitempty,omitzero"`

	// FetchConfig Configuration for URL content fetching.
	//
	// Uses lib/scraping for downloading and processing. Supports:
	// - HTTP/HTTPS URLs with security validation
	// - HTML pages (extracts readable text via go-readability)
	// - PDF files (extracts text)
	// - Images (returns as data URIs)
	// - Plain text files
	// - S3 URLs (requires s3_credentials)
	//
	// Security features (from lib/scraping.ContentSecurityConfig):
	// - Allowed host whitelist
	// - Private IP blocking (SSRF prevention)
	// - Download size limits
	// - Timeout controls
	FetchConfig FetchConfig `json:"fetch_config,omitempty,omitzero"`

	// MaxToolIterations Maximum number of tool call iterations per turn.
	// Prevents infinite loops in tool execution.
	MaxToolIterations int `json:"max_tool_iterations,omitempty,omitzero"`

	// WebsearchConfig A unified configuration for web search providers.
	//
	// Each provider has specific configuration requirements. Use the appropriate
	// provider-specific config or set common options at the top level.
	//
	// **Environment Variables (fallbacks):**
	// - GOOGLE_CSE_API_KEY, GOOGLE_CSE_ID
	// - BING_SEARCH_API_KEY
	// - SERPER_API_KEY
	// - TAVILY_API_KEY
	// - BRAVE_API_KEY
	WebsearchConfig WebSearchConfig `json:"websearch_config,omitempty,omitzero"`
}

// ChunkOptions Per-request configuration for chunking. All fields are optional - zero/omitted values use chunker defaults.
type ChunkOptions struct {
	// MaxChunks Maximum number of chunks to generate per document.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries. Only used by fixed-size chunkers.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs). Only used by fixed-size chunkers.
	Separator string `json:"separator,omitempty,omitzero"`

	// TargetTokens Target number of tokens per chunk.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`

	// Threshold Minimum confidence threshold for separator detection (0.0-1.0). Only used by ONNX models.
	Threshold float32 `json:"threshold,omitempty,omitzero"`
}

// ChunkerConfig defines model for ChunkerConfig.
type ChunkerConfig struct {
	// FullTextIndex Configuration for full-text indexing of chunks in Bleve.
	// When present (even if empty), chunks will be stored with :cft: suffix and indexed in Bleve's _chunks field.
	// When absent, chunks use :c: suffix and are only used for vector embeddings.
	FullTextIndex map[string]interface{} `json:"full_text_index,omitempty,omitzero"`

	// Provider The chunking provider to use.
	Provider ChunkerProvider `json:"provider"`

	// StoreChunks Controls whether chunk data is persisted to storage. When false (default), chunks are generated in memory and only embeddings are stored. When true, both chunks and embeddings are stored.
	StoreChunks bool `json:"store_chunks,omitempty,omitzero"`
	union       json.RawMessage
}

// ChunkerProvider The chunking provider to use.
type ChunkerProvider string

// ClarificationRequest A request for clarification from the user
type ClarificationRequest struct {
	// Options Optional list of suggested answers for the user to choose from
	Options []string `json:"options,omitempty,omitzero"`

	// Question The clarifying question to ask the user
	Question string `json:"question"`

	// Required Whether the clarification is required before proceeding
	Required bool `json:"required,omitempty,omitzero"`
}

// ClassificationStepConfig Configuration for the classification step. This step analyzes the query,
// selects the optimal retrieval strategy, and generates semantic transformations.
type ClassificationStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// ForceSemanticMode Mode for semantic query generation:
	// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
	// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
	ForceSemanticMode SemanticQueryMode `json:"force_semantic_mode,omitempty,omitzero"`

	// ForceStrategy Strategy for query transformation and retrieval:
	// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
	// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
	// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
	// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
	ForceStrategy QueryStrategy `json:"force_strategy,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// MultiPhraseCount Number of alternative query phrasings to generate
	MultiPhraseCount int `json:"multi_phrase_count,omitempty,omitzero"`

	// WithReasoning Include pre-retrieval reasoning explaining query analysis and strategy selection
	WithReasoning bool `json:"with_reasoning,omitempty,omitzero"`
}

// ClassificationTransformationResult Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
type ClassificationTransformationResult struct {
	// Confidence Classification confidence (0.0 to 1.0)
	Confidence float32 `json:"confidence"`

	// ImprovedQuery Clarified query with added context for answer generation (human-readable)
	ImprovedQuery string `json:"improved_query"`

	// MultiPhrases Alternative phrasings of the query for expanded retrieval coverage
	MultiPhrases []string `json:"multi_phrases,omitempty,omitzero"`

	// Reasoning Pre-retrieval reasoning explaining query analysis and strategy selection (only present when with_classification_reasoning is enabled)
	Reasoning string `json:"reasoning,omitempty,omitzero"`

	// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
	RouteType RouteType `json:"route_type"`

	// SemanticMode Mode for semantic query generation:
	// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
	// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
	SemanticMode SemanticQueryMode `json:"semantic_mode"`

	// SemanticQuery Optimized query for vector/semantic search. Content style depends on semantic_mode: keywords for 'rewrite', hypothetical answer for 'hypothetical'
	SemanticQuery string `json:"semantic_query"`

	// StepBackQuery Broader background query for context (only present when strategy is 'step_back')
	StepBackQuery string `json:"step_back_query,omitempty,omitzero"`

	// Strategy Strategy for query transformation and retrieval:
	// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
	// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
	// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
	// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
	Strategy QueryStrategy `json:"strategy"`

	// SubQuestions Decomposed sub-questions (only present when strategy is 'decompose')
	SubQuestions []string `json:"sub_questions,omitempty,omitzero"`
}

// ClusterBackupRequest defines model for ClusterBackupRequest.
type ClusterBackupRequest struct {
	// BackupId Unique identifier for this backup. Used to reference the backup for restore operations.
	// Choose a meaningful name that includes date/version information.
	BackupId string `json:"backup_id"`

	// Location Storage location for the backup. Supports multiple backends:
	// - Local filesystem: `file:///path/to/backup`
	// - Amazon S3: `s3://bucket-name/path/to/backup`
	//
	// The backup includes all table data, indexes, and metadata.
	Location string `json:"location"`

	// TableNames Optional list of tables to backup. If omitted, all tables are backed up.
	TableNames []string `json:"table_names,omitempty,omitzero"`
}

// ClusterBackupResponse defines model for ClusterBackupResponse.
type ClusterBackupResponse struct {
	// BackupId The backup identifier
	BackupId string `json:"backup_id"`

	// Status Overall backup status
	Status ClusterBackupResponseStatus `json:"status"`

	// Tables Status of each table backup
	Tables []TableBackupStatus `json:"tables"`
}

// ClusterBackupResponseStatus Overall backup status
type ClusterBackupResponseStatus string

// ClusterHealth Overall health status of the cluster
type ClusterHealth string

// ClusterRestoreRequest defines model for ClusterRestoreRequest.
type ClusterRestoreRequest struct {
	// BackupId Unique identifier of the backup to restore from.
	BackupId string `json:"backup_id"`

	// Location Storage location where the backup is stored.
	Location string `json:"location"`

	// RestoreMode How to handle existing tables:
	// - `fail_if_exists`: Abort if any table already exists (default)
	// - `skip_if_exists`: Skip existing tables, restore others
	// - `overwrite`: Drop and recreate existing tables
	RestoreMode ClusterRestoreRequestRestoreMode `json:"restore_mode,omitempty,omitzero"`

	// TableNames Optional list of tables to restore. If omitted, all tables in the backup are restored.
	TableNames []string `json:"table_names,omitempty,omitzero"`
}

// ClusterRestoreRequestRestoreMode How to handle existing tables:
// - `fail_if_exists`: Abort if any table already exists (default)
// - `skip_if_exists`: Skip existing tables, restore others
// - `overwrite`: Drop and recreate existing tables
type ClusterRestoreRequestRestoreMode string

// ClusterRestoreResponse defines model for ClusterRestoreResponse.
type ClusterRestoreResponse struct {
	// Status Overall restore status
	Status ClusterRestoreResponseStatus `json:"status"`

	// Tables Status of each table restore
	Tables []TableRestoreStatus `json:"tables"`
}

// ClusterRestoreResponseStatus Overall restore status
type ClusterRestoreResponseStatus string

// ClusterStatus defines model for ClusterStatus.
type ClusterStatus struct {
	// AuthEnabled Indicates whether authentication is enabled for the cluster
	AuthEnabled bool `json:"auth_enabled,omitempty"`

	// Health Overall health status of the cluster
	Health ClusterHealth `json:"health"`

	// Message Optional message providing details about the health status
	Message              string                 `json:"message,omitempty,omitzero"`
	AdditionalProperties map[string]interface{} `json:"-"`
}

// CohereEmbedderConfig Configuration for the Cohere embedding provider.
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** embed-english-v3.0 (default, 1024 dims), embed-multilingual-v3.0
//
// **Docs:** https://docs.cohere.com/reference/embed
type CohereEmbedderConfig struct {
	// ApiKey The Cohere API key. Can also be set via COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// InputType Specifies the type of input for optimized embeddings.
	InputType CohereEmbedderConfigInputType `json:"input_type,omitempty,omitzero"`

	// Model The name of the Cohere embedding model to use.
	Model string `json:"model"`

	// Truncate How to handle inputs longer than the max token length.
	Truncate CohereEmbedderConfigTruncate `json:"truncate,omitempty,omitzero"`
}

// CohereEmbedderConfigInputType Specifies the type of input for optimized embeddings.
type CohereEmbedderConfigInputType string

// CohereEmbedderConfigTruncate How to handle inputs longer than the max token length.
type CohereEmbedderConfigTruncate string

// CohereGeneratorConfig Configuration for the Cohere generative AI provider (Command models).
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** command-r-plus (default), command-r, command-a-03-2025
//
// **Docs:** https://docs.cohere.com/reference/chat
type CohereGeneratorConfig struct {
	// ApiKey The Cohere API key. If not provided, falls back to COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (0.0-1.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Cohere model to use.
	Model string `json:"model"`

	// PresencePenalty Penalty for token presence (0.0-1.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-1.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// CohereRerankerConfig Configuration for the Cohere reranking provider.
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** rerank-english-v3.0 (default), rerank-multilingual-v3.0
//
// **Docs:** https://docs.cohere.com/reference/rerank
type CohereRerankerConfig struct {
	// ApiKey The Cohere API key. Can also be set via COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// MaxChunksPerDoc Maximum number of chunks per document for long document handling.
	MaxChunksPerDoc int `json:"max_chunks_per_doc,omitempty,omitzero"`

	// Model The name of the Cohere reranking model to use.
	Model string `json:"model"`

	// TopN Number of most relevant documents to return. If not specified, returns all documents with scores.
	TopN int `json:"top_n,omitempty,omitzero"`
}

// ConfidenceStepConfig Configuration for confidence assessment. Evaluates answer quality and
// resource relevance. Can use a model calibrated for scoring tasks.
type ConfidenceStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Context Custom guidance for confidence assessment approach
	Context string `json:"context,omitempty,omitzero"`

	// Enabled Enable confidence scoring
	Enabled bool `json:"enabled,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`
}

// ConjunctionQuery defines model for ConjunctionQuery.
type ConjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Conjuncts []Query `json:"conjuncts"`
}

// CreateTableRequest defines model for CreateTableRequest.
type CreateTableRequest struct {
	// Description Optional human-readable description of the table and its purpose.
	// Useful for documentation and team collaboration.
	Description string `json:"description,omitempty,omitzero"`

	// Indexes Map of index name to index configuration. Indexes enable different query capabilities:
	// - Full-text indexes for BM25 search
	// - Vector indexes for semantic similarity
	// - Multimodal indexes for images/audio/video
	//
	// You can add multiple indexes to support different query patterns.
	Indexes map[string]IndexConfig `json:"indexes,omitempty,omitzero"`

	// NumShards Number of shards to create for the table. Data is partitioned across shards based on key ranges.
	//
	// **Sizing Guidelines:**
	// - Small datasets (<100K docs): 1-3 shards
	// - Medium datasets (100K-1M docs): 3-10 shards
	// - Large datasets (>1M docs): 10+ shards
	//
	// More shards enable better parallelism but increase overhead. Choose based on expected data size and query patterns.
	//
	// **When to Add More Shards:**
	//
	// Antfly supports **online shard reallocation** without downtime. Add more shards when:
	// - Individual shards exceed size thresholds (configurable)
	// - Query latency increases due to large shard size
	// - Need better parallelism for write-heavy workloads
	//
	// Use the internal `/reallocate` endpoint to trigger automatic shard splitting:
	// ```bash
	// POST /_internal/v1/reallocate
	// ```
	//
	// This enqueues a reallocation request that the leader processes asynchronously, splitting
	// large shards and redistributing data without service interruption.
	//
	// **Advantages over Elasticsearch:**
	// - Automatic shard splitting (no manual reindexing required)
	// - Online operation (no downtime)
	// - Transparent to applications (keys remain accessible during reallocation)
	NumShards uint `json:"num_shards,omitempty,omitzero"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema `json:"schema,omitempty,omitzero"`
}

// CreateUserRequest defines model for CreateUserRequest.
type CreateUserRequest struct {
	// InitialPolicies Optional list of initial permissions for the user.
	InitialPolicies []Permission `json:"initial_policies,omitzero"`
	Password        string       `json:"password"`

	// Username Username for the new user. If provided in the path, this field can be omitted or must match the path parameter.
	Username string `json:"username,omitempty,omitzero"`
}

// Credentials defines model for Credentials.
type Credentials struct {
	// AccessKeyId AWS access key ID. Supports keystore syntax for secret lookup. Falls back to AWS_ACCESS_KEY_ID environment variable if not set.
	AccessKeyId string `json:"access_key_id,omitempty,omitzero"`

	// Endpoint S3-compatible endpoint (e.g., 's3.amazonaws.com' or 'localhost:9000' for MinIO)
	Endpoint string `json:"endpoint,omitempty,omitzero"`

	// SecretAccessKey AWS secret access key. Supports keystore syntax for secret lookup. Falls back to AWS_SECRET_ACCESS_KEY environment variable if not set.
	SecretAccessKey string `json:"secret_access_key,omitempty,omitzero"`

	// SessionToken Optional AWS session token for temporary credentials. Supports keystore syntax for secret lookup.
	SessionToken string `json:"session_token,omitempty,omitzero"`

	// UseSsl Enable SSL/TLS for S3 connections (default: true for AWS, false for local MinIO)
	UseSsl bool `json:"use_ssl,omitempty,omitzero"`
}

// DateRangeStringQuery defines model for DateRangeStringQuery.
type DateRangeStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost          Boost     `json:"boost,omitzero"`
	DatetimeParser string    `json:"datetime_parser,omitempty,omitzero"`
	End            time.Time `json:"end,omitempty,omitzero"`
	Field          string    `json:"field,omitempty,omitzero"`
	InclusiveEnd   bool      `json:"inclusive_end,omitzero"`
	InclusiveStart bool      `json:"inclusive_start,omitzero"`
	Start          time.Time `json:"start,omitempty,omitzero"`
}

// DisjunctionQuery defines model for DisjunctionQuery.
type DisjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Disjuncts []Query `json:"disjuncts"`
	Min       float64 `json:"min,omitempty,omitzero"`
}

// DistanceRange defines model for DistanceRange.
type DistanceRange struct {
	// From Minimum distance (inclusive)
	From *float64 `json:"from,omitempty"`

	// Name Name of the distance range bucket
	Name string `json:"name"`

	// To Maximum distance (exclusive)
	To *float64 `json:"to,omitempty"`
}

// DistanceUnit Distance unit for geo aggregations:
// - m: meters
// - km: kilometers
// - mi: miles
// - ft: feet
// - yd: yards
type DistanceUnit string

// DocIdQuery defines model for DocIdQuery.
type DocIdQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost    `json:"boost,omitzero"`
	Ids   []string `json:"ids"`
}

// DocumentSchema Defines the structure of a document type
type DocumentSchema struct {
	// Description A description of the document type.
	Description string `json:"description,omitempty,omitzero"`

	// Schema A valid JSON Schema defining the document's structure.
	// This is used to infer indexing rules and field types.
	Schema map[string]interface{} `json:"schema,omitempty,omitzero"`
}

// DuckDuckGoSearchConfig defines model for DuckDuckGoSearchConfig.
type DuckDuckGoSearchConfig struct {
	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// NoHtml Remove HTML from results
	NoHtml bool `json:"no_html,omitempty,omitzero"`

	// NoRedirect Skip HTTP redirect for bang queries
	NoRedirect bool `json:"no_redirect,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// DynamicTemplate A rule for mapping dynamically detected fields. Templates are checked in order
// and the first matching template's mapping is used.
type DynamicTemplate struct {
	// Mapping Field mapping to apply when a dynamic template matches
	Mapping TemplateFieldMapping `json:"mapping,omitempty,omitzero"`

	// Match Glob pattern for field name (last path element).
	// Supports * and ** wildcards. Example: "*_text" matches "title_text", "body_text"
	Match string `json:"match,omitempty,omitzero"`

	// MatchMappingType Filter by detected JSON type
	MatchMappingType DynamicTemplateMatchMappingType `json:"match_mapping_type,omitempty,omitzero"`

	// Name Optional identifier for the template (useful for debugging)
	Name string `json:"name,omitempty,omitzero"`

	// PathMatch Glob pattern for the full dotted path. Supports ** for matching multiple segments.
	// Example: "metadata.**" matches "metadata.author", "metadata.tags.primary"
	PathMatch string `json:"path_match,omitempty,omitzero"`

	// PathUnmatch Path exclusion pattern. If it matches the full path, the template is skipped.
	PathUnmatch string `json:"path_unmatch,omitempty,omitzero"`

	// Unmatch Exclusion pattern for field name. If it matches, the template is skipped.
	// Example: "skip_*" would exclude fields like "skip_this"
	Unmatch string `json:"unmatch,omitempty,omitzero"`
}

// DynamicTemplateMatchMappingType Filter by detected JSON type
type DynamicTemplateMatchMappingType string

// Edge A typed, weighted connection between documents
type Edge struct {
	// CreatedAt When the edge was created
	CreatedAt time.Time `json:"created_at,omitempty,omitzero"`

	// Metadata Optional edge metadata
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`

	// Source Base64-encoded source document key
	Source []byte `json:"source"`

	// Target Base64-encoded target document key
	Target []byte `json:"target"`

	// Type Edge type (e.g., "cites", "similar_to", "authored_by")
	Type string `json:"type"`

	// UpdatedAt When the edge was last updated
	UpdatedAt time.Time `json:"updated_at,omitempty,omitzero"`

	// Weight Edge weight/confidence (0.0 to 1.0)
	Weight float64 `json:"weight"`
}

// EdgeDirection Direction of edges to query:
// - out: Outgoing edges from the node
// - in: Incoming edges to the node
// - both: Both outgoing and incoming edges
type EdgeDirection string

// EdgeTypeConfig Configuration for a specific edge type
type EdgeTypeConfig struct {
	// AllowSelfLoops Whether to allow edges from a node to itself
	AllowSelfLoops bool `json:"allow_self_loops,omitempty,omitzero"`

	// Field Document field containing target node key(s) for automatic edge creation.
	// Supports string (single target) or array of strings (multiple targets).
	// When omitted, edges must be provided explicitly via _edges.
	Field string `json:"field,omitempty,omitzero"`

	// MaxWeight Maximum allowed edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum allowed edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// Name Edge type name (e.g., 'cites', 'similar_to')
	Name string `json:"name"`

	// RequiredMetadata Required metadata fields for this edge type
	RequiredMetadata []string `json:"required_metadata,omitempty,omitzero"`

	// Topology Topology constraint for this edge type:
	// - tree: Single parent per node, no cycles
	// - graph: No constraints (default)
	Topology EdgeTypeConfigTopology `json:"topology,omitempty,omitzero"`
}

// EdgeTypeConfigTopology Topology constraint for this edge type:
// - tree: Single parent per node, no cycles
// - graph: No constraints (default)
type EdgeTypeConfigTopology string

// EdgesResponse defines model for EdgesResponse.
type EdgesResponse struct {
	// Count Total number of edges returned
	Count int    `json:"count,omitempty,omitzero"`
	Edges []Edge `json:"edges,omitempty,omitzero"`
}

// EmbedderConfig defines model for EmbedderConfig.
type EmbedderConfig struct {
	// Provider The embedding provider to use.
	Provider EmbedderProvider `json:"provider"`
	union    json.RawMessage
}

// EmbedderProvider The embedding provider to use.
type EmbedderProvider string

// EmbeddingIndexConfig defines model for EmbeddingIndexConfig.
type EmbeddingIndexConfig struct {
	// Chunker A unified configuration for a chunking provider.
	Chunker ChunkerConfig `json:"chunker,omitempty,omitzero"`

	// Dimension Vector dimension
	Dimension int `json:"dimension"`

	// Embedder A unified configuration for an embedding provider.
	//
	// Embedders can be configured with templates to customize how documents are
	// converted to text before embedding. Templates use Handlebars syntax and
	// support various built-in helpers.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full document as context
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active user{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// Document with metadata:
	// ```handlebars
	// Title: {{metadata.title}}
	// Date: {{metadata.date}}
	// Tags: {{#each metadata.tags}}{{this}}, {{/each}}
	//
	// {{content}}
	// ```
	//
	// HTML content extraction:
	// ```handlebars
	// Product: {{name}}
	// Description: {{scrubHtml description_html}}
	// Price: ${{price}}
	// ```
	//
	// Multimodal with image:
	// ```handlebars
	// Product: {{title}}
	// {{media url=image}}
	// Description: {{description}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{title}}
	// {{#if author}}By: {{author}}{{/if}}
	// {{#if (eq category "premium")}} Premium Content{{/if}}
	// {{body}}
	// ```
	//
	// **Environment Variables:**
	// - `GEMINI_API_KEY` - API key for Google AI
	// - `OPENAI_API_KEY` - API key for OpenAI
	// - `OPENAI_BASE_URL` - Base URL for OpenAI-compatible APIs
	// - `OLLAMA_HOST` - Ollama server URL (e.g., http://localhost:11434)
	//
	// **Importing Pre-computed Embeddings:**
	//
	// You can import existing embeddings (from OpenAI, Cohere, or any provider) by including
	// them directly in your documents using the `_embeddings` field. This bypasses the
	// embedding generation step and writes vectors directly to the index.
	//
	// **Steps:**
	// 1. Create the index first with the appropriate dimension
	// 2. Write documents with `_embeddings: { "<indexName>": [...<embedding>...] }`
	//
	// **Example:**
	// ```json
	// {
	//   "title": "My Document",
	//   "content": "Document text...",
	//   "_embeddings": {
	//     "my_vector_index": [0.1, 0.2, 0.3, ...]
	//   }
	// }
	// ```
	//
	// **Use Cases:**
	// - Migrating from another vector database with existing embeddings
	// - Using embeddings generated by external systems
	// - Importing pre-computed OpenAI, Cohere, or other provider embeddings
	// - Batch processing embeddings offline before ingestion
	Embedder EmbedderConfig `json:"embedder,omitempty,omitzero"`

	// Field Field to extract embeddings from
	Field string `json:"field,omitempty,omitzero"`

	// MemOnly Whether to use in-memory only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`

	// Summarizer A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Summarizer GeneratorConfig `json:"summarizer,omitempty,omitzero"`

	// Template Handlebars template for generating prompts. See https://handlebarsjs.com/guide/ for more information.
	Template string `json:"template,omitempty,omitzero"`
}

// EmbeddingIndexStats defines model for EmbeddingIndexStats.
type EmbeddingIndexStats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalIndexed Number of vectors in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`

	// TotalNodes Total number of nodes in the index
	TotalNodes uint64 `json:"total_nodes,omitempty,omitzero"`
}

// Error defines model for Error.
type Error struct {
	Error string `json:"error"`
}

// EvalConfig Configuration for inline evaluation of query results.
// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
type EvalConfig struct {
	// Evaluators List of evaluators to run
	Evaluators []EvaluatorName `json:"evaluators,omitempty,omitzero"`

	// GroundTruth Ground truth data for evaluation
	GroundTruth GroundTruth `json:"ground_truth,omitempty,omitzero"`

	// Judge A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Judge GeneratorConfig `json:"judge,omitempty,omitzero"`

	// Options Options for evaluation behavior
	Options EvalOptions `json:"options,omitempty,omitzero"`
}

// EvalOptions Options for evaluation behavior
type EvalOptions struct {
	// K K value for @K metrics (precision@k, recall@k, ndcg@k)
	K int `json:"k,omitempty,omitzero"`

	// PassThreshold Score threshold for pass/fail determination
	PassThreshold float32 `json:"pass_threshold,omitempty,omitzero"`

	// TimeoutSeconds Timeout for evaluation in seconds
	TimeoutSeconds int `json:"timeout_seconds,omitempty,omitzero"`
}

// EvalRequest Standalone evaluation request for POST /eval endpoint.
// Useful for testing evaluators without running a query.
type EvalRequest struct {
	// Context Retrieved documents/context
	Context []map[string]interface{} `json:"context,omitempty,omitzero"`

	// Evaluators List of evaluators to run
	Evaluators []EvaluatorName `json:"evaluators"`

	// GroundTruth Ground truth data for evaluation
	GroundTruth GroundTruth `json:"ground_truth,omitempty,omitzero"`

	// Judge A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Judge GeneratorConfig `json:"judge,omitempty,omitzero"`

	// Options Options for evaluation behavior
	Options EvalOptions `json:"options,omitempty,omitzero"`

	// Output Generated output to evaluate (optional for retrieval-only)
	Output string `json:"output,omitempty,omitzero"`

	// Query Original query/input to evaluate
	Query string `json:"query,omitempty,omitzero"`

	// RetrievedIds IDs of retrieved documents (for retrieval metrics)
	RetrievedIds []string `json:"retrieved_ids,omitempty,omitzero"`
}

// EvalResult Complete evaluation result
type EvalResult struct {
	// DurationMs Total evaluation duration in milliseconds
	DurationMs int `json:"duration_ms,omitempty,omitzero"`

	// Scores Scores organized by category
	Scores EvalScores `json:"scores,omitempty,omitzero"`

	// Summary Aggregate statistics across all evaluators
	Summary EvalSummary `json:"summary,omitempty,omitzero"`
}

// EvalScores Scores organized by category
type EvalScores struct {
	// Generation Generation quality scores (faithfulness, relevance, etc.)
	Generation map[string]EvaluatorScore `json:"generation,omitempty,omitzero"`

	// Retrieval Retrieval metric scores (recall, precision, ndcg, etc.)
	Retrieval map[string]EvaluatorScore `json:"retrieval,omitempty,omitzero"`
}

// EvalSummary Aggregate statistics across all evaluators
type EvalSummary struct {
	// AverageScore Average score across all evaluators
	AverageScore float32 `json:"average_score,omitempty,omitzero"`

	// Failed Number of evaluators that failed
	Failed int `json:"failed,omitempty,omitzero"`

	// Passed Number of evaluators that passed
	Passed int `json:"passed,omitempty,omitzero"`

	// Total Total number of evaluators run
	Total int `json:"total,omitempty,omitzero"`
}

// EvaluatorName Available evaluator types:
//
// **Retrieval metrics** (require ground_truth.relevant_ids):
// - recall: Recall@k - fraction of relevant docs retrieved
// - precision: Precision@k - fraction of retrieved docs that are relevant
// - ndcg: Normalized Discounted Cumulative Gain
// - mrr: Mean Reciprocal Rank
// - map: Mean Average Precision
//
// **LLM-as-judge metrics** (require judge config):
// - relevance: Is output relevant to query? (works on retrieval-only too)
// - faithfulness: Is output grounded in context?
// - completeness: Does output fully address query?
// - coherence: Is output well-structured?
// - safety: Is output safe/appropriate?
// - helpfulness: Is output useful?
// - correctness: Is output factually correct? (uses expectations)
// - citation_quality: Are citations accurate?
type EvaluatorName string

// EvaluatorScore Result from a single evaluator
type EvaluatorScore struct {
	// Metadata Additional evaluator-specific data
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`

	// Pass Whether the evaluation passed the threshold
	Pass bool `json:"pass,omitempty,omitzero"`

	// Reason Human-readable explanation of the result
	Reason string `json:"reason,omitempty,omitzero"`

	// Score Numeric score (0-1)
	Score float32 `json:"score,omitempty,omitzero"`
}

// FailedOperation defines model for FailedOperation.
type FailedOperation struct {
	Error     string                   `json:"error,omitempty,omitzero"`
	Id        string                   `json:"id,omitempty,omitzero"`
	Operation FailedOperationOperation `json:"operation,omitempty,omitzero"`
}

// FailedOperationOperation defines model for FailedOperation.Operation.
type FailedOperationOperation string

// FetchConfig Configuration for URL content fetching.
//
// Uses lib/scraping for downloading and processing. Supports:
// - HTTP/HTTPS URLs with security validation
// - HTML pages (extracts readable text via go-readability)
// - PDF files (extracts text)
// - Images (returns as data URIs)
// - Plain text files
// - S3 URLs (requires s3_credentials)
//
// Security features (from lib/scraping.ContentSecurityConfig):
// - Allowed host whitelist
// - Private IP blocking (SSRF prevention)
// - Download size limits
// - Timeout controls
type FetchConfig struct {
	// AllowedHosts Whitelist of allowed hostnames for fetching.
	// If empty, all hosts are allowed (except private IPs).
	// Example: ["docs.example.com", "api.example.com"]
	AllowedHosts []string `json:"allowed_hosts,omitempty,omitzero"`

	// BlockPrivateIps Block requests to private IP ranges (SSRF prevention).
	// Blocked: 127.0.0.0/8, 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16
	BlockPrivateIps *bool `json:"block_private_ips,omitempty"`

	// MaxContentLength Maximum content length in characters (truncated if exceeded)
	MaxContentLength int `json:"max_content_length,omitempty,omitzero"`

	// MaxDownloadSizeBytes Maximum download size in bytes (default: 100MB)
	MaxDownloadSizeBytes int         `json:"max_download_size_bytes,omitempty,omitzero"`
	S3Credentials        Credentials `json:"s3_credentials,omitempty,omitzero"`

	// TimeoutSeconds Download timeout in seconds
	TimeoutSeconds int `json:"timeout_seconds,omitempty,omitzero"`
}

// FieldStatistics Statistics about a specific field.
type FieldStatistics struct {
	// AvgSize Average size in bytes for variable-length fields.
	AvgSize int `json:"avg_size,omitempty,omitzero"`

	// Cardinality Approximate number of unique values (via HyperLogLog).
	Cardinality int64 `json:"cardinality,omitempty,omitzero"`

	// MaxValue Maximum value for numeric/date fields.
	MaxValue interface{} `json:"max_value,omitempty,omitzero"`

	// MinValue Minimum value for numeric/date fields.
	MinValue interface{} `json:"min_value,omitempty,omitzero"`

	// NullCount Number of rows with null values for this field.
	NullCount int64 `json:"null_count,omitempty,omitzero"`
}

// FilterSpec A filter specification to apply to search queries
type FilterSpec struct {
	// Field Field name to filter on
	Field string `json:"field"`

	// Operator Filter operator:
	// - eq: Equals
	// - ne: Not equals
	// - gt/gte: Greater than (or equal)
	// - lt/lte: Less than (or equal)
	// - contains: Contains substring
	// - prefix: Starts with
	// - range: Between two values (value should be array [min, max])
	// - in: Value in list (value should be array)
	Operator FilterSpecOperator `json:"operator"`

	// Value Filter value (string, number, boolean, or array for range/in operators)
	Value interface{} `json:"value"`
}

// FilterSpecOperator Filter operator:
// - eq: Equals
// - ne: Not equals
// - gt/gte: Greater than (or equal)
// - lt/lte: Less than (or equal)
// - contains: Contains substring
// - prefix: Starts with
// - range: Between two values (value should be array [min, max])
// - in: Value in list (value should be array)
type FilterSpecOperator string

// FollowupStepConfig Configuration for generating follow-up questions. Uses a separate generator
// call which can use a cheaper/faster model.
type FollowupStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Context Custom guidance for follow-up question focus and style
	Context string `json:"context,omitempty,omitzero"`

	// Count Number of follow-up questions to generate
	Count int `json:"count,omitempty,omitzero"`

	// Enabled Enable follow-up question generation
	Enabled bool `json:"enabled,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`
}

// Fuzziness The fuzziness of the query. Can be an integer or "auto".
type Fuzziness struct {
	union json.RawMessage
}

// Fuzziness0 defines model for .
type Fuzziness0 = int32

// Fuzziness1 defines model for Fuzziness.1.
type Fuzziness1 string

// FuzzyQuery defines model for FuzzyQuery.
type FuzzyQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness `json:"fuzziness,omitempty,omitzero"`
	PrefixLength int32     `json:"prefix_length,omitempty,omitzero"`
	Term         string    `json:"term"`
}

// GenerateResult Result of a generate operation. Formatted as markdown by default with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
type GenerateResult struct {
	// Text The generated text in markdown format with inline resource references like [resource_id res1] or [resource_id res1, res2]
	Text string `json:"text"`
}

// GeneratorConfig defines model for GeneratorConfig.
type GeneratorConfig struct {
	// Provider The generative AI provider to use.
	Provider GeneratorProvider `json:"provider"`
	union    json.RawMessage
}

// GeneratorProvider The generative AI provider to use.
type GeneratorProvider string

// GeoBoundingBoxQuery defines model for GeoBoundingBoxQuery.
type GeoBoundingBoxQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost `json:"boost,omitzero"`

	// BottomRight [lon, lat]
	BottomRight []float64 `json:"bottom_right"`
	Field       string    `json:"field,omitempty,omitzero"`

	// TopLeft [lon, lat]
	TopLeft []float64 `json:"top_left"`
}

// GeoBoundingPolygonQuery defines model for GeoBoundingPolygonQuery.
type GeoBoundingPolygonQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost         Boost      `json:"boost,omitzero"`
	Field         string     `json:"field,omitempty,omitzero"`
	PolygonPoints []GeoPoint `json:"polygon_points"`
}

// GeoDistanceQuery defines model for GeoDistanceQuery.
type GeoDistanceQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Distance string `json:"distance"`
	Field    string `json:"field,omitempty,omitzero"`

	// Location [lon, lat]
	Location []float64 `json:"location"`
}

// GeoPoint defines model for GeoPoint.
type GeoPoint struct {
	Lat float64 `json:"lat,omitempty,omitzero"`
	Lon float64 `json:"lon,omitempty,omitzero"`
}

// GeoShape A GeoJSON shape object. This is a simplified representation.
type GeoShape struct {
	Coordinates []interface{} `json:"coordinates"`
	Type        string        `json:"type"`
}

// GeoShapeGeometry defines model for GeoShapeGeometry.
type GeoShapeGeometry struct {
	Relation GeoShapeGeometryRelation `json:"relation"`

	// Shape A GeoJSON shape object. This is a simplified representation.
	Shape GeoShape `json:"shape"`
}

// GeoShapeGeometryRelation defines model for GeoShapeGeometry.Relation.
type GeoShapeGeometryRelation string

// GeoShapeQuery defines model for GeoShapeQuery.
type GeoShapeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost            `json:"boost,omitzero"`
	Field    string           `json:"field,omitempty,omitzero"`
	Geometry GeoShapeGeometry `json:"geometry"`
}

// GoogleEmbedderConfig Configuration for the Google AI (Gemini) embedding provider.
//
// API key via `api_key` field or `GEMINI_API_KEY` environment variable.
//
// **Example Models:** gemini-embedding-001 (default, 3072 dims)
//
// **Docs:** https://ai.google.dev/gemini-api/docs/embeddings
type GoogleEmbedderConfig struct {
	// ApiKey The Google API key. Can also be set via GEMINI_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimension The dimension of the embedding vector (768, 1536, or 3072 recommended).
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1'). Required for Vertex AI, optional for Gemini API.
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the embedding model to use.
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID (optional for Gemini API, required for Vertex AI).
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Url The URL of the Google API endpoint (optional, uses default if not specified).
	Url string `json:"url,omitempty,omitzero"`
}

// GoogleGeneratorConfig Configuration for the Google generative AI provider (Gemini).
//
// **Example Models:** gemini-2.5-flash (default), gemini-2.5-pro, gemini-3.0-pro
//
// **Docs:** https://ai.google.dev/gemini-api/docs/models
type GoogleGeneratorConfig struct {
	// ApiKey The Google API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1').
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the generative model to use (e.g., 'gemini-2.5-flash', 'gemini-2.5-pro', 'gemini-3.0-pro').
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Google API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// GoogleSearchConfig defines model for GoogleSearchConfig.
type GoogleSearchConfig struct {
	// ApiKey Google API key (or set GOOGLE_CSE_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// CseId Custom Search Engine ID (or set GOOGLE_CSE_ID env var)
	CseId string `json:"cse_id,omitempty,omitzero"`

	// DateRestrict Restrict results by date (e.g., 'd7' for last 7 days, 'm1' for last month)
	DateRestrict string `json:"date_restrict,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// SearchType Type of search to perform
	SearchType GoogleSearchConfigSearchType `json:"search_type,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// GoogleSearchConfigSearchType Type of search to perform
type GoogleSearchConfigSearchType string

// GraphIndexV0Config Configuration for graph_v0 index type
type GraphIndexV0Config struct {
	// EdgeTypes List of edge types with their configurations
	EdgeTypes []EdgeTypeConfig `json:"edge_types,omitempty,omitzero"`

	// MaxEdgesPerDocument Maximum number of edges per document (0 = unlimited)
	MaxEdgesPerDocument int `json:"max_edges_per_document,omitempty,omitzero"`

	// Summarizer A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Summarizer GeneratorConfig `json:"summarizer,omitempty,omitzero"`

	// Template Handlebars template for generating summarizer input text.
	// Uses document fields as template variables.
	// Same pattern as EmbeddingIndexConfig.template.
	Template string `json:"template,omitempty,omitzero"`
}

// GraphIndexV0Stats Statistics for graph_v0 index
type GraphIndexV0Stats struct {
	// EdgeTypes Count of edges per edge type
	EdgeTypes map[string]uint64 `json:"edge_types,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalEdges Total number of edges in the graph
	TotalEdges uint64 `json:"total_edges,omitempty,omitzero"`
}

// GraphNodeSelector Defines how to select start/target nodes for graph queries
type GraphNodeSelector struct {
	// Keys Explicit list of node keys
	Keys []string `json:"keys,omitempty,omitzero"`

	// Limit Maximum number of nodes to select from the referenced results
	Limit int `json:"limit,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`

	// ResultRef Reference to search results to use as nodes:
	// - "$full_text_results" - use full-text search results
	// - "$aknn_results.index_name" - use vector search results from specific index
	ResultRef string `json:"result_ref,omitempty,omitzero"`
}

// GraphQuery Declarative graph query to execute after full-text/vector searches
type GraphQuery struct {
	// Fields Which fields to return from documents
	Fields []string `json:"fields,omitempty,omitzero"`

	// IncludeDocuments Fetch full documents for graph results
	IncludeDocuments bool `json:"include_documents,omitempty,omitzero"`

	// IncludeEdges Include edge details for each node
	IncludeEdges bool `json:"include_edges,omitempty,omitzero"`

	// IndexName Graph index name (must be graph_v0 type)
	IndexName string `json:"index_name"`

	// Params Parameters for graph traversal and pathfinding
	Params GraphQueryParams `json:"params,omitempty,omitzero"`

	// Pattern Pattern steps for pattern query type
	Pattern []PatternStep `json:"pattern,omitempty,omitzero"`

	// ReturnAliases Which aliases to return from pattern query (empty = all)
	ReturnAliases []string `json:"return_aliases,omitempty,omitzero"`

	// StartNodes Defines how to select start/target nodes for graph queries
	StartNodes GraphNodeSelector `json:"start_nodes,omitempty,omitzero"`

	// TargetNodes Defines how to select start/target nodes for graph queries
	TargetNodes GraphNodeSelector `json:"target_nodes,omitempty,omitzero"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryParams Parameters for graph traversal and pathfinding
type GraphQueryParams struct {
	// Algorithm Graph algorithm to run (e.g., 'pagerank', 'betweenness')
	Algorithm string `json:"algorithm,omitempty,omitzero"`

	// AlgorithmParams Parameters for the graph algorithm
	AlgorithmParams map[string]interface{} `json:"algorithm_params,omitempty,omitzero"`

	// DeduplicateNodes Remove duplicate nodes (traversal)
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information (traversal)
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// K Number of paths to find (k-shortest-paths)
	K int `json:"k,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum number of results (traversal)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`

	// WeightMode Path weighting algorithm for pathfinding:
	// - min_hops: Minimize number of edges
	// - min_weight: Minimize sum of edge weights
	// - max_weight: Maximize product of edge weights
	WeightMode PathWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// GraphQueryResult Results of a graph query
type GraphQueryResult struct {
	// Matches Pattern matches (for pattern queries)
	Matches []PatternMatch `json:"matches,omitempty,omitzero"`

	// Nodes Result nodes
	Nodes []GraphResultNode `json:"nodes,omitempty,omitzero"`

	// Paths Result paths (for pathfinding queries)
	Paths []Path `json:"paths,omitempty,omitzero"`

	// Took Query execution time
	Took time.Duration `json:"took,omitempty,omitzero"`

	// Total Total number of results
	Total int `json:"total"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryType Type of graph query to execute
type GraphQueryType string

// GraphResultNode A node in graph query results
type GraphResultNode struct {
	// Depth Distance from start node
	Depth int `json:"depth,omitempty,omitzero"`

	// Distance Weighted distance
	Distance float64 `json:"distance,omitempty,omitzero"`

	// Document Full document (if include_documents=true)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Edges Connected edges (when include_edges=true)
	Edges []Edge `json:"edges,omitempty,omitzero"`

	// Key Document key
	Key string `json:"key"`

	// Path Keys in path from start to this node
	Path []string `json:"path,omitempty,omitzero"`

	// PathEdges Edges in path from start to this node
	PathEdges []PathEdge `json:"path_edges,omitempty,omitzero"`
}

// GroundTruth Ground truth data for evaluation
type GroundTruth struct {
	// Expectations Context for evaluators about what to expect in the response.
	// Provides guidance for LLM judges (e.g., "Should mention pricing tiers").
	Expectations string `json:"expectations,omitempty,omitzero"`

	// RelevantIds Document IDs known to be relevant (for retrieval metrics)
	RelevantIds []string `json:"relevant_ids,omitempty,omitzero"`
}

// IPRangeQuery defines model for IPRangeQuery.
type IPRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Cidr  string `json:"cidr"`
	Field string `json:"field,omitempty,omitzero"`
}

// IndexConfig Configuration for an index
type IndexConfig struct {
	// Description Optional description of the index and its purpose
	Description string `json:"description,omitempty,omitzero"`

	// Enrichments List of enrichment names to apply to documents before indexing. Enrichments must be defined at the table level.
	Enrichments []string `json:"enrichments,omitempty,omitzero"`

	// Name Name of the index
	Name string `json:"name"`

	// Type The type of the index.
	Type  IndexType `json:"type"`
	union json.RawMessage
}

// IndexStats Statistics for an index
type IndexStats struct {
	union json.RawMessage
}

// IndexStatus defines model for IndexStatus.
type IndexStatus struct {
	// Config Configuration for an index
	Config      IndexConfig           `json:"config"`
	ShardStatus map[string]IndexStats `json:"shard_status"`

	// Status Statistics for an index
	Status IndexStats `json:"status"`
}

// IndexType The type of the index.
type IndexType string

// JoinClause Configuration for joining data from another table.
// Supports inner, left, and right joins with automatic strategy selection.
type JoinClause struct {
	// JoinType Type of join to perform:
	// - `inner`: Only return rows with matches in both tables
	// - `left`: Return all rows from left table, NULL for non-matching right rows
	// - `right`: Return all rows from right table, NULL for non-matching left rows
	JoinType JoinType `json:"join_type,omitempty,omitzero"`

	// NestedJoin Optional nested join for multi-way joins.
	// The nested join operates on the result of the current join.
	NestedJoin *JoinClause `json:"nested_join"`

	// On Condition for matching rows between tables.
	On JoinCondition `json:"on"`

	// RightFields Fields to include from the right table in the result.
	// If not specified, all fields from the right table are included.
	// Fields are prefixed with the right table name in the result.
	RightFields []string `json:"right_fields,omitempty,omitzero"`

	// RightFilters Filters to apply to a table before joining.
	RightFilters JoinFilters `json:"right_filters,omitempty,omitzero"`

	// RightTable Name of the table to join with.
	RightTable string `json:"right_table"`

	// StrategyHint Strategy for executing the join:
	// - `broadcast`: Broadcast small table to all shards of large table.
	//   Best for dimension tables < 10MB. O(small_table) memory per shard.
	// - `index_lookup`: Use batch key lookups via indexes.
	//   Best for selective joins with indexed join keys. Low memory overhead.
	// - `shuffle`: Hash-partition both tables by join key.
	//   Best for large-large table joins. Requires data movement.
	StrategyHint JoinStrategy `json:"strategy_hint,omitempty,omitzero"`
}

// JoinCondition Condition for matching rows between tables.
type JoinCondition struct {
	// LeftField Field from the left (primary) table to match on.
	LeftField string `json:"left_field"`

	// Operator Comparison operator for join condition:
	// - `eq`: Equal (default)
	// - `neq`: Not equal
	// - `lt`: Less than
	// - `lte`: Less than or equal
	// - `gt`: Greater than
	// - `gte`: Greater than or equal
	Operator JoinOperator `json:"operator,omitempty,omitzero"`

	// RightField Field from the right (joined) table to match on.
	RightField string `json:"right_field"`
}

// JoinFilters Filters to apply to a table before joining.
type JoinFilters struct {
	// FilterPrefix Key prefix filter for the table.
	FilterPrefix []byte `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query to filter rows before joining.
	FilterQuery json.RawMessage `json:"filter_query,omitempty,omitzero"`

	// Limit Maximum number of rows to include from this table.
	Limit int `json:"limit,omitempty,omitzero"`
}

// JoinOperator Comparison operator for join condition:
// - `eq`: Equal (default)
// - `neq`: Not equal
// - `lt`: Less than
// - `lte`: Less than or equal
// - `gt`: Greater than
// - `gte`: Greater than or equal
type JoinOperator string

// JoinResult Statistics and metadata about join execution.
type JoinResult struct {
	// JoinTimeMs Time spent executing the join in milliseconds.
	JoinTimeMs int64 `json:"join_time_ms,omitempty,omitzero"`

	// LeftRowsScanned Number of rows scanned from the left table.
	LeftRowsScanned int64 `json:"left_rows_scanned,omitempty,omitzero"`

	// RightRowsScanned Number of rows scanned from the right table.
	RightRowsScanned int64 `json:"right_rows_scanned,omitempty,omitzero"`

	// RowsMatched Number of rows that matched the join condition.
	RowsMatched int64 `json:"rows_matched,omitempty,omitzero"`

	// RowsUnmatchedLeft Number of left rows without a match (for left/full joins).
	RowsUnmatchedLeft int64 `json:"rows_unmatched_left,omitempty,omitzero"`

	// RowsUnmatchedRight Number of right rows without a match (for right/full joins).
	RowsUnmatchedRight int64 `json:"rows_unmatched_right,omitempty,omitzero"`

	// StrategyUsed Strategy for executing the join:
	// - `broadcast`: Broadcast small table to all shards of large table.
	//   Best for dimension tables < 10MB. O(small_table) memory per shard.
	// - `index_lookup`: Use batch key lookups via indexes.
	//   Best for selective joins with indexed join keys. Low memory overhead.
	// - `shuffle`: Hash-partition both tables by join key.
	//   Best for large-large table joins. Requires data movement.
	StrategyUsed JoinStrategy `json:"strategy_used,omitempty,omitzero"`
}

// JoinStrategy Strategy for executing the join:
//   - `broadcast`: Broadcast small table to all shards of large table.
//     Best for dimension tables < 10MB. O(small_table) memory per shard.
//   - `index_lookup`: Use batch key lookups via indexes.
//     Best for selective joins with indexed join keys. Low memory overhead.
//   - `shuffle`: Hash-partition both tables by join key.
//     Best for large-large table joins. Requires data movement.
type JoinStrategy string

// JoinType Type of join to perform:
// - `inner`: Only return rows with matches in both tables
// - `left`: Return all rows from left table, NULL for non-matching right rows
// - `right`: Return all rows from right table, NULL for non-matching left rows
type JoinType string

// KeyRange Key range processed in this request
type KeyRange struct {
	From string `json:"from,omitempty,omitzero"`
	To   string `json:"to,omitempty,omitzero"`
}

// LinearMergePageStatus Status of a linear merge page operation:
// - "success": All records in batch processed successfully
// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
// - "error": Fatal error occurred, no records processed successfully
type LinearMergePageStatus string

// LinearMergeRequest Linear merge operation for syncing sorted records from external sources.
// Use this to keep Antfly in sync with an external database or data source.
//
// **How it works:**
// 1. Send sorted records from your external source
// 2. Server upserts records that exist in your batch
// 3. Server deletes Antfly records in the key range that are absent from your batch
// 4. If stopped at shard boundary, use next_cursor for next request
//
// **WARNING:** Not safe for concurrent operations with overlapping key ranges.
type LinearMergeRequest struct {
	// DryRun If true, returns what would be deleted without making changes.
	//
	// Use cases:
	// - Validate sync behavior before committing
	// - Check which records will be removed
	// - Test key range boundaries
	//
	// Response includes deleted_ids array when dry_run=true.
	DryRun bool `json:"dry_run,omitempty,omitzero"`

	// LastMergedId ID of last record from previous merge request.
	// - First request: Use empty string ""
	// - Subsequent requests: Use next_cursor from previous response
	// - Defines lower bound of key range to process
	//
	// This enables pagination for large datasets.
	LastMergedId string `json:"last_merged_id,omitempty,omitzero"`

	// Records Map of resource ID to resource object: {"resource_id_1": {...}, "resource_id_2": {...}}
	//
	// Requirements:
	// - Keys must be sorted lexicographically by your client
	// - Server will process keys in sorted order
	// - Use consistent key naming (e.g., all start with same prefix)
	//
	// This format avoids duplicate IDs and matches Antfly's batch write interface.
	Records map[string]interface{} `json:"records"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write
	// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`
}

// LinearMergeResult defines model for LinearMergeResult.
type LinearMergeResult struct {
	// Deleted Records deleted or would be deleted (if dry_run=true)
	Deleted int `json:"deleted"`

	// DeletedIds IDs that were deleted (or would be deleted if dry_run=true). Only included if dry_run=true.
	DeletedIds []string          `json:"deleted_ids,omitempty,omitzero"`
	Failed     []FailedOperation `json:"failed,omitempty,omitzero"`

	// KeyRange Key range processed in this request
	KeyRange KeyRange `json:"key_range,omitempty,omitzero"`

	// KeysScanned Total number of keys scanned from Antfly during range query
	KeysScanned int `json:"keys_scanned,omitempty,omitzero"`

	// Message Additional information (e.g., "stopped at shard boundary", "dry run - no changes made")
	Message string `json:"message,omitempty,omitzero"`

	// NextCursor ID of last record in this batch (use for next request)
	NextCursor string `json:"next_cursor"`

	// Skipped Records skipped because content hash matched (unchanged)
	Skipped int `json:"skipped"`

	// Status Status of a linear merge page operation:
	// - "success": All records in batch processed successfully
	// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
	// - "error": Fatal error occurred, no records processed successfully
	Status LinearMergePageStatus `json:"status"`
	Took   time.Duration         `json:"took,omitempty,omitzero"`

	// Upserted Records inserted or updated (0 if dry_run=true)
	Upserted int `json:"upserted"`
}

// MatchAllQuery defines model for MatchAllQuery.
type MatchAllQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost                  `json:"boost,omitzero"`
	MatchAll map[string]interface{} `json:"match_all"`
}

// MatchNoneQuery defines model for MatchNoneQuery.
type MatchNoneQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost                  `json:"boost,omitzero"`
	MatchNone map[string]interface{} `json:"match_none"`
}

// MatchPhraseQuery defines model for MatchPhraseQuery.
type MatchPhraseQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness   Fuzziness `json:"fuzziness,omitempty,omitzero"`
	MatchPhrase string    `json:"match_phrase"`
}

// MatchQuery defines model for MatchQuery.
type MatchQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness          `json:"fuzziness,omitempty,omitzero"`
	Match        string             `json:"match"`
	Operator     MatchQueryOperator `json:"operator,omitempty,omitzero"`
	PrefixLength int32              `json:"prefix_length,omitempty,omitzero"`
}

// MatchQueryOperator defines model for MatchQuery.Operator.
type MatchQueryOperator string

// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
// failover: Use full_text_search if embedding generation fails
type MergeStrategy string

// MultiPhraseQuery defines model for MultiPhraseQuery.
type MultiPhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness  `json:"fuzziness,omitempty,omitzero"`
	Terms     [][]string `json:"terms"`
}

// NodeFilter Filter nodes during graph traversal using existing query primitives
type NodeFilter struct {
	// FilterPrefix Filter by key prefix
	FilterPrefix string `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query to filter nodes (same syntax as search filter_query)
	FilterQuery map[string]interface{} `json:"filter_query,omitempty,omitzero"`
}

// NumericRangeQuery defines model for NumericRangeQuery.
type NumericRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost   `json:"boost,omitzero"`
	Field        string  `json:"field,omitempty,omitzero"`
	InclusiveMax bool    `json:"inclusive_max,omitzero"`
	InclusiveMin bool    `json:"inclusive_min,omitzero"`
	Max          float64 `json:"max,omitzero"`
	Min          float64 `json:"min,omitzero"`
}

// OllamaEmbedderConfig Configuration for the Ollama embedding provider.
//
// Local embeddings for privacy and offline use. URL via `url` field or `OLLAMA_HOST` env var.
//
// **Example Models:** nomic-embed-text (768 dims), mxbai-embed-large (1024 dims), all-minilm (384 dims)
//
// **Docs:** https://ollama.com/search?c=embedding
type OllamaEmbedderConfig struct {
	// Model The name of the Ollama model to use (e.g., 'nomic-embed-text', 'mxbai-embed-large').
	Model string `json:"model"`

	// Url The URL of the Ollama API endpoint. Can also be set via OLLAMA_HOST environment variable.
	Url string `json:"url,omitempty,omitzero"`
}

// OllamaGeneratorConfig Configuration for the Ollama generative AI provider.
//
// Ollama provides local LLM inference for privacy and offline use.
//
// **Example Models:** llama3.3:70b, qwen2.5:72b, deepseek-r1:70b, mistral:7b, llava:34b
//
// **Docs:** https://ollama.com/library
type OllamaGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Ollama model to use (e.g., 'llama3.3:70b', 'qwen2.5:72b', 'deepseek-coder:33b').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OllamaRerankerConfig Configuration for the Ollama reranking provider.
type OllamaRerankerConfig struct {
	// Model The name of the Ollama model to use for reranking.
	Model string `json:"model"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIEmbedderConfig Configuration for the OpenAI embedding provider.
//
// API key via `api_key` field or `OPENAI_API_KEY` environment variable.
// Supports OpenAI-compatible APIs via `url` field.
//
// **Example Models:** text-embedding-3-small (default, 1536 dims), text-embedding-3-large (3072 dims)
//
// **Docs:** https://platform.openai.com/docs/guides/embeddings
type OpenAIEmbedderConfig struct {
	// ApiKey The OpenAI API key. Can also be set via OPENAI_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimensions Output dimension for the embedding (uses MRL for dimension reduction). Recommended: 256, 512, 1024, 1536, or 3072.
	Dimensions int `json:"dimensions,omitempty,omitzero"`

	// Model The name of the OpenAI model to use.
	Model string `json:"model"`

	// Url The URL of the OpenAI API endpoint. Defaults to OpenAI's API. Can be set via OPENAI_BASE_URL environment variable.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIGeneratorConfig Configuration for the OpenAI generative AI provider.
//
// **Example Models:** gpt-4.1 (default), gpt-4.1-mini, o3, o4-mini
//
// **Docs:** https://platform.openai.com/docs/models
type OpenAIGeneratorConfig struct {
	// ApiKey The OpenAI API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (-2.0 to 2.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the OpenAI model to use (e.g., 'gpt-4.1', 'gpt-4.1-mini', 'o4-mini').
	Model string `json:"model"`

	// PresencePenalty Penalty for token presence (-2.0 to 2.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the OpenAI API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenRouterEmbedderConfig Configuration for the OpenRouter embedding provider.
//
// OpenRouter provides a unified API for multiple embedding models from different providers.
// API key via `api_key` field or `OPENROUTER_API_KEY` environment variable.
//
// **Example Models:** openai/text-embedding-3-small (default), openai/text-embedding-3-large,
// google/gemini-embedding-001, qwen/qwen3-embedding-8b
//
// **Docs:** https://openrouter.ai/docs/api/reference/embeddings
type OpenRouterEmbedderConfig struct {
	// ApiKey The OpenRouter API key. Can also be set via OPENROUTER_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimensions Output dimension for the embedding (if supported by the model).
	Dimensions int `json:"dimensions,omitempty,omitzero"`

	// Model The OpenRouter model identifier (e.g., 'openai/text-embedding-3-small', 'google/gemini-embedding-001').
	Model string `json:"model"`
}

// OpenRouterGeneratorConfig Configuration for the OpenRouter generative AI provider.
//
// OpenRouter provides a unified API for multiple LLM providers with automatic fallback routing.
// API key via `api_key` field or `OPENROUTER_API_KEY` environment variable.
//
// **Model Selection:**
// - Use `model` for a single model (e.g., "openai/gpt-4.1", "anthropic/claude-sonnet-4-5-20250929")
// - Use `models` array for fallback routing - OpenRouter tries models in order until one succeeds
//
// **Example Models:** openai/gpt-4.1, anthropic/claude-sonnet-4-5-20250929, google/gemini-2.5-flash,
// meta-llama/llama-3.3-70b-instruct
//
// **Docs:** https://openrouter.ai/docs/api/api-reference/chat/send-chat-completion-request
type OpenRouterGeneratorConfig struct {
	// ApiKey The OpenRouter API key. Can also be set via OPENROUTER_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (-2.0 to 2.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model Single model identifier (e.g., 'openai/gpt-4.1'). Either model or models must be provided.
	Model string `json:"model,omitempty,omitzero"`

	// Models Array of model identifiers for fallback routing. OpenRouter tries each model in order
	// until one succeeds. Either model or models must be provided.
	Models []string `json:"models,omitempty,omitzero"`

	// PresencePenalty Penalty for token presence (-2.0 to 2.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// Path defines model for Path.
type Path struct {
	Edges  []PathEdge `json:"edges,omitempty,omitzero"`
	Length int        `json:"length,omitempty,omitzero"`

	// Nodes Ordered list of node keys (base64-encoded)
	Nodes       []string `json:"nodes,omitempty,omitzero"`
	TotalWeight float64  `json:"total_weight,omitempty,omitzero"`
}

// PathEdge defines model for PathEdge.
type PathEdge struct {
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`
	Source   string                 `json:"source,omitempty,omitzero"`
	Target   string                 `json:"target,omitempty,omitzero"`
	Type     string                 `json:"type,omitempty,omitzero"`
	Weight   float64                `json:"weight,omitempty,omitzero"`
}

// PathFindRequest defines model for PathFindRequest.
type PathFindRequest struct {
	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by specific edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`
	K         int      `json:"k,omitempty,omitzero"`
	MaxDepth  int      `json:"max_depth,omitempty,omitzero"`
	MaxWeight float64  `json:"max_weight,omitempty,omitzero"`
	MinWeight float64  `json:"min_weight,omitempty,omitzero"`

	// Source Source node key (base64-encoded)
	Source string `json:"source"`

	// Target Target node key (base64-encoded)
	Target string `json:"target"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindResult defines model for PathFindResult.
type PathFindResult struct {
	Paths        []Path  `json:"paths,omitempty,omitzero"`
	PathsFound   int     `json:"paths_found,omitempty,omitzero"`
	SearchTimeMs float64 `json:"search_time_ms,omitempty,omitzero"`
	Source       string  `json:"source,omitempty,omitzero"`
	Target       string  `json:"target,omitempty,omitzero"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindWeightMode Algorithm for path finding:
// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
// - max_weight: Path with maximum product of edge weights (strongest connection chain)
// - min_weight: Path with minimum sum of edge weights (lowest cost route)
type PathFindWeightMode string

// PathWeightMode Path weighting algorithm for pathfinding:
// - min_hops: Minimize number of edges
// - min_weight: Minimize sum of edge weights
// - max_weight: Maximize product of edge weights
type PathWeightMode string

// PatternEdgeStep Edge constraints in a pattern step
type PatternEdgeStep struct {
	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// MaxHops Maximum number of hops (>1 = variable-length path)
	MaxHops int `json:"max_hops,omitempty,omitzero"`

	// MaxWeight Maximum edge weight filter
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinHops Minimum number of hops (1 = direct edge)
	MinHops int `json:"min_hops,omitempty,omitzero"`

	// MinWeight Minimum edge weight filter
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// Types Edge types to traverse (empty = any)
	Types []string `json:"types,omitempty,omitzero"`
}

// PatternMatch A single match from a pattern query
type PatternMatch struct {
	// Bindings Map of alias to matched node
	Bindings map[string]GraphResultNode `json:"bindings,omitempty,omitzero"`

	// Path Edges traversed in this match
	Path []PathEdge `json:"path,omitempty,omitzero"`
}

// PatternStep A step in a graph pattern query
type PatternStep struct {
	// Alias Name for this node (reuse alias for cycle detection)
	Alias string `json:"alias,omitempty,omitzero"`

	// Edge Edge constraints in a pattern step
	Edge PatternEdgeStep `json:"edge,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`
}

// Permission defines model for Permission.
type Permission struct {
	// Resource Resource name (e.g., table name, target username, or '*' for global).
	Resource string `json:"resource"`

	// ResourceType Type of the resource, e.g., table, user, or global ('*').
	ResourceType ResourceType `json:"resource_type"`

	// Type Type of permission.
	Type PermissionType `json:"type"`
}

// PermissionType Type of permission.
type PermissionType string

// PhraseQuery defines model for PhraseQuery.
type PhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness `json:"fuzziness,omitempty,omitzero"`
	Terms     []string  `json:"terms"`
}

// PrefixQuery defines model for PrefixQuery.
type PrefixQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Prefix string `json:"prefix"`
}

// Pruner Configuration for pruning search results based on score quality.
// Helps filter out low-relevance results in RAG pipelines by detecting
// score gaps or deviations from top results.
type Pruner struct {
	// MaxScoreGapPercent Stop returning results when score drops more than this percentage
	// from the previous result. Detects "elbows" in score distribution.
	// For example, 30.0 stops when score drops 30% from previous result.
	MaxScoreGapPercent float64 `json:"max_score_gap_percent,omitempty,omitzero"`

	// MinAbsoluteScore Hard minimum score threshold. Results with scores below this value
	// are excluded regardless of other pruning settings.
	MinAbsoluteScore float64 `json:"min_absolute_score,omitempty,omitzero"`

	// MinScoreRatio Keep only results with score >= max_score * min_score_ratio.
	// For example, 0.5 keeps results scoring at least half of the top result.
	// Applied after fusion scoring.
	MinScoreRatio float64 `json:"min_score_ratio,omitempty,omitzero"`

	// RequireMultiIndex Only keep results that appear in multiple indexes (both full-text
	// and vector search). Useful for increasing precision by requiring
	// agreement between different retrieval methods.
	RequireMultiIndex bool `json:"require_multi_index,omitempty,omitzero"`

	// StdDevThreshold Keep results within N standard deviations below the mean score.
	// For example, 1.0 keeps results with score >= mean - 1*stddev.
	// Useful for statistical outlier detection in result sets.
	StdDevThreshold float64 `json:"std_dev_threshold,omitempty,omitzero"`
}

// Query defines model for Query.
type Query struct {
	union json.RawMessage
}

// QueryBuilderRequest defines model for QueryBuilderRequest.
type QueryBuilderRequest struct {
	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// Intent Natural language description of the search intent
	Intent string `json:"intent"`

	// SchemaFields List of searchable field names to consider. Overrides table schema if provided.
	SchemaFields []string `json:"schema_fields,omitempty,omitzero"`

	// Table Name of the table to build query for. If provided, uses table schema for field context.
	Table string `json:"table,omitempty,omitzero"`
}

// QueryBuilderResult defines model for QueryBuilderResult.
type QueryBuilderResult struct {
	// Confidence Model's confidence in the generated query (0.0-1.0)
	Confidence float64 `json:"confidence,omitempty,omitzero"`

	// Explanation Human-readable explanation of what the query does and why it was structured this way
	Explanation string `json:"explanation,omitempty,omitzero"`

	// Query Generated search query in simplified DSL format.
	// Can be used directly in QueryRequest.full_text_search or filter_query.
	Query map[string]interface{} `json:"query"`

	// Warnings Any issues, limitations, or assumptions made when generating the query
	Warnings []string `json:"warnings,omitempty,omitzero"`
}

// QueryHit A single query result hit
type QueryHit struct {
	// ID ID of the record.
	ID string `json:"_id"`

	// IndexScores Scores partitioned by index when using RRF search.
	IndexScores map[string]interface{} `json:"_index_scores,omitempty,omitzero"`

	// Score Relevance score of the hit.
	Score  float64                `json:"_score"`
	Source map[string]interface{} `json:"_source,omitempty,omitzero"`
}

// QueryHits A list of query hits.
type QueryHits struct {
	Hits []QueryHit `json:"hits"`

	// MaxScore Maximum score of the results.
	MaxScore float64 `json:"max_score,omitempty,omitzero"`

	// Total Total number of hits available.
	Total uint64 `json:"total,omitempty"`
}

// QueryRequest defines model for QueryRequest.
type QueryRequest struct {
	// Aggregations Aggregation requests for computing metrics and bucketing results.
	// Each key is a user-defined name for the aggregation, and the value specifies the aggregation configuration.
	//
	// Supports metric aggregations (sum, avg, min, max, count, stats, cardinality),
	// bucketing aggregations (terms, range, date_range, histogram, date_histogram),
	// geo aggregations (geohash_grid, geo_distance), and analytics (significant_terms).
	//
	// Example:
	// ```json
	// {
	//   "price_stats": {
	//     "type": "stats",
	//     "field": "price"
	//   },
	//   "categories": {
	//     "type": "terms",
	//     "field": "category",
	//     "size": 10
	//   }
	// }
	// ```
	Aggregations map[string]AggregationRequest `json:"aggregations,omitempty,omitzero"`
	Analyses     *Analyses                     `json:"analyses,omitempty"`

	// Count If true, returns only the total count of matching documents without retrieving the actual documents.
	// Useful for pagination and displaying result counts.
	Count bool `json:"count,omitempty,omitzero"`

	// DistanceOver Minimum distance threshold for semantic similarity search. Results with distance
	// less than this value are excluded.
	//
	// Useful for excluding near-exact duplicates or finding dissimilar documents.
	DistanceOver *float32 `json:"distance_over,omitempty"`

	// DistanceUnder Maximum distance threshold for semantic similarity search. Results with distance
	// greater than this value are excluded. Lower distances indicate higher similarity.
	//
	// Useful for filtering out low-confidence matches.
	DistanceUnder *float32 `json:"distance_under,omitempty"`

	// DocumentRenderer Optional Handlebars template string for rendering document content in RAG queries.
	// Template has access to document fields via `{{this.fields.fieldName}}`.
	//
	// **Default**: Uses TOON (Token-Oriented Object Notation) format for 30-60% token reduction:
	// ```handlebars
	// {{encodeToon this.fields}}
	// ```
	//
	// **Available Helpers**:
	// - `encodeToon` - Renders fields in compact TOON format with configurable options:
	//   - `lengthMarker` (bool): Add # prefix to array counts (default: true)
	//   - `indent` (int): Indentation spacing (default: 2)
	//   - `delimiter` (string): Field separator for tabular arrays
	// - `scrubHtml` - Removes HTML tags and extracts text
	// - `media` - Wraps data URIs for GenKit multimodal support
	// - `eq` - Equality comparison for conditionals
	//
	// **Examples**:
	// - Basic TOON: `{{encodeToon this.fields}}`
	// - Compact TOON: `{{encodeToon this.fields lengthMarker=false indent=0}}`
	// - Tabular data: `{{encodeToon this.fields delimiter="\t"}}`
	// - Custom template: `Title: {{this.fields.title}}\nBody: {{this.fields.body}}`
	// - Traditional format: `{{#each this.fields}}{{@key}}: {{this}}\n{{/each}}`
	//
	// TOON format produces compact, LLM-optimized output like:
	// ```
	// title: Introduction to Vector Search
	// author: Jane Doe
	// tags[#3]: ai,search,ml
	// ```
	//
	// **References**:
	// - TOON Specification: https://github.com/toon-format/toon
	// - Go Implementation: https://github.com/alpkeskin/gotoon
	DocumentRenderer string `json:"document_renderer,omitempty,omitzero"`

	// EmbeddingTemplate Optional Handlebars template for multimodal embedding of the semantic_search query.
	// The template has access to `this` which contains the semantic_search string value.
	//
	// Use this when you want to embed multimodal content (images, PDFs, etc.) instead of
	// just text. The template is rendered using dotprompt with access to remote content helpers.
	//
	// **Available Helpers**:
	// - `remoteMedia url=<url>` - Fetches and embeds remote images/media
	// - `remotePDF url=<url>` - Fetches and extracts content from PDFs
	// - `remoteText url=<url>` - Fetches and includes remote text content
	//
	// **Examples**:
	// - PDF search: `{{remotePDF url=this}}`
	// - Image search: `{{remoteMedia url=this}}`
	// - Mixed: `Search for: {{this}} {{#if this}}{{remoteMedia url=this}}{{/if}}`
	//
	// When not specified, the semantic_search string is embedded as plain text.
	EmbeddingTemplate string `json:"embedding_template,omitempty,omitzero"`

	// Embeddings Pre-computed embeddings to use for semantic searches instead of embedding the semantic_search string.
	// The keys are the index names, and values are the embedding vectors.
	//
	// Use when you've already generated embeddings on the client side to avoid redundant embedding calls.
	Embeddings map[string][]float32 `json:"embeddings,omitempty,omitzero"`

	// ExclusionQuery Bleve query applied as a NOT condition. Documents matching this query are excluded
	// from results. Applied before scoring.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Excluding drafts: `"status:draft"`
	// - Removing deprecated content: `"deprecated:true"`
	// - Filtering out archived items: `"status:archived"`
	ExclusionQuery json.RawMessage `json:"exclusion_query,omitempty,omitzero"`

	// ExpandStrategy Strategy for merging graph results with search results:
	// - union: Include nodes from both search and graph results
	// - intersection: Only include nodes appearing in both
	ExpandStrategy QueryRequestExpandStrategy `json:"expand_strategy,omitempty,omitzero"`

	// Fields List of fields to include in the results. If not specified, all fields are returned.
	// Use to reduce response size and improve performance.
	Fields []string `json:"fields,omitempty,omitzero"`

	// FilterPrefix Filter results by key prefix. Only returns documents whose keys start with this string.
	// Applied before scoring to improve performance.
	//
	// Common use cases:
	// - Multi-tenant filtering: `"tenant:acme:"`
	// - User-specific data: `"user:123:"`
	// - Document type filtering: `"article:"`
	FilterPrefix []byte `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query applied as an AND condition. Documents must match both the main query
	// and this filter. Applied before scoring for better performance.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Status filtering: `"status:published"`
	// - Date ranges: `"created_at:>2023-01-01"`
	// - Category filtering: `"category:technology AND language:en"`
	FilterQuery json.RawMessage `json:"filter_query,omitempty,omitzero"`

	// FullTextSearch Bleve query for full-text search. Supports all Bleve query types.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Examples:
	// - Simple: `{"query": "computer"}`
	// - Field-specific: `{"query": "body:computer"}`
	// - Boolean: `{"query": "artificial AND intelligence"}`
	// - Range: `{"query": "year:>2020"}`
	// - Phrase: `{"query": "\"exact phrase\""}`
	FullTextSearch json.RawMessage `json:"full_text_search,omitempty,omitzero"`

	// GraphSearches Declarative graph queries to execute after full-text/vector searches.
	// Results can reference search results using node selectors like $full_text_results.
	GraphSearches map[string]GraphQuery `json:"graph_searches,omitempty,omitzero"`

	// Indexes List of vector index names to use for semantic search. Required when using semantic_search.
	// Multiple indexes can be specified, and their results will be merged using RRF.
	Indexes []string `json:"indexes,omitempty,omitzero"`

	// Join Configuration for joining data from another table.
	// Supports inner, left, and right joins with automatic strategy selection.
	Join JoinClause `json:"join,omitempty,omitzero"`

	// Limit Maximum number of results to return. For semantic_search, this is the topk parameter.
	// Default varies by query type (typically 10).
	Limit int `json:"limit,omitempty,omitzero"`

	// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
	// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
	// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
	// failover: Use full_text_search if embedding generation fails
	MergeStrategy MergeStrategy `json:"merge_strategy,omitempty,omitzero"`

	// Offset Number of results to skip for pagination. Only available for full_text_search queries.
	// Not supported for semantic_search due to vector index limitations.
	Offset int `json:"offset,omitempty,omitzero"`

	// OrderBy Sort order for results. Map of field names to boolean (true = descending, false = ascending).
	// Only applicable for full_text_search queries. Semantic searches are always sorted by similarity score.
	OrderBy map[string]bool `json:"order_by,omitempty,omitzero"`

	// Pruner Configuration for pruning search results based on score quality.
	// Helps filter out low-relevance results in RAG pipelines by detecting
	// score gaps or deviations from top results.
	Pruner Pruner `json:"pruner,omitempty,omitzero"`

	// Reranker A unified configuration for a reranking provider.
	Reranker *RerankerConfig `json:"reranker,omitempty"`

	// SemanticSearch Natural language query for vector similarity search. Results are ranked by semantic similarity
	// to the query and can be combined with full_text_search using Reciprocal Rank Fusion (RRF).
	//
	// The semantic_search string is automatically embedded using the configured embedding model
	// for the specified indexes. Use `embedding_template` for multimodal queries.
	SemanticSearch string `json:"semantic_search,omitempty,omitzero"`

	// Table Name of the table to query. Optional for global queries.
	Table string `json:"table,omitempty,omitzero"`
}

// QueryRequestExpandStrategy Strategy for merging graph results with search results:
// - union: Include nodes from both search and graph results
// - intersection: Only include nodes appearing in both
type QueryRequestExpandStrategy string

// QueryResponses Responses from multiple query operations.
type QueryResponses struct {
	Responses []QueryResult `json:"responses,omitempty,omitzero"`
}

// QueryResult Result of a query operation as an array of results and a count.
type QueryResult struct {
	// Aggregations Aggregation results keyed by the user-defined aggregation names from the request.
	// Contains computed metrics or buckets depending on the aggregation type.
	Aggregations map[string]AggregationResult `json:"aggregations,omitempty,omitzero"`

	// Analyses Analysis results like PCA and t-SNE per index embeddings.
	Analyses map[string]AnalysesResult `json:"analyses,omitempty,omitzero"`

	// Error Error message if the query failed.
	Error string `json:"error,omitempty,omitzero"`

	// GraphResults Results from declarative graph queries.
	GraphResults map[string]GraphQueryResult `json:"graph_results,omitempty,omitzero"`

	// Hits A list of query hits.
	Hits QueryHits `json:"hits"`

	// JoinResult Statistics and metadata about join execution.
	JoinResult JoinResult `json:"join_result,omitempty,omitzero"`

	// Status HTTP status code of the query operation.
	Status int32 `json:"status"`

	// Table Which table this result came from
	Table string `json:"table,omitempty,omitzero"`

	// Took Duration of the query in milliseconds.
	Took time.Duration `json:"took"`
}

// QueryStrategy Strategy for query transformation and retrieval:
// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
type QueryStrategy string

// QueryStringQuery defines model for QueryStringQuery.
type QueryStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Query string `json:"query"`
}

// RAGRequest defines model for RAGRequest.
type RAGRequest struct {
	// Chain Chain of generators with retry/fallback semantics. Mutually exclusive with 'generator'.
	// Each link can specify retry configuration and a condition for trying the next generator.
	// Either 'generator' or 'chain' must be provided.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Eval Configuration for inline evaluation of query results.
	// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
	Eval EvalConfig `json:"eval,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// Prompt Optional custom user prompt template for the LLM. If not provided, a default prompt is used.
	// The prompt can reference the following variables:
	// - {{documents}}: Array of retrieved documents with id and fields
	// - {{semantic_search}}: The user's semantic search query (if provided)
	// You can use Handlebars template syntax to customize the prompt, including loops and conditionals.
	// To generate a comma-separated list of document IDs, use: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	Prompt string `json:"prompt,omitempty,omitzero"`

	// Queries Array of retrieval queries to execute. Each query must specify a table and can specify its own limit and document_renderer.
	// Results from all queries are concatenated together (respecting each query's limit).
	// For single table: [{"table": "papers", "semantic_search": "...", "limit": 10}]
	// For broadcast: [{"table": "images", "limit": 5, ...}, {"table": "products", "limit": 5, ...}]
	// For mixed: [{"table": "papers", "semantic_search": "...", "limit": 10}, {"table": "books", "full_text_search": {...}, "limit": 5}]
	Queries []QueryRequest `json:"queries"`

	// SystemPrompt Optional system prompt to guide the summarization
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// RAGResult RAG result with individual query results and generation/evaluation outcome
type RAGResult struct {
	// EvalResult Complete evaluation result
	EvalResult EvalResult `json:"eval_result,omitempty,omitzero"`

	// GenerateResult Result of a generate operation. Formatted as markdown by default with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
	GenerateResult GenerateResult `json:"generate_result,omitempty,omitzero"`

	// QueryResults Results from each query. Check each result's status and error fields for failures.
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`
}

// RegexpQuery defines model for RegexpQuery.
type RegexpQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Regexp string `json:"regexp"`
}

// RerankerConfig defines model for RerankerConfig.
type RerankerConfig struct {
	// Field Field name to extract from documents for reranking.
	Field string `json:"field,omitempty,omitzero"`

	// Provider The reranking provider to use.
	Provider RerankerProvider `json:"provider"`

	// Template Handlebars template to render document text for reranking.
	Template string `json:"template,omitempty,omitzero"`
	union    json.RawMessage
}

// RerankerProvider The reranking provider to use.
type RerankerProvider string

// ResourceType Type of the resource, e.g., table, user, or global ('*').
type ResourceType string

// RestoreRequest defines model for RestoreRequest.
type RestoreRequest = BackupRequest

// RetryConfig Retry configuration for generator calls
type RetryConfig struct {
	// BackoffMultiplier Multiplier for exponential backoff
	BackoffMultiplier float32 `json:"backoff_multiplier,omitempty,omitzero"`

	// InitialBackoffMs Initial backoff delay in milliseconds
	InitialBackoffMs int `json:"initial_backoff_ms,omitempty,omitzero"`

	// MaxAttempts Maximum number of retry attempts
	MaxAttempts int `json:"max_attempts,omitempty,omitzero"`

	// MaxBackoffMs Maximum backoff delay in milliseconds
	MaxBackoffMs int `json:"max_backoff_ms,omitempty,omitzero"`
}

// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
type RouteType string

// ScanKeysRequest Request to scan keys in a table within a key range.
// If no range is specified, scans all keys in the table.
type ScanKeysRequest struct {
	// ExclusiveTo If true, exclude keys matching 'to' from the results.
	// Default: false (inclusive upper bound).
	ExclusiveTo bool `json:"exclusive_to,omitempty,omitzero"`

	// Fields List of fields to include in each result. If not specified,
	// only returns the key. Supports:
	// - Simple fields: "title", "author"
	// - Nested paths: "user.address.city"
	// - Wildcards: "_chunks.*"
	// - Exclusions: "-_chunks.*._embedding"
	// - Special fields: "_embeddings", "_summaries", "_chunks"
	Fields []string `json:"fields,omitempty,omitzero"`

	// FilterQuery Bleve query to filter documents. Only documents matching this query
	// are included in results. Uses the sear library for efficient per-document
	// matching without requiring a full index.
	//
	// Examples:
	// - Status filtering: `{"query": "status:published"}`
	// - Date ranges: `{"query": "created_at:>2023-01-01"}`
	// - Field matching: `{"query": "category:technology"}`
	FilterQuery json.RawMessage `json:"filter_query,omitempty,omitzero"`

	// From Start of the key range to scan (exclusive by default).
	// Can be a full key or a prefix. If not specified, starts from
	// the beginning of the table.
	From string `json:"from,omitempty,omitzero"`

	// InclusiveFrom If true, include keys matching 'from' in the results.
	// Default: false (exclusive lower bound for pagination).
	InclusiveFrom bool `json:"inclusive_from,omitempty,omitzero"`

	// Limit Maximum number of results to return. If not specified, returns all
	// matching keys in the range. Useful for pagination or sampling.
	Limit int `json:"limit,omitempty,omitzero"`

	// To End of the key range to scan (inclusive by default).
	// Can be a full key or a prefix. If not specified, scans to
	// the end of the table.
	To string `json:"to,omitempty,omitzero"`
}

// SemanticQueryMode Mode for semantic query generation:
// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
type SemanticQueryMode string

// SerperSearchConfig defines model for SerperSearchConfig.
type SerperSearchConfig struct {
	// ApiKey Serper API key (or set SERPER_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// SearchType Type of search to perform
	SearchType SerperSearchConfigSearchType `json:"search_type,omitempty,omitzero"`

	// TimePeriod Time period filter: d=day, w=week, m=month, y=year
	TimePeriod SerperSearchConfigTimePeriod `json:"time_period,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// SerperSearchConfigSearchType Type of search to perform
type SerperSearchConfigSearchType string

// SerperSearchConfigTimePeriod Time period filter: d=day, w=week, m=month, y=year
type SerperSearchConfigTimePeriod string

// ShardConfig defines model for ShardConfig.
type ShardConfig struct {
	ByteRange ByteRange `json:"byte_range"`
}

// SignificanceAlgorithm Algorithm for computing term significance:
// - jlh: JLH algorithm (default)
// - mutual_information: Mutual Information
// - chi_squared: Chi-squared test
// - percentage: Simple percentage comparison
type SignificanceAlgorithm string

// StorageStatus defines model for StorageStatus.
type StorageStatus struct {
	// DiskUsage Disk usage in bytes.
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Empty Whether the table has received data.
	Empty bool `json:"empty,omitempty,omitzero"`
}

// SuccessMessage defines model for SuccessMessage.
type SuccessMessage struct {
	Message string `json:"message,omitempty,omitzero"`
}

// SyncLevel Synchronization level for batch operations:
// - "propose": Wait for Raft proposal acceptance (fastest, default)
// - "write": Wait for Pebble KV write
// - "full_text": Wait for full-text index WAL write
// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
type SyncLevel string

// Table defines model for Table.
type Table struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema            `json:"schema,omitempty,omitzero"`
	Shards map[string]ShardConfig `json:"shards"`
}

// TableBackupStatus defines model for TableBackupStatus.
type TableBackupStatus struct {
	// Error Error message if backup failed
	Error string `json:"error,omitempty,omitzero"`

	// Name Table name
	Name string `json:"name"`

	// Status Backup status for this table
	Status TableBackupStatusStatus `json:"status"`
}

// TableBackupStatusStatus Backup status for this table
type TableBackupStatusStatus string

// TableRestoreStatus defines model for TableRestoreStatus.
type TableRestoreStatus struct {
	// Error Error message if restore failed
	Error string `json:"error,omitempty,omitzero"`

	// Name Table name
	Name string `json:"name"`

	// Status Restore status for this table
	Status TableRestoreStatusStatus `json:"status"`
}

// TableRestoreStatusStatus Restore status for this table
type TableRestoreStatusStatus string

// TableSchema Schema definition for a table with multiple document types
type TableSchema struct {
	// DefaultType Default type to use from the document_types.
	DefaultType string `json:"default_type,omitempty,omitzero"`

	// DocumentSchemas A map of type names to their document json schemas.
	DocumentSchemas map[string]DocumentSchema `json:"document_schemas,omitempty,omitzero"`

	// DynamicTemplates Rules for mapping dynamically detected fields. When a document contains fields
	// that don't have explicit mappings and dynamic mapping is enabled, templates are
	// evaluated in order to determine how those fields should be indexed.
	DynamicTemplates []DynamicTemplate `json:"dynamic_templates,omitempty,omitzero"`

	// EnforceTypes Whether to enforce that documents must match one of the provided document types.
	// If false, documents not matching any type will be accepted but not indexed.
	EnforceTypes bool `json:"enforce_types,omitempty,omitzero"`

	// TtlDuration The duration after which documents should expire, based on the ttl_field timestamp (optional).
	// Uses Go duration format (e.g., '24h', '7d', '168h').
	TtlDuration string `json:"ttl_duration,omitempty,omitzero"`

	// TtlField The field containing the timestamp for TTL expiration (optional).
	// Defaults to "_timestamp" if ttl_duration is specified but ttl_field is not.
	TtlField string `json:"ttl_field,omitempty,omitzero"`

	// Version Version of the schema. Used for migrations.
	Version uint32 `json:"version,omitempty,omitzero"`
}

// TableStatistics Statistics about a table used for query planning.
type TableStatistics struct {
	// FieldStats Per-field statistics for query optimization.
	FieldStats map[string]FieldStatistics `json:"field_stats,omitempty,omitzero"`

	// LastUpdated When these statistics were last computed.
	LastUpdated time.Time `json:"last_updated,omitempty,omitzero"`

	// RowCount Approximate number of rows in the table.
	RowCount int64 `json:"row_count,omitempty,omitzero"`

	// SizeBytes Approximate size of the table in bytes.
	SizeBytes int64 `json:"size_bytes,omitempty,omitzero"`
}

// TableStatus defines model for TableStatus.
type TableStatus struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema        TableSchema            `json:"schema,omitempty,omitzero"`
	Shards        map[string]ShardConfig `json:"shards"`
	StorageStatus StorageStatus          `json:"storage_status"`
}

// TavilySearchConfig defines model for TavilySearchConfig.
type TavilySearchConfig struct {
	// ApiKey Tavily API key (or set TAVILY_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// ExcludeDomains Exclude results from these domains
	ExcludeDomains []string `json:"exclude_domains,omitempty,omitzero"`

	// IncludeAnswer Include AI-generated answer summary
	IncludeAnswer bool `json:"include_answer,omitempty,omitzero"`

	// IncludeDomains Only include results from these domains
	IncludeDomains []string `json:"include_domains,omitempty,omitzero"`

	// IncludeRawContent Include raw HTML content of pages
	IncludeRawContent bool `json:"include_raw_content,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// SearchDepth Search depth:
	// - basic: Fast search with standard results
	// - advanced: Deeper search with more comprehensive results
	SearchDepth TavilySearchConfigSearchDepth `json:"search_depth,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// TavilySearchConfigSearchDepth Search depth:
// - basic: Fast search with standard results
// - advanced: Deeper search with more comprehensive results
type TavilySearchConfigSearchDepth string

// TemplateFieldMapping Field mapping to apply when a dynamic template matches
type TemplateFieldMapping struct {
	// Analyzer Analyzer name (e.g., "standard", "keyword", "en", "html_analyzer").
	// Used for text fields to control tokenization and normalization.
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// DocValues Whether to enable doc values for sorting/faceting
	DocValues bool `json:"doc_values,omitempty,omitzero"`

	// IncludeInAll Whether to include in the _all field for cross-field search
	IncludeInAll bool `json:"include_in_all,omitempty,omitzero"`

	// Index Whether to index the field (default true)
	Index bool `json:"index,omitempty,omitzero"`

	// Store Whether to store the field value (default false)
	Store bool `json:"store,omitempty,omitzero"`

	// Type Field type annotations for schema fields
	Type SchemasAntflyType `json:"type,omitempty,omitzero"`
}

// TermQuery defines model for TermQuery.
type TermQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
	Term  string `json:"term"`
}

// TermRangeQuery defines model for TermRangeQuery.
type TermRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost  `json:"boost,omitzero"`
	Field        string `json:"field,omitempty,omitzero"`
	InclusiveMax bool   `json:"inclusive_max,omitzero"`
	InclusiveMin bool   `json:"inclusive_min,omitzero"`
	Max          string `json:"max,omitzero"`
	Min          string `json:"min,omitzero"`
}

// TermiteChunkerConfig defines model for TermiteChunkerConfig.
type TermiteChunkerConfig struct {
	// ApiUrl The URL of the Termite API endpoint (e.g., 'http://localhost:8080'). Can also be set via ANTFLY_TERMITE_URL environment variable.
	ApiUrl string `json:"api_url,omitempty,omitzero"`

	// MaxChunks Maximum number of chunks to generate per document.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// Model The chunking model to use. Either 'fixed' for simple token-based chunking, or a model name from models/chunkers/{name}/.
	Model string `json:"model"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries. Only used by fixed-size chunkers.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs). Only used by fixed-size chunkers.
	Separator string `json:"separator,omitempty,omitzero"`

	// TargetTokens Target number of tokens per chunk.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`

	// Threshold Minimum confidence threshold for separator detection (0.0-1.0). Only used by ONNX models.
	Threshold float32 `json:"threshold,omitempty,omitzero"`
}

// TermiteEmbedderConfig Configuration for the Termite embedding provider.
//
// Termite is Antfly's built-in ML service for local embeddings using ONNX models.
// It provides embedding generation with multi-tier caching (memory + persistent).
//
// **Features:**
// - Local ONNX-based embedding generation
// - L1 memory cache with configurable TTL
// - L2 persistent Pebble database cache
// - Singleflight deduplication for concurrent identical requests
//
// **Example Models:** bge-base-en-v1.5 (768 dims), all-MiniLM-L6-v2 (384 dims)
//
// Models are loaded from the `models/embedders/{name}/` directory.
type TermiteEmbedderConfig struct {
	// ApiUrl The URL of the Termite API endpoint. Can also be set via ANTFLY_TERMITE_URL environment variable.
	ApiUrl string `json:"api_url,omitempty,omitzero"`

	// Model The embedding model name (maps to models/embedders/{name}/ directory).
	Model string `json:"model"`
}

// TermiteGeneratorConfig Configuration for the Termite generative AI provider.
//
// Termite is Antfly's built-in ML service for local LLM inference using
// ONNX Runtime GenAI models. It provides text generation with automatic
// model discovery from the `models/generators/` directory.
//
// **Example Models:** onnxruntime/Gemma-3-ONNX (from HuggingFace)
//
// **Features:**
// - Local inference with no external API dependencies
// - ONNX Runtime GenAI for efficient CPU/GPU execution
// - Auto-discovery of models from `models/generators/` directory
// - OpenAI-compatible chat format
type TermiteGeneratorConfig struct {
	// ApiUrl The URL of the Termite API endpoint.
	ApiUrl string `json:"api_url,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the generator model (maps to models/generators/{name}/ directory).
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// TermiteRerankerConfig Configuration for the Termite reranking provider.
type TermiteRerankerConfig struct {
	// Model The name of the reranking model (e.g., cross-encoder model name).
	Model string `json:"model"`

	// Url The URL of the Termite API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// Transform In-place document transformation using MongoDB-style operators. Transforms are applied atomically
// at the storage layer, eliminating read-modify-write races.
//
// **Important:** Transform results are NOT validated against the table schema. This improves performance
// but means it's possible to create invalid documents. Use with care and ensure your operations maintain
// schema compliance.
type Transform struct {
	// Key Document key (must be a string, not an object like inserts)
	Key string `json:"key"`

	// Operations List of operations to apply in sequence
	Operations []TransformOp `json:"operations"`

	// Upsert If true, create document if it doesn't exist (like MongoDB upsert)
	Upsert bool `json:"upsert,omitempty,omitzero"`
}

// TransformOp defines model for TransformOp.
type TransformOp struct {
	// Op MongoDB-style update operator
	Op TransformOpType `json:"op"`

	// Path JSONPath to field (e.g., "$.user.name", "$.tags", or "user.name")
	Path string `json:"path"`

	// Value Value for operation (not required for $unset, $currentDate). Type depends on operator (number for $inc/$mul, any for $set, etc.)
	Value interface{} `json:"value,omitempty,omitzero"`
}

// TransformOpType MongoDB-style update operator
type TransformOpType string

// TraversalResult A single result from graph traversal
type TraversalResult struct {
	// Depth Distance from start node (0 = start node)
	Depth int `json:"depth"`

	// Document Document data (if loaded)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Key Base64-encoded document key
	Key []byte `json:"key"`

	// Path Sequence of keys from start to this node (if include_paths=true)
	Path [][]byte `json:"path,omitempty,omitzero"`

	// PathEdges Sequence of edges from start to this node (if include_paths=true)
	PathEdges []Edge `json:"path_edges,omitempty,omitzero"`

	// TotalWeight Product of edge weights along the path
	TotalWeight float64 `json:"total_weight,omitempty,omitzero"`
}

// TraversalRules Rules for graph traversal
type TraversalRules struct {
	// DeduplicateNodes Visit each node only once
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter edges by type (empty = all types)
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information in results
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth (0 = unlimited)
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum results to return (0 = unlimited)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight filter
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight filter
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`
}

// TraverseResponse defines model for TraverseResponse.
type TraverseResponse struct {
	// Count Total number of results
	Count   int               `json:"count,omitempty,omitzero"`
	Results []TraversalResult `json:"results,omitempty,omitzero"`
}

// UpdatePasswordRequest defines model for UpdatePasswordRequest.
type UpdatePasswordRequest struct {
	NewPassword string `json:"new_password"`
}

// User defines model for User.
type User struct {
	// PasswordHash Base64 encoded password hash. Exposing this is a security risk.
	PasswordHash []byte `json:"password_hash"`
	Username     string `json:"username"`
}

// VertexEmbedderConfig Configuration for Google Cloud Vertex AI embedding models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication. Requires IAM role `roles/aiplatform.user`.
//
// **Example Models:** gemini-embedding-001 (default, 3072 dims), multimodalembedding (images/audio/video)
//
// **Docs:** https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings
type VertexEmbedderConfig struct {
	// CredentialsPath Path to service account JSON key file. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Dimension The dimension of the embedding vector (768, 1536, or 3072 for gemini-embedding-001; 128-1408 for multimodalembedding).
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the Vertex AI embedding model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`
}

// VertexGeneratorConfig Configuration for Google Cloud Vertex AI generative models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication. In GCP environments
// (Cloud Run, GKE, Compute Engine) this is automatic. For local dev, run
// `gcloud auth application-default login`. Requires IAM role `roles/aiplatform.user`.
//
// **Example Models:** gemini-2.5-flash (default), gemini-2.5-pro, gemini-3.0-pro
//
// **Docs:** https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models
type VertexGeneratorConfig struct {
	// CredentialsPath Path to service account JSON key file. Sets GOOGLE_APPLICATION_CREDENTIALS environment variable. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Vertex AI model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// VertexRerankerConfig Configuration for the Google Vertex AI Ranking API.
//
// Uses Application Default Credentials (ADC) or explicit credentials path.
//
// **Prerequisites:**
// - Enable Discovery Engine API: `gcloud services enable discoveryengine.googleapis.com`
// - Grant IAM role: `roles/discoveryengine.admin` (includes `discoveryengine.rankingConfigs.rank` permission)
//
// **Models:** semantic-ranker-default@latest (default), semantic-ranker-fast-004
//
// **Docs:** https://cloud.google.com/generative-ai-app-builder/docs/ranking
//
// **IAM:** https://cloud.google.com/generative-ai-app-builder/docs/access-control
type VertexRerankerConfig struct {
	// CredentialsPath Path to service account JSON file. Falls back to GOOGLE_APPLICATION_CREDENTIALS environment variable.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Model The ranking model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Falls back to GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// TopN Maximum number of records to return. If not specified, returns all documents with scores.
	TopN int `json:"top_n,omitempty,omitzero"`
}

// WebSearchConfig A unified configuration for web search providers.
//
// Each provider has specific configuration requirements. Use the appropriate
// provider-specific config or set common options at the top level.
//
// **Environment Variables (fallbacks):**
// - GOOGLE_CSE_API_KEY, GOOGLE_CSE_ID
// - BING_SEARCH_API_KEY
// - SERPER_API_KEY
// - TAVILY_API_KEY
// - BRAVE_API_KEY
type WebSearchConfig struct {
	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// WebSearchProvider The web search provider to use.
//
// - **google**: Google Custom Search API (requires CSE setup)
// - **bing**: Microsoft Bing Web Search API
// - **serper**: Serper.dev Google Search API (simpler setup)
// - **tavily**: Tavily AI Search API (optimized for RAG)
// - **brave**: Brave Search API
// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
type WebSearchProvider string

// WildcardQuery defines model for WildcardQuery.
type WildcardQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Field    string `json:"field,omitempty,omitzero"`
	Wildcard string `json:"wildcard"`
}

// SchemasAntflyType Field type annotations for schema fields
type SchemasAntflyType string

// SchemasChatAgentResult Result from the chat agent. Contains the assistant's response,
// any pending clarifications, applied filters, and conversation state.
type SchemasChatAgentResult struct {
	// Answer Final answer text (if available)
	Answer string `json:"answer,omitempty,omitzero"`

	// AnswerConfidence Confidence in the answer
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// AppliedFilters Filters that have been applied in this conversation
	AppliedFilters []FilterSpec `json:"applied_filters,omitempty,omitzero"`

	// Messages Updated conversation history including the assistant's response
	Messages []ChatMessage `json:"messages"`

	// PendingClarification A request for clarification from the user
	PendingClarification ClarificationRequest `json:"pending_clarification,omitempty,omitzero"`

	// QueryResults Search results from executed queries
	QueryResults []map[string]interface{} `json:"query_results,omitempty,omitzero"`

	// ToolCallsMade Number of tool calls made in this turn
	ToolCallsMade int `json:"tool_calls_made,omitempty,omitzero"`
}

// UserNamePathParameter defines model for UserNamePathParameter.
type UserNamePathParameter = string

// BadRequest defines model for BadRequest.
type BadRequest = Error

// InternalServerError defines model for InternalServerError.
type InternalServerError = Error

// NotFound defines model for NotFound.
type NotFound = Error

// ListBackupsParams defines parameters for ListBackups.
type ListBackupsParams struct {
	// Location Storage location to search for backups.
	// - Local filesystem: `file:///path/to/backup`
	// - Amazon S3: `s3://bucket-name/path/to/backup`
	Location string `form:"location" json:"location"`
}

// ListTablesParams defines parameters for ListTables.
type ListTablesParams struct {
	// Prefix Filter tables by name prefix (e.g., "prod_")
	Prefix string `form:"prefix,omitempty" json:"prefix,omitempty,omitzero"`

	// Pattern Filter tables by regex pattern (e.g., "^prod_.*_v[0-9]+$")
	Pattern string `form:"pattern,omitempty" json:"pattern,omitempty,omitzero"`
}

// LookupKeyParams defines parameters for LookupKey.
type LookupKeyParams struct {
	// Fields Comma-separated list of fields to include in the response.
	// If not specified, returns the full document. Supports:
	// - Simple fields: "title,author"
	// - Nested paths: "user.address.city"
	// - Wildcards: "_chunks.*"
	// - Exclusions: "-_chunks.*._embedding"
	// - Special fields: "_embeddings,_summaries,_chunks"
	Fields string `form:"fields,omitempty" json:"fields,omitempty,omitzero"`
}

// RemovePermissionFromUserParams defines parameters for RemovePermissionFromUser.
type RemovePermissionFromUserParams struct {
	// Resource The name of the resource for the permission to be removed.
	Resource string `form:"resource" json:"resource"`

	// ResourceType The type of the resource for the permission to be removed.
	ResourceType ResourceType `form:"resourceType" json:"resourceType"`
}

// AnswerAgentJSONRequestBody defines body for AnswerAgent for application/json ContentType.
type AnswerAgentJSONRequestBody = AnswerAgentRequest

// ChatAgentJSONRequestBody defines body for ChatAgent for application/json ContentType.
type ChatAgentJSONRequestBody = ChatAgentRequest

// QueryBuilderAgentJSONRequestBody defines body for QueryBuilderAgent for application/json ContentType.
type QueryBuilderAgentJSONRequestBody = QueryBuilderRequest

// BackupJSONRequestBody defines body for Backup for application/json ContentType.
type BackupJSONRequestBody = ClusterBackupRequest

// EvaluateJSONRequestBody defines body for Evaluate for application/json ContentType.
type EvaluateJSONRequestBody = EvalRequest

// GlobalQueryJSONRequestBody defines body for GlobalQuery for application/json ContentType.
type GlobalQueryJSONRequestBody = QueryRequest

// RagQueryJSONRequestBody defines body for RagQuery for application/json ContentType.
type RagQueryJSONRequestBody = RAGRequest

// RestoreJSONRequestBody defines body for Restore for application/json ContentType.
type RestoreJSONRequestBody = ClusterRestoreRequest

// CreateTableJSONRequestBody defines body for CreateTable for application/json ContentType.
type CreateTableJSONRequestBody = CreateTableRequest

// BackupTableJSONRequestBody defines body for BackupTable for application/json ContentType.
type BackupTableJSONRequestBody = BackupRequest

// BatchWriteJSONRequestBody defines body for BatchWrite for application/json ContentType.
type BatchWriteJSONRequestBody = BatchRequest

// CreateIndexJSONRequestBody defines body for CreateIndex for application/json ContentType.
type CreateIndexJSONRequestBody = IndexConfig

// ScanKeysJSONRequestBody defines body for ScanKeys for application/json ContentType.
type ScanKeysJSONRequestBody = ScanKeysRequest

// LinearMergeJSONRequestBody defines body for LinearMerge for application/json ContentType.
type LinearMergeJSONRequestBody = LinearMergeRequest

// QueryTableJSONRequestBody defines body for QueryTable for application/json ContentType.
type QueryTableJSONRequestBody = QueryRequest

// TableRagQueryJSONRequestBody defines body for TableRagQuery for application/json ContentType.
type TableRagQueryJSONRequestBody = RAGRequest

// RestoreTableJSONRequestBody defines body for RestoreTable for application/json ContentType.
type RestoreTableJSONRequestBody = RestoreRequest

// UpdateSchemaJSONRequestBody defines body for UpdateSchema for application/json ContentType.
type UpdateSchemaJSONRequestBody = TableSchema

// CreateUserJSONRequestBody defines body for CreateUser for application/json ContentType.
type CreateUserJSONRequestBody = CreateUserRequest

// UpdateUserPasswordJSONRequestBody defines body for UpdateUserPassword for application/json ContentType.
type UpdateUserPasswordJSONRequestBody = UpdatePasswordRequest

// AddPermissionToUserJSONRequestBody defines body for AddPermissionToUser for application/json ContentType.
type AddPermissionToUserJSONRequestBody = Permission

// Getter for additional properties for ClusterStatus. Returns the specified
// element and whether it was found
func (a ClusterStatus) Get(fieldName string) (value interface{}, found bool) {
	if a.AdditionalProperties != nil {
		value, found = a.AdditionalProperties[fieldName]
	}
	return
}

// Setter for additional properties for ClusterStatus
func (a *ClusterStatus) Set(fieldName string, value interface{}) {
	if a.AdditionalProperties == nil {
		a.AdditionalProperties = make(map[string]interface{})
	}
	a.AdditionalProperties[fieldName] = value
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a *ClusterStatus) UnmarshalJSON(b []byte) error {
	object := make(map[string]json.RawMessage)
	err := json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["auth_enabled"]; found {
		err = json.Unmarshal(raw, &a.AuthEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'auth_enabled': %w", err)
		}
		delete(object, "auth_enabled")
	}

	if raw, found := object["health"]; found {
		err = json.Unmarshal(raw, &a.Health)
		if err != nil {
			return fmt.Errorf("error reading 'health': %w", err)
		}
		delete(object, "health")
	}

	if raw, found := object["message"]; found {
		err = json.Unmarshal(raw, &a.Message)
		if err != nil {
			return fmt.Errorf("error reading 'message': %w", err)
		}
		delete(object, "message")
	}

	if len(object) != 0 {
		a.AdditionalProperties = make(map[string]interface{})
		for fieldName, fieldBuf := range object {
			var fieldVal interface{}
			err := json.Unmarshal(fieldBuf, &fieldVal)
			if err != nil {
				return fmt.Errorf("error unmarshaling field %s: %w", fieldName, err)
			}
			a.AdditionalProperties[fieldName] = fieldVal
		}
	}
	return nil
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a ClusterStatus) MarshalJSON() ([]byte, error) {
	var err error
	object := make(map[string]json.RawMessage)

	object["auth_enabled"], err = json.Marshal(a.AuthEnabled)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'auth_enabled': %w", err)
	}

	object["health"], err = json.Marshal(a.Health)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'health': %w", err)
	}

	object["message"], err = json.Marshal(a.Message)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'message': %w", err)
	}

	for fieldName, field := range a.AdditionalProperties {
		object[fieldName], err = json.Marshal(field)
		if err != nil {
			return nil, fmt.Errorf("error marshaling '%s': %w", fieldName, err)
		}
	}
	return json.Marshal(object)
}

// AsTermiteChunkerConfig returns the union data inside the ChunkerConfig as a TermiteChunkerConfig
func (t ChunkerConfig) AsTermiteChunkerConfig() (TermiteChunkerConfig, error) {
	var body TermiteChunkerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteChunkerConfig overwrites any union data inside the ChunkerConfig as the provided TermiteChunkerConfig
func (t *ChunkerConfig) FromTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteChunkerConfig performs a merge with any union data inside the ChunkerConfig, using the provided TermiteChunkerConfig
func (t *ChunkerConfig) MergeTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAntflyChunkerConfig returns the union data inside the ChunkerConfig as a AntflyChunkerConfig
func (t ChunkerConfig) AsAntflyChunkerConfig() (AntflyChunkerConfig, error) {
	var body AntflyChunkerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAntflyChunkerConfig overwrites any union data inside the ChunkerConfig as the provided AntflyChunkerConfig
func (t *ChunkerConfig) FromAntflyChunkerConfig(v AntflyChunkerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAntflyChunkerConfig performs a merge with any union data inside the ChunkerConfig, using the provided AntflyChunkerConfig
func (t *ChunkerConfig) MergeAntflyChunkerConfig(v AntflyChunkerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t ChunkerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["full_text_index"], err = json.Marshal(t.FullTextIndex)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'full_text_index': %w", err)
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	object["store_chunks"], err = json.Marshal(t.StoreChunks)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'store_chunks': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *ChunkerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["full_text_index"]; found {
		err = json.Unmarshal(raw, &t.FullTextIndex)
		if err != nil {
			return fmt.Errorf("error reading 'full_text_index': %w", err)
		}
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	if raw, found := object["store_chunks"]; found {
		err = json.Unmarshal(raw, &t.StoreChunks)
		if err != nil {
			return fmt.Errorf("error reading 'store_chunks': %w", err)
		}
	}

	return err
}

// AsGoogleEmbedderConfig returns the union data inside the EmbedderConfig as a GoogleEmbedderConfig
func (t EmbedderConfig) AsGoogleEmbedderConfig() (GoogleEmbedderConfig, error) {
	var body GoogleEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided GoogleEmbedderConfig
func (t *EmbedderConfig) FromGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided GoogleEmbedderConfig
func (t *EmbedderConfig) MergeGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexEmbedderConfig returns the union data inside the EmbedderConfig as a VertexEmbedderConfig
func (t EmbedderConfig) AsVertexEmbedderConfig() (VertexEmbedderConfig, error) {
	var body VertexEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided VertexEmbedderConfig
func (t *EmbedderConfig) FromVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided VertexEmbedderConfig
func (t *EmbedderConfig) MergeVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaEmbedderConfig returns the union data inside the EmbedderConfig as a OllamaEmbedderConfig
func (t EmbedderConfig) AsOllamaEmbedderConfig() (OllamaEmbedderConfig, error) {
	var body OllamaEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OllamaEmbedderConfig
func (t *EmbedderConfig) FromOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OllamaEmbedderConfig
func (t *EmbedderConfig) MergeOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIEmbedderConfig returns the union data inside the EmbedderConfig as a OpenAIEmbedderConfig
func (t EmbedderConfig) AsOpenAIEmbedderConfig() (OpenAIEmbedderConfig, error) {
	var body OpenAIEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) FromOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) MergeOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenRouterEmbedderConfig returns the union data inside the EmbedderConfig as a OpenRouterEmbedderConfig
func (t EmbedderConfig) AsOpenRouterEmbedderConfig() (OpenRouterEmbedderConfig, error) {
	var body OpenRouterEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenRouterEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OpenRouterEmbedderConfig
func (t *EmbedderConfig) FromOpenRouterEmbedderConfig(v OpenRouterEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenRouterEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OpenRouterEmbedderConfig
func (t *EmbedderConfig) MergeOpenRouterEmbedderConfig(v OpenRouterEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockEmbedderConfig returns the union data inside the EmbedderConfig as a BedrockEmbedderConfig
func (t EmbedderConfig) AsBedrockEmbedderConfig() (BedrockEmbedderConfig, error) {
	var body BedrockEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided BedrockEmbedderConfig
func (t *EmbedderConfig) FromBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided BedrockEmbedderConfig
func (t *EmbedderConfig) MergeBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereEmbedderConfig returns the union data inside the EmbedderConfig as a CohereEmbedderConfig
func (t EmbedderConfig) AsCohereEmbedderConfig() (CohereEmbedderConfig, error) {
	var body CohereEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided CohereEmbedderConfig
func (t *EmbedderConfig) FromCohereEmbedderConfig(v CohereEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided CohereEmbedderConfig
func (t *EmbedderConfig) MergeCohereEmbedderConfig(v CohereEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermiteEmbedderConfig returns the union data inside the EmbedderConfig as a TermiteEmbedderConfig
func (t EmbedderConfig) AsTermiteEmbedderConfig() (TermiteEmbedderConfig, error) {
	var body TermiteEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided TermiteEmbedderConfig
func (t *EmbedderConfig) FromTermiteEmbedderConfig(v TermiteEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided TermiteEmbedderConfig
func (t *EmbedderConfig) MergeTermiteEmbedderConfig(v TermiteEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t EmbedderConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *EmbedderConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsFuzziness0 returns the union data inside the Fuzziness as a Fuzziness0
func (t Fuzziness) AsFuzziness0() (Fuzziness0, error) {
	var body Fuzziness0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness0 overwrites any union data inside the Fuzziness as the provided Fuzziness0
func (t *Fuzziness) FromFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness0 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness0
func (t *Fuzziness) MergeFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzziness1 returns the union data inside the Fuzziness as a Fuzziness1
func (t Fuzziness) AsFuzziness1() (Fuzziness1, error) {
	var body Fuzziness1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness1 overwrites any union data inside the Fuzziness as the provided Fuzziness1
func (t *Fuzziness) FromFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness1 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness1
func (t *Fuzziness) MergeFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Fuzziness) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Fuzziness) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsGoogleGeneratorConfig returns the union data inside the GeneratorConfig as a GoogleGeneratorConfig
func (t GeneratorConfig) AsGoogleGeneratorConfig() (GoogleGeneratorConfig, error) {
	var body GoogleGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided GoogleGeneratorConfig
func (t *GeneratorConfig) FromGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided GoogleGeneratorConfig
func (t *GeneratorConfig) MergeGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexGeneratorConfig returns the union data inside the GeneratorConfig as a VertexGeneratorConfig
func (t GeneratorConfig) AsVertexGeneratorConfig() (VertexGeneratorConfig, error) {
	var body VertexGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided VertexGeneratorConfig
func (t *GeneratorConfig) FromVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided VertexGeneratorConfig
func (t *GeneratorConfig) MergeVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaGeneratorConfig returns the union data inside the GeneratorConfig as a OllamaGeneratorConfig
func (t GeneratorConfig) AsOllamaGeneratorConfig() (OllamaGeneratorConfig, error) {
	var body OllamaGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OllamaGeneratorConfig
func (t *GeneratorConfig) FromOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OllamaGeneratorConfig
func (t *GeneratorConfig) MergeOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermiteGeneratorConfig returns the union data inside the GeneratorConfig as a TermiteGeneratorConfig
func (t GeneratorConfig) AsTermiteGeneratorConfig() (TermiteGeneratorConfig, error) {
	var body TermiteGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided TermiteGeneratorConfig
func (t *GeneratorConfig) FromTermiteGeneratorConfig(v TermiteGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided TermiteGeneratorConfig
func (t *GeneratorConfig) MergeTermiteGeneratorConfig(v TermiteGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIGeneratorConfig returns the union data inside the GeneratorConfig as a OpenAIGeneratorConfig
func (t GeneratorConfig) AsOpenAIGeneratorConfig() (OpenAIGeneratorConfig, error) {
	var body OpenAIGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) FromOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) MergeOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenRouterGeneratorConfig returns the union data inside the GeneratorConfig as a OpenRouterGeneratorConfig
func (t GeneratorConfig) AsOpenRouterGeneratorConfig() (OpenRouterGeneratorConfig, error) {
	var body OpenRouterGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenRouterGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OpenRouterGeneratorConfig
func (t *GeneratorConfig) FromOpenRouterGeneratorConfig(v OpenRouterGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenRouterGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OpenRouterGeneratorConfig
func (t *GeneratorConfig) MergeOpenRouterGeneratorConfig(v OpenRouterGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockGeneratorConfig returns the union data inside the GeneratorConfig as a BedrockGeneratorConfig
func (t GeneratorConfig) AsBedrockGeneratorConfig() (BedrockGeneratorConfig, error) {
	var body BedrockGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided BedrockGeneratorConfig
func (t *GeneratorConfig) FromBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided BedrockGeneratorConfig
func (t *GeneratorConfig) MergeBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAnthropicGeneratorConfig returns the union data inside the GeneratorConfig as a AnthropicGeneratorConfig
func (t GeneratorConfig) AsAnthropicGeneratorConfig() (AnthropicGeneratorConfig, error) {
	var body AnthropicGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAnthropicGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) FromAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAnthropicGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) MergeAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereGeneratorConfig returns the union data inside the GeneratorConfig as a CohereGeneratorConfig
func (t GeneratorConfig) AsCohereGeneratorConfig() (CohereGeneratorConfig, error) {
	var body CohereGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided CohereGeneratorConfig
func (t *GeneratorConfig) FromCohereGeneratorConfig(v CohereGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided CohereGeneratorConfig
func (t *GeneratorConfig) MergeCohereGeneratorConfig(v CohereGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t GeneratorConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *GeneratorConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Config returns the union data inside the IndexConfig as a BleveIndexV2Config
func (t IndexConfig) AsBleveIndexV2Config() (BleveIndexV2Config, error) {
	var body BleveIndexV2Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Config overwrites any union data inside the IndexConfig as the provided BleveIndexV2Config
func (t *IndexConfig) FromBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Config performs a merge with any union data inside the IndexConfig, using the provided BleveIndexV2Config
func (t *IndexConfig) MergeBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexConfig returns the union data inside the IndexConfig as a EmbeddingIndexConfig
func (t IndexConfig) AsEmbeddingIndexConfig() (EmbeddingIndexConfig, error) {
	var body EmbeddingIndexConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexConfig overwrites any union data inside the IndexConfig as the provided EmbeddingIndexConfig
func (t *IndexConfig) FromEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexConfig performs a merge with any union data inside the IndexConfig, using the provided EmbeddingIndexConfig
func (t *IndexConfig) MergeEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Config returns the union data inside the IndexConfig as a GraphIndexV0Config
func (t IndexConfig) AsGraphIndexV0Config() (GraphIndexV0Config, error) {
	var body GraphIndexV0Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Config overwrites any union data inside the IndexConfig as the provided GraphIndexV0Config
func (t *IndexConfig) FromGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Config performs a merge with any union data inside the IndexConfig, using the provided GraphIndexV0Config
func (t *IndexConfig) MergeGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["description"], err = json.Marshal(t.Description)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'description': %w", err)
	}

	if t.Enrichments != nil {
		object["enrichments"], err = json.Marshal(t.Enrichments)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'enrichments': %w", err)
		}
	}

	object["name"], err = json.Marshal(t.Name)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'name': %w", err)
	}

	object["type"], err = json.Marshal(t.Type)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'type': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *IndexConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["description"]; found {
		err = json.Unmarshal(raw, &t.Description)
		if err != nil {
			return fmt.Errorf("error reading 'description': %w", err)
		}
	}

	if raw, found := object["enrichments"]; found {
		err = json.Unmarshal(raw, &t.Enrichments)
		if err != nil {
			return fmt.Errorf("error reading 'enrichments': %w", err)
		}
	}

	if raw, found := object["name"]; found {
		err = json.Unmarshal(raw, &t.Name)
		if err != nil {
			return fmt.Errorf("error reading 'name': %w", err)
		}
	}

	if raw, found := object["type"]; found {
		err = json.Unmarshal(raw, &t.Type)
		if err != nil {
			return fmt.Errorf("error reading 'type': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Stats returns the union data inside the IndexStats as a BleveIndexV2Stats
func (t IndexStats) AsBleveIndexV2Stats() (BleveIndexV2Stats, error) {
	var body BleveIndexV2Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Stats overwrites any union data inside the IndexStats as the provided BleveIndexV2Stats
func (t *IndexStats) FromBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Stats performs a merge with any union data inside the IndexStats, using the provided BleveIndexV2Stats
func (t *IndexStats) MergeBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexStats returns the union data inside the IndexStats as a EmbeddingIndexStats
func (t IndexStats) AsEmbeddingIndexStats() (EmbeddingIndexStats, error) {
	var body EmbeddingIndexStats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexStats overwrites any union data inside the IndexStats as the provided EmbeddingIndexStats
func (t *IndexStats) FromEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexStats performs a merge with any union data inside the IndexStats, using the provided EmbeddingIndexStats
func (t *IndexStats) MergeEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Stats returns the union data inside the IndexStats as a GraphIndexV0Stats
func (t IndexStats) AsGraphIndexV0Stats() (GraphIndexV0Stats, error) {
	var body GraphIndexV0Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Stats overwrites any union data inside the IndexStats as the provided GraphIndexV0Stats
func (t *IndexStats) FromGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Stats performs a merge with any union data inside the IndexStats, using the provided GraphIndexV0Stats
func (t *IndexStats) MergeGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexStats) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *IndexStats) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsTermQuery returns the union data inside the Query as a TermQuery
func (t Query) AsTermQuery() (TermQuery, error) {
	var body TermQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermQuery overwrites any union data inside the Query as the provided TermQuery
func (t *Query) FromTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermQuery performs a merge with any union data inside the Query, using the provided TermQuery
func (t *Query) MergeTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchQuery returns the union data inside the Query as a MatchQuery
func (t Query) AsMatchQuery() (MatchQuery, error) {
	var body MatchQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchQuery overwrites any union data inside the Query as the provided MatchQuery
func (t *Query) FromMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchQuery performs a merge with any union data inside the Query, using the provided MatchQuery
func (t *Query) MergeMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchPhraseQuery returns the union data inside the Query as a MatchPhraseQuery
func (t Query) AsMatchPhraseQuery() (MatchPhraseQuery, error) {
	var body MatchPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchPhraseQuery overwrites any union data inside the Query as the provided MatchPhraseQuery
func (t *Query) FromMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchPhraseQuery performs a merge with any union data inside the Query, using the provided MatchPhraseQuery
func (t *Query) MergeMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPhraseQuery returns the union data inside the Query as a PhraseQuery
func (t Query) AsPhraseQuery() (PhraseQuery, error) {
	var body PhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPhraseQuery overwrites any union data inside the Query as the provided PhraseQuery
func (t *Query) FromPhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePhraseQuery performs a merge with any union data inside the Query, using the provided PhraseQuery
func (t *Query) MergePhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMultiPhraseQuery returns the union data inside the Query as a MultiPhraseQuery
func (t Query) AsMultiPhraseQuery() (MultiPhraseQuery, error) {
	var body MultiPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMultiPhraseQuery overwrites any union data inside the Query as the provided MultiPhraseQuery
func (t *Query) FromMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMultiPhraseQuery performs a merge with any union data inside the Query, using the provided MultiPhraseQuery
func (t *Query) MergeMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzzyQuery returns the union data inside the Query as a FuzzyQuery
func (t Query) AsFuzzyQuery() (FuzzyQuery, error) {
	var body FuzzyQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzzyQuery overwrites any union data inside the Query as the provided FuzzyQuery
func (t *Query) FromFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzzyQuery performs a merge with any union data inside the Query, using the provided FuzzyQuery
func (t *Query) MergeFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPrefixQuery returns the union data inside the Query as a PrefixQuery
func (t Query) AsPrefixQuery() (PrefixQuery, error) {
	var body PrefixQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPrefixQuery overwrites any union data inside the Query as the provided PrefixQuery
func (t *Query) FromPrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePrefixQuery performs a merge with any union data inside the Query, using the provided PrefixQuery
func (t *Query) MergePrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsRegexpQuery returns the union data inside the Query as a RegexpQuery
func (t Query) AsRegexpQuery() (RegexpQuery, error) {
	var body RegexpQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromRegexpQuery overwrites any union data inside the Query as the provided RegexpQuery
func (t *Query) FromRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeRegexpQuery performs a merge with any union data inside the Query, using the provided RegexpQuery
func (t *Query) MergeRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsWildcardQuery returns the union data inside the Query as a WildcardQuery
func (t Query) AsWildcardQuery() (WildcardQuery, error) {
	var body WildcardQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromWildcardQuery overwrites any union data inside the Query as the provided WildcardQuery
func (t *Query) FromWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeWildcardQuery performs a merge with any union data inside the Query, using the provided WildcardQuery
func (t *Query) MergeWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsQueryStringQuery returns the union data inside the Query as a QueryStringQuery
func (t Query) AsQueryStringQuery() (QueryStringQuery, error) {
	var body QueryStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromQueryStringQuery overwrites any union data inside the Query as the provided QueryStringQuery
func (t *Query) FromQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeQueryStringQuery performs a merge with any union data inside the Query, using the provided QueryStringQuery
func (t *Query) MergeQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsNumericRangeQuery returns the union data inside the Query as a NumericRangeQuery
func (t Query) AsNumericRangeQuery() (NumericRangeQuery, error) {
	var body NumericRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromNumericRangeQuery overwrites any union data inside the Query as the provided NumericRangeQuery
func (t *Query) FromNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeNumericRangeQuery performs a merge with any union data inside the Query, using the provided NumericRangeQuery
func (t *Query) MergeNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermRangeQuery returns the union data inside the Query as a TermRangeQuery
func (t Query) AsTermRangeQuery() (TermRangeQuery, error) {
	var body TermRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermRangeQuery overwrites any union data inside the Query as the provided TermRangeQuery
func (t *Query) FromTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermRangeQuery performs a merge with any union data inside the Query, using the provided TermRangeQuery
func (t *Query) MergeTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDateRangeStringQuery returns the union data inside the Query as a DateRangeStringQuery
func (t Query) AsDateRangeStringQuery() (DateRangeStringQuery, error) {
	var body DateRangeStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDateRangeStringQuery overwrites any union data inside the Query as the provided DateRangeStringQuery
func (t *Query) FromDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDateRangeStringQuery performs a merge with any union data inside the Query, using the provided DateRangeStringQuery
func (t *Query) MergeDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBooleanQuery returns the union data inside the Query as a BooleanQuery
func (t Query) AsBooleanQuery() (BooleanQuery, error) {
	var body BooleanQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBooleanQuery overwrites any union data inside the Query as the provided BooleanQuery
func (t *Query) FromBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBooleanQuery performs a merge with any union data inside the Query, using the provided BooleanQuery
func (t *Query) MergeBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsConjunctionQuery returns the union data inside the Query as a ConjunctionQuery
func (t Query) AsConjunctionQuery() (ConjunctionQuery, error) {
	var body ConjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromConjunctionQuery overwrites any union data inside the Query as the provided ConjunctionQuery
func (t *Query) FromConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeConjunctionQuery performs a merge with any union data inside the Query, using the provided ConjunctionQuery
func (t *Query) MergeConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDisjunctionQuery returns the union data inside the Query as a DisjunctionQuery
func (t Query) AsDisjunctionQuery() (DisjunctionQuery, error) {
	var body DisjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDisjunctionQuery overwrites any union data inside the Query as the provided DisjunctionQuery
func (t *Query) FromDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDisjunctionQuery performs a merge with any union data inside the Query, using the provided DisjunctionQuery
func (t *Query) MergeDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchAllQuery returns the union data inside the Query as a MatchAllQuery
func (t Query) AsMatchAllQuery() (MatchAllQuery, error) {
	var body MatchAllQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchAllQuery overwrites any union data inside the Query as the provided MatchAllQuery
func (t *Query) FromMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchAllQuery performs a merge with any union data inside the Query, using the provided MatchAllQuery
func (t *Query) MergeMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchNoneQuery returns the union data inside the Query as a MatchNoneQuery
func (t Query) AsMatchNoneQuery() (MatchNoneQuery, error) {
	var body MatchNoneQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchNoneQuery overwrites any union data inside the Query as the provided MatchNoneQuery
func (t *Query) FromMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchNoneQuery performs a merge with any union data inside the Query, using the provided MatchNoneQuery
func (t *Query) MergeMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDocIdQuery returns the union data inside the Query as a DocIdQuery
func (t Query) AsDocIdQuery() (DocIdQuery, error) {
	var body DocIdQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDocIdQuery overwrites any union data inside the Query as the provided DocIdQuery
func (t *Query) FromDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDocIdQuery performs a merge with any union data inside the Query, using the provided DocIdQuery
func (t *Query) MergeDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBoolFieldQuery returns the union data inside the Query as a BoolFieldQuery
func (t Query) AsBoolFieldQuery() (BoolFieldQuery, error) {
	var body BoolFieldQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBoolFieldQuery overwrites any union data inside the Query as the provided BoolFieldQuery
func (t *Query) FromBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBoolFieldQuery performs a merge with any union data inside the Query, using the provided BoolFieldQuery
func (t *Query) MergeBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsIPRangeQuery returns the union data inside the Query as a IPRangeQuery
func (t Query) AsIPRangeQuery() (IPRangeQuery, error) {
	var body IPRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromIPRangeQuery overwrites any union data inside the Query as the provided IPRangeQuery
func (t *Query) FromIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeIPRangeQuery performs a merge with any union data inside the Query, using the provided IPRangeQuery
func (t *Query) MergeIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingBoxQuery returns the union data inside the Query as a GeoBoundingBoxQuery
func (t Query) AsGeoBoundingBoxQuery() (GeoBoundingBoxQuery, error) {
	var body GeoBoundingBoxQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingBoxQuery overwrites any union data inside the Query as the provided GeoBoundingBoxQuery
func (t *Query) FromGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingBoxQuery performs a merge with any union data inside the Query, using the provided GeoBoundingBoxQuery
func (t *Query) MergeGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoDistanceQuery returns the union data inside the Query as a GeoDistanceQuery
func (t Query) AsGeoDistanceQuery() (GeoDistanceQuery, error) {
	var body GeoDistanceQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoDistanceQuery overwrites any union data inside the Query as the provided GeoDistanceQuery
func (t *Query) FromGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoDistanceQuery performs a merge with any union data inside the Query, using the provided GeoDistanceQuery
func (t *Query) MergeGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingPolygonQuery returns the union data inside the Query as a GeoBoundingPolygonQuery
func (t Query) AsGeoBoundingPolygonQuery() (GeoBoundingPolygonQuery, error) {
	var body GeoBoundingPolygonQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingPolygonQuery overwrites any union data inside the Query as the provided GeoBoundingPolygonQuery
func (t *Query) FromGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingPolygonQuery performs a merge with any union data inside the Query, using the provided GeoBoundingPolygonQuery
func (t *Query) MergeGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoShapeQuery returns the union data inside the Query as a GeoShapeQuery
func (t Query) AsGeoShapeQuery() (GeoShapeQuery, error) {
	var body GeoShapeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoShapeQuery overwrites any union data inside the Query as the provided GeoShapeQuery
func (t *Query) FromGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoShapeQuery performs a merge with any union data inside the Query, using the provided GeoShapeQuery
func (t *Query) MergeGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Query) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Query) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsOllamaRerankerConfig returns the union data inside the RerankerConfig as a OllamaRerankerConfig
func (t RerankerConfig) AsOllamaRerankerConfig() (OllamaRerankerConfig, error) {
	var body OllamaRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaRerankerConfig overwrites any union data inside the RerankerConfig as the provided OllamaRerankerConfig
func (t *RerankerConfig) FromOllamaRerankerConfig(v OllamaRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided OllamaRerankerConfig
func (t *RerankerConfig) MergeOllamaRerankerConfig(v OllamaRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermiteRerankerConfig returns the union data inside the RerankerConfig as a TermiteRerankerConfig
func (t RerankerConfig) AsTermiteRerankerConfig() (TermiteRerankerConfig, error) {
	var body TermiteRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteRerankerConfig overwrites any union data inside the RerankerConfig as the provided TermiteRerankerConfig
func (t *RerankerConfig) FromTermiteRerankerConfig(v TermiteRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided TermiteRerankerConfig
func (t *RerankerConfig) MergeTermiteRerankerConfig(v TermiteRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereRerankerConfig returns the union data inside the RerankerConfig as a CohereRerankerConfig
func (t RerankerConfig) AsCohereRerankerConfig() (CohereRerankerConfig, error) {
	var body CohereRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereRerankerConfig overwrites any union data inside the RerankerConfig as the provided CohereRerankerConfig
func (t *RerankerConfig) FromCohereRerankerConfig(v CohereRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided CohereRerankerConfig
func (t *RerankerConfig) MergeCohereRerankerConfig(v CohereRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexRerankerConfig returns the union data inside the RerankerConfig as a VertexRerankerConfig
func (t RerankerConfig) AsVertexRerankerConfig() (VertexRerankerConfig, error) {
	var body VertexRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexRerankerConfig overwrites any union data inside the RerankerConfig as the provided VertexRerankerConfig
func (t *RerankerConfig) FromVertexRerankerConfig(v VertexRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided VertexRerankerConfig
func (t *RerankerConfig) MergeVertexRerankerConfig(v VertexRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t RerankerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["field"], err = json.Marshal(t.Field)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'field': %w", err)
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	object["template"], err = json.Marshal(t.Template)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'template': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *RerankerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["field"]; found {
		err = json.Unmarshal(raw, &t.Field)
		if err != nil {
			return fmt.Errorf("error reading 'field': %w", err)
		}
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	if raw, found := object["template"]; found {
		err = json.Unmarshal(raw, &t.Template)
		if err != nil {
			return fmt.Errorf("error reading 'template': %w", err)
		}
	}

	return err
}

// RequestEditorFn  is the function signature for the RequestEditor callback function
type RequestEditorFn func(ctx context.Context, req *http.Request) error

// Doer performs HTTP requests.
//
// The standard http.Client implements this interface.
type HttpRequestDoer interface {
	Do(req *http.Request) (*http.Response, error)
}

// Client which conforms to the OpenAPI3 specification for this service.
type Client struct {
	// The endpoint of the server conforming to this interface, with scheme,
	// https://api.deepmap.com for example. This can contain a path relative
	// to the server, such as https://api.deepmap.com/dev-test, and all the
	// paths in the swagger spec will be appended to the server.
	Server string

	// Doer for performing requests, typically a *http.Client with any
	// customized settings, such as certificate chains.
	Client HttpRequestDoer

	// A list of callbacks for modifying requests which are generated before sending over
	// the network.
	RequestEditors []RequestEditorFn
}

// ClientOption allows setting custom parameters during construction
type ClientOption func(*Client) error

// Creates a new Client, with reasonable defaults
func NewClient(server string, opts ...ClientOption) (*Client, error) {
	// create a client with sane default values
	client := Client{
		Server: server,
	}
	// mutate client and add all optional params
	for _, o := range opts {
		if err := o(&client); err != nil {
			return nil, err
		}
	}
	// ensure the server URL always has a trailing slash
	if !strings.HasSuffix(client.Server, "/") {
		client.Server += "/"
	}
	// create httpClient, if not already present
	if client.Client == nil {
		client.Client = &http.Client{}
	}
	return &client, nil
}

// WithHTTPClient allows overriding the default Doer, which is
// automatically created using http.Client. This is useful for tests.
func WithHTTPClient(doer HttpRequestDoer) ClientOption {
	return func(c *Client) error {
		c.Client = doer
		return nil
	}
}

// WithRequestEditorFn allows setting up a callback function, which will be
// called right before sending the request. This can be used to mutate the request.
func WithRequestEditorFn(fn RequestEditorFn) ClientOption {
	return func(c *Client) error {
		c.RequestEditors = append(c.RequestEditors, fn)
		return nil
	}
}

// The interface specification for the client above.
type ClientInterface interface {
	// AnswerAgentWithBody request with any body
	AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ChatAgentWithBody request with any body
	ChatAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	ChatAgent(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// QueryBuilderAgentWithBody request with any body
	QueryBuilderAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	QueryBuilderAgent(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BackupWithBody request with any body
	BackupWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Backup(ctx context.Context, body BackupJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListBackups request
	ListBackups(ctx context.Context, params *ListBackupsParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// EvaluateWithBody request with any body
	EvaluateWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Evaluate(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GlobalQueryWithBody request with any body
	GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RagQueryWithBody request with any body
	RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RestoreWithBody request with any body
	RestoreWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Restore(ctx context.Context, body RestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetStatus request
	GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListTables request
	ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropTable request
	DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetTable request
	GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateTableWithBody request with any body
	CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BackupTableWithBody request with any body
	BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BatchWriteWithBody request with any body
	BatchWriteWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	BatchWrite(ctx context.Context, tableName string, body BatchWriteJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListIndexes request
	ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropIndex request
	DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetIndex request
	GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateIndexWithBody request with any body
	CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ScanKeysWithBody request with any body
	ScanKeysWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	ScanKeys(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LookupKey request
	LookupKey(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LinearMergeWithBody request with any body
	LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// QueryTableWithBody request with any body
	QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// TableRagQueryWithBody request with any body
	TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RestoreTableWithBody request with any body
	RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateSchemaWithBody request with any body
	UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListUsers request
	ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetCurrentUser request
	GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteUser request
	DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserByName request
	GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateUserWithBody request with any body
	CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateUserPasswordWithBody request with any body
	UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RemovePermissionFromUser request
	RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserPermissions request
	GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// AddPermissionToUserWithBody request with any body
	AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)
}

func (c *Client) AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ChatAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewChatAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ChatAgent(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewChatAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryBuilderAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryBuilderAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryBuilderAgent(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryBuilderAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Backup(ctx context.Context, body BackupJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListBackups(ctx context.Context, params *ListBackupsParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListBackupsRequest(c.Server, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) EvaluateWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewEvaluateRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Evaluate(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewEvaluateRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Restore(ctx context.Context, body RestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetStatusRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListTablesRequest(c.Server, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BatchWriteWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchWriteRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BatchWrite(ctx context.Context, tableName string, body BatchWriteJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchWriteRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListIndexesRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequestWithBody(c.Server, tableName, indexName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequest(c.Server, tableName, indexName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ScanKeysWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewScanKeysRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ScanKeys(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewScanKeysRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LookupKey(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLookupKeyRequest(c.Server, tableName, key, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListUsersRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetCurrentUserRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteUserRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserByNameRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRemovePermissionFromUserRequest(c.Server, userName, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserPermissionsRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

// NewAnswerAgentRequest calls the generic AnswerAgent builder with application/json body
func NewAnswerAgentRequest(server string, body AnswerAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAnswerAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewAnswerAgentRequestWithBody generates requests for AnswerAgent with any type of body
func NewAnswerAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/answer")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewChatAgentRequest calls the generic ChatAgent builder with application/json body
func NewChatAgentRequest(server string, body ChatAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewChatAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewChatAgentRequestWithBody generates requests for ChatAgent with any type of body
func NewChatAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/chat")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewQueryBuilderAgentRequest calls the generic QueryBuilderAgent builder with application/json body
func NewQueryBuilderAgentRequest(server string, body QueryBuilderAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewQueryBuilderAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewQueryBuilderAgentRequestWithBody generates requests for QueryBuilderAgent with any type of body
func NewQueryBuilderAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/query-builder")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBackupRequest calls the generic Backup builder with application/json body
func NewBackupRequest(server string, body BackupJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBackupRequestWithBody(server, "application/json", bodyReader)
}

// NewBackupRequestWithBody generates requests for Backup with any type of body
func NewBackupRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backup")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListBackupsRequest generates requests for ListBackups
func NewListBackupsRequest(server string, params *ListBackupsParams) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backups")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "location", runtime.ParamLocationQuery, params.Location); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewEvaluateRequest calls the generic Evaluate builder with application/json body
func NewEvaluateRequest(server string, body EvaluateJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewEvaluateRequestWithBody(server, "application/json", bodyReader)
}

// NewEvaluateRequestWithBody generates requests for Evaluate with any type of body
func NewEvaluateRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/eval")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGlobalQueryRequest calls the generic GlobalQuery builder with application/json body
func NewGlobalQueryRequest(server string, body GlobalQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewGlobalQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewGlobalQueryRequestWithBody generates requests for GlobalQuery with any type of body
func NewGlobalQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/query")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRagQueryRequest calls the generic RagQuery builder with application/json body
func NewRagQueryRequest(server string, body RagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRagQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewRagQueryRequestWithBody generates requests for RagQuery with any type of body
func NewRagQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/rag")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRestoreRequest calls the generic Restore builder with application/json body
func NewRestoreRequest(server string, body RestoreJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRestoreRequestWithBody(server, "application/json", bodyReader)
}

// NewRestoreRequestWithBody generates requests for Restore with any type of body
func NewRestoreRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/restore")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetStatusRequest generates requests for GetStatus
func NewGetStatusRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/status")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListTablesRequest generates requests for ListTables
func NewListTablesRequest(server string, params *ListTablesParams) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "prefix", runtime.ParamLocationQuery, params.Prefix); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "pattern", runtime.ParamLocationQuery, params.Pattern); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropTableRequest generates requests for DropTable
func NewDropTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetTableRequest generates requests for GetTable
func NewGetTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateTableRequest calls the generic CreateTable builder with application/json body
func NewCreateTableRequest(server string, tableName string, body CreateTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewCreateTableRequestWithBody generates requests for CreateTable with any type of body
func NewCreateTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBackupTableRequest calls the generic BackupTable builder with application/json body
func NewBackupTableRequest(server string, tableName string, body BackupTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBackupTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBackupTableRequestWithBody generates requests for BackupTable with any type of body
func NewBackupTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/backup", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBatchWriteRequest calls the generic BatchWrite builder with application/json body
func NewBatchWriteRequest(server string, tableName string, body BatchWriteJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBatchWriteRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBatchWriteRequestWithBody generates requests for BatchWrite with any type of body
func NewBatchWriteRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/batch", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListIndexesRequest generates requests for ListIndexes
func NewListIndexesRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropIndexRequest generates requests for DropIndex
func NewDropIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetIndexRequest generates requests for GetIndex
func NewGetIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateIndexRequest calls the generic CreateIndex builder with application/json body
func NewCreateIndexRequest(server string, tableName string, indexName string, body CreateIndexJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateIndexRequestWithBody(server, tableName, indexName, "application/json", bodyReader)
}

// NewCreateIndexRequestWithBody generates requests for CreateIndex with any type of body
func NewCreateIndexRequestWithBody(server string, tableName string, indexName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewScanKeysRequest calls the generic ScanKeys builder with application/json body
func NewScanKeysRequest(server string, tableName string, body ScanKeysJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewScanKeysRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewScanKeysRequestWithBody generates requests for ScanKeys with any type of body
func NewScanKeysRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/lookup", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewLookupKeyRequest generates requests for LookupKey
func NewLookupKeyRequest(server string, tableName string, key string, params *LookupKeyParams) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "key", runtime.ParamLocationPath, key)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/lookup/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "fields", runtime.ParamLocationQuery, params.Fields); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewLinearMergeRequest calls the generic LinearMerge builder with application/json body
func NewLinearMergeRequest(server string, tableName string, body LinearMergeJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewLinearMergeRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewLinearMergeRequestWithBody generates requests for LinearMerge with any type of body
func NewLinearMergeRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/merge", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewQueryTableRequest calls the generic QueryTable builder with application/json body
func NewQueryTableRequest(server string, tableName string, body QueryTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewQueryTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewQueryTableRequestWithBody generates requests for QueryTable with any type of body
func NewQueryTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/query", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewTableRagQueryRequest calls the generic TableRagQuery builder with application/json body
func NewTableRagQueryRequest(server string, tableName string, body TableRagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewTableRagQueryRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewTableRagQueryRequestWithBody generates requests for TableRagQuery with any type of body
func NewTableRagQueryRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/rag", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRestoreTableRequest calls the generic RestoreTable builder with application/json body
func NewRestoreTableRequest(server string, tableName string, body RestoreTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRestoreTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewRestoreTableRequestWithBody generates requests for RestoreTable with any type of body
func NewRestoreTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/restore", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateSchemaRequest calls the generic UpdateSchema builder with application/json body
func NewUpdateSchemaRequest(server string, tableName string, body UpdateSchemaJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateSchemaRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewUpdateSchemaRequestWithBody generates requests for UpdateSchema with any type of body
func NewUpdateSchemaRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/schema", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListUsersRequest generates requests for ListUsers
func NewListUsersRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetCurrentUserRequest generates requests for GetCurrentUser
func NewGetCurrentUserRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/me")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDeleteUserRequest generates requests for DeleteUser
func NewDeleteUserRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserByNameRequest generates requests for GetUserByName
func NewGetUserByNameRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateUserRequest calls the generic CreateUser builder with application/json body
func NewCreateUserRequest(server string, userName UserNamePathParameter, body CreateUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewCreateUserRequestWithBody generates requests for CreateUser with any type of body
func NewCreateUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateUserPasswordRequest calls the generic UpdateUserPassword builder with application/json body
func NewUpdateUserPasswordRequest(server string, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateUserPasswordRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewUpdateUserPasswordRequestWithBody generates requests for UpdateUserPassword with any type of body
func NewUpdateUserPasswordRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/password", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRemovePermissionFromUserRequest generates requests for RemovePermissionFromUser
func NewRemovePermissionFromUserRequest(server string, userName UserNamePathParameter, params *RemovePermissionFromUserParams) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resource", runtime.ParamLocationQuery, params.Resource); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resourceType", runtime.ParamLocationQuery, params.ResourceType); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserPermissionsRequest generates requests for GetUserPermissions
func NewGetUserPermissionsRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewAddPermissionToUserRequest calls the generic AddPermissionToUser builder with application/json body
func NewAddPermissionToUserRequest(server string, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAddPermissionToUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewAddPermissionToUserRequestWithBody generates requests for AddPermissionToUser with any type of body
func NewAddPermissionToUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

func (c *Client) applyEditors(ctx context.Context, req *http.Request, additionalEditors []RequestEditorFn) error {
	for _, r := range c.RequestEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	for _, r := range additionalEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	return nil
}

// ClientWithResponses builds on ClientInterface to offer response payloads
type ClientWithResponses struct {
	ClientInterface
}

// NewClientWithResponses creates a new ClientWithResponses, which wraps
// Client with return type handling
func NewClientWithResponses(server string, opts ...ClientOption) (*ClientWithResponses, error) {
	client, err := NewClient(server, opts...)
	if err != nil {
		return nil, err
	}
	return &ClientWithResponses{client}, nil
}

// WithBaseURL overrides the baseURL.
func WithBaseURL(baseURL string) ClientOption {
	return func(c *Client) error {
		newBaseURL, err := url.Parse(baseURL)
		if err != nil {
			return err
		}
		c.Server = newBaseURL.String()
		return nil
	}
}

// ClientWithResponsesInterface is the interface specification for the client with responses above.
type ClientWithResponsesInterface interface {
	// AnswerAgentWithBodyWithResponse request with any body
	AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	// ChatAgentWithBodyWithResponse request with any body
	ChatAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error)

	ChatAgentWithResponse(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error)

	// QueryBuilderAgentWithBodyWithResponse request with any body
	QueryBuilderAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error)

	QueryBuilderAgentWithResponse(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error)

	// BackupWithBodyWithResponse request with any body
	BackupWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupResponse, error)

	BackupWithResponse(ctx context.Context, body BackupJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupResponse, error)

	// ListBackupsWithResponse request
	ListBackupsWithResponse(ctx context.Context, params *ListBackupsParams, reqEditors ...RequestEditorFn) (*ListBackupsResponse, error)

	// EvaluateWithBodyWithResponse request with any body
	EvaluateWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*EvaluateResponse, error)

	EvaluateWithResponse(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*EvaluateResponse, error)

	// GlobalQueryWithBodyWithResponse request with any body
	GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	// RagQueryWithBodyWithResponse request with any body
	RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	// RestoreWithBodyWithResponse request with any body
	RestoreWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreResponse, error)

	RestoreWithResponse(ctx context.Context, body RestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreResponse, error)

	// GetStatusWithResponse request
	GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error)

	// ListTablesWithResponse request
	ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error)

	// DropTableWithResponse request
	DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error)

	// GetTableWithResponse request
	GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error)

	// CreateTableWithBodyWithResponse request with any body
	CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	// BackupTableWithBodyWithResponse request with any body
	BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	// BatchWriteWithBodyWithResponse request with any body
	BatchWriteWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchWriteResponse, error)

	BatchWriteWithResponse(ctx context.Context, tableName string, body BatchWriteJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchWriteResponse, error)

	// ListIndexesWithResponse request
	ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error)

	// DropIndexWithResponse request
	DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error)

	// GetIndexWithResponse request
	GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error)

	// CreateIndexWithBodyWithResponse request with any body
	CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	// ScanKeysWithBodyWithResponse request with any body
	ScanKeysWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error)

	ScanKeysWithResponse(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error)

	// LookupKeyWithResponse request
	LookupKeyWithResponse(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error)

	// LinearMergeWithBodyWithResponse request with any body
	LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	// QueryTableWithBodyWithResponse request with any body
	QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	// TableRagQueryWithBodyWithResponse request with any body
	TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	// RestoreTableWithBodyWithResponse request with any body
	RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	// UpdateSchemaWithBodyWithResponse request with any body
	UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	// ListUsersWithResponse request
	ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error)

	// GetCurrentUserWithResponse request
	GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error)

	// DeleteUserWithResponse request
	DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error)

	// GetUserByNameWithResponse request
	GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error)

	// CreateUserWithBodyWithResponse request with any body
	CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	// UpdateUserPasswordWithBodyWithResponse request with any body
	UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	// RemovePermissionFromUserWithResponse request
	RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error)

	// GetUserPermissionsWithResponse request
	GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error)

	// AddPermissionToUserWithBodyWithResponse request with any body
	AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)

	AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)
}

type AnswerAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *AnswerAgentResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AnswerAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AnswerAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ChatAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ChatAgentResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ChatAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ChatAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type QueryBuilderAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryBuilderResult
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r QueryBuilderAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r QueryBuilderAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BackupResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ClusterBackupResponse
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BackupResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BackupResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListBackupsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *BackupListResponse
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListBackupsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListBackupsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type EvaluateResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *EvalResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r EvaluateResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r EvaluateResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GlobalQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GlobalQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GlobalQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RestoreResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON202      *ClusterRestoreResponse
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r RestoreResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RestoreResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetStatusResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ClusterStatus
	JSON401      *Error
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetStatusResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetStatusResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListTablesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]TableStatus
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListTablesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListTablesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *TableStatus
	JSON404      *NotFound
}

// Status returns HTTPResponse.Status
func (r GetTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
}

// Status returns HTTPResponse.Status
func (r CreateTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BackupTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *struct {
		Backup string `json:"backup,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON404 *NotFound
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BackupTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BackupTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BatchWriteResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *BatchResponse
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BatchWriteResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BatchWriteResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListIndexesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListIndexesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListIndexesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r CreateIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ScanKeysResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ScanKeysResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ScanKeysResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LookupKeyResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *map[string]interface{}
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LookupKeyResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LookupKeyResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LinearMergeResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *LinearMergeResult
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LinearMergeResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LinearMergeResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type QueryTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r QueryTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r QueryTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type TableRagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON404      *NotFound
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r TableRagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r TableRagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RestoreTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON202      *struct {
		Restore string `json:"restore,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r RestoreTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RestoreTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateSchemaResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r UpdateSchemaResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateSchemaResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListUsersResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]struct {
		Username string `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON403 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r ListUsersResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListUsersResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetCurrentUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *struct {
		Permissions []Permission `json:"permissions,omitempty,omitzero"`
		Username    string       `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r GetCurrentUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetCurrentUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserByNameResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *User
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserByNameResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserByNameResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *User
	JSON400      *Error
	JSON409      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateUserPasswordResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateUserPasswordResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateUserPasswordResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RemovePermissionFromUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RemovePermissionFromUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RemovePermissionFromUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserPermissionsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]Permission
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserPermissionsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserPermissionsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type AddPermissionToUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AddPermissionToUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AddPermissionToUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

// AnswerAgentWithBodyWithResponse request with arbitrary body returning *AnswerAgentResponse
func (c *ClientWithResponses) AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

func (c *ClientWithResponses) AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

// ChatAgentWithBodyWithResponse request with arbitrary body returning *ChatAgentResponse
func (c *ClientWithResponses) ChatAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error) {
	rsp, err := c.ChatAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseChatAgentResponse(rsp)
}

func (c *ClientWithResponses) ChatAgentWithResponse(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error) {
	rsp, err := c.ChatAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseChatAgentResponse(rsp)
}

// QueryBuilderAgentWithBodyWithResponse request with arbitrary body returning *QueryBuilderAgentResponse
func (c *ClientWithResponses) QueryBuilderAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error) {
	rsp, err := c.QueryBuilderAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryBuilderAgentResponse(rsp)
}

func (c *ClientWithResponses) QueryBuilderAgentWithResponse(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error) {
	rsp, err := c.QueryBuilderAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryBuilderAgentResponse(rsp)
}

// BackupWithBodyWithResponse request with arbitrary body returning *BackupResponse
func (c *ClientWithResponses) BackupWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupResponse, error) {
	rsp, err := c.BackupWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupResponse(rsp)
}

func (c *ClientWithResponses) BackupWithResponse(ctx context.Context, body BackupJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupResponse, error) {
	rsp, err := c.Backup(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupResponse(rsp)
}

// ListBackupsWithResponse request returning *ListBackupsResponse
func (c *ClientWithResponses) ListBackupsWithResponse(ctx context.Context, params *ListBackupsParams, reqEditors ...RequestEditorFn) (*ListBackupsResponse, error) {
	rsp, err := c.ListBackups(ctx, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListBackupsResponse(rsp)
}

// EvaluateWithBodyWithResponse request with arbitrary body returning *EvaluateResponse
func (c *ClientWithResponses) EvaluateWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*EvaluateResponse, error) {
	rsp, err := c.EvaluateWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseEvaluateResponse(rsp)
}

func (c *ClientWithResponses) EvaluateWithResponse(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*EvaluateResponse, error) {
	rsp, err := c.Evaluate(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseEvaluateResponse(rsp)
}

// GlobalQueryWithBodyWithResponse request with arbitrary body returning *GlobalQueryResponse
func (c *ClientWithResponses) GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

func (c *ClientWithResponses) GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

// RagQueryWithBodyWithResponse request with arbitrary body returning *RagQueryResponse
func (c *ClientWithResponses) RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

func (c *ClientWithResponses) RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

// RestoreWithBodyWithResponse request with arbitrary body returning *RestoreResponse
func (c *ClientWithResponses) RestoreWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreResponse, error) {
	rsp, err := c.RestoreWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreResponse(rsp)
}

func (c *ClientWithResponses) RestoreWithResponse(ctx context.Context, body RestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreResponse, error) {
	rsp, err := c.Restore(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreResponse(rsp)
}

// GetStatusWithResponse request returning *GetStatusResponse
func (c *ClientWithResponses) GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error) {
	rsp, err := c.GetStatus(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetStatusResponse(rsp)
}

// ListTablesWithResponse request returning *ListTablesResponse
func (c *ClientWithResponses) ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error) {
	rsp, err := c.ListTables(ctx, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListTablesResponse(rsp)
}

// DropTableWithResponse request returning *DropTableResponse
func (c *ClientWithResponses) DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error) {
	rsp, err := c.DropTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropTableResponse(rsp)
}

// GetTableWithResponse request returning *GetTableResponse
func (c *ClientWithResponses) GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error) {
	rsp, err := c.GetTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetTableResponse(rsp)
}

// CreateTableWithBodyWithResponse request with arbitrary body returning *CreateTableResponse
func (c *ClientWithResponses) CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

func (c *ClientWithResponses) CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

// BackupTableWithBodyWithResponse request with arbitrary body returning *BackupTableResponse
func (c *ClientWithResponses) BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

func (c *ClientWithResponses) BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

// BatchWriteWithBodyWithResponse request with arbitrary body returning *BatchWriteResponse
func (c *ClientWithResponses) BatchWriteWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchWriteResponse, error) {
	rsp, err := c.BatchWriteWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchWriteResponse(rsp)
}

func (c *ClientWithResponses) BatchWriteWithResponse(ctx context.Context, tableName string, body BatchWriteJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchWriteResponse, error) {
	rsp, err := c.BatchWrite(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchWriteResponse(rsp)
}

// ListIndexesWithResponse request returning *ListIndexesResponse
func (c *ClientWithResponses) ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error) {
	rsp, err := c.ListIndexes(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListIndexesResponse(rsp)
}

// DropIndexWithResponse request returning *DropIndexResponse
func (c *ClientWithResponses) DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error) {
	rsp, err := c.DropIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropIndexResponse(rsp)
}

// GetIndexWithResponse request returning *GetIndexResponse
func (c *ClientWithResponses) GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error) {
	rsp, err := c.GetIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetIndexResponse(rsp)
}

// CreateIndexWithBodyWithResponse request with arbitrary body returning *CreateIndexResponse
func (c *ClientWithResponses) CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndexWithBody(ctx, tableName, indexName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

func (c *ClientWithResponses) CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndex(ctx, tableName, indexName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

// ScanKeysWithBodyWithResponse request with arbitrary body returning *ScanKeysResponse
func (c *ClientWithResponses) ScanKeysWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error) {
	rsp, err := c.ScanKeysWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseScanKeysResponse(rsp)
}

func (c *ClientWithResponses) ScanKeysWithResponse(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error) {
	rsp, err := c.ScanKeys(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseScanKeysResponse(rsp)
}

// LookupKeyWithResponse request returning *LookupKeyResponse
func (c *ClientWithResponses) LookupKeyWithResponse(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error) {
	rsp, err := c.LookupKey(ctx, tableName, key, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLookupKeyResponse(rsp)
}

// LinearMergeWithBodyWithResponse request with arbitrary body returning *LinearMergeResponse
func (c *ClientWithResponses) LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMergeWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

func (c *ClientWithResponses) LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMerge(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

// QueryTableWithBodyWithResponse request with arbitrary body returning *QueryTableResponse
func (c *ClientWithResponses) QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

func (c *ClientWithResponses) QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

// TableRagQueryWithBodyWithResponse request with arbitrary body returning *TableRagQueryResponse
func (c *ClientWithResponses) TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQueryWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

func (c *ClientWithResponses) TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQuery(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

// RestoreTableWithBodyWithResponse request with arbitrary body returning *RestoreTableResponse
func (c *ClientWithResponses) RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

func (c *ClientWithResponses) RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

// UpdateSchemaWithBodyWithResponse request with arbitrary body returning *UpdateSchemaResponse
func (c *ClientWithResponses) UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchemaWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

func (c *ClientWithResponses) UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchema(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

// ListUsersWithResponse request returning *ListUsersResponse
func (c *ClientWithResponses) ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error) {
	rsp, err := c.ListUsers(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListUsersResponse(rsp)
}

// GetCurrentUserWithResponse request returning *GetCurrentUserResponse
func (c *ClientWithResponses) GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error) {
	rsp, err := c.GetCurrentUser(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetCurrentUserResponse(rsp)
}

// DeleteUserWithResponse request returning *DeleteUserResponse
func (c *ClientWithResponses) DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error) {
	rsp, err := c.DeleteUser(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteUserResponse(rsp)
}

// GetUserByNameWithResponse request returning *GetUserByNameResponse
func (c *ClientWithResponses) GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error) {
	rsp, err := c.GetUserByName(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserByNameResponse(rsp)
}

// CreateUserWithBodyWithResponse request with arbitrary body returning *CreateUserResponse
func (c *ClientWithResponses) CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

func (c *ClientWithResponses) CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

// UpdateUserPasswordWithBodyWithResponse request with arbitrary body returning *UpdateUserPasswordResponse
func (c *ClientWithResponses) UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPasswordWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

func (c *ClientWithResponses) UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPassword(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

// RemovePermissionFromUserWithResponse request returning *RemovePermissionFromUserResponse
func (c *ClientWithResponses) RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error) {
	rsp, err := c.RemovePermissionFromUser(ctx, userName, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRemovePermissionFromUserResponse(rsp)
}

// GetUserPermissionsWithResponse request returning *GetUserPermissionsResponse
func (c *ClientWithResponses) GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error) {
	rsp, err := c.GetUserPermissions(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserPermissionsResponse(rsp)
}

// AddPermissionToUserWithBodyWithResponse request with arbitrary body returning *AddPermissionToUserResponse
func (c *ClientWithResponses) AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

func (c *ClientWithResponses) AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

// ParseAnswerAgentResponse parses an HTTP response from a AnswerAgentWithResponse call
func ParseAnswerAgentResponse(rsp *http.Response) (*AnswerAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AnswerAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest AnswerAgentResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseChatAgentResponse parses an HTTP response from a ChatAgentWithResponse call
func ParseChatAgentResponse(rsp *http.Response) (*ChatAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ChatAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ChatAgentResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseQueryBuilderAgentResponse parses an HTTP response from a QueryBuilderAgentWithResponse call
func ParseQueryBuilderAgentResponse(rsp *http.Response) (*QueryBuilderAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &QueryBuilderAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryBuilderResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseBackupResponse parses an HTTP response from a BackupWithResponse call
func ParseBackupResponse(rsp *http.Response) (*BackupResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BackupResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ClusterBackupResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListBackupsResponse parses an HTTP response from a ListBackupsWithResponse call
func ParseListBackupsResponse(rsp *http.Response) (*ListBackupsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListBackupsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest BackupListResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseEvaluateResponse parses an HTTP response from a EvaluateWithResponse call
func ParseEvaluateResponse(rsp *http.Response) (*EvaluateResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &EvaluateResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest EvalResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGlobalQueryResponse parses an HTTP response from a GlobalQueryWithResponse call
func ParseGlobalQueryResponse(rsp *http.Response) (*GlobalQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GlobalQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRagQueryResponse parses an HTTP response from a RagQueryWithResponse call
func ParseRagQueryResponse(rsp *http.Response) (*RagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseRestoreResponse parses an HTTP response from a RestoreWithResponse call
func ParseRestoreResponse(rsp *http.Response) (*RestoreResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RestoreResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest ClusterRestoreResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetStatusResponse parses an HTTP response from a GetStatusWithResponse call
func ParseGetStatusResponse(rsp *http.Response) (*GetStatusResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetStatusResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ClusterStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListTablesResponse parses an HTTP response from a ListTablesWithResponse call
func ParseListTablesResponse(rsp *http.Response) (*ListTablesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListTablesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropTableResponse parses an HTTP response from a DropTableWithResponse call
func ParseDropTableResponse(rsp *http.Response) (*DropTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetTableResponse parses an HTTP response from a GetTableWithResponse call
func ParseGetTableResponse(rsp *http.Response) (*GetTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	}

	return response, nil
}

// ParseCreateTableResponse parses an HTTP response from a CreateTableWithResponse call
func ParseCreateTableResponse(rsp *http.Response) (*CreateTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	}

	return response, nil
}

// ParseBackupTableResponse parses an HTTP response from a BackupTableWithResponse call
func ParseBackupTableResponse(rsp *http.Response) (*BackupTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BackupTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest struct {
			Backup string `json:"backup,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseBatchWriteResponse parses an HTTP response from a BatchWriteWithResponse call
func ParseBatchWriteResponse(rsp *http.Response) (*BatchWriteResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BatchWriteResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest BatchResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListIndexesResponse parses an HTTP response from a ListIndexesWithResponse call
func ParseListIndexesResponse(rsp *http.Response) (*ListIndexesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListIndexesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropIndexResponse parses an HTTP response from a DropIndexWithResponse call
func ParseDropIndexResponse(rsp *http.Response) (*DropIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetIndexResponse parses an HTTP response from a GetIndexWithResponse call
func ParseGetIndexResponse(rsp *http.Response) (*GetIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateIndexResponse parses an HTTP response from a CreateIndexWithResponse call
func ParseCreateIndexResponse(rsp *http.Response) (*CreateIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseScanKeysResponse parses an HTTP response from a ScanKeysWithResponse call
func ParseScanKeysResponse(rsp *http.Response) (*ScanKeysResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ScanKeysResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLookupKeyResponse parses an HTTP response from a LookupKeyWithResponse call
func ParseLookupKeyResponse(rsp *http.Response) (*LookupKeyResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LookupKeyResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest map[string]interface{}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLinearMergeResponse parses an HTTP response from a LinearMergeWithResponse call
func ParseLinearMergeResponse(rsp *http.Response) (*LinearMergeResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LinearMergeResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest LinearMergeResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseQueryTableResponse parses an HTTP response from a QueryTableWithResponse call
func ParseQueryTableResponse(rsp *http.Response) (*QueryTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &QueryTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseTableRagQueryResponse parses an HTTP response from a TableRagQueryWithResponse call
func ParseTableRagQueryResponse(rsp *http.Response) (*TableRagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &TableRagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseRestoreTableResponse parses an HTTP response from a RestoreTableWithResponse call
func ParseRestoreTableResponse(rsp *http.Response) (*RestoreTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RestoreTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest struct {
			Restore string `json:"restore,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateSchemaResponse parses an HTTP response from a UpdateSchemaWithResponse call
func ParseUpdateSchemaResponse(rsp *http.Response) (*UpdateSchemaResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateSchemaResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListUsersResponse parses an HTTP response from a ListUsersWithResponse call
func ParseListUsersResponse(rsp *http.Response) (*ListUsersResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListUsersResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []struct {
			Username string `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 403:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON403 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetCurrentUserResponse parses an HTTP response from a GetCurrentUserWithResponse call
func ParseGetCurrentUserResponse(rsp *http.Response) (*GetCurrentUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetCurrentUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest struct {
			Permissions []Permission `json:"permissions,omitempty,omitzero"`
			Username    string       `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteUserResponse parses an HTTP response from a DeleteUserWithResponse call
func ParseDeleteUserResponse(rsp *http.Response) (*DeleteUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserByNameResponse parses an HTTP response from a GetUserByNameWithResponse call
func ParseGetUserByNameResponse(rsp *http.Response) (*GetUserByNameResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserByNameResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateUserResponse parses an HTTP response from a CreateUserWithResponse call
func ParseCreateUserResponse(rsp *http.Response) (*CreateUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 409:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON409 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateUserPasswordResponse parses an HTTP response from a UpdateUserPasswordWithResponse call
func ParseUpdateUserPasswordResponse(rsp *http.Response) (*UpdateUserPasswordResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateUserPasswordResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRemovePermissionFromUserResponse parses an HTTP response from a RemovePermissionFromUserWithResponse call
func ParseRemovePermissionFromUserResponse(rsp *http.Response) (*RemovePermissionFromUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RemovePermissionFromUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserPermissionsResponse parses an HTTP response from a GetUserPermissionsWithResponse call
func ParseGetUserPermissionsResponse(rsp *http.Response) (*GetUserPermissionsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserPermissionsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []Permission
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseAddPermissionToUserResponse parses an HTTP response from a AddPermissionToUserWithResponse call
func ParseAddPermissionToUserResponse(rsp *http.Response) (*AddPermissionToUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AddPermissionToUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// Base64 encoded, gzipped, json marshaled Swagger object
var swaggerSpec = []string{

	"H4sIAAAAAAAC/+z9jXYbOZIviL8K/uz+H0tekpJsV1c37+kzLX+Wpvw1lt11Z4s+FJgJkmhlAlkAUhLL",
	"R/sM+yL7UvskexABIJFMpEhJdtWdO3XvmWqLic8AEAjExy++DDJZVlIwYfRg8mVQUUVLZpiCvz5ppt7S",
	"kr2nZvXef7EfcqYzxSvDpRhMBh9XjNSaKUFLNh4MB9z+WFGzGgwH9rfBZFC7lgbDgWK/1FyxfDAxqmbD",
	"gc5WrKS2VXZFy6qwxf8lVyKXtrRZV/YHbRQXy8H19bVtQFdSaAZDfErzD+yXmmlj/8qkMEzAP2lVFTyj",
	"dogH/9J2nF+irv6s2GIwGfzpoJn+AX7VBy+Ukgq7as/zKc2Jcp1dDwcnwtg5F6dMXTCFtb75GHynREOv",
	"hGHB4eCtNC9lLfJvP4QPTMtaZYwIacgC+rSFXD3b7PFyqdgSOn1aZ+cMRlIpWTFlOK7bfDnLZI1j3KRy",
	"dr5UtlkCJcjeQiqi+VLwBc+oMDPDVKn3m83BhWFLpgbDwdVoKUf215E+59VIQpu0GFXSllGDyYIWmtkZ",
	"yayv/7d1OWeKyAXJZVaXliaEC2JWXJM5zqbT8/VwsFCy7Db2Wl4yReYwGzsNRcWSuWb0YDhYSFVSM5gM",
	"FoWkUcMCBhHPyJf5y5PbzNOOakb1zJ2fzvheQv+G5aRoRto5drfo8JytE0sK8yXnbE327OINHR0scxiS",
	"nBo2JMxk4/3ugYcWd5uBbd7SOOe6Kuia7LHxcjwki1DAdqT37zM7nUnFumM4DZszYwTK3LBpv/WS63o+",
	"o80BhNNG85xj+fetU3jT+Y8O8Qem6wJ4XocT1IXR9qwIpi2JdT0ftToP05Pzf7EM2jCyS8FPVfW7nhMj",
	"d9tjdTPOu++j6/gS/BmOTMyRPidoFi3Gc2rYB0ueLlNN86BTQ5WBzU/2Tk7fkb/+5fCIWBqzghp+wUjB",
	"zxmZDoS8HH2fTwf3OiF433d4Ki2Z3SVmxXAg8fqmDn1qj7wQ+W6zuNcUNhYH5rNlRW61GvGNsMdFVtSa",
	"X7DfgjFsX5q7rEp8cvfY1W82n7usUyMotleKFkupuFmV+EfxbjGY/Hwzd4xZ/nGofv15eNPVEPohyduB",
	"bHDOnVd2HkSm2YIXTkbfbR7/UTO1HlwPv7RWw0qK4w/08g3Tmi5Zayy8rKRCIloRfzJgIpM5F0uUL6+7",
	"NIgkOhzeLtO/Hg4yWjCRUzWD6V7QYvdpPXNVT3zN7qh8kRG9pIoR3weKENSw2YprI5eKlndeF2gGDpXu",
	"HpzngQ/qpk88gRv9ccPK21zXzQ1xHQ4EVYqu4Qbn2tjN2D8uVyAe25LJma94p9H5RnuHteCsyBM3r/2Z",
	"GBk6ZUSKFGuKt8hmE1csby9v78p+axZccjG74enxhgte1mV4eLgHkB0ydWzZ0mJud2tW1DmzQkh4NR/d",
	"50EkFV9y0R3SO/jdb4IV1avZUvE8JhzIuiU1EzIdFNQMCymmg/2peIEDsz8//n78/fdP/jYcHT16NH5y",
	"9Lcn08FU3EfMqBTLuOYyMeJXOEwSipC9o9HRo/0b56Dv9ZrsO0ofmhP0VQ527+nR/NfE1f6GXsF2EuFF",
	"6wRqu4kUM7XCtXM/c7FsDXC/tbkO70Ogb/ImCYqYDYHmFi8R+GHnLj/a4tfDQS242f0q8qzvk63VvYYC",
	"u7WtbmW2dxOOYJ6ex24VkuCt15WRLhIPo+MLpuiS4X1uqNG/NUP1L8QelQOevfT2RlWEdrqIYXMpNLqI",
	"255Pp+xKHNAehv+8y+iTZLz7ySvpVT9juKBF/TsuXpm6cPwd+DuPTZt8lrMLTk3ykjk11MqOOQllfseh",
	"1qlHf13+riOaycVM/1JTlboX7eDkgrjvv984YY+l1HliWbBoB5bMKJ5tcA9dl0NCL5ZDUnIxJCW9GuIx",
	"HpKMqpwLWnCz3v9NpqG4vSy6M/mn+/J7kfj65rvmo7t/N8xJ6wo0ErGIaSSxrLc2bDIVI/IGFkRPyA2L",
	"oOvSbbAhTr21LraVp/5emJD2VdA8xVrXQvtVaFt4xeSkJVMOW7e3LXIsaLE2ONjNFy/IwEzY8/szHOMh",
	"XLPIGZF3+6sDDpU/UJY9UdCLRjOya2cbHTh5dBC/PwfDQRi4/xD/EM8B/wyTsL1tDjwSIponGMzUmeXa",
	"skOVgbXJ1ZhLWTAq4JrUgqW+dPbNLU6DH0afIOMGE+72O52AxBXv5/KVG74fKfQlU8dLJky/7st+nZ0L",
	"eVmwfMlutMeFUsSsqCHLmudMg+YQWnmgSS1ypuy+ya245TW+sqRcjKfilJe8oMqe5mevjz89fzEu8yFa",
	"1iolL6A1sF1eGewBrJcM3iu0KIg2rNJTsZcVVGvYkHaMQ/uWUZxd0GJIqMgJhWmTJRNMQYn98VSE96gG",
	"DjIdfLTd5tRQ6JJyoUnJcp7RgiiWSZXrMfmkGckKLuBXu/O5kIVcrqGbOXNvTEboXNaG5JwuhdRMj+3z",
	"NvTBNaFEy4UBPRMTSy4Ys4cmouecajYmx1rXJSOUGJatsFNa55yJjLWbNHReMKKNtNdnwZa0aIyVY/KB",
	"LZiylUhBLzWMVbFlXbibi2ZZrahhxXqcfIZbcXVFU7LZc7agdWEIfLar60gsFV7ido0qXrGCC4aLRWpR",
	"MK2JvGBK8TxngnBBzuDb2XgqXtBsRQouzklGBdEVy/hiDeu5tsuy4MsalxAX1v6Gr0boz6i1JaPdY8Lu",
	"mTCc8VS8qU1Ni2JNgk6aXHKzIg9CoQdj8oKbFVPxb0Qq8gDm94CUtTa4yrA38zEQa6dHwTPbwmsuzlOc",
	"gjk91Y3W9wtaPAMC2BphfNuqvfIFm7olvZq5QzUz8pwJ3f8gMNLYjQ6l7GrKS+bscXjCWB7rpqDN8VT8",
	"tGKCaGaGkcXcbvVK1YLlZM82o81IUXFum+NKm317pBfcwJo01vV8yWyDnzRb1KiqY0LXcFZev34TeEPB",
	"S+76ENLYFWYM1+eTZpo8ffHhI06C/+qUzUwbXsJGwkWM9Br2/8GNaymQ0qJdDwe/1EzxlCR7bNfUngRb",
	"Yu29Q4BhsSuW1YaNyccVc59h8Je8KOyuMooKbe8IR2LNSioMz4hmVGWrqbA7vpKVPbeowJSw0325GZYj",
	"8Kq3Q2D2LEFH43iGP38ZcJGzKzv8nwesnLPcMucZz6/sNQ60dPody1UGE3tB5HVmNJgFdqj7XVNVsQvO",
	"LjXoOXY6KGB/iHQ5JRcnWO+oe3BgcgkTlGbqgSaCmlrRghRULGu6DEQHham/MlgOnISX9lC39aeDn+DK",
	"UQzIPGfakCUt7d4raGVk5W438udHh4eH/5Zim4qBV07rmAHHHEyewC7bEHTxnIEyDiriPlhrw0rLdMrK",
	"DLuXGd5xEhiXZasrRu3OP63nRtHMbpWFkiXpHnvbUc7wFmOEXlBewDXiT1U4fo7NQwU7bsIXqea4tod+",
	"4zw9aZ+mw9RpAu6/Va3SyC6nUP56OLDMYqaNYrAsLfqiL9mmwRjmd3r6goRK9qAo57bQkSPcMR/6Ep76",
	"+4QLbRiFY/bvp+/eEu+D1uyCSKq1w5S1mTVr1hoqSGebYwUeCpMgVqgjxyfdlXc3Oeht3eH3U5HC3uae",
	"cV7axtayJpdUGF/0lxqeCcSNzjFUDS+lbEUoXOFT8UstDSUlFXTJgM+D8towZLqWgjpjgiou9TgWHmLZ",
	"PdY94pltWGhS/RjLqV5q3027ilWDg0qHPyMNQTx1xEIxoEeEjC44jQfNkZ95sRJEScvS2y3MAjvHpQoy",
	"ZaXYKMinRDGqpbBU3OMLwmCD5uSC06mAUzFutzqGHR8q7dvLhOuoFStb1kbaTjOQdiqqNcuJkVMBcnln",
	"D9lugM/YEXJR2y0Bcrqslyt3mtsvhBsnulUQalX+2KrbuBVZ2sxUWPptglFTEXaXq5kywLjjARwR7kd3",
	"K+fE78vb3FK+1y0vtOvP7T196vlde3DvmRrBarQFXRBsm6XDreul6jEBiRmrUUFW9IJNhRWG5KVo5F+y",
	"Zxe4K6Xvw5a2tUcoa/OM4PPRHuaThX2o2Ka5BsHKD4zlQ8INqbV77RlZjQp2wYqoR6qJ43CpPYST2Y3n",
	"W3I14mt7991uu220ZP+VM6cou7GVULLdwkJakbiuttV/6crFta97+d6z1rg2nBTCN2IPttbAkv0W2eRN",
	"PWSfZTf08O6CKftua8qgt2vYgHuH40MrCRyND/fH5JkUmts3PplLsyJ0zuFSsQ90LA5Hzb+YLMsFX2Ed",
	"8dKiefeOUxrIEh8jIAEmBAmnPsEFBXlEsYJdpBWgH/wnr4tIjMzJ1SCCgrk4mvA9xrdxD3aXIjWB/tux",
	"uRhTLA7J3uX2cNd5BVG8xhQcLe02HdVVmLu+4eBuWtnbW89umpKq89zyIUeyO9j3rQR0Pfzq+/buy7j7",
	"mP+X3o27T8PzuFmzJxL2m+USrezpLRTu1K4HYXxz7jqo5Em64ahEbDfNUPvu2g0xyUlbcCN6VosX4IIL",
	"WtgXesPyEgIkqbVXTzUSG9WR5uQGhm1LJIZfayNL0LwGu44bhZGCDe0Dj/KCwO08dLf9umCtd+5TePOh",
	"4lLkjbJxTE7QrYhkMmfEVdD2OaHsFGDzmvEtFIbPEopCu8HV2h5WqXKmxmQXTd1X0bvdR4uGr/IZvsp7",
	"16X1do8XJ3oKdmOakhvZLIr1s1Utzplq9vKOzo+22rvK+VF2HR+TR6CQGS0I9ksy24LdrY5B+VdPo6hX",
	"RNVCNwVzrlhminWj0EP9NF0yIuxuqpTMmNbDqfAPUDzTcCYEYVcurukjUyU3DOKbeMbG5MQJnprb3UgW",
	"/IrlI81/ZVMRdHyjObWvnjAa2D9CkoxmK3j0N3qSqXj48JNmqHG0D+XJw4dTMSIfagHnU4PxdwRjzllV",
	"yDWe5T19SVVJSpmzfVv+P2VNcikeGCIYy0nQjR3AIELPNFNSayCB9tXgVQ68GuK4TF2BcbNgV2CY9CP0",
	"lPC6h8Rgy7owHMdqj46xchmeVt+/YnmdgVlFmzAAGPG7t2//54hmGSvcRR6oZ+dYtEdbMaW5NqD3tcUO",
	"wnyhJ6bbWqAvqHW2JfVg8t3hcGBXoKBVUI3Z3/xWsmcU9t1gONCsou6MDiwp7HGhaslMVPPwOpwQb0EO",
	"RlTQdcyonq1lPXN+T+dsfSkVBGxYpjocrExZDIb2bmSKZ84eajiEJ3o9xnBQWDYCtlC4jvCfekWhzTB/",
	"W6WQ8x6LqFkpWfFsk6HseC2F+oF/XDByfNKcwb1nBbX8GlcMzVzH708gFOqCU3JGKz47Z+szryVW5Oz4",
	"7ccfPrx7f/Jsdvz+ZPbji/88I0xccCUFvC3AmWBeMHdUnNGMvIEeJg8fkgy6HGkpBDOjJ6PvRo8OH313",
	"+LdHfyN77gW4P/SlZFXrUObo6PAofHk8+m60ovy8tp+eHB0+eoQdPpcZdLMyptKTg4NcZnpMPSHGmSwP",
	"mIBfD8DqNsL2DpAEB3afXXB2mdqPfgc9OfzbX4YDqDCYDPrnM9jcojgG2EdlZdejVmwwORx/f925x5Hu",
	"6VjZZlndWo3JyQIe3F4eHJIFLQpN5jQ7txdmZ83SS5a6meOJb3cQbTTFXuDxUrXXeI6T0Y+OmJGW82a6",
	"domyqIsC9zE5ee7l44ZS+MVIexf4yL4H/V08aL52tuCD/ZZ95OaBdiXYeOkTx9goWWiiqMhlKZiG2NFI",
	"rrTi/Aif0j/w5YopdDPSpKTnjMjaVLUhpVTMNXG/F7KR1ew8sQllNTon2hIALnkf2j0m70Sxxg8MxVqn",
	"7iE/ej0RmtNACVXPNfultjsQtk16Z9ghVKko26xgtU4MIibRcQFSAfA9Kzc2tL8fXWpVpI/mpw+vu3vP",
	"nlImcrgFyJ5/pAxRLHEbnnA8wU6txvL91ghrxZOCX/yuwTOUetY8pdl5XZ2IhUz4b8A9OLuwF3TKU9FJ",
	"dO47ulVkisGND3YuaLt1IC6Oxofjw9Tmx8Iznqeph5+JfY4bSwS1cc5AQhlhKThko8Oj0dF3qZ6sONrn",
	"eolSpS/h1ysxEf14cnBQrtH/9wAp5brXB244BzePAwybCdb5EX4PcRieS3YH8TNgHzjFCppVP+/8QrZ/",
	"85JpQ8vEGUKbUUP3S/u2xKVtkaGZ4cejw8njw8nh4f8Zb04r/Yyc+HPzFm3WPx5YoFK0bP3b+DXX5oM3",
	"n3VxAXB1EnGTXBvwCgx2S190x6dhdIhSKvzuNPUNk+h1p7rhhHwS/JeaRafDyXlcu6mAv1GO9mDvwRMt",
	"L/phgNMPkZW7UPR4Kp6tpLRveVIyap8Fi7qA0Ho87G6Lgq8TO/B8gItghtmw4A4653N08eieR9QLtH6e",
	"p3VVSWU0PmAqt5hM5Oic9RreogteMHxQT8iZ/WNycHBQUbM6MPIAWzoDD8uS/ioFOX08IWdw4vG8jywJ",
	"uuXReOc5lacNLQrnVJVTQ4fEeT2gBqVkhoKjmJ9GYPJYZ5OAN7Id4AYjqHcj67nh5G05ZCZbRdtz05nP",
	"ZCv7omTKDEnOCmYYTjKY9aK9ZbkadS9i79vi3gXHRpY842b98CEs2cOHzmtar6jKHz6ckHdNM1QxQqGC",
	"Vw9AKYwaporj0/jhwzd+N8BnbVsBh56cW6rMwW73aFStqGb2xVxyQ/YevX+GoV2uA3hvj7D9S8WNbdsO",
	"+Ad52WoH5kszHOClVOcwkaMxeeNX2yGs0ALozTT54fUzErge6tZYwTJjX9cS/HCNVDj2qXg0Js+iX3Eo",
	"ca/Oy3BoJR/DM15RYTSWg2hFYd/rj8fkeGFwFP5XoussY/aREHeL9Gj1MBVPxuR93LrzmHJ+MHotspWS",
	"Qta6WDs3FFlcRN1/NyYfWGbfVGtSSFmhOxbTrpHMrS9qLwwj7IIJQmHA8dgWlBe1YrgQ75kC1iMy5vYO",
	"7hy3ZnO7Q5mekGl9ePg4I9+VmhTUMJGBz/azaHnjJZyQ/+vRYbvoCcwCJ1XbQqHNx4dEs0yKHFZem1Fm",
	"d9SefTGreLr7OOJXNVVUGMa0G/BxUfgFdWtBnPejnSnZo/5wePUPOK/Cngbd0bMubQiY9aFvYEN7gl2S",
	"glHQtDFdl5tEh4ZOclZWcmOaZC+vEfSHbayTXX5NF8zN6ykTbMGNn9UHpyoSzNjzEJRmsLxU4c3ERc4v",
	"eF6DLwM6u4FDvr2U2GLBM24HA+wTvBzqClBXoGtc2hxGfuy9Fm44lFa8iZiRrqhjHNqzcWRk2Hpd4b9H",
	"hF1xDZ4q52yN3+xU7IIZJobEUjZ8cfLSeFNfgKxRe/lt8v1f7WsQ/imLfEazgNXhxmArweejR4+dX/Vg",
	"8vhwOGAl5YXDtPqH62GcybIBx/p3uRLkOcJd0SX0mYE+2Vl0WcnrcvD52vX/5Lu/hA4efRd1QAXr6YAK",
	"Rk5LDohcnS4+A8ZTW4wJ0+91eAx+oCfPnWeZrTEmz1suoIqV8sK7pCEPg4sVbpG30jhv7LdSjGDVbINh",
	"bTQvmDDFmvClkIrltuRz203YzE6pzHIyZwupmg3hNdBWCoJtZ+v+6BuumOU/2HZrhF5jDS6CONL2xti+",
	"G3YW7KN90xcK2xMsiJc9KrmpmnOjqFqjhk+T0s7Wbv61rJV3FAcReJwKgd1UCFXJtW33rJ0XyjlbW7Zl",
	"CV33yLYs1IUVf8q0IZWyJzxzSw8u9lLoZvGt7Ip+Zitm2Z7T9kzD8ZoO7F9wrxXMHgcIN4f1JQUTS0uW",
	"xQIu5nhBq+biISNyzlhlB1g62xydF2uiV1KZ1lbRUgE6FrvimVwqWq3Q0WpItCQZCt6VYgt+BaZBaohG",
	"2dZFfOuMio5y/L8sn0hsICtEzMDcuO0BdroW2WsoaNvx4uZNPCYpk9qNxcWoKmjW7C7i7xk0ub6RYimf",
	"Px2B7dNVlgq5zsdUo+DrDi6TRpJS5nyxjuy4jcWK5iP8OkJBTVG/jzfFXYhcyZ1UCuZN6XgSiJVwaXpx",
	"NxpIxVQzqbghKzSDtg3DysILyhkx4jb2/sxFNiR/Lutif0goUjP+XNV6NSR/ruoCCtgnjkTx7JksSylA",
	"yWplIpzaicgUa8KUmdJWVmKXegigS3pILiwnhzP4CdahEZNtd1mtFBPmOTVoOnsDzqU4ME32aJ4fIBcm",
	"ds8NCfDQuDUHLuY4nF8Nf6l7G7tlParZEhuM+wtC0wW2YY/fcNCQBYrIajAZWOrZ84ToNn8eo0d7iBY9",
	"uh76gtHE4goF1eafnF2yHFwBfc/hUPZ0a1clbgYOYOh2cMEr29yujvVhm+/isBiejX1qGbzd893QEkEm",
	"1npR213va6Z0w3gF3qnZUDWpc25CK+7QdFy723qSeCxXMjt/ATZBdlsj30+nxDXQWJHbhnd4BNtymWJw",
	"w9LC+7RGZiCpyMnxG6Jk4eSrpPVOrphiY+hoxMSy4Ho1ungyJBS0KGPDDRUj/GzYlRldPJoc3mSZu9Rj",
	"VzWT5cEcJ3Jgn2HagLIDogSdeW7kLkeWj50NNjbReYNceohta5zrCPBkl0jeWo8Y1WZ0NOiIsyACzhqU",
	"FGejOhomldgmWxFbFk0dYUni4B5ZGV7aImalZL1cVbXZahjb7MgvejB6bVq30nR4MCQPblqsjnmrl5yJ",
	"+JVlUp/30W1T/B52rp+Ac9UIAw8LsTmUZoUSndt/VTPBLmcFF0zvFDIBQTBGEqgLDzuo25iuuKhqg3FX",
	"7oUQ1nO8PXbhBosMTv2udv3oyKct+3B+3/uYWArcyYkmzJ/9YKAags5q6BShQ/IMVnxI3tiXtQ+KhYCh",
	"fr4QWdh7zaGji6PJ4RDUoeOioCV9PHo8+v5wPuJCG1VnxhVwu1PICzqqlIRfvxULSfjQ3dfi/dUP8s60",
	"3TwvO1f8+od5/E1t37+pUfvrmKXHX88V/Aa2wsXyFFyYbuvz9xObtypasXNHlxTbKcHK3iEF4kc0M+Tp",
	"ydtXs9MXxx+e/RC7npALqpJgzd5M3nYF8cedVnw8t6y35JmSWi4MnPiL78eHB+i51XENgcG1DPCfPrze",
	"alkfDhaK6ZXdgylAQMCg9KFz8zVpCjdwHM/BQfknxqyM8UYKs0q4eCVCf7Z7W77xkycwuZ/YPKK+Y9Cn",
	"zNQVOPsdjckz0FGS419r+x5EXROhJnBRyw5pMab2uyUoGh+wEiXx8no3czAsvGImrLdzYXbA7udsrW9g",
	"2O3VY2JU6wO7rG4NR7Ti+MPoks1H+GPbMau78Qt2wU5Ezq7++ajZ+ht8nZUzKYp10hDuJQHLd0tWSrUe",
	"SfBlQQVQ966/hfP5jaM9BSSW7oOJ6/NZDeCpCXyhX0MEAGgZLZ+crw1rAfLUXCDWzu3Bv5wrP/MpCTbC",
	"Yu3PpERoV8IXDhgok3WRgw/LnDXe7PcI4lBsXvMiTyJqhxVrSKCJe06DUjZUvfPCWR5vaDFDPW5+C6B/",
	"N6SvuRjJXSRlAfim/+HD2jceLVIWadicuZR6a6DkUygUQ6tusTDb7j73jJNR0T/KW43FwxPvAko8KOvt",
	"bT+T4l+1AJtRq95MSLMDLG2nrl7Zg3D7mj1LrM3NT85jAsKE5ZZ4vznRtHauIDnLFKOaEVB7un+jQ6YP",
	"JoKMA4DCTxv8h8a7R9ZzCAARdVEgTAMGy3cEq6eKXrDfXvywvfbKHx+O//liJ8njpgvff3Lw0xNS5X/P",
	"6XpIqsu/XzJ2PiRV+ffS3vFDUq3/vmZURZJAZZlgdWn/U9r/rJO+3rpiRZGtWHa+Ky5BU4NoDKhqoz3G",
	"OFnsysxylklFo5Csmx7HPpIHnr5RTbI3lwWE89KCZxCyx1ScFKMfg2sX2WZzMdHqE/8YgJ4qxS9oth4t",
	"ZAZ73cEUgFXLBzRbPlwxkQebcko8OuVLQeoqlojmtkeQTpz0QSt+AGJRR+jJqV7NJbhspAQeK7JiG+Om",
	"UVpVB/7OoOhpkRRq1lGmhi4smL3xezy2HQTKoxgP5VHXhNhBOe8+yu4Mcu53f8lFDeNcyVpBqISViy9R",
	"LoYzA+AOVBm4DuHspM4HRGY98/BN7feBFDOUVRIbbBe4J3ttQwQamCtocUnXekKO4X8h2AyK29mpHOGo",
	"FkTWJpMl2FJ89xPy0ZcFsI01ZldqwhpcYcNLJmvTKu7sO/gF62lXXFk6A3pGokYDrREqRcTHqQyGMYWa",
	"AeAfTfP9dIeIuK6dzbt2AQAX+Ho1JEX0gHb8MOJyUcjM5BeygxYRL/HWUL1mQ9wzPg+Gtq3eB1soCsiP",
	"xZ+m85QM9GxFzRYcvSyrS8RqckkYep+eCMHmCvuAeXbBZQ2xoRdMaYd6WStw8Py4Ypq1rIEOEM+BqrQx",
	"QMZT8ZZdursOnOfArcg7KXMN7QYcKprn2CB8Krg2nZCP3XHPcIKnFctSLg//7bAGJy0MwAbVr3V5uJtv",
	"TDxaCUqgZM6mAhcR1wdYhvNYJRJ8rTabGjrYjrKsBTdrUklt9G1R/lJBu8AH4IwdLGhRQFySByLTQYeY",
	"AR2X6O3x3xLa77cD6gOt9c3QfLfHuXNKAZ3U7jZ8CYQGtW7ixQH40bMw3wjYKygHHKQo5v3jipGCahM0",
	"EG67m3XlHCXmUexRrcEYsmHKDwkOBy85OGgTZ9bXDoqzhPBXRgpGlUA1gpKFz0QJz5OmjRPMYkg0A0yJ",
	"bW2NyU8w4LWsMelUyRDNENSK8zWp6rnPuQhC1r81vVteYlmW2RjCfzI9xAMeZg40ck+R1tg/775RjU/g",
	"c50G00v6mT21L0zEzmudU41Qhs0hxyvEecsYuKNco1OBAdkIhNVsHLcLhsBs4YD7W6rlgh4iG/pxDB3p",
	"Zk0cbhrL0K/lN0Ik3AnKLggPAchuC5rAuwDY0gcr0OG2nQBSCE6jITwtXgZakA/Hr1xz4/Td8HWh9nYw",
	"tXrOczNSXCSH3Q4nzv3vaLOBLmTcs2Z/twDj4n2sDeSsNFIWxPIsFygSBOUNqDgvSJFFIS8JPmm1PRyX",
	"Tg2aFVQFGQPQtwDQFAMSThbkzNbgYjlrFTwjIMwwzYQZ4pYowP3acVSfCDPGk5kKQmCsl9SlG7FMxdnJ",
	"nYm8pOeIyoAgk03gxyMcDM4u0fum7ApKXRcbMAabw5kTYL2IfGbHeokO8oEVZGAND8FRcbO/Ez7dFpi5",
	"0zYYI3rmxEBznOlvCDW3wV9uCzQXMfQGZi4SnzeR7KZiXkdhZfYQNGhyrS7+90WCs5Peie9/tAVvwoCL",
	"b+nECz2YaUT3iDkxLPUE9+mfN0zkVpJ2X/2DqQwp/roeBLJgtxAyPtjijjYz4IopI73nmKSkObPSEjzp",
	"vFhE9lAIAkBB/5sdx/4txHMg+jNaFMl4Wju63QAjgb3jOUbVaRgbfLnTsG442fF1CKQfhpX8fPPG+SCL",
	"FNqYLNjGKhPNAMI4sZsirROImcNIVvUCywDJ16dnauie2MjhrkwvfJdPqCXa5PoDJFKCyLGv1iChOgwD",
	"WRCqyTlbjzCxS0W5SmYFu2XsbphY6ghtz7kK1ecMkXSKImFx3dwbEAMqMJl+Q6W+LWLX5G1yFMchkhrG",
	"YFvsecqPCM39lT0hx3lQ1vsrew/hZTIptFH2yYfu21SftyWWCTnW5yhxAARt/M1WwGYn5AVenpuY6Bgn",
	"esnmvpy7eO2AL9mc7Dky6aYMYgguYTgLZmyll/Z/AOnBs8I9XWNIjZFEs6xW3MDbB/yZ9tsa2UAIOCEb",
	"8wMAI+fHEoYwGA6g5xuPzS7wjo4VWdGstevaB2dXq3+bu0EcYmrzAaq5F7V3PoZu2Bg13eCIxD2mU4O7",
	"qyMZQN/gwjTMxCAessY3jkJJO7encus5anUWpnnTOdK7u3lGQhXICvAWsMKzw3yewa8gQ7OyMusDWXJj",
	"7MMtb9DXJ9G5G3ZP09BrDm3bL+3qoncoqDMRm8wHIwUMFUc3iM1E98R34Mq5P5wK6p6EDk0tKPq4Rms0",
	"vIPQ07NW9nWPaDUVVZqLZUrYa022H9MBPkPOBCgPrwygSosaxBNigwgYiO0I0Q7Wa53WxMn8fMvbGxhp",
	"KnutPd+O1WxVkduyba0f7ERuWMq6+91wBxdWfxqaNiCQyL7BxlPxXrEL592y4IIbBsHN6OzSOpJIv+DU",
	"+GirvnCTzW6be8dNIC0RR/CFyceMe5Em3jMew24MMdouYAgigP3TfER+ZUr64+bRlyDgCdEWw5YbJz2L",
	"Pajdds9iLNnC0oqju9J+qZs4ef1OS43jsqtD5sxcMgZaNg0reuEmpcfkB1ZUuqOO9fHpiFnYwDE4ICg4",
	"9fN1hLnoiaTTo4/Q+7pvZPeJIDvGXBdVwY2JmNGD6VRMp+IBfLUVIORS799qQDF6Tws6sAviYz93ncHt",
	"MkG7Pb7DK8X0SqbyVfvslREqcSjtsrx4MuTMsGwTE6w1y3dv3/5Px9PH21P19Z+lNIKoFGwHvZkDoWy3",
	"cz3c9nrvopdiJFz7PC3qopiBvQMd7m4lYnTvXNscxME0+APNMeSCgNumz1fkNFdkDzAruLtw9oe+vDeP",
	"At6Ou/sm2cJMiK4XC34VxYjnofEHmjgGgbzHd0bnqCVz3yy3mWStloBHhcW3s7lgmYnjj9rpNnZPBuec",
	"IZvYqR3AY5l674uDklsq1mJ8N3kehTiAoNwE5gKiINcBSTTHuB3wzh0ToBI01wKRRHJZ2jRQ91w4B19U",
	"uVqaNTTCmG1YMtco5lQBsHrfnMh7atzLSzgWLQOxP3edpo5JLRCApXt90QTybjpIDjjgYCuuqsHj24ui",
	"urnayWiRzpico/U4dhPCYLymP4fomnzzxPJbL1TRsVc8d5+KbfNg55qWfbJDsKsUTvDUAcgc1ZLN+xfe",
	"qCaE+NsOB7dBd/D69h6KwmzAABaA3o20En48q8RLzG+xnWPjQmeRccE34/X9gKLB0t7WiXQ+uhd7qlfn",
	"umNcXFvD28Fgp4IW61+dFwio5IdT4SGY7G8Qlen8lDDfjjaWaSzX7Vw+ulEsJG2OG+rU/wrY5gupMjYL",
	"ueEsm9iKx+AKg8Xhja3QtOPItpOx4tQXvq//Q10YPqtWimo2ixKmu33+eNgrCtMIJhQN19AKsPdI/G4F",
	"bG1/27RSL+3ucduX8IldVQXlwp15uL5osdZcO5R+JKKDFGvpR25wyd08c0kDVmfr/gca99unrWuBb/Qq",
	"5RwH7n3O1oSJFRUZ81ETduqA2dKZhnueu+Pm4qZpn+tgfyKc9mAj+fq3TpDhUwfOerIRutvNp5hyMD3g",
	"ZOdfXcnEAGRvVZdUjBSjOZ2jaeGuoTfxUUoBrETnpTkpTreGo4bQ96uKCsxO4rczApSBuegrJ/mw10zr",
	"rLUe/V/pTDkTjpf9AWEMzvmGDbmVYM0pse6zHkrWhiEc/TYXVVsSUO3hOX1fdh5a6Nms7xyOQR4tOz48",
	"DjZ075D6CbTlCKoTeTG0hjkhDm4fZakHigFSzoMhWa0raVbMYF5jlzrFFok/PLgHla2QMJvT7Lxvtk+V",
	"BEC9eeNm2kzbH87EFgkbiWvyIPTyYP9eY73jDavr+U2peZ4zaAQCKur5KJTcOq3cV3yw/80z+ETHocNP",
	"O3t28xhEtGtZ8tMCKWA8/++P2futsLX/9wDuvRVA7y1wwWdgM93hnYn42JCK2BHyZEGCxSfMwcNkZucs",
	"J3U1TmEP3hVJ/K54whtH6Gbc7t8CGV4bamrdnxDOdeWKNRoK74gG0XxUGU4LKy6i2fNzGzGnKbkzIPwp",
	"9BfycJsIonzXBx5gyiOhsbVbrWLAYHczv2Exf2C0MKt+Eq7guyOhlwvdIsV+IuJcyEu7R7GCZci1aP6d",
	"s6WiOYLRg1E6rQyCZj8gk/w6PLqVEcABGwMLXihZ/lasE/MwRePg2usZvz47chMMgmITW2c3+IwvZgCv",
	"qjsRdj/IS0ugFRV5wRrkXNxMwNPP2i2cTcjxXCpIeEHF2m10Wthnyxob0O2IuTMrGbQaOD3n1WZfw+ae",
	"BKQiqOkh/tjZhDxXsnIZsBG0d7OFlp9GZ9rtQTjNKbTdPvydcl+N9bv59fL+VgoJh56b3DC/60UQDmrf",
	"TbCNP/tl7jBoo/hyydQODDoueT8G7QZzKw7tKLAji74FWz4NlLvJCrbhJleb1cy9UBMeMyLniF3vjTG2",
	"vOWTjTbYJyFvlLCezydsIXbf/sqUdDqwa8/6t3vjxhdPE2l0wwHyrkpodIAcg5Db0ofl2LG2LqqtDj9u",
	"qMkVAMi0uwE4Yt0+7MZt6dievfvhxYcXd8zFtgHq93h8GFjvkBwdPnpCcl7q/aErCEJ7wcWypgWUvgHk",
	"x8EGZrI8CC8bzPrXNkhB5MDMEx6dQbyLw6DJstYdaRvPEbsb3C6RmqN8yKL2jApCCy3BbssM0LxN393z",
	"psXziu/T7hQ32IzLDeIypa8r8PTE+Aq7Y2TQuESW3YgLdtt3v/jX8IYb/NALMC4Gqgsn0E3NllyMLnlF",
	"5Kba2eRxQrY2al2y9S6bVrWwrKk9shdvn28RUYCSmhRSLMG+RfHWLOkVem84BPCYpG/fvX0xGA5OPx5/",
	"+DgYQh+f756MCylxR+RHR8bedI6yLBGOefd8jvdiIBl2OFKjqqh1y/buvzT/pKPDxyAf35ZtZCtqbpGQ",
	"sTWmJJu4bwbGTcaxJf3iXXnIQiFi93pWMUELs065s8EHF1Vg92+o9LXwEn+/DJCbC7kTi+lnLJ32OgRH",
	"9WbGbkNvX+erwVP+kSDyv3qCyFveBR+Yom0vu1tcBQoq/7ZiI/aZlhv3h/7zvaVFbCftv5QYwv/iAmHj",
	"/DurmLIC2i2cgFtpHewOsPJL8wvINm1M6ptZa5p8O/HXZsP1c9p0810ZTlYzcZOPcim18UB1JoJZBG0I",
	"eKf7qzek1Bu6L6jab+fgcEh34zQs/65HNhHRuUtAR+NxQLVmWoMPN3lhuTNmuEKL5i81LSDzl8inIiCq",
	"BrA+3JM1mn6A/hkt+BxdG8FBOJMKdVr6/L+uO5JHIOkOExENljXPAbuwl7SEVpWSFAI2mo35FJMFMXWB",
	"PH+EDqBL++8VX67itvgiINpqknPFMlOsCc1zBWDqUVB8Gsk40qnc5PfjoA+ijt0SJpH87u4gdZ3ezG0U",
	"ynvCc2auPd1CrNsJqvNGJVjTbvJIgjrX6dZ69P8tmvfqjNoeNCQqFSLHUF0tcsAYrGpVSQC4+qTZona4",
	"eC1wJnCLYrQkmSwKOpcqaX/9pJmyFziYPvFMRS7G6PjfcqdAYeQ1vFXBGzepgnBwJ/0Zwm5aGgAobtzr",
	"kpm+EHsXDc/S/dUO4ScnOAqnJyQ5X8D9bjxEDK3onBfcjgjsBS/bXvgupvTpm0ffuanbQv9E5/a4REMg",
	"hB7gZh2SJJUyp0WrNC/pkukDWudcHliZQVrp5D9lDWhTNM8bC7WvZmQIh9ucREWNlSN1Jw1gWMQmQiHn",
	"JROYa/vxX58MXRH0nfbSDS2KkZUvi7It1EiItYuPy7kQs4tDdNUBNU/ox5VoYiRssRQTEHU5w7SIN13F",
	"WAJcmtF64uVQTGFLnnv/fKoMbDWW++ggVzVA+li5FLKb+XQSp/xXe2W9qnkO8BEaoDlH5LSEO5waqpnR",
	"ZA/Tbx4dHv5oD5nen5Cj0eOQ0nFE3rCc12VUwRYdHb3xpR+Pjg6j4q+pWrLN5llT/Ojw/4jyRUKKSjcV",
	"t5fnzC47vCyKghVcl8RBWzjIXZcBc0ycu0YgAbuqWGavbMwUy39FntLZTZY6GIYgIW4aBnEKgwAaTYXL",
	"z669Y8XDh1JYGroUuYq5/LNciocPQ+6rXF4Kw0s2hlbLaGqXKyZc1q6QqdPP+gpSlWqXtwajkjTZCwd+",
	"XmCCLvQPdalUAzk0yWtgEwXQHcdnG4MMjgz8yTv0XPjct6MVoxdryLRbSIpL8slBGYOrkOXfZwdhvuys",
	"gfwHOQZMPg3Soe/fR5BNpuLs7GxO9Woq3r87/UgOZr7Zg4ujqF0oh+4kYP34pWY1QCXFpA6xB+COA3Bc",
	"mIvVZ5zUG+lzh81IpiIikHYmy5DlFAwZdtP4pfTZc2C0qq7c9QJJlnMrNwOWmt2K5EVBteGZi37HM3bc",
	"RxCyJyQpqcBUrSEiyl/LsNDvcKsFzySo4/cWlACH4ooqfMQjSKJPJ7sHmToVK63kiTlqOFwRtcKeGnru",
	"txnr4w1o9XQwIdxjO5nkTrFoWkYCdmcv6F7hggtuOC1mlSx4xncy67oqkEqUax0UHwGzblcx+n1oAHl5",
	"EqM7yNUV1fpSKhBLYweCTD027/+h9eU7lceKj1A+IV7YYabxKT65L2FGgl3irOxzzWtJvV6womblkDUd",
	"DAQV9sHtQ2ylQrhFyEwaarQzqzRz+ZdciVyyrca8MLMeidLnSUsitTKtZ+dsnXQnOf7p1CdcshfdyfPI",
	"681ueDRer4WhV05uyRQzpJASHLtetjTHxz+dzo6fPXtxejr78cV/zk6eJ/UN9qkCj2Bm2sRYy1qNcDCj",
	"c7Ye8Xx70pWWMerxCJI3GziXgZ/6YFv92CVeopd6nMkSITLtmS1WUpvJ3w4PDx+4nCXi5N3+htdKu/IA",
	"VGpeoj1KeW4BpWYN/dPEdwRt1uC+C3D64tmHFx+jdbjDImAn0VokXdMYHGTUtt/ARHCWUNYr/e1BY2Ul",
	"IZVvlObvVnNPDRt6GeGI0kxgpnWxO8Df64OPr0+h79PH9qkgmEvX7RWIEwi5hBLHP50OXVQn6rwyWjRb",
	"aZfolufUQaifwoi/yiM3p4bZ+21WUaVRbk8dqRZWu60zspWSZp6eBBv2BefULDPXYA9/jxQETRVtqDK7",
	"VQpFdxlwks6b6SzuS2PX3r0VCcBU2jPz+SxuVto3I/icnq+hImvg+TcC05Us+4P7c1eZ7IXF2t8enx/5",
	"yvsykFFmqwe997TZjiUVBoa5p9GhMK247dddN7MLSsJvP7uNxYOp3rRunwRPXHf+K6mFA7dcMtlKbAAv",
	"o3JCQPCAR+R5OSHnvJDNLyWfkJIXCDa1MBOyYAySgq/zCVnjczKOfB4MB+d4+1kyWdKs86QnxnOZneRf",
	"5XjxvH2wbufyZ2sniesUX6dB8N6MLVlAdk3IYu1hgDDtTLBkuKCOWyjvjlNqulZ7SXNM8zq4BTgcuaAF",
	"z8m/n757S3CWJLeT8lDjvtsHupng2L0UPQoS6MkWTDUgE6oG133hMlTDmJNoDWnWW2fn9v9eyW+VekfI",
	"GWTb3XbHf8Ak3D98fPM6JITrQe8d2kbtq1bZWWxrGPx9f/j48T3xVeBwzqmL20N41K+SgKahJjkRCB+J",
	"WKIhG01UIiQCAOBoyMXAWJyIBpO+25ODgLjBsjgVTz0ygeZgXXXz+B+kpGuQI9GM1YDCSoV5BRySnXvi",
	"v5WGTR4+xCh3wGy2+7A7dHK54tmKrKgbbAgkeilBKZHXGOBYazYEEwk4FCGAr1dA+j47Ftw6O7f/t5Qu",
	"uw1P57N5vha05NlHVlZF8NzagGyoC5T1SlpVoOrAOhRTgRtUmiEu05j4ljDuBVIh4bMSzFVTAbr3FSML",
	"rvz7EU6qq/ZAh27c4Rwn08FCka16BNcoZGR74+qA2ddkiVCJV4Wce0Ufgs/A0YdX8x5At8MjlxUQIr0/",
	"noogxz8EVgHKvCLP7H0yJlG+iIeg7Z0OcL5Mk+nAcFMw9/OQTAdzma/dn2n0bqg6czOPnBgTaTDn0boA",
	"X3QcPPgj+sjGcNE3/sA5BtW7HfJ5Z/zL8BDqxNWxsLhkr45MMmxeL5dcLJOpvyylZ7uuE+ynGkzLoJ2w",
	"laNH1sOHbvu6vRasCJotwRA9biX3CBFmDx+2Viz8TmuzkgqXLfxo6FKPK8VLqtZ9SwiTqkXPtN7D5kL5",
	"TAo/QVDPcBPGEebqVTQRebkmViKrWrA30buwr+cXm51u7P6NMfT32qIjRF1YEl4CcjnMLGcewA2yLLhC",
	"ZsV1mmapy/VFnoZVtgXzIblkfLkyGJnvHrIBRS24HnQt8KBRzGfUJBNbolYMUtdcUu3MLS2tXP/j7BYh",
	"/m4z3U4CCicPhhfauDusFNrX00kk/vJkxEQmc5YT5wYRxDpUoNycCu0WiT4B22jrILDYNxtEksu+gAxG",
	"6ypkA58OMm6YRo7gTJ0zI/Fv5BYsn83X08F9wsvrKr/FFoX7ylX52vsUj1gPYfDjwQ5oHj2v/jsGoLtd",
	"G3aOazaM9vPdD4Sd13OQcbtp7upuuEAoCoFJuUubA3ZEeKtCnrl3tVlKwLuAAsHvUsgcjG9cTMiJyGTZ",
	"lHGw177EXJrVhDyVZmVbxMYQwC6u1XrX4mi5gBs/lf36djT5uK7Y7t5WlISMAsyfoC5EeFHIy5lmxWIG",
	"gKZb3yFRnmioG9OTAq3gdWdsk/dJPBwUghtrHRwAPVq2ceAljjPBCM7Zek/vIxWCbQ+IADcJWgeDvOLA",
	"NPdcJj9saJ/YyvbtD5Z/KKLJXpBlsBTEFwAzCNGISI/N5FgAs8Izbgr0R51BsVTimFtcX/RqFrOGvvS4",
	"XisF62WH0rCNr8geQMuYGs/hsEcH+K3Hkxacm9sEHxrOjgM3yoMhedDcJw/2bwKQm8XSw6YSwIHD+SJe",
	"CAvAF/GB3B0Qz8hKFnK5brNEgHfteq66shGgfKJ74I9GMTYhp7j7nZ26YgqO0pAISbJ15lR50NeEvJUx",
	"Tn0cqtyKRWV2eji8O3O+XbWadll1f0RthIXWppKhReRqjIcX1Q5xaGxkUociO6vkQXjeIQfNcNANnLwt",
	"zuwrKZfFZgDmNpzZfzJl2NUtKyHe+W0rVUwcn9yhEuA5qVtWfMpyJbPzW9ZKxrBuq+TwfTdrJcB6dwWQ",
	"9U01CLJfCxxV9MXY+i61dz3wlT1wrwmKJiNdUjX+KyMreRl5mFPFpgJTojh4WvBidCCZoetYbVVrRn6A",
	"uMQ5VdobZsH127saXlAFWRHnNS/MiAuyYkXV6OJ8W+QUAXPQqefhw1No6uHDSdy+mwZc+F55twqf/wVm",
	"+APIlHqwj808g9yFS9tOW9nWyhhLMpqtPK1ibzDy8ePryLD7HcFs0Nq3jl7e7dYVyxiE4zSKFif20JBx",
	"Fef+1JPkBySJ84g7GpOHD3Wm6vkPpiwePiQj4jTTuFMOEIDM0KXD8r0yimaGZFZKwzUDie6Hj29eQ7qz",
	"s7Ozhkrwy5cvoX2yMmUxc5lArq99Bfhf37EmZ+i6iANAP8Mz6Nx/sEPyv9uRufrHea6JYJfgFUnoAjRu",
	"hczOvWZQk71qSHJ+MSSro9HqL0NS8CFhJhvvhyFgOAQg3eH0YJ0gbk1dADwfzdEHd23p98jSj/0ChHvh",
	"wxHADURx3UQzeJWB7qXRn/iC7LFfPA7MdICZ2aaD/evrY0zSVmumvnw54AtHuabSP87Z2r5wrRhPC6hz",
	"iv9GgSKu5RzyHtuBlyznFMb+iokfuX2uG5f4ED45T36fIa5s3IPdGvZOB6vXqvg7OA8/p4Z++nASBt58",
	"tmLGGMrMalUkCkwH/vQ5dws4eFBj/K9qOR0k6wDMi/fBcVhXrlIl+iptwmd1O3HEI8RyDWQ6LIf0NmDh",
	"cs64sJXOrDw3OSMjgpoR4jUjIOd9+nCivUiJJaGzg39VbPk/5lBhOB6Pz/zGPLNEmBwcnJED/LeGP0bk",
	"Jza3/Ts/+OYR49PtgAAb4O99a26mtoFNGDHQX/ojhVBhtljbu8lhiZM9FMI9ptgmwc/Z2s7AEazxnvTo",
	"hu/RwZOLZUO3hw9PwN3cMrrn8lIUkuYYqaQhkn+PL1zGRgicjm6QQNjQ0vvnLzUyzCvjWRc6yaGVo7Jz",
	"UJCmi+WWZcIihOqWqdnqH3yMg2m3U9uRkzfyV14U1JUKnAH3iE9w5GNR/Tz9zPCCqJR0VoH5OqxcSI6k",
	"GfiYarKnGSPt9/sHHwC4P/Fc0D2WVlIbcrnihhVcG/fxveIX9gI8eY+cEW63yqcsOT398JJQY2h2rv3G",
	"8wNFT2Ywh8XuR0eHh2+edsq6nPlxwceHoUlYXxJc+7uNPjp88tfqagi7eeTW3W+jU/sE8QcA4ZvGXEJg",
	"5EFLjPmTp99olEGq/6l4AswajuFHCS7eI/IC/nSI+YJ8fPfuLcFNTfY+ynMmRu8UZ8KuzTvMW/VWGu9m",
	"28P8mi7gFTXGR11gOenPDkvhDVXnTP0dHbm4yJkwf3+yrWrO0Kiq/j4dTKcmya5+AqxDDTP8N7cLYbaQ",
	"Lh3OdmaGm1E9jhQ503wpXNRcReHIxtmJgHxGktev31hhixByYhqL78OHjw9Hfzn8/zv/O8WcARUxEexD",
	"Es4vWMQuV7xgIXeK7QZCzV6/fgPN2vKKrdzOoVlWK5qtx2GWP7I1eckgKDnixc9wdl5mxHN7NjmD6Wxk",
	"qfPHCDQ6uCakhEXRE3JmxY2f//T484RQPkTz8rAsvATzkc7rgipPNcj4Krj9y8UueIr5XhpIWFv29es3",
	"PsETyDutpPuuxhtHGY0rtSmPABGeMsEW3OiYqb6W3ridSW20k/TyOgPa22WpAQGoZFRoUkBpO55QI7T0",
	"kmoDmWrxCY1NvYYwvwBn4Dz3Qx0Ixci8BEtG5CV3gfXtoFPufTSRJ4QZuQxF0e0an5YzsjeXstjHdHl/",
	"stLagl+B5hFWEd70zrJ1ZlfvbMOBMtyyeODOyB4XZn8C4Vg+Nk1XNPOpdATmMcA3eYtzhZbCkTwje6jJ",
	"2J8QsHdHaWlAz+L2DAw1bktIwSC1NDlzp/rMV9DNpeoDzhGswBPIC9VgzLbzMI3XgpE+IuzUhYgRQtAY",
	"MiH/TgUjzyXegenNDp+8wgpvHUIYSrgT8sj9YK9WPSFPvjvscKLnLk02F+TD8StwyHB8CNyC3NfoDIVH",
	"DV7V4IMAdb0jSHP+w30Y7RVo3UEF+dSI/gZZcrOq5yBSGinFCHuFf7varyQ5sRQOUYrJyrSozpk+5+Jg",
	"KbFy68HpVsm/uoJyGoS2iJYbt8lHXD4rpXprtv3Fcvfn1LS/5NTAh490qe2HPwEsRMsMfn395Yu9Nq6v",
	"h+TLlwNbwNaYii9fojeZWyrwTPKyiJN57Ow7g3yPW8v2KWiJg2v0DJPW+y9SQICblC38XvGMTcifv3yp",
	"7L+iIUThiEAokM5uHEAgT+cFkhhWNJio02fNa83twSbiKe611Zl9iOERur5+uraN+7/C06t5rWXUsKVU",
	"9sVWKVbyuoQX2//7//zf5D3+7QXkqPJc5utolA8fvojc6v/p3Op9LODZqxdvTt6eNIgVI+9MBecJ9X/k",
	"+ATKvnv/4u1xb1lUxsUFnx6fvph9+vDaP23g+dMUjZ8Jx+9PEFvy3evXx2+OZz+8O/1oq6FaEKKxmIL6",
	"7inkXjlNVMTR0ZPHT/ZxxielfW/Z0/9eMegGcn6/CLG/7nT5wFQO5RvkyihIeA+UFjjgoQNrGIIhR6yD",
	"umvfSuMh3cJUmBUrm9h2Lsha1iq6wFCssDzsbNb05YBEXG6V+RpS5QKrm4pGxRaB0rj0KzmG8mkHER9F",
	"1TtzI7hE+qBQwyqc/tGYYBBWU8Y9dlA5t2IY7F8pbgsFKRxUGT/ZHjdxIOLJTMgXMh2gGgbafktLp4qZ",
	"Dibk5/F4jB9DFfw4Ho8/k+uzFkYKDPfs7Oxf2vb+xbJb531lm5oO3qyJ55PTwRA/e7UDFAhc1EoVtmdf",
	"KhqwLfkFr6TpoFzPkJgY+AsjPhwfDcnh+JH9z+MhsQO1xa+nIj5snzQjz6gOB+wNXyrUDaI902Xvd2nE",
	"LMO1b3gXm97df7aJT3pjTzZZt+Zry3AxShMf5VCj2f9VvP8Tu7jtirjR8VMIDavC0zseg1wsIEjR6WG5",
	"WAbQhgSujKX7KNQePR7pMiTJDVHYFROUg166o6xOwsp01c6JDFhLVnLBB8MBvP6vBkMf7T30HeI/APwe",
	"/OhQyw8o9g7VbCOLVsqjLrCWOLy/azLCvF47JnuLQAKa4PZNQjgBrSmxLYFOHBi/i8GgGUWP/RxFVSOD",
	"xjeGWMAEXXf3pipnUhTrpLeM9xmo4fk7ctnnAHjEKZ3u4yyg67Kkiv/K7pIzyfT64nbNBsxFRCBXx81c",
	"VkaPySljZIs9AZWteACbLAStgLMfWFHIYaQChtCU6eDf5UqANGH/Qc2Kii9fGAR9fPnyFqQzJ1P8/4i9",
	"Jqli5MuXYysekTWz45dFwkfxjjbYZvt+7rVj+sN1aqhJxI/mXJ/P6jR67Sn/NUTj4EXHBZmvDTi4t0Ke",
	"ITpm49Dsvml2TfKt7RTsY7PIwSl9znwynwR48i183aShxcxlv7wJdcILCi5UGMEtviolcChC5qmw7U0T",
	"ORT7ZoNJWsb9QvUkaW+Oz7EgLF6+rRHQm5j6UacXtNjd14ojCABDJCvnioZIFi54YTwVxzlw3g/Hr1wU",
	"/RBRIsJfUrloheMlE8b9nMwJjv1IdUNC8KYMQIXVYtdo+he+Yl+mbkz7MzOq3g5a/QrKfoSi18PBv2rn",
	"THxLHh2lo9w2dJ/1uruVbuFsF7XT43nvMBqbBZ+zFb3gsptK87ztndVxh/oR0SmhvX/8aJ/2imca9PcZ",
	"t2z2H+dDolhGi8L+S+TZ8h/n++1EfFsz8dnnyWwj6bL3zxp38qOfZlJtZl22LRwsKC/A7KRKLjx48j2g",
	"M9GgMNMskyJvOx8+7hDqI5beJDwXxNePun68jSbXPYe+N5nqqaEip4Vsn/M4wSpipkB+NW8ya8NiGeae",
	"DM3ZDCFStcD0gMg2kqh1fYBwH/x11LzxDnzhrn9ZM93Ng/0HW9mBrQwHqJNNxMmEl56DmLVitsM2JHsh",
	"ez7ms3KJ+EZWBE76GfZlm1N8yW0z8P0AQdGjjtIui25/zHgK4OrkOaR0UN1dBIbgKHWh4023yG7WuXCb",
	"Lfb5fvy5LzHnM5d5qH1IoWwnptZd4bOyV+6JGvGlIXs2LwrecJ0U8I5UbKeNdYolwytmvVMlV7SXi52G",
	"/hOcXROpllSAgWq+DorLDn0a7dVd8fPCoYd+uxB6rxr9mPeyQcqRvQXlZrWoC8E0JLZx4J/OsScVWxn2",
	"6bca7YeNgxDGirfzkIQrG6/p3rH2rlqzAzZ8+lz8PaZ84YBg5aHlaFFEXLnr4Y/ZRmcw1kTL+Bmn0tvk",
	"FuSC65Bj5oZ3THxzrKghrkaftHK7xlyNNDi2ocUOrr9Ni3ir7SowNJdagriUA+xI0zpGtk9Q/7i5ofTD",
	"h3YzAbsk8X049gDAloPvg9c27rkJ+eAkQzIiC2fMQW7eIAbrhrfbmmGXTsj7Rsbs1I9uA0dkzKeE7dqG",
	"7B6fkLd2bxTATJ5zDUZZlpNndVkXCDD7inIBoBBKTcgbRoUdM68UeCh9oOIcPtLKffQ7MowNafX69ZsR",
	"1SO46lPkwg/oK+Ip5HjGhJxofycHuvgQoX8je5dSnUMW1va1TIyU4KUZs6K4LVwhDLd28ta/2fI++R2W",
	"fy5ZqLGoiwg/F/vHGiu0b8bNX7KiGDXeGFBQ0wUz67iU/eUg0v1DsRUrqsSAMRzY9agUy8xmiQXNHLyx",
	"K/BvEESsHVojhswDUTIXQD9zjHtCjhULv2rnxAHjiTS8uGuBSbnVHQwHdh9Z2V0pkOCrgeXlbu0wfVUg",
	"P2h6G+oGxS+WROpAMr0wfygS5mr/2hh4WkXcvgoSIjek9XZhTy5yKBzybgD9nSJNj0PJpulRCOpKRp06",
	"5nmDDnbVkoyQb2KAcXgdprAqMJ1zQkfadiyCbNKCxjgkQfhK4I8kafu2Llm4Xcne4eho/36JCDokeglX",
	"z7sqkm56dEtdOKo0SpWM2wrJHSvNFMYr2g2bzpjTHRwzMYLJNtXTpw+NPX/BMOR+7JBBNSn4/EBnilbe",
	"xyV3znzeGakxGDUR/MA9f/j48f2B/c9p5IganBcBBIai7+kI4U7ANYTsOcOCJqrlXnnBKVnKUeTXBFzk",
	"/fOX6KQaVbTl99Eyhk0GNHvdOINi7cafe+HRhk4f43j9xaCJfjyL0ODA6hwcOBfOqcyZjmNyjZ213pd9",
	"Fl0tfd6YPa6Y4IHp/DHRxTDtgQlooU7LkTnX0oQiwAXOzWzvyaPuxgO4QtFIId8iYg00G+VkQVhZmTXm",
	"UYQmMbrBVdxjVxmrDKnCxCDoMQAP/DwdQPqKyI3bBWJXvP3j56m4Vbgb0G/m+p3xHYJTn0JYgFPJOI+1",
	"sBwIt9xdjPFUQD2WT8jRo+/Hh/b/H/x1SI4Oo39//2h89Bf46+jRkBz9zf75V/z7L3EU5y2MVx6UDLJi",
	"4F6bFQ77MZrod4eHh4d9MZ3+5DuPRiuIrCj4MStN9nyCsJzwhYMubiXhjxNk0KuZ5w0zuyVnaHJp6y6f",
	"/PW77//SP5q8tae92abjV5x+MbdO6Vara1T01orETYfmtgpxF7kfzKin4SmWzpTpn2mQajGKxkbHkcRD",
	"bQmEv+GN1qKqPcceeHPk1t+hAiUJnFGVc4EiT7cLK0Be8dKeleZNVGNaYJc9ac/y8B/WFVOv5fK1XLaT",
	"PPUYftzWgib6AfMaDbjAy/8gB2Orm44LLu5rxMUTb29E1EUx6wkFbd6WSl66686W97MPwbNh+bZOPb1z",
	"CsPUacWyFKbKAgGFdOzV6DGjwUPIAWs1iF8boIs3Wf19igLXSTpnBwoyKcOoAzvyBeAeZL9MMD4Kri7B",
	"7GvQEBZ+WZqDpWET8gp8l1yuwT2psAjcg4U5KGwRdDXufnch/noC3nPgIq3rOQ7YvWYX/GpCTg1VzrcJ",
	"Hn+W20/IU4dEYy5ls41hn+gVWHTnzHkT/1xyMSQlvfq87/Eg/gkFuUDE6nS9dswz+8U+ZyDs2cB/7D9B",
	"+C3gn34y+ABa8Cv71AH8TICJSL1Eeja9Ww0ck3NFHrqjOyTuFho2IAagyLU9HXAR1lDvdxS0uIOifeBH",
	"kDKSvpRWSKir26UBitwnFtDAqK5CHhk9JiC4Uu9PzZpsPFNhH48Oxi0LOYCyFaMVUwcL9GAHN6b/Hll/",
	"uuQjC5nVGNMJ8ZQt75KX8E2CC2Xk+dwkBRYOjCGjmiWTA0a809+uw14+mljcOCdi24K51RPqlrmEEqSJ",
	"1NnfPq3Qy/rXXzloHOzVLtYufj++Mx4/Sl2XzfOR1kYmWMLnVJKyhe/Ov7rRigiZsiyrEsT1YDkCgCTJ",
	"6WDsB7r+Koiq/RjOi5gYN7XVUO3ac8hIJN5OPHD7SwxhM6G4LZViaN6E12dccmofwGsNuT3D239MXqJn",
	"OUYdllSdW4kY8QEx/AEd3tFbJMps5qMbnLPxz/7TjOfEueXm6HL72S5g8vsRFhiGHx75Gki3rsSZZjR2",
	"OzVOqy4LUTMZF8CxbSIQldMap2L6qDt6+ytEgT76vNVbB8Z7w7LJe4NndG3Eu6Bn3LYW+snftpaDmbh1",
	"Z+BHfJdaiLtx25oOeOO21Y6FWSlZ8ey2FdO5pO+DvhHa+vrwGz1Zq0Ff96oRP3ogOBB1w/uc+sAEjxqx",
	"AaoxFUlUDbINVMMJFj5CBuqA1q2kgldg0wnJdf4bIG84eQxJ4LXlGKkRyaV/QHF8IygOqBN5UAFV7Ba6",
	"ZPOg/HJhDd4L3Kmlf1MUj68E4OGna2/cM2jn+voMSaw3h0sKueRZHAqtAEJ9HT92F/4t7QKJ/8AH+QMf",
	"5A98kD/wQf7AB/kDH+QPfJA/8EH+wAf5Ax/kD3yQ3wgfxA699UhB6S2aZ5hFB5fiqU+bbFZMR+dn6Pmt",
	"4+aOS17459B6gkggiBsSqgFuhu8X4UPGPL++ntiyzWsSfo9ek/ZrBDDyT0gFFcZ/8jyCKIm6itr/8uVP",
	"tSgs1/hHQbVxkCX4EwSx+sZvDdth31woys7wLXN97bQS9n3c/hDeXeAlpTAMz5YDrbmfqG3RMS/7k9MX",
	"TBpqRh9HxGOwtEgUOupCn7gHV4OAklj0Y0GLNWSa5jrApHReWf4FNRXewGOnAoagGVWMRv2fbtzdIFgk",
	"CQp0eY/Z+KHTSAapNVMzJzqBpPKoLcVgJKft730BScBpPA+X4n8c4TA8k2UpBdmEY3j40J6YveAlPTqu",
	"IYEMy0kTOLBvRXXUuydDWFAt5N1SnX4qPoS2/jNQtrSwcdCE5jO0uWPLXAOY3ftZYUUiz12icTj+1MYB",
	"wnxdmN47a9XENpu9YVs6EZi+pZuk3zJBpwLEipB2/mU4HDAffCClZLWWW57TXDFtH2U0MzwLxP+RsSoC",
	"/XUpurxz8xVqH8icFdK+UbiI81qTzOVMsCuaFYyqYYMRdMGiVDc68p0GT0LYggTSOdtbFwXdpaIZQ9/p",
	"PdNCDp4OXNFztv77r0zJ6SAyt2D6bchBHmrBmigG+iZg7RfuGeC0SO1EYBsIGfQKE9PqwcS+VoYBM2NZ",
	"mdGT8VESJAMhBux2rRUbTA7H31/HNoubcTPSCuOvi51Bve49xtHwABoOUSPlmvCKyaeyBjH1qbz6KjbE",
	"uTRGljOVTnjycyHFkBTUfI5t7VvTmoKh+QSLPwJDc/PHpv2934hpZDUr2OL3GNamHcyPZINeadNYWKP3",
	"slgvv1Jy2n4yVdjLDDRCuwPlv2LyPSTg3hZBuNF+z5x9GtOvlYkXGmuDDRwdnpe3S2XsM/n//jsojCSa",
	"XA8l3/u06G0KFtTsOMRC7px8ONX/6YpWyfxjr5gE1YG2BdyjzMFxgW4Dbiy0xMXsHiFXNiOrJfhGOofX",
	"Tt4Nl5Zqi3Ua03nEbX2+YUqvmCyZSW1OxYpOKAG4DGv77Gx7keHrOcmdtSfclmOHBO6kd4Jfh81gbprL",
	"N2Ypy4hUu0wmkHZzUqGh5GRS6TN2cGezr9cAvUf2XsE9vN+XZ8GD8F1wSs5oxWfnbO2w5IhUXYi/VJr9",
	"cQtwjbyxMghkI0UZIMLuOjw8CqqFIXl8+P0jkvNS76eTmFI+XsJExjm7OHCN0YqjmrVBimoLRW4SPl0+",
	"rbjL7R8BYdmeI2EpMcy25OSEmeuOj7TvKyUq+UVw+WXB94kWWpI5I5phCEqbvGnqppj6BqhXcC230+qO",
	"pFFyO2+sZjM4LLm97//y1yE5+u7xX8BHE1ZGsUyWJRM5y/fTLtz9F0g0/2eFrHPii4YER7UeZUwYRYuj",
	"B/tjEnIU2S2Mbizk+GRIWjAFuJch7W8yRSquZysZUXppu4MVUc71hjrQYizchtu2p+Gu+KGkPdAznu9A",
	"JFeYnDzfwGdoJj4kKkmp/XTKT1Wku/304bWfbbRNveGs6X2ICYy9NowvAHLK+YO7fdGALSm+1WcK16if",
	"3yVcp27B8HpeJ54JbmNUj8bfjRYF1asmhdQw/lYpGf5+PD60f9+FcwENkoFUt2AnqeX+eucxnYG4eW32",
	"BU40sRqNFt4776V5SP+hDaux9cBGyx6f2DC3zQYftH+rlIx+cQuLROgc+HhQX+uwJ6ndeqMnDgHYcYmi",
	"IpclONry2KMYkm6OHo0P2ye0E6v6aBsikqxm5ymwgmp0TrSlDUgUVNGSGabGPYgH1axKRbhkBat1TzN3",
	"R3G6I9P76qzsW+X+7+USbQ4BcStWznj17t2r1y9mz05fxHKGlS+SQD+ZZskN7Bz+cXDkhVhywfCm6nRz",
	"8vzGHnJq2Ewx+0OWdmqGLyHP/nxNIHLKH+f8+wfA+CHH7fckp2s9JA/Ko+jXUgqz2m8d4DJ5P6M9Kcqn",
	"7pnQJZt3+c66Ap7jop6MJBVTds9Eei+sB2rSnQKsOw6b3QvOs43WAlghCIw4PqyYkuQK7T07fbFvh9p2",
	"4OSizY2eSaFlEOVPmamrDaBnGjgWNeGiy1y1zDbi77xMluDs5kIfOuMGt6/QanLUcReatRp+MiavmAm7",
	"nIqcPDt9QU6ep6/inF2wQkJ6tqaVA3RdHeFCHlwcHcgLpi44u4xjZ6MDrWi1AgDRfx7eIrDI1ppdHDrY",
	"0GTCW5YvGey+mzDOfHpMHdC1uWq78+qdYc/aeXsTET/2moekkrOKqZk3XOxy5WO2yopFptK9Q/J3Ugs0",
	"QqdCff8rgOo2PROHb8auHJKebqbqbAM0asc/4fR4Kk6tvOLz61NNUqDPY18Tw8Ua3tXKAhDsn/cB0L1x",
	"iweU3N4g4u723rKz+/CvtiK1Xnf5Yy1Me7vF6Ws7E/tfAlc3ZGndJd+rA7P1iXS/KZgtLPtbmbNTVoAq",
	"IJHjmi3Av3olLzHk1xa05FLmIMpyHW2K3njgc7ZOUOGFy0VNPEiET5qtd8dn2H1BgBftws5wUs2MQ472",
	"4BeRexHlPnzNdjPDGOhtjM2uEwbaIgSO7XsG5bsylBtiFKTtxSn3OKIaZwiB09PBnxd1UcwsZ5u5gtMB",
	"GUFJ+2UETqftllxFei6ErzMGXjCzj7NQ3amYNkYB1AwYBJgpQXw9jrY7/eEE/Eca3fI5ywrqXpbNzl4j",
	"YD3LaivAQNRBINFBa7Z9IfFplJTMAyagXdzUSiCZgvfAtzgPmHqEzZpOusHdzNixxZlf49PeOQS3R8z3",
	"g+jhk977ABi9Dw+GWAKarWAb369zv2cTbyqYIQpwmKDdp9IP15/tYf8eNwQ8e7cbJMM2fY/loSaIE91R",
	"v3dyhjas0s5bFn9x+3cj1ftNHbu2Tg2r7rHLcDvPaMEhlrtn+7vPm/u/Pfg9wAcifye0KPa/xYmAq63B",
	"n9+6Kq3r03YLl+J9GljvYCkL+8GK833Wv2hrf/4aLPJ92KubG86pbmK+YBS9YErTApG9qFktOFj+EwhS",
	"S6m4WZV9BzAUcCjPQRdQ0SVTVJw/GJIHcwTXEEzrB/c5kKGzWXM0d0fJ2yBFkOSaOQzuvhI5y2t0a2J9",
	"CRJcNF8o5+SYvbAa+/fhlS4UC3XM2x6az0NhK4ff8NJ16CHzdfTW/ZZ3HQQX9V8z9nOcFOVrEe/8Jpgf",
	"GBPi4Yic7J2P9Eoqw7QZwZd7vZ0BTYtVHskrJfc2hxUL3rM3LxPsIGd7iTBJ5Lv1fsnSDlu+c9hlrtBw",
	"qyvILfrmor9vBwv1rfq+8zsCxzIrrRS1XRZY/QTF39jSX0fsvhncQjt0i0b67qKZUgOidq8Y5AogfHws",
	"THDWBo/fQQ56Y9u6Bwvq5dqA5IFfdxwRkBArvoXluPOgevihGxRyJk88f4nfhYD3IZyRMsE/0fMZH2MQ",
	"VsJLtgMWWtTtYAJwfePndQDjuZVuZ7tW5ysoCb6eRIhj/irC4Md1yhPOG0nS7+XIUuLYPQOIMr5czRHb",
	"3V97cEkPhoPzWesXeFG7d8/nu8t4m2cn4dAHWiguWhNplnIjdUP6cvVun07bYd8VG6/V22+F2Ptz4w0F",
	"nJnlJBT5mvdLbAnYXRp+GSsNIGq6o2+A+Iz9ewjFPUqDZ1IIDGdGtere5YoJ0tI0hK53tp3cg4ElbbYh",
	"6Al91O6uQ0htvx/ZGrTJIM9GWxAAQ7j2W/Gri9m2vz5Vzguv4t51UNuulHutygaPtItwL9bYpAFKPGTt",
	"RwL5E0gIwGmwz7sGlAjiPu0CAmAsTSNSeXTXyxXFLDzQhDco+FjZMSSzxqDoFn7f69dvMG9BAIWYDk4R",
	"X7JEdGJSKQ7xp4YzpaeD/fFUpFP8NPkhbtj0J881ORfyUjgDdciG8FUS/XSMHSfvP1Cx/DruwRnP04js",
	"fX7DG1sN6qecRzaSwG4zMgOUHtrfdkMWe1qwC4aGvkc7YlolE9Ruq5SwmV9/7t6b0ezSme1oK597OxMn",
	"FTnhRpOqVpXUyWRTTCierXoU28HCHgq5KLAY47ZReYd8xTm7AoT6F03jxOuFczCX5cSewBUjBnwgLM2L",
	"lkPZzwPNSioMz2aQ2RdEH5dv5/M34Mlp9fbbyIvOb6OeHm9ebVjopNwJHbtGevf7bhbne+117OJ2W323",
	"Ol3T+fWNE60TGWizcOC3UrnxatArqvKZDk3eJclUa57dQTeN79rIJp/D0YaWNkbdS6iex8UKtYOtPRuH",
	"HTZWzIvDwXAAtkn4lzfXJGNT/l1y8aygtWa7sNx/SYQEwUs8zsxuXDiEz1xBuBBMDUnBFmYI3Aoi46CF",
	"DlaSNooatlw7ezPC2nWkAlt1tsuJtHPCA2nfV9qwfGbr7u6JGBGl66UWeLMDobBNN+hco0u6xkmOpwK8",
	"daNSiE/KtEMPcG8qv6JZrZTlw7Yozl/UBSSt8g+MW0tnPrHBdqU1TNmH+IMcA6qxPpvty2Ctda+KyEcA",
	"1hmZP4/niSkuWl70mOrCmX6TLVC4daCLfDwVrl/EbGILfuXhBjfrgcVys/v2LeTYMyspLyyb5kzd4v6J",
	"SFQYpvQuBH7pioa6Blf3prsJp2Mk7iA717Z3NvrzMZVEifYHa7ZyoYPbRnjqKnSYWTxe2E8p9tXeRCl+",
	"gp/wuFDMfIIo/3MPD49eY53Db/nI7EZQ/bB9bFGyVyluJYr9hoDQIdlM9O7pN+P5NhT+bcR758u2j8/W",
	"AeO+3bMLzPKtA06NczOotCFWeyR9i/ay2cMp81RbKqRuhE4mdHfCOOHvYevOHLx+6onugYJcHgRvNDQ+",
	"+CuocObrdD5V10XI0Lobe8dXkJVtYlXov7QU4w/08k3IWN6wV17aSw1kF1A3DDxcx4GtNbju3hIgfzU6",
	"QDdDt9XbdLuNZxY00OW6XDdE2yX3RWu3tpy/IW9CN4+rw+n0pyEIAw0MJjhTnbFfzlweiiaQCD4I+BJy",
	"UsBvhTmLsk24n1j8G/GgmfBxacvHCSzcr2zj56hWNyPEL+08ECE7RJ9w1GejifPKiLzBFkE1BNAm6ObH",
	"PbIML1k64y0vmb0khfFtiCWcDGh2I+vtjrlfgCfY7TPTGRXi5qSesM1cuQ3G2j2c/X0i67lfp9Glvmuv",
	"tj80fG3vD9JpusINicOuvk2XtXDt9IBTND0DIUNyG0xKhMwetD/28wH4nIEguX+3QfQgd0TzB8r2DwO+",
	"32EcQeioXerYWwkdSV4VSiSOoXs6gDawc1iQK82VpHlGteUfT/2/iS6t8BluW/sHPNDA7lpQtWThVUPI",
	"U59avokoRlHFgfyTo8M3T8fk3R60ioLSPilZKdUaPLWh6TEMB12TCinP6+psAtA8cyD7OVsT/FlDjDQU",
	"ZLo9APdGumDxWwpLumfGOVvrMXktL33/8oKpFaOue72qF4vCMs0fqF6NKqoMSmVzaQVpnNV8Hdpqdw+E",
	"GUXkca8dEsJxEKNcXgBi27jFg8NCBActnC68jWFUvXz4YydOCV6YvZFKMPomTmniKC+YOpuQd6JYez+7",
	"JsmUN5bzFinwXmILu3kQMxu2ClTDVIWBLQ7J20+vXyNCoRSjRsINJw0agz/7Wov4XV9zgX20aOvJ4fBo",
	"NoFoGmr+yNagDE6LZJCayONHYrgUyBcul19XylOy7EHpSauCOwf8NReMqjdMLdl7umSNnqh74dbOJ6KA",
	"KqS0dRBEOKT+cE7dus4AAHMwIceWviyT9mTbpYWj1kzQlQRQK6wLJ4IWtm4DkEy0kVWF2k04y2Qua5FT",
	"tR6SrOAAGIwGA8WMWru0ZezKzLJaaamwaQjJsA2/pJDUHkIxZAZP/3xIhAwj7RtgtOLuA5iFYcQDH/OR",
	"WvaIzB/cWia0whFdA0mR7awFmD80Qm77YcKeZVeGKUELgtlENEYIOblUknPGKnIMUMGQ4G8tMqcBEk1V",
	"yzXmVDMrvCFWK7TlwvJ+kJeEGwL5oX103ikTeXI4a1mrzTFBWN4pUxdMEcwGq0MlkAHYFddgL4LasEkg",
	"Ws/VwcSx2k8j2k/2qjkPByek56ZzDbFRYUCuySdjcrK4aTPVmsX7xuGdXhl/ApEgPx1/eHvyFsA7rVCt",
	"6YJ5WHqvRwrr59ibvQUKWkEC2jBgndK05Wo9U7XYnuLpZAHwrUPiE8OC+e3S52VDouVBvCgpAF5nK98z",
	"7hNIcgXn9p+YzJbhHpmzFb3ggNW3QPzasuSArGfLPlux7NylIPPLccmLAq1p9v7JA+hcsz6OzoAfOLXC",
	"PdgF/XtK+yHPOGiZFF0TsJ07ioDVfEOR5AjTTWNVUG1mcJTyZFjxyXMUNLRx43cu34pdQD4QPIVu1eHq",
	"fgmg6e4XFBzQIxxPOZkOpgPIvFvPtS0kQmGNpVv7qtWZt5BCQlwX9oQgxEAxO9Jok0cAw1MBQE+YFUxb",
	"ZsxFwzVQTrDnWTOjN4P7HMLf5PDwcdqUCqt6O7eLN7RynkeYCenkOfrUuz/x2pmQL9NBlPxodmR58pfx",
	"eHw9JO0vj8KX6yjoGAxfE0RnXDcWMMeNCnbFMwl6d5cZZb5GJoA3BawR8hXYsY6YILgBh8RmIONdAG+U",
	"QnNtnMMEEbQE7Hg0VoPsCr4EmBwaIi5Bt7IfVsjh+dILafd24yR98ty9YJ30gxzugXYX5aXihkHOMrWg",
	"2ebm/xKt4ZH9E41tg9e0MrICxsIzNpj87W9/G//tbwgU4Yo/ioq/kYjw6Eo/6hR+HBX+ka3nkqq8Kf89",
	"lE8acdYim4EJcttD5HQtstdQsKP6dNvw882yS6Mo2DT0AkdJ+Rgi0/JcUqou59zjixbv2e8JEw1MK8Vm",
	"3A13yVTUcKq3zc7GKCh7/fvm9/GtkkgvINX7zjCEm5nhEy2es/VMeUn2praCxIuVbtBGbDowwols6SSc",
	"AJDXwHGRH3rn3ATGi1Mmdp3sAkNru9t755NeAQFTeudqDcEgIysyuvuUlDRn00ESeCJi/LtcRF7oRxaw",
	"B6GQG2JIsht9zu2o+/e6K0DmLKO1ZgHjd0X1Kqhh9mqBU+rJkL2bZTb9rIjcae/jKXs9HKAUedNkucAS",
	"9mTXVQ5Z/PYOyQ5HehMC0BuQQ5/hzA8aordXOcWtwIP7uCi+ihsQrNb/x967LreRY2uir4Jg9YQlb5K6",
	"2K6u5omK2bItu9Ql2xpJVTV7mjUkmAmSaCWB7ESmJJbDEfPrPMCJ/fM83X6SE1hrAYm88CJZcrn69I8q",
	"iyQSievCwrp834gnSbD73avqeDG+6MpWvddKPGCzlFZi23ZB2ZUNO5tn3KxqGsFpt4dD/b6cndi3FFq/",
	"OSarUnrlWPxBR6G1vtCx5y7UQLLMVdx6f747CWrbGLcPrhVSVRunM3Jl2bRh4oLiZdAEXvsWEwzNqGSZ",
	"27upD7aiNHSr65WxIvhlf6iybDpg5yKSVhnlCTvn6oq9KcDS2aP6hT0LdebZUbOyeGaL2xEpEj5UmYHK",
	"Eswfv7DPlHUpO26J/K2sbbJkC6n2FvzWkZBwdiNVrG+gtf7lNy7MG58bKqtT2Gst3m7qvbKStkQ0DCDC",
	"7GNV4xkOc2bs/12lrasAsOHXyoTfd8HnIltUsZ6319DWQ11DxW2rN8ipWpXeiImYpDPVU2RxLYH9xSXX",
	"LFmayYW0q8fc1a9cZlReeQ/zZ8SXN1zMW99E213AlJMKVzRHBmocRET4svvnBXxGbtr7YiEyGT1csPDq",
	"9Q23CiOvxWjBYRpXRDsFFpXgEQzn2vwI1d1MBlnxaADoLdW9nmy7hiLP8P0QjfHZVSjGyB5YIgIj5EEm",
	"r3mECGF6OgVq6MKIPuAAAt5xkSUh1vGH09Ojd0ejHz5cXI4dgN1KyFClFzJC/FfERtn587ffIZpxly1u",
	"J5zAYclJtHOwf/jc/cyTpLeQSiYLtvPsu+frMJCRNAEwy3B3/Pfoe9/PGhsEwRnXW1YjgXAsDACT2CFC",
	"x8QO4FybfHBw8PzZ8ybScQDTuQ6Jk6apFYWz3q4nXfakMVB12M2WzqxGuXXqwopOdddjQlLbK5iQraDN",
	"wTpZidhc9mBlYx4IbLKdvftu22oNDTSV8Cx60A/IFJHKYQyt222r9g9U+6z/bPDn/UmX/eNGqMP+i8Gf",
	"DyddFguRGiGuetkB/rqQVs1LBn+edO1z13zw7Plk435J5CTj2bLFsv/oSLb33SLhoNjtEQyL/egHJtKx",
	"yAbPnk3q2yWs4F+osl8aVbZNgjz0Rj8HuJN7Hp8ZPFw5PjsPKOkxaYtecW9A8kcexVSoo5N7KiHw7H2p",
	"FD6cHb8/2kyl4HMH8G0h3/HR2Ympay4rBaw9LQN8+mc9jPQp6RcOXjz71mkkjcKktWyiaEgTntuJ6SOn",
	"E8hdwDgH4vxtSBrMVa/f73dKNob2drcyWd2Nj4Fmby0fQ3WO7sHH0HKifABOzCBkyi2nch3tAMr+u/PT",
	"WnCV56gFhgRPxzBghy++7bIXB4ddZvXKGnPD1kDrK4d6w9bHgVxNjrCy3u1UN0DQT2WwpjaqbuXUlqob",
	"EXzCyY0FnhiATYaZb076y6OL45GtdDudrrWVDyqk7qvT4WCs0elaKRCQMa7CfIBfwVWly/SzLtPP4cMd",
	"ZcH9+A5q27U18B28MCpajuwbk7ylpjP8AQcHOH39Q2zHqjJ2ddxNo+kdthNffSFyBM/sd+dNWvIhYB1P",
	"yj9hWu1nmuEG+4F/a5tF2NhbwF3mwD3zoFPw9ei2X5ta2iIdH1ZWnQOJ4/2VKnx+lWIVlPDXUA6U5lLE",
	"0C2feGhlWo2+h5wAsZzCddUTwmemv53Odv7hp8vj83tSYKEs3NugjO12VxYERaw7VAhev9fGO4TX5z37",
	"v2fBL9+tuiJ71s0+J0Yanso9j2q8ndKms5retranTfWNeD/vrsLRStioxlWn7cupcnLKDKrwImaTJfwM",
	"Y7S7tYzfNJRrBwYlvoyFyu0GybzUX1srnAWrl1j9PNjUws8XJp+h/NBArDNq3U2inJ6+K6VGPW17ypNk",
	"wqMrZle0vfc+uFQBacIuXFY4ESL/ZAQbw0giIT9nRqpZ4iiQfAwNTRWd4Bg44xl296KEF7HoGa2UyHvP",
	"ey96h/uHL/b/cviXYWe3+hozplhQ+7Z6r1kvHPoc6KZJ/EqFMXysULlMmFYCg7lFbDZITWpzl23T3i6r",
	"rl/P1NQdqoXIeQ/MCnvw/96z/rPen/cnPamQkvpOkpKnsldKy2jO8z0jVNyzf/WQj9rOU8+HKq9mbX6+",
	"/5dvGyJ0JXmz50puEDh/dVL0n0g1b8An3cX6exHuydVC2Wnku312LAFKAp/QmdtFLriWlkTcKo/XqOlY",
	"TUsIHmxpPW000bTu835zmwMGOz2tXLhuc69v37M6REGjc9uIg063s0Ie3A3e4J/vesN+kDM7D9c8KSBe",
	"8kowjYrNQmeCqvjCtyBs3wG07yiBpBU4uXPNgo5/zl2pzSN9RrB5Teaa7ZnCPxuDrtspo6k+i0WkTWG1",
	"u1HETWYVtjPhRnz7vAc5/Bhj+uCYU8h9UwIiPxQY5WeEdvjZasy6y13fFN5y3zdjMkVzeO8wnMAr8Fk1",
	"tDKHb//8VzeVb6SKgzy+Ws7BI2PVe/aaxwWtv6pcDg9Cgbe/H4i8g4cDiHfv2g9e9uIh3/XwC6kOvv5w",
	"9ZYbt6baYS6VE6ltEvXzd3pNey/pth76lXdEgbcbr4YEX4nVxzHzPfn1IbZ5e2aRxy7/EiDk8LLRVBcq",
	"/qzj2tGOltgnj7Fef7+D5vNX0+cul6C6im3NSom5Tk3DjHbkKWYc0D0jpHvIcHTPDdgFwZFjmcmSzXXK",
	"ImAl3Jlkgsf5vDeFHFWc5S6TMwUR3jgqBuwqpRQcMNtmB76A91HK+fPsn/Qk2zF5ptXMvj1CeGur20dz",
	"LtWua2VLrUQ9YYpFs8ZE32B1JodLHqTiuIjwYLQCsV2RtZ8Bwl6jk2jjb5hTQ+1lgTdmqH2CgGlD/ibq",
	"xIr1AfLlWsalPkVgKLBlV8xMJY4+HLVyoCpD+HmjZu9HVmkBUq5WiG3IlM0zLhWgUDLueS+Mfab7YKqS",
	"7RP0taakbLKz2GfYDsDGiAP2vbcm9fAyBNO723kUlWMjJwxFoD84NcwW40Q7tT5OdoRwjqCdDzcwdyOs",
	"eYyBWaFmH5ekx7l2eRIiIH9Ty0e4s37ewVPyw7TQSTjrPCSTImpsldiusSknKN3uDe3bwg/TihIArHse",
	"alHENYqKO49EOxkBAv+7iSyzazEh7AsC/n/mBLfL3COQqyhpMbVn/dzCmK/APEVfFlEhsJ1MAF0rTBJk",
	"uS2jBFgwUQh/jtIv4pnYkvfIHzf3p5r6nLEX2UIaQwdUdSgdTkUrfxHd0YC5E03uJTKu/RvuU4URGX6h",
	"M/bk6RPkMEz0hCd1v2cWi8x4BNgWsA7CzNgGodk1z6E0b/NMORCtYOt+LOpNWQPAXqtyJaFP6suFgNtW",
	"4e10OwCQ0el2eLyQAItbjhmVaIzVHyp/cDPbxHZpgmeQiffInS6TAtf74alcezsL1ZbK2PS6p1kBKbc1",
	"fucJt0JeK8xSZf8oeCLzZX+ofhBJalweoC5yluibHhF/RMI/LxU7P3rLUpmKBNJeJ0sn89RsqLDWGU8N",
	"QGWJa0kgT5jxq1NXUX9F/gdUMJrxdJSKLCJeozrWGlSTF1klpxigkPD9cWa1M/CaAOQqSG2qj8/EUPn8",
	"4xBiqEggOtX2xbBhRyQTfWOGHcC8wWqlnbBJQRjwbwDUEbZTlz3b7+8DcFZLQ57t/7cmoFET9PvZ/kMr",
	"tnxidFLkAke1OZI/8Cwub6ERjlcmzFwncZ85oj9E7aFkaJHoGxxP8FMNFc8EE7eEwZKJGc/iRBiAwkPw",
	"/XIhAjpWHWdpv79/8ND9xkUEm6ENR1CkTCPGYr2DiJcpvmd+KbKnrFZjfeb3+y8ARM74+mxhuBjnLBHc",
	"5GzOk6mHTPd7oD9UR2maSBF7tnIIXqLHG+P04iGHieTNCIJpRkjfsRFRDQB3ADDPk9YDolyaCp4B9K8L",
	"zSFwULYDWJWehn2ouIqrzPO7ffaTEdMiAaklVZQJbjDWUEQSBmSyZNhcEDF8lgmAuPKw7GUMYYWaaK5j",
	"U+FBujszrMnjUSyuR35XrFhO4UqSir1nJucqtrsrEIFu7wi2EJwkRH0xHfT3a4upbXHax3vs4KnJ41hc",
	"I6ChG0HjoJ95YsV4IgEfkJRSO0fE69ACeXbwkEusza/rz9ftaGIuRbYo4dDXlQwAQLYqGuo4mx64S9kG",
	"AMOmB6x6s9yyHYGKsqnsuZiJ23S7sr/IJI54Fm9XGkpdgN6y3QPNpP1NT9hpv0Px1zwXUPwurXqJomC7",
	"wq+0+nuhYANt2SRp7vZAFftoq9IlJtHG1ujoJN5+WID/YbviFeK2jXRMQr/UBZhOXurbrZ9xXJ13fsmZ",
	"TpazbSfgrdAXc566t/zqhNXLQiaxyFb6smcuHHaj0acWNwuAEXmrfvue50XGE5ZwNSv4TLTxrDkMGawi",
	"vNa9kSoGyMW0mCTSzK12keUySoRjIVzwaC6VsLoJatAlhr5VVpaCZ63wadCTlaQ7jrMNWwaXeYys9cxt",
	"ABIZi6zPPlyLLIPoXrz1Y9VMTtvD6P7WyWUORxEhsoW0Vb6bI57fLYTsLvw2E7sOCC5lqjOAyXVtBVTc",
	"WlcgRg+6HyEhZNVe4WZkY0g2TfCvqw5Tvz7bnbDA8hWLVlpaCOt9YlhZxkVUughL12EfA1bVR79r1Ra2",
	"TpERt2nCEY215WZSLLjqZYLHMKpBWTs1yKM5d/g1sRaIEnozXwIQMzcM44eLDIgTpGE3YIwsZ+AClqlA",
	"092T+pZ4wpBnAeD/cB6P3r8mLVQYhquP2DHFLY/yZMme+KX4pG3/3AOk562fCNrv2F97IZWLNMGw+NcX",
	"pwSf2h8qSqEsDNANZwIaJhUjRndE621AUcFiLcF9GjCqXMWgrJFpI9iGBGHWqQ8gCFxX3O/VXGSLzqDc",
	"sihoGyv7Butoi4pVSyaNKYTpMqClQdUaDITcmGKRoqq94LHAe7gLtSTaBWf1DWQL8h09iXguZjpbPgES",
	"MAglwJu/3c9dwoGqLgmpTC54fBepU9ve2JyVu/uHNt4d77IIqa/ZXDbR79cAO2PgdKSzuL/KTk2Atiev",
	"bXPwhojX4DtiHl+g5cAzOWD6DRKFwhTh0J6fv6FV3l/l46AWwaNYKzRthXHj3Nuu8PZEvZ7LvDVctfWW",
	"Q2/EN1QhN+G5b59jC7yh+84Riu4NWEN9fSDvF/Vw3TJp2ys+uhQXylzmLdRlc3p2KzePX5Rtbh69sHWk",
	"+dIbD/C730SmS7I/b1hZ7fGtTJczF249Zc3pQWr9jWi6diQYv+YyadD5FGtAWOtdbPWmbDc2oZBuAbKc",
	"zTIxK3mn7+N6PCrrcO9peB+DMh6g3cE4pphURLzPcOZOiuhK5IEhtj9Ux5z4YiTkbxmR9Rz9rio9aYIF",
	"XUIaTvsl2BU9C6OpF0R9xZm6IRXLQ3Ngu8LShu2YYtFl/HrWZQupumzBb7sYFtSFY9x0mb39SgWG8N3u",
	"UJU9qlYE3oMuoip3WcxzMaK/59LkepbxBX3tP9vqZkLXKpoJPedmPpplMu6ymdCjmC45uzgMgFkK7F07",
	"Rs6UnMqIq3wEDdiFLlNu1mCoxuPx341WQ/VxqBgbIuo40LgCvwh8a7+3i9J+MezQb133Cxxm+BM8POzY",
	"Xz51sT46F6VYVR20qr06d6YGvxr5Gzx3sA8vGapP0IXQTFdKNxgHs8WyduU+2StC0XapapBBgAUYDbJW",
	"DmCgmJ6WzI8lv7RjiCDrotMleJQXPCnLVe1wAdeAndJYmjThy3Kf4BvNtnwNboWMAPxzZVCIK1ba8YmW",
	"CWFWrd4oE57JfOkO26qZ3z0/VImnuSut/Sw09juGDNdh/N52UAme9UArLpH8DSqZcDO3b6GGVEaver04",
	"uIvE38Qx64evUHHr+NHZ83DjNws5/1YNITsFFgv3lLFqERIfzDEZqHxffbhRYbej6Zx1wUWO6BLWuhA+",
	"f0xp6kaZsIPaNqyejvgHruJETHhmIG8oARoV5AVBdCpbQ7jrvKpNDkerw0jo0aV7fs4N40AyFNLBO8Je",
	"SPL9+NGOfB+/wn/s9f7TpzHl8BIYzdOnANJr2OWHD+/ZzqW+Eqr3IZNC2cvXBxBI7L3G68auY6uYArBP",
	"79v9/0YJZh4XCOXy3Hd6qD5+xGDwS61xOVCjPjn5Z1tz5LQP9oNIUpGZp0+JudI/O2Y9dg6jZVxP4aq6",
	"SO12g+ZT62A9+sPSVopTaQZW8gJtmJrl83c8uxLZmO1YYbM7YEdxzL5x3Ke5ptxiFFYeGGEAwnSXKrIK",
	"ucrHbEeqfHfATuAjij6TciBmKh88dE/FAm5w8G5cCrsDhpcxI1JeUnnmfFJYUQEtQZIyE2XF5Id8keBw",
	"LPS1MOyHy3enLOcz1EvEbZ7xKDcM/U49Nl6IWHL7wC8ZT4kJ7qfzE1Ru3gr1o8zRgbXQMU8cWoBjDmU9",
	"pA61Wz8qSUeJ1sipYtXUaTd/L7mREUzOwK7JVSthDMxBwVSuKc3C2fsetiTDefh+n2q6pHGzHV1Xk5+I",
	"74ed4TAfdlxLgHzY79cBG1/KPBEDVt1VYJv79Gk4VC91vKz/OtHx0rUn455WAtcotOobSFStDMTHj/9+",
	"JZafPrnKoPaPH/dsSahsqMKVjrG/wrht0GWnp+9AcC3kbyJ2WZSJvCKFaahy7MmJyjFuGCgTNfsZPZNo",
	"HBoqXuRznQ3YX7kS7LUWQ2WX19++efbrgHHZpTjyRRJs4XOXgO7mHhp6QSlJSALnE9lnMp8XE0BkyrVW",
	"PewP/G0ffavZiV1GC7edWp/kSXolzJVUezONT1YMXauXW5uRyoNGjNy031Goe4AG3EQlAIc3XFcB353B",
	"6dJqYu2SfWxbPSYyLXsscKlMa2V0osBB6wm80Pw3F0Cexm64ym2l0LCwpe682ZELPhOmy85evzFdJvKo",
	"v+ssPUxPh+rvhclBqPRZpdFAQ6gwrxNNGrHO00wvUpLFZY8ysdB5wC+Cwr6/4RDAp95ZKcaKLPkeuT2L",
	"LEG/sJVQbwTSJIEAtD007l3Yqz2QgUFtZ6/fbFWXE6beAJbpBYxQUNeluM23qczTmVHTAKaZKm4Vn7aR",
	"OMMgMKotR/kAAubE9rFZshyxoOw7eSviARtfELa53eZO2LCPH7+RU4YfVtXy8eOenJIw+sWuLqVzf2uN",
	"u+vWpzS0L0TMuGFpwqXCFdXYu219Xbtv15oGvJFngxLY4iypZYBkoofmABGH+N4B4GipMjtLe7mJArGw",
	"ephIKEBWNIfIJAorQY8S3pQpWd79XtaLMSYljZ8TAE+uBeNJJni8DPwcQRc0+kAca6aMkX/3WssY9DsV",
	"WwlSvijiSVINMynvr6DnG6nV104Cz10ckmGcvf9wGXBMs9f+HuyvxiBS6cngOkNxdc4OxFx0EzEklnFN",
	"Q3UhBJvYBvSgmh5gSaSyv+SLxBubEpFjrgED6xG0p5xRu2XtTj72984449PcDNh4SC6HAXwz7MCOBzUR",
	"iok0ExHMO0kdeKT8Guy19NSbyjXLLk95LWIGOyl8k/sFHqt6Tyh89MC7gLxdZBA05cM5q1UF1mBxm3IV",
	"j8x2HNMLkc1KFotqCFElDhRGrlCgU5wQXT+SP8AUQtRWQMlSqc8+CldBQ8BHFSI2qgZjwkDaIWFxJRML",
	"3txBF7irppXRZJO3mVTYXPvXl6gwuAhPpnXJzJPEPWdXLxqEwJ4B6oLGa1wJLMOM/E3gybVIM30tHG2z",
	"vbI3UFGcq7rIkk63Y4rFgoPHKQJ7wN291NsRivjw3pBYpB9SSZvQoDXXhiRrQMwIu9rL3vbNCyPdOgpD",
	"9UovFlrBAVCSpkJEVC8Xiqu8tFnAzsEvBzxaiAHttp+MyHo+f58uLsNOYUQ2ODh85oo5kYTCoVorudYH",
	"biP6o26yzFtzAxocKl+9hFbgjG4X0VY5xVwmZAmfC7aw6gXUguGXMM/Y61UyGoTJROSAxFab5gcU3cSa",
	"XZ1AkoLeSezm3OrYyAoMxcr9NEA183D/8Flv/6C3f0BPvCIpW6vfC99cRHOlEz1bwni6cJuBUHcT4rV6",
	"loJnZZP2QYrXPe73WWf3Aj951DUJZkgX2uvtod4bY+VshWZomRKv8mcuIXc9wDUkwRHCxh+HODXkekDt",
	"NBt2PtE5LpLYi5ZG8YmOl4P6MxQk2ChsRcxURpInMOH2EEsSObO3fvcoxMU1HqwtDVcYA0YbpYfDYQet",
	"6Eh9Zz/jI5uWZqU3KCyaixUWJhzsI6eif1ZGo1uptQXzWkQJJ7xHVCPIlAu38FsRFbnw8e+0lvYqEeKw",
	"aJyVPeKKeZC/enILXrshPc8ALKPODJh92J/KHVhJQGmo7BS4vlrjoKYFN5E1t54+I0rmOAx1qN13+kP1",
	"rh43HxEUeqC1oHtUZoFah3ziyOJdhlG0qyQjuyhGwNtTxVgYlbxFd1JM/q7lxrT0v2qpXiW8MJBIB2bG",
	"bcD+fHaBJuWlz94EgztyAA5wkknj8iquAvTmoSLTPmSwY55SKYbYTr5Mif36YH+3NmKH++1sudlMVBTx",
	"tTG6FdbET92Onk5NG3bM+7ZemyuZ1ryIpMz5AAUvfSuRXKWbBIj3PeDttDl8LC5A260s6CCoqu48ahsT",
	"yLscTZbrBEeLL7OG15PlhESKriBS3CkLuhZEStWwHXvwse8hNlaAV7HL0Ar+PePuKzuxOGopuCE3Dhu7",
	"aFgt7BWBJzfc6soePDh0A1IaR1UmB9o+HdEU9FJB/ArkTuoT+9bnAEApiBJCvpnNyawVXhrAuKksgy3i",
	"j8vT3snl1V5QjkiFVzROTb/pUOU6iN0ECk0UdsSkGeNtpDFHJN/aSUB3zs/fYGTE5Vq7m8cHhq3vrXBY",
	"N9h9yGEWGoUQEXOoXNiKl8pOXPcRjrdpPB/X7eHl/mzEA5NGEWoTRH1fC9emxYyBQG1kUneIa0bzO/Mm",
	"/TLD2je10tAbeSVTEUveGrncHp52Tvdo05oJjj+h2cGnj+Ha0I5fvSVuLQsr3T54jQKl2+IyVzaeIqsb",
	"LbeHi54yXm8t3dG4Q3B1ch0ie9CT2uzPg0d3uX6uC+7Cdl2JZQmJXgnWCsOuUAL7VAGKDOvbaz95ZLxB",
	"2IWH2TskxFIZFosURbKzr4ZV25Hvb44AuteQ0PMrxwN+l2W6HWiLZ6+OUN/qXbw/thdgOh1LM3G/1dyb",
	"ZW0M9sf2a0Zk+0xOA+k35TIRcStSM2rm1KzPV8xXDcB5yMgcr9LVW7vrQke3iRg1TmOkHm2jOJZNLjn1",
	"a1kCl5dnLhY/slq/DgfXb8hKLOcqPuyVcvMX8DuSxJz7pcIiiGTMgF+oKYOJxr92F3IJ+pV2SsUWMkmk",
	"EZFWsam39s7s/3XQA9sUP4Yrg4gvtrMwkw6dcWWwkS7Azafewq3c0K0cManoKQQ9A4Mg3mgZWLcBuoK9",
	"FCanBNaMy9k8n+rshmcxm1KcXXl09uxCtWvGXppfZoJfkcHg1t8tpdUyTDHpgZTCHAFqIaqAglutxb+U",
	"WsUzaKtxCnAP4GNGEx5dDZjLxmCTTHOrrtqvZxlkCtB2lpnJwfWnShRSOmL9q3z9TAkR+6wC8P712HwZ",
	"i+BV82Wq87nAdF6uDESLkbWvS05syMFG1ZmmIHgbnxhw3e5FWkUidSNpQhWfjPI4Z3A5pNGFZUP973Q7",
	"tm2tVvpGUuhnQmh4W+z65KjV2RPnR29XxlEDKl8Lgob92m5Mn9JHjhM7qss9D7judEt7QynscFo98pao",
	"n/GJJ76KJy4YOpHqCvRcXBZLrLUay+wVBLLrYvBTtnSqqRK3edk6WzMCtwevA6Ac6OCTFfjtW6lKMBan",
	"Ul213fvtAtsIR3fNk/LG8TlJkhhAsSYIJcIoJau3MIq2qASj2JE7PX3nHUFl1h5nFJTmnpMGEqfI8Uxf",
	"Vg1OtrapThJ9g4EmCI6HlsiPH72H5dOnATsq9T+UO3EtpJjJGKYcfVFYQ+3mYuu5JK3sialbl1x6XpA3",
	"uTtU/6ELaHRhRHvYJfK655qGTv4mCArF9rdLjjTbvUTrFNXWMMLNDk/AwmAX7GLBexSzF4Ca+4jMk9cG",
	"ciQHzEV7BQNF4WIytn9+U2Dc8b8n3OSfPnXZx497+BUEXGD8V+3u9NIh2uRzYURZddcNCkx0DpoWRtYb",
	"aSdsqFpaM1SvdcSCNtXi2WyJoCFD9TNPZGx7+ECdW5U5KMU6kogS96JpXO0zkEC4VkAoOBnESatxd3D3",
	"vcwN0zcKjUEYvV4P9Q0ssoiZl5Sv5hlcoyOeCwULItczAZJqx97aECoI6SmgUU8MvmmXwDAovQ3aNmB/",
	"+zhEzYwyFHgqMoN0ObXNggX6/T7+CnViqsGnX7FmOLgjbvJGtRgeVXvwRZf1+307UdUmYMjgitL0qgXG",
	"Fz1I6+sNmGh9RZXUrSSQo4GNDptmW7Wt8K9kISGgzgk+d9A8DMzS5GIx2iilsZwX0JoBES1aU8BFLn9D",
	"7TXc2VaSgfkNIuSmRcKOThg3BqLl8z67oCfrYrnmFbBrURqRtJNVWkk8Mnkm+MJ+07y9KdgjFxfHzJcK",
	"b/VBVNNfLz6891EDTdiZNvXFbuuVCswKy8PRW3cFwVNExfJaxk5FXlbsDSXTyJ4VDwVdP4o80gvRMELY",
	"Ilte0OwJX17Q3Gmw5cNOvS0rgJaHt901t9RScvTZq7mIrvAbfPiJT86GuEW4elOwB/LmyKTI8EL7OFaj",
	"EHrl0ZDkMnjJZg2ZyrWusAZheemQrjbaN6MeeeIM83jYwDWD7Ahez9lMPV5yaW1nyD5z5Yl7pz1GuU3x",
	"AW+SPb5KzQQc15va2EDnowa0jOq2yEatnPHb4OJIu2nu9NQrPRfZXR/6WWS5uK0/9GszHODIs/NFDQTC",
	"Vbz2gZukBVCAONdioWYR13v/A9gzXUt6+/1vXw7eHHxbI2GD4bQrYuvkpcZyaqVka3YgJNamezO9HeEN",
	"EG4zgkHvdDvXMJCtl+YKzOhKdE+KZYOSXRZApYJGnQHyARnsd548JT5IapiDQ7UFO93O0yr+50qw1HNh",
	"cm2XjL9Abxeq8pJHV0XqNYdfoao8W65iijxvuQKD/8HdAjG2tom/zKMrPZ2OyFsg3eQRct1hA07Zl6M8",
	"RWy45AmjqtbSV71oxfQuI6UhNIUnI9+sGpb4/v5+vUUn+Ih7PYtFwht2wAqW+H67S5rfjngOmeXVlz7r",
	"buFjt6Pvn67Q16xFMaf3rujus/2W/rq3b+pv/U2t56su8hV75lVilUOXZlMiH9g6Bt7qxXa8aS40LS53",
	"mY84YTviNk00LEIKGwjZF1xNHUcY0rq/LyKufhRLE+yj+vqHH8Dfb69fEI8JSNV4LSMwQQ4RnRD51h8q",
	"sGLgJyZNGCBi68CgK1eR9/S1ga16m9Uo15uRH336NMV64zt8QPiTXD8JfUMuwua1y/pD1/wO2BbAUFak",
	"qcjYRBcq3m0Fabxv8G+gC7YE/w6VDkNic0wwKIPWgpAyqh5S3GVu715A0QopYcOOLfdeGHu9BfIZW8zK",
	"2T6P40wY049kvsRiDmAPyoyieaGuTP8p/nbsMgTgx57/tV9G5WBByCDjSdCosgTdBUd0k3L3WKrMPt8e",
	"oox9sVufONb6OZ+Ze4Unf+XRs7l2yMZlvjnG08TrshsQ3ZYWV1yCZ6LD33gkNpbIScYpRkJMpzKC5JFU",
	"ZD1X/1D5+ks4AcI0ZRyiHdDJ2BLh2IySrQYKNiNmP7WEzNbiI9eFzwYhk35YmjU0QwopOhF4ZvWizZPE",
	"s9xpNV6qeQG4U9rRAVUaOdhLVCsaJvsgqJcuyr0Z4g9R7XhdHCr7somYSaWCPMRALpYqEcaZ7++3aUVe",
	"dI3Kvm0lMZ1sqklMW8uTerZCU2KWQ5IAVABIzFpo2EoB+jkBd81BdUKTJ0mwmsPDBg8p1o6CYU9X4het",
	"487ub9Q4ct1mmYnXrKXyqPnctQTnaq5xIYnypauX0GHbEmpTZly4GcjDdrIl+201tBRFWmnZASGRCYD6",
	"H7BL55r13mW4nadcWRF2JZY3OouNcwcaVqZJhwFepAadimuRsENXCFcbuilLv2TgruStDktwUN7oIokD",
	"qGiCls8DCbzzw/L1MesxfOuz+lsr7AaO2CB8X7saJrJUZJjm2WbrWAuNKyaVB+2BtSWhN77WEXmzHRjU",
	"nF0cn59VebvZNc92W/E2iYvOq7qOKo10zu6KGyPNXa5d5kbo4nWPKnEDpJhg9ra6YcIj+MPMdZpSLHDz",
	"8JcLMUpFJnWLPehSLiAnSOqYzqoBi7+P+bLLbr6/EeKqyxbfL7TK5122/J5QRl3DgKvCaiKdbmfZ8u7m",
	"5mmc900KBJyDfiyu2VvgnKbEfjsrlIcAk0R3ewNc/XYfZ4xXuY7pcUJEoFrsOT5UdtmIXELJNJOAdgGm",
	"R26WdsqLlPK6L+zfg6dPh+qgzy7kTLEiZTz3Kf3Gt3aoDvvsrcj96kGjGjfzieZZ3E6KXz4OjPjt4VQX",
	"c57F5S6o3auXDtFqo4VySZDLDeNYUEeb0fHCo1lFwhP7tfi1KoxyJe5YLrIFM0EdIPr+nswH7K+nPwRE",
	"dA5uBMn3wE0/ksoHrAzIdc9Oyu9syWguR+YfBc9EPGCv5rJHH1guDACBlBwSA3dLKL8KYEEqwurvid1x",
	"zVZ0up3ghXYT+qraJVmuMz4TFz4Yqs4VZ65GBSjOzcAjaa5YgfFnitlJMlsB3EFmedrGrv7LHF16ZTTp",
	"nBuWiUhAfizcJtpdIM1FUQAwgtP6Wxig/Q/lOfvBR1u6XKEYKe2NsQf7csvzd6kiOG2qEta+H8NfakJ9",
	"qaJ5phWdSSyBgwpy5SDlrgxYhYU5dBVZhfkXLtHUfM6nEHGQamOPyMgewwA5tTPlxi60LgtX7xA5fCpV",
	"nImJHfEff2b4GxTzrsBK0TI/C0MYfzk6DR8SKpPRHI5f+1iQ18+Cn1x2YLXpO4aGQxcmKB1oJtQBfqVU",
	"pVGVlANoDbqyJsLkPTGd6ixnlcp9JPbOlCeJAUMSpOXbUuD7lwuhi7zLDPJmdtlCm5zFiHxUVR7K2XVK",
	"hB86KOW7ba/IV6o9MfnSBQvWNmG4XlZ6Q1sAvXMHOlku8UufrwDBLUCCDra3U+KlfxFYBcOLis9guk/I",
	"6Il9vIy/aWwZBCz9uAoffFP10KkLLGofsgfSvdsaHmfNttaOJmi4f2M5Tm3nFLQS7dmrxO22wb4TqIUi",
	"fdv0PDegdUppR4fWuF60Bv2vCpHFTjifqKewc8Z/tye8ELW7wTXVXMk0FXHVbRCWXO8ocwO+OvAUOknu",
	"hs8d5wyr+d0GmrqxcaTzTM5mIqsMsB/zqoMmKPkgI33hd2gdoRkw68s0W3LflWboMjMjDlPvm74ZOrmC",
	"W0s1FxTj7SAFz2VNOquxjzHCPOG2sfdFSADcV264fPlSDtW9mgtMPoOG+twzTL/0I/B3ox0+eHuAfLxU",
	"fCEjnw3UtmqKhDDoFxzuXYwegrhS5O0RLkSwzwBoiFdBEiH3wsUQwlU71upJzub8GoHzZSRzVz2GRdA7",
	"/DulPb/tZMdd7y6HOK6hoqgRtH5ill6uoWHZQirB5kBppI0zlzMzh4v+xOWy3iXu9DW2yyE8tkafWv2Z",
	"2BPNGrVUMyrJaEhaEBK08i5WFz9ZW9/ocEH7XlCH0nlpyeOKckpdPi6qdCJmkyKHopWBaFrp8jwZxS56",
	"v9UNHfsIYciTRiS0sjk05OI2lZnolhR/oFfkCVJ2gIpkcr5I2Y5zi+8i5olhb3X5DgLVI1rOJ4fP50+6",
	"7MmfY/v/g2+/mz+pmhsD64B7VXsnSjoMLpWLaS4bZffA5eUp9gJbUmknyQ7YiMPOyD847EBKTTCGFb8Y",
	"TEI5CMDemq/owLXITOsc/Iw/eAw7WK5g50Sr2ULOgkS1yq2qNdfk00oJ7ci7TKvxnH4jHhcnoAvXDDT4",
	"pQkHS3czxwyGAKGh7ys5wScQtLKJDCayHg61KdtbNi406bXKzISbfFSksRU5rdvbxfkG1d+IjLhrXApa",
	"ZRpsXT27XlqZYfXNaAVk9FGaZvpWLngeUtZn+qbmXN0iX8fqDfI3MYKb9/o3AdhQJU2z9ca+6kVrl1Zh",
	"trd94gWnafE0aIUYlXrQWg29YrOo6y21upqKy6/Q+muZLL+4ARdf2zDgXh79fHL6H1sZcMlVPor1wp7R",
	"LTos+dKzMLrRRbHjM3dxxZKjaYRW94pFo42Xw8F+HZ30SiA8stiXsFXN48q9ZmW3KmhgD9y3jNvtGhBn",
	"rXXBuTbwGwQHduiVespSMnw3+0d291ikji7dmYUm3NTBMzyTEIPyYPaBYgP2xgokU5qKS07IAEeNx0BR",
	"Eg/YayFSkVUeAAJbu6ozMRcKfFn+0eBG4Zrl6noo87nbASd1szn9IOvOo/Ojt6BeHp1UctRdIgawd6aZ",
	"6KWZjoQxIq4h1LnwBconDOlbHG7gZjN6Do3rR3pxLzN6rCPTD+toO6Scggqn4TtUolcFyDodO9cwKEsE",
	"guFeB/fhqYTZ3swMVzxZ/tYWoXhEv1R41CEcANYZRoGQxw8/CIX/zvNFMnIVDzukB+IsYkysD62xeybT",
	"CSKcO8OnnSBlj6LEneXtGlWsoxFCdG7erRXVHQ6+WEcO4BMcoDrLpZrtTXkE9BxrpZNUI54kd3prDUFw",
	"5HEC0QuRaWOcauPcaG3vrzPptsneyltjcYsJDFC3c10gwnq7hMo9f86WXUPTRPkSpCLwr4LH29+1Dfk9",
	"/ds7Uvk0WXoC/JZt4/hcHy0wHhnGNoXFQ6lfV7QwoLR8tGaWwSQLDqtFFUmCFuUKoFt9YeMjmL66+ZH1",
	"dZetWV/hOv8JhaS/mherUgnWp5kW6gqN4maFalZkSftt8qfzU6clUyNAzAsVQ6i3v75auT7Y20t0xJO5",
	"Nvngu/3v9p/s9tkrrhhPDDD4WcXuWnJ29P7yzel/jC6Pz9+dXB6P7DuEupaZVmAScOmeVTN96xsq18BM",
	"tslGinQPFYypvAVrX7O7EMrnoWhcEDpzGcDw4BOUkuiWBHHdQ1OAexhp8qgK5eAL8LPZi3ASzd5H+9On",
	"vWovXdPWbyzs06/30TbCmfS99WkDoHbQr0AqFQmVZ/b4ETFDGAiRXUtn7vEefV9TgD2QS5GxCFB1HMh0",
	"MCQLnsK59+H9+/9J3yORos6WZArcceQ1uQb7F2ZzsBudXRE909Onr9yLgWbTgMLSY1PMCvQBprci7sGF",
	"z7dzsiQuESQk2pkUMsl7UnWZoja58Qbn2pFaEs0+NB5MUBTTbVuXaB6vneSyb9RsHBZq7unBgL0TC9tz",
	"O15kCz7sLaQqcsEuL0+h1OGAnYnMSAPKNTknY55zu/wwoFbNEjFN5Gyes1g4UiBZ8mdERQYE7jIWCmOH",
	"HPVYg4vSSYWVG2/Bbyn0tTN4sV+mlLglrK9FlvB0BONMZYJkkjKLw9OQdAadIfr0c57NRB48uv+pFIPH",
	"CCeVrUp4WL/oSyfnqlWP5+sTw9yiYO9O/bq31cFQhGDmiGtVLmUwaAbbo3xn6bRdtVXYzgKXwr+x1M+2",
	"W+5vBM+LTLh1fgoNse8lEdT2IlxhbNFYYBXSGr/IgrfW1xg+/PkrLeAeKPctm8wE9KInVO/6oP+C7fz5",
	"2+9YLBdmF8Cke++kkqfveqff9q4P2c6z757jj7Y+rAWyWO1eFHHp7xjTliQQsnJPjstN2b/L2j8M0qfq",
	"be60LvFP3Qc8ch/5SD2825Fab3wNzI2uTE7Yr5qKciZ2qy1sGd/7nYxeeNSxL+4oPdy2uhb2+v2ZEuT0",
	"9B2TymFegBAZKpAi54XK5UKwt0IdnTiZwkKRkgcoJV6aeNi9oXJHqomsHF4290OJv1LZCat2p1bqNsNW",
	"7b0ViwXvPetBU3eg5h+K2Uyq2Rseid01oqrsLbRXQUKryBRPYI0jfJlQkRRgtmkZi2ro/6uzn/benv1E",
	"GAwk7I6KXPfKnuspDSCOwfr+w1tT+yYI0OG5tAIwIuifBc9bUnw+azdvs934rT8JN8eYY0nI/SdzY7/V",
	"UL5mE6sAwrDMEsQVVd/LwTBu2syrllCrk0ssIMiraGOwfYW2EsMyrmK9UMKAqyDYDUClftjf3+2vzTk8",
	"3MCdnut0dNVGaZv2rnyUfYCG2453ptNR2gZIGyWiMCuqWd3m9XzvdxWHzfT0u0jD9sTjWljhduusrIrW",
	"GV4s0RyE1FpZcKbstgYuPN4u3H5cXV5ACzeq6kH8d+D8ruK7oRr5TquZfv2yZ/IlkAnS9uqXKQeEluuo",
	"CnJNgQxDRXz95PBhCV+KrMuAeE5xYg/mcW+hYzld9jAkMOORcKRYJ5D+xVVuRX6Z4pAFqLPvP1yya57I",
	"GB0ZMy6VyQM3mvPaXgJoNHJYmJDdYKgmRc4WgivDZP7EsFQbIwkoFfOlmFTwijCNDNiFQG2FzquYCWWK",
	"TLClLrIgJBR4GHIu1VBhUzByVbawiHzsgEvKc1kcHD6z9xZfFVhWdNoZdP4kVWRXNubE/al/LTGwHwx8",
	"ncEBQBJAQdJ7X3O42vgHEm7yn6W4cWT81T3S6hnz7BvgF3MwY5xQdrsQ8sAVw6WHgJpSGZHlptVNFnZr",
	"VaZnMIreji4VM1ZzV5HYNr7EL5wPaZuTqUhtK++Q2kWLwm8bOWUyZ7EWRj3Jmbi1rd+BAaC9w/AVu5vB",
	"YezIV8Zm7Z7+kDZtlTq9w3Cg0dati/o0/PXiw/szns8xjxKs1M7Z8Kc+ZL1a0YeuhT9BEqn9W2cuJxZ/",
	"3a0cuuVabcZh4OJtRGGA0dqK+hJqd8cuNjdu8NufCmVE3mXhgt/ts0skkrBqHHB8OfHFdkhDgWelivb+",
	"tCiSLkT1wFdQGbAANuZIp24nbZic9nT1qjzFmAffrsC/Z5vQ6XawY/YP3PN/Sgszx3+TxP7L4/hSX2CR",
	"FNpmuwL/SAX/8Fv7T1US/CkTED7YGuSc8WuRGY/00/RAObAuAiQCRRaRY3P3bEuMYNq2yF476mWoBHmJ",
	"gMphZ599H3zeXQuHugr3g3DX3VZdHf/S5q7xEg84Y3fklC7zu5011CsbWtIqWl9yI759TmpFEIyG0mA9",
	"ldH2r27f5BckTK28haTOYB4g+BFip+x8WDFHbjbIff/euaqa/IKrSJcqovduLR+JeNYWRBO2H4p8TgfW",
	"Ql/FM/EZfQC++dGNkLN5y446Q3A51wmG5QzjiaaQOZi9MLxJFxUgl+2JvKFBrecObtFf77+6S8lRJOvj",
	"XjdLC88hPwJquY3O1Z+lkTniQMB0A+KDRjWhdureQXDA3ZGiAzetjte+8Kdux07jqnBVYm/D5Tpx3CSQ",
	"csW+BywPeHB3+1iZ7XtU2QHbB9PY4izIYgtQET5nfBf8tiXkZiWOjV8vGHeDZ0ShkMg6/qwjwrakAkRX",
	"Avmsak0jff6h2xNKC9ecVY0JxAbl4T6gtIA7fltzmmODtoDHbc6nz5ZQwlFQtABFt4eFXlr53cROaDWx",
	"BOto2wtKReHaCnHwJ9Acz7gxNzqLV+JeK3EzSqlQNZdSiZuLZ1H2LD/7d2NuPmRxOEP+kY1JKGH9bQrx",
	"TwaDmKrNco+M5tzMV2lEzGlErjSzpfvs+DbVxmO2gGPYiKgAZppMmquqne+vb98s/9fhX4p3i36/vw01",
	"pL28uKyhspq/67mKtdg4IP7pbq2TbYODiHt39yC6zPREFzHDStjRSd3dYdiOsKs/zaQRvVnGY7Hr2BgN",
	"ckCSl8yl6LzKRIwgaYbtHL1+tYs5QUU+R7cZUlIRu5lhJ0fvWKYTwcb2/2aPyzThuR1guB+OV5rvZ2Ih",
	"lez59vb29w98YFKXPdv/86FztZU0OkE+KPGa8yKWeu9axkLvtgf2RXaE+jMYLuDNR2i+Hpd7pe/Efop1",
	"5DxBUs3M3kzkkEDbC/CWataaWC6EwtQB2+BuJ9ERpXN0CtOjWIWDwD/X1m1UfeyCGMm4M+gslr1ZlPbo",
	"u6oHj3AFGwabqJy2Ubua7+7xzuvDI4w0APBaiJKUieizoyoAwtHrV7AAlFa9t6/OQh/eilStckgq6HB/",
	"PmwLb/GlnTG0TuQNPtcuO3jx7FswLMC6QLDA5kD+X+zg8LvewfP972r0S77UbrtFvJy2MCqnOoPVxle2",
	"XyZmbluWO/Ho7MQHIwU1PemyJ6Kwc9e7ESY/WBWS9PbDh7enx6NXpx9+ej06/fDq6PLkw/s+C7NhKtX2",
	"tww1WrEA19vCV8qXEBXTy8kVr2hDgPWL/uO68aWC7OT1FmN1dv7hr8evLld6m+9rR8cxuIe3doWkDhy3",
	"jyqqTxSrb9yh2sHWnBeqy97+eNxlryj5/1jNpBK75bnqHLjIxIhu4lhcd1lWqKEaz0C8wkvD2O+eizBN",
	"9Eyq8QMeGIf9F71pws28xProhr+lmfafn/X37eeHOBeAhG0PJ6p+CqwW+oGf9Pn+X75tHAO+M/c4Amou",
	"yf3+nx/vULgQuXG77Ojs7PQExdHo1fnx6+P3lydHpxft++2zj5N/Wsn8mS70AEAObjEbXeo1+R+uvG1l",
	"/0aJH1b6dUr7B/Tjsx/kbC4yl6iw4FeC6SJPixzzd7CKL+vuR2hLg6LTB9jkOmU/MrwQG0+CxUwxQT9a",
	"juvrgYIFcIgOYIhquz8Y+y8SUtCKZr5lRAEtyXL1n1M0gEuGusOxjODTmI8fyGQwqdF5d5YJ6JORuY9Q",
	"IgaK1z5wCA9n24IBcycvSW7jc2dcaQGF6YDjqTT2kAN8z7cZV7k/iAfuJK4/yeOFVGMCVIyFYeN6CQqQ",
	"wAE08HHMUpEtpDGIAmS7Vh7hDsmwR6DuJJX+HWAH8vBAr5eccpP39vefb3mUVw7wHk/T3qSQSSwyPMyp",
	"3RRhcPTuc+riAD3Vo2ypqmLgTvv1/f4Krn94yr+pQCzd57jf8g6ycTxaAPl5SxpE5QzaWOnDnEitg3Tf",
	"s0inI7UdTGuks3h7mNY64RhwUJt+e9r4drK0nlHd4hJezQhxIyYuwdUtZgzwAYYqT7Ew56akT6zWQo0M",
	"Qm+ATDa12yCTPBdD5arp1apglMEd6cUCAgDwHKTIJHs4Apybu3gEk/ezo3lD+DE76WaXhLOb+YtjlxPe",
	"Db87eW0LvTx5/3Z0cXx0/uoHVwqC1StgoPabanY5PHp+9PNx+YXdFNION8RNITDSokxAncC/K9LSpJpV",
	"pq7bmWT8Wqwsb3+sPRAX0ZX9b6ZXQrgU0ZX9762uPYqidCUjEPxaewQhLVdCCzSBXbsdzNxdjWnQgBIo",
	"RejyPVh6SzHbkK6OEL3NayumIstEXJKmB1z2/pYhFFwujP3/NHtSDYgRatUFoc0b9WIzw0ONBssLjYrm",
	"uRF5eVt+Hi8YQoIevHetG6/gZlYfrQLGqbiy/49FbbSKdnAuPhUVXvs1bmJSq+wjbqg8xPq9PJmOWoaw",
	"CNuIQPa7qzgg8JntODG2ZSPqNOekNQi1RSy7o3UIgetPn+Luffp00A6FC1fpzNl2Xl0cI/LtLj5spZJ9",
	"9J2MMm30NGdWFrFfxCR4HovilreF14H3QgYe4PSGr8G9b59tQy5ANKEKWIFrnhV09jGQeI0mlTLPlinl",
	"GztRwEPHjhAzA95BDl/I1iPYgSr4JInBLopqL+O85HJCuSJr22KzHKvEI2cq39BrNidV+5JtK7ElRXwF",
	"XgKEQHCldM7LiyoFzBIhSACmh5id83xhVW6COuh07RVRZACKUe7fmOeCUIBmQsOuxT/NnKeA0OcM1fax",
	"RE863U4i1ZVneRlxM1rqArHt2qbEdfLVnOdHM6HylRR+QbRcPqc0Dm6f6DNPpw+KjSM7fGK8iac7VFwt",
	"mePTjxKeec4b0/XR1yjL7BfI3wp+ZdChTM7zVkqYEDimOjEqAHMXtzlEUPFrLiFfvDWqF0uPQPWKIUa3",
	"/cINvzkrFjXg/iaBboe6P6Lurwq5MZgnDBh5EyGUHzZoiTSVEds2MAyrvkhF1BZdTFiVLU1CB35tlubS",
	"QMpxSce7akHcgdU5dyDLLe2jBTWqLKiNdYaFA9LQDXyOF1XVBGkdka42djyyYbfWhWo2ZE29Y7nWyQio",
	"xEYL3kax8D4wsOoEWceYLepXA6lNm25NboZ/bcOidYEJADqJy+AlNzI6KvCeDkMqApghqmKe52nn0yeI",
	"2JpqDExROY9ArmB0QgfFaocSTTrOiDGT+byYgPmCQ4l4Qn+0YF7C9xhDEUu7kScwG1di2UO4EAQRseKk",
	"yhKBViBMKWRaMc6ePsX0YcCLjuwaVaYwzJaWuYjyIhNPn2IqcqQXE6mIS2ciMNw/z7ibb5/jaxwmUiwy",
	"ZY/2iKd8IhOZE91xLBJ5bW+Py0kmHUaLvd6ZiCeoyXzzDfvFbvt3/Eq4ZEj2k5L/KAT+/A37AZ/GBYoK",
	"wMt3hy/Yv7GfsdMXmPsvc9A03nh47RC4icankYh9LiKZZuA7O+fqir0B6ie2c37+hnSRd95XbWsHLGYY",
	"cUfqIG7zLsOYhy6DoAcU8BD5gFUce9es0/qMrQtBCrqURNhlR79csJciznR01XUa1luw33ftyMwzncoI",
	"a/yBZ/ENzwQ7iiKRkAkcdLSTd68rkH6G7Rz9/D8P945+/p+9FweHdjXcfvdtl70//vDefjg6f7cL7b14",
	"d8x2LiIOBwh7x/NM3rLj2xyjANCDeXT+zs3K62BBvnLrKRgxXGmvhZEzbBiRkQeLb5bpIiWoVaK7smok",
	"RK9HSWFykWHTXI7SjlaA7s8AMZrm5wedyd/s9ksYgE+TZvva1uZ9pIDdmvIshzUsYsYhWwwrMi057pnw",
	"5mN8TdhfyCPgEE4KE3kEaVWUgAZVIoS6W2SR1rZdPNcZJd8fnr1yVMG5UDl9m+gIrZ/2hW+kEr23GZe2",
	"ua9ts+zOgiVOzhDCabcDCkn40ZJsSksVoeXEsB2CVu9i4S7zwOrdEE6+y/iVQrOwndyjk9579A241Fxs",
	"0/nRW5hLz7rsWc57vJjZmkTcyDS+ENm1yHoXQuXs+Bq93LYyp6RbJQu3Vi6SRNqPjjZZI8lENWG5wbZD",
	"E+Qi8x3OB646YujxaB7OyrpDyX27q8AVqJEwmMd+pOBSwqMru3ZVCKIA6zTkzcZ6E8FjkfUg4JlA1nzd",
	"pWRh52Khc2HFA5WAZeV7HOsblWged4M6uiSFKLYucg4yu52cODp7/YbUTQDbg0P9p/NTw3bsebQHh9Ke",
	"ebY3lYkbiIuL8zcszYSdKIcr5kD6KJcPhpykgF1l9vhnx7ep1REgac927lUCWdenQMMmhXEdCpANL17/",
	"aCgOowvZQBdw+GGDz5b5XCtsMgjIsxOwQGLtYBsnkGwvo+AddAse3/bwWO09HTfuLgDwVU4DJf1cQNJP",
	"mTmJa5LyMDEXyLCdP0kVdSkHCfJ9dgP2uFq+JNZ/KpXgGXsnspnA3cNzkYADE1IowTCksxxML2hNJu2L",
	"0t2RapZ2jQO6Y+dAnExLpYVcGbsa4XD4tJXMPYW1vYVQf8/cAX1+Lay+idufFD9cGj7CG+EAU57Pp1LF",
	"vrLLy1PH2lhdvgGAsG1TQC8FeaA9kFUo6jHufgdTEGCe6Fe34sq2smGxv3/4LcMzC4QjtuODSqz2A6cB",
	"u0gTmeeNHZUJnrgIBtxIrhxMR3ks2Im128/eU7H6H4uJyJSwI/yBUsPgNAekAZ6wMS08lzc2LuWX1Xuc",
	"sEjkVETLKBFswRWfCaQktC84y/RC5HNRGPbOytcIpuWlw4dYaCVzwF/0Sck413pihVtlKP6XyHTvNTWf",
	"/ZRC8BJUd64TaEpB37kTsaYg4hntBv9NIm4h/faksoNQKbI7GKoe+zNmdL0/ZjtWW9vtsrE9YvAb0sZg",
	"XM75S5n/D/s7TDoWyESCkzyXabnu6MRHaUxK1NiLYEFfj7ts7CSxCL9MZSrsyvDfsR1kK5mUAr2Ur/Qy",
	"MOY4wazpnYTZNGY7ngLO7zC/kGyX0qxQUM5l4zlzpv0xI/c39pegNTPRI3TNVv3zZwn6KTrb/o05eBSm",
	"M0be/DK2MtR2d1CRpDrPkmI2Az3nqHIBGLBjboCbk8exkx0Eh2hnF6I8MjGzupDVp3IrocBskchIUMi+",
	"uwAlCTvHTKlzYRcmID1Vb0O4U/pS7yVixhMkNMuT8v7EzopJIiN2dHbSCdDAO9cHPEnn/ICylRVPZWfQ",
	"edbf7z+jBFC4ze2BBcfslWaUVLfx/kLEwOnpO0grR8riJWxSSkqHqxCoHd0yEZ8RdQ5o21ZMu6WAN4Ou",
	"uz5X0eyrEnUuyvqA1OqWjj8fTcQV2WD6pHYZ10JST7ukD3lck667xGNNZCTihl1cHDM418Hf6DN2T2IY",
	"blsKdLEOXqGFyV/qeOluty5DswyrQJpXd03eSDMTvMFbJarXdUoDcUYUmMHD/f3HaQEmc0DY0W2+B8PS",
	"MzDA1QobHII1XZbhQzifUA1ulUFjmqoIDl02l7kZQS4k/E1fCAUOY240IPKXgPtdmskum+ok0TejIh2V",
	"BNpBsVgr0WVI0tIMqm2xMuD6AL275OvqUsfgmMGe6gxjEryV61O38/wB5wcIZNqaeEIQDzxsalaatl58",
	"mUY4dQzWAA1waEYCDIjAgPS3Xz/92u044G4/0rAAWe/+9x1wTcwM8Z5ny1GISWAb5MReNOf5aqH3KrBt",
	"2ivI0VsaWbDDOmgM4xl9nPkTbzpIzg3318xeha/FUFUN31CQOJ4zMZVKIJDJPNPFbF4a9kog6R/FktWw",
	"oJ4+DZvJfsA2gOvKNxDm/TZ3GownxoGgC1JN7cte4cvgYYzrRmQpPDepS2zHm2OcyaVLVphdZMcpVIQs",
	"d1idu+6EXfevYBFXLOX2OeBGuyLnwNJOs9u9nswNDw5fJ3GvMLKPgwIbRcWiIPWezObU7YqpOuj6G4qP",
	"gAbV+m6VW5gH13nb0DTTi9SZJEyeFaAcxBRCSZDfF8co/1Dro8kaVxbAyEn2sRsMJURskDpNqrTI2Y5n",
	"y/GSzC4aCgQBZWVMdObkDRgPaDiw3d5CvRPw7sDP9q6IFZCryBUdD5w/cVUNsKnw2bnMx2D0k9cyLmDz",
	"B2ZyKIJCaTxwTkdYiqAgws9WGo/BZFOdHU+SCKVAmIwHDDm0dASAEISHXnn0TaJvHNQ6XbENAGg4SzcD",
	"I7u3aDW8FwDBfjJ1+EgwI5VpK8OVxq3+hzGlF8MRMFTPfDtiadKEL2vV+ZntspnIafZxzIbqea0TStw4",
	"uU5CkCR+CmBvMYCJUUeH6kXf6eUsE6ngtnaVS+8Xk8arUTEoqVWVx/sEH0nhCXyOv4u6U/d5PqayU5P9",
	"fut3WXX7dlltN3aHCnQfp9sEyksbfn3zWH7lHbV+UbYsfnCwfnF9JQrb9kfTVmBgna7SoivgBSY4xNFU",
	"WDkHt9ZU4FcXvrvhnsaVu6qBRg3GMGWVBp6UsV4kp9G8jozrPDzMXiaCzFtLApwu7ZKob0XISg9UTgg1",
	"gQhX9s4GRgHa1v3S2kEv1Zlb9VgTUcUB8OcciN0IEV2COCRifiAqeWlHgHQDuCaCJRDJRsuRgJOd8t1A",
	"P6eULP9QyRX4xFCkBqBdziD9rLTa2/7YuXSWEdMiJqGvL3FmHlNchu/5nSRmtQkkNBtbCy1C6Fut8Bt/",
	"afHiTkqKzkOMElrxQIFmMBEfI0Kgdc8fv3XE3qlzNtWFin9fiefGxgqMCNhDgNVz906SEFYE4BjA9qZN",
	"bTdmXexslnfIPbvmUgb4dYZxx1Krpwg6g9HOOgt49PC7PoNQbbfb6TGXGgJSBack8LHCWHaJBdF00d5d",
	"jetGLPskod/wQWQ+Ap4gEP+/mTzeRbkm3Jsj3wPy4aIBny24klMIrLQHS57x6Aoj4qmprj9DZc8RJPaU",
	"peJNtTubvUOhJDYzwAxGmu8QQ3gqE2GWJheLAVwkxGBvby/l+Xwv1zQVkHdztOC/acUung3Y2Dwb7O1N",
	"iuhK5D3FF6JZ3r6XSHwv3IkCrx2Px0P10TXx095Q/dd//r//9Z//57/+8/+wj/j4SMafem5g3Iz0gbeU",
	"sR36wY/VbqUGGJ+DT72wqloV6FDxU115Hiayd9Brq6ef86z/m8mb5Q+3Lo/lDte0z5b+Tyrd7/dpwBon",
	"Do7tY2nlOMT4jt9LM6+2wVnTmjKNVtkKPv3yvGl7mW/93ksenzfUz/WPOGGKV4DjOyuP1PCa5BIJcufi",
	"V4GwpHU/Kj1hFXEJEzATeTsaKUqRqrCh58qISJdUUkpPt037Q3VOF14vIZHNE3IxK/LUc6Rin5zk6g6V",
	"Jz9Fozt5L8hh0W9Z5LblL6l33Y7P0UQg2TrNKEH0On8lJItheLzOXF/7jy32qjldtvhiiQ+QH6dHLdkD",
	"KvfOAM/AjqP5LjPG63stZKqvX/h+fcR9iONvZ2LdJnSIt+VacqvyK96A0Ohmi7fYcvZesFo/OS8UIwJq",
	"nQFsa8nTbHeOsyqSN8reCv0t6yd/12G5MHhz8VV13d8QMMWjeclFCPAyE+CHdmVgT9lz+NxfZRbOVe7T",
	"Hhj6dEd5VuTzPrlY85GMHZ0hPCpi+80uKEqZsEpil6WZiMDR2mUqjmZdtsiyLlvwFF96evqux03v70U8",
	"E23vxR9QnXIVk3+3azXQfD4tEiWM6XrR7j7NkfOgC0kw+bLL5iJJg9KZvYjSB4kxLaN/FBw9/g0hc0xU",
	"4Y90ltrqf6cjFF+96op27JfJ5rPzy9zVyoVbv7a5a1oJmQzmgt2v5+KEy/k+N6cL4L1MtBLhADj7x+bb",
	"0j98Jk2rMDpGI6JxMsa5Qqw+4La7O6vBa4VhPRU2djL24Ai7kGS84hPSDbEQ1eOKncaPiu3HoWJs2IGX",
	"DTsDNuzcyCuZiljyYaeLP9YNRbbcxyH2HZ+Z6Hg5IMbsbNj5RA9CCpMtcbA/VJ9IbUbm1UrIwaYmEXi9",
	"8S1yIQtBg7AUhTJJ76KMRIVA1tdAV0j75N+GGLwxsr0Y+diTYefXejcOa934oRIfDrHXm7qSIiivucPg",
	"JjzNdcpm4NMuB7d1DOZyNg+JCOgpx2aerRoAalZb70OTYLNxaSYjMRgW+/vPosP9/X129P41k2pkch1d",
	"gTQtW4wCgt5YwrxDFfhnsE1ahv/gRXX4f7FXeR+ZtGnkCxN2n3qVZmIqb7FALhRX+YBHCzG4w/SgE7nW",
	"VSDsNnjItY4b8pQPYgEyvmXLvKittfevEVcB4jCgr2+sdlEkV8582gVnVOlGdlZVbhg9DLaP8SuUGb3L",
	"ZSoG4e7Yu+2p2A7fuE959BCPCLQMtmZ8fDhU44GzGZQjjILDjlvLyhx2jk7gp3LV/W3YEYsJzLLv9ItP",
	"tSpjHcGUtU1DMJ7DTl7kOpM8gYH09R3sf1p1V3+b6AlP/gcp+o9mFy61jG6nbaSr1bU4jb6wEfnc177S",
	"gFyqI19cGaFokz+cS+oMBTLjbAbLjrkL5gY1IuOzuygRkHGCoXbc8e6X3EOYH1cYZwsoLQo+6DTrs8sA",
	"AYxJ5zgVMcThNf2qOxcXx7uUcs+THkTrUsh5M1bvnM8ec8OdH739nZR6ePND+6r1lC14dhXrG+UnE7lI",
	"XQYOSGeAP7B6jtnG63x+9JZWS3vEnF81tZA5ck3LPAiRcrsREzO/tCywPfnjSgLb+h1vA+gd+SSktz5a",
	"bndrKSE8i/sK2wcWMO5KAS4g7+YgGwsi41FdNQMoR2S33NsusNA7HZchVPaaNZLTEVAVmfGAHU10BjxG",
	"XC0Zkt0SfRZPMsHjJbIamRKkC6OermRaqefiSqZY1DsFnR2k5KK3f8Pj+lpkkMMyHrDXmV7/JAwEdt85",
	"g9xP0upNSxXNM610YVgPs3e9CzzP5GyGyd/lQxSEj54gF40kFwt7m8pFskTxyqO8oGxUepICnSBaCGPV",
	"87kYqkxEWkUykfh7onVqxTDdBnkmkJFExG12Wpqkx/VG0EvuJHYPH60Rq02hbsXSrP2BHBKu5WVwaGUP",
	"T5zLaaN5FC8cKx0SzpUAGBLEazwXPIFYtpjh086pS+IkME1QfAm9valti/wC3//43il6UVvIFQk86oy3",
	"o7YshoPHP0x+UrzI5zoDGJleDWTZW9W+2EJ7K3J/Ihg3VxtXFXnEylXVdBZdOqfZWl+RC47F1T1BfnyG",
	"1/OSIi7NdDyq07/BlytcN1hBJ3TULPjtqVAzOwaHL160oHdvbFomZuLWZRGVjfvf0JD+09H13/Z7f/n1",
	"3/5Ub+j/LozIRv2nq9qKFa5q7Iv9/e6De5m2oxKxPXfbqkEj0kzMYAl5nmh1fPXuJq/sBEsevli14Pcw",
	"ZuA9X4hPKEsTkYvm+rcaCIxeU+49bwHQQrjVTKfpH+iEAi2LovbWj1+3XUi8FfmKMXq4s6GyhFfFfsUi",
	"5zIxQcTZ+pF7r/M3GCp2RzmbV163YczWis33Aay2mwGQLUTtRqLFr9a1LuxNkvHX7sbgLyVuqHdwYXTZ",
	"XQ51KxZTqSRG1fsgLsrUL0O4nDfjJyPYK26cI+MCgNqo+qnOWKGCwFirTreagFWxGKGWAjbkqlX1smzr",
	"dBs/SbWyZ84Uj5GqYORVjNmvXFrtiFZg8CMrPRqVb1trcj/YuUDLMeIAkYG6LFDibzWeBnN/3PJ1tWKc",
	"51rFWMiDEkDUPFnwCSNt2Pm1+sCnbv3l4F558PfbuUK3wfYtmeh4+UgNqb87/PipNlm+GorE6UnV40kS",
	"eqOwZ9jeoGpfLf3hah46dMhR2Q+/yGyRT02/j1+slNsg49vaMi3rClPjsUJqwqeVG8pBO3mUo+031gtq",
	"bMUfZJvhOC0jnvNEU8ZhLYG59BLeeVuSG+zLbUvnd/tdtye64r6C3Vmb7i+wSbvNCQFn5IaXI0jg9i8n",
	"EMmHFBKl/7TqNL2fqPALf7OoIN/eOmFBgBnB+JDzF3+uNDgo4kAhGtvPQcnSTgP4scrgDxFmnN6eJL2F",
	"VDJZ1MoUGZWY53k62NsD6qG5Nvng4OD5s+dOrJUD1pBv33zDXgqTszNIHY5QM+mx15Al7KFFdcYiMC+C",
	"v5vl2sMxBJ55QO0GQmHUPsSNwwcjnNIFoK7znBuRG7Zz0HsGBlKrFC0EV1LNpgXdW+CybKrXZAoyCBzf",
	"lUAKqOuVVgYgejliQU10RQ8K8PloKUDLKqh4bfmJoA2WKv0jWB/LN/xOHh/s3cqbBOYSVO9wlBiaJF7Z",
	"BYxQGNd73e/ukhMH7Qn18/vcdMMkkDtdSuwW8JbKe19P1lxH2uLwH3MB3iMK/24WxRoCsx/3IJC5dMO3",
	"MdDVQUNXheiTy4LBtYw/UKj+HW/PXzi2v7EBrJBtutVa13+OaPB3XP5THwfs3/KFNkIezX/JZP54+yCP",
	"5o+4DbZ497oklMqItweu/PGXtXMp4wKTyogsR98MWiUNAunee9G7I2qdjf+EynwJazS86z7W6FCHKe1l",
	"X+28etN02O7mPMKvv5/NsCGL1q+ivY/wx1aGc5joTrsEqcdlxOL2D2o4V4RTRw7draZ3lRl9xYg9nNpb",
	"2Xtt8TEwD/c2o39BV6esNPWr3U7ddW+TNN0tb/O77GEUCbw/lMvr4TUJqNsRKW2tSLQtPx7HfyAhcBTH",
	"pQwAsI8tJMAKGZtofa/r2SPporVAx4grw67EEoJFeOAlsh9V6Sq6EkuWcTUTLIyiyudiwbgZKiVuEqlE",
	"LxZEkIOBijsY4r5LqAIQGumBsTiWwcsQvHOobO/tq0rcLsRaR2I+EZfAqASDwi6JwLqEPhkqmTssEwcP",
	"Z0/sei+DEDo78PCz6zn2tS2Cy47Yj2JpHmnHueoD9f1uFpP2GPbaWmudrS6mKMMkybbpYRztxsMOjv42",
	"oa22LwjdwXbCqGVaGP9UOr+du5V7qdxB91H3UYjsfbwSy0+rdX4o9KNYbgrreaUXC94zxKEQe108MI2i",
	"cbvBPj1Uq/kobUEr2f0e7Tv8bsQNIU8xvmTgHJBdjLcadmyR98LY9gDirssO6vM4zoQx/UjmSyzmqLGg",
	"zAjDr/tP8bdjl+MDP/b8r/0wiwqaY3sA6e2uPWUJ0x1R+L0wXarCPlUJHAqb3/XIFDC17aFEnt3q8fLT",
	"78Cj0xaPGeksLoF2/mk2Jm4M2oNyu3v3V6Vf/iiClBGYpFwzUixa33sllg9yQVyIDOkwv0bdhQLB5W+o",
	"lFwJkTqoDKmQtwShBR31AQR3E/8BS+SVYBdzncrpsjtUZ9rks0yYLrt4BhABXC2rRAr0ZJ8dJUazK6Vv",
	"FONmQLX6xiDs5VA5XiP4qWslKtLa8oS+Eb1ILxYii7AIxNe81Pmc3kPGIpNLhZYyyPibCNeoyRIThuzY",
	"X4lln5HJyQriTIjeDV8ymD4QvidkgUJMzIAXAl8GPiwipYjm9pTy9BHoSkObFY2uq4BPDKhiZT0s5TPh",
	"sJQcMQUxK5zEYpHqnGhP3mucIcBSZBOR3wih4HHTZxd8KpDPFGLphwrv4WoJBZicIlJwVqQYZ2/f5+OS",
	"gBXDVk0ONzt2nmSqMuxHZyeG7bg1wH7R+hX9tEsTyBJ+JZi4hVMMlsUNz8RcAwQvhp7m2g3LVGcs0Te9",
	"hCN9TsUlR6385ej8/cn7tzgCOZKTomtSuQBvmDRKJ9LXIkuQ/heVB9MfqgsgNepFhHVqu3p0dsK0Spbt",
	"2DBK8AwIQx5JaQ3e8Dt5/iotWIXjAD8/LPzRV6qIBpIRVnErA0yw8kPht0vZiBxuAjzD9XgfpbXEW7iz",
	"X9JpTo/vjYHcx8f0Sv7/KuP4j793sHO85Kevq4or8v1a1r9LFL67W9InhH4RRSrIWS4zUcE9VR2Ery2X",
	"mcGXePkskRR8Omwz1RljU/6V7/yvfOdHyne+r0j7IyVIrxQP95ORQZr0nbUEnxascv1FlAXK+3xMdeHx",
	"k3erUUzBBASmLZeRe78opvNq5vUfOMHXWXGDnPT7aMLB4P+udpSiZU3jtR/ZLx9pTWOeFxb9WkJCie6z",
	"IGr2f9q7IE5vA8B/c6QpBCivy0yHNG0D90SCNE0SIBfwieeIGttn5zjdhvF4IRVLRQYwhVr1W4Fsf4I3",
	"P1TUUlXc2fbhNgrl3d/1XMVabCPtNsc2XfilFAQW/h756/jSZ4//0jc6m8g4For1XIp8c66/vLqDW4Z9",
	"RpBXQSvRbRW7MsPtsYcLacMOoXgWH+JGhr5kGcILiBje1m9DaXiFD8DbP3NbVHdDOTtm60i/s8qMVjdD",
	"9/P311e+n/4gKxhwI8ie3Fxk61b0R/tPSyRgtYXOIRDcAdpXLxZsX7nPWyl5MoqQ/Z0gdl/ymJ1XMXXd",
	"mmbSeASQL8eAAkPyOxKg3HsN4tQzvmLJde8iNjeus7cCxOPLpdeLH0mhhNbfSUr9a9H+wQQnEWTVg1D9",
	"uq3d4dpaWhaBBWMX5RnP52fu6862sA3QFs/uPJPXQpVTi7z5xtzoLO6zn/yMK4igYTm/EgbQ50UsVCT6",
	"K5ICvXR+rJxA+4KKQaNlsUByHrhq/cB/uayVVZu6bNlXdBxJsj0C6Wm50ffcSmALaRY8j+a03f/y+K18",
	"pdU0kVFF+NQABXf/QEKgkpi5vcLkZ6DF0HN/IVG0MReSAwS44N20b3VO4pP2dWeusY+z8/FF7iVrdv97",
	"cVP2YfvN/3ALiU7ud8gE29ZE14tN1qIvLgpUOHbA2Bcc/P869e9qJAOxlZb7Yqs9X71Cr7ownYuFvq5e",
	"mMonWVY4GzNqyyWpRCYosMof+Pa+3ILiDPWXd/M3mV7Qub7W5Hw5p6pLLy6+zxkrglbmmk1sCfumuL8i",
	"yNVVsNY2XVoGdBaLzIy8A2lTJKRtry304O29tG9e1+YNTpuykrYo3par7lkw/djEr0asOBIZdPWV66fU",
	"PcJR+4pEDtMZO9chYahfF6g6+9X5x5FNuLPDde1ZfAMRFVjltrha8yQJKrzbFfssEHhfIrN4nb3xX9fw",
	"f/ZreFpZbStW++NeyI/i2N3Gq4fLxh1zFMdlSy/1I96zw03Sor+WzXZGNdv8OP6il+wt9OyynWvzRb+W",
	"K/e/dvTdUmqr22fdCYY121e1Ka3vuFQQ8o5FOt1OkSWdQWePp3Lv+gD2MlX7sRG7KqMrJlVe5gZAU1zM",
	"IoXyH52dOLzTVxhmfyonGeSD2a+pFCGgGcaLXPdKyv+L1z9SdoWt8kMqFDSWhAVMzAAxyp4+faufPh2w",
	"8Uzm82LSj/SC6E/jCf3h6FBnmv4a44NW9bqAnkEF/157rJebMdtR6WIXi58t87lWUJQKpPDNmO2cLc9O",
	"gHf7KEmw7TxDLbsH+QmYXJPm1awaGK2zE59iG+lYsJknyoDhe2P1iiyay1xEyG2ur0V2LcVNl00Fz4sM",
	"4/F5Jo1WhDpbGMEibgSbFTJGlksjkFDibws78y6/EN7z6848z1Mz2KN+96Xei3VkdiETgpT8mchzqWYj",
	"YmbodDu3vViaNOHoL4ADBxKGL8ISOjJ82gNJgPe7v3V+mctobgeJmbkukpidQHutArXwecr/vdPt/KBv",
	"WKzZScX9Vhk5W+qXubBDwBU7YVMJkLuxYHQ9Mv/dnm6Nxa+VzCE/KWYYtMGWusjcyiVQ+CemSRRQrmgE",
	"lP8BCjiODQczT495Tg2/yMv42w28AwNccVjR0i45u7CUjqvsBP6s5Ak+EItZxmMRQwKPtu/BgoUKqGeL",
	"EhB/WqgofL5QwStfZdKOOXL0F9DA6VRESCKL1UnkObWPQkgkPEbEzzcyFv5RGjcaealmuHlx/Fg0F9GV",
	"H68BG789vmR72JTfYLOeZXoh8rkojON3daXo4xiob3WWs+eH+/u29p8MrHgjfMWUl5vbQXIraeFbRLE2",
	"OMA8ERl0VKppxj0ccz/cEi3kAc1d4VbKu1qhlo3h1zsOh5za/eBmSrrVuMRFz3Nb1u6DWE4hctjzWuDa",
	"EgbgFCsbqew7LXUYgnJs23cL7hBPsd22V/oM2RBwJWMJJ2NoxWIec8n3QcA5bkdhMJn9gH8ZxNRGoeXH",
	"35tvYOtAYo5rELUPz6GnTyHqGat6+pSinguT64VrubjNhQKtuD9Uv8xlIjxcQpfwvCGFh8Av/R424lpY",
	"MTwRSkwlJGaXpwmk3eWwe46VgT0DjYy0MtJgThtxovrhwac/pLlcAGUGoH1INbOVvCmShF2K2xy/ZTCt",
	"YLyRChkT4TZrZVmaZjrNpJ3cl4m4FmyBSW9U/0uR22V0AZl0tmrb3B6/4RlNBSx2hPM0jvnTsySjn6wK",
	"8vn0KSZ6UMuhKdhxyuqD08+p9xTz7CM9adqDaWIXbpYD/QA6bIC1NosrpcMpLecSZqOOwbwGHLkdsXwF",
	"MPIGWOS1oMirwcK3AP+9JxRxHXh3BUj4/RswzxfJhndaJXLDO8ES0fJKsG0Qw2izhZ+2a+J2I+OwBza0",
	"tBULeyMaNqwygmhY1Zl18MkB8nFltbUhFdhqpzwxolLyvrDsn1bjob9eKr6QUSCt2M64rUVjJFwfb2jv",
	"mPXYBwV554AahjgaeAbYWyMbl2M8ZjuZgBRkZa+4VvwFsml3w+vsJd2+jVCVksS/DLsEcDk700TcSqcu",
	"mUTfiAwqboJ30GOBFDUslsYKwZgobhGT4wOsHvP06cDhHY/bFtcYRZvChyrdBvzkKjVEgPmBFdiTRT2x",
	"N425yGTOxismf4zXq5Rb1cHWcmS3IZyrVNGg2UbaqmNHmbtij/p9wvr9/ieHME0i/dgLa/z+m6CJsHPH",
	"QwVtsU2hZ+DIw81iaOyXdqjn+gZ1OphKnMg+e+c5xUBTwOiDUvOAUv549Oc35oTDM3DHW4+3bleQizPx",
	"5xOgSyMgOFRZbcjmWquiPHzFGGq1OuWY7djCu3Akl1+PRvQg3W1/QQIBe4z3uOktddHbrmfdkjeBm9FS",
	"F4SmftfmHM4yvnDkCXb6XunFxAExnBeJcBthbJ8f4/P2QBnD3XlR5AXsRGKcvhZsJ5prbQTTSjBuWJpJ",
	"SHGzzdvFO0L5hWE7WG+XKt2FK+IELssTkCnI5cAzySFJcuzGr8vGzf6PicSx+QP7N+YftdJE31Ddusgr",
	"bWQ7YOPgcWyoz7vNDQAreTxUL7VOBAfLCsmSUr6gqwGGelBRdtrO8ar0j8Wtl7gh+vs3q8WEU8h7VqlM",
	"GHc7E3cRArQ34Y4MQQONRyhqoDCgNFjlt4efiTajqbDd8bxqIwtwvYMzxY52Dx3CrYujyzbMfpeNE6mu",
	"xrsM9WVoVYzGFg1vmAs/2di5HXtMjMttyXRmP+K28Otut18VjpewH2lOQPGnb/w+6cGlICT0KZlJcn0l",
	"HH4KXmMVT5ZGGghtw4VDSPn2juNHDCjWfVVkB+3DS3FHrnvpD5fvTlnOZyCfQaaWb4PfKvX54eix41se",
	"5T2Is/KyHUYNWv2biHfLik5em659iemyiOdippEYHtnuTX/l5uyx43gmmOrZYXcVZzgSRa4dkkW/RbL5",
	"uaKTAl8Cy4D12E/np3v2bzfb1C//Cjex37D3yJEB8+G2dTmpxKBhq3wP5BuG7cA13f5lH5kmmtt14oci",
	"0oXKTZcBo4eduUhngoZggvXb2i6zQuzBRmfXPCn8Tfsb9prnYu9SLkTQjJjnIpcLGDH7k8n5IvUIgf7V",
	"GMe354J4IISqyyBHuqz/rdAm5bnd/uULZkKDDca+4JTnMi9isZdoNYO/GPxWvijRaOO10611Fttzw/Vx",
	"JrSZc5zcVzB/t2wm9Czj6VxGDH4ra5rowp7NsFoyMaP7PjbU4ZeVrfTwZbbyn5EiooQ0w9WJhgvQSeGi",
	"HUxNgxKIZiXRE1vhS6msfACLQFhVUINc8BktbPvPBJ8odxDICjhOTxTli9svT6YNJcqqoTVNFWUfSrCp",
	"yKwKCTpgeK0ew75xKnvzQBmz//q//x82DhShRlFHIoMib9ih5Rw+W/LGNB+nNRwW91/96nXJItcLnsuI",
	"vYE1GpgMuPsJ1Ac4btEMWGLz8QBijww8zuQ6HuVu+Y+tsvSaNkZwhPknfUnjnvWQd/AsKvxOQix46tG6",
	"y3PTJeqjEmWrPzoJ/CC+Quo39Ja9xyT/V1rZnedU6V/mQgV8un6ygxXgrHYuQNpfkWpKMfFPFdOpvBVu",
	"aM7C8w3ue3gi2VlGHQtuDIbpTM5kWSkw+kANP5KQpNMPlNGVGuxFu/LaqmIeo7n/Tvr1GkWXxofUU6tu",
	"kJpbivfyp+CIb54CYTE6TnZEy4m0u4aFB25hONQgZBondaC+QAlhD1YGBytY2nuke7tFYcv4+y0Y5qSa",
	"DYJNXb+HCDLptfDo4LscZ06PHcVx+0lcP3ID3wP5EKCfqG+AvlxXIGC7WB0DFAEWFxka6FEt9oCU0+W6",
	"Oy/I2FRnOVcVVWbqxcg33zgcOLB8Oi6h0mzZdmUh2TLn14LN5WwuslJfj7TJWVwA3kK5iIw0VYWIqrA7",
	"dsrB5u9vtpMip1u9M6OnVo/jCU4yHV5tow7iL1xwvlX6WmRzweP6uQedwhMraFFVqMKdLHbHB/QpnIba",
	"/Tu1ChdIAkDw44buMsw43EHfKCtRaQ5eOyl7eXnKdqxO0rvUvVN5LXYDYU/jYcoGMnGbyqxUgSGc1H7Q",
	"09AlMbUDzAOAnbgk6XxdFmt03QUaTpbEUj7LIEgusgdUkbK/6wnLCgXOA413oXM+zVkieCwyr3qAm5+9",
	"CtlB7U/uCwG9vrECHbM6wBWBQAro4RjneTJybR63mr0d/Z0Vcxj/4xkEw4exyOHzkl9wrb2c6np8ezmQ",
	"Sjv+wI0G4GGntN+2vPbTGvq4FuvmD/qGyZzd6OzKAK1jj5WLAhaYoCVURWlyY+pDF2RWagkk4wwLdQza",
	"GZMlI/I6NBNUFBgRM54TA4rUCg6Vl82llxXKWF08W7Jn+8yISKvYtCxCxPi1fYjDHQHEbvY65fa1PRmk",
	"MEwuFiKWPBfJku1MxFRnwr1z10NbIppQJpCuRcRs52B/fz+sP7crWC4Emopm2oc9QNMirYxQpvCX31fo",
	"2rH74NxBI6H645y7/P8j79ufG7eR/P8V1GS3VvKKsizZk6y2pu48fky88WttT3bve05ZMAlLjCmCISF7",
	"lCnnb/8W+gGAFGV7Jpf75X5JPCIB4tHobvTj0+z+MfULi10po2RiT3y41C8cErzFPHNEvk1qD4PCf3Qv",
	"upHmdWcIPvXHn6BwWGsOkZX06EikEobSKIhQWD1fMGhXWvElN0bdVcFRXqSNhQN7jbOB0C+AkOg4BuRB",
	"qithuxalAkjVNK+p+RUKJnwnzcXF4d5oNPqbwMlzlNpkOBjuRIOtaLB1tTUcDwbjweD/oe3Pn3827gFa",
	"N3z7Mc0wSkJAkJtj53DbZpZwiMucX+d20ExaALsvPuiAdcB7qHuOBpW9OPrjDL/uzO2PO2Ke5gtDwn+4",
	"PbM/DrfFTC9K/O1bMLN8KxK5rETHUBKerMTW2+9mqJrav+xLW+JRqXsec7NANbL8IIahtdTt6onZmq07",
	"MZmszI2E0ERLFX676VuOy27BfIjZTmrNJn0C3EW0H8cEdI4w/Pie1aLAP5wgr8b+CUv2Slld0F5q9iQo",
	"y6+cGEhLP2jbWAmVG+CXNHLeChq7Y9/06WM9FRcaI7Be+dXRoLZUx3rapqFw7j9+djSA7XeKR021nUl7",
	"01BlWpk0ps32gQiXRpdyqujAWaL1F14M9EgEI+Bb0TAZmwndGQHDH6+zZ52tLgFtA1WearQ3JKpSZSoz",
	"NlfmSiUoQUFnJplWxTKHZr9tDQaRFSmfnHY8kzk8B12rBpsvbnWS4sE4SfN0LjHESk6VU3tF57fRQNwu",
	"DSmo3LSLq4ChDYcgD5ksIkEuonu1pBlZ4qLgJa91dn6bp3Gp6cR2adLpvLA3JZ1TKARBHEO3sSQY5Hma",
	"ZUD9obKKI9qjFXmvZvIh1SUN6aJV6Hdc3fnbDJ0jxyD6IzBW+9JxnaJEsSeSBUa8KlB6oMlOhN2JaSlj",
	"SJ9IdSIUxbU8lqkhAwOWAS0V9ZCgfoJqQOKUA6cQVF1Bn4XdeJypbO4ALyEGi4m1Hi5mKdAHkMCXMz2d",
	"siuHSYbjw+iUHJ0engkMSrQfsZ2Eunp4yt4Nt103NwCP/SCzd6NBxb3AHqhELAo65KECBXbZd9tDEXS3",
	"M7fbamR2Q++/2xqNvq05Xk50Qs5MO7SVG8HGxi7WsIXzpzEVGFbLbi0RAbHBKoiMqd8PvFNytyiyFEIR",
	"TallbNIHe3YbNrGqLvB8GjLOGfxzsrwn37vTD91ms9Se6wcaOh8gZZojs3OaF2ZJLgAYY5aF54kw8CBE",
	"z2jkIuelekj1osqWLTtRqrlMaRB7M5lPbVP+4voly9VjY3DoXH/0slnS6oUqcdvaHfjRlyqWWbzICDrG",
	"DsXvYWBARGo4TueMzcl+6b1Mx/dNdHwXN7+xgW7606tzsI8s81jEtkXFgWYcQQjRo9wlHgDiQRC1tbKK",
	"LEeo/MpvNfZCHfAhoQhpCAIkR2EcUjIEnF0du/Vrrhm7DYGoqS+v1INCZLtg/Y2VN13yn6cy12Fs5goi",
	"22pkJlY0fkVc5r4WRyCewBuLUYkuLpDuQyTdLZ3xnOohzAm7O0UsCwyc5YXAWXNY51+qWlRn7JH9nc2N",
	"rYxgXmmN2WS0UXA1BDwTzWFQEjusqrlJFTV7NcByLLJwnSNoI+OM9thikz6kyYLqWpF8ZwcFVig9qwX7",
	"HdzdpXGKoF34Wbt9+GFvta5RhBQVClzK90HkYxj5de6iq62aVxgyTnKZULa236tlBO4vUci0rLq1+qEd",
	"58wGdYVHv59aVnS7sMR/Vcq8krGbxUragtHzNCavNgRbo2AUJmjo4OCdL0uX6I6+zodRMZMVhCXMUyM6",
	"w/M9Kx610bHO+gJs+rJZZFdUhcwrv2oY5c3m/eu8aa0jcOrUWOVfiiSYYDDO/hrbx1ZfnFB8HOPfygw8",
	"dKoS3x/vBao3RPqqDMKQgsniAK/zYV/sBb+SChEMgepi9NC+GacFxGbgiqZgBK6u81Ff7KL5DoqIGgRb",
	"XsSxUkmv9llc1NoXrvPtvjgPe7fSLNcGDTiS+SzKFkTI1dlD8PmdvrhQsQaVK9O6cBoRdkKOS1ckAbyj",
	"pIyHY6PIeFzzQ8zk4Mvtxobzb3GhD3JV7p4fOdYvIvGzZYgLDHQnIuFzQf0AfXICAetsKBgg8wDzA4j6",
	"dCnkrS6NMHqqzAxNRVaQw3Qtl4IA/9VZ4CrOZJ5kKhEPqYSNdEtEYsexANvLb8PBvGIJFISG4CEyjXO3",
	"sRFcXGraODVAs1M1hlIpo1js+M7BXLCm78Y4sM4LOBtg3xegMXCfgQR81GVlIsix6axMl+4QHxaylLlR",
	"bluDLSByhRVn20EHmUlqll302awsM6bAus0QHauyoFEP8LvnTSrEkEVXNSaYlOh4jb9OuOAylHeq2ygK",
	"EypOUExFoU7jStkgVRFFhTA2Ranv0kyJv1q9n1HOu85TEBmKb0LWbWbSoDWHFymkxveL7J48OJwODLw1",
	"yyJdRrm2uspUVGouc77TgloFYg3Ll3T2LSe7XOYxTPH/QhEkms7vqH+UrlY/6rkqAo16Rz0nYdeXOXpG",
	"2ODdu1FrBbegkFMOIez4Sdwre2KGfXGprPzB36HMkdF1jcYzRytEaFGgWNBYLAqcIRsQVybzTOkmrNm0",
	"bSVDoaQBdpZbdQ1GEYm8VqrJMfBazaa240aOd6KpzZPl5T+PwQt+eXB8sHclNsThxdkJl2mqxNnF/sGF",
	"eP9fIk3E8dHJ0ZWAS/fZ4eHlwZUYTK5zIaKV0k777xslmGpll7DNxSInCwBHSM/0osyWm4lMs2UXfbPS",
	"nRgXVIsHw8otGDekbAGuLWSaDgfD7WiwtckT6P9c6fw/ANHkXZpg1SsosPluuFMbfUD0sTQy01NOCCkr",
	"XQZ0gm1obrcq1nOX3gJch76MLkg36pEAHnEs7xWm0pWuICtE5ojOxJ7LzcFgsAVjnvSE+2XIv/T7/S5+",
	"HxViZFtIMXDafSUsqo+Fb58T6Dt+Ks0FLEhPVArSG0njAdK6Xbp6YXbgdtS3ZRrfVy1UkqjMSMSJ8YRi",
	"tXdPKbU1bgyxWawL38Rsn1rRLrrnWCkVNMdgdUvi7zlzipUdV+eMlB3cRChOAsY1St6LuJiZqNUywz7q",
	"pdF89bOoXOSNamctysgllurwibQ9e2RLmSf2Q2hHRgPl/1YNMrpHxVB1MU8EwemDkxjj2fFaBhvyIMtU",
	"Lypn5LSPVE5ppBNLRuPNzc1Cmtmm0ZvYEALxNKR3WjIju1skJtVovLl5u4jvlYEm9sXdufxV5+JyZL/P",
	"yP7BvbJUt4s0S5hGAqx/UeWyqGbaxQeKHyzFsT34Ot9PSxWb4KJGd0kqWAN4KxTnwTdOf0lECZaWYpGn",
	"vyxQioVmgGZ5gVUrAJzzs8Yb65Mz11ydQCG8t0cVz0bt7l+5wwTrwtzckjexx5fv/o0LIIaGhqKt9sVb",
	"TzdlvQxDq7WAqhc5hy9pcrWMyrtG/G9PPGB45ErMY+869yIE0hKl1cwp8B5sD1Y7gYNxoeK0KIEKL2R+",
	"Lw6h7qzoXFwcuus4qgO1wGgIRobo6EsSUeBXx7xHKouzzI38hLlB+lGVd4tMBMNP8ykcDnAo17MUU6sM",
	"TG51shxbfrAwqgRDIMfu4ibo0r61e7pvOf/Zhf3v6dkVvHgBRb59V0slyzFcIdRwMBxgPvOstDqdf+n6",
	"DUZSFfDg+o2zD1+SKuumeioRByCT+XQh/Zdoo1a2BSsHQ2O/tz5kwYX+cEYuTIFqQrEeDRKfuqxbOrk+",
	"sTdG+A7nOlGZ27TvkSJwJLjF1zkFplWNqDL+LssSnFo7tbTkD9jObmxnN6TCoMMaKIODTIPtZV/39Rv+",
	"btAOM0StrJBobciydApxt+za5HULshNubP83ub3O1bIRKIaTvEowVVdtGVnrHdaCwkJgqPMy+d45b5Q7",
	"B/CLOC/VXfqJch2wnFfAIx9nulJYVBulJxUid0SPhvdGKgl+7KbArt9wKekxOPlhLkwj4FKC7uEqRO9t",
	"DUcYXQD/2t55e/2mMWo419f5blFkSyFrh1da/iZ2T/etQMUQ1fbhuR2t7y6lCCzHRsWzXGd6uoTeGifx",
	"+s0TT8Y7O+COhEkJwKcsQwbMDBpantBG4A/Oser2kSd2gEFywU5wRGZjtp3Tsys/0W5jpor7fXGyiSpK",
	"hRD1ZxeEAjAGZvegkmCuDWuK1WAUW4gooQLdymCsT9jEXcXaEW0p8/s0n/YoYzxAuvP9Mv++2P0gOgSc",
	"JrNodzG1q6ES8cEhnXQxhrchhfKEwVCUj4MmVnB8fEIl0Vf4T8mf4p7gNaq5xyfrmUp5If9rFG5LVb1m",
	"W+x9NS7G1n8DpL2PxwZp6rJ9qkdVit0p5F5e50eOrxgux6YXYGXBw+qCG/Ghx4iBNdjLZFVZbl75xasE",
	"EEmF0QNW1+BoZ6zdTotv1ZDCoIccWW2rEhCuiQ9OlzCLSnSslHXaUleEMfJH+/S8IgnUDbcjppGj7anH",
	"no2qx8PosRJjV5QW78jRHMmSC4YpaLPQM14DsAKrJGK6GiIdeKAD+wHxywKCkR1/3eo3pRYHUnsN5K9O",
	"QncxLA24xqQpgiiwtiFgJs621RcXTJqlQpWO3IWW067XkgCiU2ZwkNkv5PlMTZQ6jcDxrKH9Kp1lz4nR",
	"DqvyWCeqRCFOdylINXL07RBWgSgjt+UONaJvh267Z44yB000jhclRu3IfEVbCPKte6LSbNyeC8sOyREd",
	"uThFHgpZG40uxA6EiaD22NQLWsX7FJMpMlmAc5mlOpgd7BtbgwH9VNJkarF8RGglBellmZxLF6R3/QZm",
	"RbF1Kp/GUm/+81Hlo4hXJhr0374fH269DRoFgVK1vMaV0Di7iSMmHXFeLnLYSZKwemHgYk5k7TduKRJl",
	"CMkH93QqC7iQVATiNE/zdL6YgyGwmuksaUfWaF3QOYRSKZEpWeYeTcIu1SJvrN48zW9gBDfAz+yzQX/H",
	"r578RI+nsrgpVBlT4ORo0B+srEYkJo3+JmPxg1IF6ig8fSfIICC2MuLff3Yl43RBr2FvbZ+fjMWlfQ+i",
	"szH5TiSlLpC6gaj//Wd3cYO41nhh0gdVZ2PfiO0+GaQvjT0PUxBVe5jjPNOP61TiMuATnMyMF/2yvJuI",
	"DsURd8frblcRM4ykh4ZX8ajAkybmujIAHIbxg2V1N7G9ZBKGfwmU4jrJrZzP0l9JVD+qdDqj1bUrwqhE",
	"2RKNEDLN9IMqJxiu4OeW3gU8wAs2cHm4pdphq7DTnZHXTkI9cMI56IHmCvElRamIZTR0mUB/uc6Bbwf6",
	"C0keRsC5pdh/uCmV9LsJtDslS7LcbGzU0njQZ0YJOF4KWaHIspf2dAz270uvpdcMsaLjV+2vjh7Q8o28",
	"m7U3o0Uuy1I/ojlBYzjMCNMMmYtBZLij9wrM19gNnlPk+YCcqxcmS1VZhaaVlQKlq7YVxgd60bjyvO3j",
	"2auht3uoqrFcaGG4OAQir+NgNaU/bfLLdhirzKJDxStwrTYVLoDgIebomojZV6+3pmAXVouc60RmzVxQ",
	"RDFx1pFmWox51C4vHZNuIGjEaTiBnvIwcHnegWkFP3Cdvz8Z7lAKfXPwpJLDlabvMzPBZoD4TRgq04Ss",
	"qqcc0snZa4QNtcTFurDzcOxOyIRZL5APlSaf3MO5mt9YWeBAEOpx5meYDc/AFPz2RHQYGqw7Fkd3ACHT",
	"Y9Q+XFbLPdVcQ13fbCk6i0rBnV2XwiiI9urWXf30EbuufJ0SMpvqMjWz+XrTlOhgOqG3TXVbjVOis2qc",
	"6q5Yp0RnxTrVXTVPic6qearrsllwd/9SrWYg+03mNEe6SNhJmeqFNL1VpAhHtPI+z4leKUn70p8bItjd",
	"oij1p3RuT+F9lCtZWp6cWyl1C+uz+8PpaZfhhkD1WVGU6wT+0MwH76/epRu7+70sk0dZqkjGscro2pSk",
	"lYGXOTAwiBG6PDrZh/yVchG7m+Wn795u7p7sj8Xuj/8eIvv58d/RztYQ5Qf5ipGz0CBDoLVI7F6cjMXp",
	"wdkpNL48ORCdy1hmFABnyvSTR+XpCjdWMEpZinmfmn/ay1FuOPwQjfPJIlYJ0/2d1qYoISIrTzhI2yeG",
	"nmrx4fxjGLyiXaS57W3v/CPxl0QVmV4Goc8tyXIvcAYikBam4HavxheSdI6zB93yu236GV/+aoVfZllk",
	"FelsHjxflPR0Zkwx3tzMrH4205UZb21tj7ZblHyX/5JQsjvzJx7eZCwO6M962CUsLOtUjoKrkNnJrNGp",
	"W4rJmA+X+0l06sABPACrxNWwBrrkeFJZMhlT0joE+t66INh/XJ6dnkszY0s9Z+A0rjwT+Inx2fok/fj3",
	"P/UBNvzW3hwIoseoeZFJoyZj8T3EI91KqxHRr8hZMHeoKPW8MIHOie4vtPT8Csv6Y2qnvRmIX7wOg1vB",
	"hyUjasOmXCSp3rTEoevyA24MDLTYEBUkx90GnhN5tYrzFiM7k2MFYVdWbfF0UacGJ/TPgGZFB91/J3Dv",
	"7q4ep2cI/XkyfxWRM32f62KRSbIzVGMx8d3ZPQYbegQzihizZ/7pVqb0WybLqXJ3YQCKPnpxKoXKZdo2",
	"FQAKcmsbjaJqDrhD9KYs0pt7RXbX6j7q9/vhVE54Cu3dTERna2f0Nun2Wt7AeYjOaPDtsO0NmchoMBi6",
	"PhzYitbTTIkPyi7ZSxOf4lsvT3ww2A5u7YDITKm412/my4h+8rYSgmthP0Fk78mlzLbaGey3b78LEr5q",
	"tI2HLIRcoesOHjGPqrP7r0vxXiWlju9fmvUtvdZGuuDX7pvUyDwgsujBjxxBY9zMlKxMtNW66+s7s0S7",
	"9unQPo31TJWqj7+rfJql1Sx6GK08gkXK0ny6kJl9zrjKfu2OXCL+dU78m28esXTJFA5oBngWXjKAcbGu",
	"0874fB4Z4MtdOl4pOlePOro0cqq6nJ2LfXgDojPmw5bW4afMTJEtEG9ewcNWw9N6Uf/Hi3IQ0OwwdCvw",
	"lR1nmXyQrUI/DI3b2GBZRMvZmUDDSdetarWyrACf4+RKJ2SsXQcBgyoB5XniUVQJfwtJmzSDjQ2UGxBZ",
	"hF/v0R9RMUuBVm/lfeMJNBlNGOTYsmdE6y9MtK3te/BXZBblrf+nhoFSK+Rt2Ar+jIb9QXSXyWoWqU8F",
	"NMLft/o7ljc1foE3qa/d3MxKXWBI9CTOpL11jKKdqNJ5rkw0HAy3twZDPJP8VBeLCp4MhsO/TRhPGZgK",
	"VwPATvvrO4wehuOBk1OnaFELjm2HwoH4CAF6O5nEGfQjwVCZVkb5e07J1mD4BcekJkReK0ZeEiQr9I+b",
	"/pdq1UFguRiuBLp5MMmXzUPI11yOtnQZqjV25FDHHcWfqCSVlKPt0ZSQGQYLTqy0F+b9yVy4sGYBeWGg",
	"4rGq9iiX3t5yNMdQTyAhWam32wIdLYnoQIjQx4ujLhCV/dcYZrP5c6Gmf7+Ft3sYio7/wFs7hx7Sy0X+",
	"+ncf1W3xzMs4zI8XxxhNSLocoiZiwQiASxzRHxRn5oh814oWgUGc4kfWir+yQ0J48o5F9MPaabTdBBlr",
	"+/rNOQV4ns+00T5mwzZ0kAdtC53++P7s4nHww4ep3t3d3T29/Dg7+Djdbah8iMdGl4voPdxfz+FeAUSE",
	"KAXpr2jQr4NtxDp/UEB7jAtExmlP8Uh+LdeY/yGhuM7PxDn79LXaQo7F58+wvE9P19f5HgcfiM+fORAB",
	"Huz7/uyzoPunJ/eB/2mhXBegvC3iEoIbfbgpXDgtBa6urF1vVw5l5h7/XEFdmekiTdQmJTsSYgCkNvK2",
	"tKTjxxLyoDE6OcjKRlwjctaMPZoD924vup9MvfdSxcrKDUCeqCW8ywoNw59MaDLBmdLEJ58/O+y0p6fJ",
	"WBxhFh5a2CD2kl77JiV416enfr//+fNmegcN9jhGRWYi09M05vcRbqEs5ZJb2F/wIwZ1PnhacYNFnlmu",
	"7YJeuBn+TqN7UCUkxrmPUuv/BCb89GRZxOfP/3mvlu7vu7SsjPtXJuEfY3GsdYGgcxyDsbHxfpFmJkpz",
	"8b3KClVyvP1WX2xsVHG5uP3ezLONDREJKh+IBLxZmSVEc0wrwj8zpYwNpo0TAHSp5wBcBiQ7mUw8HcEv",
	"nz+7/sXMzLMbMmo8PXED+D9/uBIT5M04AOLN6OuiB3ZI/DsA7mN7KLuWq8cMwlIwBe0WsolVhmAqolP0",
	"RJI+9MRsK5q97Yks7QllYoxbFz7oo8hkStPDoLRSQSpgIkolE1cIBnxRGxvqF1i4A3Y8+7hqjpLmLa3W",
	"rpElwo76hSvlXL/BZPXrN92np134kwiz8b6lB6uYY8IcvM44n0DTYStiFSM7ZhDcMOwPKv8hNSLRhixE",
	"KNNR57DHD0oVrXhk1s4Emy/K7B1ImX1p5MeLIzdw/9jM0qoP79wsyqzlBbSnWNZE9Y2AK0GL/s/FFGO8",
	"VtqAPOXMF47sxkZFvq5RM2h89SO0eEKI8Obw8eIYoUQpgwWoCHUOgECt6zys8rgIjnVqT7/fnzBNOr1B",
	"bAaKg4jEv9St/X7VDJpy+IHLQnHkA2aGCB8e3xYPL+zs+TSRXiIicTmKgKINAChy0H2HgHvoxeaC36sl",
	"An7Dgnn80j0a3LkzJ/p129hAfRGASPVjnmkJsNOlqsBu3knvKC2h26vrE25hXU/n+4cVSpNPhrkWJiAC",
	"08R0klLlCQTWSLIQuOaWn9nmF3DcM7rE+35QVTnRv6ZZJuktxxSQRqjMHcy41JmjD54ZSs+i1HaDMLOL",
	"d45L5HF8itV/kMUR4PpMV0Y8zlKjsrQy9PC8TB+s7Dk6R7YHwt0hnlxeXhwKaYyM7ysmLR4KQhNCCFAV",
	"COmtweDk/cq7Jp0rvai9OBq4LmEHAxP6SqfDwfZ3xaceVsCjnWVCuVRqLNqrs23WbLvf8ApFUUwW/m3g",
	"xHDQrrTOkSPDP13hpKuzs1OHgHWl71UenZUpRmcSeO0pQRR117I3/wkBDAxRIx1TaX8sMpVPzexElveq",
	"fIcw1Vas5+bd9ktNEwVrqMp312+ur00rQ4KZHRJwhA8G3NgYDaK3gz8jUjp6sNCdRDIKT88/Ls9OmcL2",
	"NAL3kJuC0BfH6KNswAswUQKsAM4QgVIgWcBK5v/+ZvTTWMi0R979ecbC/kregh2ctsP2vshTj+Lg6n7w",
	"V85q7rPj4xNRyLIiy58Q4syZz5B9hSs+EZ1brbPuGPBavxEYLANoFDB2xBgPiNSUC+X4L27UBIDKu2Ow",
	"OFIpQVEVMoZj5snbNXP7NhEdjDnvsm+ILukakdkNLQXqjOBLFxPa6wm/UfEZ4ZuhXphiYcY1HQpd5eKo",
	"UaySncYuv1FgfZ6x+IfMldjXyPfaN2yF1hw8YSDxgP4ua+Uq3TkOClUarfMIdxz+ptYftDiyc3IlGlsb",
	"y6y4V9V9mm9ONTa+zv/l7B58eeuhTwh9cajmixRQ5xJnRoFEZYMQZmkZXLLTSjBKl0r6NQzqA2T9dkVB",
	"3LI/j4sh8hdd2WDvxWq6/hCzGLvLpwRXj2o0VcHxYN3uFHzhDTi46jpnYtudt34lXXcZXX8PbdxB3VSJ",
	"Sp2b1dkoAHFfF4Sa43CaJpg5Qa5N4Yr8EJg4CIuiVIXKk0pM/tSfsA+W0pe5CtKf+i2+Uyi+UGRpnJpg",
	"3+h9KOnz34Of+ug0nziGlgaeBbvDXvgjVXF2uaSMkj4jV5NDlnR/ROyH5DkXD4S5ni5BrF6qx1fdrPm2",
	"eUVdolQKbAD0mwM2oXwlibil+sMNFafaqHHodbdnTs9TgwH2hC1524TshzMdGPTZLTD6btv7yALzMhxR",
	"xsxks87XGpC+fftdq4XIGYZ+l8Xnq+3Lqz7GL/TTPPflpj9hTTD2uZcz6OwQl8osiq83ze+M3q6SJ5W9",
	"eT1thg7vL3F5rzi9//T57PzgdPfoZvf86OaHg/96al2HVhj7jQ2Kbfa68GNaqQzgx75HzHT3qHIxmpgu",
	"EC8hMcABiNOla5Oi4ABjnczqUPfVmcxaSqaF8bgNTiPS3Giom5rm07tFRjEiVVDOC89ThSHbS4ZfM486",
	"qgxcAz2pib+6CJluALoP16IeYVtRK6oegjyZKuribfShEnuZXgDQGwVuQBEKKy50YYXiZmHvOfGyJ2L7",
	"YhARQmEqRJGbVSwZXY3UrlBBgTx4BtAn4f3o3LIJVUNFQK47juiRDzpNxONMZ8ongNSAPX3SDuoztp/d",
	"sA7ApYvtu4K8HHytVitgc7WQWb18wBil7VZf7GMGZYjrt4qLD5aAVtDVZ2GbaSn/eOBmDlf7AyqFtla8",
	"WFdu8hXQzEMunRSG9FtFoXV5g1TZAFDeh+nWFnZdoO/6wYw4TcCKRyq4QYXS2kbTniZMwwoyLHNfbWSc",
	"yaKF5YHC21Z/AajNlVvJV0sxeJWOqq2Qq8CVCute54iIhABXrvJDmhcLsPtbNRGr7fbtjZdLn/cAZbm4",
	"fuNawr+NLpAQMllYEYDmXk7VVK4Swz7BdUCl6ZksCpVXyA6WeuHQEEts8B8MsILGgYp/R1RXRHkHZDWh",
	"8jKNZ/aE9ZowdYQhEWSiMyqkL7PQF9+rUv3FjkQahEMtVGxwYP6jiJokOlTlgZlXrh4pBA+QRQgYtGZH",
	"6TpP7S63OlWPFGVvtDhg6M4rRKp0IXotM69Pb906eNZlr+J2urXjc2t1jfz87PJKbGIu5uZn+D+4cTZp",
	"pTY/wx/w2ytUjJrK0O/3V8/0gRuf2/zadMin5Jaj7trE2WGNrPoGMqJqgB7sX/agqk3E4iDWcg1iMeTB",
	"Yt10rC2CbgMrzanaf1HqaamqyrGKk8aD+pIDUtFrV5yW7ljreyGNmAAI2g2OgWry+AXl7wHuNLzpk8jL",
	"UpfoluRKj7tAL34/XGxCa9ZU/UuQQ9VrHk6o1F8hqjNAN485ytiUyya+9KFMM5UEnbYXRTFlypxLfSp0",
	"bgW9zGDj9d3dM9vpwRMbG8pI4Ng3our6mdkLWpq7NCozU2HBeYBcTO9EpecKFgEn6OGkYVoB4GIL5XQm",
	"qxTQ3P2nCep1sKJkNEN0Yq6oz2jUsCqVam7OolQCgreCpW7iGIdoVQ+pbMpZcAIwDyPL8cbGnp7Pdc7T",
	"FJexymWZ6pqX012SAXfoYy4fZJohyCPZoYIFp21obDzmQKryIY0VIxNWzj7emAfLuw4H5/jopW5rVhR1",
	"BFYEewpuwEYyDomRSmJ50M7gWHSA/Bk9NEwzhAdd5668sDQHyMvgz2crrnPREBVTQqApl840jKWhyCgM",
	"Qc6sozvdGLzfaPRnw23p7zF25X9ZaEOq6mpYt/NPQiweMggoEQmVJlAL6IXuiq6bwHEAjh7k4yNmd/6g",
	"KpNOZeAJu6AtrowuyFs8l5+ENPY2ZZrbSruKQtpVA4VtrfGqjY1DmWV2CTnPdUlEeAhJPinQEhx5cAL1",
	"HJ6pzxllPGJqbxf3TmbIXuAfK4TzuJZDwt63Gg9fRo2hdCCjyvkLmDG1N13yWTlVNzwJ0mxpivWYoqtZ",
	"WjnO6AAZske5rBjfhbOAmdUFIdOWPy/8aXbCxUGhozazAjV/pQnIkRhLM3nA3q5KXaChmAU/Kitisn9w",
	"fHB18CK/hBN3oagkt4Ndx0+NxaRF0WnrZNQPVA9wZlUrIilixYKKsGtjr3xBIVvWMjv1JMgu63A1lHfN",
	"lbi4sm74teucAdAoKRwun7iYhHwgE9UXjXjsjktk69KhaeIPryrAvoAYQHy9x5CxE/mzLgP1nY8XZBXA",
	"ClXKVD0GBqNAM6+rjl+ja2Jjd1zwny6aE/uMqM+ICumsSREAD/l8Sa5xQrJzKJArAXYfSllQJiplm0NV",
	"36urYwgVhad+UaESLK8qcCaAqk11Xs3SAi2ljI5hSmlFlgeL6Yvj9D4A7ekJ6A4ubtV1zqG4reXmWMUv",
	"VIm1trHaRHiMfJFcPyVx9mAlqHpcnQxit6GbxmphdhAuFzkYI8yTUXhSQqUlgLM8IYBcO5JcEV4dQii6",
	"PqDCC66FM8BHM11wBEQUoFaFq4kQfPaiEYSdTf0c2ivbuIsJb1Vb9q6OU5ndwBtNgvjG7f9zJfSCPbJv",
	"hxUlVBkO8vUl9V418lLFKjdYQIQhrJ+vKvZi8bkD2PgvLDzn+FWtAt3vLRwnYzwMYgZY8h77/V7VawB1",
	"7eHCoAvginZKsuIa0mEROiTr1QJ0K4ezeUV8rvIcdfqFVeccXT1UtQqUuDPhLxsbomN8vYsuIjE5PRxU",
	"9UapE6cpkckwKMfyYkGM1cKBPpFx4oprEQXxLOwYkR1/yRjDk4HMKxwplrvXtL4wTGk8mFzQ2A0byGWV",
	"GkWHikiluQC6QRznSOwzdkjYG+UvQYVVBy4iaqXUnim55vYVAAkc6vVq3TUhK68sX10d/2/UYXu26BoI",
	"hOrr+SiGTd68ogToVo3PXtnDK7A1wrhzF3+nva+xI6rTBgWuoRHjTEH5ALuYu/SrOFQq+fr5/B7u6rGA",
	"LAVksjJQ9s6OGmYYdvp3oTN7tyM+0lZibaWI3IUCVOocKwD+jk0zpQKxfROI7JeKtza3jvtwQXRBX38X",
	"pborVTUTAN9thXhGyE86S2r7y5sY3pF/BzUW6Y1dwy+lQ3tPhnYgu+1mPUeFYBPI0gQB9PJEPwbX8DSf",
	"vrYanuMaLCnr3MMDGDDMbQv3aNTUo3p1JNcBsRNq3CGTrEnTqi5OCUTBdd8soOdqbNp+O1tdWCnoleqE",
	"lApiLOvqwKvq6kEvHsD7y4vj1fWvsC4fg4b78ngrUn99iTxSyr+8PB5sHxevam7a+np566viIR4G2i/p",
	"xXUV8JBs7eaAwtJtL3bnSK+94l1QdxHh5OtE11b5TjWJ+Wd9y6L1xt7Eb4zJ3o2+tAAeTgeL320Nv/XV",
	"777720rxu53t0dApuidkGQUtUSVNpRwE75VtXjvoiahSe1qp6smtiu1WUm6A3TfL1HmGjq8gBeV26A9V",
	"bejOatusxhfeMNcW4WvedCKxh/DvYIGA84jgcIVDTlWuoLfz9XgNn2oRBekVqDqjOYK6wiN+nslcyDiG",
	"IjFTKtwQFHVYQVFpKccH5pxgVGz5YUveajW83Sxzt9BYz4H+5zJ3tr515fae+9KawnvOwKPal+aZknnn",
	"7gK+UoUO7i+hhmuvMamphH7MYXspwpyKBCRTrmfna/VRzEebXis6dojuMPo2lNV1qsE4oJx+Pg5WFCqe",
	"hUOrZrJUXtyEui4VPYDXmKQaVQH3ZG4HMweKRlaSt1LuM2UGMeKf6Pj06hyIzAF4hpX2W2sNkqlqJRjI",
	"areUlRuiotXU+urVAQSOBG9qlom10QRePaFIAhfqRLol66+v6KEXPF6jfDY/ITNLFjdcbvz3fWJrtj4e",
	"wl4oXHxT/SZVd+T7dQ9tJDpL43RlZyCqxMre2lr3aw42x38zPWULxr8AURuKy6TTWch6gypO1A4YTQI6",
	"S0jzIr1zPXMlFylutTGZylV8T5dbdMlUM11CybVGpUqcj92ByN78U77eMOwlKvSVS8b1HJUm8qMq7Xlq",
	"mpRuSe9w0RYYmeAxuKBTHk0IMwkssFQUt4vAADXJFIkDcAW02EMI1bIpi0sM6w7hGmHnny+IidzkFQUx",
	"X4ZrZGM6msrRyM3EhyCLadzm7bLbtsgScWS3pA7ZSBZ5yO63vaLPF8xB9sU9mVOZTaZxbyaj+mLO9tQK",
	"2HgWVjPBymZGY3CNX8WPlSpbVg5+fm2Xll2leJP2HZ+7H1u6Dx4+/WQfGzn9UOpFYXfjM3dBXv7zxW2W",
	"QimZN703Rk5hx6Yo1G6gAIBK3vTeEKeuU0RL1dTVCiotwJ8rxAXrG6xZQFWNkdGKBlP86emnp/8fAAD/",
	"/wWcO6AK0gMA",
}

// GetSwagger returns the content of the embedded swagger specification file
// or error if failed to decode
func decodeSpec() ([]byte, error) {
	zipped, err := base64.StdEncoding.DecodeString(strings.Join(swaggerSpec, ""))
	if err != nil {
		return nil, fmt.Errorf("error base64 decoding spec: %w", err)
	}
	zr, err := gzip.NewReader(bytes.NewReader(zipped))
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}
	var buf bytes.Buffer
	_, err = buf.ReadFrom(zr)
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}

	return buf.Bytes(), nil
}

var rawSpec = decodeSpecCached()

// a naive cached of a decoded swagger spec
func decodeSpecCached() func() ([]byte, error) {
	data, err := decodeSpec()
	return func() ([]byte, error) {
		return data, err
	}
}

// Constructs a synthetic filesystem for resolving external references when loading openapi specifications.
func PathToRawSpec(pathToFile string) map[string]func() ([]byte, error) {
	res := make(map[string]func() ([]byte, error))
	if len(pathToFile) > 0 {
		res[pathToFile] = rawSpec
	}

	return res
}

// GetSwagger returns the Swagger specification corresponding to the generated code
// in this file. The external references of Swagger specification are resolved.
// The logic of resolving external references is tightly connected to "import-mapping" feature.
// Externally referenced files must be embedded in the corresponding golang packages.
// Urls can be supported but this task was out of the scope.
func GetSwagger() (swagger *openapi3.T, err error) {
	resolvePath := PathToRawSpec("")

	loader := openapi3.NewLoader()
	loader.IsExternalRefsAllowed = true
	loader.ReadFromURIFunc = func(loader *openapi3.Loader, url *url.URL) ([]byte, error) {
		pathToFile := url.String()
		pathToFile = path.Clean(pathToFile)
		getSpec, ok := resolvePath[pathToFile]
		if !ok {
			err1 := fmt.Errorf("path not found: %s", pathToFile)
			return nil, err1
		}
		return getSpec()
	}
	var specData []byte
	specData, err = rawSpec()
	if err != nil {
		return
	}
	swagger, err = loader.LoadFromData(specData)
	if err != nil {
		return
	}
	return
}
