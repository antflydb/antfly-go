// Package oapi provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/oapi-codegen/oapi-codegen/v2 version v2.5.0 DO NOT EDIT.
package oapi

import (
	"bytes"
	"compress/gzip"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"path"
	"strings"
	"time"

	"github.com/getkin/kin-openapi/openapi3"
	"github.com/oapi-codegen/runtime"
)

const (
	BasicAuthScopes = "BasicAuth.Scopes"
)

// Defines values for AntflyType.
const (
	AntflyTypeBlob            AntflyType = "blob"
	AntflyTypeBoolean         AntflyType = "boolean"
	AntflyTypeDatetime        AntflyType = "datetime"
	AntflyTypeEmbedding       AntflyType = "embedding"
	AntflyTypeGeopoint        AntflyType = "geopoint"
	AntflyTypeGeoshape        AntflyType = "geoshape"
	AntflyTypeHtml            AntflyType = "html"
	AntflyTypeKeyword         AntflyType = "keyword"
	AntflyTypeLink            AntflyType = "link"
	AntflyTypeNumeric         AntflyType = "numeric"
	AntflyTypeSearchAsYouType AntflyType = "search_as_you_type"
	AntflyTypeText            AntflyType = "text"
)

// Defines values for BingSearchConfigFreshness.
const (
	BingSearchConfigFreshnessDay   BingSearchConfigFreshness = "Day"
	BingSearchConfigFreshnessMonth BingSearchConfigFreshness = "Month"
	BingSearchConfigFreshnessWeek  BingSearchConfigFreshness = "Week"
)

// Defines values for BraveSearchConfigFreshness.
const (
	BraveSearchConfigFreshnessPd BraveSearchConfigFreshness = "pd"
	BraveSearchConfigFreshnessPm BraveSearchConfigFreshness = "pm"
	BraveSearchConfigFreshnessPw BraveSearchConfigFreshness = "pw"
	BraveSearchConfigFreshnessPy BraveSearchConfigFreshness = "py"
)

// Defines values for ChainCondition.
const (
	ChainConditionAlways      ChainCondition = "always"
	ChainConditionOnError     ChainCondition = "on_error"
	ChainConditionOnRateLimit ChainCondition = "on_rate_limit"
	ChainConditionOnTimeout   ChainCondition = "on_timeout"
)

// Defines values for ChatMessageRole.
const (
	ChatMessageRoleAssistant ChatMessageRole = "assistant"
	ChatMessageRoleSystem    ChatMessageRole = "system"
	ChatMessageRoleTool      ChatMessageRole = "tool"
	ChatMessageRoleUser      ChatMessageRole = "user"
)

// Defines values for ChatToolName.
const (
	ChatToolNameAddFilter        ChatToolName = "add_filter"
	ChatToolNameAskClarification ChatToolName = "ask_clarification"
	ChatToolNameFetch            ChatToolName = "fetch"
	ChatToolNameSearch           ChatToolName = "search"
	ChatToolNameWebsearch        ChatToolName = "websearch"
)

// Defines values for ChunkerProvider.
const (
	ChunkerProviderAntfly  ChunkerProvider = "antfly"
	ChunkerProviderMock    ChunkerProvider = "mock"
	ChunkerProviderTermite ChunkerProvider = "termite"
)

// Defines values for ClusterHealth.
const (
	ClusterHealthDegraded  ClusterHealth = "degraded"
	ClusterHealthError     ClusterHealth = "error"
	ClusterHealthHealthy   ClusterHealth = "healthy"
	ClusterHealthUnhealthy ClusterHealth = "unhealthy"
	ClusterHealthUnknown   ClusterHealth = "unknown"
)

// Defines values for CohereEmbedderConfigInputType.
const (
	CohereEmbedderConfigInputTypeClassification CohereEmbedderConfigInputType = "classification"
	CohereEmbedderConfigInputTypeClustering     CohereEmbedderConfigInputType = "clustering"
	CohereEmbedderConfigInputTypeSearchDocument CohereEmbedderConfigInputType = "search_document"
	CohereEmbedderConfigInputTypeSearchQuery    CohereEmbedderConfigInputType = "search_query"
)

// Defines values for CohereEmbedderConfigTruncate.
const (
	CohereEmbedderConfigTruncateEND   CohereEmbedderConfigTruncate = "END"
	CohereEmbedderConfigTruncateNONE  CohereEmbedderConfigTruncate = "NONE"
	CohereEmbedderConfigTruncateSTART CohereEmbedderConfigTruncate = "START"
)

// Defines values for EdgeDirection.
const (
	EdgeDirectionBoth EdgeDirection = "both"
	EdgeDirectionIn   EdgeDirection = "in"
	EdgeDirectionOut  EdgeDirection = "out"
)

// Defines values for EmbedderProvider.
const (
	EmbedderProviderBedrock EmbedderProvider = "bedrock"
	EmbedderProviderCohere  EmbedderProvider = "cohere"
	EmbedderProviderGemini  EmbedderProvider = "gemini"
	EmbedderProviderMock    EmbedderProvider = "mock"
	EmbedderProviderOllama  EmbedderProvider = "ollama"
	EmbedderProviderOpenai  EmbedderProvider = "openai"
	EmbedderProviderVertex  EmbedderProvider = "vertex"
)

// Defines values for EvaluatorName.
const (
	EvaluatorNameCitationQuality EvaluatorName = "citation_quality"
	EvaluatorNameCoherence       EvaluatorName = "coherence"
	EvaluatorNameCompleteness    EvaluatorName = "completeness"
	EvaluatorNameCorrectness     EvaluatorName = "correctness"
	EvaluatorNameFaithfulness    EvaluatorName = "faithfulness"
	EvaluatorNameHelpfulness     EvaluatorName = "helpfulness"
	EvaluatorNameMap             EvaluatorName = "map"
	EvaluatorNameMrr             EvaluatorName = "mrr"
	EvaluatorNameNdcg            EvaluatorName = "ndcg"
	EvaluatorNamePrecision       EvaluatorName = "precision"
	EvaluatorNameRecall          EvaluatorName = "recall"
	EvaluatorNameRelevance       EvaluatorName = "relevance"
	EvaluatorNameSafety          EvaluatorName = "safety"
)

// Defines values for FailedOperationOperation.
const (
	FailedOperationOperationDelete FailedOperationOperation = "delete"
	FailedOperationOperationUpsert FailedOperationOperation = "upsert"
)

// Defines values for FilterSpecOperator.
const (
	FilterSpecOperatorContains FilterSpecOperator = "contains"
	FilterSpecOperatorEq       FilterSpecOperator = "eq"
	FilterSpecOperatorGt       FilterSpecOperator = "gt"
	FilterSpecOperatorGte      FilterSpecOperator = "gte"
	FilterSpecOperatorIn       FilterSpecOperator = "in"
	FilterSpecOperatorLt       FilterSpecOperator = "lt"
	FilterSpecOperatorLte      FilterSpecOperator = "lte"
	FilterSpecOperatorNe       FilterSpecOperator = "ne"
	FilterSpecOperatorPrefix   FilterSpecOperator = "prefix"
	FilterSpecOperatorRange    FilterSpecOperator = "range"
)

// Defines values for Fuzziness1.
const (
	Fuzziness1Auto Fuzziness1 = "auto"
)

// Defines values for GeneratorProvider.
const (
	GeneratorProviderAnthropic GeneratorProvider = "anthropic"
	GeneratorProviderBedrock   GeneratorProvider = "bedrock"
	GeneratorProviderCohere    GeneratorProvider = "cohere"
	GeneratorProviderGemini    GeneratorProvider = "gemini"
	GeneratorProviderMock      GeneratorProvider = "mock"
	GeneratorProviderOllama    GeneratorProvider = "ollama"
	GeneratorProviderOpenai    GeneratorProvider = "openai"
	GeneratorProviderVertex    GeneratorProvider = "vertex"
)

// Defines values for GeoShapeGeometryRelation.
const (
	GeoShapeGeometryRelationContains   GeoShapeGeometryRelation = "contains"
	GeoShapeGeometryRelationIntersects GeoShapeGeometryRelation = "intersects"
	GeoShapeGeometryRelationWithin     GeoShapeGeometryRelation = "within"
)

// Defines values for GoogleSearchConfigSearchType.
const (
	GoogleSearchConfigSearchTypeImage GoogleSearchConfigSearchType = "image"
	GoogleSearchConfigSearchTypeWeb   GoogleSearchConfigSearchType = "web"
)

// Defines values for GraphQueryType.
const (
	GraphQueryTypeKShortestPaths GraphQueryType = "k_shortest_paths"
	GraphQueryTypeNeighbors      GraphQueryType = "neighbors"
	GraphQueryTypePattern        GraphQueryType = "pattern"
	GraphQueryTypeShortestPath   GraphQueryType = "shortest_path"
	GraphQueryTypeTraverse       GraphQueryType = "traverse"
)

// Defines values for IndexType.
const (
	IndexTypeAknnV0     IndexType = "aknn_v0"
	IndexTypeFullTextV0 IndexType = "full_text_v0"
	IndexTypeGraphV0    IndexType = "graph_v0"
)

// Defines values for LinearMergePageStatus.
const (
	LinearMergePageStatusError   LinearMergePageStatus = "error"
	LinearMergePageStatusPartial LinearMergePageStatus = "partial"
	LinearMergePageStatusSuccess LinearMergePageStatus = "success"
)

// Defines values for MatchQueryOperator.
const (
	MatchQueryOperatorAnd MatchQueryOperator = "and"
	MatchQueryOperatorOr  MatchQueryOperator = "or"
)

// Defines values for MergeStrategy.
const (
	MergeStrategyFailover MergeStrategy = "failover"
	MergeStrategyRrf      MergeStrategy = "rrf"
	MergeStrategyRsf      MergeStrategy = "rsf"
)

// Defines values for PathFindWeightMode.
const (
	PathFindWeightModeMaxWeight PathFindWeightMode = "max_weight"
	PathFindWeightModeMinHops   PathFindWeightMode = "min_hops"
	PathFindWeightModeMinWeight PathFindWeightMode = "min_weight"
)

// Defines values for PathWeightMode.
const (
	PathWeightModeMaxWeight PathWeightMode = "max_weight"
	PathWeightModeMinHops   PathWeightMode = "min_hops"
	PathWeightModeMinWeight PathWeightMode = "min_weight"
)

// Defines values for PermissionType.
const (
	PermissionTypeAdmin PermissionType = "admin"
	PermissionTypeRead  PermissionType = "read"
	PermissionTypeWrite PermissionType = "write"
)

// Defines values for QueryRequestExpandStrategy.
const (
	QueryRequestExpandStrategyIntersection QueryRequestExpandStrategy = "intersection"
	QueryRequestExpandStrategyUnion        QueryRequestExpandStrategy = "union"
)

// Defines values for QueryStrategy.
const (
	QueryStrategyDecompose QueryStrategy = "decompose"
	QueryStrategyHyde      QueryStrategy = "hyde"
	QueryStrategySimple    QueryStrategy = "simple"
	QueryStrategyStepBack  QueryStrategy = "step_back"
)

// Defines values for RerankerProvider.
const (
	RerankerProviderCohere  RerankerProvider = "cohere"
	RerankerProviderOllama  RerankerProvider = "ollama"
	RerankerProviderTermite RerankerProvider = "termite"
	RerankerProviderVertex  RerankerProvider = "vertex"
)

// Defines values for ResourceType.
const (
	ResourceTypeAsterisk ResourceType = "*"
	ResourceTypeTable    ResourceType = "table"
	ResourceTypeUser     ResourceType = "user"
)

// Defines values for RouteType.
const (
	RouteTypeQuestion RouteType = "question"
	RouteTypeSearch   RouteType = "search"
)

// Defines values for SemanticQueryMode.
const (
	SemanticQueryModeHypothetical SemanticQueryMode = "hypothetical"
	SemanticQueryModeRewrite      SemanticQueryMode = "rewrite"
)

// Defines values for SerperSearchConfigSearchType.
const (
	SerperSearchConfigSearchTypeImages   SerperSearchConfigSearchType = "images"
	SerperSearchConfigSearchTypeNews     SerperSearchConfigSearchType = "news"
	SerperSearchConfigSearchTypePlaces   SerperSearchConfigSearchType = "places"
	SerperSearchConfigSearchTypeSearch   SerperSearchConfigSearchType = "search"
	SerperSearchConfigSearchTypeShopping SerperSearchConfigSearchType = "shopping"
)

// Defines values for SerperSearchConfigTimePeriod.
const (
	SerperSearchConfigTimePeriodD SerperSearchConfigTimePeriod = "d"
	SerperSearchConfigTimePeriodM SerperSearchConfigTimePeriod = "m"
	SerperSearchConfigTimePeriodW SerperSearchConfigTimePeriod = "w"
	SerperSearchConfigTimePeriodY SerperSearchConfigTimePeriod = "y"
)

// Defines values for SyncLevel.
const (
	SyncLevelAknn        SyncLevel = "aknn"
	SyncLevelEnrichments SyncLevel = "enrichments"
	SyncLevelFullText    SyncLevel = "full_text"
	SyncLevelPropose     SyncLevel = "propose"
	SyncLevelWrite       SyncLevel = "write"
)

// Defines values for TavilySearchConfigSearchDepth.
const (
	TavilySearchConfigSearchDepthAdvanced TavilySearchConfigSearchDepth = "advanced"
	TavilySearchConfigSearchDepthBasic    TavilySearchConfigSearchDepth = "basic"
)

// Defines values for TransformOpType.
const (
	TransformOpTypeAddToSet    TransformOpType = "$addToSet"
	TransformOpTypeCurrentDate TransformOpType = "$currentDate"
	TransformOpTypeInc         TransformOpType = "$inc"
	TransformOpTypeMax         TransformOpType = "$max"
	TransformOpTypeMin         TransformOpType = "$min"
	TransformOpTypeMul         TransformOpType = "$mul"
	TransformOpTypePop         TransformOpType = "$pop"
	TransformOpTypePull        TransformOpType = "$pull"
	TransformOpTypePush        TransformOpType = "$push"
	TransformOpTypeRename      TransformOpType = "$rename"
	TransformOpTypeSet         TransformOpType = "$set"
	TransformOpTypeUnset       TransformOpType = "$unset"
)

// Defines values for WebSearchProvider.
const (
	WebSearchProviderBing       WebSearchProvider = "bing"
	WebSearchProviderBrave      WebSearchProvider = "brave"
	WebSearchProviderDuckduckgo WebSearchProvider = "duckduckgo"
	WebSearchProviderGoogle     WebSearchProvider = "google"
	WebSearchProviderSerper     WebSearchProvider = "serper"
	WebSearchProviderTavily     WebSearchProvider = "tavily"
)

// Analyses defines model for Analyses.
type Analyses struct {
	Pca  bool `json:"pca,omitempty,omitzero"`
	Tsne bool `json:"tsne,omitempty,omitzero"`
}

// AnalysesResult defines model for AnalysesResult.
type AnalysesResult struct {
	Pca  []float64 `json:"pca,omitempty,omitzero"`
	Tsne []float64 `json:"tsne,omitempty,omitzero"`
}

// AnswerAgentRequest defines model for AnswerAgentRequest.
type AnswerAgentRequest struct {
	// Chain Default chain of generators for all pipeline steps unless overridden in `steps`.
	// Each link can specify retry configuration and a condition for trying the next generator.
	// Mutually exclusive with 'generator'. Either 'generator' or 'chain' must be provided.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Eval Configuration for inline evaluation of query results.
	// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
	Eval EvalConfig `json:"eval,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// MaxContextTokens Maximum total tokens allowed for retrieved document context.
	// When set, documents are pruned (lowest-ranked first) to fit within this budget.
	// Useful for ensuring LLM context limits are not exceeded.
	// Uses BERT tokenizer for estimation.
	MaxContextTokens int `json:"max_context_tokens,omitempty,omitzero"`

	// Queries Array of query requests to execute. The query text will be transformed for semantic search
	// and populated into the semantic_search field of each query.
	Queries []QueryRequest `json:"queries"`

	// Query User's natural language query to be classified and improved
	Query string `json:"query"`

	// ReserveTokens Tokens to reserve for system prompt, answer generation, and other overhead.
	// Subtracted from max_context_tokens to determine available context budget.
	// Defaults to 4000 if max_context_tokens is set.
	ReserveTokens int `json:"reserve_tokens,omitempty,omitzero"`

	// Steps Per-step configuration for the answer agent pipeline. Each step can have
	// its own generator (or chain of generators) and step-specific options.
	// If a step is not configured, it uses the top-level generator as default.
	Steps AnswerAgentSteps `json:"steps,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results (classification, queries, results, answer) instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`

	// WithoutGeneration When true, skip AI answer generation and return search results only.
	// Useful when you want search quality without LLM cost, such as for
	// quota management or rate limiting scenarios.
	WithoutGeneration bool `json:"without_generation,omitempty,omitzero"`
}

// AnswerAgentResult defines model for AnswerAgentResult.
type AnswerAgentResult struct {
	// Answer Generated answer in markdown format
	Answer string `json:"answer"`

	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0)
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// ClassificationTransformation Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
	ClassificationTransformation ClassificationTransformationResult `json:"classification_transformation,omitempty,omitzero"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance,omitempty,omitzero"`

	// EvalResult Complete evaluation result
	EvalResult EvalResult `json:"eval_result,omitempty,omitzero"`

	// FollowupQuestions Suggested follow-up questions
	FollowupQuestions []string `json:"followup_questions,omitempty,omitzero"`

	// QueryResults Results from each executed query
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`
}

// AnswerAgentSteps Per-step configuration for the answer agent pipeline. Each step can have
// its own generator (or chain of generators) and step-specific options.
// If a step is not configured, it uses the top-level generator as default.
type AnswerAgentSteps struct {
	// Answer Configuration for the answer generation step. This step generates the final
	// answer from retrieved documents using the reasoning as context.
	Answer AnswerStepConfig `json:"answer,omitempty,omitzero"`

	// Classification Configuration for the classification step. This step analyzes the query,
	// selects the optimal retrieval strategy, and generates semantic transformations.
	Classification ClassificationStepConfig `json:"classification,omitempty,omitzero"`

	// Confidence Configuration for confidence assessment. Evaluates answer quality and
	// resource relevance. Can use a model calibrated for scoring tasks.
	Confidence ConfidenceStepConfig `json:"confidence,omitempty,omitzero"`

	// Followup Configuration for generating follow-up questions. Uses a separate generator
	// call which can use a cheaper/faster model.
	Followup FollowupStepConfig `json:"followup,omitempty,omitzero"`
}

// AnswerConfidence Confidence assessment for the generated answer
type AnswerConfidence struct {
	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0). Considers both ability to answer from provided resources and general knowledge.
	AnswerConfidence float32 `json:"answer_confidence"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance"`
}

// AnswerResult Result from answer generation with optional confidence and follow-up questions
type AnswerResult struct {
	// Answer Generated answer in markdown format
	Answer string `json:"answer"`

	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0)
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance,omitempty,omitzero"`

	// FollowupQuestions Suggested follow-up questions
	FollowupQuestions []string `json:"followup_questions,omitempty,omitzero"`
}

// AnswerStepConfig Configuration for the answer generation step. This step generates the final
// answer from retrieved documents using the reasoning as context.
type AnswerStepConfig struct {
	// AnswerContext Custom guidance for answer tone, detail level, and style
	AnswerContext string `json:"answer_context,omitempty,omitzero"`

	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// SystemPrompt Custom system prompt for answer generation
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`
}

// AntflyChunkerConfig Configuration for the local Antfly chunking provider.
//
// This provider runs chunking directly within the storage node process,
// without requiring an external Termite service. It uses simple fixed-size
// tokenizer-based chunking with no caching overhead.
//
// **Use this when:**
// - Running single-node deployments (swarm mode)
// - You don't need embedding/chunk caching across nodes
// - You want minimal setup complexity
//
// **Use Termite instead when:**
// - Running multi-node clusters where caching reduces costs
// - You need ONNX-accelerated chunking models
// - You want persistent chunk/embedding caches
type AntflyChunkerConfig struct {
	// FullText Configuration for full-text indexing of chunks in Bleve.
	// When present (even if empty), chunks will be stored with :cft: suffix and indexed in Bleve's _chunks field.
	// When absent, chunks use :c: suffix and are only used for vector embeddings.
	// This object is reserved for future options like boosting, field mapping, etc.
	FullText map[string]interface{} `json:"full_text,omitempty,omitzero"`

	// MaxChunks Maximum number of chunks to generate per document. Prevents excessive chunking of very large documents.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs).
	Separator string `json:"separator,omitempty,omitzero"`

	// TargetTokens Target number of tokens per chunk. Chunker will aim for chunks around this size.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`
}

// AntflyType defines model for AntflyType.
type AntflyType string

// AnthropicGeneratorConfig Configuration for the Anthropic generative AI provider (Claude models).
//
// API key via `api_key` field or `ANTHROPIC_API_KEY` environment variable.
//
// **Example Models:** claude-sonnet-4-5-20250929 (default), claude-opus-4-5-20251101, claude-3-5-haiku-20241022
//
// **Docs:** https://docs.anthropic.com/en/docs/about-claude/models/overview
type AnthropicGeneratorConfig struct {
	// ApiKey The Anthropic API key. If not provided, falls back to ANTHROPIC_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The full model ID of the Anthropic model to use (e.g., 'claude-sonnet-4-5-20250929', 'claude-opus-4-5-20251101').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-1.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Anthropic API endpoint (optional, uses default if not specified).
	Url string `json:"url,omitempty,omitzero"`
}

// BackupRequest defines model for BackupRequest.
type BackupRequest struct {
	// BackupId Unique identifier for this backup. Used to reference the backup for restore operations.
	// Choose a meaningful name that includes date/version information.
	BackupId string `json:"backup_id"`

	// Location Storage location for the backup. Supports multiple backends:
	// - Local filesystem: `file:///path/to/backup`
	// - Amazon S3: `s3://bucket-name/path/to/backup`
	//
	// The backup includes all table data, indexes, and metadata for the specified table.
	Location string `json:"location"`
}

// BatchRequest Batch insert, delete, and transform operations in a single request.
//
// **Atomicity**:
// - **Single shard**: Operations are atomic within shard boundaries
// - **Multiple shards**: Uses distributed 2-phase commit (2PC) for atomic cross-shard writes
//
// **How distributed transactions work**:
// 1. Metadata server allocates HLC timestamp and selects coordinator shard
// 2. Coordinator writes transaction record, participants write intents
// 3. After all intents succeed, coordinator commits transaction
// 4. Participants are notified asynchronously to resolve intents
// 5. Recovery loop ensures notifications complete even after coordinator failure
//
// **Performance**:
// - Single-shard batches: < 5ms latency
// - Cross-shard transactions: ~20ms latency
// - Intent resolution: < 30 seconds worst-case (via recovery loop)
//
// **Guarantees**:
// - All writes succeed or all fail (atomicity across all shards)
// - Coordinator failure is recoverable (new leader resumes notifications)
// - Idempotent resolution (duplicate notifications are safe)
//
// **Benefits**:
// - Reduces network overhead compared to individual requests
// - More efficient indexing (updates are batched)
// - Automatic distributed transactions when operations span shards
//
// The inserts are upserts - existing keys are overwritten, new keys are created.
type BatchRequest struct {
	// Deletes Array of document IDs to delete. Documents are removed from all indexes.
	//
	// Notes:
	// - Non-existent keys are silently ignored
	// - Deletions are processed before inserts in the same batch
	// - Keys are permanently removed from storage and indexes
	Deletes []string `json:"deletes,omitempty,omitzero"`

	// Inserts Map of document IDs to document objects. Each key is the unique identifier for the document.
	//
	// Best practices:
	// - Use consistent key naming schemes (e.g., "user:123", "article:456")
	// - Key length affects storage and performance - keep them reasonably short
	// - Keys are sorted lexicographically, so choose prefixes that support range scans
	Inserts map[string]map[string]interface{} `json:"inserts,omitempty,omitzero"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write
	// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`

	// Transforms Array of transform operations for in-place document updates using MongoDB-style operators.
	//
	// Transform operations allow you to modify documents without read-modify-write races:
	// - Operations are applied atomically on the server
	// - Multiple operations per document are applied in sequence
	// - Supports numeric operations ($inc, $mul), array operations ($push, $pull), and more
	//
	// Common use cases:
	// - Increment counters (views, likes, votes)
	// - Update timestamps ($currentDate)
	// - Manage arrays (add/remove tags, items)
	// - Update nested fields without overwriting the entire document
	Transforms []Transform `json:"transforms,omitempty,omitzero"`
}

// BedrockEmbedderConfig Configuration for the AWS Bedrock embedding provider.
//
// Uses AWS credentials from environment or IAM roles.
//
// **Example Models:** cohere.embed-english-v4, amazon.titan-embed-text-v2:0
//
// **Docs:** https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html
type BedrockEmbedderConfig struct {
	// BatchSize The batch size for embedding requests to optimize throughput.
	BatchSize int `json:"batch_size,omitempty,omitzero"`

	// Model The Bedrock model ID to use (e.g., 'cohere.embed-english-v4', 'amazon.titan-embed-text-v2:0').
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service (e.g., 'us-east-1').
	Region string `json:"region,omitempty,omitzero"`

	// StripNewLines Whether to strip new lines from the input text before embedding.
	StripNewLines bool `json:"strip_new_lines,omitempty,omitzero"`
}

// BedrockGeneratorConfig Configuration for the AWS Bedrock generative AI provider.
//
// Provides access to models from Anthropic, Meta, Amazon, Cohere, Mistral, and others.
//
// **Example Models:** anthropic.claude-sonnet-4-5-20250929-v1:0, meta.llama3-3-70b-instruct-v1:0, amazon.nova-pro-v1:0
//
// **Docs:** https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html
type BedrockGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The Bedrock model ID to use (e.g., 'anthropic.claude-sonnet-4-5-20250929-v1:0').
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service.
	Region string `json:"region,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-1.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// BingSearchConfig defines model for BingSearchConfig.
type BingSearchConfig struct {
	// ApiKey Bing Search API key (or set BING_SEARCH_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Endpoint Bing API endpoint URL
	Endpoint string `json:"endpoint,omitempty,omitzero"`

	// Freshness Filter results by freshness
	Freshness BingSearchConfigFreshness `json:"freshness,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// BingSearchConfigFreshness Filter results by freshness
type BingSearchConfigFreshness string

// BleveIndexV2Config defines model for BleveIndexV2Config.
type BleveIndexV2Config struct {
	// MemOnly Whether to use memory-only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`
}

// BleveIndexV2Stats defines model for BleveIndexV2Stats.
type BleveIndexV2Stats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// Rebuilding Whether the index is currently rebuilding
	Rebuilding bool `json:"rebuilding,omitempty,omitzero"`

	// TotalIndexed Number of documents in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`
}

// BoolFieldQuery defines model for BoolFieldQuery.
type BoolFieldQuery struct {
	Bool bool `json:"bool"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
}

// BooleanQuery defines model for BooleanQuery.
type BooleanQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost   Boost            `json:"boost,omitzero"`
	Filter  Query            `json:"filter,omitempty,omitzero"`
	Must    ConjunctionQuery `json:"must,omitempty,omitzero"`
	MustNot DisjunctionQuery `json:"must_not,omitempty,omitzero"`
	Should  DisjunctionQuery `json:"should,omitempty,omitzero"`
}

// Boost A floating-point number used to decrease or increase the relevance scores of a query.
type Boost = float64

// BraveSearchConfig defines model for BraveSearchConfig.
type BraveSearchConfig struct {
	// ApiKey Brave Search API key (or set BRAVE_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Freshness Freshness filter: pd=day, pw=week, pm=month, py=year
	Freshness BraveSearchConfigFreshness `json:"freshness,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// Spellcheck Enable spellcheck suggestions
	Spellcheck bool `json:"spellcheck,omitempty,omitzero"`

	// TextDecorations Include text decorations (bold, italic markers)
	TextDecorations bool `json:"text_decorations,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// BraveSearchConfigFreshness Freshness filter: pd=day, pw=week, pm=month, py=year
type BraveSearchConfigFreshness string

// ByteRange defines model for ByteRange.
type ByteRange = [][]byte

// ChainCondition Condition for trying the next generator in chain:
// - always: Always try next regardless of outcome
// - on_error: Try next on any error (default)
// - on_timeout: Try next only on timeout errors
// - on_rate_limit: Try next only on rate limit errors
type ChainCondition string

// ChainLink A single link in a generator chain with optional retry and condition
type ChainLink struct {
	// Condition Condition for trying the next generator in chain:
	// - always: Always try next regardless of outcome
	// - on_error: Try next on any error (default)
	// - on_timeout: Try next only on timeout errors
	// - on_rate_limit: Try next only on rate limit errors
	Condition ChainCondition `json:"condition,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator"`

	// Retry Retry configuration for generator calls
	Retry RetryConfig `json:"retry,omitempty,omitzero"`
}

// ChatAgentRequest defines model for ChatAgentRequest.
type ChatAgentRequest struct {
	// AccumulatedFilters Filters accumulated from previous conversation turns.
	// These are applied to all queries automatically.
	// New filters discovered in this turn will be added to this list in the response.
	AccumulatedFilters []FilterSpec `json:"accumulated_filters,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator"`

	// MaxContextTokens Maximum tokens for retrieved document context
	MaxContextTokens int `json:"max_context_tokens,omitempty,omitzero"`

	// Messages Conversation history. Include all previous messages to maintain context.
	// The last message should typically be from the user.
	Messages []ChatMessage `json:"messages"`

	// Queries Base query configurations. The chat agent will modify these queries
	// based on conversation context, applying filters and transformations.
	Queries []QueryRequest `json:"queries"`

	// Steps Per-step configuration for the chat agent pipeline. Similar to AnswerAgentSteps
	// but includes tool-specific configuration.
	Steps ChatAgentSteps `json:"steps,omitempty,omitzero"`

	// SystemPrompt Optional custom system prompt for the chat agent.
	// If not provided, uses a default conversational RAG prompt.
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// ChatAgentResult defines model for ChatAgentResult.
type ChatAgentResult struct {
	// Answer Final answer text (if available)
	Answer string `json:"answer,omitempty,omitzero"`

	// AnswerConfidence Confidence in the answer
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// AppliedFilters Filters that have been applied in this conversation
	AppliedFilters []FilterSpec `json:"applied_filters,omitempty,omitzero"`

	// ClassificationTransformation Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
	ClassificationTransformation ClassificationTransformationResult `json:"classification_transformation,omitempty,omitzero"`

	// Messages Updated conversation history including the assistant's response
	Messages []ChatMessage `json:"messages"`

	// PendingClarification A request for clarification from the user
	PendingClarification ClarificationRequest `json:"pending_clarification,omitempty,omitzero"`

	// QueryResults Search results from executed queries
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`

	// ToolCallsMade Number of tool calls made in this turn
	ToolCallsMade int `json:"tool_calls_made,omitempty,omitzero"`
}

// ChatAgentSteps Per-step configuration for the chat agent pipeline. Similar to AnswerAgentSteps
// but includes tool-specific configuration.
type ChatAgentSteps struct {
	// Answer Configuration for the answer generation step. This step generates the final
	// answer from retrieved documents using the reasoning as context.
	Answer AnswerStepConfig `json:"answer,omitempty,omitzero"`

	// Classification Configuration for the classification step. This step analyzes the query,
	// selects the optimal retrieval strategy, and generates semantic transformations.
	Classification ClassificationStepConfig `json:"classification,omitempty,omitzero"`

	// Tools Configuration for chat agent tools.
	//
	// If `enabled_tools` is empty/omitted, defaults to: add_filter, ask_clarification, search.
	//
	// For models that don't support native tool calling (e.g., Ollama),
	// a prompt-based fallback is used with structured output parsing.
	Tools ChatToolsConfig `json:"tools,omitempty,omitzero"`
}

// ChatMessage A message in the conversation history
type ChatMessage struct {
	// Content Text content of the message
	Content string `json:"content"`

	// Role Role of the message sender in the conversation
	Role ChatMessageRole `json:"role"`

	// ToolCalls Tool calls made by the assistant (only for assistant role)
	ToolCalls []ChatToolCall `json:"tool_calls,omitempty,omitzero"`

	// ToolResults Results from tool executions (only for tool role)
	ToolResults []ChatToolResult `json:"tool_results,omitempty,omitzero"`
}

// ChatMessageRole Role of the message sender in the conversation
type ChatMessageRole string

// ChatToolCall A tool call made by the assistant
type ChatToolCall struct {
	// Arguments Arguments passed to the tool as key-value pairs
	Arguments map[string]interface{} `json:"arguments"`

	// Id Unique identifier for this tool call
	Id string `json:"id"`

	// Name Name of the tool being called
	Name string `json:"name"`
}

// ChatToolName Available tool names for the chat agent.
// - add_filter: Add search filters (field constraints)
// - ask_clarification: Ask user for clarification
// - search: Execute semantic searches
// - websearch: Search the web (requires websearch_config)
// - fetch: Fetch URL content (subject to security controls)
type ChatToolName string

// ChatToolResult Result from executing a tool call
type ChatToolResult struct {
	// Error Error message if tool execution failed
	Error string `json:"error,omitempty,omitzero"`

	// Result Result data from the tool execution
	Result map[string]interface{} `json:"result"`

	// ToolCallId ID of the tool call this result corresponds to
	ToolCallId string `json:"tool_call_id"`
}

// ChatToolsConfig Configuration for chat agent tools.
//
// If `enabled_tools` is empty/omitted, defaults to: add_filter, ask_clarification, search.
//
// For models that don't support native tool calling (e.g., Ollama),
// a prompt-based fallback is used with structured output parsing.
type ChatToolsConfig struct {
	// EnabledTools List of tools to enable. If empty, defaults to filter, clarification, and search.
	EnabledTools []ChatToolName `json:"enabled_tools,omitempty,omitzero"`

	// FetchConfig Configuration for URL content fetching.
	//
	// Uses lib/scraping for downloading and processing. Supports:
	// - HTTP/HTTPS URLs with security validation
	// - HTML pages (extracts readable text via go-readability)
	// - PDF files (extracts text)
	// - Images (returns as data URIs)
	// - Plain text files
	//
	// Security features (from lib/scraping.ContentSecurityConfig):
	// - Allowed host whitelist
	// - Private IP blocking (SSRF prevention)
	// - Download size limits
	// - Timeout controls
	FetchConfig FetchConfig `json:"fetch_config,omitempty,omitzero"`

	// MaxToolIterations Maximum number of tool call iterations per turn.
	// Prevents infinite loops in tool execution.
	MaxToolIterations int `json:"max_tool_iterations,omitempty,omitzero"`

	// WebsearchConfig A unified configuration for web search providers.
	//
	// Each provider has specific configuration requirements. Use the appropriate
	// provider-specific config or set common options at the top level.
	//
	// **Environment Variables (fallbacks):**
	// - GOOGLE_CSE_API_KEY, GOOGLE_CSE_ID
	// - BING_SEARCH_API_KEY
	// - SERPER_API_KEY
	// - TAVILY_API_KEY
	// - BRAVE_API_KEY
	WebsearchConfig WebSearchConfig `json:"websearch_config,omitempty,omitzero"`
}

// ChunkerConfig defines model for ChunkerConfig.
type ChunkerConfig struct {
	// Provider The chunking provider to use.
	Provider ChunkerProvider `json:"provider"`
	union    json.RawMessage
}

// ChunkerProvider The chunking provider to use.
type ChunkerProvider string

// ClarificationRequest A request for clarification from the user
type ClarificationRequest struct {
	// Options Optional list of suggested answers for the user to choose from
	Options []string `json:"options,omitempty,omitzero"`

	// Question The clarifying question to ask the user
	Question string `json:"question"`

	// Required Whether the clarification is required before proceeding
	Required bool `json:"required,omitempty,omitzero"`
}

// ClassificationStepConfig Configuration for the classification step. This step analyzes the query,
// selects the optimal retrieval strategy, and generates semantic transformations.
type ClassificationStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// ForceSemanticMode Mode for semantic query generation:
	// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
	// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
	ForceSemanticMode SemanticQueryMode `json:"force_semantic_mode,omitempty,omitzero"`

	// ForceStrategy Strategy for query transformation and retrieval:
	// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
	// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
	// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
	// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
	ForceStrategy QueryStrategy `json:"force_strategy,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// MultiPhraseCount Number of alternative query phrasings to generate
	MultiPhraseCount int `json:"multi_phrase_count,omitempty,omitzero"`

	// WithReasoning Include pre-retrieval reasoning explaining query analysis and strategy selection
	WithReasoning bool `json:"with_reasoning,omitempty,omitzero"`
}

// ClassificationTransformationResult Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
type ClassificationTransformationResult struct {
	// Confidence Classification confidence (0.0 to 1.0)
	Confidence float32 `json:"confidence"`

	// ImprovedQuery Clarified query with added context for answer generation (human-readable)
	ImprovedQuery string `json:"improved_query"`

	// MultiPhrases Alternative phrasings of the query for expanded retrieval coverage
	MultiPhrases []string `json:"multi_phrases,omitempty,omitzero"`

	// Reasoning Pre-retrieval reasoning explaining query analysis and strategy selection (only present when with_classification_reasoning is enabled)
	Reasoning string `json:"reasoning,omitempty,omitzero"`

	// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
	RouteType RouteType `json:"route_type"`

	// SemanticMode Mode for semantic query generation:
	// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
	// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
	SemanticMode SemanticQueryMode `json:"semantic_mode"`

	// SemanticQuery Optimized query for vector/semantic search. Content style depends on semantic_mode: keywords for 'rewrite', hypothetical answer for 'hypothetical'
	SemanticQuery string `json:"semantic_query"`

	// StepBackQuery Broader background query for context (only present when strategy is 'step_back')
	StepBackQuery string `json:"step_back_query,omitempty,omitzero"`

	// Strategy Strategy for query transformation and retrieval:
	// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
	// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
	// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
	// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
	Strategy QueryStrategy `json:"strategy"`

	// SubQuestions Decomposed sub-questions (only present when strategy is 'decompose')
	SubQuestions []string `json:"sub_questions,omitempty,omitzero"`
}

// ClusterHealth Overall health status of the cluster
type ClusterHealth string

// ClusterStatus defines model for ClusterStatus.
type ClusterStatus struct {
	// AuthEnabled Indicates whether authentication is enabled for the cluster
	AuthEnabled bool `json:"auth_enabled,omitempty"`

	// Health Overall health status of the cluster
	Health ClusterHealth `json:"health"`

	// Message Optional message providing details about the health status
	Message              string                 `json:"message,omitempty,omitzero"`
	AdditionalProperties map[string]interface{} `json:"-"`
}

// CohereEmbedderConfig Configuration for the Cohere embedding provider.
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** embed-english-v3.0 (default, 1024 dims), embed-multilingual-v3.0
//
// **Docs:** https://docs.cohere.com/reference/embed
type CohereEmbedderConfig struct {
	// ApiKey The Cohere API key. Can also be set via COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// InputType Specifies the type of input for optimized embeddings.
	InputType CohereEmbedderConfigInputType `json:"input_type,omitempty,omitzero"`

	// Model The name of the Cohere embedding model to use.
	Model string `json:"model"`

	// Truncate How to handle inputs longer than the max token length.
	Truncate CohereEmbedderConfigTruncate `json:"truncate,omitempty,omitzero"`
}

// CohereEmbedderConfigInputType Specifies the type of input for optimized embeddings.
type CohereEmbedderConfigInputType string

// CohereEmbedderConfigTruncate How to handle inputs longer than the max token length.
type CohereEmbedderConfigTruncate string

// CohereGeneratorConfig Configuration for the Cohere generative AI provider (Command models).
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** command-r-plus (default), command-r, command-a-03-2025
//
// **Docs:** https://docs.cohere.com/reference/chat
type CohereGeneratorConfig struct {
	// ApiKey The Cohere API key. If not provided, falls back to COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (0.0-1.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Cohere model to use.
	Model string `json:"model"`

	// PresencePenalty Penalty for token presence (0.0-1.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-1.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// CohereRerankerConfig Configuration for the Cohere reranking provider.
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** rerank-english-v3.0 (default), rerank-multilingual-v3.0
//
// **Docs:** https://docs.cohere.com/reference/rerank
type CohereRerankerConfig struct {
	// ApiKey The Cohere API key. Can also be set via COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// MaxChunksPerDoc Maximum number of chunks per document for long document handling.
	MaxChunksPerDoc int `json:"max_chunks_per_doc,omitempty,omitzero"`

	// Model The name of the Cohere reranking model to use.
	Model string `json:"model"`

	// TopN Number of most relevant documents to return. If not specified, returns all documents with scores.
	TopN int `json:"top_n,omitempty,omitzero"`
}

// ConfidenceStepConfig Configuration for confidence assessment. Evaluates answer quality and
// resource relevance. Can use a model calibrated for scoring tasks.
type ConfidenceStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Context Custom guidance for confidence assessment approach
	Context string `json:"context,omitempty,omitzero"`

	// Enabled Enable confidence scoring
	Enabled bool `json:"enabled,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`
}

// ConjunctionQuery defines model for ConjunctionQuery.
type ConjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Conjuncts []Query `json:"conjuncts"`
}

// CreateTableRequest defines model for CreateTableRequest.
type CreateTableRequest struct {
	// Description Optional human-readable description of the table and its purpose.
	// Useful for documentation and team collaboration.
	Description string `json:"description,omitempty,omitzero"`

	// Indexes Map of index name to index configuration. Indexes enable different query capabilities:
	// - Full-text indexes for BM25 search
	// - Vector indexes for semantic similarity
	// - Multimodal indexes for images/audio/video
	//
	// You can add multiple indexes to support different query patterns.
	Indexes map[string]IndexConfig `json:"indexes,omitempty,omitzero"`

	// NumShards Number of shards to create for the table. Data is partitioned across shards based on key ranges.
	//
	// **Sizing Guidelines:**
	// - Small datasets (<100K docs): 1-3 shards
	// - Medium datasets (100K-1M docs): 3-10 shards
	// - Large datasets (>1M docs): 10+ shards
	//
	// More shards enable better parallelism but increase overhead. Choose based on expected data size and query patterns.
	//
	// **When to Add More Shards:**
	//
	// Antfly supports **online shard reallocation** without downtime. Add more shards when:
	// - Individual shards exceed size thresholds (configurable)
	// - Query latency increases due to large shard size
	// - Need better parallelism for write-heavy workloads
	//
	// Use the internal `/reallocate` endpoint to trigger automatic shard splitting:
	// ```bash
	// POST /_internal/v1/reallocate
	// ```
	//
	// This enqueues a reallocation request that the leader processes asynchronously, splitting
	// large shards and redistributing data without service interruption.
	//
	// **Advantages over Elasticsearch:**
	// - Automatic shard splitting (no manual reindexing required)
	// - Online operation (no downtime)
	// - Transparent to applications (keys remain accessible during reallocation)
	NumShards uint `json:"num_shards,omitempty,omitzero"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema `json:"schema,omitempty,omitzero"`
}

// CreateUserRequest defines model for CreateUserRequest.
type CreateUserRequest struct {
	// InitialPolicies Optional list of initial permissions for the user.
	InitialPolicies []Permission `json:"initial_policies,omitzero"`
	Password        string       `json:"password"`

	// Username Username for the new user. If provided in the path, this field can be omitted or must match the path parameter.
	Username string `json:"username,omitempty,omitzero"`
}

// DateRange defines model for DateRange.
type DateRange struct {
	From *string `json:"from,omitempty"`
	Name string  `json:"name"`
	To   *string `json:"to,omitempty"`
}

// DateRangeResult defines model for DateRangeResult.
type DateRangeResult struct {
	Count int     `json:"count"`
	From  *string `json:"from,omitempty"`
	Name  string  `json:"name"`
	To    *string `json:"to,omitempty"`
}

// DateRangeStringQuery defines model for DateRangeStringQuery.
type DateRangeStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost          Boost     `json:"boost,omitzero"`
	DatetimeParser string    `json:"datetime_parser,omitempty,omitzero"`
	End            time.Time `json:"end,omitempty,omitzero"`
	Field          string    `json:"field,omitempty,omitzero"`
	InclusiveEnd   bool      `json:"inclusive_end,omitzero"`
	InclusiveStart bool      `json:"inclusive_start,omitzero"`
	Start          time.Time `json:"start,omitempty,omitzero"`
}

// DisjunctionQuery defines model for DisjunctionQuery.
type DisjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Disjuncts []Query `json:"disjuncts"`
	Min       float64 `json:"min,omitempty,omitzero"`
}

// DocIdQuery defines model for DocIdQuery.
type DocIdQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost    `json:"boost,omitzero"`
	Ids   []string `json:"ids"`
}

// DocumentSchema Defines the structure of a document type
type DocumentSchema struct {
	// Description A description of the document type.
	Description string `json:"description,omitempty,omitzero"`

	// Schema A valid JSON Schema defining the document's structure.
	// This is used to infer indexing rules and field types.
	Schema map[string]interface{} `json:"schema,omitempty,omitzero"`
}

// DuckDuckGoSearchConfig defines model for DuckDuckGoSearchConfig.
type DuckDuckGoSearchConfig struct {
	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// NoHtml Remove HTML from results
	NoHtml bool `json:"no_html,omitempty,omitzero"`

	// NoRedirect Skip HTTP redirect for bang queries
	NoRedirect bool `json:"no_redirect,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// Edge A typed, weighted connection between documents
type Edge struct {
	// CreatedAt When the edge was created
	CreatedAt time.Time `json:"created_at,omitempty,omitzero"`

	// Metadata Optional edge metadata
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`

	// Source Base64-encoded source document key
	Source []byte `json:"source"`

	// Target Base64-encoded target document key
	Target []byte `json:"target"`

	// Type Edge type (e.g., "cites", "similar_to", "authored_by")
	Type string `json:"type"`

	// UpdatedAt When the edge was last updated
	UpdatedAt time.Time `json:"updated_at,omitempty,omitzero"`

	// Weight Edge weight/confidence (0.0 to 1.0)
	Weight float64 `json:"weight"`
}

// EdgeDirection Direction of edges to query:
// - out: Outgoing edges from the node
// - in: Incoming edges to the node
// - both: Both outgoing and incoming edges
type EdgeDirection string

// EdgeTypeConfig Configuration for a specific edge type
type EdgeTypeConfig struct {
	// AllowSelfLoops Whether to allow edges from a node to itself
	AllowSelfLoops bool `json:"allow_self_loops,omitempty,omitzero"`

	// MaxWeight Maximum allowed edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum allowed edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// Name Edge type name (e.g., 'cites', 'similar_to')
	Name string `json:"name"`

	// RequiredMetadata Required metadata fields for this edge type
	RequiredMetadata []string `json:"required_metadata,omitempty,omitzero"`
}

// EdgesResponse defines model for EdgesResponse.
type EdgesResponse struct {
	// Count Total number of edges returned
	Count int    `json:"count,omitempty,omitzero"`
	Edges []Edge `json:"edges,omitempty,omitzero"`
}

// EmbedderConfig defines model for EmbedderConfig.
type EmbedderConfig struct {
	// Provider The embedding provider to use.
	Provider EmbedderProvider `json:"provider"`
	union    json.RawMessage
}

// EmbedderProvider The embedding provider to use.
type EmbedderProvider string

// EmbeddingIndexConfig defines model for EmbeddingIndexConfig.
type EmbeddingIndexConfig struct {
	// Chunker A unified configuration for a chunking provider.
	Chunker ChunkerConfig `json:"chunker,omitempty,omitzero"`

	// Dimension Vector dimension
	Dimension int `json:"dimension"`

	// Embedder A unified configuration for an embedding provider.
	//
	// Embedders can be configured with templates to customize how documents are
	// converted to text before embedding. Templates use Handlebars syntax and
	// support various built-in helpers.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full document as context
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active user{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// Document with metadata:
	// ```handlebars
	// Title: {{metadata.title}}
	// Date: {{metadata.date}}
	// Tags: {{#each metadata.tags}}{{this}}, {{/each}}
	//
	// {{content}}
	// ```
	//
	// HTML content extraction:
	// ```handlebars
	// Product: {{name}}
	// Description: {{scrubHtml description_html}}
	// Price: ${{price}}
	// ```
	//
	// Multimodal with image:
	// ```handlebars
	// Product: {{title}}
	// {{media url=image}}
	// Description: {{description}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{title}}
	// {{#if author}}By: {{author}}{{/if}}
	// {{#if (eq category "premium")}} Premium Content{{/if}}
	// {{body}}
	// ```
	//
	// **Environment Variables:**
	// - `GEMINI_API_KEY` - API key for Google AI
	// - `OPENAI_API_KEY` - API key for OpenAI
	// - `OPENAI_BASE_URL` - Base URL for OpenAI-compatible APIs
	// - `OLLAMA_HOST` - Ollama server URL (e.g., http://localhost:11434)
	//
	// **Importing Pre-computed Embeddings:**
	//
	// You can import existing embeddings (from OpenAI, Cohere, or any provider) by including
	// them directly in your documents using the `_embeddings` field. This bypasses the
	// embedding generation step and writes vectors directly to the index.
	//
	// **Steps:**
	// 1. Create the index first with the appropriate dimension
	// 2. Write documents with `_embeddings: { "<indexName>": [...<embedding>...] }`
	//
	// **Example:**
	// ```json
	// {
	//   "title": "My Document",
	//   "content": "Document text...",
	//   "_embeddings": {
	//     "my_vector_index": [0.1, 0.2, 0.3, ...]
	//   }
	// }
	// ```
	//
	// **Use Cases:**
	// - Migrating from another vector database with existing embeddings
	// - Using embeddings generated by external systems
	// - Importing pre-computed OpenAI, Cohere, or other provider embeddings
	// - Batch processing embeddings offline before ingestion
	Embedder EmbedderConfig `json:"embedder,omitempty,omitzero"`

	// Field Field to extract embeddings from
	Field string `json:"field,omitempty,omitzero"`

	// MemOnly Whether to use in-memory only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`

	// Summarizer A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Summarizer GeneratorConfig `json:"summarizer,omitempty,omitzero"`

	// Template Handlebars template for generating prompts. See https://handlebarsjs.com/guide/ for more information.
	Template string `json:"template,omitempty,omitzero"`
}

// EmbeddingIndexStats defines model for EmbeddingIndexStats.
type EmbeddingIndexStats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalIndexed Number of vectors in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`

	// TotalNodes Total number of nodes in the index
	TotalNodes uint64 `json:"total_nodes,omitempty,omitzero"`
}

// Error defines model for Error.
type Error struct {
	Error string `json:"error"`
}

// EvalConfig Configuration for inline evaluation of query results.
// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
type EvalConfig struct {
	// Evaluators List of evaluators to run
	Evaluators []EvaluatorName `json:"evaluators,omitempty,omitzero"`

	// GroundTruth Ground truth data for evaluation
	GroundTruth GroundTruth `json:"ground_truth,omitempty,omitzero"`

	// Judge A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Judge GeneratorConfig `json:"judge,omitempty,omitzero"`

	// Options Options for evaluation behavior
	Options EvalOptions `json:"options,omitempty,omitzero"`
}

// EvalOptions Options for evaluation behavior
type EvalOptions struct {
	// K K value for @K metrics (precision@k, recall@k, ndcg@k)
	K int `json:"k,omitempty,omitzero"`

	// PassThreshold Score threshold for pass/fail determination
	PassThreshold float32 `json:"pass_threshold,omitempty,omitzero"`

	// TimeoutSeconds Timeout for evaluation in seconds
	TimeoutSeconds int `json:"timeout_seconds,omitempty,omitzero"`
}

// EvalRequest Standalone evaluation request for POST /eval endpoint.
// Useful for testing evaluators without running a query.
type EvalRequest struct {
	// Context Retrieved documents/context
	Context []map[string]interface{} `json:"context,omitempty,omitzero"`

	// Evaluators List of evaluators to run
	Evaluators []EvaluatorName `json:"evaluators"`

	// GroundTruth Ground truth data for evaluation
	GroundTruth GroundTruth `json:"ground_truth,omitempty,omitzero"`

	// Judge A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Judge GeneratorConfig `json:"judge,omitempty,omitzero"`

	// Options Options for evaluation behavior
	Options EvalOptions `json:"options,omitempty,omitzero"`

	// Output Generated output to evaluate (optional for retrieval-only)
	Output string `json:"output,omitempty,omitzero"`

	// Query Original query/input to evaluate
	Query string `json:"query,omitempty,omitzero"`

	// RetrievedIds IDs of retrieved documents (for retrieval metrics)
	RetrievedIds []string `json:"retrieved_ids,omitempty,omitzero"`
}

// EvalResult Complete evaluation result
type EvalResult struct {
	// DurationMs Total evaluation duration in milliseconds
	DurationMs int `json:"duration_ms,omitempty,omitzero"`

	// Scores Scores organized by category
	Scores EvalScores `json:"scores,omitempty,omitzero"`

	// Summary Aggregate statistics across all evaluators
	Summary EvalSummary `json:"summary,omitempty,omitzero"`
}

// EvalScores Scores organized by category
type EvalScores struct {
	// Generation Generation quality scores (faithfulness, relevance, etc.)
	Generation map[string]EvaluatorScore `json:"generation,omitempty,omitzero"`

	// Retrieval Retrieval metric scores (recall, precision, ndcg, etc.)
	Retrieval map[string]EvaluatorScore `json:"retrieval,omitempty,omitzero"`
}

// EvalSummary Aggregate statistics across all evaluators
type EvalSummary struct {
	// AverageScore Average score across all evaluators
	AverageScore float32 `json:"average_score,omitempty,omitzero"`

	// Failed Number of evaluators that failed
	Failed int `json:"failed,omitempty,omitzero"`

	// Passed Number of evaluators that passed
	Passed int `json:"passed,omitempty,omitzero"`

	// Total Total number of evaluators run
	Total int `json:"total,omitempty,omitzero"`
}

// EvaluatorName Available evaluator types:
//
// **Retrieval metrics** (require ground_truth.relevant_ids):
// - recall: Recall@k - fraction of relevant docs retrieved
// - precision: Precision@k - fraction of retrieved docs that are relevant
// - ndcg: Normalized Discounted Cumulative Gain
// - mrr: Mean Reciprocal Rank
// - map: Mean Average Precision
//
// **LLM-as-judge metrics** (require judge config):
// - relevance: Is output relevant to query? (works on retrieval-only too)
// - faithfulness: Is output grounded in context?
// - completeness: Does output fully address query?
// - coherence: Is output well-structured?
// - safety: Is output safe/appropriate?
// - helpfulness: Is output useful?
// - correctness: Is output factually correct? (uses expectations)
// - citation_quality: Are citations accurate?
type EvaluatorName string

// EvaluatorScore Result from a single evaluator
type EvaluatorScore struct {
	// Metadata Additional evaluator-specific data
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`

	// Pass Whether the evaluation passed the threshold
	Pass bool `json:"pass,omitempty,omitzero"`

	// Reason Human-readable explanation of the result
	Reason string `json:"reason,omitempty,omitzero"`

	// Score Numeric score (0-1)
	Score float32 `json:"score,omitempty,omitzero"`
}

// FacetOption defines model for FacetOption.
type FacetOption struct {
	DateRanges    []DateRange    `json:"date_ranges,omitempty,omitzero"`
	Field         string         `json:"field,omitempty,omitzero"`
	NumericRanges []NumericRange `json:"numeric_ranges,omitempty,omitzero"`
	Size          int            `json:"size,omitempty,omitzero"`
}

// FacetResult defines model for FacetResult.
type FacetResult struct {
	DateRanges    []DateRangeResult    `json:"date_ranges,omitempty,omitzero"`
	Field         string               `json:"field,omitempty,omitzero"`
	Missing       int                  `json:"missing,omitempty,omitzero"`
	NumericRanges []NumericRangeResult `json:"numeric_ranges,omitempty,omitzero"`
	Terms         []TermFacetResult    `json:"terms,omitempty,omitzero"`
	Total         int                  `json:"total,omitempty,omitzero"`
}

// FailedOperation defines model for FailedOperation.
type FailedOperation struct {
	Error     string                   `json:"error,omitempty,omitzero"`
	Id        string                   `json:"id,omitempty,omitzero"`
	Operation FailedOperationOperation `json:"operation,omitempty,omitzero"`
}

// FailedOperationOperation defines model for FailedOperation.Operation.
type FailedOperationOperation string

// FetchConfig Configuration for URL content fetching.
//
// Uses lib/scraping for downloading and processing. Supports:
// - HTTP/HTTPS URLs with security validation
// - HTML pages (extracts readable text via go-readability)
// - PDF files (extracts text)
// - Images (returns as data URIs)
// - Plain text files
//
// Security features (from lib/scraping.ContentSecurityConfig):
// - Allowed host whitelist
// - Private IP blocking (SSRF prevention)
// - Download size limits
// - Timeout controls
type FetchConfig struct {
	// AllowedHosts Whitelist of allowed hostnames for fetching.
	// If empty, all hosts are allowed (except private IPs).
	// Example: ["docs.example.com", "api.example.com"]
	AllowedHosts []string `json:"allowed_hosts,omitempty,omitzero"`

	// BlockPrivateIps Block requests to private IP ranges (SSRF prevention).
	// Blocked: 127.0.0.0/8, 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16
	BlockPrivateIps *bool `json:"block_private_ips,omitempty"`

	// MaxContentLength Maximum content length in characters (truncated if exceeded)
	MaxContentLength int `json:"max_content_length,omitempty,omitzero"`

	// MaxDownloadSizeBytes Maximum download size in bytes (default: 100MB)
	MaxDownloadSizeBytes int `json:"max_download_size_bytes,omitempty,omitzero"`

	// TimeoutSeconds Download timeout in seconds
	TimeoutSeconds int `json:"timeout_seconds,omitempty,omitzero"`
}

// FilterSpec A filter specification to apply to search queries
type FilterSpec struct {
	// Field Field name to filter on
	Field string `json:"field"`

	// Operator Filter operator:
	// - eq: Equals
	// - ne: Not equals
	// - gt/gte: Greater than (or equal)
	// - lt/lte: Less than (or equal)
	// - contains: Contains substring
	// - prefix: Starts with
	// - range: Between two values (value should be array [min, max])
	// - in: Value in list (value should be array)
	Operator FilterSpecOperator `json:"operator"`

	// Value Filter value (string, number, boolean, or array for range/in operators)
	Value interface{} `json:"value"`
}

// FilterSpecOperator Filter operator:
// - eq: Equals
// - ne: Not equals
// - gt/gte: Greater than (or equal)
// - lt/lte: Less than (or equal)
// - contains: Contains substring
// - prefix: Starts with
// - range: Between two values (value should be array [min, max])
// - in: Value in list (value should be array)
type FilterSpecOperator string

// FollowupStepConfig Configuration for generating follow-up questions. Uses a separate generator
// call which can use a cheaper/faster model.
type FollowupStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Context Custom guidance for follow-up question focus and style
	Context string `json:"context,omitempty,omitzero"`

	// Count Number of follow-up questions to generate
	Count int `json:"count,omitempty,omitzero"`

	// Enabled Enable follow-up question generation
	Enabled bool `json:"enabled,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`
}

// Fuzziness The fuzziness of the query. Can be an integer or "auto".
type Fuzziness struct {
	union json.RawMessage
}

// Fuzziness0 defines model for .
type Fuzziness0 = int32

// Fuzziness1 defines model for Fuzziness.1.
type Fuzziness1 string

// FuzzyQuery defines model for FuzzyQuery.
type FuzzyQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness `json:"fuzziness,omitempty,omitzero"`
	PrefixLength int32     `json:"prefix_length,omitempty,omitzero"`
	Term         string    `json:"term"`
}

// GeneratorConfig defines model for GeneratorConfig.
type GeneratorConfig struct {
	// Provider The generative AI provider to use.
	Provider GeneratorProvider `json:"provider"`
	union    json.RawMessage
}

// GeneratorProvider The generative AI provider to use.
type GeneratorProvider string

// GeoBoundingBoxQuery defines model for GeoBoundingBoxQuery.
type GeoBoundingBoxQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost `json:"boost,omitzero"`

	// BottomRight [lon, lat]
	BottomRight []float64 `json:"bottom_right"`
	Field       string    `json:"field,omitempty,omitzero"`

	// TopLeft [lon, lat]
	TopLeft []float64 `json:"top_left"`
}

// GeoBoundingPolygonQuery defines model for GeoBoundingPolygonQuery.
type GeoBoundingPolygonQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost         Boost      `json:"boost,omitzero"`
	Field         string     `json:"field,omitempty,omitzero"`
	PolygonPoints []GeoPoint `json:"polygon_points"`
}

// GeoDistanceQuery defines model for GeoDistanceQuery.
type GeoDistanceQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Distance string `json:"distance"`
	Field    string `json:"field,omitempty,omitzero"`

	// Location [lon, lat]
	Location []float64 `json:"location"`
}

// GeoPoint defines model for GeoPoint.
type GeoPoint struct {
	Lat float64 `json:"lat,omitempty,omitzero"`
	Lon float64 `json:"lon,omitempty,omitzero"`
}

// GeoShape A GeoJSON shape object. This is a simplified representation.
type GeoShape struct {
	Coordinates []interface{} `json:"coordinates"`
	Type        string        `json:"type"`
}

// GeoShapeGeometry defines model for GeoShapeGeometry.
type GeoShapeGeometry struct {
	Relation GeoShapeGeometryRelation `json:"relation"`

	// Shape A GeoJSON shape object. This is a simplified representation.
	Shape GeoShape `json:"shape"`
}

// GeoShapeGeometryRelation defines model for GeoShapeGeometry.Relation.
type GeoShapeGeometryRelation string

// GeoShapeQuery defines model for GeoShapeQuery.
type GeoShapeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost            `json:"boost,omitzero"`
	Field    string           `json:"field,omitempty,omitzero"`
	Geometry GeoShapeGeometry `json:"geometry"`
}

// GoogleEmbedderConfig Configuration for the Google AI (Gemini) embedding provider.
//
// API key via `api_key` field or `GEMINI_API_KEY` environment variable.
//
// **Example Models:** gemini-embedding-001 (default, 3072 dims)
//
// **Docs:** https://ai.google.dev/gemini-api/docs/embeddings
type GoogleEmbedderConfig struct {
	// ApiKey The Google API key. Can also be set via GEMINI_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimension The dimension of the embedding vector (768, 1536, or 3072 recommended).
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1'). Required for Vertex AI, optional for Gemini API.
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the embedding model to use.
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID (optional for Gemini API, required for Vertex AI).
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Url The URL of the Google API endpoint (optional, uses default if not specified).
	Url string `json:"url,omitempty,omitzero"`
}

// GoogleGeneratorConfig Configuration for the Google generative AI provider (Gemini).
//
// **Example Models:** gemini-2.5-flash (default), gemini-2.5-pro, gemini-3.0-pro
//
// **Docs:** https://ai.google.dev/gemini-api/docs/models
type GoogleGeneratorConfig struct {
	// ApiKey The Google API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1').
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the generative model to use (e.g., 'gemini-2.5-flash', 'gemini-2.5-pro', 'gemini-3.0-pro').
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Google API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// GoogleSearchConfig defines model for GoogleSearchConfig.
type GoogleSearchConfig struct {
	// ApiKey Google API key (or set GOOGLE_CSE_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// CseId Custom Search Engine ID (or set GOOGLE_CSE_ID env var)
	CseId string `json:"cse_id,omitempty,omitzero"`

	// DateRestrict Restrict results by date (e.g., 'd7' for last 7 days, 'm1' for last month)
	DateRestrict string `json:"date_restrict,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// SearchType Type of search to perform
	SearchType GoogleSearchConfigSearchType `json:"search_type,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// GoogleSearchConfigSearchType Type of search to perform
type GoogleSearchConfigSearchType string

// GraphIndexV0Config Configuration for graph_v0 index type
type GraphIndexV0Config struct {
	// EdgeTypes List of edge types with their configurations
	EdgeTypes []EdgeTypeConfig `json:"edge_types,omitempty,omitzero"`

	// MaxEdgesPerDocument Maximum number of edges per document (0 = unlimited)
	MaxEdgesPerDocument int `json:"max_edges_per_document,omitempty,omitzero"`
}

// GraphIndexV0Stats Statistics for graph_v0 index
type GraphIndexV0Stats struct {
	// EdgeTypes Count of edges per edge type
	EdgeTypes map[string]uint64 `json:"edge_types,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalEdges Total number of edges in the graph
	TotalEdges uint64 `json:"total_edges,omitempty,omitzero"`
}

// GraphNodeSelector Defines how to select start/target nodes for graph queries
type GraphNodeSelector struct {
	// Keys Explicit list of node keys
	Keys []string `json:"keys,omitempty,omitzero"`

	// Limit Maximum number of nodes to select from the referenced results
	Limit int `json:"limit,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`

	// ResultRef Reference to search results to use as nodes:
	// - "$full_text_results" - use full-text search results
	// - "$aknn_results.index_name" - use vector search results from specific index
	ResultRef string `json:"result_ref,omitempty,omitzero"`
}

// GraphQuery Declarative graph query to execute after full-text/vector searches
type GraphQuery struct {
	// Fields Which fields to return from documents
	Fields []string `json:"fields,omitempty,omitzero"`

	// IncludeDocuments Fetch full documents for graph results
	IncludeDocuments bool `json:"include_documents,omitempty,omitzero"`

	// IncludeEdges Include edge details for each node
	IncludeEdges bool `json:"include_edges,omitempty,omitzero"`

	// IndexName Graph index name (must be graph_v0 type)
	IndexName string `json:"index_name"`

	// Params Parameters for graph traversal and pathfinding
	Params GraphQueryParams `json:"params,omitempty,omitzero"`

	// Pattern Pattern steps for pattern query type
	Pattern []PatternStep `json:"pattern,omitempty,omitzero"`

	// ReturnAliases Which aliases to return from pattern query (empty = all)
	ReturnAliases []string `json:"return_aliases,omitempty,omitzero"`

	// StartNodes Defines how to select start/target nodes for graph queries
	StartNodes GraphNodeSelector `json:"start_nodes,omitempty,omitzero"`

	// TargetNodes Defines how to select start/target nodes for graph queries
	TargetNodes GraphNodeSelector `json:"target_nodes,omitempty,omitzero"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryParams Parameters for graph traversal and pathfinding
type GraphQueryParams struct {
	// Algorithm Graph algorithm to run (e.g., 'pagerank', 'betweenness')
	Algorithm string `json:"algorithm,omitempty,omitzero"`

	// AlgorithmParams Parameters for the graph algorithm
	AlgorithmParams map[string]interface{} `json:"algorithm_params,omitempty,omitzero"`

	// DeduplicateNodes Remove duplicate nodes (traversal)
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information (traversal)
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// K Number of paths to find (k-shortest-paths)
	K int `json:"k,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum number of results (traversal)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`

	// WeightMode Path weighting algorithm for pathfinding:
	// - min_hops: Minimize number of edges
	// - min_weight: Minimize sum of edge weights
	// - max_weight: Maximize product of edge weights
	WeightMode PathWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// GraphQueryResult Results of a graph query
type GraphQueryResult struct {
	// Matches Pattern matches (for pattern queries)
	Matches []PatternMatch `json:"matches,omitempty,omitzero"`

	// Nodes Result nodes
	Nodes []GraphResultNode `json:"nodes,omitempty,omitzero"`

	// Paths Result paths (for pathfinding queries)
	Paths []Path `json:"paths,omitempty,omitzero"`

	// Took Query execution time
	Took time.Duration `json:"took,omitempty,omitzero"`

	// Total Total number of results
	Total int `json:"total"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryType Type of graph query to execute
type GraphQueryType string

// GraphResultNode A node in graph query results
type GraphResultNode struct {
	// Depth Distance from start node
	Depth int `json:"depth,omitempty,omitzero"`

	// Distance Weighted distance
	Distance float64 `json:"distance,omitempty,omitzero"`

	// Document Full document (if include_documents=true)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Edges Connected edges (when include_edges=true)
	Edges []Edge `json:"edges,omitempty,omitzero"`

	// Key Document key
	Key string `json:"key"`

	// Path Keys in path from start to this node
	Path []string `json:"path,omitempty,omitzero"`

	// PathEdges Edges in path from start to this node
	PathEdges []PathEdge `json:"path_edges,omitempty,omitzero"`
}

// GroundTruth Ground truth data for evaluation
type GroundTruth struct {
	// Expectations Context for evaluators about what to expect in the response.
	// Provides guidance for LLM judges (e.g., "Should mention pricing tiers").
	Expectations string `json:"expectations,omitempty,omitzero"`

	// RelevantIds Document IDs known to be relevant (for retrieval metrics)
	RelevantIds []string `json:"relevant_ids,omitempty,omitzero"`
}

// IPRangeQuery defines model for IPRangeQuery.
type IPRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Cidr  string `json:"cidr"`
	Field string `json:"field,omitempty,omitzero"`
}

// IndexConfig Configuration for an index
type IndexConfig struct {
	// Description Optional description of the index and its purpose
	Description string `json:"description,omitempty,omitzero"`

	// Enrichments List of enrichment names to apply to documents before indexing. Enrichments must be defined at the table level.
	Enrichments []string `json:"enrichments,omitempty,omitzero"`

	// Name Name of the index
	Name string `json:"name"`

	// Type The type of the index.
	Type  IndexType `json:"type"`
	union json.RawMessage
}

// IndexStats Statistics for an index
type IndexStats struct {
	union json.RawMessage
}

// IndexStatus defines model for IndexStatus.
type IndexStatus struct {
	// Config Configuration for an index
	Config      IndexConfig           `json:"config"`
	ShardStatus map[string]IndexStats `json:"shard_status"`

	// Status Statistics for an index
	Status IndexStats `json:"status"`
}

// IndexType The type of the index.
type IndexType string

// KeyRange Key range processed in this request
type KeyRange struct {
	From string `json:"from,omitempty,omitzero"`
	To   string `json:"to,omitempty,omitzero"`
}

// LinearMergePageStatus Status of a linear merge page operation:
// - "success": All records in batch processed successfully
// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
// - "error": Fatal error occurred, no records processed successfully
type LinearMergePageStatus string

// LinearMergeRequest Linear merge operation for syncing sorted records from external sources.
// Use this to keep Antfly in sync with an external database or data source.
//
// **How it works:**
// 1. Send sorted records from your external source
// 2. Server upserts records that exist in your batch
// 3. Server deletes Antfly records in the key range that are absent from your batch
// 4. If stopped at shard boundary, use next_cursor for next request
//
// **WARNING:** Not safe for concurrent operations with overlapping key ranges.
type LinearMergeRequest struct {
	// DryRun If true, returns what would be deleted without making changes.
	//
	// Use cases:
	// - Validate sync behavior before committing
	// - Check which records will be removed
	// - Test key range boundaries
	//
	// Response includes deleted_ids array when dry_run=true.
	DryRun bool `json:"dry_run,omitempty,omitzero"`

	// LastMergedId ID of last record from previous merge request.
	// - First request: Use empty string ""
	// - Subsequent requests: Use next_cursor from previous response
	// - Defines lower bound of key range to process
	//
	// This enables pagination for large datasets.
	LastMergedId string `json:"last_merged_id,omitempty,omitzero"`

	// Records Map of resource ID to resource object: {"resource_id_1": {...}, "resource_id_2": {...}}
	//
	// Requirements:
	// - Keys must be sorted lexicographically by your client
	// - Server will process keys in sorted order
	// - Use consistent key naming (e.g., all start with same prefix)
	//
	// This format avoids duplicate IDs and matches Antfly's batch write interface.
	Records map[string]interface{} `json:"records"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write
	// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`
}

// LinearMergeResult defines model for LinearMergeResult.
type LinearMergeResult struct {
	// Deleted Records deleted or would be deleted (if dry_run=true)
	Deleted int `json:"deleted"`

	// DeletedIds IDs that were deleted (or would be deleted if dry_run=true). Only included if dry_run=true.
	DeletedIds []string          `json:"deleted_ids,omitempty,omitzero"`
	Failed     []FailedOperation `json:"failed,omitempty,omitzero"`

	// KeyRange Key range processed in this request
	KeyRange KeyRange `json:"key_range,omitempty,omitzero"`

	// KeysScanned Total number of keys scanned from Antfly during range query
	KeysScanned int `json:"keys_scanned,omitempty,omitzero"`

	// Message Additional information (e.g., "stopped at shard boundary", "dry run - no changes made")
	Message string `json:"message,omitempty,omitzero"`

	// NextCursor ID of last record in this batch (use for next request)
	NextCursor string `json:"next_cursor"`

	// Skipped Records skipped because content hash matched (unchanged)
	Skipped int `json:"skipped"`

	// Status Status of a linear merge page operation:
	// - "success": All records in batch processed successfully
	// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
	// - "error": Fatal error occurred, no records processed successfully
	Status LinearMergePageStatus `json:"status"`
	Took   time.Duration         `json:"took,omitempty,omitzero"`

	// Upserted Records inserted or updated (0 if dry_run=true)
	Upserted int `json:"upserted"`
}

// MatchAllQuery defines model for MatchAllQuery.
type MatchAllQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost                  `json:"boost,omitzero"`
	MatchAll map[string]interface{} `json:"match_all"`
}

// MatchNoneQuery defines model for MatchNoneQuery.
type MatchNoneQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost                  `json:"boost,omitzero"`
	MatchNone map[string]interface{} `json:"match_none"`
}

// MatchPhraseQuery defines model for MatchPhraseQuery.
type MatchPhraseQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness   Fuzziness `json:"fuzziness,omitempty,omitzero"`
	MatchPhrase string    `json:"match_phrase"`
}

// MatchQuery defines model for MatchQuery.
type MatchQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness          `json:"fuzziness,omitempty,omitzero"`
	Match        string             `json:"match"`
	Operator     MatchQueryOperator `json:"operator,omitempty,omitzero"`
	PrefixLength int32              `json:"prefix_length,omitempty,omitzero"`
}

// MatchQueryOperator defines model for MatchQuery.Operator.
type MatchQueryOperator string

// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
// failover: Use full_text_search if embedding generation fails
type MergeStrategy string

// MultiPhraseQuery defines model for MultiPhraseQuery.
type MultiPhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness  `json:"fuzziness,omitempty,omitzero"`
	Terms     [][]string `json:"terms"`
}

// NodeFilter Filter nodes during graph traversal using existing query primitives
type NodeFilter struct {
	// FilterPrefix Filter by key prefix
	FilterPrefix string `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query to filter nodes (same syntax as search filter_query)
	FilterQuery map[string]interface{} `json:"filter_query,omitempty,omitzero"`
}

// NumericRange defines model for NumericRange.
type NumericRange struct {
	From *float64 `json:"from,omitempty"`
	Name string   `json:"name"`
	To   *float64 `json:"to,omitempty"`
}

// NumericRangeQuery defines model for NumericRangeQuery.
type NumericRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost   `json:"boost,omitzero"`
	Field        string  `json:"field,omitempty,omitzero"`
	InclusiveMax bool    `json:"inclusive_max,omitzero"`
	InclusiveMin bool    `json:"inclusive_min,omitzero"`
	Max          float64 `json:"max,omitzero"`
	Min          float64 `json:"min,omitzero"`
}

// NumericRangeResult defines model for NumericRangeResult.
type NumericRangeResult struct {
	Count int      `json:"count"`
	From  *float64 `json:"from,omitempty"`
	Name  string   `json:"name"`
	To    *float64 `json:"to,omitempty"`
}

// OllamaEmbedderConfig Configuration for the Ollama embedding provider.
//
// Local embeddings for privacy and offline use. URL via `url` field or `OLLAMA_HOST` env var.
//
// **Example Models:** nomic-embed-text (768 dims), mxbai-embed-large (1024 dims), all-minilm (384 dims)
//
// **Docs:** https://ollama.com/search?c=embedding
type OllamaEmbedderConfig struct {
	// Model The name of the Ollama model to use (e.g., 'nomic-embed-text', 'mxbai-embed-large').
	Model string `json:"model"`

	// Url The URL of the Ollama API endpoint. Can also be set via OLLAMA_HOST environment variable.
	Url string `json:"url,omitempty,omitzero"`
}

// OllamaGeneratorConfig Configuration for the Ollama generative AI provider.
//
// Ollama provides local LLM inference for privacy and offline use.
//
// **Example Models:** llama3.3:70b, qwen2.5:72b, deepseek-r1:70b, mistral:7b, llava:34b
//
// **Docs:** https://ollama.com/library
type OllamaGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Ollama model to use (e.g., 'llama3.3:70b', 'qwen2.5:72b', 'deepseek-coder:33b').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OllamaRerankerConfig Configuration for the Ollama reranking provider.
type OllamaRerankerConfig struct {
	// Model The name of the Ollama model to use for reranking.
	Model string `json:"model"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIEmbedderConfig Configuration for the OpenAI embedding provider.
//
// API key via `api_key` field or `OPENAI_API_KEY` environment variable.
// Supports OpenAI-compatible APIs via `url` field.
//
// **Example Models:** text-embedding-3-small (default, 1536 dims), text-embedding-3-large (3072 dims)
//
// **Docs:** https://platform.openai.com/docs/guides/embeddings
type OpenAIEmbedderConfig struct {
	// ApiKey The OpenAI API key. Can also be set via OPENAI_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimensions Output dimension for the embedding (uses MRL for dimension reduction). Recommended: 256, 512, 1024, 1536, or 3072.
	Dimensions int `json:"dimensions,omitempty,omitzero"`

	// Model The name of the OpenAI model to use.
	Model string `json:"model"`

	// Url The URL of the OpenAI API endpoint. Defaults to OpenAI's API. Can be set via OPENAI_BASE_URL environment variable.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIGeneratorConfig Configuration for the OpenAI generative AI provider.
//
// **Example Models:** gpt-4.1 (default), gpt-4.1-mini, o3, o4-mini
//
// **Docs:** https://platform.openai.com/docs/models
type OpenAIGeneratorConfig struct {
	// ApiKey The OpenAI API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (-2.0 to 2.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the OpenAI model to use (e.g., 'gpt-4.1', 'gpt-4.1-mini', 'o4-mini').
	Model string `json:"model"`

	// PresencePenalty Penalty for token presence (-2.0 to 2.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the OpenAI API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// Path defines model for Path.
type Path struct {
	Edges  []PathEdge `json:"edges,omitempty,omitzero"`
	Length int        `json:"length,omitempty,omitzero"`

	// Nodes Ordered list of node keys (base64-encoded)
	Nodes       []string `json:"nodes,omitempty,omitzero"`
	TotalWeight float64  `json:"total_weight,omitempty,omitzero"`
}

// PathEdge defines model for PathEdge.
type PathEdge struct {
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`
	Source   string                 `json:"source,omitempty,omitzero"`
	Target   string                 `json:"target,omitempty,omitzero"`
	Type     string                 `json:"type,omitempty,omitzero"`
	Weight   float64                `json:"weight,omitempty,omitzero"`
}

// PathFindRequest defines model for PathFindRequest.
type PathFindRequest struct {
	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by specific edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`
	K         int      `json:"k,omitempty,omitzero"`
	MaxDepth  int      `json:"max_depth,omitempty,omitzero"`
	MaxWeight float64  `json:"max_weight,omitempty,omitzero"`
	MinWeight float64  `json:"min_weight,omitempty,omitzero"`

	// Source Source node key (base64-encoded)
	Source string `json:"source"`

	// Target Target node key (base64-encoded)
	Target string `json:"target"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindResult defines model for PathFindResult.
type PathFindResult struct {
	Paths        []Path  `json:"paths,omitempty,omitzero"`
	PathsFound   int     `json:"paths_found,omitempty,omitzero"`
	SearchTimeMs float64 `json:"search_time_ms,omitempty,omitzero"`
	Source       string  `json:"source,omitempty,omitzero"`
	Target       string  `json:"target,omitempty,omitzero"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindWeightMode Algorithm for path finding:
// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
// - max_weight: Path with maximum product of edge weights (strongest connection chain)
// - min_weight: Path with minimum sum of edge weights (lowest cost route)
type PathFindWeightMode string

// PathWeightMode Path weighting algorithm for pathfinding:
// - min_hops: Minimize number of edges
// - min_weight: Minimize sum of edge weights
// - max_weight: Maximize product of edge weights
type PathWeightMode string

// PatternEdgeStep Edge constraints in a pattern step
type PatternEdgeStep struct {
	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// MaxHops Maximum number of hops (>1 = variable-length path)
	MaxHops int `json:"max_hops,omitempty,omitzero"`

	// MaxWeight Maximum edge weight filter
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinHops Minimum number of hops (1 = direct edge)
	MinHops int `json:"min_hops,omitempty,omitzero"`

	// MinWeight Minimum edge weight filter
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// Types Edge types to traverse (empty = any)
	Types []string `json:"types,omitempty,omitzero"`
}

// PatternMatch A single match from a pattern query
type PatternMatch struct {
	// Bindings Map of alias to matched node
	Bindings map[string]GraphResultNode `json:"bindings,omitempty,omitzero"`

	// Path Edges traversed in this match
	Path []PathEdge `json:"path,omitempty,omitzero"`
}

// PatternStep A step in a graph pattern query
type PatternStep struct {
	// Alias Name for this node (reuse alias for cycle detection)
	Alias string `json:"alias,omitempty,omitzero"`

	// Edge Edge constraints in a pattern step
	Edge PatternEdgeStep `json:"edge,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`
}

// Permission defines model for Permission.
type Permission struct {
	// Resource Resource name (e.g., table name, target username, or '*' for global).
	Resource string `json:"resource"`

	// ResourceType Type of the resource, e.g., table, user, or global ('*').
	ResourceType ResourceType `json:"resource_type"`

	// Type Type of permission.
	Type PermissionType `json:"type"`
}

// PermissionType Type of permission.
type PermissionType string

// PhraseQuery defines model for PhraseQuery.
type PhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness `json:"fuzziness,omitempty,omitzero"`
	Terms     []string  `json:"terms"`
}

// PrefixQuery defines model for PrefixQuery.
type PrefixQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Prefix string `json:"prefix"`
}

// Pruner Configuration for pruning search results based on score quality.
// Helps filter out low-relevance results in RAG pipelines by detecting
// score gaps or deviations from top results.
type Pruner struct {
	// MaxScoreGapPercent Stop returning results when score drops more than this percentage
	// from the previous result. Detects "elbows" in score distribution.
	// For example, 30.0 stops when score drops 30% from previous result.
	MaxScoreGapPercent float64 `json:"max_score_gap_percent,omitempty,omitzero"`

	// MinAbsoluteScore Hard minimum score threshold. Results with scores below this value
	// are excluded regardless of other pruning settings.
	MinAbsoluteScore float64 `json:"min_absolute_score,omitempty,omitzero"`

	// MinScoreRatio Keep only results with score >= max_score * min_score_ratio.
	// For example, 0.5 keeps results scoring at least half of the top result.
	// Applied after fusion scoring.
	MinScoreRatio float64 `json:"min_score_ratio,omitempty,omitzero"`

	// RequireMultiIndex Only keep results that appear in multiple indexes (both full-text
	// and vector search). Useful for increasing precision by requiring
	// agreement between different retrieval methods.
	RequireMultiIndex bool `json:"require_multi_index,omitempty,omitzero"`

	// StdDevThreshold Keep results within N standard deviations below the mean score.
	// For example, 1.0 keeps results with score >= mean - 1*stddev.
	// Useful for statistical outlier detection in result sets.
	StdDevThreshold float64 `json:"std_dev_threshold,omitempty,omitzero"`
}

// Query defines model for Query.
type Query struct {
	union json.RawMessage
}

// QueryBuilderRequest defines model for QueryBuilderRequest.
type QueryBuilderRequest struct {
	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// Intent Natural language description of the search intent
	Intent string `json:"intent"`

	// SchemaFields List of searchable field names to consider. Overrides table schema if provided.
	SchemaFields []string `json:"schema_fields,omitempty,omitzero"`

	// Table Name of the table to build query for. If provided, uses table schema for field context.
	Table string `json:"table,omitempty,omitzero"`
}

// QueryBuilderResult defines model for QueryBuilderResult.
type QueryBuilderResult struct {
	// Confidence Model's confidence in the generated query (0.0-1.0)
	Confidence float64 `json:"confidence,omitempty,omitzero"`

	// Explanation Human-readable explanation of what the query does and why it was structured this way
	Explanation string `json:"explanation,omitempty,omitzero"`

	// Query Generated search query in simplified DSL format.
	// Can be used directly in QueryRequest.full_text_search or filter_query.
	Query map[string]interface{} `json:"query"`

	// Warnings Any issues, limitations, or assumptions made when generating the query
	Warnings []string `json:"warnings,omitempty,omitzero"`
}

// QueryHit A single query result hit
type QueryHit struct {
	// ID ID of the record.
	ID string `json:"_id"`

	// IndexScores Scores partitioned by index when using RRF search.
	IndexScores map[string]interface{} `json:"_index_scores,omitempty,omitzero"`

	// Score Relevance score of the hit.
	Score  float64                `json:"_score"`
	Source map[string]interface{} `json:"_source,omitempty,omitzero"`
}

// QueryHits A list of query hits.
type QueryHits struct {
	Hits []QueryHit `json:"hits"`

	// MaxScore Maximum score of the results.
	MaxScore float64 `json:"max_score,omitempty,omitzero"`

	// Total Total number of hits available.
	Total uint64 `json:"total,omitempty"`
}

// QueryRequest defines model for QueryRequest.
type QueryRequest struct {
	Analyses *Analyses `json:"analyses,omitempty"`

	// Count If true, returns only the total count of matching documents without retrieving the actual documents.
	// Useful for pagination and displaying result counts.
	Count bool `json:"count,omitempty,omitzero"`

	// DistanceOver Minimum distance threshold for semantic similarity search. Results with distance
	// less than this value are excluded.
	//
	// Useful for excluding near-exact duplicates or finding dissimilar documents.
	DistanceOver *float32 `json:"distance_over,omitempty"`

	// DistanceUnder Maximum distance threshold for semantic similarity search. Results with distance
	// greater than this value are excluded. Lower distances indicate higher similarity.
	//
	// Useful for filtering out low-confidence matches.
	DistanceUnder *float32 `json:"distance_under,omitempty"`

	// DocumentRenderer Optional Handlebars template string for rendering document content in RAG queries.
	// Template has access to document fields via `{{this.fields.fieldName}}`.
	//
	// **Default**: Uses TOON (Token-Oriented Object Notation) format for 30-60% token reduction:
	// ```handlebars
	// {{encodeToon this.fields}}
	// ```
	//
	// **Available Helpers**:
	// - `encodeToon` - Renders fields in compact TOON format with configurable options:
	//   - `lengthMarker` (bool): Add # prefix to array counts (default: true)
	//   - `indent` (int): Indentation spacing (default: 2)
	//   - `delimiter` (string): Field separator for tabular arrays
	// - `scrubHtml` - Removes HTML tags and extracts text
	// - `media` - Wraps data URIs for GenKit multimodal support
	// - `eq` - Equality comparison for conditionals
	//
	// **Examples**:
	// - Basic TOON: `{{encodeToon this.fields}}`
	// - Compact TOON: `{{encodeToon this.fields lengthMarker=false indent=0}}`
	// - Tabular data: `{{encodeToon this.fields delimiter="\t"}}`
	// - Custom template: `Title: {{this.fields.title}}\nBody: {{this.fields.body}}`
	// - Traditional format: `{{#each this.fields}}{{@key}}: {{this}}\n{{/each}}`
	//
	// TOON format produces compact, LLM-optimized output like:
	// ```
	// title: Introduction to Vector Search
	// author: Jane Doe
	// tags[#3]: ai,search,ml
	// ```
	//
	// **References**:
	// - TOON Specification: https://github.com/toon-format/toon
	// - Go Implementation: https://github.com/alpkeskin/gotoon
	DocumentRenderer string `json:"document_renderer,omitempty,omitzero"`

	// EmbeddingTemplate Optional Handlebars template for multimodal embedding of the semantic_search query.
	// The template has access to `this` which contains the semantic_search string value.
	//
	// Use this when you want to embed multimodal content (images, PDFs, etc.) instead of
	// just text. The template is rendered using dotprompt with access to remote content helpers.
	//
	// **Available Helpers**:
	// - `remoteMedia url=<url>` - Fetches and embeds remote images/media
	// - `remotePDF url=<url>` - Fetches and extracts content from PDFs
	// - `remoteText url=<url>` - Fetches and includes remote text content
	//
	// **Examples**:
	// - PDF search: `{{remotePDF url=this}}`
	// - Image search: `{{remoteMedia url=this}}`
	// - Mixed: `Search for: {{this}} {{#if this}}{{remoteMedia url=this}}{{/if}}`
	//
	// When not specified, the semantic_search string is embedded as plain text.
	EmbeddingTemplate string `json:"embedding_template,omitempty,omitzero"`

	// Embeddings Pre-computed embeddings to use for semantic searches instead of embedding the semantic_search string.
	// The keys are the index names, and values are the embedding vectors.
	//
	// Use when you've already generated embeddings on the client side to avoid redundant embedding calls.
	Embeddings map[string][]float32 `json:"embeddings,omitempty,omitzero"`

	// ExclusionQuery Bleve query applied as a NOT condition. Documents matching this query are excluded
	// from results. Applied before scoring.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Excluding drafts: `"status:draft"`
	// - Removing deprecated content: `"deprecated:true"`
	// - Filtering out archived items: `"status:archived"`
	ExclusionQuery json.RawMessage `json:"exclusion_query,omitempty,omitzero"`

	// ExpandStrategy Strategy for merging graph results with search results:
	// - union: Include nodes from both search and graph results
	// - intersection: Only include nodes appearing in both
	ExpandStrategy QueryRequestExpandStrategy `json:"expand_strategy,omitempty,omitzero"`

	// Facets Faceting configuration for aggregating results by field values.
	// Useful for building faceted navigation and filters.
	Facets map[string]FacetOption `json:"facets,omitempty,omitzero"`

	// Fields List of fields to include in the results. If not specified, all fields are returned.
	// Use to reduce response size and improve performance.
	Fields []string `json:"fields,omitempty,omitzero"`

	// FilterPrefix Filter results by key prefix. Only returns documents whose keys start with this string.
	// Applied before scoring to improve performance.
	//
	// Common use cases:
	// - Multi-tenant filtering: `"tenant:acme:"`
	// - User-specific data: `"user:123:"`
	// - Document type filtering: `"article:"`
	FilterPrefix []byte `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query applied as an AND condition. Documents must match both the main query
	// and this filter. Applied before scoring for better performance.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Status filtering: `"status:published"`
	// - Date ranges: `"created_at:>2023-01-01"`
	// - Category filtering: `"category:technology AND language:en"`
	FilterQuery json.RawMessage `json:"filter_query,omitempty,omitzero"`

	// FullTextSearch Bleve query for full-text search. Supports all Bleve query types.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Examples:
	// - Simple: `{"query": "computer"}`
	// - Field-specific: `{"query": "body:computer"}`
	// - Boolean: `{"query": "artificial AND intelligence"}`
	// - Range: `{"query": "year:>2020"}`
	// - Phrase: `{"query": "\"exact phrase\""}`
	FullTextSearch json.RawMessage `json:"full_text_search,omitempty,omitzero"`

	// GraphSearches Declarative graph queries to execute after full-text/vector searches.
	// Results can reference search results using node selectors like $full_text_results.
	GraphSearches map[string]GraphQuery `json:"graph_searches,omitempty,omitzero"`

	// Indexes List of vector index names to use for semantic search. Required when using semantic_search.
	// Multiple indexes can be specified, and their results will be merged using RRF.
	Indexes []string `json:"indexes,omitempty,omitzero"`

	// Limit Maximum number of results to return. For semantic_search, this is the topk parameter.
	// Default varies by query type (typically 10).
	Limit int `json:"limit,omitempty,omitzero"`

	// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
	// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
	// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
	// failover: Use full_text_search if embedding generation fails
	MergeStrategy MergeStrategy `json:"merge_strategy,omitempty,omitzero"`

	// Offset Number of results to skip for pagination. Only available for full_text_search queries.
	// Not supported for semantic_search due to vector index limitations.
	Offset int `json:"offset,omitempty,omitzero"`

	// OrderBy Sort order for results. Map of field names to boolean (true = descending, false = ascending).
	// Only applicable for full_text_search queries. Semantic searches are always sorted by similarity score.
	OrderBy map[string]bool `json:"order_by,omitempty,omitzero"`

	// Pruner Configuration for pruning search results based on score quality.
	// Helps filter out low-relevance results in RAG pipelines by detecting
	// score gaps or deviations from top results.
	Pruner Pruner `json:"pruner,omitempty,omitzero"`

	// Reranker A unified configuration for a reranking provider.
	Reranker *RerankerConfig `json:"reranker,omitempty"`

	// SemanticSearch Natural language query for vector similarity search. Results are ranked by semantic similarity
	// to the query and can be combined with full_text_search using Reciprocal Rank Fusion (RRF).
	//
	// The semantic_search string is automatically embedded using the configured embedding model
	// for the specified indexes. Use `embedding_template` for multimodal queries.
	SemanticSearch string `json:"semantic_search,omitempty,omitzero"`

	// Table Name of the table to query. Optional for global queries.
	Table string `json:"table,omitempty,omitzero"`
}

// QueryRequestExpandStrategy Strategy for merging graph results with search results:
// - union: Include nodes from both search and graph results
// - intersection: Only include nodes appearing in both
type QueryRequestExpandStrategy string

// QueryResponses Responses from multiple query operations.
type QueryResponses struct {
	Responses []QueryResult `json:"responses,omitempty,omitzero"`
}

// QueryResult Result of a query operation as an array of results and a count.
type QueryResult struct {
	// Analyses Analysis results like PCA and t-SNE per index embeddings.
	Analyses map[string]AnalysesResult `json:"analyses,omitempty,omitzero"`

	// Error Error message if the query failed.
	Error  string                 `json:"error,omitempty,omitzero"`
	Facets map[string]FacetResult `json:"facets,omitempty,omitzero"`

	// GraphResults Results from declarative graph queries.
	GraphResults map[string]GraphQueryResult `json:"graph_results,omitempty,omitzero"`

	// Hits A list of query hits.
	Hits QueryHits `json:"hits"`

	// Status HTTP status code of the query operation.
	Status int32 `json:"status"`

	// Table Which table this result came from
	Table string `json:"table,omitempty,omitzero"`

	// Took Duration of the query in milliseconds.
	Took time.Duration `json:"took"`
}

// QueryStrategy Strategy for query transformation and retrieval:
// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
type QueryStrategy string

// QueryStringQuery defines model for QueryStringQuery.
type QueryStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Query string `json:"query"`
}

// RAGRequest defines model for RAGRequest.
type RAGRequest struct {
	// Chain Chain of generators with retry/fallback semantics. Mutually exclusive with 'generator'.
	// Each link can specify retry configuration and a condition for trying the next generator.
	// Either 'generator' or 'chain' must be provided.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Eval Configuration for inline evaluation of query results.
	// Add to RAGRequest, QueryRequest, or AnswerAgentRequest.
	Eval EvalConfig `json:"eval,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// Prompt Optional custom user prompt template for the LLM. If not provided, a default prompt is used.
	// The prompt can reference the following variables:
	// - {{documents}}: Array of retrieved documents with id and fields
	// - {{semantic_search}}: The user's semantic search query (if provided)
	// You can use Handlebars template syntax to customize the prompt, including loops and conditionals.
	// To generate a comma-separated list of document IDs, use: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	Prompt string `json:"prompt,omitempty,omitzero"`

	// Queries Array of retrieval queries to execute. Each query must specify a table and can specify its own limit and document_renderer.
	// Results from all queries are concatenated together (respecting each query's limit).
	// For single table: [{"table": "papers", "semantic_search": "...", "limit": 10}]
	// For broadcast: [{"table": "images", "limit": 5, ...}, {"table": "products", "limit": 5, ...}]
	// For mixed: [{"table": "papers", "semantic_search": "...", "limit": 10}, {"table": "books", "full_text_search": {...}, "limit": 5}]
	Queries []QueryRequest `json:"queries"`

	// SystemPrompt Optional system prompt to guide the summarization
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// RAGResult RAG result with individual query results and summary
type RAGResult struct {
	// EvalResult Complete evaluation result
	EvalResult EvalResult `json:"eval_result,omitempty,omitzero"`

	// QueryResults Results from each query. Check each result's status and error fields for failures.
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`

	// SummaryResult Result of a summarization operation. The summary is formatted as markdown with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
	SummaryResult SummarizeResult `json:"summary_result,omitempty,omitzero"`
}

// RegexpQuery defines model for RegexpQuery.
type RegexpQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Regexp string `json:"regexp"`
}

// RerankerConfig defines model for RerankerConfig.
type RerankerConfig struct {
	// Field Field name to extract from documents for reranking.
	Field string `json:"field,omitempty,omitzero"`

	// Provider The reranking provider to use.
	Provider RerankerProvider `json:"provider"`

	// Template Handlebars template to render document text for reranking.
	Template string `json:"template,omitempty,omitzero"`
	union    json.RawMessage
}

// RerankerProvider The reranking provider to use.
type RerankerProvider string

// ResourceType Type of the resource, e.g., table, user, or global ('*').
type ResourceType string

// RestoreRequest defines model for RestoreRequest.
type RestoreRequest = BackupRequest

// RetryConfig Retry configuration for generator calls
type RetryConfig struct {
	// BackoffMultiplier Multiplier for exponential backoff
	BackoffMultiplier float32 `json:"backoff_multiplier,omitempty,omitzero"`

	// InitialBackoffMs Initial backoff delay in milliseconds
	InitialBackoffMs int `json:"initial_backoff_ms,omitempty,omitzero"`

	// MaxAttempts Maximum number of retry attempts
	MaxAttempts int `json:"max_attempts,omitempty,omitzero"`

	// MaxBackoffMs Maximum backoff delay in milliseconds
	MaxBackoffMs int `json:"max_backoff_ms,omitempty,omitzero"`
}

// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
type RouteType string

// ScanKeysRequest Request to scan keys in a table within a key range.
// If no range is specified, scans all keys in the table.
type ScanKeysRequest struct {
	// ExclusiveTo If true, exclude keys matching 'to' from the results.
	// Default: false (inclusive upper bound).
	ExclusiveTo bool `json:"exclusive_to,omitempty,omitzero"`

	// Fields List of fields to include in each result. If not specified,
	// only returns the key. Supports:
	// - Simple fields: "title", "author"
	// - Nested paths: "user.address.city"
	// - Wildcards: "_chunks.*"
	// - Exclusions: "-_chunks.*._embedding"
	// - Special fields: "_embeddings", "_summaries", "_chunks"
	Fields []string `json:"fields,omitempty,omitzero"`

	// FilterQuery Bleve query to filter documents. Only documents matching this query
	// are included in results. Uses the sear library for efficient per-document
	// matching without requiring a full index.
	//
	// Examples:
	// - Status filtering: `{"query": "status:published"}`
	// - Date ranges: `{"query": "created_at:>2023-01-01"}`
	// - Field matching: `{"query": "category:technology"}`
	FilterQuery json.RawMessage `json:"filter_query,omitempty,omitzero"`

	// From Start of the key range to scan (exclusive by default).
	// Can be a full key or a prefix. If not specified, starts from
	// the beginning of the table.
	From string `json:"from,omitempty,omitzero"`

	// InclusiveFrom If true, include keys matching 'from' in the results.
	// Default: false (exclusive lower bound for pagination).
	InclusiveFrom bool `json:"inclusive_from,omitempty,omitzero"`

	// Limit Maximum number of results to return. If not specified, returns all
	// matching keys in the range. Useful for pagination or sampling.
	Limit int `json:"limit,omitempty,omitzero"`

	// To End of the key range to scan (inclusive by default).
	// Can be a full key or a prefix. If not specified, scans to
	// the end of the table.
	To string `json:"to,omitempty,omitzero"`
}

// SemanticQueryMode Mode for semantic query generation:
// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
type SemanticQueryMode string

// SerperSearchConfig defines model for SerperSearchConfig.
type SerperSearchConfig struct {
	// ApiKey Serper API key (or set SERPER_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// SearchType Type of search to perform
	SearchType SerperSearchConfigSearchType `json:"search_type,omitempty,omitzero"`

	// TimePeriod Time period filter: d=day, w=week, m=month, y=year
	TimePeriod SerperSearchConfigTimePeriod `json:"time_period,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// SerperSearchConfigSearchType Type of search to perform
type SerperSearchConfigSearchType string

// SerperSearchConfigTimePeriod Time period filter: d=day, w=week, m=month, y=year
type SerperSearchConfigTimePeriod string

// ShardConfig defines model for ShardConfig.
type ShardConfig struct {
	ByteRange ByteRange `json:"byte_range"`
}

// StorageStatus defines model for StorageStatus.
type StorageStatus struct {
	// DiskUsage Disk usage in bytes.
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Empty Whether the table has received data.
	Empty bool `json:"empty,omitempty,omitzero"`
}

// SuccessMessage defines model for SuccessMessage.
type SuccessMessage struct {
	Message string `json:"message,omitempty,omitzero"`
}

// SummarizeResult Result of a summarization operation. The summary is formatted as markdown with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
type SummarizeResult struct {
	// Summary The generated summary text in markdown format with inline resource references like [resource_id res1] or [resource_id res1, res2]
	Summary string `json:"summary"`
}

// SyncLevel Synchronization level for batch operations:
// - "propose": Wait for Raft proposal acceptance (fastest, default)
// - "write": Wait for Pebble KV write
// - "full_text": Wait for full-text index WAL write
// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
type SyncLevel string

// Table defines model for Table.
type Table struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema            `json:"schema,omitempty,omitzero"`
	Shards map[string]ShardConfig `json:"shards"`
}

// TableSchema Schema definition for a table with multiple document types
type TableSchema struct {
	// DefaultType Default type to use from the document_types.
	DefaultType string `json:"default_type,omitempty,omitzero"`

	// DocumentSchemas A map of type names to their document json schemas.
	DocumentSchemas map[string]DocumentSchema `json:"document_schemas,omitempty,omitzero"`

	// EnforceTypes Whether to enforce that documents must match one of the provided document types.
	// If false, documents not matching any type will be accepted but not indexed.
	EnforceTypes bool `json:"enforce_types,omitempty,omitzero"`

	// TtlDuration The duration after which documents should expire, based on the ttl_field timestamp (optional).
	// Uses Go duration format (e.g., '24h', '7d', '168h').
	TtlDuration string `json:"ttl_duration,omitempty,omitzero"`

	// TtlField The field containing the timestamp for TTL expiration (optional).
	// Defaults to "_timestamp" if ttl_duration is specified but ttl_field is not.
	TtlField string `json:"ttl_field,omitempty,omitzero"`

	// Version Version of the schema. Used for migrations.
	Version uint32 `json:"version,omitempty,omitzero"`
}

// TableStatus defines model for TableStatus.
type TableStatus struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema        TableSchema            `json:"schema,omitempty,omitzero"`
	Shards        map[string]ShardConfig `json:"shards"`
	StorageStatus StorageStatus          `json:"storage_status"`
}

// TavilySearchConfig defines model for TavilySearchConfig.
type TavilySearchConfig struct {
	// ApiKey Tavily API key (or set TAVILY_API_KEY env var)
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// ExcludeDomains Exclude results from these domains
	ExcludeDomains []string `json:"exclude_domains,omitempty,omitzero"`

	// IncludeAnswer Include AI-generated answer summary
	IncludeAnswer bool `json:"include_answer,omitempty,omitzero"`

	// IncludeDomains Only include results from these domains
	IncludeDomains []string `json:"include_domains,omitempty,omitzero"`

	// IncludeRawContent Include raw HTML content of pages
	IncludeRawContent bool `json:"include_raw_content,omitempty,omitzero"`

	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// SearchDepth Search depth:
	// - basic: Fast search with standard results
	// - advanced: Deeper search with more comprehensive results
	SearchDepth TavilySearchConfigSearchDepth `json:"search_depth,omitempty,omitzero"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// TavilySearchConfigSearchDepth Search depth:
// - basic: Fast search with standard results
// - advanced: Deeper search with more comprehensive results
type TavilySearchConfigSearchDepth string

// TermFacetResult defines model for TermFacetResult.
type TermFacetResult struct {
	Count int    `json:"count"`
	Term  string `json:"term"`
}

// TermQuery defines model for TermQuery.
type TermQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
	Term  string `json:"term"`
}

// TermRangeQuery defines model for TermRangeQuery.
type TermRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost  `json:"boost,omitzero"`
	Field        string `json:"field,omitempty,omitzero"`
	InclusiveMax bool   `json:"inclusive_max,omitzero"`
	InclusiveMin bool   `json:"inclusive_min,omitzero"`
	Max          string `json:"max,omitzero"`
	Min          string `json:"min,omitzero"`
}

// TermiteChunkerConfig Configuration for the Termite chunking provider.
//
// Termite is a centralized HTTP service that provides chunking with multi-tier caching.
// The model name maps to ONNX model directory names (similar to how Ollama works).
//
// **Chunking Models:**
// - fixed: Simple fixed-size chunking by token count (built-in, no ONNX required)
// - Any other name will attempt to load from models/chunkers/{name}/ directory
//
// **Caching:**
// - L1: Memory cache with 2-minute TTL
// - L2: Persistent Pebble database
// - Singleflight deduplication for concurrent identical requests
type TermiteChunkerConfig struct {
	// ApiUrl The URL of the Termite API endpoint (e.g., 'http://localhost:8080'). Can also be set via ANTFLY_TERMITE_URL environment variable.
	ApiUrl string `json:"api_url,omitempty,omitzero"`

	// FullText Configuration for full-text indexing of chunks in Bleve.
	// When present (even if empty), chunks will be stored with :cft: suffix and indexed in Bleve's _chunks field.
	// When absent, chunks use :c: suffix and are only used for vector embeddings.
	// This object is reserved for future options like boosting, field mapping, etc.
	FullText map[string]interface{} `json:"full_text,omitempty,omitzero"`

	// MaxChunks Maximum number of chunks to generate per document. Prevents excessive chunking of very large documents.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// Model The chunking model to use. Either 'fixed' for simple token-based chunking, or a model name from models/chunkers/{name}/.
	Model string `json:"model"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs). Only used with fixed strategy.
	Separator string `json:"separator,omitempty,omitzero"`

	// TargetTokens Target number of tokens per chunk. Chunker will aim for chunks around this size.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`

	// Threshold Minimum confidence threshold for separator detection. Only used with ONNX-based models.
	Threshold float32 `json:"threshold,omitempty,omitzero"`
}

// TermiteRerankerConfig Configuration for the Termite reranking provider.
type TermiteRerankerConfig struct {
	// Model The name of the reranking model (e.g., cross-encoder model name).
	Model string `json:"model"`

	// Url The URL of the Termite API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// Transform In-place document transformation using MongoDB-style operators. Transforms are applied atomically
// at the storage layer, eliminating read-modify-write races.
//
// **Important:** Transform results are NOT validated against the table schema. This improves performance
// but means it's possible to create invalid documents. Use with care and ensure your operations maintain
// schema compliance.
type Transform struct {
	// Key Document key (must be a string, not an object like inserts)
	Key string `json:"key"`

	// Operations List of operations to apply in sequence
	Operations []TransformOp `json:"operations"`

	// Upsert If true, create document if it doesn't exist (like MongoDB upsert)
	Upsert bool `json:"upsert,omitempty,omitzero"`
}

// TransformOp defines model for TransformOp.
type TransformOp struct {
	// Op MongoDB-style update operator
	Op TransformOpType `json:"op"`

	// Path JSONPath to field (e.g., "$.user.name", "$.tags", or "user.name")
	Path string `json:"path"`

	// Value Value for operation (not required for $unset, $currentDate). Type depends on operator (number for $inc/$mul, any for $set, etc.)
	Value interface{} `json:"value,omitempty,omitzero"`
}

// TransformOpType MongoDB-style update operator
type TransformOpType string

// TraversalResult A single result from graph traversal
type TraversalResult struct {
	// Depth Distance from start node (0 = start node)
	Depth int `json:"depth"`

	// Document Document data (if loaded)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Key Base64-encoded document key
	Key []byte `json:"key"`

	// Path Sequence of keys from start to this node (if include_paths=true)
	Path [][]byte `json:"path,omitempty,omitzero"`

	// PathEdges Sequence of edges from start to this node (if include_paths=true)
	PathEdges []Edge `json:"path_edges,omitempty,omitzero"`

	// TotalWeight Product of edge weights along the path
	TotalWeight float64 `json:"total_weight,omitempty,omitzero"`
}

// TraversalRules Rules for graph traversal
type TraversalRules struct {
	// DeduplicateNodes Visit each node only once
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter edges by type (empty = all types)
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information in results
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth (0 = unlimited)
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum results to return (0 = unlimited)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight filter
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight filter
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`
}

// TraverseResponse defines model for TraverseResponse.
type TraverseResponse struct {
	// Count Total number of results
	Count   int               `json:"count,omitempty,omitzero"`
	Results []TraversalResult `json:"results,omitempty,omitzero"`
}

// UpdatePasswordRequest defines model for UpdatePasswordRequest.
type UpdatePasswordRequest struct {
	NewPassword string `json:"new_password"`
}

// User defines model for User.
type User struct {
	// PasswordHash Base64 encoded password hash. Exposing this is a security risk.
	PasswordHash []byte `json:"password_hash"`
	Username     string `json:"username"`
}

// VertexEmbedderConfig Configuration for Google Cloud Vertex AI embedding models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication. Requires IAM role `roles/aiplatform.user`.
//
// **Example Models:** gemini-embedding-001 (default, 3072 dims), multimodalembedding (images/audio/video)
//
// **Docs:** https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings
type VertexEmbedderConfig struct {
	// CredentialsPath Path to service account JSON key file. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Dimension The dimension of the embedding vector (768, 1536, or 3072 for gemini-embedding-001; 128-1408 for multimodalembedding).
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the Vertex AI embedding model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`
}

// VertexGeneratorConfig Configuration for Google Cloud Vertex AI generative models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication. In GCP environments
// (Cloud Run, GKE, Compute Engine) this is automatic. For local dev, run
// `gcloud auth application-default login`. Requires IAM role `roles/aiplatform.user`.
//
// **Example Models:** gemini-2.5-flash (default), gemini-2.5-pro, gemini-3.0-pro
//
// **Docs:** https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models
type VertexGeneratorConfig struct {
	// CredentialsPath Path to service account JSON key file. Sets GOOGLE_APPLICATION_CREDENTIALS environment variable. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Vertex AI model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// VertexRerankerConfig Configuration for the Google Vertex AI Ranking API.
//
// Uses Application Default Credentials (ADC) or explicit credentials path.
//
// **Prerequisites:**
// - Enable Discovery Engine API: `gcloud services enable discoveryengine.googleapis.com`
// - Grant IAM role: `roles/discoveryengine.admin` (includes `discoveryengine.rankingConfigs.rank` permission)
//
// **Models:** semantic-ranker-default@latest (default), semantic-ranker-fast-004
//
// **Docs:** https://cloud.google.com/generative-ai-app-builder/docs/ranking
//
// **IAM:** https://cloud.google.com/generative-ai-app-builder/docs/access-control
type VertexRerankerConfig struct {
	// CredentialsPath Path to service account JSON file. Falls back to GOOGLE_APPLICATION_CREDENTIALS environment variable.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Model The ranking model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Falls back to GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// TopN Maximum number of records to return. If not specified, returns all documents with scores.
	TopN int `json:"top_n,omitempty,omitzero"`
}

// WebSearchConfig A unified configuration for web search providers.
//
// Each provider has specific configuration requirements. Use the appropriate
// provider-specific config or set common options at the top level.
//
// **Environment Variables (fallbacks):**
// - GOOGLE_CSE_API_KEY, GOOGLE_CSE_ID
// - BING_SEARCH_API_KEY
// - SERPER_API_KEY
// - TAVILY_API_KEY
// - BRAVE_API_KEY
type WebSearchConfig struct {
	// Language Preferred language for results (e.g., 'en', 'es', 'fr')
	Language string `json:"language,omitempty,omitzero"`

	// MaxResults Maximum number of search results to return
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// Provider The web search provider to use.
	//
	// - **google**: Google Custom Search API (requires CSE setup)
	// - **bing**: Microsoft Bing Web Search API
	// - **serper**: Serper.dev Google Search API (simpler setup)
	// - **tavily**: Tavily AI Search API (optimized for RAG)
	// - **brave**: Brave Search API
	// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
	Provider WebSearchProvider `json:"provider"`

	// Region Preferred region for results (e.g., 'us', 'uk', 'de')
	Region string `json:"region,omitempty,omitzero"`

	// SafeSearch Enable safe search filtering
	SafeSearch *bool `json:"safe_search,omitempty"`

	// TimeoutMs Request timeout in milliseconds
	TimeoutMs int `json:"timeout_ms,omitempty,omitzero"`
}

// WebSearchProvider The web search provider to use.
//
// - **google**: Google Custom Search API (requires CSE setup)
// - **bing**: Microsoft Bing Web Search API
// - **serper**: Serper.dev Google Search API (simpler setup)
// - **tavily**: Tavily AI Search API (optimized for RAG)
// - **brave**: Brave Search API
// - **duckduckgo**: DuckDuckGo Instant Answer API (limited, no API key)
type WebSearchProvider string

// WildcardQuery defines model for WildcardQuery.
type WildcardQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Field    string `json:"field,omitempty,omitzero"`
	Wildcard string `json:"wildcard"`
}

// SchemasChatAgentResult Result from the chat agent. Contains the assistant's response,
// any pending clarifications, applied filters, and conversation state.
type SchemasChatAgentResult struct {
	// Answer Final answer text (if available)
	Answer string `json:"answer,omitempty,omitzero"`

	// AnswerConfidence Confidence in the answer
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// AppliedFilters Filters that have been applied in this conversation
	AppliedFilters []FilterSpec `json:"applied_filters,omitempty,omitzero"`

	// Messages Updated conversation history including the assistant's response
	Messages []ChatMessage `json:"messages"`

	// PendingClarification A request for clarification from the user
	PendingClarification ClarificationRequest `json:"pending_clarification,omitempty,omitzero"`

	// QueryResults Search results from executed queries
	QueryResults []map[string]interface{} `json:"query_results,omitempty,omitzero"`

	// ToolCallsMade Number of tool calls made in this turn
	ToolCallsMade int `json:"tool_calls_made,omitempty,omitzero"`
}

// UserNamePathParameter defines model for UserNamePathParameter.
type UserNamePathParameter = string

// BadRequest defines model for BadRequest.
type BadRequest = Error

// InternalServerError defines model for InternalServerError.
type InternalServerError = Error

// NotFound defines model for NotFound.
type NotFound = Error

// ListTablesParams defines parameters for ListTables.
type ListTablesParams struct {
	// Prefix Filter tables by name prefix (e.g., "prod_")
	Prefix string `form:"prefix,omitempty" json:"prefix,omitempty,omitzero"`

	// Pattern Filter tables by regex pattern (e.g., "^prod_.*_v[0-9]+$")
	Pattern string `form:"pattern,omitempty" json:"pattern,omitempty,omitzero"`
}

// LookupKeyParams defines parameters for LookupKey.
type LookupKeyParams struct {
	// Fields Comma-separated list of fields to include in the response.
	// If not specified, returns the full document. Supports:
	// - Simple fields: "title,author"
	// - Nested paths: "user.address.city"
	// - Wildcards: "_chunks.*"
	// - Exclusions: "-_chunks.*._embedding"
	// - Special fields: "_embeddings,_summaries,_chunks"
	Fields string `form:"fields,omitempty" json:"fields,omitempty,omitzero"`
}

// RemovePermissionFromUserParams defines parameters for RemovePermissionFromUser.
type RemovePermissionFromUserParams struct {
	// Resource The name of the resource for the permission to be removed.
	Resource string `form:"resource" json:"resource"`

	// ResourceType The type of the resource for the permission to be removed.
	ResourceType ResourceType `form:"resourceType" json:"resourceType"`
}

// AnswerAgentJSONRequestBody defines body for AnswerAgent for application/json ContentType.
type AnswerAgentJSONRequestBody = AnswerAgentRequest

// ChatAgentJSONRequestBody defines body for ChatAgent for application/json ContentType.
type ChatAgentJSONRequestBody = ChatAgentRequest

// QueryBuilderAgentJSONRequestBody defines body for QueryBuilderAgent for application/json ContentType.
type QueryBuilderAgentJSONRequestBody = QueryBuilderRequest

// EvaluateJSONRequestBody defines body for Evaluate for application/json ContentType.
type EvaluateJSONRequestBody = EvalRequest

// GlobalQueryJSONRequestBody defines body for GlobalQuery for application/json ContentType.
type GlobalQueryJSONRequestBody = QueryRequest

// RagQueryJSONRequestBody defines body for RagQuery for application/json ContentType.
type RagQueryJSONRequestBody = RAGRequest

// CreateTableJSONRequestBody defines body for CreateTable for application/json ContentType.
type CreateTableJSONRequestBody = CreateTableRequest

// BackupTableJSONRequestBody defines body for BackupTable for application/json ContentType.
type BackupTableJSONRequestBody = BackupRequest

// BatchJSONRequestBody defines body for Batch for application/json ContentType.
type BatchJSONRequestBody = BatchRequest

// CreateIndexJSONRequestBody defines body for CreateIndex for application/json ContentType.
type CreateIndexJSONRequestBody = IndexConfig

// ScanKeysJSONRequestBody defines body for ScanKeys for application/json ContentType.
type ScanKeysJSONRequestBody = ScanKeysRequest

// LinearMergeJSONRequestBody defines body for LinearMerge for application/json ContentType.
type LinearMergeJSONRequestBody = LinearMergeRequest

// QueryTableJSONRequestBody defines body for QueryTable for application/json ContentType.
type QueryTableJSONRequestBody = QueryRequest

// TableRagQueryJSONRequestBody defines body for TableRagQuery for application/json ContentType.
type TableRagQueryJSONRequestBody = RAGRequest

// RestoreTableJSONRequestBody defines body for RestoreTable for application/json ContentType.
type RestoreTableJSONRequestBody = RestoreRequest

// UpdateSchemaJSONRequestBody defines body for UpdateSchema for application/json ContentType.
type UpdateSchemaJSONRequestBody = TableSchema

// CreateUserJSONRequestBody defines body for CreateUser for application/json ContentType.
type CreateUserJSONRequestBody = CreateUserRequest

// UpdateUserPasswordJSONRequestBody defines body for UpdateUserPassword for application/json ContentType.
type UpdateUserPasswordJSONRequestBody = UpdatePasswordRequest

// AddPermissionToUserJSONRequestBody defines body for AddPermissionToUser for application/json ContentType.
type AddPermissionToUserJSONRequestBody = Permission

// Getter for additional properties for ClusterStatus. Returns the specified
// element and whether it was found
func (a ClusterStatus) Get(fieldName string) (value interface{}, found bool) {
	if a.AdditionalProperties != nil {
		value, found = a.AdditionalProperties[fieldName]
	}
	return
}

// Setter for additional properties for ClusterStatus
func (a *ClusterStatus) Set(fieldName string, value interface{}) {
	if a.AdditionalProperties == nil {
		a.AdditionalProperties = make(map[string]interface{})
	}
	a.AdditionalProperties[fieldName] = value
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a *ClusterStatus) UnmarshalJSON(b []byte) error {
	object := make(map[string]json.RawMessage)
	err := json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["auth_enabled"]; found {
		err = json.Unmarshal(raw, &a.AuthEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'auth_enabled': %w", err)
		}
		delete(object, "auth_enabled")
	}

	if raw, found := object["health"]; found {
		err = json.Unmarshal(raw, &a.Health)
		if err != nil {
			return fmt.Errorf("error reading 'health': %w", err)
		}
		delete(object, "health")
	}

	if raw, found := object["message"]; found {
		err = json.Unmarshal(raw, &a.Message)
		if err != nil {
			return fmt.Errorf("error reading 'message': %w", err)
		}
		delete(object, "message")
	}

	if len(object) != 0 {
		a.AdditionalProperties = make(map[string]interface{})
		for fieldName, fieldBuf := range object {
			var fieldVal interface{}
			err := json.Unmarshal(fieldBuf, &fieldVal)
			if err != nil {
				return fmt.Errorf("error unmarshaling field %s: %w", fieldName, err)
			}
			a.AdditionalProperties[fieldName] = fieldVal
		}
	}
	return nil
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a ClusterStatus) MarshalJSON() ([]byte, error) {
	var err error
	object := make(map[string]json.RawMessage)

	object["auth_enabled"], err = json.Marshal(a.AuthEnabled)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'auth_enabled': %w", err)
	}

	object["health"], err = json.Marshal(a.Health)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'health': %w", err)
	}

	object["message"], err = json.Marshal(a.Message)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'message': %w", err)
	}

	for fieldName, field := range a.AdditionalProperties {
		object[fieldName], err = json.Marshal(field)
		if err != nil {
			return nil, fmt.Errorf("error marshaling '%s': %w", fieldName, err)
		}
	}
	return json.Marshal(object)
}

// AsTermiteChunkerConfig returns the union data inside the ChunkerConfig as a TermiteChunkerConfig
func (t ChunkerConfig) AsTermiteChunkerConfig() (TermiteChunkerConfig, error) {
	var body TermiteChunkerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteChunkerConfig overwrites any union data inside the ChunkerConfig as the provided TermiteChunkerConfig
func (t *ChunkerConfig) FromTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteChunkerConfig performs a merge with any union data inside the ChunkerConfig, using the provided TermiteChunkerConfig
func (t *ChunkerConfig) MergeTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAntflyChunkerConfig returns the union data inside the ChunkerConfig as a AntflyChunkerConfig
func (t ChunkerConfig) AsAntflyChunkerConfig() (AntflyChunkerConfig, error) {
	var body AntflyChunkerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAntflyChunkerConfig overwrites any union data inside the ChunkerConfig as the provided AntflyChunkerConfig
func (t *ChunkerConfig) FromAntflyChunkerConfig(v AntflyChunkerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAntflyChunkerConfig performs a merge with any union data inside the ChunkerConfig, using the provided AntflyChunkerConfig
func (t *ChunkerConfig) MergeAntflyChunkerConfig(v AntflyChunkerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t ChunkerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *ChunkerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsGoogleEmbedderConfig returns the union data inside the EmbedderConfig as a GoogleEmbedderConfig
func (t EmbedderConfig) AsGoogleEmbedderConfig() (GoogleEmbedderConfig, error) {
	var body GoogleEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided GoogleEmbedderConfig
func (t *EmbedderConfig) FromGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided GoogleEmbedderConfig
func (t *EmbedderConfig) MergeGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexEmbedderConfig returns the union data inside the EmbedderConfig as a VertexEmbedderConfig
func (t EmbedderConfig) AsVertexEmbedderConfig() (VertexEmbedderConfig, error) {
	var body VertexEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided VertexEmbedderConfig
func (t *EmbedderConfig) FromVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided VertexEmbedderConfig
func (t *EmbedderConfig) MergeVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaEmbedderConfig returns the union data inside the EmbedderConfig as a OllamaEmbedderConfig
func (t EmbedderConfig) AsOllamaEmbedderConfig() (OllamaEmbedderConfig, error) {
	var body OllamaEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OllamaEmbedderConfig
func (t *EmbedderConfig) FromOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OllamaEmbedderConfig
func (t *EmbedderConfig) MergeOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIEmbedderConfig returns the union data inside the EmbedderConfig as a OpenAIEmbedderConfig
func (t EmbedderConfig) AsOpenAIEmbedderConfig() (OpenAIEmbedderConfig, error) {
	var body OpenAIEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) FromOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) MergeOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockEmbedderConfig returns the union data inside the EmbedderConfig as a BedrockEmbedderConfig
func (t EmbedderConfig) AsBedrockEmbedderConfig() (BedrockEmbedderConfig, error) {
	var body BedrockEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided BedrockEmbedderConfig
func (t *EmbedderConfig) FromBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided BedrockEmbedderConfig
func (t *EmbedderConfig) MergeBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereEmbedderConfig returns the union data inside the EmbedderConfig as a CohereEmbedderConfig
func (t EmbedderConfig) AsCohereEmbedderConfig() (CohereEmbedderConfig, error) {
	var body CohereEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided CohereEmbedderConfig
func (t *EmbedderConfig) FromCohereEmbedderConfig(v CohereEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided CohereEmbedderConfig
func (t *EmbedderConfig) MergeCohereEmbedderConfig(v CohereEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t EmbedderConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *EmbedderConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsFuzziness0 returns the union data inside the Fuzziness as a Fuzziness0
func (t Fuzziness) AsFuzziness0() (Fuzziness0, error) {
	var body Fuzziness0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness0 overwrites any union data inside the Fuzziness as the provided Fuzziness0
func (t *Fuzziness) FromFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness0 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness0
func (t *Fuzziness) MergeFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzziness1 returns the union data inside the Fuzziness as a Fuzziness1
func (t Fuzziness) AsFuzziness1() (Fuzziness1, error) {
	var body Fuzziness1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness1 overwrites any union data inside the Fuzziness as the provided Fuzziness1
func (t *Fuzziness) FromFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness1 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness1
func (t *Fuzziness) MergeFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Fuzziness) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Fuzziness) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsGoogleGeneratorConfig returns the union data inside the GeneratorConfig as a GoogleGeneratorConfig
func (t GeneratorConfig) AsGoogleGeneratorConfig() (GoogleGeneratorConfig, error) {
	var body GoogleGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided GoogleGeneratorConfig
func (t *GeneratorConfig) FromGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided GoogleGeneratorConfig
func (t *GeneratorConfig) MergeGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexGeneratorConfig returns the union data inside the GeneratorConfig as a VertexGeneratorConfig
func (t GeneratorConfig) AsVertexGeneratorConfig() (VertexGeneratorConfig, error) {
	var body VertexGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided VertexGeneratorConfig
func (t *GeneratorConfig) FromVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided VertexGeneratorConfig
func (t *GeneratorConfig) MergeVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaGeneratorConfig returns the union data inside the GeneratorConfig as a OllamaGeneratorConfig
func (t GeneratorConfig) AsOllamaGeneratorConfig() (OllamaGeneratorConfig, error) {
	var body OllamaGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OllamaGeneratorConfig
func (t *GeneratorConfig) FromOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OllamaGeneratorConfig
func (t *GeneratorConfig) MergeOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIGeneratorConfig returns the union data inside the GeneratorConfig as a OpenAIGeneratorConfig
func (t GeneratorConfig) AsOpenAIGeneratorConfig() (OpenAIGeneratorConfig, error) {
	var body OpenAIGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) FromOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) MergeOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockGeneratorConfig returns the union data inside the GeneratorConfig as a BedrockGeneratorConfig
func (t GeneratorConfig) AsBedrockGeneratorConfig() (BedrockGeneratorConfig, error) {
	var body BedrockGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided BedrockGeneratorConfig
func (t *GeneratorConfig) FromBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided BedrockGeneratorConfig
func (t *GeneratorConfig) MergeBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAnthropicGeneratorConfig returns the union data inside the GeneratorConfig as a AnthropicGeneratorConfig
func (t GeneratorConfig) AsAnthropicGeneratorConfig() (AnthropicGeneratorConfig, error) {
	var body AnthropicGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAnthropicGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) FromAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAnthropicGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) MergeAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereGeneratorConfig returns the union data inside the GeneratorConfig as a CohereGeneratorConfig
func (t GeneratorConfig) AsCohereGeneratorConfig() (CohereGeneratorConfig, error) {
	var body CohereGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided CohereGeneratorConfig
func (t *GeneratorConfig) FromCohereGeneratorConfig(v CohereGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided CohereGeneratorConfig
func (t *GeneratorConfig) MergeCohereGeneratorConfig(v CohereGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t GeneratorConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *GeneratorConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Config returns the union data inside the IndexConfig as a BleveIndexV2Config
func (t IndexConfig) AsBleveIndexV2Config() (BleveIndexV2Config, error) {
	var body BleveIndexV2Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Config overwrites any union data inside the IndexConfig as the provided BleveIndexV2Config
func (t *IndexConfig) FromBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Config performs a merge with any union data inside the IndexConfig, using the provided BleveIndexV2Config
func (t *IndexConfig) MergeBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexConfig returns the union data inside the IndexConfig as a EmbeddingIndexConfig
func (t IndexConfig) AsEmbeddingIndexConfig() (EmbeddingIndexConfig, error) {
	var body EmbeddingIndexConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexConfig overwrites any union data inside the IndexConfig as the provided EmbeddingIndexConfig
func (t *IndexConfig) FromEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexConfig performs a merge with any union data inside the IndexConfig, using the provided EmbeddingIndexConfig
func (t *IndexConfig) MergeEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Config returns the union data inside the IndexConfig as a GraphIndexV0Config
func (t IndexConfig) AsGraphIndexV0Config() (GraphIndexV0Config, error) {
	var body GraphIndexV0Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Config overwrites any union data inside the IndexConfig as the provided GraphIndexV0Config
func (t *IndexConfig) FromGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Config performs a merge with any union data inside the IndexConfig, using the provided GraphIndexV0Config
func (t *IndexConfig) MergeGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["description"], err = json.Marshal(t.Description)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'description': %w", err)
	}

	object["enrichments"], err = json.Marshal(t.Enrichments)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'enrichments': %w", err)
	}

	object["name"], err = json.Marshal(t.Name)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'name': %w", err)
	}

	object["type"], err = json.Marshal(t.Type)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'type': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *IndexConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["description"]; found {
		err = json.Unmarshal(raw, &t.Description)
		if err != nil {
			return fmt.Errorf("error reading 'description': %w", err)
		}
	}

	if raw, found := object["enrichments"]; found {
		err = json.Unmarshal(raw, &t.Enrichments)
		if err != nil {
			return fmt.Errorf("error reading 'enrichments': %w", err)
		}
	}

	if raw, found := object["name"]; found {
		err = json.Unmarshal(raw, &t.Name)
		if err != nil {
			return fmt.Errorf("error reading 'name': %w", err)
		}
	}

	if raw, found := object["type"]; found {
		err = json.Unmarshal(raw, &t.Type)
		if err != nil {
			return fmt.Errorf("error reading 'type': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Stats returns the union data inside the IndexStats as a BleveIndexV2Stats
func (t IndexStats) AsBleveIndexV2Stats() (BleveIndexV2Stats, error) {
	var body BleveIndexV2Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Stats overwrites any union data inside the IndexStats as the provided BleveIndexV2Stats
func (t *IndexStats) FromBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Stats performs a merge with any union data inside the IndexStats, using the provided BleveIndexV2Stats
func (t *IndexStats) MergeBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexStats returns the union data inside the IndexStats as a EmbeddingIndexStats
func (t IndexStats) AsEmbeddingIndexStats() (EmbeddingIndexStats, error) {
	var body EmbeddingIndexStats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexStats overwrites any union data inside the IndexStats as the provided EmbeddingIndexStats
func (t *IndexStats) FromEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexStats performs a merge with any union data inside the IndexStats, using the provided EmbeddingIndexStats
func (t *IndexStats) MergeEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Stats returns the union data inside the IndexStats as a GraphIndexV0Stats
func (t IndexStats) AsGraphIndexV0Stats() (GraphIndexV0Stats, error) {
	var body GraphIndexV0Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Stats overwrites any union data inside the IndexStats as the provided GraphIndexV0Stats
func (t *IndexStats) FromGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Stats performs a merge with any union data inside the IndexStats, using the provided GraphIndexV0Stats
func (t *IndexStats) MergeGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexStats) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *IndexStats) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsTermQuery returns the union data inside the Query as a TermQuery
func (t Query) AsTermQuery() (TermQuery, error) {
	var body TermQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermQuery overwrites any union data inside the Query as the provided TermQuery
func (t *Query) FromTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermQuery performs a merge with any union data inside the Query, using the provided TermQuery
func (t *Query) MergeTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchQuery returns the union data inside the Query as a MatchQuery
func (t Query) AsMatchQuery() (MatchQuery, error) {
	var body MatchQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchQuery overwrites any union data inside the Query as the provided MatchQuery
func (t *Query) FromMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchQuery performs a merge with any union data inside the Query, using the provided MatchQuery
func (t *Query) MergeMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchPhraseQuery returns the union data inside the Query as a MatchPhraseQuery
func (t Query) AsMatchPhraseQuery() (MatchPhraseQuery, error) {
	var body MatchPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchPhraseQuery overwrites any union data inside the Query as the provided MatchPhraseQuery
func (t *Query) FromMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchPhraseQuery performs a merge with any union data inside the Query, using the provided MatchPhraseQuery
func (t *Query) MergeMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPhraseQuery returns the union data inside the Query as a PhraseQuery
func (t Query) AsPhraseQuery() (PhraseQuery, error) {
	var body PhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPhraseQuery overwrites any union data inside the Query as the provided PhraseQuery
func (t *Query) FromPhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePhraseQuery performs a merge with any union data inside the Query, using the provided PhraseQuery
func (t *Query) MergePhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMultiPhraseQuery returns the union data inside the Query as a MultiPhraseQuery
func (t Query) AsMultiPhraseQuery() (MultiPhraseQuery, error) {
	var body MultiPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMultiPhraseQuery overwrites any union data inside the Query as the provided MultiPhraseQuery
func (t *Query) FromMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMultiPhraseQuery performs a merge with any union data inside the Query, using the provided MultiPhraseQuery
func (t *Query) MergeMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzzyQuery returns the union data inside the Query as a FuzzyQuery
func (t Query) AsFuzzyQuery() (FuzzyQuery, error) {
	var body FuzzyQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzzyQuery overwrites any union data inside the Query as the provided FuzzyQuery
func (t *Query) FromFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzzyQuery performs a merge with any union data inside the Query, using the provided FuzzyQuery
func (t *Query) MergeFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPrefixQuery returns the union data inside the Query as a PrefixQuery
func (t Query) AsPrefixQuery() (PrefixQuery, error) {
	var body PrefixQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPrefixQuery overwrites any union data inside the Query as the provided PrefixQuery
func (t *Query) FromPrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePrefixQuery performs a merge with any union data inside the Query, using the provided PrefixQuery
func (t *Query) MergePrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsRegexpQuery returns the union data inside the Query as a RegexpQuery
func (t Query) AsRegexpQuery() (RegexpQuery, error) {
	var body RegexpQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromRegexpQuery overwrites any union data inside the Query as the provided RegexpQuery
func (t *Query) FromRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeRegexpQuery performs a merge with any union data inside the Query, using the provided RegexpQuery
func (t *Query) MergeRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsWildcardQuery returns the union data inside the Query as a WildcardQuery
func (t Query) AsWildcardQuery() (WildcardQuery, error) {
	var body WildcardQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromWildcardQuery overwrites any union data inside the Query as the provided WildcardQuery
func (t *Query) FromWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeWildcardQuery performs a merge with any union data inside the Query, using the provided WildcardQuery
func (t *Query) MergeWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsQueryStringQuery returns the union data inside the Query as a QueryStringQuery
func (t Query) AsQueryStringQuery() (QueryStringQuery, error) {
	var body QueryStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromQueryStringQuery overwrites any union data inside the Query as the provided QueryStringQuery
func (t *Query) FromQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeQueryStringQuery performs a merge with any union data inside the Query, using the provided QueryStringQuery
func (t *Query) MergeQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsNumericRangeQuery returns the union data inside the Query as a NumericRangeQuery
func (t Query) AsNumericRangeQuery() (NumericRangeQuery, error) {
	var body NumericRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromNumericRangeQuery overwrites any union data inside the Query as the provided NumericRangeQuery
func (t *Query) FromNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeNumericRangeQuery performs a merge with any union data inside the Query, using the provided NumericRangeQuery
func (t *Query) MergeNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermRangeQuery returns the union data inside the Query as a TermRangeQuery
func (t Query) AsTermRangeQuery() (TermRangeQuery, error) {
	var body TermRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermRangeQuery overwrites any union data inside the Query as the provided TermRangeQuery
func (t *Query) FromTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermRangeQuery performs a merge with any union data inside the Query, using the provided TermRangeQuery
func (t *Query) MergeTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDateRangeStringQuery returns the union data inside the Query as a DateRangeStringQuery
func (t Query) AsDateRangeStringQuery() (DateRangeStringQuery, error) {
	var body DateRangeStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDateRangeStringQuery overwrites any union data inside the Query as the provided DateRangeStringQuery
func (t *Query) FromDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDateRangeStringQuery performs a merge with any union data inside the Query, using the provided DateRangeStringQuery
func (t *Query) MergeDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBooleanQuery returns the union data inside the Query as a BooleanQuery
func (t Query) AsBooleanQuery() (BooleanQuery, error) {
	var body BooleanQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBooleanQuery overwrites any union data inside the Query as the provided BooleanQuery
func (t *Query) FromBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBooleanQuery performs a merge with any union data inside the Query, using the provided BooleanQuery
func (t *Query) MergeBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsConjunctionQuery returns the union data inside the Query as a ConjunctionQuery
func (t Query) AsConjunctionQuery() (ConjunctionQuery, error) {
	var body ConjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromConjunctionQuery overwrites any union data inside the Query as the provided ConjunctionQuery
func (t *Query) FromConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeConjunctionQuery performs a merge with any union data inside the Query, using the provided ConjunctionQuery
func (t *Query) MergeConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDisjunctionQuery returns the union data inside the Query as a DisjunctionQuery
func (t Query) AsDisjunctionQuery() (DisjunctionQuery, error) {
	var body DisjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDisjunctionQuery overwrites any union data inside the Query as the provided DisjunctionQuery
func (t *Query) FromDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDisjunctionQuery performs a merge with any union data inside the Query, using the provided DisjunctionQuery
func (t *Query) MergeDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchAllQuery returns the union data inside the Query as a MatchAllQuery
func (t Query) AsMatchAllQuery() (MatchAllQuery, error) {
	var body MatchAllQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchAllQuery overwrites any union data inside the Query as the provided MatchAllQuery
func (t *Query) FromMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchAllQuery performs a merge with any union data inside the Query, using the provided MatchAllQuery
func (t *Query) MergeMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchNoneQuery returns the union data inside the Query as a MatchNoneQuery
func (t Query) AsMatchNoneQuery() (MatchNoneQuery, error) {
	var body MatchNoneQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchNoneQuery overwrites any union data inside the Query as the provided MatchNoneQuery
func (t *Query) FromMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchNoneQuery performs a merge with any union data inside the Query, using the provided MatchNoneQuery
func (t *Query) MergeMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDocIdQuery returns the union data inside the Query as a DocIdQuery
func (t Query) AsDocIdQuery() (DocIdQuery, error) {
	var body DocIdQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDocIdQuery overwrites any union data inside the Query as the provided DocIdQuery
func (t *Query) FromDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDocIdQuery performs a merge with any union data inside the Query, using the provided DocIdQuery
func (t *Query) MergeDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBoolFieldQuery returns the union data inside the Query as a BoolFieldQuery
func (t Query) AsBoolFieldQuery() (BoolFieldQuery, error) {
	var body BoolFieldQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBoolFieldQuery overwrites any union data inside the Query as the provided BoolFieldQuery
func (t *Query) FromBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBoolFieldQuery performs a merge with any union data inside the Query, using the provided BoolFieldQuery
func (t *Query) MergeBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsIPRangeQuery returns the union data inside the Query as a IPRangeQuery
func (t Query) AsIPRangeQuery() (IPRangeQuery, error) {
	var body IPRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromIPRangeQuery overwrites any union data inside the Query as the provided IPRangeQuery
func (t *Query) FromIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeIPRangeQuery performs a merge with any union data inside the Query, using the provided IPRangeQuery
func (t *Query) MergeIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingBoxQuery returns the union data inside the Query as a GeoBoundingBoxQuery
func (t Query) AsGeoBoundingBoxQuery() (GeoBoundingBoxQuery, error) {
	var body GeoBoundingBoxQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingBoxQuery overwrites any union data inside the Query as the provided GeoBoundingBoxQuery
func (t *Query) FromGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingBoxQuery performs a merge with any union data inside the Query, using the provided GeoBoundingBoxQuery
func (t *Query) MergeGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoDistanceQuery returns the union data inside the Query as a GeoDistanceQuery
func (t Query) AsGeoDistanceQuery() (GeoDistanceQuery, error) {
	var body GeoDistanceQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoDistanceQuery overwrites any union data inside the Query as the provided GeoDistanceQuery
func (t *Query) FromGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoDistanceQuery performs a merge with any union data inside the Query, using the provided GeoDistanceQuery
func (t *Query) MergeGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingPolygonQuery returns the union data inside the Query as a GeoBoundingPolygonQuery
func (t Query) AsGeoBoundingPolygonQuery() (GeoBoundingPolygonQuery, error) {
	var body GeoBoundingPolygonQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingPolygonQuery overwrites any union data inside the Query as the provided GeoBoundingPolygonQuery
func (t *Query) FromGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingPolygonQuery performs a merge with any union data inside the Query, using the provided GeoBoundingPolygonQuery
func (t *Query) MergeGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoShapeQuery returns the union data inside the Query as a GeoShapeQuery
func (t Query) AsGeoShapeQuery() (GeoShapeQuery, error) {
	var body GeoShapeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoShapeQuery overwrites any union data inside the Query as the provided GeoShapeQuery
func (t *Query) FromGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoShapeQuery performs a merge with any union data inside the Query, using the provided GeoShapeQuery
func (t *Query) MergeGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Query) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Query) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsOllamaRerankerConfig returns the union data inside the RerankerConfig as a OllamaRerankerConfig
func (t RerankerConfig) AsOllamaRerankerConfig() (OllamaRerankerConfig, error) {
	var body OllamaRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaRerankerConfig overwrites any union data inside the RerankerConfig as the provided OllamaRerankerConfig
func (t *RerankerConfig) FromOllamaRerankerConfig(v OllamaRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided OllamaRerankerConfig
func (t *RerankerConfig) MergeOllamaRerankerConfig(v OllamaRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermiteRerankerConfig returns the union data inside the RerankerConfig as a TermiteRerankerConfig
func (t RerankerConfig) AsTermiteRerankerConfig() (TermiteRerankerConfig, error) {
	var body TermiteRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteRerankerConfig overwrites any union data inside the RerankerConfig as the provided TermiteRerankerConfig
func (t *RerankerConfig) FromTermiteRerankerConfig(v TermiteRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided TermiteRerankerConfig
func (t *RerankerConfig) MergeTermiteRerankerConfig(v TermiteRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereRerankerConfig returns the union data inside the RerankerConfig as a CohereRerankerConfig
func (t RerankerConfig) AsCohereRerankerConfig() (CohereRerankerConfig, error) {
	var body CohereRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereRerankerConfig overwrites any union data inside the RerankerConfig as the provided CohereRerankerConfig
func (t *RerankerConfig) FromCohereRerankerConfig(v CohereRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided CohereRerankerConfig
func (t *RerankerConfig) MergeCohereRerankerConfig(v CohereRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexRerankerConfig returns the union data inside the RerankerConfig as a VertexRerankerConfig
func (t RerankerConfig) AsVertexRerankerConfig() (VertexRerankerConfig, error) {
	var body VertexRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexRerankerConfig overwrites any union data inside the RerankerConfig as the provided VertexRerankerConfig
func (t *RerankerConfig) FromVertexRerankerConfig(v VertexRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided VertexRerankerConfig
func (t *RerankerConfig) MergeVertexRerankerConfig(v VertexRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t RerankerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["field"], err = json.Marshal(t.Field)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'field': %w", err)
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	object["template"], err = json.Marshal(t.Template)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'template': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *RerankerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["field"]; found {
		err = json.Unmarshal(raw, &t.Field)
		if err != nil {
			return fmt.Errorf("error reading 'field': %w", err)
		}
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	if raw, found := object["template"]; found {
		err = json.Unmarshal(raw, &t.Template)
		if err != nil {
			return fmt.Errorf("error reading 'template': %w", err)
		}
	}

	return err
}

// RequestEditorFn  is the function signature for the RequestEditor callback function
type RequestEditorFn func(ctx context.Context, req *http.Request) error

// Doer performs HTTP requests.
//
// The standard http.Client implements this interface.
type HttpRequestDoer interface {
	Do(req *http.Request) (*http.Response, error)
}

// Client which conforms to the OpenAPI3 specification for this service.
type Client struct {
	// The endpoint of the server conforming to this interface, with scheme,
	// https://api.deepmap.com for example. This can contain a path relative
	// to the server, such as https://api.deepmap.com/dev-test, and all the
	// paths in the swagger spec will be appended to the server.
	Server string

	// Doer for performing requests, typically a *http.Client with any
	// customized settings, such as certificate chains.
	Client HttpRequestDoer

	// A list of callbacks for modifying requests which are generated before sending over
	// the network.
	RequestEditors []RequestEditorFn
}

// ClientOption allows setting custom parameters during construction
type ClientOption func(*Client) error

// Creates a new Client, with reasonable defaults
func NewClient(server string, opts ...ClientOption) (*Client, error) {
	// create a client with sane default values
	client := Client{
		Server: server,
	}
	// mutate client and add all optional params
	for _, o := range opts {
		if err := o(&client); err != nil {
			return nil, err
		}
	}
	// ensure the server URL always has a trailing slash
	if !strings.HasSuffix(client.Server, "/") {
		client.Server += "/"
	}
	// create httpClient, if not already present
	if client.Client == nil {
		client.Client = &http.Client{}
	}
	return &client, nil
}

// WithHTTPClient allows overriding the default Doer, which is
// automatically created using http.Client. This is useful for tests.
func WithHTTPClient(doer HttpRequestDoer) ClientOption {
	return func(c *Client) error {
		c.Client = doer
		return nil
	}
}

// WithRequestEditorFn allows setting up a callback function, which will be
// called right before sending the request. This can be used to mutate the request.
func WithRequestEditorFn(fn RequestEditorFn) ClientOption {
	return func(c *Client) error {
		c.RequestEditors = append(c.RequestEditors, fn)
		return nil
	}
}

// The interface specification for the client above.
type ClientInterface interface {
	// AnswerAgentWithBody request with any body
	AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ChatAgentWithBody request with any body
	ChatAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	ChatAgent(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// QueryBuilderAgentWithBody request with any body
	QueryBuilderAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	QueryBuilderAgent(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// EvaluateWithBody request with any body
	EvaluateWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Evaluate(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GlobalQueryWithBody request with any body
	GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RagQueryWithBody request with any body
	RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetStatus request
	GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListTables request
	ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropTable request
	DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetTable request
	GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateTableWithBody request with any body
	CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BackupTableWithBody request with any body
	BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BatchWithBody request with any body
	BatchWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Batch(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListIndexes request
	ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropIndex request
	DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetIndex request
	GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateIndexWithBody request with any body
	CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ScanKeysWithBody request with any body
	ScanKeysWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	ScanKeys(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LookupKey request
	LookupKey(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LinearMergeWithBody request with any body
	LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// QueryTableWithBody request with any body
	QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// TableRagQueryWithBody request with any body
	TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RestoreTableWithBody request with any body
	RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateSchemaWithBody request with any body
	UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListUsers request
	ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetCurrentUser request
	GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteUser request
	DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserByName request
	GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateUserWithBody request with any body
	CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateUserPasswordWithBody request with any body
	UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RemovePermissionFromUser request
	RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserPermissions request
	GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// AddPermissionToUserWithBody request with any body
	AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)
}

func (c *Client) AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ChatAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewChatAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ChatAgent(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewChatAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryBuilderAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryBuilderAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryBuilderAgent(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryBuilderAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) EvaluateWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewEvaluateRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Evaluate(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewEvaluateRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetStatusRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListTablesRequest(c.Server, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BatchWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Batch(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListIndexesRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequestWithBody(c.Server, tableName, indexName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequest(c.Server, tableName, indexName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ScanKeysWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewScanKeysRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ScanKeys(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewScanKeysRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LookupKey(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLookupKeyRequest(c.Server, tableName, key, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListUsersRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetCurrentUserRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteUserRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserByNameRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRemovePermissionFromUserRequest(c.Server, userName, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserPermissionsRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

// NewAnswerAgentRequest calls the generic AnswerAgent builder with application/json body
func NewAnswerAgentRequest(server string, body AnswerAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAnswerAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewAnswerAgentRequestWithBody generates requests for AnswerAgent with any type of body
func NewAnswerAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/answer")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewChatAgentRequest calls the generic ChatAgent builder with application/json body
func NewChatAgentRequest(server string, body ChatAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewChatAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewChatAgentRequestWithBody generates requests for ChatAgent with any type of body
func NewChatAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/chat")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewQueryBuilderAgentRequest calls the generic QueryBuilderAgent builder with application/json body
func NewQueryBuilderAgentRequest(server string, body QueryBuilderAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewQueryBuilderAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewQueryBuilderAgentRequestWithBody generates requests for QueryBuilderAgent with any type of body
func NewQueryBuilderAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/query-builder")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewEvaluateRequest calls the generic Evaluate builder with application/json body
func NewEvaluateRequest(server string, body EvaluateJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewEvaluateRequestWithBody(server, "application/json", bodyReader)
}

// NewEvaluateRequestWithBody generates requests for Evaluate with any type of body
func NewEvaluateRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/eval")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGlobalQueryRequest calls the generic GlobalQuery builder with application/json body
func NewGlobalQueryRequest(server string, body GlobalQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewGlobalQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewGlobalQueryRequestWithBody generates requests for GlobalQuery with any type of body
func NewGlobalQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/query")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRagQueryRequest calls the generic RagQuery builder with application/json body
func NewRagQueryRequest(server string, body RagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRagQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewRagQueryRequestWithBody generates requests for RagQuery with any type of body
func NewRagQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/rag")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetStatusRequest generates requests for GetStatus
func NewGetStatusRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/status")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListTablesRequest generates requests for ListTables
func NewListTablesRequest(server string, params *ListTablesParams) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "prefix", runtime.ParamLocationQuery, params.Prefix); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "pattern", runtime.ParamLocationQuery, params.Pattern); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropTableRequest generates requests for DropTable
func NewDropTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetTableRequest generates requests for GetTable
func NewGetTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateTableRequest calls the generic CreateTable builder with application/json body
func NewCreateTableRequest(server string, tableName string, body CreateTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewCreateTableRequestWithBody generates requests for CreateTable with any type of body
func NewCreateTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBackupTableRequest calls the generic BackupTable builder with application/json body
func NewBackupTableRequest(server string, tableName string, body BackupTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBackupTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBackupTableRequestWithBody generates requests for BackupTable with any type of body
func NewBackupTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/backup", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBatchRequest calls the generic Batch builder with application/json body
func NewBatchRequest(server string, tableName string, body BatchJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBatchRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBatchRequestWithBody generates requests for Batch with any type of body
func NewBatchRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/batch", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListIndexesRequest generates requests for ListIndexes
func NewListIndexesRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropIndexRequest generates requests for DropIndex
func NewDropIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetIndexRequest generates requests for GetIndex
func NewGetIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateIndexRequest calls the generic CreateIndex builder with application/json body
func NewCreateIndexRequest(server string, tableName string, indexName string, body CreateIndexJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateIndexRequestWithBody(server, tableName, indexName, "application/json", bodyReader)
}

// NewCreateIndexRequestWithBody generates requests for CreateIndex with any type of body
func NewCreateIndexRequestWithBody(server string, tableName string, indexName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewScanKeysRequest calls the generic ScanKeys builder with application/json body
func NewScanKeysRequest(server string, tableName string, body ScanKeysJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewScanKeysRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewScanKeysRequestWithBody generates requests for ScanKeys with any type of body
func NewScanKeysRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/lookup", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewLookupKeyRequest generates requests for LookupKey
func NewLookupKeyRequest(server string, tableName string, key string, params *LookupKeyParams) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "key", runtime.ParamLocationPath, key)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/lookup/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "fields", runtime.ParamLocationQuery, params.Fields); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewLinearMergeRequest calls the generic LinearMerge builder with application/json body
func NewLinearMergeRequest(server string, tableName string, body LinearMergeJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewLinearMergeRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewLinearMergeRequestWithBody generates requests for LinearMerge with any type of body
func NewLinearMergeRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/merge", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewQueryTableRequest calls the generic QueryTable builder with application/json body
func NewQueryTableRequest(server string, tableName string, body QueryTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewQueryTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewQueryTableRequestWithBody generates requests for QueryTable with any type of body
func NewQueryTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/query", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewTableRagQueryRequest calls the generic TableRagQuery builder with application/json body
func NewTableRagQueryRequest(server string, tableName string, body TableRagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewTableRagQueryRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewTableRagQueryRequestWithBody generates requests for TableRagQuery with any type of body
func NewTableRagQueryRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/rag", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRestoreTableRequest calls the generic RestoreTable builder with application/json body
func NewRestoreTableRequest(server string, tableName string, body RestoreTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRestoreTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewRestoreTableRequestWithBody generates requests for RestoreTable with any type of body
func NewRestoreTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/restore", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateSchemaRequest calls the generic UpdateSchema builder with application/json body
func NewUpdateSchemaRequest(server string, tableName string, body UpdateSchemaJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateSchemaRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewUpdateSchemaRequestWithBody generates requests for UpdateSchema with any type of body
func NewUpdateSchemaRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/schema", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListUsersRequest generates requests for ListUsers
func NewListUsersRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetCurrentUserRequest generates requests for GetCurrentUser
func NewGetCurrentUserRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/me")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDeleteUserRequest generates requests for DeleteUser
func NewDeleteUserRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserByNameRequest generates requests for GetUserByName
func NewGetUserByNameRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateUserRequest calls the generic CreateUser builder with application/json body
func NewCreateUserRequest(server string, userName UserNamePathParameter, body CreateUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewCreateUserRequestWithBody generates requests for CreateUser with any type of body
func NewCreateUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateUserPasswordRequest calls the generic UpdateUserPassword builder with application/json body
func NewUpdateUserPasswordRequest(server string, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateUserPasswordRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewUpdateUserPasswordRequestWithBody generates requests for UpdateUserPassword with any type of body
func NewUpdateUserPasswordRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/password", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRemovePermissionFromUserRequest generates requests for RemovePermissionFromUser
func NewRemovePermissionFromUserRequest(server string, userName UserNamePathParameter, params *RemovePermissionFromUserParams) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resource", runtime.ParamLocationQuery, params.Resource); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resourceType", runtime.ParamLocationQuery, params.ResourceType); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserPermissionsRequest generates requests for GetUserPermissions
func NewGetUserPermissionsRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewAddPermissionToUserRequest calls the generic AddPermissionToUser builder with application/json body
func NewAddPermissionToUserRequest(server string, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAddPermissionToUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewAddPermissionToUserRequestWithBody generates requests for AddPermissionToUser with any type of body
func NewAddPermissionToUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

func (c *Client) applyEditors(ctx context.Context, req *http.Request, additionalEditors []RequestEditorFn) error {
	for _, r := range c.RequestEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	for _, r := range additionalEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	return nil
}

// ClientWithResponses builds on ClientInterface to offer response payloads
type ClientWithResponses struct {
	ClientInterface
}

// NewClientWithResponses creates a new ClientWithResponses, which wraps
// Client with return type handling
func NewClientWithResponses(server string, opts ...ClientOption) (*ClientWithResponses, error) {
	client, err := NewClient(server, opts...)
	if err != nil {
		return nil, err
	}
	return &ClientWithResponses{client}, nil
}

// WithBaseURL overrides the baseURL.
func WithBaseURL(baseURL string) ClientOption {
	return func(c *Client) error {
		newBaseURL, err := url.Parse(baseURL)
		if err != nil {
			return err
		}
		c.Server = newBaseURL.String()
		return nil
	}
}

// ClientWithResponsesInterface is the interface specification for the client with responses above.
type ClientWithResponsesInterface interface {
	// AnswerAgentWithBodyWithResponse request with any body
	AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	// ChatAgentWithBodyWithResponse request with any body
	ChatAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error)

	ChatAgentWithResponse(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error)

	// QueryBuilderAgentWithBodyWithResponse request with any body
	QueryBuilderAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error)

	QueryBuilderAgentWithResponse(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error)

	// EvaluateWithBodyWithResponse request with any body
	EvaluateWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*EvaluateResponse, error)

	EvaluateWithResponse(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*EvaluateResponse, error)

	// GlobalQueryWithBodyWithResponse request with any body
	GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	// RagQueryWithBodyWithResponse request with any body
	RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	// GetStatusWithResponse request
	GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error)

	// ListTablesWithResponse request
	ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error)

	// DropTableWithResponse request
	DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error)

	// GetTableWithResponse request
	GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error)

	// CreateTableWithBodyWithResponse request with any body
	CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	// BackupTableWithBodyWithResponse request with any body
	BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	// BatchWithBodyWithResponse request with any body
	BatchWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchResponse, error)

	BatchWithResponse(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchResponse, error)

	// ListIndexesWithResponse request
	ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error)

	// DropIndexWithResponse request
	DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error)

	// GetIndexWithResponse request
	GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error)

	// CreateIndexWithBodyWithResponse request with any body
	CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	// ScanKeysWithBodyWithResponse request with any body
	ScanKeysWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error)

	ScanKeysWithResponse(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error)

	// LookupKeyWithResponse request
	LookupKeyWithResponse(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error)

	// LinearMergeWithBodyWithResponse request with any body
	LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	// QueryTableWithBodyWithResponse request with any body
	QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	// TableRagQueryWithBodyWithResponse request with any body
	TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	// RestoreTableWithBodyWithResponse request with any body
	RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	// UpdateSchemaWithBodyWithResponse request with any body
	UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	// ListUsersWithResponse request
	ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error)

	// GetCurrentUserWithResponse request
	GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error)

	// DeleteUserWithResponse request
	DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error)

	// GetUserByNameWithResponse request
	GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error)

	// CreateUserWithBodyWithResponse request with any body
	CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	// UpdateUserPasswordWithBodyWithResponse request with any body
	UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	// RemovePermissionFromUserWithResponse request
	RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error)

	// GetUserPermissionsWithResponse request
	GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error)

	// AddPermissionToUserWithBodyWithResponse request with any body
	AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)

	AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)
}

type AnswerAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *AnswerAgentResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AnswerAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AnswerAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ChatAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ChatAgentResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ChatAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ChatAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type QueryBuilderAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryBuilderResult
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r QueryBuilderAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r QueryBuilderAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type EvaluateResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *EvalResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r EvaluateResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r EvaluateResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GlobalQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GlobalQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GlobalQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetStatusResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ClusterStatus
	JSON401      *Error
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetStatusResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetStatusResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListTablesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]TableStatus
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListTablesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListTablesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *TableStatus
	JSON404      *NotFound
}

// Status returns HTTPResponse.Status
func (r GetTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
}

// Status returns HTTPResponse.Status
func (r CreateTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BackupTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *struct {
		Backup string `json:"backup,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON404 *NotFound
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BackupTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BackupTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BatchResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *struct {
		// Deleted Number of documents successfully deleted
		Deleted int `json:"deleted,omitempty,omitzero"`

		// Failed List of failed operations with error details
		Failed []struct {
			// Error Error message for this failure
			Error string `json:"error,omitempty,omitzero"`

			// Id The document ID that failed
			Id string `json:"id,omitempty,omitzero"`
		} `json:"failed,omitempty,omitzero"`

		// Inserted Number of documents successfully inserted
		Inserted int `json:"inserted,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON404 *NotFound
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BatchResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BatchResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListIndexesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListIndexesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListIndexesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r CreateIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ScanKeysResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ScanKeysResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ScanKeysResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LookupKeyResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *map[string]interface{}
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LookupKeyResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LookupKeyResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LinearMergeResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *LinearMergeResult
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LinearMergeResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LinearMergeResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type QueryTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r QueryTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r QueryTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type TableRagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON404      *NotFound
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r TableRagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r TableRagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RestoreTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON202      *struct {
		Restore string `json:"restore,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r RestoreTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RestoreTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateSchemaResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r UpdateSchemaResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateSchemaResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListUsersResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]struct {
		Username string `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON403 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r ListUsersResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListUsersResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetCurrentUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *struct {
		Permissions []Permission `json:"permissions,omitempty,omitzero"`
		Username    string       `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r GetCurrentUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetCurrentUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserByNameResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *User
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserByNameResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserByNameResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *User
	JSON400      *Error
	JSON409      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateUserPasswordResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateUserPasswordResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateUserPasswordResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RemovePermissionFromUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RemovePermissionFromUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RemovePermissionFromUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserPermissionsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]Permission
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserPermissionsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserPermissionsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type AddPermissionToUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AddPermissionToUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AddPermissionToUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

// AnswerAgentWithBodyWithResponse request with arbitrary body returning *AnswerAgentResponse
func (c *ClientWithResponses) AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

func (c *ClientWithResponses) AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

// ChatAgentWithBodyWithResponse request with arbitrary body returning *ChatAgentResponse
func (c *ClientWithResponses) ChatAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error) {
	rsp, err := c.ChatAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseChatAgentResponse(rsp)
}

func (c *ClientWithResponses) ChatAgentWithResponse(ctx context.Context, body ChatAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*ChatAgentResponse, error) {
	rsp, err := c.ChatAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseChatAgentResponse(rsp)
}

// QueryBuilderAgentWithBodyWithResponse request with arbitrary body returning *QueryBuilderAgentResponse
func (c *ClientWithResponses) QueryBuilderAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error) {
	rsp, err := c.QueryBuilderAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryBuilderAgentResponse(rsp)
}

func (c *ClientWithResponses) QueryBuilderAgentWithResponse(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error) {
	rsp, err := c.QueryBuilderAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryBuilderAgentResponse(rsp)
}

// EvaluateWithBodyWithResponse request with arbitrary body returning *EvaluateResponse
func (c *ClientWithResponses) EvaluateWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*EvaluateResponse, error) {
	rsp, err := c.EvaluateWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseEvaluateResponse(rsp)
}

func (c *ClientWithResponses) EvaluateWithResponse(ctx context.Context, body EvaluateJSONRequestBody, reqEditors ...RequestEditorFn) (*EvaluateResponse, error) {
	rsp, err := c.Evaluate(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseEvaluateResponse(rsp)
}

// GlobalQueryWithBodyWithResponse request with arbitrary body returning *GlobalQueryResponse
func (c *ClientWithResponses) GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

func (c *ClientWithResponses) GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

// RagQueryWithBodyWithResponse request with arbitrary body returning *RagQueryResponse
func (c *ClientWithResponses) RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

func (c *ClientWithResponses) RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

// GetStatusWithResponse request returning *GetStatusResponse
func (c *ClientWithResponses) GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error) {
	rsp, err := c.GetStatus(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetStatusResponse(rsp)
}

// ListTablesWithResponse request returning *ListTablesResponse
func (c *ClientWithResponses) ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error) {
	rsp, err := c.ListTables(ctx, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListTablesResponse(rsp)
}

// DropTableWithResponse request returning *DropTableResponse
func (c *ClientWithResponses) DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error) {
	rsp, err := c.DropTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropTableResponse(rsp)
}

// GetTableWithResponse request returning *GetTableResponse
func (c *ClientWithResponses) GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error) {
	rsp, err := c.GetTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetTableResponse(rsp)
}

// CreateTableWithBodyWithResponse request with arbitrary body returning *CreateTableResponse
func (c *ClientWithResponses) CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

func (c *ClientWithResponses) CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

// BackupTableWithBodyWithResponse request with arbitrary body returning *BackupTableResponse
func (c *ClientWithResponses) BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

func (c *ClientWithResponses) BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

// BatchWithBodyWithResponse request with arbitrary body returning *BatchResponse
func (c *ClientWithResponses) BatchWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchResponse, error) {
	rsp, err := c.BatchWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchResponse(rsp)
}

func (c *ClientWithResponses) BatchWithResponse(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchResponse, error) {
	rsp, err := c.Batch(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchResponse(rsp)
}

// ListIndexesWithResponse request returning *ListIndexesResponse
func (c *ClientWithResponses) ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error) {
	rsp, err := c.ListIndexes(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListIndexesResponse(rsp)
}

// DropIndexWithResponse request returning *DropIndexResponse
func (c *ClientWithResponses) DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error) {
	rsp, err := c.DropIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropIndexResponse(rsp)
}

// GetIndexWithResponse request returning *GetIndexResponse
func (c *ClientWithResponses) GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error) {
	rsp, err := c.GetIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetIndexResponse(rsp)
}

// CreateIndexWithBodyWithResponse request with arbitrary body returning *CreateIndexResponse
func (c *ClientWithResponses) CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndexWithBody(ctx, tableName, indexName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

func (c *ClientWithResponses) CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndex(ctx, tableName, indexName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

// ScanKeysWithBodyWithResponse request with arbitrary body returning *ScanKeysResponse
func (c *ClientWithResponses) ScanKeysWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error) {
	rsp, err := c.ScanKeysWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseScanKeysResponse(rsp)
}

func (c *ClientWithResponses) ScanKeysWithResponse(ctx context.Context, tableName string, body ScanKeysJSONRequestBody, reqEditors ...RequestEditorFn) (*ScanKeysResponse, error) {
	rsp, err := c.ScanKeys(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseScanKeysResponse(rsp)
}

// LookupKeyWithResponse request returning *LookupKeyResponse
func (c *ClientWithResponses) LookupKeyWithResponse(ctx context.Context, tableName string, key string, params *LookupKeyParams, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error) {
	rsp, err := c.LookupKey(ctx, tableName, key, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLookupKeyResponse(rsp)
}

// LinearMergeWithBodyWithResponse request with arbitrary body returning *LinearMergeResponse
func (c *ClientWithResponses) LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMergeWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

func (c *ClientWithResponses) LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMerge(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

// QueryTableWithBodyWithResponse request with arbitrary body returning *QueryTableResponse
func (c *ClientWithResponses) QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

func (c *ClientWithResponses) QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

// TableRagQueryWithBodyWithResponse request with arbitrary body returning *TableRagQueryResponse
func (c *ClientWithResponses) TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQueryWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

func (c *ClientWithResponses) TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQuery(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

// RestoreTableWithBodyWithResponse request with arbitrary body returning *RestoreTableResponse
func (c *ClientWithResponses) RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

func (c *ClientWithResponses) RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

// UpdateSchemaWithBodyWithResponse request with arbitrary body returning *UpdateSchemaResponse
func (c *ClientWithResponses) UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchemaWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

func (c *ClientWithResponses) UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchema(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

// ListUsersWithResponse request returning *ListUsersResponse
func (c *ClientWithResponses) ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error) {
	rsp, err := c.ListUsers(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListUsersResponse(rsp)
}

// GetCurrentUserWithResponse request returning *GetCurrentUserResponse
func (c *ClientWithResponses) GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error) {
	rsp, err := c.GetCurrentUser(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetCurrentUserResponse(rsp)
}

// DeleteUserWithResponse request returning *DeleteUserResponse
func (c *ClientWithResponses) DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error) {
	rsp, err := c.DeleteUser(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteUserResponse(rsp)
}

// GetUserByNameWithResponse request returning *GetUserByNameResponse
func (c *ClientWithResponses) GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error) {
	rsp, err := c.GetUserByName(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserByNameResponse(rsp)
}

// CreateUserWithBodyWithResponse request with arbitrary body returning *CreateUserResponse
func (c *ClientWithResponses) CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

func (c *ClientWithResponses) CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

// UpdateUserPasswordWithBodyWithResponse request with arbitrary body returning *UpdateUserPasswordResponse
func (c *ClientWithResponses) UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPasswordWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

func (c *ClientWithResponses) UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPassword(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

// RemovePermissionFromUserWithResponse request returning *RemovePermissionFromUserResponse
func (c *ClientWithResponses) RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error) {
	rsp, err := c.RemovePermissionFromUser(ctx, userName, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRemovePermissionFromUserResponse(rsp)
}

// GetUserPermissionsWithResponse request returning *GetUserPermissionsResponse
func (c *ClientWithResponses) GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error) {
	rsp, err := c.GetUserPermissions(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserPermissionsResponse(rsp)
}

// AddPermissionToUserWithBodyWithResponse request with arbitrary body returning *AddPermissionToUserResponse
func (c *ClientWithResponses) AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

func (c *ClientWithResponses) AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

// ParseAnswerAgentResponse parses an HTTP response from a AnswerAgentWithResponse call
func ParseAnswerAgentResponse(rsp *http.Response) (*AnswerAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AnswerAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest AnswerAgentResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseChatAgentResponse parses an HTTP response from a ChatAgentWithResponse call
func ParseChatAgentResponse(rsp *http.Response) (*ChatAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ChatAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ChatAgentResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseQueryBuilderAgentResponse parses an HTTP response from a QueryBuilderAgentWithResponse call
func ParseQueryBuilderAgentResponse(rsp *http.Response) (*QueryBuilderAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &QueryBuilderAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryBuilderResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseEvaluateResponse parses an HTTP response from a EvaluateWithResponse call
func ParseEvaluateResponse(rsp *http.Response) (*EvaluateResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &EvaluateResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest EvalResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGlobalQueryResponse parses an HTTP response from a GlobalQueryWithResponse call
func ParseGlobalQueryResponse(rsp *http.Response) (*GlobalQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GlobalQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRagQueryResponse parses an HTTP response from a RagQueryWithResponse call
func ParseRagQueryResponse(rsp *http.Response) (*RagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseGetStatusResponse parses an HTTP response from a GetStatusWithResponse call
func ParseGetStatusResponse(rsp *http.Response) (*GetStatusResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetStatusResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ClusterStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListTablesResponse parses an HTTP response from a ListTablesWithResponse call
func ParseListTablesResponse(rsp *http.Response) (*ListTablesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListTablesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropTableResponse parses an HTTP response from a DropTableWithResponse call
func ParseDropTableResponse(rsp *http.Response) (*DropTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetTableResponse parses an HTTP response from a GetTableWithResponse call
func ParseGetTableResponse(rsp *http.Response) (*GetTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	}

	return response, nil
}

// ParseCreateTableResponse parses an HTTP response from a CreateTableWithResponse call
func ParseCreateTableResponse(rsp *http.Response) (*CreateTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	}

	return response, nil
}

// ParseBackupTableResponse parses an HTTP response from a BackupTableWithResponse call
func ParseBackupTableResponse(rsp *http.Response) (*BackupTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BackupTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest struct {
			Backup string `json:"backup,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseBatchResponse parses an HTTP response from a BatchWithResponse call
func ParseBatchResponse(rsp *http.Response) (*BatchResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BatchResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest struct {
			// Deleted Number of documents successfully deleted
			Deleted int `json:"deleted,omitempty,omitzero"`

			// Failed List of failed operations with error details
			Failed []struct {
				// Error Error message for this failure
				Error string `json:"error,omitempty,omitzero"`

				// Id The document ID that failed
				Id string `json:"id,omitempty,omitzero"`
			} `json:"failed,omitempty,omitzero"`

			// Inserted Number of documents successfully inserted
			Inserted int `json:"inserted,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListIndexesResponse parses an HTTP response from a ListIndexesWithResponse call
func ParseListIndexesResponse(rsp *http.Response) (*ListIndexesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListIndexesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropIndexResponse parses an HTTP response from a DropIndexWithResponse call
func ParseDropIndexResponse(rsp *http.Response) (*DropIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetIndexResponse parses an HTTP response from a GetIndexWithResponse call
func ParseGetIndexResponse(rsp *http.Response) (*GetIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateIndexResponse parses an HTTP response from a CreateIndexWithResponse call
func ParseCreateIndexResponse(rsp *http.Response) (*CreateIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseScanKeysResponse parses an HTTP response from a ScanKeysWithResponse call
func ParseScanKeysResponse(rsp *http.Response) (*ScanKeysResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ScanKeysResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLookupKeyResponse parses an HTTP response from a LookupKeyWithResponse call
func ParseLookupKeyResponse(rsp *http.Response) (*LookupKeyResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LookupKeyResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest map[string]interface{}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLinearMergeResponse parses an HTTP response from a LinearMergeWithResponse call
func ParseLinearMergeResponse(rsp *http.Response) (*LinearMergeResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LinearMergeResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest LinearMergeResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseQueryTableResponse parses an HTTP response from a QueryTableWithResponse call
func ParseQueryTableResponse(rsp *http.Response) (*QueryTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &QueryTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseTableRagQueryResponse parses an HTTP response from a TableRagQueryWithResponse call
func ParseTableRagQueryResponse(rsp *http.Response) (*TableRagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &TableRagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseRestoreTableResponse parses an HTTP response from a RestoreTableWithResponse call
func ParseRestoreTableResponse(rsp *http.Response) (*RestoreTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RestoreTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest struct {
			Restore string `json:"restore,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateSchemaResponse parses an HTTP response from a UpdateSchemaWithResponse call
func ParseUpdateSchemaResponse(rsp *http.Response) (*UpdateSchemaResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateSchemaResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListUsersResponse parses an HTTP response from a ListUsersWithResponse call
func ParseListUsersResponse(rsp *http.Response) (*ListUsersResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListUsersResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []struct {
			Username string `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 403:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON403 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetCurrentUserResponse parses an HTTP response from a GetCurrentUserWithResponse call
func ParseGetCurrentUserResponse(rsp *http.Response) (*GetCurrentUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetCurrentUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest struct {
			Permissions []Permission `json:"permissions,omitempty,omitzero"`
			Username    string       `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteUserResponse parses an HTTP response from a DeleteUserWithResponse call
func ParseDeleteUserResponse(rsp *http.Response) (*DeleteUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserByNameResponse parses an HTTP response from a GetUserByNameWithResponse call
func ParseGetUserByNameResponse(rsp *http.Response) (*GetUserByNameResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserByNameResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateUserResponse parses an HTTP response from a CreateUserWithResponse call
func ParseCreateUserResponse(rsp *http.Response) (*CreateUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 409:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON409 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateUserPasswordResponse parses an HTTP response from a UpdateUserPasswordWithResponse call
func ParseUpdateUserPasswordResponse(rsp *http.Response) (*UpdateUserPasswordResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateUserPasswordResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRemovePermissionFromUserResponse parses an HTTP response from a RemovePermissionFromUserWithResponse call
func ParseRemovePermissionFromUserResponse(rsp *http.Response) (*RemovePermissionFromUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RemovePermissionFromUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserPermissionsResponse parses an HTTP response from a GetUserPermissionsWithResponse call
func ParseGetUserPermissionsResponse(rsp *http.Response) (*GetUserPermissionsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserPermissionsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []Permission
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseAddPermissionToUserResponse parses an HTTP response from a AddPermissionToUserWithResponse call
func ParseAddPermissionToUserResponse(rsp *http.Response) (*AddPermissionToUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AddPermissionToUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// Base64 encoded, gzipped, json marshaled Swagger object
var swaggerSpec = []string{

	"H4sIAAAAAAAC/+y9i3IjubE2+CpY2ida6iUpqdUzY/OPCVt915m+6Eg9nj1hdlBgFUjCqgJqAJQkTof2",
	"GfZF9qX2STaQCaBQLFCkLu1jxz//H8fTYuGaSCQSicwvv/YyWVZSMGF0b/S1V1FFS2aYgr9+1kx9pCU7",
	"oWZx4r/YDznTmeKV4VL0Rr3PC0ZqzZSgJRv2+j1uf6yoWfT6Pftbb9SrXUu9fk+xX2uuWN4bGVWzfk9n",
	"C1ZS2yq7pmVV2OL/kAuRS1vaLCv7gzaKi3nv5ubGNqArKTSDIb6g+Sn7tWba2L8yKQwT8E9aVQXPqB3i",
	"3j+0HefXqKs/KjbrjXp/2Gumv4df9d5rpaTCrtrzfEFzolxnN/3esTB2zsUZU5dMYa1vPgbfKdHQK2FY",
	"sN/7KM0bWYv82w/hlGlZq4wRIQ2ZQZ+2kKtnmz0StFi6BaqUrJgy3P2VQb9uVadSFowKO3yjBUt9uQks",
	"IKf/YJnp9XvXg7kc2B8H+oJXAwnjosWgklwAf85oodlNPwzjlOm6MGsHww0r4e+ZVCU1vVFvVkhqGuYT",
	"dTllKu7Zl/n+ea8ZIFWKLuO5PHLDDyOFvmLqaM6EibZLmxzZgnLR3d2v2IzWhSHwmcgZmTPBFDVSaTKT",
	"itCiIBWvWMEFI9qwSpNaFExrIi+ZUjzPmSBckHP4dj4ci9c0W5CCiwuSUUF0xTI+WxLFjFqSTIoZn9cK",
	"OJZQkRNqf8s5/G37M2rJxZyYBSOCXZtmOMOx+FCbmhbFkrDrrKg1v2TkipsFeRIKPRmS19wsmIp/I1KR",
	"JzC/J6SstSFTRiolL3nO8uFYWJHml/K2HfPStvCei4sUU7BLWmzccpe0eAkEsDXC+DZVe+sLNnVLej0B",
	"KXBtJkZeMKG7C/uBXvOyLomRhhYES9nVlFcsB0rbFeHskuUkl1ldMmGIa3M4Fr8smCCamX74qAlVlm61",
	"YDnZsc1oM1BUXNjmuNJmlxhJZtzAmnBBzIJrMq3zObMN/qzZrC6gYyZ0beU9ef/+g++SFLzkrg8reNh1",
	"xhiuz8+aafLi9elnnAT/jSlsRhteAiPhIobz5WDf/r9+r+TCUqA3OgjrZffNnIFE/bVmym2NNuGO7Jra",
	"nWBLLP2RoO3s2DXLasOGxJ6J+BkGf8WLwnKVUVRoKw4ciTUrqTA8I5pRlS3GwnJ8Jau6oIblhAsjgdN9",
	"uQmWIzPOitwOgdm9BB0N4xn+/WuPi5xd2+H/vcfKKctzLuYTnl/3vvR7QEtLh37P0CkcuZWSeZ0Z3bvp",
	"b1X3u6aqYpecXenezZctN8p/2fGeNidpycUx1jvobhyYXHcRrG7yRBNBTa1oQQoq5jWdB6JLS+2soFrz",
	"GWc5SBJe2k3N8phQvV8W1ABTWTJPmTZkTkvLewWtjARhljNF/vhsf3//L12FBNQRexS3thlIzN7oOXDZ",
	"irKE+8xI4ioiHyy1YaUVOmVl+oSCuPaijUvRhwlIEFxWrC4YtZx/Vk+NoplllZmSJelue9tRbtW20opn",
	"ekl5YVct7Kqw/ZyYhwp23ITPUs1xbTf9yn563t5N+6ndBNJ/E2NEx9QZlL/p96ywmGijGCxLi76oQLbp",
	"+1rA/M7OXpNQyW4UBUqAJjueKTJHWLfN+76Ep/4u4UIbRmGb/efZp4/EK54NF0QKjB2mrM2kWbPWUOEg",
	"Xh0ryFCYBLHnNzk67q48LLxiplbCCYkwFSmKZSM4r2xjS1mTKyqML/prTQtulsSNzglUbfpE19mCUDjC",
	"x+LXWhpKSironIGct9KfGoZC11JQZ0xQxaXGpU+oaY1e/3e3ZxsR+mVVdVlVSbyCRovi0wzE12Y2cbWs",
	"vFqRz0hDapt2xEI1YHXpuwecxo3myA9yw7Y1HIuxsCK93cIkiHNcKrtXKBeaVIoNXOO0IIpRLYWl4g6f",
	"EQYMmpNLTscCdsWw3eoQOD5U2rWHCddRK1wTWhtpO81A26mo1iwnRo6FlWJdHrLdgJyxI+SitiwhZ8Ty",
	"xHzhdvOKMnjbRDcqQq3Kn1t1w6qBRjRRYek3KUZNReAuVzNxPJ+67QESEc5HdyrnxPPlXU4p3+sGZfzm",
	"S5unz7y8aw/uhKkBrEZb0QXFtlk6ZF2vVQ8JaMxYjQqyoJdsLKwyJK9Eo/+SHbvAXS19F1ja1h6grs0z",
	"gjcFu5mPZ4Ri01yDYuUHxvI+4cZe7DUMzchqULBLVkQ9Uk2chEvxEE5mO5lvydWor23uuxu7rbRk/5Uz",
	"kbGNrYSS7RZm0qrEdbWp/htXLq59s1buvWyNq80jzTdiN7bWIJI9i6zKpjVkn2S39PDpkil7b2vKENDH",
	"AwPu7A/3rSZwMNzfHZKXUmieM6XJVJoFoVMOh4qRvjhsNX9jsiIXDAQ6kqUFuRDyqmD5HExEnRtxiZcR",
	"0AATioS7KeOCgj6iWMEuaXJ2p/4TyjiWGpnTq0EFtRswnvADxrdyDnaXIjWB9adjczCmRBySvSvt4azz",
	"toB4je1yIDsP6irMXd+ycdvdvl1hPcs0JVUXuZVDjmSrGvIWRgqrAd30H51v77+M24/5X5obt5+Gl3GT",
	"hic68zir53Om4aqRZKFwpnZuSK2Tc9tBJXfSLVslErtpgbrurF1Rk5y2BSeiF7V4AM64oIW9oTciL6FA",
	"klp781SjsVEdWU5uEdi2RGL4tTayJPOa58BHYHXDURgpWN9e8CgvCJzOfXfaLwvWuue+gDtfxjWKAcOy",
	"hbDq45Aci6yoc/s5Z8RV0PY6oewUgHnNMHXzXWMwfJkwFFoGV0u7WaXKmRqSbSx1j2J3e4gVDW/lE7yV",
	"r12X1t09XpzoKth9yEgyspkVy5eLWlwwdTdeLmRGC4INkMy2YNnOSRp/feE6/EJULXRTMOeKZaZYNpY5",
	"RrSRis4ZEZYtKiUzpnV/LPxNEjcnMLcg7Nq9SnxmquSGwesEz9iQHDsNUnPLVmTGr1k+0Pw3NhbBWDeY",
	"Unt9CaMBRhCSZDRbwO29MXiMxdOnP2uGpkN74x09fToWA3JaC9hodu8VbABjzllVyCVuyh19RVVJSpmz",
	"XVv+v2VNcimeGCIYy0kwcu3BIELPNFNSayCB9tXgeg1CF15hTG11eTu5a26WzQg9JbwRITHYsi4Mx7Ha",
	"PWCsgoXbzvevWF7b88Fe2cMAYMSfPn78vwY0y1jhTuRAPTvHoj3aiinNtQEDri22F+YLPdm5xbLiK5qP",
	"bUndG3233+/ZFShoFWxc9jfPSnazAd/1+j3NKuo2W8+SwvI9VXNmopr7N6vyb1YXxcSLPpqjrZ8WJ1Gh",
	"lKWnuxNsQwMwa4EB01l+cCJW9rywEtLbrivFtKXIDrtkgtiLeVmZ5W7fl/cmW7sPWI5MOcpmZkR0PZvx",
	"azQpgqE0D40/0cQRDk20vjM6tX2FtmvNyChrtUQVA4OO/Ya24UuW2TtWWCt7W4NNjBKDgE0ATIi5m72p",
	"bSN4tSMFv2BkKqU2XMz7zmJc0qqCP5nJVox4X1MiKWaEyJr1Xces6R8TUPWIyG5kOEYtH4aDckhOlKW8",
	"0WDK13AEBCaWM3LJ1JIUlnuaw9UeCbcb7Vc59dZBfwyDbYylrgEyZeaKMbDpaJbVJgxPD8k7VlSalJSD",
	"uSfYUp20QBEylbXIqeKsPei0bbTZNtF4/Q5aUcN8WYJHCZqPq4IbsNPtsOF82CdPxmMxHosn8NVWmCta",
	"LfRu8hxf2aItknXt11A4WmdHOru2MPMhcScY7iDKS7Q8ITtQZemC8tseA5tWdP05+Rl+/tpjwlb9ew8t",
	"nhOqJ0tZT6BSv3fBlldS5XbWVr70ewtTFr2+1ZCZ4pmlLjXMcPBM8NbMfq+wyoTVHSQopfhPvaDQZtiQ",
	"tkohp5FS2tD0SJiFkhXPVtWKLQ/0UD9oEZeMHB03B/jOy4JarQ3F/S6cjUcnx+SCLcklp+ScVnxywZbn",
	"/q1IkfOjj5/fnX46OX45OTo5nvz0+r/PCROXXEkBFoZLqjidFsyds69RMpAP0MPo6VOSQZcDLYVgZvB8",
	"8N3g2f6z7/b//OzPZMfxjJWfWEpWtQ5lDg72D8KXw8F3gwXlF7X99Pxg/9kz7PCVzKCbhTGVHu3t5TLT",
	"Q+oJMcxkuccE/LpHp7I2A2xvD0mwZ3fuJWdXqcPM8/bz/T9/3+9Bhd6ot34+vdXzDccAfFRWdj1qxXqj",
	"/eEPndPM0T3tJtMsq1urITmegdnN3wr7ZEaLQpMpzS6sPOqsWXrJUvs6nvjXjfK6EYFBXjtN0L97RJ1E",
	"wssRMxZct9K1SxR7bCMfk+NX/pbcUAq/GAmnppdv67t40nztsOCT3dYr6e0D7crJeOkT29goWWiiqMhl",
	"KZgGlSO6XdpL/QANau/4fMEUuaRFzexBcsGIrE1VG1JKe+uCJh5mJzOymlwkmFBWgwuiLQHghuC9uobk",
	"k1U+NG55uNw6oy/5KagU8KgOpuh6qtmvteVAYJs0Z9ghVN0hfKyzgtU6MYiYREcFXClA7tnbY0P7h9Gl",
	"VkV6a/58+r7Le3aXMpHDKUB2vKmij3cax/BWd7Q72BnXWb7bGmGtePL6F1s3cA+ljBsvaHZRV2t9dqbw",
	"ecLzxAO54L/WjPCcCWOHpdzZwlG21NWQ/IyvRkSxGVNgTYNHcPjqPEBA+yWyckxsddCXCyk1I5SUjNp7",
	"zKwuiKClrUyt5g3WBE3swbp3aW8eUhAuwgPQitrppgAbb7B/MDj4bnD5LLX77BW3eVZtqUTupupLhEPU",
	"z/OsriqpjMYbl2Vw+4WJXI/sPek9XJ5nvGB4lR+Rc/vHaG9vr6JmsWfkHrZ0bksflfQ3KcjZ4Yic68PR",
	"3t60zi6YGVgSdMvjs6EjaaANLQoC3hOWSrTvrhHu8bFkhtqfwzQCY2GdVQLCIMolDmMP72ID7FHv1Zop",
	"PYB6ew2JNzJkw1cR4dP8abJFxJ6rHpMmW9grMFOmT3JWMMNwkuFBMeItKy+pu8J7rxqnixwZWfKMm+XT",
	"p7BkT5+eYTG9oCp/+nREPjXN2KsUhQrengGlIpUcm/jguQE+a9sKuBLl3FJlCi+GzwbVgmpmr/glN2Tn",
	"2cnLXbTxYAeg8g+w/SvFjW3bDvidvGq1A/OlGQ7wSqoLmMjBkHzwq+0cOmkB9GaavHv/kljNVBtaVmjV",
	"YwXLjCaZlCrnAm8BtuuxeDYkL6NfcShxr0SxTKq8b6Wt4RmvqL16QTnCwV1Uj8XhkBzNDI7C/0p0nWXM",
	"KiZxt0iPVg9j8XxITuLWna+W88DRS5EtlBSy1sXSOcDI4jLq/rshOWWZxJuflBU6gjHtGsnc+qK5xTAC",
	"N3cKA47HNqO8qBXDhThhCkSPyJjjHeQct2ZTy6FMj8i43t8/zMh3pSYFNUxkS1v2ZbS88RKOyP/9bL9d",
	"9BhmgZOqbaHQ5uE+0SyTIoeV12aQWY7asVq6iqe7iyN+W1NFhWFMuwEfFYVfULcWxPld2pmSHeo3h7+B",
	"2k/I02DsetmlDRoPoG8QQzuCXZGCUTANMl2Xq0SHho5zVlZyZZpkJ6/Rx5itrJNdfk1nzM3rBRNsxo2f",
	"1amzbQlm7H4IVj5YXqrwZOIi55c8r8GLAt3sbN0P9lBisxnPuB1MsPbs1FUOe8d2jUubw8iPvL/ELZty",
	"wUQsjHRFneDQXoyjIMPW6wr/PSDsmoONxarz+M1OxS6YYaJPLGXDl0wxarxTaXRHQdEIDndWYo9++JPV",
	"QOGfssgnNMtkLYyVwG4MthJ8Pnh2CLeOOeuNDvft7ZTywrnQ/9X1YK9OjS/+f8qFIK/Qu57Ooc8MLNnu",
	"LZmVvC57X25c/8+/+z508Oy7qAMq2JoOqGDkrOQQANDp4gu4lLfVmDD9ta6WwQP1+JXzabM1huRVy/lU",
	"sVJeemc4lGFwsMIp8lEahgf+RykGsGq2wbA2mhdMmGJJ+FxIxXJb8pXtJjCzs4KznEzZzLKgZwhvMrda",
	"ELCdrfuTb7hiVv5g260RehN7Y0lcscRu5obtHt1uWnyTNrF2/L49xZ25EQygVE25UVQt0apg7y4GTdVL",
	"WSun0+CLSnQnaNSF1UtolVzbds/a+b9csKUVW5bQ9RrdtjEVwoq/YNperO0Oz9zS/wxnudDN4lvdFT3c",
	"FsyKPXfDHIftNe7Zv+BcK5jdDuPerltfUjAxt2SZzeBgjhe0ag4eMiAXjFV2gKV7FaRTe9taSGVarKKl",
	"soKpYNc8k2CzQxevPtGSZKh4V4rN+DU8SlJDNOq29s44t6SnomPN/7eVEwkGskrEBB46N73nnS1F9h4K",
	"2na8unmbjEnqpJaxuBhUBc0a7iL+nMHH3g9SzOWrFwN4dXWVpUKp8znVKHjZg7OmkaSUOZ8toxfk5omN",
	"5gP8OkBFTVHPx6vqblUVoGSBKgAPq9LJJFAr4dD06m40kNgi32rIKs1ww88Y6Ez+BuUMp3EbO3/kIuuT",
	"P5Z1sdsnFKkZf65qveiTP1Z1AQXsFUeievZSlqUUYNixOhFO7Vhkirlog1rAq9gOOJj34U1D98mlleSw",
	"B3+GdWjUZNtdVivFhHlFDb71fQC3VhyYJjs0z/dQChPLc30CMjRuTTg3B5RwfjX8oe5f963oUQ1LrAju",
	"rz2wAQaxYbdfv9eQBYrIqjfqWerZ/UTNwv41RF/6fg+MQ73RwU3fF4wmFlcoqDZ/4+yK5eCE6HsOm3JN",
	"t3ZV4mZgA4Zue5e8ss1t69If2HwbV8l+7wXLlcwuXoMp/a6P3Ue/nBHXQPM61n7shnucLZcpBocELbxD",
	"aGQ9lYocH30gShZORUgaveWCKTaEjgZMzAuuF4PL531CwRAwNNxQMcDPhl2bweWz0f5tBu0rPXRVM1nu",
	"TXEie/YmoQ3c1+c1D1btgZPvLB+6p4vYsu3t2Okhto3YriOIwJwjeWs9YFSbwUGvo5GBFjPR/DfWMu0e",
	"pOy3UBZec9BCGJYkjoyRleGlLWIWStbzRVWbjfbk1Y78ogdb8apROE2HJ33y5LbF6liF15IzEfwxT5qk",
	"Pjs2xe+Bc/0EnHtEGHhYiNWhNCuU6Nz+q5oIdjUpuGB6q3gDiCAxEh4PK7ibQN3G4stFVRsMWnJKbljP",
	"4WbH/1sMmTj1+z6HRVs+/SAG+/cE/9CEZlZRd6cr83s/2HX7YHbpO1ten7yEFe+TD/ZySIso2ma9XIge",
	"pta+IgwuD0b7fbDoDYuClvRwcDj4YX864EIbVWfGFXDcKeQlHVRKwq/fSoQkHNAe+lD06Bt5a9qu7pet",
	"Kz7+Zh5+0yejf+pb0OO85gwfz4/6FrHCxfwMXv4bgbJdENEvbNqqaDWnLV9ybacEK/t3XAi+0MyQF8cf",
	"307OXh+dvnwXv9iSS6p2UxziX5faL6h+u9OKD6dW9JY8U1LLmYEdf/nDcH8PHR46L6owuNa71c+n7zc+",
	"SPV7M8X0wvJgd75veGGcYbAwmkyXpCncDw4Yr8C79xfGrI7xQQqzSHhGJOJmNvt1ffCTJzC5X9g0or4T",
	"0GfM1BU42B0MyUsws5Gj32p7pUFzCaEmSFErDmkxpPa7JSjaz7ESJfHyeh9tsI2/ZSast/P/dVAIF2yp",
	"bxHY7dVjYlDrPbusbg0HtOL4w+CKTQf4Y9ufocv49hJ8LHJ2/bdnDeuvyHVWTqQoEhwcaQJW7paslGo5",
	"AP8zZ8PonvV38Ny+dbRnhpoENETO9cWk1mA/6LzwWcXRPc6CoczKyenSMN1ibC7M98+7wmt7P3jmQTxW",
	"Ykrtz6Rk2o6O8BnRdgr2elrk8PQ7ZY0r+AMiIBSb1rzIQ5hrcsUaEmjiboRgVwxV771wVsYbWkycU2NK",
	"1nsdoDFWONMn1HnMxUhykZTFG3sr/y8fE75yaZGySMOLgB/kpjvsCyhkRaHtI2FVXX0ktd19WTNORsX6",
	"Ud5pLIXZHESHXVmlq97c9ksp/lELePZo1ZsIubHuK647dfXCboS711yzxNrcfuU8IqBMWGmJ55tTTWvn",
	"zZCzTDGqGQHLnfs3+jH5SBydScW0ZWTagCcE1s1lPYXoCVEXBWIcoP9xR7F6oegl++erH7bXtfrH6dHf",
	"Xm+ledx24PtPBNlvRKr8x5wu+6S6+vGKsYs+qcofS3vG90m1/HHJqIo0gcoKwerK/k9p/2eZdJHUFSuK",
	"bMGyi22D+psaRGM0kos9SuAJsWszyVkmg+Fr0+XYh8HA1TeqSXamsoBYWFrwDOLdmNK76bvw3XWb1cXE",
	"h4v4x8pfaivFL2m2HMxkBrzuYvzhYcZHA1s5XDGRh2fRlHp0xueC1FWsEU1tj6CdOO2DVnwP1KKO0pNT",
	"vZhK8DpIKTxWZcU2hk2jtKr2/JlB0VkgqdQsDTulYr4GPsme+GscHR1+yLMYTORZ9xUMQoVeejyhts4t",
	"xQTP/8SibYM/ZI9CCIkCKzYtruhSj8gR/Bein6C4YnOqcsRHmhFZm0yWYGL33Y/IZ18W0B+WiPHVeNi6",
	"woaXTNamVdyZ/fEL1tOuuL2nTwDOIVGjwXoIlaLtjFPp9WMKNQPAP5rmk3u9CdHqPr94jx9AhAIXoIak",
	"GM7eDmhFoCgq8gYYqgtfEC/xxtixhiEeGDAGQ9tU79QWiiLEY5Wi6TylV7xcUHM7hhfNsrpE8KAJiu61",
	"1zkwkvnCPoKbXXJZQ7DiJVMapZSplcDYE6ZZ65HISHhkdygfbVCK4Vh8ZFfu/ACfKvA2wacl8EIESBMf",
	"ZUPzHBuETwXXpuN9vD0QF07wrGLZY0cE3g1XC+xktyNp3R2Wyl1DdNKe1KzagtuL3LIJ7wScNr/AvhGw",
	"kK7EseBSk4JqE+48qOIRs6zc6+I0chKuNZhfV96/Aghh7w0Hr0bi3sI0Ae99UkKQGyMFo0rgxUXJwqNF",
	"gkLUtHGMSINEMwgB39TWkPwCA17KGgOhSobgY2DImC5JVU89LiJ4qv6l6Z1qzbWhwqwM4b+Z7qPEDDMH",
	"GjnlpzX2L9uHrpoPSOMUq66FIHthdVqEumoBiWhEHssA1ApARGCDuSdmAzvYNToWGHaJuDUN4zgu6MMu",
	"h6PO7+GW32ZwB14PO+ZIN2kCZtLQY34tvxGA2FbIU0G0BtypDcG/nwK+wrooYNNaCIRaaUd6gBc5DX7k",
	"8TLQgpwevXXNtTCXmkP1cZGxtnjc8ZInlqG3gzxFJ9bdIJ7cfwerDXTRnl42vN7Ceop5WhtqWJ8YKQti",
	"5ZfztA4qxQrKkz9y7EXziqBCre1GuXJGmKygKjg6AnAOYBGiR+/xjJzbGlzMJ62C5wQisBmGggJ7FOC/",
	"6KRrznVV0GULCmIsCIGxXlGObGUFjHulcw90Jb3AOGzEh2s8p5/hYHB2id5XT3kwKTnn2iFYPM/dUe+V",
	"iXM71iv0MA1iIYO3uBBdEDf7PwQttQEh6qyNo4Z+ATFGFGf6G6JErciau2JERcK9QYg64yUvKBh0V0Go",
	"xmJaR3EZdhM0QFCtLv5VQZzskLeS4J9twdvAl+LzNnETCSZe0d0gTqFKXTU82PLK85q9Ybmv3njtOki+",
	"PsqC3UFdOLXFHW0mINNSD3xe3pGS5szqPQB84hUcsoPqDCB5+d/sOHbvAL0BRH9JiyIJhWxHtx1SGwhn",
	"3IVodgljgy/3GtYt+zI+2ID0/bCSX25nnFNZpGB+ZMFWVploBtihCW6KbtegMPYjrdOrHj0k37r7dEP3",
	"BCOHky698N1druZoz78bBMORr9ZAELqwQVkQqskFWw7AoYxUlCudMvncMXQtTCy1hdCvtPNqQcuwMlB9",
	"yhD5oigSrzWrvAEhUAKh6xsqrWMRuyYfk6M4CtCrMAbbok6riQN7GZ54w+tRHgx9/sDdwYjuTAptlL28",
	"ofci1RdtfWNEjvQF6gsQgR9/sxWw2RF5jUffKhgxhkldsakv545NO+ArNiU7jky6KYPgXXMYzowZW+mN",
	"/Q8EV3pRuKNr9Cg3kmiW1YobuMWAL8Ru2/IUCAE7ZGV+ADji3sDDEHr9HvR867bZBlfNiSKrWLW4rr1x",
	"tn0xbEs3CMNJMR/ACXtFeett6IaNQYNN6G7cY2rrhaMjGT/ahGI3wsQgEKnG24pCPTm3u3LjPmp1FqZ5",
	"2z7S27uIRSoR6AqgyVvV14GtTuBX0IAB5WVPltwYewXLG9jjUbTv+t3d1HfbAtp+Y1cXPcvACx+xhLwv",
	"fghbdnSLgDk+gRvYbn8sqLvcOfSjGS0KiPnnGl+y4BaDXmK1svd0DBCvqNJczFOqWmuyXbK95xr1EPsZ",
	"wMqhPNwRgCotahBPiBUiYByiI0Q7VqW1WxM788sdT28QpAmlAva3EzUbTYG2bNt+B5zIDUu9DH3X38L9",
	"ze+Gpg3wo7c3qOFYBFgbLmZccMMgtg8fyltbEukXHKKebbT8rYrZTXPvPDGmNeIVuLHmfi4F2+Km7oCu",
	"2u3Ya/rt94Uu1Bk6r6+k6Aj+y5tYBlo68cVXpU9o50v3Te6I1AJDVLv3LZoAU0v7YAOyWW8jVJZBaqWB",
	"sZrlOInm3XVG7IzJ+fEMo6OzRF/vpj8H0pU8FuMtvjaY+8hbFrraRNsW3BFMDj/iFiNa4WSTDiCTeO9s",
	"VCRQY0wIgrId9u4S/+YNKmsoCrMBa2cA4TTSHgLxrBKHtWexrV2vQ2eR9cg34w06EGfI0s48Cah1vTY6",
	"f+2leku36/YVvoOPSQUtlr85eEywufTHwgep29/A6d892SEWutVYDZsv2zjrutE9kwbmrRLV/GvhTs6k",
	"ytgk5O2wYmJjxJorDCalD7ZC044j21bWqDNf+KGPXXVh+KRaKKrZBENOYz4/XA+nRiPwFnylgFa4mLf8",
	"xlv+wJuPvxYs/vYOHevA+Nl1VVAu3J6HJ2VaLDXXDkEViehAF1oq9C0eH6t7Lmmh7LDuf+FLTnu3dZ9b",
	"GtW7nOLA/fPrkjCxoCJj3inPTh2iWjvTcBqc224uLIeue0VfD1LeHmyEyPzPBi/2aV0mazLFuNPNw/+7",
	"QGZ4b/bIfUnQVrKzqEsqBorR3CrKuw/w7Iy3UioENdovzU5x1y8cNURWXVdUIHK0Z2eEcACL4iMDMNtj",
	"prXXWibqR9pTzsrnsTgBgwH2+cojQSv5hbvnPGQ9lKwNQ5DATd4atiRgDQJQ40PFeWhhDbN+cmFyebTs",
	"CAS6t2KeAVh+MKhg2HH0TNUa5og4EETUpZ4oBrHET/pksaykWTBw2AhI/rZI/OHJA6hslYSJvdSum+0L",
	"JQFyxJaZIzJkM22/ORMsEhiJa/Ik9PJk90FjvecJq+vpbbDprxg0Av569XQQSm6cVu4rPtn95ujq0Xbo",
	"yNMOz65ug4h2rXwbaYUUcI7fMVqYxXp8/wV8h2fbOshBh5Ecm87FhZBX9tzCCnYAtWj+nbO5ojkm/AI7",
	"XfryA82eQV+b7G4rVvPaLCZOGiUMaCLniOTkn41teWYJFzR/nwyoUbj9HBM+/LLk5jemZJPWcRHoePvT",
	"Wkz0xoXolvuYt1ziBRMgwgFj3vvb2LG2Fmmj/c8NNckUEH15v1hwrLsuDHwTIOrLT+9en76+JxrqSnzw",
	"4XA/+Gj2ycH+s+ck56Xe7buCoAIUXMxrWkDpW+KFXARyJsu9gM2HoN1t4wO4AUw84dE25D3Meg3OaXek",
	"7dBw7K53NyhTR/mAY/qSCkILDYn3NDNA8zZ9t0cujecVu+h2p7jysO+Q8lzGomUFDz/oLGE5RobTNULV",
	"jgRKt333i5d8K2/a9gfYW865qeuZ3AVHTS5Gl7wierXqMHkMidoOgE223j0zVC2saGqP7PXHV52hvJNX",
	"tp8FFXnhgsM1KaSYgy2D4stmSa/R29Hh4cQk/fjp4+tev3f2+ej0c68PfXy5PxwmUuKeQeSOjGsBlWVZ",
	"IjjJ9ojKDxIgGXY4UIOqqHULQtl/af5JB/uHEMJ8V7GRLai5AyRya0xJMfFQDORVwbEBAPm+MmSmEL9m",
	"OamYoIVZphxt4INzMrD8Gyo9Vuj1/xwG8+pCbiVi1guWTnsdgqMqm7G70NvXebRI998hmv/dIZrveBac",
	"Mkgxfb+jQEHlf67aiH2m9cbdvv/8YG0R20m/VSWG8C+uEDZ5SCYVU1ZB20acupwTLZAzywFWf2l+Ad2m",
	"DW9zu2hNk28r+dow3HpJm26+q8PJaiJui9EupTYhgVcUsQ3Iu/BY7Y/eADDdd1/QwbeNSOeCZlNUusOW",
	"TeTY3Ma/I5URc0heW+mMeK9ovfLpjqnIxyKAM4S4X+TJGsHLgf4ZLfgUEyhBHpVMQk4VQ/XFv+/T050S",
	"ySVJS2hVKUnBf2M1hZxm6hJl/gCjYeb23ws+X7TSMs6i9IYhvRjNcwW4TJGHexoUJbKp3PbG42Iaoo7d",
	"EiaDgu//GHaTZuZ2QPsDI/0z155uBb9uFfV/q3dr025ySwLqyWdLxrVRhS2ar7UZtV9LSFQqOJLBB0C7",
	"NZpUtaokxPW5DOaWHVtBwi5TIS1JJouCTqVKZhD4WTNlD3BA8Mc91VzvcV+3TeeojLyHu6pLcpQwQbg4",
	"pvV4ubctDWCdNE+pSdxbhPHA1AnS/dX2xyfHOApnJyQ5n8H5bnzsF60wGS932Jlv2hnQnIvpiw/PvnNT",
	"t4X+honF4hINgTCOAFLZOcjQUua0aJXmJZ0zvUfrnMs9qzNIq538t6whPTXN8ybRgq9mZPCOW51ERY3V",
	"I3UHFDssIiKSIEhMyYQGKh7+6bnPxYR+Ml67oUUxsPplUbaVGgmud/F2uRBicrmPzzJg5gn9uBIhMx0U",
	"SwkBUZcTBAm/7SjGEuC+giBDXg/FhA7kFTUUwnOoMsBqLPdY7q5qiNWzeilg/XpkujP+mz2y3tY8h1gQ",
	"7bIMnpVwhlNDNTOa7CAY/cH+/k92k+ndETkYHAaA8wH5wHJel1EFW3Rw8MGXPhwc7EfF32NmtnbzrCl+",
	"sP9/RujpANjupuJ4ecrsssPNoihYwXVJXJyKQ+/wWR+JSzgSSMCuK5bZIxvzJvDfUKZ0uMlSB7LvGQlu",
	"1DCIMxgE0GgsXMJM7dFtnz6VwtLQJYxQzGVj4FI8fRqQYHN5JQwv2RBaLaOpQZJHxLANuPV+1tcA3K8d",
	"BCbTC1nkmuyEDT8tEK4WfQFcYoFADk3yGsQEZsTD8WEezQH5yMB3qEPPmc8EMVgwermEvBOFpLgkPztU",
	"FHgWsvL7fC/Ml5036GGgx/D5HN8vHIq+69+nnRuNxfn5+ZTqxVicfDr7TPYmvtm9y4OoXSgXspEy8WvN",
	"aoiBjEkd/MzAtRbibDEzgcdf1yvJJPrNSMYiIhC+OisWMP/hIcMyjV9KD8QJo1V15Y4XSDmSW70ZgqQt",
	"K5LXBdWGZ84ZHvfY0TqCkB0hSUkFJi4I+Qn8sQwL/QlZLYDzQh3PW1ACnEcqqvASj2H3PrnCDuDWK1Za",
	"zRPhLjkcEbXCnhp67rYF6+EKSlPy2oPn2EbUX8u1Z1g0rSOBuLMH9FrlggtuOC0mlSx4lgx27ngJuioA",
	"rM+1DoaPEIy+rRp9EhpAWZ6E+wl6dUW1hmyC9myK0u9k6tCc/FXrq0+QaTAQN5RPqBd2mOlwlZ/dlzAj",
	"wa5wVva6FpKHO7tgRc2ij375LiqECnvhdg7uRCpS1togTn+o0QZpbObyD7kQuWQbH/PCzFIa5Ssagbis",
	"ZHpVsuw+Ym/xaO0fPD3JErfhB7S7Mjvo5NaZ3TWauSFJ18U5ONZtuFWHnA+JiNLQ/hnM/FGuIz4x5qSi",
	"SqOGlQKvbAH02DoDl02za5Bfg6pmdW13IZ64BtfsxOgq11TRhiqzXaVQdJsBp8RZB8PsoTR27T34ygcW",
	"1fbMPIjZ7ebVZgRJhpfZcf4oM+V5e44b/LU7QXhrxwe3xbNwWq0638wA3RrzmbtQGoR9C+Y/5/Vyhxvv",
	"Uepu22ovacNsjtQ7BFiSS1rwnPzn2aePBGdJcjspD0Hlu32imwn6PNE+kggulzOmmjxJqgboFOGSHMCY",
	"9TCFyZXcBXV2Yf/vrfxW0HdCTgDtfhOkxSnmcXj3+cP7AMi6Bsuibxu1qqCys9jU8NkFr8i7z59PiK8C",
	"x/GUOsdGBAh4FAC4hprkWGAINkbTBzS4qETAggMYFcBtYiwGguuk5vfmeJcNBy77mIvfzeN/kZIuwQyM",
	"tt8GFsElGfPRoE4v/igNGz19imEAgGBi+bA7dHK14NmCLKgbbPDnfyNBk89r9ACtNetjSh6r4iOEhb+1",
	"+z47zx51dmH/by4duhxP48m9ztNx/rZg3idXjM8XBv2AhXNI9Xm/g/G7awPGHF4TapIoraiXsXzOyBXV",
	"PuNXC19y7aFzB4dilzbwbuIkaNIwvNDGKuXu4DUJFt40PtH3zwdMZNIqq84QH2TkBVvGBEni+t0BtRYi",
	"qTYOAot9s0EEZ6WWfdrSGfyQQlqpDJJEQk4pZ2ybGOlyTNVmIRXLJ9PluPcQZ1ZMT7QtiwKKlavy2HyK",
	"W2wNYfDj3haxA2u0mXu6uzquDZzjmg2j/XL/DWHn9QoOjC6+ZN11WAtFrRphFwSMhGDJAjsSADx+qs1c",
	"gnc9FAgv/0LmYP7hYkSORSbLpozDYfAlptIsRuSFNAvbIjaGSefiWq3QexwtF5AXPwXlfjeafF5WbPv3",
	"PkoCQA3zO6iLWVEU8mqiWTGbQITtxkM9Aj3HBFwRPSnQClQlY5t8CIp2Sa8nMd+vAzL2D9YwGJa7DYkV",
	"H4/34WqQGs9+ZzzolPHNx5O2ezSiEqwfIaePFZdP+uRJIyyf7N4WizmJj8ZVddHFWTYpljHHV4AXibnt",
	"nneVtdYDO0F96vy4uvepKMCu7Q1kaBH5NCDPoqoWI0hEtjsosvWNEnSkrZJ2dT207xor/lbKebHq6b0p",
	"VvxvTBl2fcdKiLNw10oVE0fHd6yUTmW2qVbS5/0hEfC+qccPgRfrvOt9l9obHX1lj15hWFlBUiJ4+QLn",
	"A/4bIwt5FfmWUMXGArGRjEMQSiafIp9Da7Vm5B14JE+p0kQvhaHX6PThHxkvqQKg02nNCzPggixYUTUX",
	"Ct8WOcOM72jOf/r0DJp6+nQUt++mAWZ9fwNZhM//0HAHwYxLu9jMS4Ajndt2mlEDcm4MkUsymi08reJ3",
	"IPL58/vgEzYi35GSi9qnPHz69CX6d7RbVyxj4Ii3YGRWR947hGofSuXyMHuSvEOSuLewgyF5+lRnqp6+",
	"M2Xx9CkZEHe9Rk7ZwzAzQ+doOWDXRtHMkMyejrhmcJLayzigFp6fnzdUgl++fg3tE3u/nzhIoJsbXwH+",
	"6zvW5BwfLXEA+MJ4Dp37D3ZI/nc7Mlf/KM81EewKc5thhvBpAfkCCxciu1P1Sc4v+2RxMFh83ycF7xNm",
	"suFuGAI6QkE8I04P1gk8VtUlBGHSHF/fl5Z+zyz92K9AuNfeEQlzWXPd+DH5q5peS6M/8BnZYb/66Kdx",
	"DwEWx73dm5sjxFqsNVNfv+7xmaNcU+mvF2xpbxZWfaIF1DnDf+NZF9dyT3GHduAlyzmFsb9l4idur0nG",
	"YZnCJ+fD44Eey8YxwK3h2ulg9VoVP4LbwCtq6M+nx2HgzWd7AA+hzKRWRaLAOKRFitLJ7kGN4T+q+biX",
	"rKMPbQX3mrk3rbMLZlylSqyrNOMFG+3t7VXULPaMTHTiiEeIlRo+wRrgXJ1hImHYVsBK51bVGJ2TAcEb",
	"KfE3UlBBfj49DkmHsSR0tvePis3/1xQq9IfD4blnzHNLhNHe3jnZw39r+GMAaZF+Pn3vPGCat1qPuwW6",
	"Vc4MywKw6ICcu5naBt7LDNikYB7MlpqF31LnQEdb7OxwAGxt4L3RpzzeQf1w5AquEvyCLc93A8Gad1Mf",
	"w3qCT7tczBu6PX16DI4mVtC9kleikDRHH0UNMTw7fOaAVyFkIjpBAmFDSyev3mgUmNfGiy58HptxpQ2p",
	"7BwU4PWx3IpMWIRQ3Qo1W/3UezeZdjs+D/BvvCioKxUkA/KIRzrzXuh+nn5mIcW4QeeG6TKsXEBJ0wxe",
	"lzXZ0YyR9r3p1Lv+7o68FHR6/EJqQ64W3LCCa+M+nih+aQ/A4xOUjHC6VR676Ozs9A2hxtDsQnvG8wNF",
	"Hwaw6enolDrY3//wolPWJQmICx7uhyZhfUlw6uk2+mz/+Z+q6z5w88Ctu2ejM8ZGTdYJ8OQYcgku0Xst",
	"NeYPnn6DQQa5DcbiOQhr2IafJTh3DMhr+BN5hwvy+dOnjwSZmux8lhdMDD4pzoRdm08IYPdRGv/Avkb4",
	"NV3A/WKI940gctKfXRTVB8g08iM8UYLpXpgfn2+qmjO0DKsfx73x2CTF1S8LagjXMMO/OC6E2XJNKB5Z",
	"memv+vM5UuRM87lw/rIVhS0bw5QB+Ywk799/sMoWIeTYNGbrp08P9wff7/+HC/9QzFmBMRqqogr3Lzx3",
	"XC14wQI6ve0GnEzfv/8Azdryii0c59AsqxXNlsMwy5/YkrxhEI4QyeKXODuvM+K+PR+dw3RW4Cr9NoKM",
	"1i7Tu0v/MiLnVt34+x8Ov4wI5X20kffLwmswn+m0LqjyVAPgZsEhDzh6LXmK+V6awH9b9v37Dx7pDfSd",
	"2gombSigSrsaHxxlNK7Uqj4CRHjBBJtxo2Oh+l56C30mtdFO08vrDGhvlwWysJGSUaFJAaXteEKN0NIb",
	"ql1eQLjTYlPvMfGqD2RyPjuhDjhhZV6DJQPyhruQmra7OcClQUghyIQwIzRhx6drvFvOyc5UymIXcTP/",
	"4HLlg8UHVhEu2RpTApzb1TuPhI1RNQunLG64c7LDhdkdgSOm90rVFc0AF18qnyscL8ktyRVaClvynOyg",
	"DWF3RCCNGdGsopjoBCwQjmd8pvLQlpCCAVo8OXe7+txX0M2h6kNNMEzJE8gr1Yabgtl5mObpxUjvC3rm",
	"nEMJIWiEHhHIzv9K4hmYZnb45G0peOoQwlDDHZFn7gd7tOoRef7dfkcSvXLI91yQ06O38Krk5BC8bbqv",
	"0R4Klxo8qgEQBOr616xm/4fzMOIVaN0FCXuMVH+CzLlZ1FNQKY2UYoC9wr9d7beSHFsKB//kZGVaVBdM",
	"X3CxN5dYuXXhdKvkb13+BRuVtoiWK6fJZ1w+q6VikSEsqJXur6hpf8mpgQ+f6VzbD3+AgLCmIp3rm5uv",
	"X+2xcXPTJ1+/7tkCtsZYfP0a3cncUsHzqtdFnM5jZ98Z5Amylu1T0BIH19gZRq37X2SAgLdeW/hE8YyN",
	"yB+/fq3sv6IhRI7ImO7KKg63DiCQp3MDSQwrGkzU6cvmtuZ4sPF1jHttdWYvYriFbm5eLG3j/q9w9Wpu",
	"axk1bC6VvbFVipW8LuHG9v/9v/8POcG/vYIcVZ7KfBmN8unT11EU1d9cFJX3Aj5/+/rD8cfjJlZt0CTz",
	"koqgQY4cHUPZTyevPx6tLYvWsbjgi6Oz15OfT9/7qw1cf5qi8TXh6ORYY9X3748+HE3efTr7bKuhnQ78",
	"MJmC+u4q5G45hb2TWAV2dHDw/PD5Ls74uLT3Lbv7TxSDbgC6/3Xw+ne7y7ukcyhP2DXXUCsKD9gBowUO",
	"uEkEDnavZTB37VptPIBqjYVZsLKJauGCLGWtogMM1Qorw86b7CfahRA6BL3pEjCzQdSNRWNii8JRHche",
	"jk682gEBRfE07pmnlejNsEqv5MFtcobiZQeNcwuGYT6V4rZQ0MLBlPGL7XE1AiyezIh8JeMemmGg7Y+0",
	"dKaYcW9E/j4cDvFjqIIfh8PhF3Jz3oqOhOGen5//Q9vev1pxO+7BnrJNjXsflsTLyXGvj5+92QEKBCkK",
	"+YuGw1AqGrAt+RWPpHGvXE6QmOjyDyPeHx70yf7wmf2fwz6xA7XFb8Yi3mw/a0ZeUh022Ac+V2gbxHck",
	"l4QDWwddz97hXVRKl/9sEz/rFZ70wd9wCWTXzj8bL+VQo+H/Kub/BBe3/SlWOn4BTqFVuHrHY5CzGbgn",
	"OzssF/MQrpWIKLV0H4Tag8OBLgNadoi/qJigHOzSHWN1MqC0a3ZO4JzOWckF7/V7cPu/7vV9nEffd9jv",
	"uQT5AE/kIAwAHjWF2BFkSBzB032sQZjWLWFpozigJn5ldcZOE2tKbMJDjGNftnkZaEYRPDFX88KBL5gM",
	"pt04igrxVu/vrrJlJmouBpiMmjxOMup+T9dlSRX/jd0HAtO/YHTH3X0fQMuoF9/ItWVl9JCcMUY2PByg",
	"VRV3WsB7bDtnv2NFIfuRrRcSG4x7/ykXAtQG+w9qFlR8/crArfnr14+ghjnl4f8g9jykipGvX4+sHgSp",
	"yzSRRT6899p2/Ek9+35Z+4LoN9fvicAfnIfbawTfKgu3H4qQOdObH6eh2D81Jfhrv1Br0jI02+dIuESq",
	"a3PwrLDyKmRc1OklLbZ3ZuEY58MwWN35+mCwmnO1HI7FUQ6S9/TorQuU6ZM4yR2c5VFip9OQ46ubBQD7",
	"keqWFABNGUADqLfOrPnaV1yHzY8ojhOj6s24dG+h7GcoetPv/aN23pp3lNERuvimoTvjUcK94Q7eTFE7",
	"a0KVHAxLs+BTtqCXXHaR0duprw86Ljk/IQANtPfXn+wdXvFMg6E+41bM/vWiTxTLaFHYf4k8m//1YreN",
	"q7wRWNneQyYhJrHtIzTsZEQ4y+wpFYoHO/DejPIC3pdUyYXHR3sAOg6+HEw0y6TI295dhx1CfXY5j1cI",
	"zwXx9aOuDzfR5GbNpl+LjX9mqMhpIdv7PMbLx7BIgMv1b2PtyHfD3N2g2ZvBobsWiPbsktWPRToL2XUy",
	"pc1q6ll4HXG5Z1d9nKLkMCsb+3exsoVY6ffQ+Nol0dtwpXMoUlbNdvAlZCckooySBdNiYFXgpK/bOvBg",
	"xefcNgPf9xD3MOoo7Tbn+GPCUzHsx6805gjtcBG8+EZI1E427d7fcy5isS8Pk8/rcNZfuuSW7U0KZTsR",
	"QO4In5Rr9Z6oEV/aCpySFwVvpE4qtlYqthVjnWHJcItZblXJFV0rxc5C/wnJrolUcyrgJWq6DBbKDn0a",
	"M9V9ITLCpod+uygZbxtDmHenQcqRnRnlZjGrC8G07jf4Ps6DJxUJEvj0W432dGUjhLHi6dwn4cjGY3rt",
	"WNeuWsMBK85787licytH7G2EQ5C6R4+gRRFJ5a4LNYLHT2CsqZx18BmnsrbJzhHfOcpdtrNb7jHxybGg",
	"ppMfbUVbuVtjrkYa/87QYgun26ZFPNW2VRiaQ+2WhIChdYzDG6GhcZWh9NOnIeUeic/Docf4shJ8F8IG",
	"kOdG5NRphmRAZu7VBqV5AwqmG9luawYuHZGTRsfs1I9OA0dkqgLQlrENWR4fkY+WNwoQJq+4htdXlpOX",
	"dVkXiCH1lnLIRVgqNSIfGBV2zLxS4Ip0SsUFfKSV++g5MowNafX+/YcB1QM46lPkwg8uOaGjkJMZI3Ks",
	"/Zkc6OJjMP5Cdq6kugBQ/faxTIyUmOYwEkVxW7hCGKjv9K2/2PI+vzKWfyVZqDGriwgiC/vHGgt8yIyb",
	"v2JFMWjcLqCgpjNmlnEp+8teZOSHYgtWVIkB16CKuh6VYplZLTGjmUMwcwX+QnYgABABWTDAD4iSuXC/",
	"iRPcI3KkWPhVO28NGE9kykWuBSHlVrfX71k+srq7UqDBV5A70K1dD0RLID/YdxvqBnMvlkTqAFZ8mD8U",
	"CXO1f60MPG0ibh8Ft2aRpERzMY83eUcI3y+U7yiUbJpu0jonw/qc8LzFBrtoaUY+p+siuu4lI2sxO0fC",
	"Rtr2IILkIILGUdNB+UpESydp+7EuWThdyc7+4GD3YVijHRK9oRkzn0Lo94pWSA2bIPzS1gEWMfhDN03U",
	"WlAEgTO9a2+OQGs71Pw3tgZtIk2KRpd+RFKsS8x8G0EAqQWT0XQP8keg1voxGabK7dv8zFQZUy6ZFtup",
	"HdutgtWFPlWRur3G2NkF1khTUsZthWQalWYKIxStBE2jtHcHF+XX3MIWGucBhjSemMoUDCGaFHy6pzNF",
	"K+9dlTs3Uu8G1zxVDolzukbcu3efP5/s2f85i1ygg9ssYCiEtMfgzgJOSWTHvXRpolqOvZeckrkcRB51",
	"cKydvHqD7tFRRVt+F99kscmAoKobN2Ss3UQSQCN22sEreOY8FZ0/QkyJoXMB8WVfRmrMOhffNf694Nbr",
	"nHzRbzXt1gvgU86i5jMzJ4xOLlBwYntPHituPJgSrhlpk/w64oEmCy1kgLFNYsiMq7jDrjNWGVKFiQFG",
	"v3chIH8f9wANOYoNcFHVFW//+GUs7pQ6Eug3cf1O+BaRpi8g1sSZ/5wbZFgOFFHdxRiOBdRj+YgcPPth",
	"uG///96f+uRgP/r3D8+GB9/DXwfP+uTgz/bPP+Hf34/FvR5KPbgSgCwjr00KB44Z58bd39/fXxfD6je1",
	"c5O1Su+CgnO80mTH55vICZ85JLxW/q4Yb5leT/y2n1iWnODzXttO/vxP3/3w/frR5C2e9k+EHWf19JXw",
	"TnbnVUf3tsV5K/EOGZPPKpalkCown3IIh6YhM2lVof+Pw/5oQElWELdue+r30KOukzQWLx4WqdfQN66a",
	"KwACif06wugnkCGC2SugISz8Mjd7c8NG5C14JrkcIjtSYREQSIXZK2wRdCTufresRrnQI/CNAwdoXU9x",
	"wO4KO+PXI3JmqHKeS3Djs9tuRF44fA9zJT24/w6+segFPONOmfMV/nvJRZ+U9PrLro+y/xsU5AKR6NL1",
	"2hns2a/2DmPvH3MD/2P/CRpvAf/0k8Fbz4xf2/sN6G4QfJ+6fkCva1cDx+QcjfvOhtEnThygZxtMD6y3",
	"tqc9LsIa6t2OVRY5KOIDP4LUy+gbaaV1Xd0N3jvymZhBA4O6CvjQekhAOaDeW5o1KNtjAYm4EWkmC9je",
	"2YLRiqm9Gfqng5PS/x5o3l3ykZnMap9+cQlx+82b+Bv4JsFBMvJrbpJ9CYcCkEHeygQz3iktbGJx758O",
	"9q4Y4QnSRDbsbw8X/qb+7TcOZgarOYmlC5cPV1cuzOGz1InUqOi0NjIhEr6kkg/MfHetNKKIgG9FlSCu",
	"BysRAHpGjntDP9Dlo4C+rb/LzWJi3Jq/PxS88RIy0k02Ew/ubokhrAg5KJUSaIlUU/cDPei+MG6DenDX",
	"WuhOfeda4Dd611oO+OCu1Y6EWShZ8eyuFdO5vx6CmRDaenzQhDVZxuCu+7Y5VtYAJyBWgncg9O7kPtZ/",
	"BQphLJJYCGQTFII7MHxcA9SBG2tJBa/AQB/AkP83wEvw6WaBBN70if71kb7xO4DCNwJQgDqROwxQxbLQ",
	"FZuG26VzRvcuvc6k80/FXngk2AU/XatRnkM7NzfnSGK9OlxSyDnP4gBWBeidy/gSM/N3JBf++Tuqw++o",
	"Dr+jOvyO6vA7qsPvqA6/ozr8jurwO6rD76gOv6M6/JNQHezQW5cU1N6ieYZZdNAEXvg0V2bBdLR/+l7e",
	"OmnupOSlvw4tR4jfgGgPoRqgHfh+EfRhyPObm5Et29wm4ffoNmm/RrAQf4MsBGH8x68iYImoq6j9r1//",
	"UIvCSo2/FlQbBzSBP0FEom/8zmAL9s6FquwE7zI3N84qYe/H7Q/h3gUeBgpjqmw5sIb6idoWnfCyPzl7",
	"waihZvRxQDxyRotEoaMuYIW7cDW4FYlFPxK0WEJmMK4DuEXnluVvUGPhDfd2KmDgn1DFaNT/2crZDYpF",
	"kqBAlxPMngidRjpIrZmaONUJNJVnbS0Gw/JsfycFJG2j8TxcSsZhFD3/UpalFGQ1iP7pU7tjdoLL6+Co",
	"npeolDVe4LtWVX+DUiMVj4BmIe9j6OxT8Sa09V+CsaWFaIJPIz45iNu2zDWA2dheFlYl8tIlGoeTT230",
	"FkwVgenYslZNbLPhDdvSMcBKsERSRSsEnQkQK0KawDdhc8B88IKU0tVaLi3OcsW0vZTRzPAsEP8nxqoI",
	"qtVlh/CeqtdofSBTVkh7R+EizkNGMocwblc0KxhV/QbZ5ZK59CLo79E4woIXDrAgcU5dHoh5rmjG0BF2",
	"x7TwXsfe/+uCLX/8jSk57tnLlE+cDR4rkDMu1II1UQxTzBs0xQJtnBWpnYNiBdcgSttvbyshD3RvXpnB",
	"8+FBEtpgJf/8/vCHm/gJ4Xa0g7TB+MGIB9Sb27dCP3jL5AtZgz76Ql4/yiPQVBojy4lK5wH4eyFFnxTU",
	"fIkfSzdmMYKXwmMs/gxeCps/tvcoNLKaFGz2PzGs1fcnP5IVeqWfpMIanchiOX+kXFTryVRhLxMw/Wzv",
	"B/mWyRNbY2Pc10r7a+b8itubUsYeK/EWNNYOET/YvyjvlrnMp1j8n+egMJJocmsoiavSoWBBzZZDLOTW",
	"ucZS/Z8taJVMy/OWSbARaFvA3b4cWhIYMeBowie3WK4jUMZqPKxUORfUuY51HHBdtpYNr8KYCCBu68st",
	"U3rLZMlMijkVKzr+tuB8p+39su0GhNfkpHTWnnAbth0SuJP1BH7tN4O5bS7fWKTMI1JtM5lA2tVJhYaS",
	"k0mlG9jCH8leUwMyGtl5Cwfu7joYfI+RdskpOacVn1ywpYP6IlJ1EdhYBNd26eDahi08LPLBKhuQ8QoP",
	"+whaaX//INgQ+uRw/4dnJOel3k0nyqJ8OIeJDHN2uecaoxVHe2qD79PWftwkeqPeUtbKlh9gsqQ4/fb+",
	"D88irSgxzLaK5LSWm44Pse8rpRP5RXA5zMB5hRZakikjmqGfdpu8aeqmhPoKFFPw8LTT6o6ksWY7d5qG",
	"GRzU184P3/+pTw6+O/wenOxgZRTLZFkykbN8d5h0T1l/gETzf1nIOichPbJPjVLrQcaEUbQ4eLI7JCG7",
	"iWVhdB8hR8d90gouR16G1HIporj1jNMWrVna7mDBm7RDHWgx1mLDabum4a76oaTd0BOeb0EkV5gcv1qJ",
	"qm8m3g9pmNuU2k1SpFZFutufT9/72UZsGtJmh977mCTPm734DICCnEOv44sGIkfxjbg0uEbr5V3CZekO",
	"Am/NNcQLwU2C6tnwu8GsoHoRhNRuP/5WKRn+Phzu27/vI7mABsmQhDuIk9RyP95+TG6v6Fr5dY3vehN1",
	"3JjbvYdkWoas37RhNTZu2GjZ4x0b5rba4JP2b5WS0S9uYZEInQ0fD+qxNnuS2q3LeGITwIMtUVTksgRP",
	"SR67hEIuusGz4X57h3YiDJ9twrGR1eQiFWJeDS6ItrQBjSJOyJ2KU68mVSoaMitYrdc0c3/snXsKvUcX",
	"Zd8qv+xaKdGWEBB4YPWMt58+vX3/evLy7HWsZ1j9IgnPkmmWZGDnsY2DI6/FnAuGJ1Wnm+NXt/aAwZfM",
	"/pAlQX/wS8jlOl2SHJBm3HbOf3gCgh9SP/5AcrrUffKkPIh+LaUwi93WBi6T5zM+HE2aBJheCF2xaVfu",
	"LCuQOS5sxUhSMWV5JjJwYT2wh24VhbhFkl0vNloL4PPrOsXJ3jCTK7Tz8uz1rh1q21OTi7Y0eimFlkGV",
	"P2OmrlZweGmQWNSEgy5z1TLbiD/zMlmCV5vzXe+MG/y7QqvJUcddaNZq+PmQvGUmcDkVOXl59pocv1qT",
	"bZddskJC9qymlT30UR3gQu5dHuzJS6YuObtKp+J9q2i1ANjHv+3fITLE1ppc7juwx2QeSJbPGXDfbchU",
	"Pq+fDuDHXLX9dvXWYFXtdJapXOz0egJJ+CYVUxP/QrHNkY/Z/SoWvYnu7JMfSS1cwufdx4VPjFclwHF2",
	"oM08qEx3RTYsxjqgnY2QkDfdLV0L06ZQnKuxM7F/CQDPkIhxm5SODjUT6PutUTNh2T/KnJ2xAm6v61Pn",
	"L+QVhhnagpZcyuy5TMqI9hmYYm0M4gVbJqjw+roqeMYN8RHCkIAVym4dnLv9gsD22WYH4qSaGYdsu+HN",
	"Pu9mmb87rKrtZoJxlxsxCmTOMLgPsTZs3xMo3z323RCjwFCvATh9nmqcIQRrjnt/nNVFMTHs2rYIBcc9",
	"MoCS9ssAHCLbLbmK9EIIX2cIsmBi7xOhurOKrIwCqBlQShB7XTwEe/i+KHGwA/4rDaP3imUFdZehhrOX",
	"iIzNstqeueARH0i015rtujDcdIh8tvCPn/BmCyn4gUxxBvpH3w+YzIBNmk66AaXM2LHFuSTj3d7ZBHeH",
	"5vaDWCMn/cs4CHofkgh+7jRbABs/rHPPs4lrAMwQdQ7MRlzWGg6HcPzZHh6Soh1uapvf0AKbnmB5qGkM",
	"UwkLxQl+gLQR2nly4i+Of1fyGt/WsWvrzLDqAVyG7DyhBYf40TXs7z6v8n978DsADkF+JLQodr/FjoCj",
	"rQG63rgqrePzxueSf0gDyy0edwI/WA103YNVxNpfHkNEngReXWU4Z22I5YJR9JIpTQtEbKFmMePwWJ2A",
	"D5lLxc2iXLcBQwEHJxuurxWdM0XFxZM+eTLFgH7BtH7ykA0ZOps0W3N7OK4VUgRNrplD7/4rkbO8Rpcb",
	"tg6J3UWahXJOj9kJq7H7EFnpwoTQLLrpbvQqFHa5yNddzhxiwXQZXc++5VkHgS/rjxn7Oc6+8FjEu7gN",
	"qxLGhBgcIic7FwO9kMowbQbwZfchOiZAqbDKw7ik9N5ms2LBB/bmdYIt9GyvESaJfL/er1jax8h3Dlzm",
	"CvU3ei/coW8u1veNZtZv1ve97xE4lklptajNusDiFyj+wZZ+HLV7HUTzqeMLOSM01r67sInUgKq9Vg1y",
	"BRCnOlYmOGujVG+hB32wbT1ABK2V2oAUiV+3HBGQECt+hOW496DWyEM3KJRMnnj+EL8PAR9COCNlQn6i",
	"Vy5exiDkgZcs3labTSa9EQA9DV/VAQDkTradzVadRzASPJ5GiGN+FGXw8zLlvOXt+un7cmTcd+KeASwS",
	"ny+mCCLtjz04pHv93sWk9QvcqN2958v9dbzVvZPwQQMrFBetiTRLuQKBmT5cvaeis3bYe8XKbfXurBA7",
	"LK7coUAys5yEIo95vsTG6+214Tex0QAiejv2Bogd2H2AUrzGaPBSCoGhtmhW3blaMEFalobQ9dbm/gcI",
	"sOQzYwjIQbeq+9sQUuz3E1uCNRn02YgFAcyCa8+Kj65m2/7WmXJeexP3toPadKQ8aFVWZKRdhAeJxibf",
	"SOIiaz8SAGonITikAVnuPqBEWNpprwUACmkakUoTOpW1IVcLiuk+oAn/oODjOIeQHhcDdluYYe/ff0CA",
	"9ABYMO6dIaZdidCUpFIcYiMNZ0qPe7vDsUjnEmmA6G9h+uNXmlwIeSXcm2qAXX+UjCKdx47jE4D3fRSP",
	"1oznaaTdda6uK6wG9VP+DivZJje9iwJ8F76/bQdC9aJglwwf+p5tibeUzIS5qVLimffmS/fcjGaXTqFF",
	"Wxmi2yn/qMgJN5pUtaqkTma1YULxbLHGsB0ehUMhF6EU42o2Ju+QATVn14A8/LppnHi7cA7PZTmxO3DB",
	"iIFne0vzouUD9feeZiUVhmcTSCEKqo9L7PHlG8jktHn7Y+T45dloTY+3rzYsdFLvhI5dI2v5fbsX5wfx",
	"OnZxN1bfrk736fzm1onWiVSXWdjwG6nceBvoBVX5RIcm75PNpjXP7qCbxrdtZFXO4WhDSyujXkuoNZeL",
	"BVoHWzwbh8Q1r5iX+71+D94m4V/+uSYZTvETWyJMfkqFQmxUD3SA7j6gqThU5+4Tn5Llmiiz9LnQocB7",
	"LhhVH5iasxM6Zw3TdLdH7QwkBVQhpa2DaDcB29298Oo6A6SG3ogcFQV4pKscVLFpnP2Z5cSVhOhLrFtR",
	"ZQDOahQh+RBtZFWhqINFJVOr4lC17JOs4IBsg9qDPcmX6G8j7NpktdJSYdPgn2EbfkMhlRb4Zcgsq5Vi",
	"eZ8IGUa6boDR8rsPcEeEEff6neydzXpEZF6bz+99TNdAUhBHeilAF9KIDeWHCTptk6tb1ioD3IKftYuG",
	"NpJcMFaRI8C0AZzopcgcrJNoqoaU4S59uGvLuZW9k1eEGwJZabx32RkTeXI4kJV+ZUzgVnaG6fYR8l+H",
	"SpDIB5KUh5z2wCTgbebqYHYA7acR8ZPdmRdh44SkQHSqAe0/DMg1+XxIjme3MVOtWcw3Dpjj2vgdiAT5",
	"5ej04/FHQJn4KDHjjcdPA2YSplk/5/wlL5kqaAVZBsKAdQogOFfLiarFZozZ4xngjPSJR/8HXfzKA0Mj",
	"0fKQ0LGkgMyULXzPyCeAsgv79m+YsYAhj/j0oV4VyWRZcggBt2VfLlh24TCQ/XJc8aJA1bqULrMTREc3",
	"6+PozDEPwam7JPiLsvZDtqq8Q1mBi7SjCFyhkWJBt3GE6eLoFlSbCWylPOkWe/zKCjNwOsXxu/dfxS4B",
	"uBJ3oQopbwfkDaB7uV9GEHyOz8O4y8m4N+7Zcmf1VNtCIhTWWLrFV63O/HUJUiM4HyhEywGK2ZFGTB4h",
	"4YwFBCoiLLG2wthlQXUutXYOdj9rZvQK5XouFH20v3+YvlfBqt7NBvOBVs4MCfueHL/CB3b3Jx47I/J1",
	"3PO/TXg+ObAy+etwOLyx18D4y7Pw5SZymgUteIQwAstGHXbSqGDXPJNwCDsIz+kShQCeFLBGKFeAYx0x",
	"wQsMJCQ2A5DbAWVACs21cdYTq7kDyBneXGlROMMCZgCxii6iBe2GFXLAM/RSWt5uXkzttdReLfy7AUq4",
	"J9odlFeKGwagyWpGs1Xm/xqt4YH9EzXv3ntaGVmBYOEZ643+/Oc/D//8Zwx0cMWfRcU/SIQicKWfdQof",
	"RoV/YsuppCpvyv8A5ZMa3VJkE7iPbNLqzpYiew8FV5U6z4Zfbtdd1iYMQomSenBAoeWlpFRdybnDZy3Z",
	"s7vGZzQIrXQqUziVrpiKGk71ttrZkHwScGaDcOx8H94pnUiTDXEra9dq+p9EixdsiYmPNrUVNF6spCc6",
	"o0Kk1mT1NQN2pCuNEtMpAHkNEhfloX+pS8QouaTrXYt7k8es9fbuLVFrFQRM7pKrJXiGDKzK6M5TUtKc",
	"jXvJwIlI8G9zEHmlH0XADvhFrqghyW7srby6jdddATJlGa01C2A0C6oXTgLlZKcWOKU1uVK2u6alrxXR",
	"29pDns1u+i5x1G2T5QJL2J1dVzkkgtnZJ1ts6dUQdn+bDH2GPd9riN5e5ZS0gufco6J4FJsgrNaEFkUi",
	"j/ZqvFMounZUH6VgjzgsIQXbdlxQdu3AThaK6nVDc7hPadvo/2zSAJxbBaPfbKBtlV5Li39TKtySDA7F",
	"ob9QQ5YXKvLk/fnuWRhSNE4T1wqpM6OoYfNlO5hMqVknmAyKW50fyrtrXzlFWNGWy7m9mwbLq/NJt7pe",
	"YzjCH4djodRstJqElrypIfZ/4Npn2qd3RqhR1RRXtrilSF3QsVAaGnPJbiFfaNOW8MlxQ2vTJSm52Cvp",
	"tUfLpOSKi1xewWhD51f+zRfrjYXVKey1Fm83q7OCrFshIj8KcbXVdDsHK5BZ6RnmVoVGk1wAIGa3yoT/",
	"WYbv5mzcXkO7HaoJGk5xb+Rgtc7XEb0ync606i+LvAT2F+9psySV4iW33JMKKrBtTlzeqFvcK+09KWSX",
	"uu9js+vtV7/Y299EwR7f+ITMYlLswBXNZ63QPl4k7uz+TgIPcFRrpVHtsLa39W5Ifd5WnKAM6FdbZ+Tz",
	"zzdrbMrftvvUi06S7SNSfWNRABcwzS/ZpKTA8aIuIIe6Z7yu8Smqgrm+NldxbXedaNZUjbC7uLhXzZsN",
	"ZG2u1NtFwK8kAe4+O7mkXRsOaizXXfMvN/0eZhq6H7YS1l2Hp4QJCxpsIoxkUfySZhirLGezggsGiDKA",
	"SADIS7UqYtSlT+/fH304mrz7dPb53IfSrwUvEbLkGSLRYMjbzg/f/wlxlfqkvJ5SB1MzQDPezsH+s+f+",
	"My2KQckFL0qyc/in57ehMSFOI0RPo5z7S/ZjmOcKAKUDVlod2QrupAd+BMCGnsshUVgCLqQ2o4OD54fP",
	"u5hLEWDIbZggbpmSeCCr43rSJ086hFoFAElMZj3ejlf81kyqfzs6hRt7C50iCR8V8cla7KhmBmsH80iw",
	"F+n8XXfbVrdknnIlAnA/zAMcgLjwoaO37bZ1+weaPRwejn7Yn/bJr1dMPBt+N/rh2bRPcsYqzdjFQB3g",
	"15Jbhb0Y/TDt23qXdHT4fLpxvxR8qqhaJt5ovjmmzn23SEwUuz0istg/A2EymTM1Ojycrm6XuIHf8W3+",
	"2fg2KQny2Bv9FKLY7nl8KqjcOj57jyjp0RfPdXFvaLRvTEVIXHhPJQTq3hfU8dPJ649Hm0EdfZJ611uc",
	"Yuno5Fivai5rBaw9LSOkvMOBLmlRRECQB98dfu81kk5hp7VsAousCmrswgwRRhrkLqCtQa6+beAi9cVg",
	"OBz2GlzI9LiT4Nl3Q4Z0q3crMmR7je6BDJk4UT5BGo4IDtKzU8NHO4D39+H0Pea2CCVDWhzAagzAkCPy",
	"7Lvv++Q7SOe+/+z5Cobk1pBva0m9YesjIdfDNK5tdzvVDbD8Kh7x1EbVrVnaRnVzOUXg5MYCTzQAOPmE",
	"tiuL/uLo7PXENrqdTpcc5aMKqfvqdEiMW3S6JBgjgtS3MBjxJ7iq9Ik87BP5HP64oyy4H/LiynZNgmzD",
	"e5rIlhPbY2ESLZ3gByQOpBEKlciOVWUsd9xNoxk8S0Nw/5NgGkMygTtv0gaZEdt40vwTltX+7Va4g8MY",
	"ek3Z9rW9BdxlDXydR12Cfx3d9l9NLU1Ix8eTVScuoqgL6rU97v+Dw3P6veZt6UEAS6nzW2EuyA7oFNnB",
	"rJwDl8bzm2CMICxYEyv+WHF6DzB0h9XqrLpPZ7PJ2H/fntG1rEveO5ATIFce1EIyD8D29f/llvINF3nk",
	"1bzigfWNYTwCsNe3xfO4aB2iB7GA3d+PROzB42Fn+L72o86+e8y+Hp+RVnEpHq/dZuOuBCagZ6kXqSmJ",
	"+vCdvnI4NkiEj93lHQEy7MZbAcloeS4hzcJMvjzGNk/7WQZYh38GPgN0NpnJWuQPOq49iDAv2WS7VDn/",
	"XgfNw7npoewSNde6g1gpsZCV7lxCjgL6lscAIQ4EBPy9fb0ROXNIDVhmuiQLWWFOVrIzVYzmZjHAfNwu",
	"xyjhcwH+LkgVDdnbGik4InbMLqeeu245D+iA5etqQu5VKea29wwj/yEr3YJysetHmWjVofLouuy2WMgr",
	"bE4bomRtwDHR+8dE1IrEdkvWPgCfYgVpJwVts3ADhRzCnRVKLxCAEPHf2Crm7CqBQrkEXVaXCO7Btuya",
	"lWl5FcVUawjVIuHDqGaYElZpAbzCJPoAxA0YRbkwmMQwQAJpW6f/aKqSnRPMdUVJ2WRGsHXIzrje3z9k",
	"B+THYKwauBzVdnl3e99E5dgIl+X8cR4dNWsLOrmdukonSyFcIxjn4xHmblhe34Iwa9Ts1w2EuZHea4xF",
	"uJhi+Q3urA87eBrorATSjuZiDqngAWZWyTLak2nIrylKt3tHPSegs5IxUwBIaqnsHfHb6D13pkQapwUx",
	"UfxCNrEG6B77T8RCeeACp2XuEchVlLTo6Hj72gLN10AVoDHcocSQHcUAyRoWCXx+l1kBAMEohB+i9LN8",
	"zraEhAvHzf1R+B5Ce6YgHy4eUKvZBtfd0E599B+CGqMFGbEq7C/233CfqjVT+INU5MlTzAoyL+SUFiu2",
	"ZAjN0xNoIx266CIIt4GT8MNDRIntICgaQiRxKAItVodyCzbFSpNrsc6qUC7GIrAKb6/fg3DBXr9H8xKz",
	"OTY0cyU6tPq38qbeDMSzndP0Cfglf+sMtsFF+nbDuCuXHmctUo7d3We7StUQgLACfT/1ef3BZ5/8WtOC",
	"m+VwLN6xotLeK1rWhhTyauAwkTIW6nNBTo/ekopXrIAgAMh+DTJPzMcCW53TSgNwALvkLuQd4x9k5Rsa",
	"rvGhggYmc1pNKqayZL6SM2zG1KoVYQGB4dh/rqx2Vtp/mgV1B5prj87ZWIRojDjgui7ghdfORZNxjxVT",
	"eaXHPYgAxma5XbApgD0Ox+KNVMRtpz453B/uA4xAYiCH+//RDe+2vbWDdw/3H1uxpVMti9owpGqXku+o",
	"yptbaIb0UkwvZJEPicdAxRhmFxrCCnmF9LykRc3GgipG2LWLSFVsTlVeMA3AINIsWMyIgBWwGnW+P9w/",
	"eOx5IxPBZkihqrCKSFEsG84JEyR48fmRBFYkT8lKi6srvz/8DiA1dGjPFoaLsSEFo9qQBS1m/uWs2QPD",
	"sTiqqoKzPCRyAA8NV71Dp+8ek0xO3kzKujB8gshGG/ElIPwY4ENCPg/A16gqRpXdJ9BaVThsHKbJzlSa",
	"RZOhYiyoyNtJOXaH5GfNZjXmx+QiU4xqdIRiGQeCTJcuVyaIGDpXDAL+icNcJzmfgduoaaO2LWSuWxBx",
	"dwfN1iaf5OxyEnbFGnaKOYkL8pFoQ0Vud1ckAv3eYaRk1EmIVWY6GO6vMFOKOW31ATl4qk2es0uEd/EU",
	"1B62ihZWjBcc0FKcUmrXCBsmCQCIg8dksVQwQThft0PQ+sxUiVU2oWBF4ZBbFY11nE0V7lK2E462qYJV",
	"b5ZbjiNSUTaVPWVzdl1tV/YXXuQZVfl2paHUGegt21XoxuVsqmGX/Q7FX1HDoPhdRvUCRcF2hV9K8Y9a",
	"wAbackhc361COxJ8q9JNhPbG0cjsON+eLG+s/rpd8Ram5UakOiZfyBpMJy/k9dZ1PIzxnTs5kcVyvu0C",
	"tBPOQ2gR/PNFzYucqbVv2XPvT7c5hXzb8Q5iwkxSv/1ITa1oQQoq5jWFpEMdCEofUYtNxNe6N1zkAEBT",
	"1dOC64XVLpThWcE8QGtJswUXzOomqEEHbRgwJ5aMqiSYBMxksi6HlIezxJHBZR79lAOoJUDm5EwNyadL",
	"phSEfuCtH5smfOZ9CvMVuErDDRxFDp8iRvQL05xQcwfwSnhOmxYbYClxeEaSqeUDFzw6kwpAw/xYXWrt",
	"1lTsSYzTzxArt22v8Cuy0UfKLfCXdYdp4M/0IywAIOYsidgNfppPNGnKhOR/zoHQTxjc2A6G+7ttffRP",
	"SW1hazczdl0VVKxJc/2uLqkYKEZzoGpU1i4NQgwvfDRvLhliJl0tlgBLRzXRRtWZgQypcFu5AmNkswJn",
	"LkcarNST1S3xxJLCg6HgOh59fOUztmuC3OeAg9k1zUyxJE8CKz5J7Z97hCy/DQvh9jvO115IeVkVkLmd",
	"vDp778CkhmPh3JBrDUjsisHAuCAu2QVil3UC84FZm1DnDqgUFTkoa860EW1DB+jQWyUgCFxfPOxVw1TZ",
	"GzVbFgVth7OvsI2EkDkSS8K1rpnuE8iliKo1GAip1nVZoapd0pzhPdx7Y4p5wzBt2QLnHXmSUcPmUi2f",
	"QAJOcCXAm7/dz30XFd9mCS60YTS/i9RZ2d44nLW7+10qWWR4soizApAF72KB3gJzh5DcmVT5cJ2d2sF7",
	"Hb+yw8EbIl6D74gAd4aWA8DEtD+x3F7oEEMZlghJe3r6xnH5cN0bhxsRVMVWYWhrjBunwXaFtyc36wU3",
	"SffY5C3H9Yg9pAPZYQTB0H1nD0XfA7awyh92BcMMb2OT1F4J3qXIKAtudDc0a+HqbvXME5gy9cwjS9tG",
	"ZZbBeIC//caUbLAEgmFl/Ytva7m8uXDrJesuz5aZUiwlCL2kvPDBGVslv12dYvI1ZTvaxEJ6DayP3vy8",
	"eOTL3fSbEPsNOKFgDkPrlCVK5tMcg3i3u7PBIffgoc7U4gUrzUxNoxSdbaNEBENpz+mc66qgy8Z6iz3q",
	"baE8fY6RCeDCrH0h98UaoyZaSBwCjz1EeUEVN0svedo2T19/LMCi2ZiSwfRJYsunB0/1E8bf7QQFo2oA",
	"KkID8qjxxMVURjnXbiAt6rV1rYO7sP8mPI9AvlrkSfq5jfh49JtDjnh1OwnJewA49bW0PSMQE3PB5wum",
	"ov5WyY3ai6Wmf7mItFqHpHmrPfXhNHVLN1HMEjVF1pBS4B0VecGmVGlipUIBCLsIGYvhrraFeNcFvcO9",
	"vrjsV8Ox+OzrL6gmFPCn47QBPqcvBHh+/WopP8Sf8D/2rnNzc+4iuFx029OngN+kyedPnz6Snc/ygonB",
	"J8WZsJroJ5Bq5KNE3WvXA5nOIFJw8P3+f7iAnBBoOBqL8/PzRZj0WHz9ip6xn6VEdnCDurmBojiaIy+K",
	"yTtWVEzpp0/Boey8qXtOBuQUqKX9TEFvLyu73WD4bnTAjyHRvm0Ul1KPxoKQATlH96YPVF0wdU52rLDZ",
	"HZGjPCd/cKBFkJcBIIhRWIWwthEI013XkNVOhDknO1yY3RE5hj9R9OmKAmZ3U/GZr5UzzKxv+0ZW2B0R",
	"1Ew1qyhYDtABgU5rKypgJOAOd64zVU/fmbJAcpTykmny7vOH98TQOV6M2LVRNDOaoBF+QM5LlnNqK/yi",
	"aKUR4vvn02O8D71l4idu0JpfypwWRGMEMdL/V1vvtXs6RHIrrt27YyaFV4F0KzDQr98LqnkGizOyPLmO",
	"E84BVDpayltKk3j1foQtSXAdftx3LX12dLMTva2lsBA/jnvjsRn3/EhqbWQZ9uuInH/mpmAj0t5VYKi4",
	"uRmPxQuZL1e/TmW+/P/Z+9ftxm1kbxi/FSwlz2rZI8mn7sxsPSvrP27b3fGk2+1tO8nsPcpjQSQkIaYA",
	"DkHaVnp5f/xfwHuJ75W8C1WFAynKhz4lmWc+zMRNgSAOhUIdf+XGU3CPOIo0CqP6CopK1xbi/fu/Xonl",
	"3Z3rDHp//37LtoTORiqmdAyEFMYdgx578+YtMK6F/FWklkHmlkfKKzGk01biTI5ViUGUUMtOsx/RTYOa",
	"8kjxqpzrYsj+xpVgh1qMlCWvf3y19/OQcdmjoNpFFh1hXwne7T0M9JzyM7A+gM/1nMlyXk0gxbPUWvVx",
	"PvC3ffW1ZseWjBbuOLW+ybP8SpgrqbZmGt+saf3rya21fItLN7502/5Epm7PQ3SIQnK2t+LVsQCd9g2V",
	"Jto5+9iOekw46/Za4FKZ1s7oRoGL1mO7oy3Eal1LXbEbrrBUkx1YPFJ333Tlgs+ssn16+Mr0mCiTwYZT",
	"e5mejtQvlSmBqQxYbdBQoUJhkhvqd6ku80IvcuLFYUaFWOgygp5FZj944BLAt95aLsaqIvsWfGNJVWTo",
	"JLMcCirHk2UIZmjct3BWW8ADo95OD189qi/HTL01oNALWKGorwtxWz6mM490T0MD3CfquJV92kHiDgPD",
	"qI8c+QMwmGM7x9WWYcWitm/lrUiHbHxOsHf2mDtmw96//0pOGf5jXS/v32/JKTGjnyx1KV26PCyR9u6j",
	"T2noXIiUccPyjEuFFLVydtvmeu+5vTdE02u8DwiBLZbjRjh8IQBRo4JyfwEwLEIwCSKzMzuGQxSxhfXL",
	"REwBUkQ5hGm4MlRgXu8BLcFRD7+HftHhHio8OAbw7FownhWCp8vI6BtNQaNB2BVUkSkYwwGzHuQ7lVoO",
	"Ej6U8Cyr+9yDqQLkfCO1isAbHwUjFzw4sYL/i9FqcMZv3hKkdyyry4UVVlwWUmfYAa4v1WzLvtW5u/v5",
	"PnBI7oIyDOPs5N1FEGkG7NDrwV41BpZKb0bqDAUZOfsFc6EeVDwjBHmM1LkQbGIH0Idu+gB2kMvBki8y",
	"ByebZ6Kk8kNQ5AvGE3bUHll7ko+83pkWfFqaIRuPyP46hCejDpx4EBOhmcgLkcC+E9eBV8JjMF7RW69q",
	"apYlT3ktUgYnKf6S+wVeq5uSKZZux9vDO87wOoyG8u6MNboC05i4zblKL00NmrceGhaB8C5EMQsAp/V4",
	"ilpQHKxcpUCmcGXYERcUthBCWCK03lp/9lVQBQ1GWAxrGP3UDQbIALdT0F0tLQW+3EF/oOumFex2yhNR",
	"fnDY+Sv7NoorqzwMfiQLd7PI32xWiBma0H0U4ZJM4Mhy6sYe8JWBMms7FSlT/FrOgvUHlfV1bOIh/yLJ",
	"6aX2axwqTOJJO542rx+eZe49e0TR6gVGG5CJNOqqoUglM/JXgdfzIi/0tWC5KOCaUCslN4JzsiqyqI5e",
	"r5OA0ePpfsnHAepGWxGAdalChDPrRVa7uTZ0fUSFSYB1+QumnUPBSreuwkgd6MVCK7jlQtEgiIHpl0Jx",
	"VQbDDLAHfDjkyUIMiaX8YETR9xnbpJ2NOpURxXBnd88181U7gQPWeyVn6tBxG3+fT5ZlazT4Cobw7/4a",
	"UuB+bL+HrASO2SvAqCC+zMpQ0AsG3ME+46zXXUR4ckVpSau5zZ/wfqKqcfUNJFbv3YJuz60igVWxoFk4",
	"T0OUpXe3d/f62zv97R1644Cukkb//oYpRTJXOtOzJaynC7AYCvW0m6rRz1LwIgxpG66qpo/1Q+jsg+Au",
	"PitNgq3VBXN6o6+Hl7N8tgazvcyprthHkpDTgZCGpP3b6jQj3JpRZ8hGHRLBi1HnjoQVkaWetaw0n+h0",
	"OWy+Q2FhK40ti5nKRPIMNtze1FkmZ0Ilwr0KkVArLzZIwzXGEMGV1qPRqIOuAiz9YP+NrzxEmrXZILNY",
	"JVYgTKxF6fSQj8phc5TarLAskowTTFioXy8xCIhK8fuIZ6KlrVpMMBCNcyUkXLHCGZKa6QxoW4CELCMy",
	"VHPAtsW+DiewlnKwInBQqPJ6iYOGFqlb96h2A0YlydLYud1Q6gYj9bYZKZ0QgFwktQDnFrKIZFesp4dV",
	"7ILjvF0kubREcQlox/Ws+suA9vwkwQQso4/BIvPR4ZpEkQF7FS3VpUvAh3tJGhcXfxUhWI0UeSMgAxnz",
	"TAJTYd1ymVMtt53tjcb8d7fbaz8VM1HTHe6NsazVALnrdfR0atqwP07aZm2uZN5wfJJo5h3MnpfWInGC",
	"ZwfKSCJjFXW/m2ubViC71sgzCopp+rva1gTy5i4ny/vYQIv7tYG3UpRYG4+8VySGUxZrIwiQumFde42x",
	"byG2UYAjtMfQcP8t4+6R3VhctRw8pw8uGztfMbRA8c/shlvJF9dysqx5LikMv85hI9mdLlwKWqghNkVc",
	"JPeJWffHcEMriPJAzN2HkxFr2LyAUVIjg0fEj4a723HZ9Y5b0I/sF3GdVl29I1XqKPYOCsIg66K6MFhf",
	"dHWPiFu1l7Tpnp292hhgccT7TIW8KvWCl3T0veEQ+wZTFemvsR0LEQtHyqFZeh7rmC+koLDxqr1/3DTh",
	"h/O5Es9J8kEsG1Ahx0a4LREzHNJWQO0nxKWix4B5L0TIkPVDrQ30Rl7JXKSSt0aetocXuaqspjWTF39C",
	"S4lP/0HaCBVvV+OOirjTxwcfUaBrW1zd2sFTZOzKyO3lAuWrG6MljQt9vRFft5vJ0fm7Op84OudDBCoX",
	"tRMm2Ix8tL/LkBcEQs7pwT6KCf3zkyOrt9E1EEy4g1ZTLFSlXoUCgPLXVCORyWl0zLFaZDti6sdbpVZ2",
	"NQwVxVWa9MdLq+uW9ywu05WuE2BbF9NF0D0mcM7U6yU2Yp4vLk5dZHFiJVod74Anz1pk2rpaZ2u5yE/g",
	"OCT+Mff0xBJAOCgAcbilzo9uwdZ31Rfr45SKLWSWSSMSrVLTHO2TKzs2U7jtUPwarg2JPH+ciZgkyoIr",
	"E4p+2gPlEwlB4zSkcSLCDr2FEE5g7EJtjYF5GhLx2UthSkrHK7iczcupLm54kbIpBcqFi6Rv6c2SjFUI",
	"XxaCX5EyfOv1JmnvXFNN+hAaiBHPNEIUiAS3d7j/KI2KFzBW48TBPoBhXE54cjVkLracTQrNrfBmH88K",
	"iHumMy8LU4LvTgVMRbpw/Kd8/0wJkfoY6VuskD1fpiL61HyZ63IuMDmRKwPhXmTJ6pEXGjJKUZCkLYi+",
	"xicGfK9biVaJyN1KmljgddX4Yc9A8aHVBbKh+Xd6HTu2VjP7SorbRwICeDvj/ake62PBz/Zfr40KBYyx",
	"FjwA+9geTJ+gRJ4Pu6rLrSnPMrsMXtKy8npll9NKVbdUqwrfeOa7eDYYqSOezFkm1RVIfUgWS+y14Ttw",
	"1yXZLDF6qVg6QQ2K1/qubc8S0sWjzwHsB0zwmS/p7ROEYLMfJTjAWryR6qpNp7UE9iC41jXPgvz9MSlf",
	"GAFxTxRJgmFGlYHEeQiXqEWT2JV78+atd3KEHCTOKKrMvScNpIGQ55ge1o0ptrepzjJ9g5EiCPWFVrb3",
	"77334O5uyPaDNIR8J23EBDOZkndHZKnBHhpyvO3HjsXO7plpWk5cslGUBbYxUv+lKxh0ZUR73CTW7Cs1",
	"LZ38VRCwg51vj5xEdnqZ1rmhApYhRM0uT4BMB4JdLHifgu4iiGYfUnl8aCDja8hcuFa0UBTvJVP751cV",
	"Bg7/NeOmvLvrsffvt/ARRExgAFdDk3jp8DnKuTAidN1ziwIbXYI4xjgJhUOrOLWMZqQOdcKiMTUC0myL",
	"aCAj9SPPZGpn+Ikmty4PSrYpE00SC7dkZDgcMOBASCvAFBwP4iTVOI3UPZelYfpGoWkEw8+bsbqRtRER",
	"wLLwaasQ29uGl0IBQZR6JoBTda0Og8AncAHjoJ4Z/NIGpfZTsg6Mbcj+8X6EkhkafHOei8JgDfHGYcEG",
	"g8EAf4U+7bOd7bufsWe4uBNuypVuMb6p8eKLHhsMBnaj6kPAmL81relTCwwQ+iSjbw5govUVddK0GdgG",
	"73HQ8dDsqB7L/Gs5FQgPcozv7axeBmZpSrG4fJBLYzvPoDWD0jRoWwD3r/wVpdf4ZFtOBsYoCHGbVhnb",
	"P2bcGAh3LwfsnN5ssuWGxdvSojQiay9fYTnxpSkLwRf2yaqKp+CMnJ8fMd8q1nGjsKS/nb878R7xVRCN",
	"NvHFHuu1AswaPXz/tVNB8BZRqbyWqRORlzXtO/jWG5UBrnlGOuJj7vKgBMInYu3yHq0wHPEBO5iL5Aqf",
	"4MvPfE4oRAiCIk0RB2Cw5DKrClQgP97Y4YMMHjlnT1muwzZFO4aM+GwIWAV85GFZmNq10tJKsbLgVm0W",
	"JhZtgC2vvEEarxVQKEjx9xLNw2XHQumoxxlwT117KivSHk7cJuKAF8VeVEEGAffrQ2NcQRWjAbSs6mMR",
	"WVrrxT0Gz0OW4olvHei5KJ760o+iKMVt86WfV53a+6xSaAJuCXhaU9Mucg+0JEJTqbFUqFnC9dZ/3gi1",
	"13cj6W8Pvnk5fLXzTWvh1Lsn5BmtkFNrpZbVCcRFtVx5fVe2tcQNAnwFu+idXucaFrJVPa7BI65FJaSI",
	"LGjZYxHEI8jOBWRsk6G6+2yTagPRwByMo23Y6XU267iFa0Eez4QptSUZryo/LuDiJU+uqtzLCD9DV2Wx",
	"XFci66xF2QW7u9P3MAx2FTeWJ1d6Or0kK7l0m0eIW7srMLC+HaUU4sAlzxh1dW+ZnxetWMQhqBkCLHh2",
	"6YfVwEDe3t5ujugYX3GfZ6nI+IrFr4aBvN3uiuW3l7yEjNj6R/d6j/At29X3b9fKbtyLvkzfXTPdve2W",
	"+bqvPzTflgLWq/eWrso1Z+Ygs2Kgy4gJGdu2j6G3b7GuN8LFRsTlBvNxE6wrbvNMAxGSuzxGjXc9dVyh",
	"g9bzfZ5w9b1YmugcNekffgA/t1W0IKoQEHZRASMQNA5xiRC/NRgpsFfgv5g0cZiD7QNDh1xH3sPVBhLp",
	"rVOXpX4Ysc5nOlNYNn7Dx24/K/WzAH8T4kQOXYIeuqS7vnw7q/JcFGyiK5VutILLfWgIayRMtoSwjpSO",
	"AztLzAUIoVdRYBR1b1UrCANB1Qqzt0Yd2+5EGKvIQtEM28zy2QFP00IYM0hkucRmDhgM2lwm80pdmcEm",
	"/nbkgvnhx77/dRBiS7AhJHvxLBpUaEFa3yXpTE5jpc7s++2BtjgXe/SpNtSg5DPzQUG2v/MY0FI7RNaQ",
	"Go5xJOl9iQiIyknElQbQP3R0G48gxaieNd4v06lMIM8jF0Xf9T9Svv+Q+U9YjIyDlx99ji1xequxnvVw",
	"t9W4z7uWwM9GlN99QaBR4J9fltUeVgPjKMYOyj/qRZvPiBelk2o8V/MMsBss5oCGi8UuAxoPLZN9EcRL",
	"F6u9GqgOsdmob46U/dhEzKRSUcpgxBeDSITR0tvbbVKRZ12XYW6P4piONzU4pu3lWTPmfpVjhiXJIKsf",
	"OGYjJGotA/2YQLPVRXVMk2dZRM3xZYOXFGsHrLC3K1VYbOJlbj8ocZS6zQaT3kNL4ar5WFqCe7XUSEgi",
	"fHQ9Ce22kVCbMOPCrIAftheJsU/rAZLI0kJ5TGAShQCI8iG7cE5Y70cG7TznyrKwK7G80UVqnOPPsJDR",
	"HAc2kRj0RlyLjO26Rkht6JAMHsjIMclbXZPgirzRVZZGELcEiV1GHLj73fLwiPUZfnWv+dUaKrsDZI+/",
	"1y6GiSIXBWZkttk67oX0FJPai/bCemSZXPysK5HLurCoJTs/Ojs9OouLWLNrXmy04gRSDS0v6roSTyRz",
	"9tZojLR3pXb5B7Ez172qxA0U8wMDt5UNM57AH2au85wiWlcvf7kQl7kopG6xB13IBWS2SO1Sk4Ys/Tbl",
	"yx67+fZGiKseW3y70Kqc99jyW0JHdAMDjH0riXR6nWXLt1cPz8p9vwrdjnswSMU1e631LBOUgw+VpjGa",
	"HjaJdHvDOEUoFIzb8SsMXSm1e53AC6gXe4+PlCUbUUpomRcSgCnAdsnN0m55lVMK9rn9e7i5OVI7A3Yu",
	"Z4pVOeOlz743frQjtTtgr0XpqQeNatzMJ5oXaXuJ5/A6VHZuj9E+n/MiDaegoVcvS3EJXPRBC+WSoGJX",
	"jGNRH21Gx/NSF3wmzn3kTrNMk7m6rED2W42SkeaKVRhRpZj9jnkUthTkMedttY9/mqP/KQQCzrlhhUgE",
	"ZGOCQNxur1+dVwVp+E5wbSm+6n8IV8U7HyjnkjZSZrAjezctH3mFNIzS90bo1bwqUSgUuJPJGG7VSlzV",
	"ErOmFry4SvWNco6FTKpgkwpecJdE8A9fmUOmCLWdyBRlzJ/tXdv6+w426PkHu+4NgmRc0V+dD6PVbheS",
	"sN2kwNIrVZhMDGhzz5wgPLA25EKYndWJ2KdWRDK7Pz9oQXZDbz0hS5XA/Vfn+XbuGHrTuGaWKpkXWrkt",
	"zeDqhBw0SGULoaMgJYxcR1aE/4lLNH6f8SlEO+Ta2Es7sYIB4FV1p9yUwpQ9L0BhJ3D51ro4FRN7gL7/",
	"keFv0My7IWtNQ94Txlj+tP8mfkmoQiZzEAjsaxEoAIt+cll39aF3DS2HrkzUOpKVaAL8SqnaoGrB/zAa",
	"pIyJMGVfTKe6KFmtcx8T3Z3yLDNg2oKcftsK4g7kQuiq7DGDFQh7bKFNyVKETaqLM2F3nVjjlw5a+Wlb",
	"pf1KtWc1X7hAxQZPjellrSe2BRq5dPB9gWNd+MwBCKyBctJgDXxDFb5fRHbKWHXymUEfEnV6bF8PsT8r",
	"RwahH9+vQ1p+qHuY1Dk2tS/ZK/KDxxpfsKtjbfABGLj/YlinNr4Qj3JV2ESw5JDtR/6XYEcMIeVpnAG8",
	"alyngx6JnfWUNAyNgtwhl7zlzH4+HATTFdtkWt+E1utDl9ml7YZta7qlFpg1AwP1STOYBeZX4BejHTDt",
	"mvhuNdWuxJS5R4DQjFqiqpO2JRVr5f05LiyrsRdo3UVjQtSHVUe9ts0VJW65FDbk1iJlk6qEpkhE6TqT",
	"QFlml6kLCm69O1MfeAiphYiQFIZj5qDIidtcFqIX6iAByygzxDUH7mdKvshZ1/ngNhAmwLDXOnyDbmGq",
	"XfZs9/n8WY89+3Nq/3/nm7/Mn9VtG5Eq4j7VPomAGc6lcqGSYVD2eFxcvMFZ4Ehq4yQ6B6IZdS79i6MO",
	"hPNHa1gzwsMmhEWAEnflmglci8K07sGP+IPHtgL6BKMKqugLOYuyQWryb2sI+91abuKl8Mdpw3jBrOrA",
	"BoX6yxCPfy+HrKkAK6JRva9VTvgzjP5aZssvrtLjZ1dU+ov9H4/f/NejVHpynlymesGlaqsKSt6VIg6Y",
	"cRGM+M5TjPNkerxEO0xNomxDmHaYLfvH/SBAkw0nhAyt8hT3mbXTqkG5fOK5Ffzm0oUPPGyUdWPgN4js",
	"6KDH9JTlZApZnR9ZYlKRu8KfTiyfcNNMCvaY+Azag9gNzYbsFfdFswk+x1U3ikBweApg2+mQHQqRi6L2",
	"ApRis1RdiLlQYN30r0bypBuW6+tTGVTcCThuGlLoB9k0J57tvwZjyP5xLVvPBeFCHaq8EP280FbtFWkD",
	"Xsg5tCiXJAYid6BPDxtWShjcINGLDzKspDoxg7iPNknhQhSLOAWrpYIEIUi32LYBzf+hUC5o5ZCof14z",
	"hM8cdvaEka4bYVTo5rMNM7hqFhyAf1SVZagd1UA/miwMX8E0kIdfub/vMJr7O7zPtEMBXwfzqh6o99Ax",
	"tWIDvcvAB1yLwILzSr9KwzhLhCoLnsGhxdw5UVxLJ8x646jvKUrYKqUoWAKJuQ5aDwK4MCxwwXOQoN6d",
	"nPydnmMtDV0sSSjvOsjuUrO5vmEYGMdudHFlNuh8H7gPQ6UVAye9z6YYSu199bci7QPclB/nZEkIygjD",
	"3p1UMiv7UvWYojE5qgWrwL5aUqVFGDwI2BQeY0eXaZ5Sdi4MYyvBbTFb7237u60wNxo2LgsN983OkL0V",
	"Cztzu16kle32F1JVpbDCKLTaHbJTK/8ZuJXIqmL1bCtnY2yCmmVimkG58lQ4KHQZUIOTqoAafjIVCt0w",
	"BQaamJVyJLm8rIqsM+xYXjfc2sp0wrO5NuXwL9t/2a6ZIYbvKe4Hgwqsqh+C9WD1O72OvhZFxvNLWHZq",
	"E4Xphfg4j8XcGXZGCC6LtYqjV7fvei2SGYy3TeL/4eyNE5kddVsuL1QKsX9exWid6rONATvgivHMQCka",
	"K9ddS872Ty5evfmvy4ujs7fHF0eX9htCXctCK1DbXKZP3UqydjG9qF7I1gTgaLGfUBdk9fw3LGzk9caN",
	"Y1IhtNCAEEbzQhiAqBXXQlntBqzlGz3X3imaEBNImATDZFoOmammU3lL6KugdPrOnxlGhIKamPsYnxhI",
	"UaTfKiPYMKn1xAuBVRQqU3dJRqnYltFYUQMR1DH3VhTX1H5alVXhccnRgAs3C2JjUFADOLkQibdxLNo4",
	"cUz4kfz3YvvhODuaahklR+VRHMqAnRZ25UvDxK2VgaxM51kYoOYUS5bZwxHFrnQejNDDkxnLqu6Qrh4d",
	"/znk0RThylwiIbyIRcPRPYZstY+qv3sZawfF7P8+Zlk/MW5oK0eiyVDuXfuAIIPN7USoA1/iNNHKiKQq",
	"/SqbAcOKzVYDKbkrV3VbMp4U2tC1h2EX3OWut9TjitY+Ym7x+hOfa6oKDpQ+Klxg8kxCjV/PtEYjNRqp",
	"ZxRSUXDIpjcbFMMERwXBQuxCMofNM2hHxajx2dqKrizpBRaQV82VtRQMCzNgJJ3QfSkXeA0h0XNMg0Z4",
	"RPmreJhuGwViaWRQY6K9NklUn6JZXcOtrK/aurJcVgggMkY6HdwbCXx/JbaGFIwn8Of1Yt1qAsZT5Lr2",
	"0PqG1zEwgeaRVxEISugKDy8RHZB/H3Hei+hcb7SS1Yfey4MHL8bHr6uLfGkp1KP6EOEQWVzrWAXounyr",
	"1UwfvuybcgmVLSjjexCCaggHyUFKlnqBEDojRZX0yIDFMr4URY9BFQTlQF952l/oVE6XfXQxFTwRDqH9",
	"GAIcuSqt7hmCeIoIT+jk3QW75plM0TAz41KZMnJfO1Mh3I6ENWpiFMqRmlQllD02TJbPDMu1MZIgcDAi",
	"kEkFn4gDJQHqGgp/wORVyoQy9o5d6qqIXIyeh44UlW8Ex7ZsQXt93wETm8cc3dnds/Kj7wrseDrvDDtf",
	"S5VYysaoz68H1xJDVwAxtzPcgaQbaEiC7yEHEdO/kHFT/ijFjSuTVz8jrZY+j5IKdj6XMs+JR/fAzs6V",
	"E0BAwpDKiKI0rWa/eFrrYpmjVSw1EBjWJ7Siu0rEY/PdPOG8y9uMZlVuR/mE4EUiCn9s5JTJEgpFqmcl",
	"E7d29F1YADo7DD+x8XCio1352trce6bf5av2Ap0/YTkgZeDO0UVzG/52/u7klJdzjBS2IiJxwVHn6wHE",
	"dVvWh3HVX0OYtP1bFy7qG3+tFfaMaHXV+I/Eu2L6h2JOltUHEKWuJTa3bvDb15UyouyxmOA3BuwCAT9z",
	"oVIAnHfsi3Xp+oZ3pUq2vl5UWQ9cSfAIOoOSFCt7pHN3kh7YnPaEjDo/rXLLuPy4InulHUKn18GJ2T/w",
	"zH+dV2aO/80y+1+ephf6HJvkMDY7FfiPVPAffmv/U+cEXxcCPK2tTvOCX4vC+FzW9VUiKbkWhFoEMyrd",
	"uy1O1LyNyFwJZuwE8aMBcrO7zb6N/r1xL7TPA6X23VF9mhLpOR4UMOrKKdg7RLrRuQci94GRtLLWl9yI",
	"b56TWBF5QJEb3A85/fhPtx/yc2Kmlt9C2HK0D+AdBoed3Q/L5si/ANkd30JlqpgJPwiOvVLX8fEjvxTp",
	"rM3fHI8fmnzMBO5N7k5n4iPmAMUPL2+EnM1bTtQpAiW4STBsZxjPNPlpYffaaiI/uaocDKj13sEj+vOH",
	"U3fgHFXWCulnH2M+44Pcwhc0vIQ6Bw866n6URpaY6QTbDQYTjWJC49Z9AuMA8yW5pB+ijkPf+K7Xsdu4",
	"LkaCUPaRXCcOdRZsTOxbyFaDFzce7/t7/IxqJ+DxzkHbnEkVlIOQ9/Mx67vgty0uxLWZmp5e0I+Id0Sl",
	"sKpa+lFXhB1JDashpKquG81KgsinHk/MLdxw1g0mYhsUaf4JuQXo+G3D2V5ngvisw7n7aA4lHLjoPU7J",
	"+yv6rhB/ZLCJ6OixCkpN4HoUAukPIDmecmNudJGuxXBT4uYyp0b1UGslbs73kmKvPP2rMTfvijTeIf/K",
	"Q6aHWv9tAvEPBqMs6sNyr1zOuZmvk4iYk4hca2ZbD9jRba6Nz0oEf50RSQWYw4U0V3VD6t9ev1r+9+5/",
	"VG8Xg8HgMSU8rPLi4idDN7/ouUq1eHBB/Nu9xiTbFgcxJY4QavgJVi+Xe5HpKmXYCds/bqISG9YVlvrz",
	"QhrRnxU8FRuuaobBWh3kJnMxjAeFSBEGwLDu/uHBBgZNVuUc/WZoMSQUesOO99+yQmeCje3/my0u84yX",
	"doFBP3S1XylzM/gq2UwspJJ9P97+9vaOL13aY3vbf95lqVyYjV4EkBzFF1ORPV6lUm9dy1TojfZAhcSu",
	"0GAGywVFHBF8os/llguAvhb2X6lOzFbwp2zNRAnuon6UUdyw1qRyIRTGq9kB9zqZTiiGsFOZPrmQdyIA",
	"j7Zpo+hjCQJK6ncWy/4syfv0rI7pQcgZKwabJGzbZbuY7/R458bmCTqAAYgJoj5kJgZsv57is394AASg",
	"tOq/PjiN/XxrYlnDktTwD/682+Zj8a2dMbRZVY51//zNX3ps58XeN2BYALpAOIzVhfzfbGf3L/2d59t/",
	"aQBr+1axlTZi12HbYtdEfQfrg68dv0LM3LEMJ3H/9Ng7KqKenvXYM1HZvevfCFPurPOxvn737vWbo8uD",
	"N+9+OLx88+5g/+L43cmAxSGYtW5bN6PF37WGAO+3ha/lLzHui+eTaz7RhnHkif79fetLDdnx4SPW6vTs",
	"3d+ODi7WeqQ/1I6Oa9BE3fxwTh2Yz+dl1ceKNQ/uSHVxNGeV6rHX3x/1oBRyVQp2pGZSiY1wrzpEfKyx",
	"Ad57lorrHisqNVLjGbBX+Ggcy9Z3aKGZnkk1/oQXxu7gRX+acTP3l8VGL/4tL7T/995g2/77U9wLAK+/",
	"hRvVvAXWM31+6z2Kz7f/45uVa8BP5gOuAMT5suOsCig4/+fPdymci9K4U7Z/evrmGNnR5cHZ0eHRycXx",
	"/pvz9vP20dfJvyxnjkjjYSCC4Ln30RIBIgG0mPZ7bT3/jynvsbz/QY4fd/r75PaNQ9PCvMtCZ4YVXKV6",
	"oYSByKCQKMe624Pt/u5ge2PAvpOzuShcWdwFvxKu+jnEI2MX97vOd+91nfc6pc4vr9o00bx/5WEjorJG",
	"6Mk3yDp9BlKpc/a9j/xxgO7MVBP0o5VIX+0kZIeQt9UlSjJRmZZB4BLtwBI1Tn+09l8kpKAVr++REQVE",
	"koH6zygawAV3P+FaRni1TCayZBFPBpMa3XenhYA5GVkKF8tJaKqH0iQa4p3wcrYjGDJ38xLnNkxg69S1",
	"FtCYLjieS2MvOUCweV1wVfqLeOhu4uabPF1INSbIkFQYNm62oAAJXEAD/xyzXBQLaQxmldqphSvcYXX0",
	"CbaQuNJfM14KU8YXerPllJuyv739/JFXee0C7/M870PVWFHgZU7jpgiD/bcf0xdWmu8nyDnqgoG77e+f",
	"9+9A/cNb/lUtZfdDrvtH6iAPrkcL5CRvicWr3UEPdvppbqTWRfrQu0jnl+pxQESJLtLHAxE1wfOhupgZ",
	"tKfBPY6XNjPEWlzC6zFPb8TEJew4YqbKmzx6BEATHoWw3gsNMgq9sUya5/YYFJKXYqRcN/1GF4wy0hIs",
	"J+zuQYpMspcjwAM4xSPavB9dyQJMZ7ebbjaIObudPz9yOW69+NnxIRT8PD55fXl+tH928J1rBdHqNbgb",
	"+6SeLQevnu3/eBQe2EMh7XJD3BQGUVK4LuSIwH/XpIZINattXa8zKfi1WNve/th4Ia2SK/u/mV6be1wl",
	"V/Z/r3XjVWSla6tYwK+NVxC0ZW2q5Cp0Ua+DmUjrczRXUiMDC12egKU3sNkV7upK3bV5bcVUFIVIQzm8",
	"qEqh1zKEAuXC2P+fFs/qATFCrVMQ2rxRLx6OrW5AunumUZM8H8QWeywCtWcMMQQ16l33rVekmTVXq4J1",
	"qq7s/6eisVpVa+SQ4VNRq1h4j5uYxCr7ilsqDyL4QZ5MB55M2BZtULfbvXUop/jO41BfH4u33Vndk9Yg",
	"1Ba27K5Wywz7bHMTT+/m5rAd7AlU6cLZdg7OjxDbaQNftlzJvvpWJoU2eloyy4vYT2ISvY9N8cjbxvfB",
	"U0FiFCBRxZ/Bs2/fbcvExBT2WvKlG55ldPY14HgrQwo8z7YJ/I0dK6ipwPYxBxi+QQ5fSKKiNMo6mAmx",
	"wR6yas/jPOdyTLnGa9tisxxu6mfOFryhzzyc2OhbtlEifbF/MOfl/kyo8gE8Jq+0JnNeMj6DXJADBCxA",
	"ZFFf0+KZ8daP3khxtWQ51nVlScYLD3hsej4wGY+56bkyPeByBfHClLxsxQOOc8TrARwqQvITtyUEF/ny",
	"u60Br9j6MsTmr9FFMW6fDDw0gA/Xlnsdmv4lTX9dNIrBzMa5PQsTIZRfNhiJNLUVe2zMFHZ9noukLfCW",
	"AMBahoS+7cYuzaWBJMlQdWkdQTyheFfp4MlaxkcEdVkjqAf7jBtHtWEeqAZyXr+1sSgIViVKXbmgeFqP",
	"L9/fMrFS6+wScOQvF7wNXzPOGtIZQs4z29RTA0kUDykUbod/boP9cT57AKxBMnjJjUz2K1RhYUlFhChA",
	"XVhlvXN3B8FMU40xG6rkCfAVdNx39lU5Bb4acjmtfj+T5byagGbPoUU6oT/aqqLa5xhekEp7kCewG1di",
	"2QezH6b/ATupQ4SigYRBbi3TinG2uYm5wQDNBflWylSG2dayFElZFWJzczBSx6WrdIzsbiIwEr4suNtv",
	"n/lqHPxBKgplb72E53wiM1lSVatUZPLaKlbLSSFTNzheMpPwDC/5r75iP9lj/5ZfCcNoxj8o+c9K4M9f",
	"se/wbSRQvBtfvt19wf7EfsRJn/vyzfamfOXzLGOMhpV8xUdUbMZvvfVuXNs7wF5huR5C9BS3ZY9hOECP",
	"QTwAMngICsAujrzX0glExvaFadU99i4Xav+4x/Z/OmcvRVro5KrnhI/XYNru2ZWZFzqXCfb4HS/SG14I",
	"tp8kIiPrMIgvx28PaxCthnX3f/z77tb+j3/vv9jZtdRw+5dveuzk6N2J/cf+2dsNGO/52yPWPU841m9/",
	"y8tC3rKj2xId5Ojc2z9763blMCLIA0dP0YohpR0KI2c4MKo5FxHfrNBVjhZhh3VuJSwI7E6yypSiwKG5",
	"9J2uVpinCeBctD/f6UL+ao9fxgDni4S+Q9tbvaB2zosSaFikLo8QUb4oj8Zp/BMILPeWVfxMPF8IsecQ",
	"aQkbuQ8ZR5SbBV0iWp0jskRrOy6rOFNi2+7pgQM5LIUq6WmmEzQM2g++kkr0Xxccio4f2mHZkwUkTn4C",
	"gsSzCwqp6QmVbQWwOzAqGNYlFLseNu6FyuW9GLmvx/iVQoup3dz94/4Jms1fCbCX086e7b+GvfTFtXwx",
	"uz6vZrYnkcbuChjOuSiuRdE/F6pkR9foALadOfnVCll4tFxtcVeEttBV6bEN/F6uQC3TBrmgdYdMgFRH",
	"8Mw+m9YZILuU97axDjmBBgmLeeRXCuT1UEs2xCOECl4O9RH6zQRPRdGHWGDCU/F9B87CzsRCl8KyB2oB",
	"ZOVnnOoblWme9qI+esSFKOwscb4je5wcOzo9fEXiJuDqwKX+w9kbw7r2PtqCS2nL7G1NZeYW4vz87BXL",
	"MfvZFTp1eDyU5gZLTlzAUpm9/tnRbW5lBMhns5M7yABt/w1g8Eth3IQiEKPzw+8NhSj0IFHmHC4/HPDp",
	"spxbBd0OGRjk6TEY57B3MBsTwJ7nUfANUhDHt328VvubY8aV0iUP/ieXgE/bQPkw55APE5IKkSYpRRHT",
	"ZAzrfi1V0qP0HEiF2YhKBzRSCbH/N1IJXrC3opgJPD28FFBdEssngM1EFyVYJdDQStIXeK8yhnimdGou",
	"XOGsM6iaRaTSUlkLp0olV31GR+Hewt6gdjjzmLcw58OoQLirEwmk4YOfEfkn5+V8KlXqO7u4eONKdtTJ",
	"NwJ0s2OKsMUhRbIPvApZPYakdzE6H/aJfnUUF8YKqLS73zC8s4A54jjeIXAs3Abs3KVt14dUCJ455z4e",
	"JJ/ebbcjXAt2Y+3xK+WC9vP7aiIKJewKv6OsKbjNocIEz9iYCM+lVI0D/7Jyj2MWmZyKZJlkgi244jOB",
	"9SjsB04LvRDlXFSGvbX8NYFteUlAKWyhlSwBasnn6+Je64llbrWl+G9R6P4hDZ/9kENcD3R3pjMYSkXP",
	"3I3YEBDxjnaL/yoTt5CZelw7QSgU2RMMXY9Dpcvr7THrWmlto8fG9orBJySNwbqc8Zey/E/7O1bDhwaF",
	"yHCT5zIPdEc3PnJjEqLGngULejzusbHjxCJ+mMtcWMrwz1gXgWGj4uCBv9LHwM7hGLOmbxJwwph1Pf6/",
	"P2GekOyU8qJS0M4lqjlLn/2xIM8wzpdQtArRJyCtVvnzRwnyKfqh/kT3j9WUCkaO7hB2GEu7XRQkqc/T",
	"rJrNQM7ZrykAQ3bEDRRm4WnqeAfC70JCCARAFGJmZSErT5WWQ4HZIpOJoGh2pwBlGTvDJKIzQgJZ0Ybw",
	"pAyk3srEjGeIZl9mQX9ip9UkkwnbPz3uROiMnesdnuVzvkOJvIrnsjPs7A22B3uUGwna3BZYcMxWMKPk",
	"uq3oEzjT37x5CxnXWK9qiRAqmK8NqhCIHb2Qo84IpRikbcum6xWfe059rqOL1jnqXIT+RErKhP1wqNms",
	"yAYzILHLuBGSeNojeQi/Bg9IiceeyEjEDdRFRVSTQZzje5zCcttWIIt1UIUWpnyp06XTbl3yYog4wBo/",
	"Tk1+ENE3+oK3StTVdcqQcEYU2MHd7e3PM4JQK1TclluwLH0sGlvvcKWAREOWpUqzuJ/QDR6V4co21cEN",
	"emwuS3MJaYLwNz0QCnyp3GhASA0AqD3ayR5Vz72s8stQPS1qlmoleliltSXetMXKgPQBcndAuu9FJXQJ",
	"CkcXjbK5d73O80+4P0cw5JYhHhP6AY+HWgTT1osvMwgnjgEN0ALHZiSAR4gMSP+A0pweEr8TKzys/+H6",
	"DljtZ8bVJV5exun6dkCO7SVzXq5negeRbdOqIPuvaWXBDutQIwwjG5o3f6Kmg5XZQH8trCp8LUaqbvim",
	"gvmQaViIqVQCMT7mha5m82DYC5iR34ulVzjJz725GQ+TfYdjAK+OH2ADG8iDakM8Aomm9mMH+DF4GUOe",
	"YaHp3qQpsa43xziTS4+sMBuIrF2pBOtDYHdO3Ymn7j8Btdpzbt8DGPorcg4s7Ta70+tx8/Hi8H0eLhVf",
	"yISRfRwE2CSpFhWJ92Q2d5BI8TpFU39FoQMwoMbcrXAL++AmbweKhb/JJGHKogLhIKXoQkL3PD9C/odS",
	"H23WuEYAl46zj91iKCFSgyj1UuVVybqJc614TmaJhmIkQFgZUy078gaMh7QcOG5voQ49EcVZXRE7IKBY",
	"13Q8dK62dT1gaUl4dy7LMRj9XNnumnMbmiBTGg+dPw5IEQRE+Nly4zGYbOq748uLQCtgJuMhA+7DdAJY",
	"CQR9Wnv1VaZvHKoqqdgGsCWcpZuBkd1btFa8F4C2ejx10EGwI7VtC5E841b/w5gyb+EKGKk9P45Umjzj",
	"y0Z3fmd7bCZK2n1cs5F63piEEjeOrxMTJI6f26FYAUn7iY7Ui4GTy1khcsFt76qU3i8mTSg5AkJqXeTx",
	"PsHPJPBEPsffRNxp+jw/p7DT4P3+6PdY/fj2WOM09kYKZB8n20TCSxtC++q1fOAdtZ4oW4gfHKxfXF5J",
	"4rH90aQVWFgnq7TICqjARJc4mgpr9+CjJRX41UW2PqCnceVUNZCowRimrNDAsxAGRXwazetYbo/Hl1lU",
	"h5QgcoNdEuWtBEsSAi4dojAg+JPV2cAoQMd6EKwd9FFdsLgAK1WHRYjfuTQB/VQCO6SqjIBJ/tKuAMkG",
	"oCaCJRDruoSVgJudUsFAPqdsJf9SqDPyzBAAGYDpziAzK1jt7XzsXjrLiGlhkzDXl7gzn5Ndxt/5jThm",
	"fQjENFeOFlqE0Ldaqwz2pdmLuykpcA3hO4jioSSFwRx1jAiB0T3//KPDckRKl2yqK5X+thzPrY1lGJZN",
	"sSmXmUg3nsQJgSIgxR+ONx1qezCbbOdhfmdP3Xr+dlYpZltUgHDItIqq0vCSe5mdbD1QpNjxsKi+aykM",
	"8gXfVc/9De5InswDqD/kNWNdMtdGK1LIzjyjWDhDtI+3Y2gxvSyLqpwPXOHQS5m6ugDwqkjtkw2qhmq3",
	"oMfyQiRgxuwxlSazHlsURY8teI4fffPmbZ+b/i9VOhNt38Uf0FvrOibrac/ubzmfVpkSxvS8jO3+NccC",
	"cj2IviyXPTYXWR61Liybp39I9Bhd/rPiaE9f4YxHuFziMzFE2/1vxAjx0+sY4JEnk3U1Er80JwyE22SK",
	"jgkGrD64jDd+P2wJyflD+NI5FCrJtBLxAjjp4mFe5MvDtzOjIxTRjeMxztBg2aivE1xiggLYhNBpVqs9",
	"RaIUrrAL+MEL1FVTx0PfjNoBHXc8HttdGKn3I8XYqAMfwzrnN/JK5iKVfNTp4Y9NMcy2q9dGn+h0OaSy",
	"hcWoc0cvQuysbbGzPVJ38FVXwqRm0H9oSISaavyInEMgGhC2Ikeh9AbARNQqsfgeqPacffMfI3SNXNpZ",
	"XHrPzqjzc3Mau41pfFeLvoLIpoemkiManHnC4mY8L3XOZmAxDovbugZzOZvHCLj0FnN7s24BaFhts48F",
	"7tXB5YVMBJbUT3a3t7fZ/skhk+rSlDq5Am4aRowMgr4Y8EWhC/wzOiYty7/zor78PyEEOPn9Hlp5K+pH",
	"y46zwjLo2KAUiqtyyJOFGD5he9BE25gqlbGHS6513bDg1zAVwONbjsyLBq2dHGJCH3g5YK6vrHRRZVdO",
	"OemBqScYaZ3Owg2jl0GxHB8gz+hfLHMxjE/H1m1fpXb5xgNK4AJvP+AB257x9dFIjYc0sPdhhZFx2HVr",
	"ocxRZ/8YfgpU949RRywmsMt+0i/uGl1CZWf7Xss2ROs56pRVqQvJM1hI39/OtlvBFQnjdaYnPMNQ+8+o",
	"dQUpo9dpW+l6dy0mmS+sop353teqZ0Ec+eLCCPly/nAGn1NkyIyzGZAdTuRhMaLgs6cIERDPiY5s7gtB",
	"e9B7jD6vjIuuD1UcfUhHgYWxvbVPOrMkFsZusVp2z8+PNijXi2d9iIWhgK5VT/gZn33OA3e2//o3Eurh",
	"y5/aEqynoXi320xfoyYu4u1qdz/Gpnu2/5qopd0f7amm4ZAmw68sIwekO42Y9vCleYGdyR+XE9jRd70N",
	"oL/vQ3xfh9Ldj+USoQ7pTLTmX6HPCXKvqFbWXPAMfEApw7ehXH6WYdpDTekguyxFja/eo6Kk0qaf09+C",
	"H/c1VFddFdjATcZbSFp0553PTyY/KF6Vc11AZmK/gdvl9eWIatu+4hdzy1EdsoqjJ9Pca1G67aMFimiK",
	"frgMkZJEVah+RlRV3/c30pQX2KTX8RAxWMeiFRGZ1NkJVsJjKHiHqgNWAblsVhSAh1AovDPsuNOgXFK3",
	"7aATVz2PCrPvvnjRAgj34NAKMRO3LvouDO7/wEAGm5fX/9ju/8fPf/q6OdD/Y5WLy8HmurFih+sG21ZF",
	"3m7hR52nx6HTRnWRV5FpW8qMZ1S+g6gjMP37SfglT89WePXnpXooNAJ4245KHcnDg3UEv/Ue/nvCF+IO",
	"ealV0Fbp/7DQORaIXtmn522llAHBp9B5vt6g97tbQjtH5+26f/167UzitSjXrNGnuxtqJLzOZ5KKksvM",
	"RJ6a+1fuRJev0MXyRD5b1j73wJrdyzZPIqQ2twPAW6haALEWT62dpsD7FM74c29dJBvUw7H6hBI3NDsQ",
	"BV1UJPlAWSqmUkmMRiEl32djB7QXZ6f8wQh2wI0zUVJRU+zeKhOVihzKKS95q3FHVYtLlFLAOlS3l1yE",
	"sU4fYwGtd7bnjGzo4QXzjWLMPnLh6JdEgdGPLNgqa09be3I/2L1AmxDmz5LpKTQIeesrb4MhL215XO8Y",
	"97nRMTbyyTwQbUK2uSuxvNFFOur8XH/hrtf8OBhOP/n37V6hQfDxI5nodPmZBtL8dvzPu8Zm+W4IXK0v",
	"VZ9nWWxnxpnheKOufbf0h+t55ABHLsM8PJHZJnerFl1PrBQTJNPbBpmGvuKUEuyQhnC39kC5lGifHfz4",
	"g/WCBluz9NphuDIpCS95pilStxH4H+z/Tz6WZOD+csfSWdR/0+OJRvbfwelsbPcXOKS91Q0BN8MDH0dw",
	"jcd/XFULUcjkUzKJ4Bmpu0M+jFV4wn+YVZDV/j5mQYlm0fqQWwd/rg04auKSqVaOn0MnopMGafu1xR8h",
	"ch19Pcv6C6lktmi0qQpqsVKLemfn+d5zx9bCgq3wt6++Yi+FKdkphNwnKJn02SFE1zshByuOF4Jc3azU",
	"Po2pVnWyz86hRhVKH+LG5dVj/JhZAJAfL7kRpWHdnf4ehERboWghuJJqNq1Ib3Fl42M1mdyHkUur5iKF",
	"vg60MoD6xDGHeqJrclCEa0GkACOroUm0xfWCNBhE+s8Q2Ru+8BvZcnF2azUJLBBZ1+EooDrLvLArXInw",
	"D1ORnxJLigUrI/n8QzTdrQlPriosOfkkpcQeAXr3I9STe9SROgG+hE99TgLELzyJ9p5mUWyAevl1j/BO",
	"g4OtrahBE2xnhVBxCi7floFaxstPY3d4ovb8hQwVNONVU4VlsqsG81b6LxFg8InkP/URfv4rX+gg2PF+",
	"riNQJvMvdgIoAuI+oKqAalDjuu7NNoxLDPpaX34Yf4+rEGPiBYSQBfONN6LWx4x+n1WPLLztkvoQb1wa",
	"+FZVtJajagMohuo5LuX9+BBzBmk+j+AHq5BgWKr5g5bYv9oKB/YITlQ7Ge2hA3989uOcesgIqDI2yFhI",
	"ogaBwj6YOTlR4j5fzDG1+RJeA/jWh3gNYlkz2DV/t/vqXQjxuFf3EX797Wy7K3fG/VS09R7+eJSDAza6",
	"087um57xVNz+QR0cinA4IO/gkdu7zt2xZsU+nXpSO3ttEQqwDx/s7viCLmlZG+rv9jj17vuapO1u+Zo/",
	"ZZ9G4EM9L5DXpxf7oG+Hof5oqa+N/Hia/oGYwH6aBh4AyYyP4ABreGym9Qep0Z9JZ2iEmiVcGSwEL708",
	"AnKv/acKLr0rsWQFVzPh0o1c/NCCcTNSStxkUol+KggbG0PFuhhkvDFgIXTYJ/5zbIOiInxzpOzs7acC",
	"LgFiSWJNjrhYPqV5sguqXRdSO0dKli5X08Ff2Bu7OUu4uKEuUumr4buZ41wHLfYuu2Lfi6X5TCfOdR/p",
	"Wk+zbLVHETdorXW3elgpCjZJtm0P42jfH3Vw9R8TXGjngqmJrBvHjRJh/EvJ/Hbv1p6lcII+RNxHJrL1",
	"/kos79bL/NDoe7F8KPzqQC8WvG8IIzb1snhkwqY68M3CcyO1vhSNbWg5uz+jA4dPaCBvkDz6+JGhcxT3",
	"MC5u1LFNToQpBWIdGpefMeBpWghjBoksl9jMoeJDm0sMgB1s4m9HLssCfuz7XwdxHgsMx86AZ9F4QgvT",
	"u6QAaGF61IV9qxbgFQ+/5yB1B7C17SFf+KXOA4z6o8TEJ+CEtwQCAx5mSCT+lzmYeDDoDMrH6d2/K/ny",
	"exEF7cMmlZqRYNH63Sux/CQK4kIUWAnn9yi7LFUyL7SSv6JQciVE7jDNpUJcZrTgOWhXyOomfFeWySvB",
	"zuc6l9Nlb6ROtSlnhTA9dr4HSdpcLetAsfTmgO1nRrMrpW8U42ZIvfrBIKzPSDncdvipZzkqVrTiGT0R",
	"/UQvFqJIsAnEQb3U5Zy+Q8YiU0qFljLIuZoIN6jJElM27NpfieWAkcnJMuJCiP4NXzLYPmC+x2SBQsyf",
	"CPcWPwa+RgLdTeb2lvLwuOjyRJsVra7rgE8MiGKhH5bzmaAALg+8S8ixx6lY5LokWOcTjTsEWDFsIsob",
	"IRS8bgbsnE8FljICxL6RQj1cLaEBk1NEQiuqvBQpZc/7+DFA/bVdk2PUrp0H0a8t+/7psWFdRwPsJ60P",
	"6KcN2kCW8SvBxC3cYkAWN7wQcw0QYxgiXGq3LFOomXzTzzjCg9dcpzTKn/bPTo5PXuMKlFiXCF3IygXi",
	"w6aR8VlfiyLDyl8oPJjBSJ0DaHs/ISwnO9X902OmVbZsk1gRERkAkT+T0Bp94Tfy0NZGsC6THn5+OIn+",
	"X0AQjTgjUHErwnVE+THz26B8MA6aAC+QHj9EaA0Z70/2HzvJ6fN7zSD77HN6j/+vyvn8458dnBwPpSmb",
	"ouKajKsW+nepmk93H/uUvC8iSEVZoyEXENxT9UX4vWWTMniIymfIZfcJiavJphhD9O+M039nnH6mjNMP",
	"ZWl/pBTVtezhw3ikgPTSD5MS6GUAHPwiwsIZfvBzigv0iSfxkN2PiLWJNiAybRVyNhPF46JL2gxJuC8u",
	"3Mx394dxALkZOCsuCNA+qPHJknC0+L+pHaVqoWlU+7G6z2eiaczHw6a/l9BdKmdUUenJf1ldELd3BaD0",
	"4YhgCCS/D0EA0ukN6InoPuBZBuCpHiDALE0pFgN25moG83QhFctFAUBxWg1ajBWm/AG+/Kmilurszo4P",
	"j1HM737Rc5Vq8SGxdC2U5UkpCgD9LXAG8KN7n/+jr3QxkWkqFOuzYt1ef3lxB48M+4ggr4oo0R0VS5nx",
	"8dhCQnrghFA8iw9xI0NftoxhIEQKXxu0oWkc4Avw9Y88FvXTEHbHPDrS77S2o83A0o8+X7/z8/QHoWDA",
	"9yB78iqR3UfR7+1/WiIB6yN0DoFIB2inXmzYTrnPWyHHCxfE/duAnL7kKTuro5o6mmbSeKSWL4fwDEvy",
	"GwI8fzAN4tYzvobkek9hmw/S2WsB7PHl0svFn0mghNE/iUv9m2j/YIyTCgA0g1A93TZ0uLaRhiZAMJYo",
	"T3k5P3WPO4+F14Cx+Op1M3ktVNharAtqzI0u0gH7we+4gggaVkKV77wQiUiFSsRgTfKm586fK3fTfqBm",
	"0GghFkiiBFetX/hPm2L0IYc6jOx3dB1Jsj1CUadw0LccJbCFNAteJnM67v/x+Ud5oNU0k0mN+TCeFYKn",
	"SyZupSl/CwzwD2YCtQTaxwtMfgdaDD0fziSqtsos5ACBWpdu2x91T+Kb9nOnbrCf5+Tjh9xH7jn9J+Im",
	"zOHxh//TERLd3G8xR69tiG4WD1mLvjgrUPHaQUWS6OL/963/VCMZsK08nItHnfm6Cr1OYToTC31dV5jC",
	"m6yonI0ZpeUA618ICqzyF77Vl1twdKH/oJu/KvSC7vV7Tc4Xc+o6eHHxe85YEY2y1GxiW9gvpYM1Qa6u",
	"g3tt08EyoItUFObSO5AeioS047WNPvl4L+yX7xvzA06b0ElbFG+LqnsabT8O8XfDVlwZD3T1BfoJske8",
	"ar8jlsN0wc50XBDJ0wWKzp46/zi8CU92TNe+SlnEoiKr3CNUa55lUYdPU7FPI4b3JTKL77M3/lsN/1dX",
	"w/Mata2h9s+rkO+nqdPG65fLgydmP03DSC/0Z9Sz40PSIr+GYTujmh1+mn5RJfsRcnYY5735or8Xlfvf",
	"J/ppKbX143PfDYY920+1Ca1vuVQQ8o5NOr1OVWSdYWeL53LregfOMnX7fiV2VSZXTKoy5AbAUFzMIoXy",
	"758eO1xaKpn8Rk4KyAezj6kVIdUZqB7fDyVNzw+/p+wK2yVUOLeDJWYBGzNELLnNzdd6c3PIxjNZzqvJ",
	"INGLLcQBTCf0B/2nP9P015iKrC9zcQ4zgw7+2nitX5ox66p8sYHNT5flXCtoSg1yeDJm3dPl6fEGTCvL",
	"cOy8QCm7D/kJmFyTl/WsGlit02OfYpvoVERl82H5Xlm5okjmshQJ1m7U16K4luKmx6ZYeh7i8XkhjVaE",
	"DlwZwRJuBJtVMsU6g0YI+N4/FnbnXX4hfOfn7rwsczPconkPpN5KdWI2IBOChPyZKEupZpeQTQJRTbd9",
	"KqB9gi1eYwsE6QNX3wrRaSVLyAtKGQZLsKWuCkcxBJr/zKwWUgiUhID730EDLFDrqyi413y5Wk9cIe71",
	"gboMQ9xp7Aiq9tsNVTqtV2/wdxTP8IVUzAqeihQSZ7T9DjasFL/mMoMAqEkVCga4mvzu/UpFnzwoZCkT",
	"njmII8P4dCoSLJ+J3Ums8GhfhVBEeA377t/IVPhXad1o5aFSv30N148lc5Fc+fUasvHrowu2hUP5FQ7J",
	"aaEXopyLyrjKlq4V/XMMRT91UbLnu9vbtvcfDFCaEb5jyoct7SKVFIK68COiGBdcYJ6JAiYq1bTgHq56",
	"EJNiS3GFVWp0lPI2NGohSCRCSkOSqo0cBwwLMiCxYIuA6wREgSm6oUQYYcI4oj2nesYjhX8ZhPXG8+in",
	"6C0TQJ2Qc+IGRONDFru5CQG92NXmJgX0VqbUCzdycVsKBQLfYKR+mstMeCSAHkGKQ3YK4W/6Y2LEtbAc",
	"ZiKUmErIOQ6MEjLKSiDQI2WALGGQiVZGGkzXooKLfnnw7Xd5KRdQtQOALKSa2U5eVVnGLsRtiU8tzzJo",
	"l5AKy7GBoqahmH6h80Ja2sEy2AvM56L+X4rS7vQ5JInZru1w+/yGF7QVQE+IKGpcWUFfghVdQHWc0c1N",
	"zGGgkcNQcOKUsAaM3UmuFM7rgxhp26NtYudul6OrDyZsoCRmkdZax1sa9hJ2owkDfQ8+czto+hps5geQ",
	"me/FZV6PV/4I/OEPRENuYv+uwSn/8AHMy0X2wDetfPTAN0HJbvkkqO1UvnB1hHePG+LjVsal1T8w0lY4",
	"7gcBuYHKCH1g3WTuQ3COwJdr1NaWhG+7nfLMiFrLD0WGv1sPyX64VHwhk4hbse64bURjrOY8fmC8Y9Zn",
	"7xSkVAMgFkJE4B1gFSI2Dms8Zt1CQHatstqbZX8Rb9p44HNW/7RfI8CgLPMfwykBEkx3molb6SQSk+kb",
	"UUDHq7gU9FrERQ1LpbFMMKX6mQg38Q6ox2xuDh3k8riNuMbI2hS+VJs2QDjXq1NEcBbYgb1Z1DMrRM9F",
	"IUs2XrP5Y9Qccl4IVdpe9u0xhHuVOhqujpGO6tjV41xzRv05YYPB4M6BXBNLP/LMGp9/FQ0RTu54pGAs",
	"dij0Dlx5eFgMrf3SLvVc36DYBFuJGzlgb52MgZICOtaD5AGt/PXo729Md4Z3QH25H/LdUpALofD3EwBc",
	"IyY5dFkfyMO91ll5/Ikx9GrFtjHr2sYbcCWHx5eX9CKpbT9hDQN7jfe56S911X/czHqhdAM3l0tdEaD7",
	"U4ezOyv4wtVvsNt3oBcThzFwVmXCHYSxfX+M79sLZQxq4aIqKziJVM72WrBuMtfaCKaVYNywvJCQvWWH",
	"t4FieHhgWBf77VGnGyzhik1AD5wAT8FyEryQHPL/xm79emy8Ov8xcpWWH9ifmH/VchN9Q33rqqyNkXVB",
	"fedpamjOG6sHACh5PFIvtc4EB6MB8ZLAX9CKDks9rAk7bfd4nfun4tZz3BiA/qv1bMIJ5H0rVGaMu5OJ",
	"pwgx4leRfAyh3owvkdVAYwAgsMJvH/9NlTtWBbYn3ldt9Qrc7OBOsavdR19nK3H02AO732PjTKqr8QZD",
	"eRlGlaIdQcMX5sJvNk6ua6+JcTiWTBf2n3gsPN1tDOrM8QLOI+0JCP70xJ+TPmtWVQ/FUUp9JRw0CGqK",
	"imdLIw1EbSHhEFi/1XH8ikH9Zt9VKOzedyfyvo9+d/H2DSv5DPgz8NTwNfit1p9fjj47uuVJ2YcQIs/b",
	"YdVg1L+KdCN0dHxoevYjpscSXoqZxqrTWErbDNYezj47SmeCqb5ddtdxgStRldqBNAxaOJvfK7op8CNA",
	"BqzPfjh7s2X/drtN8/KfcBv7FTvBMh2wH+5Yh02lIh62S4RENqxLQMeoOE8zzS2d+KVIdKVK02NQVMTu",
	"XKILQUswwf5tbxdFJbbgoLNrnlVe0/6KHfJSbF3IhYiGkfJSlHIBK2Z/MiVf5B78zn8aQ9S2XHwKRAf1",
	"GKT/hv5fC21yXtrjHz4wExrMHPYDb3gpyyoVW5lWM/iLwW/hQ5mmovk9lmhdpPbecHOcCW3mHDf3APbv",
	"ls2EnhU8n8uEwW+hp4mu7N0M1FKIGen7OFAHzRVG6ZG5bOc/YpWKgNaF1ImGC5BJQdGOtmalKhHtSqYn",
	"tsOXUln+ABaBuKuoB7ngMyJs+58JvhFOEPAKuE6PFaVC24fH0xUhyoqhDUkVeR9ysKkorAgJMmCsVo/h",
	"3DiRffVCGbP/9////7BxJAitNHV1bJDljRxud/xuKF2z+jrRcNzcP/rZy5JVqRe8lAl7hZX9g8mAu59A",
	"fIDrFi1tAXaOR+hxZOBxVs3xZenIf2yFpUM6GNEV5t/0LY1716O5wbso8DsOseC5B6IO96bLQUchyna/",
	"fxyZ+H2HNG+YLTvB/PUDrezJc6L0T3OhgpQbNjuiAGe1c7G/XkVqCMVUAquaTuWtcEtzGt9voO/hjWR3",
	"GWUs0BgM04WcydApFBWCHr4nJkm3HwijayXY83bhtVXEPMJAnyfJ1/cIurQ+JJ5acYPE3MDew0/RFb96",
	"C8TN6DrpipYbaeOeQkCgheFSA5NZuakj8QVaCHuxMrhYwZjdJ9nbEYVt4/VbMMxJNRtGh7qphwgy6bWU",
	"8sFvubI9fbafpu03cfPKjcz7ZKaHeaK8AfJyU4CA42JlDBAEWFoVaANHsdhjLU6X9+m8wGNzXZRc1USZ",
	"qWcjX33lIM7A8unKGQWzZZvKQrxlzq8Fm8vZXBRBXk+0KVlaAZRAICIjTV0goi7siZ1yMMt7zXZSlaTV",
	"OzN6buU4nuEm0+XVturA/mKC86PS16KYC5427z2YFN5Y0YjqTBV0stRdHzCneBsa+nduBS7gBABOxw3p",
	"Msw4SD0/KMtRaQ8OHZe9uHjDulYm6V/o/ht5LTYiZk/rYcIAmbjNZRFEYIiUtP+olZrgU7vAPMKOSUOd",
	"0MPQbGXqLoZusmQcMvVnBcR/JfaCqnL2i56wolLgPNCoC53xackywVNReNEDPNjsIC5Qan9yDwTM+sYy",
	"dExYAFcEYgSgh2NcltmlG/O41eztKvBZNoehLb6IYfwyNtl9Hkoc3msvp74+v70c6lq7EoYPGoBHnWC/",
	"bfns3T0V7Fqsm9/pGyZLdqOLKwOVJfssEAUQmCASqgMQuTX1XnlZBCmBeJxhsYxBJ2OyZFQ/D80ENQFG",
	"pIyXVNxDagWXystV0isqZawsXizZ3jYzItEqNS1EiPC1dg5pfCKgtpxVp9y5tjeDFIbJxUKkkpciW7Lu",
	"REx1Idw3NzxqIwLlFAIrkYiUdXe2t7fj/ktLwXIh0FQ0096jD0NLtDJCmcorvwfo2rHn4Myh/qD44/yn",
	"3Ll/yrrCYleqFDy1Jz5e6gcOCWox9xyRP6e1H6Pag6QXXfLycWcIPvX5T1A8rDWHyN706EikKoq8FBAE",
	"sHq+YNC+uuNDboy6q8IFMJE0Fg/sMc4GAnYAQqLjGJEHia4EW5oXAtBCpaqJ+QYvJmwjFTt7dbC3t/cf",
	"DCfvArDGu9u7L/rbO/3tnYud3eH29nB7+7/R9hfOvzPuARA1fPtGZhiIwCB+y7Nz0LYdS3iFy6xGyg7a",
	"kRYgyrPXOmId0A5lz71tYxXHcJzh6YuFffiCLaSqSrr8d5/P7cPd52yuqwKf/RnMLH9mKV8a1i0pv4wb",
	"tvPNX+Yomtq/bKMddiPElRtzs0Y2svwoTKC12u7qidmZrzsxGTflJYeoO0sVYbvpW57L7sB8iNmOa6+N",
	"B4Qli0A2nglohQjz2M5KUeAfTpFXY/8Ek3ohrCxolZoDDsLyIycGt2UYtH1ZMKFK4Jc0crcVNHbPvunT",
	"b/SMnWkMLnrkV/e2a0v1Rs/aJBSX1o6f3duG7feCR020nXOraYhCmlImtNkhEOG81AWfCTpwlmiDwouB",
	"Hilz4O72ahgPyzHpjABPj+rsu+7OBmFIA1WeaLQ3pMKIQvLMmSuVECneoCAz051mEq7gtf/Z2d7u2yvl",
	"1kvHc67gd5C1aojwbKJTiQfjrVRywTGKic+EF3tZ93/2ttlkWZKA6l7dwFXA0IZXcB86sugzchFdiSXN",
	"yBIXxQcFqbP7PwuZFJpO7AZNWi5yqylpRaEQhN4L3SacEH4XMsuA+mNhFUd0QCvyUsz5tdQFDems9dLv",
	"+tL3kwydI2/g6u+DsTpURevmBV57LK0wmFOA0AOvvOhjd2xW8AQyA6ROmaC4lptClmRgwIJthaAeUpRP",
	"UAxIvXDgBQKzweizsBs3c5EtPJYjhDk5Yq1HZFkKjKrm2S9nejZzrhxHMi4Ei07J8cmrdwzj7exHbCex",
	"rB6fsm93n/tuLgH5+Zpn3+5tG9cL7IFIWZXTIY8FKLDLfvt8l0XdvVjYbS15dkntv93Z2/tzzfHyVqfk",
	"zLRDW9EINjf3sYwunD+NWa6wWnZriQiIDZooMqauHwSn5H6eZxKi/cpC86SU1/bsNmxipn7hhQxbnDP4",
	"53hxRb53Lx/6zXa39kJf09DdARJlc2R2Tou8XJILAMaYZfF5Ing3iIIrNXKR00JcS12ZbNmyE4VYcEmD",
	"OJhzNbOvui+uXzIlbhqDQ+f6TbibOa1eLBK3rd1RGH0hEp4lVUaoKHYoYQ8jAyJSwxu5cLCTzi99kOnk",
	"qgn87kPCNzfRTX9ycQr2kaVKWGLfMC7QzIVTQoCm6xIPAPEgiNpaWUV3j1Blkf+psRfqwB0SCv6FIEBy",
	"FCYxJUPA2cUbv37NNXNuQyBq6isI9SAQ2S6c/OaEN124P0+40nH44wrY2GrwIxZVvjf00eFRgsU+Yj1o",
	"VYLi1nHdxS2qudirQVojDP9IIayfQ6LsOcOHvJZpRZWP6Jp0dn6sYfmuFjN3NJ3KRCKsE36WaQdlE4y/",
	"tYXlzOC9RRkhiI0LIx8pHwdspaW8JBufKyTpjNZXYtkHLxLLuSzMRq3CZNf7hOHWd6M/lPZETypLQxcF",
	"V4YnfhYrge2lXsiEnMMQFoz3CyujFz1guHcJ6QK9uiO128/n3IB3fyFL1t09PbC3jC51orMBA9M4b5bL",
	"ZSbnyoRVw3hkZyUfqabRi+CLZWllaM7SaILROAdrTAg7A/aWwswcQirPwNElDPvuzUEkwULArMggmiea",
	"LA5wpHYH7CB6SjdxNASqnNBDM2EicwhxwBWVYEs1I7U3YPtoBYMyk2UowSrSXu2zuKi1L4zU8wE7jXu3",
	"l4LSJdpBuGNXyKIRQ1Vn19HnXwzYmUg0SC6Z1rkXLLAT8v95GH1wMpJMG4+NYrhxzV9hrL/TETc3vZvI",
	"lYIgj9/+6bHnoKzPfrF8pcKQbCISdy6oH6BPF+ruRB/krxAjj5HsRH26YHyii5KVeibKOVpc7H0I07Vs",
	"B0LRV2eBqzjnKs1Eyq4lh430S0Tc27MA28v/7G4vjGPkUYQFHqKyce42NyP5vybU0gtovTFDKKaxl7AX",
	"oXPQutf03RgHVgIBmz3sewUXr+szukhudGHKPmRhdFemS6L464oXXJXCb2u0BUSusOJOBe8iM5HlcgNd",
	"HyvLjEmSfjNY1978aBsDhOdFkwox8s/XFYkmxbpBcK4TLnje+FRsNMqGxPIHlNsQKBr4YidIVURRMdBJ",
	"XuipzAT7kxWfHQ72hje490sKE0LWDbWbwSjiFimmxpdVdkWOEJcwCrw1y/q66Cttr/wZM2LBlVMNQTqB",
	"aw0LXHQPLSc7X6oEpvh/Q5kcms5HVMiRq/Vxeh5nvlERp+dv2PWFcO65bFCFbVTjwC3I+cxF4nXDJK6E",
	"PTG7A3Yu7P2Dz6EQTqnrEk1gjvYSoUWBcjJDVuU4Q2eHW5nMPcV9sKrPc3sz5IKXwM6UuC1xFH2masV8",
	"PAOvVfVpO27kvyaa2nq7PP/PN+BMPj96c3RwwTbZq7N3b10hH8PenR0enbGX/8Vkyt4cvz2+YKC7vnv1",
	"6vzogm2PR4qx/krxn8OXjSI9tcI8+M5ZpUiRdoHGc10V2XIr5TJbbqCLk/sT42NT8WDYewvGDclFgHwK",
	"uYi727vP+9s7W24Cg1+MVv8/wLz4VqZYFwlKMH67+6I2+ojoE17yTM9cXkVhdBHRCb5Dc5uIRC98lghw",
	"HfoyevL8qPcY8Ig3/Epg0lfhS3ZCgAvrju253Nre3t6BMY97zD/ZdU8Gg8EGfh8FYmRbSDFw2kOtJKqg",
	"hK1PCRYcPyUVgwXpMWPJm3zKBklrsvQVpezA7agnhUyuTAuVpCIrOSKJBEKx0nuglNoaN4bYLOeELTFp",
	"plbWiXJw7C0VvY4x35bEX7oEJCfs+EpYJOzgJkL5CrBRUZpZ35W7YrVqV9hHvXhWqI/VLyrVqIfVIoyc",
	"YzGHkGrZs0e24Cq1H0JzLNr5vlSVKtKjEqjLp1JGgOvga8WwcFTLYEOueSF1Zbyt0P4kFCU8ji0ZDbe2",
	"tnJezrdKvYUvQjybhkRES2Zkvuqzsdkbbm1NquRKlPCKbbi/4L9qxc737Pcd9nukVxZiUsksdTQSocEz",
	"o3hu5tqH2bHvLcU5s+pIHcpCJGWkqJEuSSVNAJGDwiWcxhmURLzBZMEqJf9Z4S0Wa9NNAPpVZRrOedBU",
	"W3Rpqv7ivYok59TS9qaNINMeu8YYvJXAut5IBQYLuW/cyq0U3Q2aub27gWzORCLzAvbojKsr9grqdrLu",
	"2dkrr6ziZVmLvoWIVwjBPScGDs5bTK6jsiJLVfJbTEDRN6KYVhmLhi/VDEgHvJb1VDhpr8rxRKfLoT0t",
	"VSkKsDa5AFFcbF3YVvsnh5Yvvjuz/3/y7gIankGR5NDVUvBiCAK22N3e3ca81HlhJZ7QaNTBcJ0cfhh1",
	"vBHynAQ9P9UTjnnUGVeziocv0UatbAtWXoWXw94Gv7iPL3FpnzAFqqnjpEy4D6nLujnN1XcNqnrocKFT",
	"kflN+w4pAkeCWzxSFP1kGqFL7ruO0+LU2qmlJUjddnZpO7ukCx69okAZLpIx2l7nUB113Hej9zAN0XJS",
	"jrp4lskZBHc6/5lbtygE/tL2f6msslMLeadAQXJdwFR9tVpkPFOspYOFlFAidOQ79S4Pfw7gCTstxFTe",
	"UkA9lkOKOMjNXBuBRYnxbqFCzp7o0brbyFfAj13m2HXHleIdgicZ5uJoBPwW0D0oCtRuZ3cPXdjwr+cv",
	"vhl1GqOGcz1S+3meLRmvHV5uGFds/+TQXjcYB9k+PL+j9d2lOPTlsBTJXOlMz5bQW+Mkjjp3bjLBog4a",
	"BEa+A5+y+gNgDtDQVEobgQ+8987vo5vYEUZiRTvhwv4as+2evLsIE91ozFS4fh+cbCryQiDE97szQgoY",
	"ArO7Fmk014atwd7vwtlPKGoffZdgEbYyPMSVmER7oi24upJq1qO05AgpLPTr+PfZ/mvWJeApnvX3q5ld",
	"DZGy1x4pYgMDRRu3kEodmIQIwbbECt68eUslpVf4T+E+5XqCZlSzzJ2seyqNxfyvUfhKinrNqyQ4BHwg",
	"Z/gGyAgh6BduU59SYm5EwfZnkOA3Useer5SunJWuwAaBh9VH0OGPAWMD1uAg48ZYbm7C4hkGRGLQRW0F",
	"TRdSi7WvafGFgdR6cMMiq20VAuI1CRHQHGZhWNfesu5jZoPFgdjHh/S7oRtoI96OhEaOlpkeo4hL03PD",
	"QFs8rSgt3rGnObpLzlwufJv92oECACuwIhTmRGE6fcimtx9g/6wg4tXz151B89Zy0bpBAvmTv6E3MPYJ",
	"uMa4eQVR9Gbjghl7y49VrIk0C4GiNfmkLKddLyUBxCHP4CC7EOfAZ2pXqZcIPM/atV+lsxw4MVophUp0",
	"Kgq8xEnTgHwWT98eoRKIsu+33EMTDOzQbfeOoyygoFKSVAWGhnC1Ii1ESb09ZrQz/S6YZYfk7ez7YDg3",
	"FLLFlTpnLyAWAaXHplzQer3PMGI/4zl4MN2tDkq5bbGzvU2PCppMLWCMCK2gSLAs4wvuI8FGHZgVBXAJ",
	"NUu43vrPG6H2+m5l+tuDb14OX+18E70URePUkudW4q/sJu450mGnRaVgJ+mG1VUJaiuRddi4JUtFSYgs",
	"uKcznoM2aggEZyGVXFQLMJOZuc7SdviG1gVdQLyOYJnghQqQBXapKtVYvYVUlzCCS+Bn9rftwYuwevyW",
	"fp7x/DIXRULReXvbg+2V1eizcaO/8ZB9L0SOMoqbvr/IIOrSlOzv/8uX3NI5NcPe2j4/tsq0zjEEGDO8",
	"WFroHKkbiPrv/8sbviB4MqlKeS3qbOwr9nxA5trz0p6HGVxVB5hIO9c360TiIuITLmMW1eCimI5Zl4JV",
	"N4brtKu+YxhpD82S7EaAn4kttCkBeAmD1AozHdteMg7DPwdK8Z0oe89n8le6qm+EnM1pde2KyCnYwcts",
	"iSo6l5m+FsUYfeJhbnIa8YBwsYFDwC/VC2cz9bIz8tpxLAeOXaJzJLlCEENeCGIZDVkmkl9GCvh2JL/Q",
	"zeNgViYUYA6aUkHPy0i6E7wgu8bmZi1XBD1KlOURbiF7Kbq7l/Z0CNbh8yCl18yUrBtW7U+eHtAujLzb",
	"SW+lZooXhb4Bok41xlzsYS6b42IQfuzp3YBxF7vBc4o8H5BHdVVmUhQmNjysFHhctTw4EJp7TA8OZz0g",
	"apE2hZkwjzc6YBdW2FrolGfNvDxElPBGhGaKQnmjfY4wJkBAfoQXBKLr/Hrb59xGFgj8wEi9fLv7gtKZ",
	"m4MnyRUk/0HIkgPVGrF0MOClCR9UT/8iAjtohHC0xCj6EOB47J4XxxkIkJsi01v/40IsLi3L9Anp9Zjf",
	"d5iZ7EACXOsx6zqYpo0hO54CnEfPgZThslomIxYayodmS9atjADVVhesFBB5s1H3F9NH7Lo6rYPxbKYL",
	"Wc4X6y04rIupXcGEs9Fqw2HdVRvOxooRh3VXjDgbq1Yc1l214mz4zALc3WdmNRs0bLJLOSN5206qNA+k",
	"TK1m7Xui5VdKEb1Swux5ODdEsPt5XuhbubCn8KqvBC8s61KWmU9gffa/PznZcNAvICGsyJN1Ar9u5uYO",
	"VlXOxu5+x4v0hheiz5NEZKRdpNKU0NgFaUWBJufHbw8hl6CoEq+A3f7lm639t4dDtv/j33fRKfjj3/sv",
	"dnaRzZLDETkLDTIGveqz/bO3Q3Zy9O4EXj5/e8S65wnPKBipLORtQEjZYH6sYLuxFPNSlv9pdQhVulAw",
	"tPCmVSJSR/dTrcu8gLAelbqA2ZCkd6LZ69Mf4ggI7aN+bW8Hpz8Qf0lFnullFIbakrj0AGcgAmlhCn73",
	"anwhlQucPYhgf3lOj7HxB8vFPMv6Vt7MFtHvVUG/zssyH25tZVaMmWtTDnd2nu89b5GFfS5CSonHjj+5",
	"4Y2H7Ij+rIfAwcI60cNTsImZHc8anfqlGA/d4fKPWLeexO0GYGWdWt73BnkvRJaOh5RADEGXEx+Q+Lfz",
	"dyenvJw7g7bLhmhoBmN45LCyBnT7uedfDwCdeGIFbIJLKcUiz3gpxkP2HQS1TLgVHOgpchbM48gLvcjL",
	"SDRDH4qv524XQNppb0XXL2qNYH0PIaKYQb/Fq1TqLUscun5/gGDtQO8aVwXd434DT4m8Wq/zFlu0I0cD",
	"sTtWLAp0UacGf+m/A5plXfQhvQX1dGP1ON1D6PeT+aOI3NH3qc6rjJM6boZsHLqzewym5j7MqO/wUxa3",
	"Ey7pWcaLmfAqI+DRHj84lVwoLtumAqAtfm37e32zAAwYaslzeXklyDxprvqDwSCeyls3hfZuxqy782Lv",
	"m3Sj19IC58G6e9t/3m1rwVPe397e9X144AutZ5lgr4VdsocmPsNWD098e/t5pNzqX0RSUlrkqLNY9ulR",
	"MCkQdIYzp/etOlnwbKedwf75m79EyTc12sZDFsNfkFaARywgnOz/dM5eirTQydVDs55QszbSBefooJQl",
	"VxGR9a/DyBHAw8/M6tX9ndZdX9+ZJdq1v+7aXxM9F4UY4HOhZpk08/713spPsEiZVLOKZ/Z3ByMb1u7Y",
	"J0WPFPFvp3kk3Ae2e9AP4FmoZADjcrJOO+MLOT2A9XXueSXrXtzo/nnJZ2LDZUpiH8HO5m3esKV1KKBy",
	"Lshkhppd9GOrfWb9Vf/5r3K4oJ1fza/AB3acZfyat176cXyV1bR/jJezO4YXxxt+Vc3KsgKUib9XujFj",
	"3fBwHCgSUM4dHkWRum8haZNksLmJ9waEp+DXe/RHP59LoNUJv2r8Aq/sjR3grGXPCAqel/3n2raDv/pl",
	"VUzCPzUMlN5C3oZvwZ/93cF2f5pxM++L2xxewuc7gxeWNzWeQEvqa1+V80LnGFc7TjJutY69/ou+0UqJ",
	"sr+7vft8Z3sXz6T7VeeVgV+2d3f/Y+ywbYGpONBx7HSwvsP+9e5w299TJ2h4io5tl2JK3BECsGqyHDsA",
	"hhTjLVoZ5ceckp3t3Scck9ol8thr5KGLZIX+cdOfmVU7uuViuBLoDcGES2dNRL7m82W5zxassSOPAO0p",
	"/q1IJad82YBsg8wwWnBipb04B4sr5mNjGeTogIjnRLUbvgz2luMFxgsCCXEjvnnO0B+Rsi4Ebf1wdrwB",
	"RGX/NYTZbP2Si9n/nkDrHsYz4z9Qa3fxa9Q4V49veyMm+T2NcZg/nL3BkDSS5RDBDnHpAbpuj/6gYCVP",
	"5Pv2amEYCch+dFLxB3ZIaDvB/4buSjuNNk3Q4R6POqcUJXg616UOoQ32RZ9+3rbQ8seX785utr9/PdP7",
	"+/v7J+c/zI9+mO03RD7ExiLlov8S9NdT0CuAiDBjXP6Kdu868EGi1bUA2nMYLWTDDRSP5NeixnyiS3Gd",
	"O8blT9PXags5ZO/fw/Le3Y1G6sD56Nn7985fDz8chv7sb1H3d3f+A5/6Uq5foG5b2DlEyIWYRVA4LQWu",
	"rqxdb191Ye5//sVA+YpZJVOxRYlnlL0NaWZuW1pSoxMOOakY4hplyCLGDPk0hiGz3vVuFd3bst57IRJh",
	"7w1AAaglH3ODhuHbMjaZ4Exp4uP37z2O1d3deMiOMZULLWwQwEfNvpIEtXl3NxgM3r/fklN44cCFcvCM",
	"ZXomE9ceU9+Lgi/dG/YJfqREmQ9+Ne6FSmWWa/vYEPcaPqfRXYsCsqv8R+ntvwITvruzLOL9+79eiaX/",
	"eyoLU/p/ZRz+MWRvtM4RAMyFKmxuvqxkVvalYt+JLBeFC9reGbDNTZMU1eS7cpFtbrI+oyplSMBbplxC",
	"0MPMEBZVWfCkxBReAuMt9AJApIBkx+NxoCN48v6975/Ny0V2SUaNuzv3AvzXfdiwMfJmHADxZnQJ0Q92",
	"SO45gJ/j+1DdSYmbDKI3MI9pApmdIkNgC9bNeyyV1z023+nPv+mxTPaYKBMMfmYhNiLPuKTpYexWISCf",
	"LGWF4KmvewEum81N8U9YuCPnnw3BuS7U1m2pWbtGlgi74p+uMMiog4nDo87G3d0+/EmE2Whv6eH/4+1a",
	"m9u2sfZfwTh955W8kuzEaZtVJ7Pjxnaa1rexlc3s1BmJlmCJNU1wSciON5P/voNzA0BSsp1M9lMbiwRx",
	"OTg4OJfncYY5Vl3B44y5CDIdvkWqYsf1GQ5u6PZbnf+RWjUzljxEeKajzeG2nxtDMyKzciT4+rLMXsMp",
	"s5fY5P3ZO+m4/9ku0moAz4yXZdbyAPpTnGoilknQSvDG4K9ijqlQjXfgPOXyCU4PxpeKfNVL9czj5kdo",
	"8pRS4c3h/dkhwjpSGQRIEdocAEcZ2zxs8kiiwyqzZzAYTFgmxW5QW4HhoPrqg75036/quUWC5XZfaE4Q",
	"wPIC5XOs25KqgWucdxPZJaqvznf6INEWwOw4c7tDICr0YH3Cr/U9gi/DhHksyTfUuVNxJ/p529xEexFA",
	"Ic1dnpkEIIBLXYHfvJNeUW57txfbEzKx0tLp3kGFp8kny1oLq9hAaWJNQqnzGeSfJOQhkNedPnOvn8F2",
	"z+gS79tBU+XI/CfNsoSeEqWAMkJsWjDi0mQiHzwyPD2L0rgFwvIgXjlm4uI0Dmf/oIoj8OuFqay6W6RW",
	"Z2ll6cfTMr11Z8+7U1R7cLgL+sT5+dmBSqxNptcVixZ3BWHiIFOmCg7p59vbR782nrXpjTbL6MGdbWkS",
	"VjBwoTcafbH98lXxqYdEW7SyLCjnWg9VOwnUVuTbfcYz1O9PycP/EjQxbLSRMTlqZPinkNiMTk6OBY1o",
	"ZK513j8pU0xiJCDRY4KL6a5Ub/4TChQYIviJUmn/WWU6n9vFUVJe6/I1Qga7Yz23r18+9OpMwxzq8vXF",
	"xsWFbVVIMLIDKuL3OXObmzvb/Z+2/w9RqzGCheEkOqNw9/x+fnLMEvbGIIgKhSkICW+IMcpajToLJdSm",
	"4wgRtAJy6t3J/OeznY9DlaQ9iu7fZHzYj5JL8IPTcrjWl3nqoQCEg4G/chKFzw4Pj1SRlBV5/pRSJ+I+",
	"Q/UVzvhEdS6NybpDwM58pjCnBCASoO+I9xwIqS2XWvQvLtQEQKO7Q/A4EmOZqopkCtvMi7e8Jus2UR1M",
	"ze5ybIgu6QZRsi1NBdqMEEtXE1rrCT9R8R7hm6FZ2mJph5ENhaFy9a7GicdBYymSU8iVMlS/J7lWewb1",
	"XvuCNWRNoOKCEw/k7zxixZN9HPDhWWPyPq44/D+9/daod25MwgTX+nKSFde6uk7zrbnBly/yD+L34Mtb",
	"D2NCGItDM1+lgAA2EzcKVLtahJNKy+CSnVaKEZP0bBDhAe+j6nczCsctx/OY+42/KOykPopVD/0hfiw2",
	"l88JOhzNaGIk8cDJsgueeAMOrroSTGy788ZX0lWX0dX30NodVIZKUiphVvFRAPq5KQjBRDBzJlhgQKFN",
	"JYQrBOwMh0VR6kLns0pNfhhMOAZLNbDMSPPDoCV2CkD4RZZOUxusGz0P9Cp/bn8cYNB8IgotDSILboX9",
	"4Y9SxSXKCRVeDBhFmAKyZPsjejpU8ks+EBYMSh1VTJviSQaj2DbPqNQTpaAGwL7ZZxfKV4qITNV3d1Qc",
	"G6uHYdTd7Tlzk1rMQyecv8s6fDrs6cChz2GBnVcvfYwscC/DFmX8QnbrfK0D6eefXrV6iMQx9E0en6/2",
	"LzdjjE+M06z7cj2esCJn+dSfMxjsUOfaLouvd83/uPNTUzyJguTxshkGvJ8S8m4EvX/4fHK6f7z7brx7",
	"+m78x/6/vrTOQyuk+OYmpQB7W/gurXQGUFC/IX61/FRJIQNm1U/vIX9ewJzp0rVFWXCAd01udaC5FJdZ",
	"C31VmLZa0zQqza1RNzpxauhqmVGOSBVQK+F+qjCz+Z6hsOyd6VcWroFe1NTfJEOmGwCgw7WoRwBJ9BYx",
	"OaBOJgJRvI3eVupNZpYAukWJG0AI4I4LU7hDcatw95zpfU9N3YNBRgilqZBEblXThJGuyOwKDRQopmYw",
	"czq87yQsOyNmSkR1uuKMnuTWpDN1tzCZ9nUSEciir21Be8a1sxtisp9Lbt8IylfwsQi3fatJKhVDuQ/x",
	"tH0+UHtYaBhirDUxysET0AqAuRZCl6by+4Pocrrad2BtbGUfWEX99wiY3BdMYxNmvjtDoXV6g4rSANzb",
	"p+lGE7sq0Xd1Z3Y4m94dj0R+QKRVbb1pr6albgWFiLlnfhhmSdGi8sDgbcPCB2kT6ou8CYvvTTpivqBQ",
	"gdA2dS9yhNVBlCRB4Qe+dpWAJV8i8+nA3XgVuQZ7gHhbXGzIm/BvawoUhCwp3BGA7l6uaNSCir9HmA8f",
	"3LcXSVHovEJ1cG+W4HTCNHp44R+M0oHOgYr/jgibiLgN8FxK52U6Xbgd1qtjnREQQVCwzQh9HvJ+oH7T",
	"pf5/15PEIjRloacWO+Y/itA7qkOI+6y8cn1HKXgAT0EgjZEfpSuR2l1+61jfUZa9NWqfYRRHiBooKXot",
	"I4+Ht2oevOpyV3E33Gj7XDpbIz89OR+pLSxZ3PoM/4UwzhbN1NZn+B/42yNMjMhkGAwGzT29L/2TxY+G",
	"QzElmY44tImjQ76ieAEZ3TJAcvUPe4DLOnpskGu5Aj0WykUBFZd4HjBs4E5zIjcvSjMvdVWJqjiq/RBP",
	"OcDdPHbGaeoOjblWiVUTQNIaYx+IH8VPKH8PMIDhSV9rXZamxLAks+7tgrz49ZDchNbiovhLUGrUq29O",
	"ICavEGEXYHSHnGVsy/s61u9BkmZ6FjTaTlBhy5Q1l/5UmNwd9EkGC2+urtYsp0fgqy0oozJj24hw6kfm",
	"LmhpLtVGdqFD8m/A7UuvVGVukHEdB+ihfWFYAWpfi+R0Jk0JqK/+lwnadTCj5DRrJ2eHWal0fXGWpVaQ",
	"vBVMdR1TNoQ8uk2T+jkLQQDWYeQ53tx8Y25uTM7DVOdTnSdlaqIop1ySAbzmvWfEFy9WMOG0DLWFx1JB",
	"Xd6mU83wdpX4x2vj4POuw8k5Pnup21oVRQ2BF8HtgjH4SIahMBI9kUd+DLZFB8SfISjDajz4oSvhyjMn",
	"c4CCC/F89uJKiIakmOrmbHkvrmGk6SGnMCQ5s40utjFEv9Hpz47b0t9j3Mz/e2ksmarNtG6JT0IuHioI",
	"oOsD1H+0AnphuKIrAzgMgKqDsnXET85vdWXTeRJEws5oiStrCooW3ySfVGLdbcrWl5VWFQ9pYWaEZY10",
	"1ebmQZJlbgq5HPSehPAAinxSkCXY8hAE6gkopi+tZFBbet9N7lWSoXqBfzQE526lhoS1b3UePgyuQuVA",
	"Vpc3D0CrRE9K8Vk512MeBFm2NMQ4p2i0SCvRjIJbkN0l9xXDoHCxLKu6IGXa6eel381yuAgsNVozDdjv",
	"kSE0QFIs9eIBd7sqTYGOYj740VhRk739w/3R/oP6EnbcmSZ6ZIHAxk8N1aTF0GlrZGcQmB4QzKoaR1Kf",
	"DQsixDbWXfkCUlG2MjtxEWSXbbgIcdswKxKznIZfu8gZRYtqp+HyiZNJAAHJTA9ULR+7I4VsXdo0dRDb",
	"pgHsyZwAoutXTBk7Sv4yZWC+8/aCqgKYoUrbqsfAXpRo5m3V4WNsTXxZtgv+U7I5sc0+tdknUpMVJQIQ",
	"Ib+5p9A4waEJlGAjwe5tmRRUiUpF2cCwOhodQqoo/OonFVg5eVZBMwHeaWryapEW6CllEAlbJu7I8pgq",
	"A3WYXgfYNj0FzcHFrbrIORW3lfqLTfxCl8h7jMj/4TbyhKV+SOrk1p2g+q45GERrwzCNs8JcJ6QCP+gj",
	"jJPBalKCNiUcsHxGKKuuJ7kmXGvE4ZM2gG0D50Ic8P2FKTgDoh+AO4WziThu7qIRpJ3N/RjaWUbkYsJL",
	"1Va9a6Zpko3hibpAPJP1X0dnFqyRezpE99dl2MnH05s9quelnurcIpkD4yCvZ3h6kAhsHxb+iSRgoq8i",
	"NrBvJfFKprgZ1AIAyT2A+LWO+Vi6bnNh0gVoRTekhJnxZyEhGIp1kwyssTnrV8R1LGDU6BMZwESubquI",
	"DRBXJvzL5qbqWM890EXAIrHDwVSv0U6IpUQuw4Aa40FygiaJmy9knAjREUkQj8L1EdXxU/oY7gxUXmFP",
	"kXrc0PxCNxPrMdeCl6XbIC5NaVQdIvRJcwVyg2DAfbXHEBtha1S/BGyXgsGhIlqrNfRXsq4ASCDQyU0O",
	"LJVU3lgejQ7/F5xYawmw4ECovl6PYtrk+BF0jM8jPTtym1fh24gFzk38QmsfqSPizAKyYXiJ4ZgAg95N",
	"5i79VR1oPfv68XyLdvWQOU4CsqSyQEHmeg0jDBv9RZnM3e1Ij7TRXTUIvc40QBvnyMb2DYtmSw3H9jg4",
	"sh8i0qwvHbchSXRBW7+oUl+VuloowIB2h3hGAEkmm0Xry4sY3pG/QRqLdOzm8Kly6O7J8B6c3W6x1kkh",
	"+ASydIY4c/nM3AXXcKTVfxQzmWgNPilj7eEBDBgNtkV71PjNiDuMznUAtgS+MVSS0WlaxccpgShI83Uy",
	"M+E7dO12nndhpqBVIpsoNeRYxubAozjOoBWPAv10orLY/go50hh52lOVNU791XRlZJQ/naoMlo+JhOqL",
	"tpq7bDVDGeJhoP+SHlzFRoZi6xYHDJZuO/GYiF47+1jAgYeY5LHQtbGQ6bow/2Uu+Wgdu5v42Nrs9c5T",
	"ychwOEhE9vzFz56J7NXfG0RkP77ceSGG7hF5RsFK1LO6UQ4H78i9Hm30mapSt1uJOuNST91SUm2AWzen",
	"1HmEoldQgnLX9dsq6rp4bevMaOENcyUhWv2m01dvEEMcPBCwHxFDrRCAUS3kyhLr8RY+EdoE5RVoOqM7",
	"gprCLX6aJblKplNgGpkT+n/ADNBAUWmhRgN3TtAr9vywJ6/JTLabZXILnZobkP+bJBdf3yrqs3VfWkGC",
	"Jg4e3T41a+jLTuUC3mAEg/tLaOG6a0xqK2XuclheyjAnpPnZnLnFPG8a5Xy02bWq47oom9G/Q1Vdxwac",
	"A1rs82Ewo0CbFXatWiSl9sdNaOsScj48xiJVY2h7k+SuMzcg0ahK8lbJXUP5hhn/JMfHo1Nk1Gecy5D1",
	"vJX3jVxVjWQgZ91SVW6IihaZ9dWjEwhEBMeRZ2JlNoE3TyiTQFKdyLZk+/URLfSCn1cYn/VPJJkTizFT",
	"P3/bJ54vVudDuAuF5DfFN6k4kO/nPfSRmCydpo2VQXp9cxV7gQZRgE30b2bm7MH4AMDTwFCSzheh6g2o",
	"gOg9UDQzsFlCmVfplbTMdCCJujTWZjrX02u63GJIplqYEni7aqyBOB63An1380/5esPokGjQV1KM6zUq",
	"DeSfunT7qe5SuiS7Q7ItMDPBY3BBo9ybEI0RVGCpKW8XgQGik6mv9iEU0OIPIfDH+llcYlp3iGoIK7+e",
	"nBC1yVpywpOQNwI5pKzBDBT/qfeVLluahz8/tkm3p1O8bvqGT+WPLc0HP3756H62yfxtaZZFtTH88zM3",
	"QaHw0+VllgJpx0ZvwyZz98zGHDX/GMDk9Wyjt0HqLJ62FprHJldFC4hkYwU+uskI5iyY+lrPaEaDIX78",
	"8vHLfwMAAP//01d9sA9WAwA=",
}

// GetSwagger returns the content of the embedded swagger specification file
// or error if failed to decode
func decodeSpec() ([]byte, error) {
	zipped, err := base64.StdEncoding.DecodeString(strings.Join(swaggerSpec, ""))
	if err != nil {
		return nil, fmt.Errorf("error base64 decoding spec: %w", err)
	}
	zr, err := gzip.NewReader(bytes.NewReader(zipped))
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}
	var buf bytes.Buffer
	_, err = buf.ReadFrom(zr)
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}

	return buf.Bytes(), nil
}

var rawSpec = decodeSpecCached()

// a naive cached of a decoded swagger spec
func decodeSpecCached() func() ([]byte, error) {
	data, err := decodeSpec()
	return func() ([]byte, error) {
		return data, err
	}
}

// Constructs a synthetic filesystem for resolving external references when loading openapi specifications.
func PathToRawSpec(pathToFile string) map[string]func() ([]byte, error) {
	res := make(map[string]func() ([]byte, error))
	if len(pathToFile) > 0 {
		res[pathToFile] = rawSpec
	}

	return res
}

// GetSwagger returns the Swagger specification corresponding to the generated code
// in this file. The external references of Swagger specification are resolved.
// The logic of resolving external references is tightly connected to "import-mapping" feature.
// Externally referenced files must be embedded in the corresponding golang packages.
// Urls can be supported but this task was out of the scope.
func GetSwagger() (swagger *openapi3.T, err error) {
	resolvePath := PathToRawSpec("")

	loader := openapi3.NewLoader()
	loader.IsExternalRefsAllowed = true
	loader.ReadFromURIFunc = func(loader *openapi3.Loader, url *url.URL) ([]byte, error) {
		pathToFile := url.String()
		pathToFile = path.Clean(pathToFile)
		getSpec, ok := resolvePath[pathToFile]
		if !ok {
			err1 := fmt.Errorf("path not found: %s", pathToFile)
			return nil, err1
		}
		return getSpec()
	}
	var specData []byte
	specData, err = rawSpec()
	if err != nil {
		return
	}
	swagger, err = loader.LoadFromData(specData)
	if err != nil {
		return
	}
	return
}
