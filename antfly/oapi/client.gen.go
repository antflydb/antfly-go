// Package oapi provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/oapi-codegen/oapi-codegen/v2 version v2.5.0 DO NOT EDIT.
package oapi

import (
	"bytes"
	"compress/gzip"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"path"
	"strings"
	"time"

	"github.com/getkin/kin-openapi/openapi3"
	"github.com/oapi-codegen/runtime"
)

const (
	BasicAuthScopes = "BasicAuth.Scopes"
)

// Defines values for AntflyType.
const (
	AntflyTypeBlob            AntflyType = "blob"
	AntflyTypeBoolean         AntflyType = "boolean"
	AntflyTypeDatetime        AntflyType = "datetime"
	AntflyTypeEmbedding       AntflyType = "embedding"
	AntflyTypeGeopoint        AntflyType = "geopoint"
	AntflyTypeGeoshape        AntflyType = "geoshape"
	AntflyTypeHtml            AntflyType = "html"
	AntflyTypeKeyword         AntflyType = "keyword"
	AntflyTypeLink            AntflyType = "link"
	AntflyTypeNumeric         AntflyType = "numeric"
	AntflyTypeSearchAsYouType AntflyType = "search_as_you_type"
	AntflyTypeText            AntflyType = "text"
)

// Defines values for ChainCondition.
const (
	ChainConditionAlways      ChainCondition = "always"
	ChainConditionOnError     ChainCondition = "on_error"
	ChainConditionOnRateLimit ChainCondition = "on_rate_limit"
	ChainConditionOnTimeout   ChainCondition = "on_timeout"
)

// Defines values for ChunkerProvider.
const (
	ChunkerProviderAntfly  ChunkerProvider = "antfly"
	ChunkerProviderMock    ChunkerProvider = "mock"
	ChunkerProviderTermite ChunkerProvider = "termite"
)

// Defines values for ChunkingStrategy.
const (
	ChunkingStrategyChonkyOnnx ChunkingStrategy = "chonky_onnx"
	ChunkingStrategyFixed      ChunkingStrategy = "fixed"
)

// Defines values for ClusterHealth.
const (
	ClusterHealthDegraded  ClusterHealth = "degraded"
	ClusterHealthError     ClusterHealth = "error"
	ClusterHealthHealthy   ClusterHealth = "healthy"
	ClusterHealthUnhealthy ClusterHealth = "unhealthy"
	ClusterHealthUnknown   ClusterHealth = "unknown"
)

// Defines values for CohereEmbedderConfigInputType.
const (
	CohereEmbedderConfigInputTypeClassification CohereEmbedderConfigInputType = "classification"
	CohereEmbedderConfigInputTypeClustering     CohereEmbedderConfigInputType = "clustering"
	CohereEmbedderConfigInputTypeSearchDocument CohereEmbedderConfigInputType = "search_document"
	CohereEmbedderConfigInputTypeSearchQuery    CohereEmbedderConfigInputType = "search_query"
)

// Defines values for CohereEmbedderConfigTruncate.
const (
	CohereEmbedderConfigTruncateEND   CohereEmbedderConfigTruncate = "END"
	CohereEmbedderConfigTruncateNONE  CohereEmbedderConfigTruncate = "NONE"
	CohereEmbedderConfigTruncateSTART CohereEmbedderConfigTruncate = "START"
)

// Defines values for EdgeDirection.
const (
	EdgeDirectionBoth EdgeDirection = "both"
	EdgeDirectionIn   EdgeDirection = "in"
	EdgeDirectionOut  EdgeDirection = "out"
)

// Defines values for EmbedderProvider.
const (
	EmbedderProviderBedrock EmbedderProvider = "bedrock"
	EmbedderProviderCohere  EmbedderProvider = "cohere"
	EmbedderProviderGemini  EmbedderProvider = "gemini"
	EmbedderProviderMock    EmbedderProvider = "mock"
	EmbedderProviderOllama  EmbedderProvider = "ollama"
	EmbedderProviderOpenai  EmbedderProvider = "openai"
	EmbedderProviderVertex  EmbedderProvider = "vertex"
)

// Defines values for FailedOperationOperation.
const (
	FailedOperationOperationDelete FailedOperationOperation = "delete"
	FailedOperationOperationUpsert FailedOperationOperation = "upsert"
)

// Defines values for Fuzziness1.
const (
	Fuzziness1Auto Fuzziness1 = "auto"
)

// Defines values for GeneratorProvider.
const (
	GeneratorProviderAnthropic GeneratorProvider = "anthropic"
	GeneratorProviderBedrock   GeneratorProvider = "bedrock"
	GeneratorProviderCohere    GeneratorProvider = "cohere"
	GeneratorProviderGemini    GeneratorProvider = "gemini"
	GeneratorProviderMock      GeneratorProvider = "mock"
	GeneratorProviderOllama    GeneratorProvider = "ollama"
	GeneratorProviderOpenai    GeneratorProvider = "openai"
	GeneratorProviderVertex    GeneratorProvider = "vertex"
)

// Defines values for GeoShapeGeometryRelation.
const (
	GeoShapeGeometryRelationContains   GeoShapeGeometryRelation = "contains"
	GeoShapeGeometryRelationIntersects GeoShapeGeometryRelation = "intersects"
	GeoShapeGeometryRelationWithin     GeoShapeGeometryRelation = "within"
)

// Defines values for GraphQueryType.
const (
	GraphQueryTypeKShortestPaths GraphQueryType = "k_shortest_paths"
	GraphQueryTypeNeighbors      GraphQueryType = "neighbors"
	GraphQueryTypePattern        GraphQueryType = "pattern"
	GraphQueryTypeShortestPath   GraphQueryType = "shortest_path"
	GraphQueryTypeTraverse       GraphQueryType = "traverse"
)

// Defines values for IndexType.
const (
	IndexTypeAknnV0     IndexType = "aknn_v0"
	IndexTypeFullTextV0 IndexType = "full_text_v0"
	IndexTypeGraphV0    IndexType = "graph_v0"
)

// Defines values for LinearMergePageStatus.
const (
	LinearMergePageStatusError   LinearMergePageStatus = "error"
	LinearMergePageStatusPartial LinearMergePageStatus = "partial"
	LinearMergePageStatusSuccess LinearMergePageStatus = "success"
)

// Defines values for MatchQueryOperator.
const (
	MatchQueryOperatorAnd MatchQueryOperator = "and"
	MatchQueryOperatorOr  MatchQueryOperator = "or"
)

// Defines values for MergeStrategy.
const (
	MergeStrategyFailover MergeStrategy = "failover"
	MergeStrategyRrf      MergeStrategy = "rrf"
	MergeStrategyRsf      MergeStrategy = "rsf"
)

// Defines values for PathFindWeightMode.
const (
	PathFindWeightModeMaxWeight PathFindWeightMode = "max_weight"
	PathFindWeightModeMinHops   PathFindWeightMode = "min_hops"
	PathFindWeightModeMinWeight PathFindWeightMode = "min_weight"
)

// Defines values for PathWeightMode.
const (
	PathWeightModeMaxWeight PathWeightMode = "max_weight"
	PathWeightModeMinHops   PathWeightMode = "min_hops"
	PathWeightModeMinWeight PathWeightMode = "min_weight"
)

// Defines values for PermissionType.
const (
	PermissionTypeAdmin PermissionType = "admin"
	PermissionTypeRead  PermissionType = "read"
	PermissionTypeWrite PermissionType = "write"
)

// Defines values for QueryRequestExpandStrategy.
const (
	QueryRequestExpandStrategyIntersection QueryRequestExpandStrategy = "intersection"
	QueryRequestExpandStrategyUnion        QueryRequestExpandStrategy = "union"
)

// Defines values for QueryStrategy.
const (
	QueryStrategyDecompose QueryStrategy = "decompose"
	QueryStrategyHyde      QueryStrategy = "hyde"
	QueryStrategySimple    QueryStrategy = "simple"
	QueryStrategyStepBack  QueryStrategy = "step_back"
)

// Defines values for RerankerProvider.
const (
	RerankerProviderCohere  RerankerProvider = "cohere"
	RerankerProviderOllama  RerankerProvider = "ollama"
	RerankerProviderTermite RerankerProvider = "termite"
)

// Defines values for ResourceType.
const (
	ResourceTypeAsterisk ResourceType = "*"
	ResourceTypeTable    ResourceType = "table"
	ResourceTypeUser     ResourceType = "user"
)

// Defines values for RouteType.
const (
	RouteTypeQuestion RouteType = "question"
	RouteTypeSearch   RouteType = "search"
)

// Defines values for SemanticQueryMode.
const (
	SemanticQueryModeHypothetical SemanticQueryMode = "hypothetical"
	SemanticQueryModeRewrite      SemanticQueryMode = "rewrite"
)

// Defines values for SyncLevel.
const (
	SyncLevelAknn        SyncLevel = "aknn"
	SyncLevelEnrichments SyncLevel = "enrichments"
	SyncLevelFullText    SyncLevel = "full_text"
	SyncLevelPropose     SyncLevel = "propose"
	SyncLevelWrite       SyncLevel = "write"
)

// Defines values for TransformOpType.
const (
	TransformOpTypeAddToSet    TransformOpType = "$addToSet"
	TransformOpTypeCurrentDate TransformOpType = "$currentDate"
	TransformOpTypeInc         TransformOpType = "$inc"
	TransformOpTypeMax         TransformOpType = "$max"
	TransformOpTypeMin         TransformOpType = "$min"
	TransformOpTypeMul         TransformOpType = "$mul"
	TransformOpTypePop         TransformOpType = "$pop"
	TransformOpTypePull        TransformOpType = "$pull"
	TransformOpTypePush        TransformOpType = "$push"
	TransformOpTypeRename      TransformOpType = "$rename"
	TransformOpTypeSet         TransformOpType = "$set"
	TransformOpTypeUnset       TransformOpType = "$unset"
)

// Analyses defines model for Analyses.
type Analyses struct {
	Pca  bool `json:"pca,omitempty,omitzero"`
	Tsne bool `json:"tsne,omitempty,omitzero"`
}

// AnalysesResult defines model for AnalysesResult.
type AnalysesResult struct {
	Pca  []float64 `json:"pca,omitempty,omitzero"`
	Tsne []float64 `json:"tsne,omitempty,omitzero"`
}

// AnswerAgentRequest defines model for AnswerAgentRequest.
type AnswerAgentRequest struct {
	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//    - Returns: `<<<dotprompt:media:url data:image/png;base64,...>>>`
	//    - Compatible with GenKit's dotprompt format
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator"`

	// MaxContextTokens Maximum total tokens allowed for retrieved document context.
	// When set, documents are pruned (lowest-ranked first) to fit within this budget.
	// Useful for ensuring LLM context limits are not exceeded.
	// Uses BERT tokenizer for estimation.
	MaxContextTokens int `json:"max_context_tokens,omitempty,omitzero"`

	// Queries Array of query requests to execute. The query text will be transformed for semantic search
	// and populated into the semantic_search field of each query.
	Queries []QueryRequest `json:"queries"`

	// Query User's natural language query to be classified and improved
	Query string `json:"query"`

	// ReserveTokens Tokens to reserve for system prompt, answer generation, and other overhead.
	// Subtracted from max_context_tokens to determine available context budget.
	// Defaults to 4000 if max_context_tokens is set.
	ReserveTokens int `json:"reserve_tokens,omitempty,omitzero"`

	// Steps Per-step configuration for the answer agent pipeline. Each step can have
	// its own generator (or chain of generators) and step-specific options.
	// If a step is not configured, it uses the top-level generator as default.
	Steps AnswerAgentSteps `json:"steps,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results (classification, queries, results, answer) instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// AnswerAgentResult defines model for AnswerAgentResult.
type AnswerAgentResult struct {
	// Answer Generated answer in markdown format
	Answer string `json:"answer"`

	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0)
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// ClassificationTransformation Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
	ClassificationTransformation ClassificationTransformationResult `json:"classification_transformation,omitempty,omitzero"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance,omitempty,omitzero"`

	// FollowupQuestions Suggested follow-up questions
	FollowupQuestions []string `json:"followup_questions,omitempty,omitzero"`

	// QueryResults Results from each executed query
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`
}

// AnswerAgentSteps Per-step configuration for the answer agent pipeline. Each step can have
// its own generator (or chain of generators) and step-specific options.
// If a step is not configured, it uses the top-level generator as default.
type AnswerAgentSteps struct {
	// Answer Configuration for the answer generation step. This step generates the final
	// answer from retrieved documents using the reasoning as context.
	Answer AnswerStepConfig `json:"answer,omitempty,omitzero"`

	// Classification Configuration for the classification step. This step analyzes the query,
	// selects the optimal retrieval strategy, and generates semantic transformations.
	Classification ClassificationStepConfig `json:"classification,omitempty,omitzero"`

	// Confidence Configuration for confidence assessment. Evaluates answer quality and
	// resource relevance. Can use a model calibrated for scoring tasks.
	Confidence ConfidenceStepConfig `json:"confidence,omitempty,omitzero"`

	// Followup Configuration for generating follow-up questions. Uses a separate generator
	// call which can use a cheaper/faster model.
	Followup FollowupStepConfig `json:"followup,omitempty,omitzero"`
}

// AnswerConfidence Confidence assessment for the generated answer
type AnswerConfidence struct {
	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0). Considers both ability to answer from provided resources and general knowledge.
	AnswerConfidence float32 `json:"answer_confidence"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance"`
}

// AnswerResult Result from answer generation with optional confidence and follow-up questions
type AnswerResult struct {
	// Answer Generated answer in markdown format
	Answer string `json:"answer"`

	// AnswerConfidence Overall confidence in the answer (0.0 to 1.0)
	AnswerConfidence float32 `json:"answer_confidence,omitempty,omitzero"`

	// ContextRelevance Relevance of the provided resources to the question (0.0 to 1.0)
	ContextRelevance float32 `json:"context_relevance,omitempty,omitzero"`

	// FollowupQuestions Suggested follow-up questions
	FollowupQuestions []string `json:"followup_questions,omitempty,omitzero"`
}

// AnswerStepConfig Configuration for the answer generation step. This step generates the final
// answer from retrieved documents using the reasoning as context.
type AnswerStepConfig struct {
	// AnswerContext Custom guidance for answer tone, detail level, and style
	AnswerContext string `json:"answer_context,omitempty,omitzero"`

	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//    - Returns: `<<<dotprompt:media:url data:image/png;base64,...>>>`
	//    - Compatible with GenKit's dotprompt format
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// SystemPrompt Custom system prompt for answer generation
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`
}

// AntflyChunkerConfig Configuration for the local Antfly chunking provider.
//
// This provider runs chunking directly within the storage node process,
// without requiring an external Termite service. It uses simple fixed-size
// tokenizer-based chunking with no caching overhead.
//
// **Use this when:**
// - Running single-node deployments (swarm mode)
// - You don't need embedding/chunk caching across nodes
// - You want minimal setup complexity
//
// **Use Termite instead when:**
// - Running multi-node clusters where caching reduces costs
// - You need ONNX-accelerated chunking (e.g., chonky_onnx strategy)
// - You want persistent chunk/embedding caches
type AntflyChunkerConfig struct {
	// FullText Configuration for full-text indexing of chunks in Bleve.
	// When present (even if empty), chunks will be stored with :cft: suffix and indexed in Bleve's _chunks field.
	// When absent, chunks use :c: suffix and are only used for vector embeddings.
	// This object is reserved for future options like boosting, field mapping, etc.
	FullText map[string]interface{} `json:"full_text,omitempty,omitzero"`

	// MaxChunks Maximum number of chunks to generate per document. Prevents excessive chunking of very large documents.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs).
	Separator string `json:"separator,omitempty,omitzero"`

	// TargetTokens Target number of tokens per chunk. Chunker will aim for chunks around this size.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`
}

// AntflyType defines model for AntflyType.
type AntflyType string

// AnthropicGeneratorConfig Configuration for the Anthropic generative AI provider (Claude models).
//
// API key via `api_key` field or `ANTHROPIC_API_KEY` environment variable.
//
// **Example Models:** claude-sonnet-4-5-20250929 (default), claude-opus-4-5-20251101, claude-3-5-haiku-20241022
//
// **Docs:** https://docs.anthropic.com/en/docs/about-claude/models/overview
type AnthropicGeneratorConfig struct {
	// ApiKey The Anthropic API key. If not provided, falls back to ANTHROPIC_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The full model ID of the Anthropic model to use (e.g., 'claude-sonnet-4-5-20250929', 'claude-opus-4-5-20251101').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-1.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Anthropic API endpoint (optional, uses default if not specified).
	Url string `json:"url,omitempty,omitzero"`
}

// BackupRequest defines model for BackupRequest.
type BackupRequest struct {
	// BackupId Unique identifier for this backup. Used to reference the backup for restore operations.
	// Choose a meaningful name that includes date/version information.
	BackupId string `json:"backup_id"`

	// Location Storage location for the backup. Supports multiple backends:
	// - Local filesystem: `file:///path/to/backup`
	// - Amazon S3: `s3://bucket-name/path/to/backup`
	//
	// The backup includes all table data, indexes, and metadata for the specified table.
	Location string `json:"location"`
}

// BatchRequest Batch insert, delete, and transform operations in a single request.
//
// **Atomicity**:
// - **Single shard**: Operations are atomic within shard boundaries
// - **Multiple shards**: Uses distributed 2-phase commit (2PC) for atomic cross-shard writes
//
// **How distributed transactions work**:
// 1. Metadata server allocates HLC timestamp and selects coordinator shard
// 2. Coordinator writes transaction record, participants write intents
// 3. After all intents succeed, coordinator commits transaction
// 4. Participants are notified asynchronously to resolve intents
// 5. Recovery loop ensures notifications complete even after coordinator failure
//
// **Performance**:
// - Single-shard batches: < 5ms latency
// - Cross-shard transactions: ~20ms latency
// - Intent resolution: < 30 seconds worst-case (via recovery loop)
//
// **Guarantees**:
// - All writes succeed or all fail (atomicity across all shards)
// - Coordinator failure is recoverable (new leader resumes notifications)
// - Idempotent resolution (duplicate notifications are safe)
//
// **Benefits**:
// - Reduces network overhead compared to individual requests
// - More efficient indexing (updates are batched)
// - Automatic distributed transactions when operations span shards
//
// The inserts are upserts - existing keys are overwritten, new keys are created.
type BatchRequest struct {
	// Deletes Array of document IDs to delete. Documents are removed from all indexes.
	//
	// Notes:
	// - Non-existent keys are silently ignored
	// - Deletions are processed before inserts in the same batch
	// - Keys are permanently removed from storage and indexes
	Deletes []string `json:"deletes,omitempty,omitzero"`

	// Inserts Map of document IDs to document objects. Each key is the unique identifier for the document.
	//
	// Best practices:
	// - Use consistent key naming schemes (e.g., "user:123", "article:456")
	// - Key length affects storage and performance - keep them reasonably short
	// - Keys are sorted lexicographically, so choose prefixes that support range scans
	Inserts map[string]map[string]interface{} `json:"inserts,omitempty,omitzero"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write
	// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`

	// Transforms Array of transform operations for in-place document updates using MongoDB-style operators.
	//
	// Transform operations allow you to modify documents without read-modify-write races:
	// - Operations are applied atomically on the server
	// - Multiple operations per document are applied in sequence
	// - Supports numeric operations ($inc, $mul), array operations ($push, $pull), and more
	//
	// Common use cases:
	// - Increment counters (views, likes, votes)
	// - Update timestamps ($currentDate)
	// - Manage arrays (add/remove tags, items)
	// - Update nested fields without overwriting the entire document
	Transforms []Transform `json:"transforms,omitempty,omitzero"`
}

// BedrockEmbedderConfig Configuration for the AWS Bedrock embedding provider.
//
// Uses AWS credentials from environment or IAM roles.
//
// **Example Models:** cohere.embed-english-v4, amazon.titan-embed-text-v2:0
//
// **Docs:** https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html
type BedrockEmbedderConfig struct {
	// BatchSize The batch size for embedding requests to optimize throughput.
	BatchSize int `json:"batch_size,omitempty,omitzero"`

	// Model The Bedrock model ID to use (e.g., 'cohere.embed-english-v4', 'amazon.titan-embed-text-v2:0').
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service (e.g., 'us-east-1').
	Region string `json:"region,omitempty,omitzero"`

	// StripNewLines Whether to strip new lines from the input text before embedding.
	StripNewLines bool `json:"strip_new_lines,omitempty,omitzero"`
}

// BedrockGeneratorConfig Configuration for the AWS Bedrock generative AI provider.
//
// Provides access to models from Anthropic, Meta, Amazon, Cohere, Mistral, and others.
//
// **Example Models:** anthropic.claude-sonnet-4-5-20250929-v1:0, meta.llama3-3-70b-instruct-v1:0, amazon.nova-pro-v1:0
//
// **Docs:** https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html
type BedrockGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The Bedrock model ID to use (e.g., 'anthropic.claude-sonnet-4-5-20250929-v1:0').
	Model string `json:"model"`

	// Region The AWS region for the Bedrock service.
	Region string `json:"region,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-1.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// BleveIndexV2Config defines model for BleveIndexV2Config.
type BleveIndexV2Config struct {
	// MemOnly Whether to use memory-only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`
}

// BleveIndexV2Stats defines model for BleveIndexV2Stats.
type BleveIndexV2Stats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// Rebuilding Whether the index is currently rebuilding
	Rebuilding bool `json:"rebuilding,omitempty,omitzero"`

	// TotalIndexed Number of documents in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`
}

// BoolFieldQuery defines model for BoolFieldQuery.
type BoolFieldQuery struct {
	Bool bool `json:"bool"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
}

// BooleanQuery defines model for BooleanQuery.
type BooleanQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost   Boost            `json:"boost,omitzero"`
	Filter  Query            `json:"filter,omitempty,omitzero"`
	Must    ConjunctionQuery `json:"must,omitempty,omitzero"`
	MustNot DisjunctionQuery `json:"must_not,omitempty,omitzero"`
	Should  DisjunctionQuery `json:"should,omitempty,omitzero"`
}

// Boost A floating-point number used to decrease or increase the relevance scores of a query.
type Boost = float64

// ByteRange defines model for ByteRange.
type ByteRange = [][]byte

// ChainCondition Condition for trying the next generator in chain:
// - always: Always try next regardless of outcome
// - on_error: Try next on any error (default)
// - on_timeout: Try next only on timeout errors
// - on_rate_limit: Try next only on rate limit errors
type ChainCondition string

// ChainLink A single link in a generator chain with optional retry and condition
type ChainLink struct {
	// Condition Condition for trying the next generator in chain:
	// - always: Always try next regardless of outcome
	// - on_error: Try next on any error (default)
	// - on_timeout: Try next only on timeout errors
	// - on_rate_limit: Try next only on rate limit errors
	Condition ChainCondition `json:"condition,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//    - Returns: `<<<dotprompt:media:url data:image/png;base64,...>>>`
	//    - Compatible with GenKit's dotprompt format
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator"`

	// Retry Retry configuration for generator calls
	Retry RetryConfig `json:"retry,omitempty,omitzero"`
}

// ChunkerConfig defines model for ChunkerConfig.
type ChunkerConfig struct {
	// Provider The chunking provider to use.
	Provider ChunkerProvider `json:"provider"`
	union    json.RawMessage
}

// ChunkerProvider The chunking provider to use.
type ChunkerProvider string

// ChunkingStrategy Document chunking strategy. The strategy name maps to ONNX model directory names when using Termite.
// - fixed: Simple fixed-size chunking by token count (built-in, no ONNX required)
// - chonky_onnx: ONNX-accelerated chunking using sentence boundary detection (requires models/chunkers/chonky_onnx/)
type ChunkingStrategy string

// ClassificationStepConfig Configuration for the classification step. This step analyzes the query,
// selects the optimal retrieval strategy, and generates semantic transformations.
type ClassificationStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// ForceSemanticMode Mode for semantic query generation:
	// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
	// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
	ForceSemanticMode SemanticQueryMode `json:"force_semantic_mode,omitempty,omitzero"`

	// ForceStrategy Strategy for query transformation and retrieval:
	// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
	// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
	// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
	// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
	ForceStrategy QueryStrategy `json:"force_strategy,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//    - Returns: `<<<dotprompt:media:url data:image/png;base64,...>>>`
	//    - Compatible with GenKit's dotprompt format
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// MultiPhraseCount Number of alternative query phrasings to generate
	MultiPhraseCount int `json:"multi_phrase_count,omitempty,omitzero"`

	// WithReasoning Include pre-retrieval reasoning explaining query analysis and strategy selection
	WithReasoning bool `json:"with_reasoning,omitempty,omitzero"`
}

// ClassificationTransformationResult Query classification and transformation result combining all query enhancements including strategy selection and semantic optimization
type ClassificationTransformationResult struct {
	// Confidence Classification confidence (0.0 to 1.0)
	Confidence float32 `json:"confidence"`

	// ImprovedQuery Clarified query with added context for answer generation (human-readable)
	ImprovedQuery string `json:"improved_query"`

	// MultiPhrases Alternative phrasings of the query for expanded retrieval coverage
	MultiPhrases []string `json:"multi_phrases,omitempty,omitzero"`

	// Reasoning Pre-retrieval reasoning explaining query analysis and strategy selection (only present when with_classification_reasoning is enabled)
	Reasoning string `json:"reasoning,omitempty,omitzero"`

	// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
	RouteType RouteType `json:"route_type"`

	// SemanticMode Mode for semantic query generation:
	// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
	// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
	SemanticMode SemanticQueryMode `json:"semantic_mode"`

	// SemanticQuery Optimized query for vector/semantic search. Content style depends on semantic_mode: keywords for 'rewrite', hypothetical answer for 'hypothetical'
	SemanticQuery string `json:"semantic_query"`

	// StepBackQuery Broader background query for context (only present when strategy is 'step_back')
	StepBackQuery string `json:"step_back_query,omitempty,omitzero"`

	// Strategy Strategy for query transformation and retrieval:
	// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
	// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
	// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
	// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
	Strategy QueryStrategy `json:"strategy"`

	// SubQuestions Decomposed sub-questions (only present when strategy is 'decompose')
	SubQuestions []string `json:"sub_questions,omitempty,omitzero"`
}

// ClusterHealth Overall health status of the cluster
type ClusterHealth string

// ClusterStatus defines model for ClusterStatus.
type ClusterStatus struct {
	// AuthEnabled Indicates whether authentication is enabled for the cluster
	AuthEnabled bool `json:"auth_enabled,omitempty"`

	// Health Overall health status of the cluster
	Health ClusterHealth `json:"health"`

	// Message Optional message providing details about the health status
	Message              string                 `json:"message,omitempty,omitzero"`
	AdditionalProperties map[string]interface{} `json:"-"`
}

// CohereEmbedderConfig Configuration for the Cohere embedding provider.
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** embed-english-v3.0 (default, 1024 dims), embed-multilingual-v3.0
//
// **Docs:** https://docs.cohere.com/reference/embed
type CohereEmbedderConfig struct {
	// ApiKey The Cohere API key. Can also be set via COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// InputType Specifies the type of input for optimized embeddings.
	InputType CohereEmbedderConfigInputType `json:"input_type,omitempty,omitzero"`

	// Model The name of the Cohere embedding model to use.
	Model string `json:"model"`

	// Truncate How to handle inputs longer than the max token length.
	Truncate CohereEmbedderConfigTruncate `json:"truncate,omitempty,omitzero"`
}

// CohereEmbedderConfigInputType Specifies the type of input for optimized embeddings.
type CohereEmbedderConfigInputType string

// CohereEmbedderConfigTruncate How to handle inputs longer than the max token length.
type CohereEmbedderConfigTruncate string

// CohereGeneratorConfig Configuration for the Cohere generative AI provider (Command models).
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** command-r-plus (default), command-r, command-a-03-2025
//
// **Docs:** https://docs.cohere.com/reference/chat
type CohereGeneratorConfig struct {
	// ApiKey The Cohere API key. If not provided, falls back to COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (0.0-1.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Cohere model to use.
	Model string `json:"model"`

	// PresencePenalty Penalty for token presence (0.0-1.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-1.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// CohereRerankerConfig Configuration for the Cohere reranking provider.
//
// API key via `api_key` field or `COHERE_API_KEY` environment variable.
//
// **Example Models:** rerank-english-v3.0 (default), rerank-multilingual-v3.0
//
// **Docs:** https://docs.cohere.com/reference/rerank
type CohereRerankerConfig struct {
	// ApiKey The Cohere API key. Can also be set via COHERE_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// MaxChunksPerDoc Maximum number of chunks per document for long document handling.
	MaxChunksPerDoc int `json:"max_chunks_per_doc,omitempty,omitzero"`

	// Model The name of the Cohere reranking model to use.
	Model string `json:"model"`

	// TopN Number of most relevant documents to return. If not specified, returns all documents with scores.
	TopN int `json:"top_n,omitempty,omitzero"`
}

// ConfidenceStepConfig Configuration for confidence assessment. Evaluates answer quality and
// resource relevance. Can use a model calibrated for scoring tasks.
type ConfidenceStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Context Custom guidance for confidence assessment approach
	Context string `json:"context,omitempty,omitzero"`

	// Enabled Enable confidence scoring
	Enabled bool `json:"enabled,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//    - Returns: `<<<dotprompt:media:url data:image/png;base64,...>>>`
	//    - Compatible with GenKit's dotprompt format
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`
}

// ConjunctionQuery defines model for ConjunctionQuery.
type ConjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Conjuncts []Query `json:"conjuncts"`
}

// CreateTableRequest defines model for CreateTableRequest.
type CreateTableRequest struct {
	// Description Optional human-readable description of the table and its purpose.
	// Useful for documentation and team collaboration.
	Description string `json:"description,omitempty,omitzero"`

	// Indexes Map of index name to index configuration. Indexes enable different query capabilities:
	// - Full-text indexes for BM25 search
	// - Vector indexes for semantic similarity
	// - Multimodal indexes for images/audio/video
	//
	// You can add multiple indexes to support different query patterns.
	Indexes map[string]IndexConfig `json:"indexes,omitempty,omitzero"`

	// NumShards Number of shards to create for the table. Data is partitioned across shards based on key ranges.
	//
	// **Sizing Guidelines:**
	// - Small datasets (<100K docs): 1-3 shards
	// - Medium datasets (100K-1M docs): 3-10 shards
	// - Large datasets (>1M docs): 10+ shards
	//
	// More shards enable better parallelism but increase overhead. Choose based on expected data size and query patterns.
	//
	// **When to Add More Shards:**
	//
	// Antfly supports **online shard reallocation** without downtime. Add more shards when:
	// - Individual shards exceed size thresholds (configurable)
	// - Query latency increases due to large shard size
	// - Need better parallelism for write-heavy workloads
	//
	// Use the internal `/reallocate` endpoint to trigger automatic shard splitting:
	// ```bash
	// POST /_internal/v1/reallocate
	// ```
	//
	// This enqueues a reallocation request that the leader processes asynchronously, splitting
	// large shards and redistributing data without service interruption.
	//
	// **Advantages over Elasticsearch:**
	// - Automatic shard splitting (no manual reindexing required)
	// - Online operation (no downtime)
	// - Transparent to applications (keys remain accessible during reallocation)
	NumShards uint `json:"num_shards,omitempty,omitzero"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema `json:"schema,omitempty,omitzero"`
}

// CreateUserRequest defines model for CreateUserRequest.
type CreateUserRequest struct {
	// InitialPolicies Optional list of initial permissions for the user.
	InitialPolicies []Permission `json:"initial_policies,omitzero"`
	Password        string       `json:"password"`

	// Username Username for the new user. If provided in the path, this field can be omitted or must match the path parameter.
	Username string `json:"username,omitempty,omitzero"`
}

// DateRange defines model for DateRange.
type DateRange struct {
	From *string `json:"from,omitempty"`
	Name string  `json:"name"`
	To   *string `json:"to,omitempty"`
}

// DateRangeResult defines model for DateRangeResult.
type DateRangeResult struct {
	Count int     `json:"count"`
	From  *string `json:"from,omitempty"`
	Name  string  `json:"name"`
	To    *string `json:"to,omitempty"`
}

// DateRangeStringQuery defines model for DateRangeStringQuery.
type DateRangeStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost          Boost     `json:"boost,omitzero"`
	DatetimeParser string    `json:"datetime_parser,omitempty,omitzero"`
	End            time.Time `json:"end,omitempty,omitzero"`
	Field          string    `json:"field,omitempty,omitzero"`
	InclusiveEnd   bool      `json:"inclusive_end,omitzero"`
	InclusiveStart bool      `json:"inclusive_start,omitzero"`
	Start          time.Time `json:"start,omitempty,omitzero"`
}

// DisjunctionQuery defines model for DisjunctionQuery.
type DisjunctionQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost   `json:"boost,omitzero"`
	Disjuncts []Query `json:"disjuncts"`
	Min       float64 `json:"min,omitempty,omitzero"`
}

// DocIdQuery defines model for DocIdQuery.
type DocIdQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost    `json:"boost,omitzero"`
	Ids   []string `json:"ids"`
}

// DocumentSchema Defines the structure of a document type
type DocumentSchema struct {
	// Description A description of the document type.
	Description string `json:"description,omitempty,omitzero"`

	// Schema A valid JSON Schema defining the document's structure.
	// This is used to infer indexing rules and field types.
	Schema map[string]interface{} `json:"schema,omitempty,omitzero"`
}

// Edge A typed, weighted connection between documents
type Edge struct {
	// CreatedAt When the edge was created
	CreatedAt time.Time `json:"created_at,omitempty,omitzero"`

	// Metadata Optional edge metadata
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`

	// Source Base64-encoded source document key
	Source []byte `json:"source"`

	// Target Base64-encoded target document key
	Target []byte `json:"target"`

	// Type Edge type (e.g., "cites", "similar_to", "authored_by")
	Type string `json:"type"`

	// UpdatedAt When the edge was last updated
	UpdatedAt time.Time `json:"updated_at,omitempty,omitzero"`

	// Weight Edge weight/confidence (0.0 to 1.0)
	Weight float64 `json:"weight"`
}

// EdgeDirection Direction of edges to query:
// - out: Outgoing edges from the node
// - in: Incoming edges to the node
// - both: Both outgoing and incoming edges
type EdgeDirection string

// EdgeTypeConfig Configuration for a specific edge type
type EdgeTypeConfig struct {
	// AllowSelfLoops Whether to allow edges from a node to itself
	AllowSelfLoops bool `json:"allow_self_loops,omitempty,omitzero"`

	// MaxWeight Maximum allowed edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum allowed edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// Name Edge type name (e.g., 'cites', 'similar_to')
	Name string `json:"name"`

	// RequiredMetadata Required metadata fields for this edge type
	RequiredMetadata []string `json:"required_metadata,omitempty,omitzero"`
}

// EdgesResponse defines model for EdgesResponse.
type EdgesResponse struct {
	// Count Total number of edges returned
	Count int    `json:"count,omitempty,omitzero"`
	Edges []Edge `json:"edges,omitempty,omitzero"`
}

// EmbedderConfig defines model for EmbedderConfig.
type EmbedderConfig struct {
	// Provider The embedding provider to use.
	Provider EmbedderProvider `json:"provider"`
	union    json.RawMessage
}

// EmbedderProvider The embedding provider to use.
type EmbedderProvider string

// EmbeddingIndexConfig defines model for EmbeddingIndexConfig.
type EmbeddingIndexConfig struct {
	// Chunker A unified configuration for a chunking provider.
	Chunker ChunkerConfig `json:"chunker,omitempty,omitzero"`

	// Dimension Vector dimension
	Dimension int `json:"dimension"`

	// Embedder A unified configuration for an embedding provider.
	//
	// Embedders can be configured with templates to customize how documents are
	// converted to text before embedding. Templates use Handlebars syntax and
	// support various built-in helpers.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full document as context
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active user{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//    Returns: `<<<dotprompt:media:url data:image/png;base64,...>>>`
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// Document with metadata:
	// ```handlebars
	// Title: {{metadata.title}}
	// Date: {{metadata.date}}
	// Tags: {{#each metadata.tags}}{{this}}, {{/each}}
	//
	// {{content}}
	// ```
	//
	// HTML content extraction:
	// ```handlebars
	// Product: {{name}}
	// Description: {{scrubHtml description_html}}
	// Price: ${{price}}
	// ```
	//
	// Multimodal with image:
	// ```handlebars
	// Product: {{title}}
	// {{media url=image}}
	// Description: {{description}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{title}}
	// {{#if author}}By: {{author}}{{/if}}
	// {{#if (eq category "premium")}} Premium Content{{/if}}
	// {{body}}
	// ```
	//
	// **Environment Variables:**
	// - `GEMINI_API_KEY` - API key for Google AI
	// - `OPENAI_API_KEY` - API key for OpenAI
	// - `OPENAI_BASE_URL` - Base URL for OpenAI-compatible APIs
	// - `OLLAMA_HOST` - Ollama server URL (e.g., http://localhost:11434)
	//
	// **Importing Pre-computed Embeddings:**
	//
	// You can import existing embeddings (from OpenAI, Cohere, or any provider) by including
	// them directly in your documents using the `_embeddings` field. This bypasses the
	// embedding generation step and writes vectors directly to the index.
	//
	// **Steps:**
	// 1. Create the index first with the appropriate dimension
	// 2. Write documents with `_embeddings: { "<indexName>": [...<embedding>...] }`
	//
	// **Example:**
	// ```json
	// {
	//   "title": "My Document",
	//   "content": "Document text...",
	//   "_embeddings": {
	//     "my_vector_index": [0.1, 0.2, 0.3, ...]
	//   }
	// }
	// ```
	//
	// **Use Cases:**
	// - Migrating from another vector database with existing embeddings
	// - Using embeddings generated by external systems
	// - Importing pre-computed OpenAI, Cohere, or other provider embeddings
	// - Batch processing embeddings offline before ingestion
	Embedder EmbedderConfig `json:"embedder,omitempty,omitzero"`

	// Field Field to extract embeddings from
	Field string `json:"field,omitempty,omitzero"`

	// MemOnly Whether to use in-memory only storage
	MemOnly bool `json:"mem_only,omitempty,omitzero"`

	// Summarizer A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//    - Returns: `<<<dotprompt:media:url data:image/png;base64,...>>>`
	//    - Compatible with GenKit's dotprompt format
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Summarizer GeneratorConfig `json:"summarizer,omitempty,omitzero"`

	// Template Handlebars template for generating prompts. See https://handlebarsjs.com/guide/ for more information.
	Template string `json:"template,omitempty,omitzero"`
}

// EmbeddingIndexStats defines model for EmbeddingIndexStats.
type EmbeddingIndexStats struct {
	// DiskUsage Size of the index in bytes
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalIndexed Number of vectors in the index
	TotalIndexed uint64 `json:"total_indexed,omitempty,omitzero"`

	// TotalNodes Total number of nodes in the index
	TotalNodes uint64 `json:"total_nodes,omitempty,omitzero"`
}

// Error defines model for Error.
type Error struct {
	Error string `json:"error"`
}

// FacetOption defines model for FacetOption.
type FacetOption struct {
	DateRanges    []DateRange    `json:"date_ranges,omitempty,omitzero"`
	Field         string         `json:"field,omitempty,omitzero"`
	NumericRanges []NumericRange `json:"numeric_ranges,omitempty,omitzero"`
	Size          int            `json:"size,omitempty,omitzero"`
}

// FacetResult defines model for FacetResult.
type FacetResult struct {
	DateRanges    []DateRangeResult    `json:"date_ranges,omitempty,omitzero"`
	Field         string               `json:"field,omitempty,omitzero"`
	Missing       int                  `json:"missing,omitempty,omitzero"`
	NumericRanges []NumericRangeResult `json:"numeric_ranges,omitempty,omitzero"`
	Terms         []TermFacetResult    `json:"terms,omitempty,omitzero"`
	Total         int                  `json:"total,omitempty,omitzero"`
}

// FailedOperation defines model for FailedOperation.
type FailedOperation struct {
	Error     string                   `json:"error,omitempty,omitzero"`
	Id        string                   `json:"id,omitempty,omitzero"`
	Operation FailedOperationOperation `json:"operation,omitempty,omitzero"`
}

// FailedOperationOperation defines model for FailedOperation.Operation.
type FailedOperationOperation string

// FollowupStepConfig Configuration for generating follow-up questions. Uses a separate generator
// call which can use a cheaper/faster model.
type FollowupStepConfig struct {
	// Chain Chain of generators to try in order. Mutually exclusive with 'generator'.
	Chain []ChainLink `json:"chain,omitempty,omitzero"`

	// Context Custom guidance for follow-up question focus and style
	Context string `json:"context,omitempty,omitzero"`

	// Count Number of follow-up questions to generate
	Count int `json:"count,omitempty,omitzero"`

	// Enabled Enable follow-up question generation
	Enabled bool `json:"enabled,omitempty,omitzero"`

	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//    - Returns: `<<<dotprompt:media:url data:image/png;base64,...>>>`
	//    - Compatible with GenKit's dotprompt format
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`
}

// Fuzziness The fuzziness of the query. Can be an integer or "auto".
type Fuzziness struct {
	union json.RawMessage
}

// Fuzziness0 defines model for .
type Fuzziness0 = int32

// Fuzziness1 defines model for Fuzziness.1.
type Fuzziness1 string

// FuzzyQuery defines model for FuzzyQuery.
type FuzzyQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness `json:"fuzziness,omitempty,omitzero"`
	PrefixLength int32     `json:"prefix_length,omitempty,omitzero"`
	Term         string    `json:"term"`
}

// GeneratorConfig defines model for GeneratorConfig.
type GeneratorConfig struct {
	// Provider The generative AI provider to use.
	Provider GeneratorProvider `json:"provider"`
	union    json.RawMessage
}

// GeneratorProvider The generative AI provider to use.
type GeneratorProvider string

// GeoBoundingBoxQuery defines model for GeoBoundingBoxQuery.
type GeoBoundingBoxQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost `json:"boost,omitzero"`

	// BottomRight [lon, lat]
	BottomRight []float64 `json:"bottom_right"`
	Field       string    `json:"field,omitempty,omitzero"`

	// TopLeft [lon, lat]
	TopLeft []float64 `json:"top_left"`
}

// GeoBoundingPolygonQuery defines model for GeoBoundingPolygonQuery.
type GeoBoundingPolygonQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost         Boost      `json:"boost,omitzero"`
	Field         string     `json:"field,omitempty,omitzero"`
	PolygonPoints []GeoPoint `json:"polygon_points"`
}

// GeoDistanceQuery defines model for GeoDistanceQuery.
type GeoDistanceQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Distance string `json:"distance"`
	Field    string `json:"field,omitempty,omitzero"`

	// Location [lon, lat]
	Location []float64 `json:"location"`
}

// GeoPoint defines model for GeoPoint.
type GeoPoint struct {
	Lat float64 `json:"lat,omitempty,omitzero"`
	Lon float64 `json:"lon,omitempty,omitzero"`
}

// GeoShape A GeoJSON shape object. This is a simplified representation.
type GeoShape struct {
	Coordinates []interface{} `json:"coordinates"`
	Type        string        `json:"type"`
}

// GeoShapeGeometry defines model for GeoShapeGeometry.
type GeoShapeGeometry struct {
	Relation GeoShapeGeometryRelation `json:"relation"`

	// Shape A GeoJSON shape object. This is a simplified representation.
	Shape GeoShape `json:"shape"`
}

// GeoShapeGeometryRelation defines model for GeoShapeGeometry.Relation.
type GeoShapeGeometryRelation string

// GeoShapeQuery defines model for GeoShapeQuery.
type GeoShapeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost            `json:"boost,omitzero"`
	Field    string           `json:"field,omitempty,omitzero"`
	Geometry GeoShapeGeometry `json:"geometry"`
}

// GoogleEmbedderConfig Configuration for the Google AI (Gemini) embedding provider.
//
// API key via `api_key` field or `GEMINI_API_KEY` environment variable.
//
// **Example Models:** gemini-embedding-001 (default, 3072 dims)
//
// **Docs:** https://ai.google.dev/gemini-api/docs/embeddings
type GoogleEmbedderConfig struct {
	// ApiKey The Google API key. Can also be set via GEMINI_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimension The dimension of the embedding vector (768, 1536, or 3072 recommended).
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1'). Required for Vertex AI, optional for Gemini API.
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the embedding model to use.
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID (optional for Gemini API, required for Vertex AI).
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Url The URL of the Google API endpoint (optional, uses default if not specified).
	Url string `json:"url,omitempty,omitzero"`
}

// GoogleGeneratorConfig Configuration for the Google generative AI provider (Gemini).
//
// **Example Models:** gemini-2.5-flash (default), gemini-2.5-pro, gemini-3.0-pro
//
// **Docs:** https://ai.google.dev/gemini-api/docs/models
type GoogleGeneratorConfig struct {
	// ApiKey The Google API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Location The Google Cloud location (e.g., 'us-central1').
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the generative model to use (e.g., 'gemini-2.5-flash', 'gemini-2.5-pro', 'gemini-3.0-pro').
	Model string `json:"model"`

	// ProjectId The Google Cloud project ID.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Google API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// GraphIndexV0Config Configuration for graph_v0 index type
type GraphIndexV0Config struct {
	// EdgeTypes List of edge types with their configurations
	EdgeTypes []EdgeTypeConfig `json:"edge_types,omitempty,omitzero"`

	// MaxEdgesPerDocument Maximum number of edges per document (0 = unlimited)
	MaxEdgesPerDocument int `json:"max_edges_per_document,omitempty,omitzero"`
}

// GraphIndexV0Stats Statistics for graph_v0 index
type GraphIndexV0Stats struct {
	// EdgeTypes Count of edges per edge type
	EdgeTypes map[string]uint64 `json:"edge_types,omitempty,omitzero"`

	// Error Error message if stats could not be retrieved
	Error string `json:"error,omitempty,omitzero"`

	// TotalEdges Total number of edges in the graph
	TotalEdges uint64 `json:"total_edges,omitempty,omitzero"`
}

// GraphNodeSelector Defines how to select start/target nodes for graph queries
type GraphNodeSelector struct {
	// Keys Explicit list of node keys
	Keys []string `json:"keys,omitempty,omitzero"`

	// Limit Maximum number of nodes to select from the referenced results
	Limit int `json:"limit,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`

	// ResultRef Reference to search results to use as nodes:
	// - "$full_text_results" - use full-text search results
	// - "$aknn_results.index_name" - use vector search results from specific index
	ResultRef string `json:"result_ref,omitempty,omitzero"`
}

// GraphQuery Declarative graph query to execute after full-text/vector searches
type GraphQuery struct {
	// Fields Which fields to return from documents
	Fields []string `json:"fields,omitempty,omitzero"`

	// IncludeDocuments Fetch full documents for graph results
	IncludeDocuments bool `json:"include_documents,omitempty,omitzero"`

	// IncludeEdges Include edge details for each node
	IncludeEdges bool `json:"include_edges,omitempty,omitzero"`

	// IndexName Graph index name (must be graph_v0 type)
	IndexName string `json:"index_name"`

	// Params Parameters for graph traversal and pathfinding
	Params GraphQueryParams `json:"params,omitempty,omitzero"`

	// Pattern Pattern steps for pattern query type
	Pattern []PatternStep `json:"pattern,omitempty,omitzero"`

	// ReturnAliases Which aliases to return from pattern query (empty = all)
	ReturnAliases []string `json:"return_aliases,omitempty,omitzero"`

	// StartNodes Defines how to select start/target nodes for graph queries
	StartNodes GraphNodeSelector `json:"start_nodes,omitempty,omitzero"`

	// TargetNodes Defines how to select start/target nodes for graph queries
	TargetNodes GraphNodeSelector `json:"target_nodes,omitempty,omitzero"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryParams Parameters for graph traversal and pathfinding
type GraphQueryParams struct {
	// Algorithm Graph algorithm to run (e.g., 'pagerank', 'betweenness')
	Algorithm string `json:"algorithm,omitempty,omitzero"`

	// AlgorithmParams Parameters for the graph algorithm
	AlgorithmParams map[string]interface{} `json:"algorithm_params,omitempty,omitzero"`

	// DeduplicateNodes Remove duplicate nodes (traversal)
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information (traversal)
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// K Number of paths to find (k-shortest-paths)
	K int `json:"k,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum number of results (traversal)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`

	// WeightMode Path weighting algorithm for pathfinding:
	// - min_hops: Minimize number of edges
	// - min_weight: Minimize sum of edge weights
	// - max_weight: Maximize product of edge weights
	WeightMode PathWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// GraphQueryResult Results of a graph query
type GraphQueryResult struct {
	// Matches Pattern matches (for pattern queries)
	Matches []PatternMatch `json:"matches,omitempty,omitzero"`

	// Nodes Result nodes
	Nodes []GraphResultNode `json:"nodes,omitempty,omitzero"`

	// Paths Result paths (for pathfinding queries)
	Paths []Path `json:"paths,omitempty,omitzero"`

	// Took Query execution time
	Took time.Duration `json:"took,omitempty,omitzero"`

	// Total Total number of results
	Total int `json:"total"`

	// Type Type of graph query to execute
	Type GraphQueryType `json:"type"`
}

// GraphQueryType Type of graph query to execute
type GraphQueryType string

// GraphResultNode A node in graph query results
type GraphResultNode struct {
	// Depth Distance from start node
	Depth int `json:"depth,omitempty,omitzero"`

	// Distance Weighted distance
	Distance float64 `json:"distance,omitempty,omitzero"`

	// Document Full document (if include_documents=true)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Edges Connected edges (when include_edges=true)
	Edges []Edge `json:"edges,omitempty,omitzero"`

	// Key Document key
	Key string `json:"key"`

	// Path Keys in path from start to this node
	Path []string `json:"path,omitempty,omitzero"`

	// PathEdges Edges in path from start to this node
	PathEdges []PathEdge `json:"path_edges,omitempty,omitzero"`
}

// IPRangeQuery defines model for IPRangeQuery.
type IPRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Cidr  string `json:"cidr"`
	Field string `json:"field,omitempty,omitzero"`
}

// IndexConfig Configuration for an index
type IndexConfig struct {
	// Description Optional description of the index and its purpose
	Description string `json:"description,omitempty,omitzero"`

	// Enrichments List of enrichment names to apply to documents before indexing. Enrichments must be defined at the table level.
	Enrichments []string `json:"enrichments,omitempty,omitzero"`

	// Name Name of the index
	Name string `json:"name"`

	// Type The type of the index.
	Type  IndexType `json:"type"`
	union json.RawMessage
}

// IndexStats Statistics for an index
type IndexStats struct {
	union json.RawMessage
}

// IndexStatus defines model for IndexStatus.
type IndexStatus struct {
	// Config Configuration for an index
	Config      IndexConfig           `json:"config"`
	ShardStatus map[string]IndexStats `json:"shard_status"`

	// Status Statistics for an index
	Status IndexStats `json:"status"`
}

// IndexType The type of the index.
type IndexType string

// KeyRange Key range processed in this request
type KeyRange struct {
	From string `json:"from,omitempty,omitzero"`
	To   string `json:"to,omitempty,omitzero"`
}

// LinearMergePageStatus Status of a linear merge page operation:
// - "success": All records in batch processed successfully
// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
// - "error": Fatal error occurred, no records processed successfully
type LinearMergePageStatus string

// LinearMergeRequest Linear merge operation for syncing sorted records from external sources.
// Use this to keep Antfly in sync with an external database or data source.
//
// **How it works:**
// 1. Send sorted records from your external source
// 2. Server upserts records that exist in your batch
// 3. Server deletes Antfly records in the key range that are absent from your batch
// 4. If stopped at shard boundary, use next_cursor for next request
//
// **WARNING:** Not safe for concurrent operations with overlapping key ranges.
type LinearMergeRequest struct {
	// DryRun If true, returns what would be deleted without making changes.
	//
	// Use cases:
	// - Validate sync behavior before committing
	// - Check which records will be removed
	// - Test key range boundaries
	//
	// Response includes deleted_ids array when dry_run=true.
	DryRun bool `json:"dry_run,omitempty,omitzero"`

	// LastMergedId ID of last record from previous merge request.
	// - First request: Use empty string ""
	// - Subsequent requests: Use next_cursor from previous response
	// - Defines lower bound of key range to process
	//
	// This enables pagination for large datasets.
	LastMergedId string `json:"last_merged_id,omitempty,omitzero"`

	// Records Map of resource ID to resource object: {"resource_id_1": {...}, "resource_id_2": {...}}
	//
	// Requirements:
	// - Keys must be sorted lexicographically by your client
	// - Server will process keys in sorted order
	// - Use consistent key naming (e.g., all start with same prefix)
	//
	// This format avoids duplicate IDs and matches Antfly's batch write interface.
	Records map[string]interface{} `json:"records"`

	// SyncLevel Synchronization level for batch operations:
	// - "propose": Wait for Raft proposal acceptance (fastest, default)
	// - "write": Wait for Pebble KV write
	// - "full_text": Wait for full-text index WAL write
	// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
	// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
	SyncLevel SyncLevel `json:"sync_level,omitempty,omitzero"`
}

// LinearMergeResult defines model for LinearMergeResult.
type LinearMergeResult struct {
	// Deleted Records deleted or would be deleted (if dry_run=true)
	Deleted int `json:"deleted"`

	// DeletedIds IDs that were deleted (or would be deleted if dry_run=true). Only included if dry_run=true.
	DeletedIds []string          `json:"deleted_ids,omitempty,omitzero"`
	Failed     []FailedOperation `json:"failed,omitempty,omitzero"`

	// KeyRange Key range processed in this request
	KeyRange KeyRange `json:"key_range,omitempty,omitzero"`

	// KeysScanned Total number of keys scanned from Antfly during range query
	KeysScanned int `json:"keys_scanned,omitempty,omitzero"`

	// Message Additional information (e.g., "stopped at shard boundary", "dry run - no changes made")
	Message string `json:"message,omitempty,omitzero"`

	// NextCursor ID of last record in this batch (use for next request)
	NextCursor string `json:"next_cursor"`

	// Skipped Records skipped because content hash matched (unchanged)
	Skipped int `json:"skipped"`

	// Status Status of a linear merge page operation:
	// - "success": All records in batch processed successfully
	// - "partial": Processing stopped at shard boundary, client should retry with next_cursor
	// - "error": Fatal error occurred, no records processed successfully
	Status LinearMergePageStatus `json:"status"`
	Took   time.Duration         `json:"took,omitempty,omitzero"`

	// Upserted Records inserted or updated (0 if dry_run=true)
	Upserted int `json:"upserted"`
}

// MatchAllQuery defines model for MatchAllQuery.
type MatchAllQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost                  `json:"boost,omitzero"`
	MatchAll map[string]interface{} `json:"match_all"`
}

// MatchNoneQuery defines model for MatchNoneQuery.
type MatchNoneQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost     Boost                  `json:"boost,omitzero"`
	MatchNone map[string]interface{} `json:"match_none"`
}

// MatchPhraseQuery defines model for MatchPhraseQuery.
type MatchPhraseQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness   Fuzziness `json:"fuzziness,omitempty,omitzero"`
	MatchPhrase string    `json:"match_phrase"`
}

// MatchQuery defines model for MatchQuery.
type MatchQuery struct {
	Analyzer string `json:"analyzer,omitempty,omitzero"`

	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness    Fuzziness          `json:"fuzziness,omitempty,omitzero"`
	Match        string             `json:"match"`
	Operator     MatchQueryOperator `json:"operator,omitempty,omitzero"`
	PrefixLength int32              `json:"prefix_length,omitempty,omitzero"`
}

// MatchQueryOperator defines model for MatchQuery.Operator.
type MatchQueryOperator string

// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
// failover: Use full_text_search if embedding generation fails
type MergeStrategy string

// MultiPhraseQuery defines model for MultiPhraseQuery.
type MultiPhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness  `json:"fuzziness,omitempty,omitzero"`
	Terms     [][]string `json:"terms"`
}

// NodeFilter Filter nodes during graph traversal using existing query primitives
type NodeFilter struct {
	// FilterPrefix Filter by key prefix
	FilterPrefix string `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query to filter nodes (same syntax as search filter_query)
	FilterQuery map[string]interface{} `json:"filter_query,omitempty,omitzero"`
}

// NumericRange defines model for NumericRange.
type NumericRange struct {
	From *float64 `json:"from,omitempty"`
	Name string   `json:"name"`
	To   *float64 `json:"to,omitempty"`
}

// NumericRangeQuery defines model for NumericRangeQuery.
type NumericRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost   `json:"boost,omitzero"`
	Field        string  `json:"field,omitempty,omitzero"`
	InclusiveMax bool    `json:"inclusive_max,omitzero"`
	InclusiveMin bool    `json:"inclusive_min,omitzero"`
	Max          float64 `json:"max,omitzero"`
	Min          float64 `json:"min,omitzero"`
}

// NumericRangeResult defines model for NumericRangeResult.
type NumericRangeResult struct {
	Count int      `json:"count"`
	From  *float64 `json:"from,omitempty"`
	Name  string   `json:"name"`
	To    *float64 `json:"to,omitempty"`
}

// OllamaEmbedderConfig Configuration for the Ollama embedding provider.
//
// Local embeddings for privacy and offline use. URL via `url` field or `OLLAMA_HOST` env var.
//
// **Example Models:** nomic-embed-text (768 dims), mxbai-embed-large (1024 dims), all-minilm (384 dims)
//
// **Docs:** https://ollama.com/search?c=embedding
type OllamaEmbedderConfig struct {
	// Model The name of the Ollama model to use (e.g., 'nomic-embed-text', 'mxbai-embed-large').
	Model string `json:"model"`

	// Url The URL of the Ollama API endpoint. Can also be set via OLLAMA_HOST environment variable.
	Url string `json:"url,omitempty,omitzero"`
}

// OllamaGeneratorConfig Configuration for the Ollama generative AI provider.
//
// Ollama provides local LLM inference for privacy and offline use.
//
// **Example Models:** llama3.3:70b, qwen2.5:72b, deepseek-r1:70b, mistral:7b, llava:34b
//
// **Docs:** https://ollama.com/library
type OllamaGeneratorConfig struct {
	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Ollama model to use (e.g., 'llama3.3:70b', 'qwen2.5:72b', 'deepseek-coder:33b').
	Model string `json:"model"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OllamaRerankerConfig Configuration for the Ollama reranking provider.
type OllamaRerankerConfig struct {
	// Model The name of the Ollama model to use for reranking.
	Model string `json:"model"`

	// Url The URL of the Ollama API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIEmbedderConfig Configuration for the OpenAI embedding provider.
//
// API key via `api_key` field or `OPENAI_API_KEY` environment variable.
// Supports OpenAI-compatible APIs via `url` field.
//
// **Example Models:** text-embedding-3-small (default, 1536 dims), text-embedding-3-large (3072 dims)
//
// **Docs:** https://platform.openai.com/docs/guides/embeddings
type OpenAIEmbedderConfig struct {
	// ApiKey The OpenAI API key. Can also be set via OPENAI_API_KEY environment variable.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// Dimensions Output dimension for the embedding (uses MRL for dimension reduction). Recommended: 256, 512, 1024, 1536, or 3072.
	Dimensions int `json:"dimensions,omitempty,omitzero"`

	// Model The name of the OpenAI model to use.
	Model string `json:"model"`

	// Url The URL of the OpenAI API endpoint. Defaults to OpenAI's API. Can be set via OPENAI_BASE_URL environment variable.
	Url string `json:"url,omitempty,omitzero"`
}

// OpenAIGeneratorConfig Configuration for the OpenAI generative AI provider.
//
// **Example Models:** gpt-4.1 (default), gpt-4.1-mini, o3, o4-mini
//
// **Docs:** https://platform.openai.com/docs/models
type OpenAIGeneratorConfig struct {
	// ApiKey The OpenAI API key.
	ApiKey string `json:"api_key,omitempty,omitzero"`

	// FrequencyPenalty Penalty for token frequency (-2.0 to 2.0).
	FrequencyPenalty float32 `json:"frequency_penalty,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the OpenAI model to use (e.g., 'gpt-4.1', 'gpt-4.1-mini', 'o4-mini').
	Model string `json:"model"`

	// PresencePenalty Penalty for token presence (-2.0 to 2.0).
	PresencePenalty float32 `json:"presence_penalty,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0).
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopP Nucleus sampling parameter.
	TopP float32 `json:"top_p,omitempty,omitzero"`

	// Url The URL of the OpenAI API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// Path defines model for Path.
type Path struct {
	Edges  []PathEdge `json:"edges,omitempty,omitzero"`
	Length int        `json:"length,omitempty,omitzero"`

	// Nodes Ordered list of node keys (base64-encoded)
	Nodes       []string `json:"nodes,omitempty,omitzero"`
	TotalWeight float64  `json:"total_weight,omitempty,omitzero"`
}

// PathEdge defines model for PathEdge.
type PathEdge struct {
	Metadata map[string]interface{} `json:"metadata,omitempty,omitzero"`
	Source   string                 `json:"source,omitempty,omitzero"`
	Target   string                 `json:"target,omitempty,omitzero"`
	Type     string                 `json:"type,omitempty,omitzero"`
	Weight   float64                `json:"weight,omitempty,omitzero"`
}

// PathFindRequest defines model for PathFindRequest.
type PathFindRequest struct {
	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter by specific edge types
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`
	K         int      `json:"k,omitempty,omitzero"`
	MaxDepth  int      `json:"max_depth,omitempty,omitzero"`
	MaxWeight float64  `json:"max_weight,omitempty,omitzero"`
	MinWeight float64  `json:"min_weight,omitempty,omitzero"`

	// Source Source node key (base64-encoded)
	Source string `json:"source"`

	// Target Target node key (base64-encoded)
	Target string `json:"target"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindResult defines model for PathFindResult.
type PathFindResult struct {
	Paths        []Path  `json:"paths,omitempty,omitzero"`
	PathsFound   int     `json:"paths_found,omitempty,omitzero"`
	SearchTimeMs float64 `json:"search_time_ms,omitempty,omitzero"`
	Source       string  `json:"source,omitempty,omitzero"`
	Target       string  `json:"target,omitempty,omitzero"`

	// WeightMode Algorithm for path finding:
	// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
	// - max_weight: Path with maximum product of edge weights (strongest connection chain)
	// - min_weight: Path with minimum sum of edge weights (lowest cost route)
	WeightMode PathFindWeightMode `json:"weight_mode,omitempty,omitzero"`
}

// PathFindWeightMode Algorithm for path finding:
// - min_hops: Shortest path by hop count (breadth-first search, ignores weights)
// - max_weight: Path with maximum product of edge weights (strongest connection chain)
// - min_weight: Path with minimum sum of edge weights (lowest cost route)
type PathFindWeightMode string

// PathWeightMode Path weighting algorithm for pathfinding:
// - min_hops: Minimize number of edges
// - min_weight: Minimize sum of edge weights
// - max_weight: Maximize product of edge weights
type PathWeightMode string

// PatternEdgeStep Edge constraints in a pattern step
type PatternEdgeStep struct {
	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// MaxHops Maximum number of hops (>1 = variable-length path)
	MaxHops int `json:"max_hops,omitempty,omitzero"`

	// MaxWeight Maximum edge weight filter
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinHops Minimum number of hops (1 = direct edge)
	MinHops int `json:"min_hops,omitempty,omitzero"`

	// MinWeight Minimum edge weight filter
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`

	// Types Edge types to traverse (empty = any)
	Types []string `json:"types,omitempty,omitzero"`
}

// PatternMatch A single match from a pattern query
type PatternMatch struct {
	// Bindings Map of alias to matched node
	Bindings map[string]GraphResultNode `json:"bindings,omitempty,omitzero"`

	// Path Edges traversed in this match
	Path []PathEdge `json:"path,omitempty,omitzero"`
}

// PatternStep A step in a graph pattern query
type PatternStep struct {
	// Alias Name for this node (reuse alias for cycle detection)
	Alias string `json:"alias,omitempty,omitzero"`

	// Edge Edge constraints in a pattern step
	Edge PatternEdgeStep `json:"edge,omitempty,omitzero"`

	// NodeFilter Filter nodes during graph traversal using existing query primitives
	NodeFilter NodeFilter `json:"node_filter,omitempty,omitzero"`
}

// Permission defines model for Permission.
type Permission struct {
	// Resource Resource name (e.g., table name, target username, or '*' for global).
	Resource string `json:"resource"`

	// ResourceType Type of the resource, e.g., table, user, or global ('*').
	ResourceType ResourceType `json:"resource_type"`

	// Type Type of permission.
	Type PermissionType `json:"type"`
}

// PermissionType Type of permission.
type PermissionType string

// PhraseQuery defines model for PhraseQuery.
type PhraseQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`

	// Fuzziness The fuzziness of the query. Can be an integer or "auto".
	Fuzziness Fuzziness `json:"fuzziness,omitempty,omitzero"`
	Terms     []string  `json:"terms"`
}

// PrefixQuery defines model for PrefixQuery.
type PrefixQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Prefix string `json:"prefix"`
}

// Pruner Configuration for pruning search results based on score quality.
// Helps filter out low-relevance results in RAG pipelines by detecting
// score gaps or deviations from top results.
type Pruner struct {
	// MaxScoreGapPercent Stop returning results when score drops more than this percentage
	// from the previous result. Detects "elbows" in score distribution.
	// For example, 30.0 stops when score drops 30% from previous result.
	MaxScoreGapPercent float64 `json:"max_score_gap_percent,omitempty,omitzero"`

	// MinAbsoluteScore Hard minimum score threshold. Results with scores below this value
	// are excluded regardless of other pruning settings.
	MinAbsoluteScore float64 `json:"min_absolute_score,omitempty,omitzero"`

	// MinScoreRatio Keep only results with score >= max_score * min_score_ratio.
	// For example, 0.5 keeps results scoring at least half of the top result.
	// Applied after fusion scoring.
	MinScoreRatio float64 `json:"min_score_ratio,omitempty,omitzero"`

	// RequireMultiIndex Only keep results that appear in multiple indexes (both full-text
	// and vector search). Useful for increasing precision by requiring
	// agreement between different retrieval methods.
	RequireMultiIndex bool `json:"require_multi_index,omitempty,omitzero"`

	// StdDevThreshold Keep results within N standard deviations below the mean score.
	// For example, 1.0 keeps results with score >= mean - 1*stddev.
	// Useful for statistical outlier detection in result sets.
	StdDevThreshold float64 `json:"std_dev_threshold,omitempty,omitzero"`
}

// Query defines model for Query.
type Query struct {
	union json.RawMessage
}

// QueryBuilderRequest defines model for QueryBuilderRequest.
type QueryBuilderRequest struct {
	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//    - Returns: `<<<dotprompt:media:url data:image/png;base64,...>>>`
	//    - Compatible with GenKit's dotprompt format
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator,omitempty,omitzero"`

	// Intent Natural language description of the search intent
	Intent string `json:"intent"`

	// SchemaFields List of searchable field names to consider. Overrides table schema if provided.
	SchemaFields []string `json:"schema_fields,omitempty,omitzero"`

	// Table Name of the table to build query for. If provided, uses table schema for field context.
	Table string `json:"table,omitempty,omitzero"`
}

// QueryBuilderResult defines model for QueryBuilderResult.
type QueryBuilderResult struct {
	// Confidence Model's confidence in the generated query (0.0-1.0)
	Confidence float64 `json:"confidence,omitempty,omitzero"`

	// Explanation Human-readable explanation of what the query does and why it was structured this way
	Explanation string `json:"explanation,omitempty,omitzero"`

	// Query Generated search query in simplified DSL format.
	// Can be used directly in QueryRequest.full_text_search or filter_query.
	Query map[string]interface{} `json:"query"`

	// Warnings Any issues, limitations, or assumptions made when generating the query
	Warnings []string `json:"warnings,omitempty,omitzero"`
}

// QueryHit A single query result hit
type QueryHit struct {
	// ID ID of the record.
	ID string `json:"_id"`

	// IndexScores Scores partitioned by index when using RRF search.
	IndexScores map[string]interface{} `json:"_index_scores,omitempty,omitzero"`

	// Score Relevance score of the hit.
	Score  float64                `json:"_score"`
	Source map[string]interface{} `json:"_source,omitempty,omitzero"`
}

// QueryHits A list of query hits.
type QueryHits struct {
	Hits []QueryHit `json:"hits"`

	// MaxScore Maximum score of the results.
	MaxScore float64 `json:"max_score,omitempty,omitzero"`

	// Total Total number of hits available.
	Total uint64 `json:"total,omitempty"`
}

// QueryRequest defines model for QueryRequest.
type QueryRequest struct {
	Analyses *Analyses `json:"analyses,omitempty"`

	// Count If true, returns only the total count of matching documents without retrieving the actual documents.
	// Useful for pagination and displaying result counts.
	Count bool `json:"count,omitempty,omitzero"`

	// DistanceOver Minimum distance threshold for semantic similarity search. Results with distance
	// less than this value are excluded.
	//
	// Useful for excluding near-exact duplicates or finding dissimilar documents.
	DistanceOver *float32 `json:"distance_over,omitempty"`

	// DistanceUnder Maximum distance threshold for semantic similarity search. Results with distance
	// greater than this value are excluded. Lower distances indicate higher similarity.
	//
	// Useful for filtering out low-confidence matches.
	DistanceUnder *float32 `json:"distance_under,omitempty"`

	// DocumentRenderer Optional Handlebars template string for rendering document content in RAG queries.
	// Template has access to document fields via `{{this.fields.fieldName}}`.
	//
	// **Default**: Uses TOON (Token-Oriented Object Notation) format for 30-60% token reduction:
	// ```handlebars
	// {{encodeToon this.fields}}
	// ```
	//
	// **Available Helpers**:
	// - `encodeToon` - Renders fields in compact TOON format with configurable options:
	//   - `lengthMarker` (bool): Add # prefix to array counts (default: true)
	//   - `indent` (int): Indentation spacing (default: 2)
	//   - `delimiter` (string): Field separator for tabular arrays
	// - `scrubHtml` - Removes HTML tags and extracts text
	// - `media` - Wraps data URIs for GenKit multimodal support
	// - `eq` - Equality comparison for conditionals
	//
	// **Examples**:
	// - Basic TOON: `{{encodeToon this.fields}}`
	// - Compact TOON: `{{encodeToon this.fields lengthMarker=false indent=0}}`
	// - Tabular data: `{{encodeToon this.fields delimiter="\t"}}`
	// - Custom template: `Title: {{this.fields.title}}\nBody: {{this.fields.body}}`
	// - Traditional format: `{{#each this.fields}}{{@key}}: {{this}}\n{{/each}}`
	//
	// TOON format produces compact, LLM-optimized output like:
	// ```
	// title: Introduction to Vector Search
	// author: Jane Doe
	// tags[#3]: ai,search,ml
	// ```
	//
	// **References**:
	// - TOON Specification: https://github.com/toon-format/toon
	// - Go Implementation: https://github.com/alpkeskin/gotoon
	DocumentRenderer string `json:"document_renderer,omitempty,omitzero"`

	// EmbeddingTemplate Optional Handlebars template for multimodal embedding of the semantic_search query.
	// The template has access to `this` which contains the semantic_search string value.
	//
	// Use this when you want to embed multimodal content (images, PDFs, etc.) instead of
	// just text. The template is rendered using dotprompt with access to remote content helpers.
	//
	// **Available Helpers**:
	// - `remoteMedia url=<url>` - Fetches and embeds remote images/media
	// - `remotePDF url=<url>` - Fetches and extracts content from PDFs
	// - `remoteText url=<url>` - Fetches and includes remote text content
	//
	// **Examples**:
	// - PDF search: `{{remotePDF url=this}}`
	// - Image search: `{{remoteMedia url=this}}`
	// - Mixed: `Search for: {{this}} {{#if this}}{{remoteMedia url=this}}{{/if}}`
	//
	// When not specified, the semantic_search string is embedded as plain text.
	EmbeddingTemplate string `json:"embedding_template,omitempty,omitzero"`

	// Embeddings Pre-computed embeddings to use for semantic searches instead of embedding the semantic_search string.
	// The keys are the index names, and values are the embedding vectors.
	//
	// Use when you've already generated embeddings on the client side to avoid redundant embedding calls.
	Embeddings map[string][]float32 `json:"embeddings,omitempty,omitzero"`

	// ExclusionQuery Bleve query applied as a NOT condition. Documents matching this query are excluded
	// from results. Applied before scoring.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Excluding drafts: `"status:draft"`
	// - Removing deprecated content: `"deprecated:true"`
	// - Filtering out archived items: `"status:archived"`
	ExclusionQuery json.RawMessage `json:"exclusion_query,omitempty,omitzero"`

	// ExpandStrategy Strategy for merging graph results with search results:
	// - union: Include nodes from both search and graph results
	// - intersection: Only include nodes appearing in both
	ExpandStrategy QueryRequestExpandStrategy `json:"expand_strategy,omitempty,omitzero"`

	// Facets Faceting configuration for aggregating results by field values.
	// Useful for building faceted navigation and filters.
	Facets map[string]FacetOption `json:"facets,omitempty,omitzero"`

	// Fields List of fields to include in the results. If not specified, all fields are returned.
	// Use to reduce response size and improve performance.
	Fields []string `json:"fields,omitempty,omitzero"`

	// FilterPrefix Filter results by key prefix. Only returns documents whose keys start with this string.
	// Applied before scoring to improve performance.
	//
	// Common use cases:
	// - Multi-tenant filtering: `"tenant:acme:"`
	// - User-specific data: `"user:123:"`
	// - Document type filtering: `"article:"`
	FilterPrefix []byte `json:"filter_prefix,omitempty,omitzero"`

	// FilterQuery Bleve query applied as an AND condition. Documents must match both the main query
	// and this filter. Applied before scoring for better performance.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Use for:
	// - Status filtering: `"status:published"`
	// - Date ranges: `"created_at:>2023-01-01"`
	// - Category filtering: `"category:technology AND language:en"`
	FilterQuery json.RawMessage `json:"filter_query,omitempty,omitzero"`

	// FullTextSearch Bleve query for full-text search. Supports all Bleve query types.
	//
	// See bleve-query-openapi.yaml for complete type definitions.
	//
	// Examples:
	// - Simple: `{"query": "computer"}`
	// - Field-specific: `{"query": "body:computer"}`
	// - Boolean: `{"query": "artificial AND intelligence"}`
	// - Range: `{"query": "year:>2020"}`
	// - Phrase: `{"query": "\"exact phrase\""}`
	FullTextSearch json.RawMessage `json:"full_text_search,omitempty,omitzero"`

	// GraphSearches Declarative graph queries to execute after full-text/vector searches.
	// Results can reference search results using node selectors like $full_text_results.
	GraphSearches map[string]GraphQuery `json:"graph_searches,omitempty,omitzero"`

	// Indexes List of vector index names to use for semantic search. Required when using semantic_search.
	// Multiple indexes can be specified, and their results will be merged using RRF.
	Indexes []string `json:"indexes,omitempty,omitzero"`

	// Limit Maximum number of results to return. For semantic_search, this is the topk parameter.
	// Default varies by query type (typically 10).
	Limit int `json:"limit,omitempty,omitzero"`

	// MergeStrategy Merge strategy for combining results from the semantic_search and full_text_search.
	// rrf: Reciprocal Rank Fusion - combines scores using reciprocal rank formula
	// rsf: Relative Score Fusion - normalizes scores by min/max within a window and combines weighted scores
	// failover: Use full_text_search if embedding generation fails
	MergeStrategy MergeStrategy `json:"merge_strategy,omitempty,omitzero"`

	// Offset Number of results to skip for pagination. Only available for full_text_search queries.
	// Not supported for semantic_search due to vector index limitations.
	Offset int `json:"offset,omitempty,omitzero"`

	// OrderBy Sort order for results. Map of field names to boolean (true = descending, false = ascending).
	// Only applicable for full_text_search queries. Semantic searches are always sorted by similarity score.
	OrderBy map[string]bool `json:"order_by,omitempty,omitzero"`

	// Pruner Configuration for pruning search results based on score quality.
	// Helps filter out low-relevance results in RAG pipelines by detecting
	// score gaps or deviations from top results.
	Pruner Pruner `json:"pruner,omitempty,omitzero"`

	// Reranker A unified configuration for a reranking provider.
	Reranker *RerankerConfig `json:"reranker,omitempty"`

	// SemanticSearch Natural language query for vector similarity search. Results are ranked by semantic similarity
	// to the query and can be combined with full_text_search using Reciprocal Rank Fusion (RRF).
	//
	// The semantic_search string is automatically embedded using the configured embedding model
	// for the specified indexes. Use `embedding_template` for multimodal queries.
	SemanticSearch string `json:"semantic_search,omitempty,omitzero"`

	// Table Name of the table to query. Optional for global queries.
	Table string `json:"table,omitempty,omitzero"`
}

// QueryRequestExpandStrategy Strategy for merging graph results with search results:
// - union: Include nodes from both search and graph results
// - intersection: Only include nodes appearing in both
type QueryRequestExpandStrategy string

// QueryResponses Responses from multiple query operations.
type QueryResponses struct {
	Responses []QueryResult `json:"responses,omitempty,omitzero"`
}

// QueryResult Result of a query operation as an array of results and a count.
type QueryResult struct {
	// Analyses Analysis results like PCA and t-SNE per index embeddings.
	Analyses map[string]AnalysesResult `json:"analyses,omitempty,omitzero"`

	// Error Error message if the query failed.
	Error  string                 `json:"error,omitempty,omitzero"`
	Facets map[string]FacetResult `json:"facets,omitempty,omitzero"`

	// GraphResults Results from declarative graph queries.
	GraphResults map[string]GraphQueryResult `json:"graph_results,omitempty,omitzero"`

	// Hits A list of query hits.
	Hits QueryHits `json:"hits"`

	// Status HTTP status code of the query operation.
	Status int32 `json:"status"`

	// Table Which table this result came from
	Table string `json:"table,omitempty,omitzero"`

	// Took Duration of the query in milliseconds.
	Took time.Duration `json:"took"`
}

// QueryStrategy Strategy for query transformation and retrieval:
// - simple: Direct query with multi-phrase expansion. Best for straightforward factual queries.
// - decompose: Break complex queries into sub-questions, retrieve for each. Best for multi-part questions.
// - step_back: Generate broader background query first, then specific query. Best for questions needing context.
// - hyde: Generate hypothetical answer document, embed that for retrieval. Best for abstract/conceptual questions.
type QueryStrategy string

// QueryStringQuery defines model for QueryStringQuery.
type QueryStringQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Query string `json:"query"`
}

// RAGRequest defines model for RAGRequest.
type RAGRequest struct {
	// Generator A unified configuration for a generative AI provider.
	//
	// Generators can be configured with custom prompts using templates. Templates use
	// Handlebars syntax and support various built-in helpers for formatting and data manipulation.
	//
	// **Template System:**
	// - **Syntax**: Handlebars templating (https://handlebarsjs.com/guide/)
	// - **Caching**: Templates are automatically cached with configurable TTL (default: 5 minutes)
	// - **Context**: Templates receive the full context data passed to the generator
	//
	// **Built-in Helpers:**
	//
	// 1. **scrubHtml** - Remove script/style tags and extract clean text from HTML
	//    ```handlebars
	//    {{scrubHtml html_content}}
	//    ```
	//    - Removes `<script>` and `<style>` tags
	//    - Adds newlines after block elements (p, div, h1-h6, li, etc.)
	//    - Returns plain text with preserved readability
	//    - Useful for cleaning web content before summarization
	//
	// 2. **eq** - Equality comparison for conditionals
	//    ```handlebars
	//    {{#if (eq status "active")}}Active{{/if}}
	//    {{#if (eq @key "special")}}Special field{{/if}}
	//    ```
	//    - Use in `{{#if}}` blocks for conditional logic
	//    - Compares any two values for equality
	//
	// 3. **media** - GenKit dotprompt media directive for multimodal content
	//    ```handlebars
	//    {{media url=imageDataURI}}
	//    {{media url=this.image_url}}
	//    {{media url="https://example.com/image.jpg"}}
	//    {{media url="s3://endpoint/bucket/image.png"}}
	//    {{media url="file:///path/to/image.jpg"}}
	//    ```
	//    - Returns: `<<<dotprompt:media:url data:image/png;base64,...>>>`
	//    - Compatible with GenKit's dotprompt format
	//
	//    **Supported URL Schemes:**
	//    - `data:` - Base64 encoded data URIs (e.g., `data:image/jpeg;base64,...`)
	//    - `http://` / `https://` - Web URLs with automatic content type detection
	//    - `file://` - Local filesystem paths
	//    - `s3://` - S3-compatible storage (format: `s3://endpoint/bucket/key`)
	//
	//    **Automatic Content Processing:**
	//    - **Images**: Downloaded, resized (if needed), converted to data URIs
	//    - **PDFs**: Text extracted or first page rendered as image
	//    - **HTML**: Readable text extracted using Mozilla Readability
	//
	//    **Security Controls:**
	//    Downloads are protected by content security settings (see Configuration Reference):
	//    - Allowed host whitelist
	//    - Private IP blocking (prevents SSRF attacks)
	//    - Download size limits (default: 100MB)
	//    - Download timeouts (default: 30s)
	//    - Image dimension limits (default: 2048px, auto-resized)
	//
	//    See: https://antfly.io/docs/configuration#security--cors
	//
	// 4. **encodeToon** - Encode data in TOON format (Token-Oriented Object Notation)
	//    ```handlebars
	//    {{encodeToon this.fields}}
	//    {{encodeToon this.fields lengthMarker=false indent=4}}
	//    {{encodeToon this.fields delimiter="\t"}}
	//    ```
	//
	//    **What is TOON?**
	//    TOON is a compact, human-readable format designed for passing structured data to LLMs.
	//    It provides **30-60% token reduction** compared to JSON while maintaining high LLM
	//    comprehension accuracy.
	//
	//    **Key Features:**
	//    - Compact syntax using `:` for key-value pairs
	//    - Array length markers: `tags[#3]: ai,search,ml`
	//    - Tabular format for uniform data structures
	//    - Optimized for LLM parsing and understanding
	//    - Maintains human readability
	//
	//    **Benefits:**
	//    - **Lower API costs** - Reduced token usage means lower LLM API costs
	//    - **Faster responses** - Less tokens to process
	//    - **More context** - Fit more documents within token limits
	//
	//    **Options:**
	//    - `lengthMarker` (bool): Add # prefix to array counts like `[#3]` (default: true)
	//    - `indent` (int): Indentation spacing for nested objects (default: 2)
	//    - `delimiter` (string): Field separator for tabular arrays (default: none, use `"\t"` for tabs)
	//
	//    **Example output:**
	//    ```
	//    title: Introduction to Vector Search
	//    author: Jane Doe
	//    tags[#3]: ai,search,ml
	//    metadata:
	//      edition: 2
	//      pages: 450
	//    ```
	//
	//    **Default in RAG:** TOON is the default format for document rendering in RAG queries.
	//
	//    **References:**
	//    - TOON Specification: https://github.com/toon-format/toon
	//    - Go Implementation: https://github.com/alpkeskin/gotoon
	//
	// **Template Examples:**
	//
	// RAG summarization with document references:
	// ```handlebars
	// Based on these documents, provide a comprehensive summary:
	//
	// {{#each documents}}
	// Document {{this.id}}:
	// {{scrubHtml this.content}}
	//
	// {{/each}}
	//
	// Valid document IDs: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	// ```
	//
	// Conditional formatting:
	// ```handlebars
	// {{#if system_prompt}}System: {{system_prompt}}{{/if}}
	//
	// User Query: {{query}}
	//
	// {{#if context}}
	// Context:
	// {{#each context}}
	// - {{this}}
	// {{/each}}
	// {{/if}}
	// ```
	//
	// Multimodal prompt with images:
	// ```handlebars
	// Analyze this image:
	// {{media url=image_url}}
	//
	// Focus on: {{focus_area}}
	// ```
	//
	// Structured data encoding:
	// ```handlebars
	// User Profile:
	// {{encodeToon user_data indent=2 lengthMarker=true}}
	//
	// Please analyze this profile.
	// ```
	//
	// **Common Use Cases:**
	// - **RAG (Retrieval-Augmented Generation)**: Format retrieved documents with citations
	// - **Summarization**: Clean HTML content and structure summaries
	// - **Query Classification**: Format queries with metadata for better classification
	// - **Multimodal**: Include images/audio/video in prompts
	// - **Data Formatting**: Convert structured data to readable text
	//
	// **Best Practices:**
	// - Keep templates simple - complex logic belongs in application code
	// - Use clear, descriptive field names in context
	// - Handle missing fields gracefully (templates use "missingkey=zero" by default)
	// - Test templates with representative data before production use
	Generator GeneratorConfig `json:"generator"`

	// Prompt Optional custom user prompt template for the LLM. If not provided, a default prompt is used.
	// The prompt can reference the following variables:
	// - {{documents}}: Array of retrieved documents with id and fields
	// - {{semantic_search}}: The user's semantic search query (if provided)
	// You can use Handlebars template syntax to customize the prompt, including loops and conditionals.
	// To generate a comma-separated list of document IDs, use: {{#each documents}}{{this.id}}{{#unless @last}}, {{/unless}}{{/each}}
	Prompt string `json:"prompt,omitempty,omitzero"`

	// Queries Array of retrieval queries to execute. Each query must specify a table and can specify its own limit and document_renderer.
	// Results from all queries are concatenated together (respecting each query's limit).
	// For single table: [{"table": "papers", "semantic_search": "...", "limit": 10}]
	// For broadcast: [{"table": "images", "limit": 5, ...}, {"table": "products", "limit": 5, ...}]
	// For mixed: [{"table": "papers", "semantic_search": "...", "limit": 10}, {"table": "books", "full_text_search": {...}, "limit": 5}]
	Queries []QueryRequest `json:"queries"`

	// SystemPrompt Optional system prompt to guide the summarization
	SystemPrompt string `json:"system_prompt,omitempty,omitzero"`

	// WithStreaming Enable SSE streaming of results instead of JSON response
	WithStreaming bool `json:"with_streaming,omitempty,omitzero"`
}

// RAGResult RAG result with individual query results and summary
type RAGResult struct {
	// QueryResults Results from each query. Check each result's status and error fields for failures.
	QueryResults []QueryResult `json:"query_results,omitempty,omitzero"`

	// SummaryResult Result of a summarization operation. The summary is formatted as markdown with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
	SummaryResult SummarizeResult `json:"summary_result,omitempty,omitzero"`
}

// RegexpQuery defines model for RegexpQuery.
type RegexpQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost  Boost  `json:"boost,omitzero"`
	Field  string `json:"field,omitempty,omitzero"`
	Regexp string `json:"regexp"`
}

// RerankerConfig defines model for RerankerConfig.
type RerankerConfig struct {
	// Field Field name to extract from documents for reranking.
	Field string `json:"field,omitempty,omitzero"`

	// Provider The reranking provider to use.
	Provider RerankerProvider `json:"provider"`

	// Template Handlebars template to render document text for reranking.
	Template string `json:"template,omitempty,omitzero"`
	union    json.RawMessage
}

// RerankerProvider The reranking provider to use.
type RerankerProvider string

// ResourceType Type of the resource, e.g., table, user, or global ('*').
type ResourceType string

// RestoreRequest defines model for RestoreRequest.
type RestoreRequest = BackupRequest

// RetryConfig Retry configuration for generator calls
type RetryConfig struct {
	// BackoffMultiplier Multiplier for exponential backoff
	BackoffMultiplier float32 `json:"backoff_multiplier,omitempty,omitzero"`

	// InitialBackoffMs Initial backoff delay in milliseconds
	InitialBackoffMs int `json:"initial_backoff_ms,omitempty,omitzero"`

	// MaxAttempts Maximum number of retry attempts
	MaxAttempts int `json:"max_attempts,omitempty,omitzero"`

	// MaxBackoffMs Maximum backoff delay in milliseconds
	MaxBackoffMs int `json:"max_backoff_ms,omitempty,omitzero"`
}

// RouteType Classification of query type: question (specific factual query) or search (exploratory query)
type RouteType string

// SemanticQueryMode Mode for semantic query generation:
// - rewrite: Transform query into expanded keywords/concepts optimized for vector search (Level 2 optimization)
// - hypothetical: Generate a hypothetical answer that would appear in relevant documents (HyDE - Level 3 optimization)
type SemanticQueryMode string

// ShardConfig defines model for ShardConfig.
type ShardConfig struct {
	ByteRange ByteRange `json:"byte_range"`
}

// StorageStatus defines model for StorageStatus.
type StorageStatus struct {
	// DiskUsage Disk usage in bytes.
	DiskUsage uint64 `json:"disk_usage,omitempty,omitzero"`

	// Empty Whether the table has received data.
	Empty bool `json:"empty,omitempty,omitzero"`
}

// SuccessMessage defines model for SuccessMessage.
type SuccessMessage struct {
	Message string `json:"message,omitempty,omitzero"`
}

// SummarizeResult Result of a summarization operation. The summary is formatted as markdown with inline resource references using [resource_id <id>] or [resource_id <id1>, <id2>] format.
type SummarizeResult struct {
	// Summary The generated summary text in markdown format with inline resource references like [resource_id res1] or [resource_id res1, res2]
	Summary string `json:"summary"`
}

// SyncLevel Synchronization level for batch operations:
// - "propose": Wait for Raft proposal acceptance (fastest, default)
// - "write": Wait for Pebble KV write
// - "full_text": Wait for full-text index WAL write
// - "enrichments": Pre-compute enrichments before Raft proposal (synchronous enrichment generation)
// - "aknn": Wait for vector index write with best-effort synchronous embedding (falls back to async on timeout, slowest, most durable)
type SyncLevel string

// Table defines model for Table.
type Table struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema TableSchema            `json:"schema,omitempty,omitzero"`
	Shards map[string]ShardConfig `json:"shards"`
}

// TableSchema Schema definition for a table with multiple document types
type TableSchema struct {
	// DefaultType Default type to use from the document_types.
	DefaultType string `json:"default_type,omitempty,omitzero"`

	// DocumentSchemas A map of type names to their document json schemas.
	DocumentSchemas map[string]DocumentSchema `json:"document_schemas,omitempty,omitzero"`

	// EnforceTypes Whether to enforce that documents must match one of the provided document types.
	// If false, documents not matching any type will be accepted but not indexed.
	EnforceTypes bool `json:"enforce_types,omitempty,omitzero"`

	// TtlDuration The duration after which documents should expire, based on the ttl_field timestamp (optional).
	// Uses Go duration format (e.g., '24h', '7d', '168h').
	TtlDuration string `json:"ttl_duration,omitempty,omitzero"`

	// TtlField The field containing the timestamp for TTL expiration (optional).
	// Defaults to "_timestamp" if ttl_duration is specified but ttl_field is not.
	TtlField string `json:"ttl_field,omitempty,omitzero"`

	// Version Version of the schema. Used for migrations.
	Version uint32 `json:"version,omitempty,omitzero"`
}

// TableStatus defines model for TableStatus.
type TableStatus struct {
	// Description Optional description of the table.
	Description string                 `json:"description,omitempty,omitzero"`
	Indexes     map[string]IndexConfig `json:"indexes"`
	Name        string                 `json:"name"`

	// Schema Schema definition for a table with multiple document types
	Schema        TableSchema            `json:"schema,omitempty,omitzero"`
	Shards        map[string]ShardConfig `json:"shards"`
	StorageStatus StorageStatus          `json:"storage_status"`
}

// TermFacetResult defines model for TermFacetResult.
type TermFacetResult struct {
	Count int    `json:"count"`
	Term  string `json:"term"`
}

// TermQuery defines model for TermQuery.
type TermQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost Boost  `json:"boost,omitzero"`
	Field string `json:"field,omitempty,omitzero"`
	Term  string `json:"term"`
}

// TermRangeQuery defines model for TermRangeQuery.
type TermRangeQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost        Boost  `json:"boost,omitzero"`
	Field        string `json:"field,omitempty,omitzero"`
	InclusiveMax bool   `json:"inclusive_max,omitzero"`
	InclusiveMin bool   `json:"inclusive_min,omitzero"`
	Max          string `json:"max,omitzero"`
	Min          string `json:"min,omitzero"`
}

// TermiteChunkerConfig Configuration for the Termite chunking provider.
//
// Termite is a centralized HTTP service that provides chunking with multi-tier caching.
// It supports multiple chunking strategies - the strategy name maps to ONNX model directory names
// (similar to how Ollama works with model names).
//
// **Chunking Strategies:**
// - fixed: Simple fixed-size chunking by token count (built-in, no ONNX required)
// - chonky_onnx: ONNX model from models/chunkers/chonky_onnx/ directory
// - Any other name will attempt to load from models/chunkers/{name}/ directory
//
// **Caching:**
// - L1: Memory cache with 2-minute TTL
// - L2: Persistent Pebble database
// - Singleflight deduplication for concurrent identical requests
type TermiteChunkerConfig struct {
	// ApiUrl The URL of the Termite API endpoint (e.g., 'http://localhost:8080'). Can also be set via ANTFLY_TERMITE_URL environment variable.
	ApiUrl string `json:"api_url,omitempty,omitzero"`

	// FullText Configuration for full-text indexing of chunks in Bleve.
	// When present (even if empty), chunks will be stored with :cft: suffix and indexed in Bleve's _chunks field.
	// When absent, chunks use :c: suffix and are only used for vector embeddings.
	// This object is reserved for future options like boosting, field mapping, etc.
	FullText map[string]interface{} `json:"full_text,omitempty,omitzero"`

	// MaxChunks Maximum number of chunks to generate per document. Prevents excessive chunking of very large documents.
	MaxChunks int `json:"max_chunks,omitempty,omitzero"`

	// OverlapTokens Number of tokens to overlap between consecutive chunks. Helps maintain context across chunk boundaries.
	OverlapTokens int `json:"overlap_tokens,omitempty,omitzero"`

	// Separator Separator string for splitting (e.g., '\n\n' for paragraphs). Only used with fixed strategy.
	Separator string `json:"separator,omitempty,omitzero"`

	// Strategy Document chunking strategy. The strategy name maps to ONNX model directory names when using Termite.
	// - fixed: Simple fixed-size chunking by token count (built-in, no ONNX required)
	// - chonky_onnx: ONNX-accelerated chunking using sentence boundary detection (requires models/chunkers/chonky_onnx/)
	Strategy ChunkingStrategy `json:"strategy"`

	// TargetTokens Target number of tokens per chunk. Chunker will aim for chunks around this size.
	TargetTokens int `json:"target_tokens,omitempty,omitzero"`

	// Threshold Minimum confidence threshold for separator detection. Only used with ONNX-based strategies like chonky_onnx.
	Threshold float32 `json:"threshold,omitempty,omitzero"`
}

// TermiteRerankerConfig Configuration for the Termite reranking provider.
type TermiteRerankerConfig struct {
	// Model The name of the reranking model (e.g., cross-encoder model name).
	Model string `json:"model"`

	// Url The URL of the Termite API endpoint.
	Url string `json:"url,omitempty,omitzero"`
}

// Transform In-place document transformation using MongoDB-style operators. Transforms are applied atomically
// at the storage layer, eliminating read-modify-write races.
//
// **Important:** Transform results are NOT validated against the table schema. This improves performance
// but means it's possible to create invalid documents. Use with care and ensure your operations maintain
// schema compliance.
type Transform struct {
	// Key Document key (must be a string, not an object like inserts)
	Key string `json:"key"`

	// Operations List of operations to apply in sequence
	Operations []TransformOp `json:"operations"`

	// Upsert If true, create document if it doesn't exist (like MongoDB upsert)
	Upsert bool `json:"upsert,omitempty,omitzero"`
}

// TransformOp defines model for TransformOp.
type TransformOp struct {
	// Op MongoDB-style update operator
	Op TransformOpType `json:"op"`

	// Path JSONPath to field (e.g., "$.user.name", "$.tags", or "user.name")
	Path string `json:"path"`

	// Value Value for operation (not required for $unset, $currentDate). Type depends on operator (number for $inc/$mul, any for $set, etc.)
	Value interface{} `json:"value,omitempty,omitzero"`
}

// TransformOpType MongoDB-style update operator
type TransformOpType string

// TraversalResult A single result from graph traversal
type TraversalResult struct {
	// Depth Distance from start node (0 = start node)
	Depth int `json:"depth"`

	// Document Document data (if loaded)
	Document map[string]interface{} `json:"document,omitempty,omitzero"`

	// Key Base64-encoded document key
	Key []byte `json:"key"`

	// Path Sequence of keys from start to this node (if include_paths=true)
	Path [][]byte `json:"path,omitempty,omitzero"`

	// PathEdges Sequence of edges from start to this node (if include_paths=true)
	PathEdges []Edge `json:"path_edges,omitempty,omitzero"`

	// TotalWeight Product of edge weights along the path
	TotalWeight float64 `json:"total_weight,omitempty,omitzero"`
}

// TraversalRules Rules for graph traversal
type TraversalRules struct {
	// DeduplicateNodes Visit each node only once
	DeduplicateNodes bool `json:"deduplicate_nodes,omitempty,omitzero"`

	// Direction Direction of edges to query:
	// - out: Outgoing edges from the node
	// - in: Incoming edges to the node
	// - both: Both outgoing and incoming edges
	Direction EdgeDirection `json:"direction,omitempty,omitzero"`

	// EdgeTypes Filter edges by type (empty = all types)
	EdgeTypes []string `json:"edge_types,omitempty,omitzero"`

	// IncludePaths Include path information in results
	IncludePaths bool `json:"include_paths,omitempty,omitzero"`

	// MaxDepth Maximum traversal depth (0 = unlimited)
	MaxDepth int `json:"max_depth,omitempty,omitzero"`

	// MaxResults Maximum results to return (0 = unlimited)
	MaxResults int `json:"max_results,omitempty,omitzero"`

	// MaxWeight Maximum edge weight filter
	MaxWeight float64 `json:"max_weight,omitempty,omitzero"`

	// MinWeight Minimum edge weight filter
	MinWeight float64 `json:"min_weight,omitempty,omitzero"`
}

// TraverseResponse defines model for TraverseResponse.
type TraverseResponse struct {
	// Count Total number of results
	Count   int               `json:"count,omitempty,omitzero"`
	Results []TraversalResult `json:"results,omitempty,omitzero"`
}

// UpdatePasswordRequest defines model for UpdatePasswordRequest.
type UpdatePasswordRequest struct {
	NewPassword string `json:"new_password"`
}

// User defines model for User.
type User struct {
	// PasswordHash Base64 encoded password hash. Exposing this is a security risk.
	PasswordHash []byte `json:"password_hash"`
	Username     string `json:"username"`
}

// VertexEmbedderConfig Configuration for Google Cloud Vertex AI embedding models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication. Requires IAM role `roles/aiplatform.user`.
//
// **Example Models:** gemini-embedding-001 (default, 3072 dims), multimodalembedding (images/audio/video)
//
// **Docs:** https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings
type VertexEmbedderConfig struct {
	// CredentialsPath Path to service account JSON key file. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Dimension The dimension of the embedding vector (768, 1536, or 3072 for gemini-embedding-001; 128-1408 for multimodalembedding).
	Dimension int `json:"dimension,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// Model The name of the Vertex AI embedding model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`
}

// VertexGeneratorConfig Configuration for Google Cloud Vertex AI generative models (enterprise-grade).
//
// Uses Application Default Credentials (ADC) for authentication. In GCP environments
// (Cloud Run, GKE, Compute Engine) this is automatic. For local dev, run
// `gcloud auth application-default login`. Requires IAM role `roles/aiplatform.user`.
//
// **Example Models:** gemini-2.5-flash (default), gemini-2.5-pro, gemini-3.0-pro
//
// **Docs:** https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models
type VertexGeneratorConfig struct {
	// CredentialsPath Path to service account JSON key file. Sets GOOGLE_APPLICATION_CREDENTIALS environment variable. Alternative to ADC for non-GCP environments.
	CredentialsPath string `json:"credentials_path,omitempty,omitzero"`

	// Location Google Cloud region for Vertex AI API (e.g., 'us-central1', 'europe-west1'). Can also be set via GOOGLE_CLOUD_LOCATION. Defaults to 'us-central1'.
	Location string `json:"location,omitempty,omitzero"`

	// MaxTokens Maximum number of tokens to generate in the response.
	MaxTokens int `json:"max_tokens,omitempty,omitzero"`

	// Model The name of the Vertex AI model to use.
	Model string `json:"model"`

	// ProjectId Google Cloud project ID. Can also be set via GOOGLE_CLOUD_PROJECT environment variable.
	ProjectId string `json:"project_id,omitempty,omitzero"`

	// Temperature Controls randomness in generation (0.0-2.0). Higher values make output more random.
	Temperature float32 `json:"temperature,omitempty,omitzero"`

	// TopK Top-k sampling parameter. Only sample from the top K options for each subsequent token.
	TopK int `json:"top_k,omitempty,omitzero"`

	// TopP Nucleus sampling parameter (0.0-1.0). Alternative to temperature.
	TopP float32 `json:"top_p,omitempty,omitzero"`
}

// WildcardQuery defines model for WildcardQuery.
type WildcardQuery struct {
	// Boost A floating-point number used to decrease or increase the relevance scores of a query.
	Boost    Boost  `json:"boost,omitzero"`
	Field    string `json:"field,omitempty,omitzero"`
	Wildcard string `json:"wildcard"`
}

// UserNamePathParameter defines model for UserNamePathParameter.
type UserNamePathParameter = string

// BadRequest defines model for BadRequest.
type BadRequest = Error

// InternalServerError defines model for InternalServerError.
type InternalServerError = Error

// NotFound defines model for NotFound.
type NotFound = Error

// ListTablesParams defines parameters for ListTables.
type ListTablesParams struct {
	// Prefix Filter tables by name prefix (e.g., "prod_")
	Prefix string `form:"prefix,omitempty" json:"prefix,omitempty,omitzero"`

	// Pattern Filter tables by regex pattern (e.g., "^prod_.*_v[0-9]+$")
	Pattern string `form:"pattern,omitempty" json:"pattern,omitempty,omitzero"`
}

// RemovePermissionFromUserParams defines parameters for RemovePermissionFromUser.
type RemovePermissionFromUserParams struct {
	// Resource The name of the resource for the permission to be removed.
	Resource string `form:"resource" json:"resource"`

	// ResourceType The type of the resource for the permission to be removed.
	ResourceType ResourceType `form:"resourceType" json:"resourceType"`
}

// AnswerAgentJSONRequestBody defines body for AnswerAgent for application/json ContentType.
type AnswerAgentJSONRequestBody = AnswerAgentRequest

// QueryBuilderAgentJSONRequestBody defines body for QueryBuilderAgent for application/json ContentType.
type QueryBuilderAgentJSONRequestBody = QueryBuilderRequest

// GlobalQueryJSONRequestBody defines body for GlobalQuery for application/json ContentType.
type GlobalQueryJSONRequestBody = QueryRequest

// RagQueryJSONRequestBody defines body for RagQuery for application/json ContentType.
type RagQueryJSONRequestBody = RAGRequest

// CreateTableJSONRequestBody defines body for CreateTable for application/json ContentType.
type CreateTableJSONRequestBody = CreateTableRequest

// BackupTableJSONRequestBody defines body for BackupTable for application/json ContentType.
type BackupTableJSONRequestBody = BackupRequest

// BatchJSONRequestBody defines body for Batch for application/json ContentType.
type BatchJSONRequestBody = BatchRequest

// CreateIndexJSONRequestBody defines body for CreateIndex for application/json ContentType.
type CreateIndexJSONRequestBody = IndexConfig

// LinearMergeJSONRequestBody defines body for LinearMerge for application/json ContentType.
type LinearMergeJSONRequestBody = LinearMergeRequest

// QueryTableJSONRequestBody defines body for QueryTable for application/json ContentType.
type QueryTableJSONRequestBody = QueryRequest

// TableRagQueryJSONRequestBody defines body for TableRagQuery for application/json ContentType.
type TableRagQueryJSONRequestBody = RAGRequest

// RestoreTableJSONRequestBody defines body for RestoreTable for application/json ContentType.
type RestoreTableJSONRequestBody = RestoreRequest

// UpdateSchemaJSONRequestBody defines body for UpdateSchema for application/json ContentType.
type UpdateSchemaJSONRequestBody = TableSchema

// CreateUserJSONRequestBody defines body for CreateUser for application/json ContentType.
type CreateUserJSONRequestBody = CreateUserRequest

// UpdateUserPasswordJSONRequestBody defines body for UpdateUserPassword for application/json ContentType.
type UpdateUserPasswordJSONRequestBody = UpdatePasswordRequest

// AddPermissionToUserJSONRequestBody defines body for AddPermissionToUser for application/json ContentType.
type AddPermissionToUserJSONRequestBody = Permission

// Getter for additional properties for ClusterStatus. Returns the specified
// element and whether it was found
func (a ClusterStatus) Get(fieldName string) (value interface{}, found bool) {
	if a.AdditionalProperties != nil {
		value, found = a.AdditionalProperties[fieldName]
	}
	return
}

// Setter for additional properties for ClusterStatus
func (a *ClusterStatus) Set(fieldName string, value interface{}) {
	if a.AdditionalProperties == nil {
		a.AdditionalProperties = make(map[string]interface{})
	}
	a.AdditionalProperties[fieldName] = value
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a *ClusterStatus) UnmarshalJSON(b []byte) error {
	object := make(map[string]json.RawMessage)
	err := json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["auth_enabled"]; found {
		err = json.Unmarshal(raw, &a.AuthEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'auth_enabled': %w", err)
		}
		delete(object, "auth_enabled")
	}

	if raw, found := object["health"]; found {
		err = json.Unmarshal(raw, &a.Health)
		if err != nil {
			return fmt.Errorf("error reading 'health': %w", err)
		}
		delete(object, "health")
	}

	if raw, found := object["message"]; found {
		err = json.Unmarshal(raw, &a.Message)
		if err != nil {
			return fmt.Errorf("error reading 'message': %w", err)
		}
		delete(object, "message")
	}

	if len(object) != 0 {
		a.AdditionalProperties = make(map[string]interface{})
		for fieldName, fieldBuf := range object {
			var fieldVal interface{}
			err := json.Unmarshal(fieldBuf, &fieldVal)
			if err != nil {
				return fmt.Errorf("error unmarshaling field %s: %w", fieldName, err)
			}
			a.AdditionalProperties[fieldName] = fieldVal
		}
	}
	return nil
}

// Override default JSON handling for ClusterStatus to handle AdditionalProperties
func (a ClusterStatus) MarshalJSON() ([]byte, error) {
	var err error
	object := make(map[string]json.RawMessage)

	object["auth_enabled"], err = json.Marshal(a.AuthEnabled)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'auth_enabled': %w", err)
	}

	object["health"], err = json.Marshal(a.Health)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'health': %w", err)
	}

	object["message"], err = json.Marshal(a.Message)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'message': %w", err)
	}

	for fieldName, field := range a.AdditionalProperties {
		object[fieldName], err = json.Marshal(field)
		if err != nil {
			return nil, fmt.Errorf("error marshaling '%s': %w", fieldName, err)
		}
	}
	return json.Marshal(object)
}

// AsTermiteChunkerConfig returns the union data inside the ChunkerConfig as a TermiteChunkerConfig
func (t ChunkerConfig) AsTermiteChunkerConfig() (TermiteChunkerConfig, error) {
	var body TermiteChunkerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteChunkerConfig overwrites any union data inside the ChunkerConfig as the provided TermiteChunkerConfig
func (t *ChunkerConfig) FromTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteChunkerConfig performs a merge with any union data inside the ChunkerConfig, using the provided TermiteChunkerConfig
func (t *ChunkerConfig) MergeTermiteChunkerConfig(v TermiteChunkerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAntflyChunkerConfig returns the union data inside the ChunkerConfig as a AntflyChunkerConfig
func (t ChunkerConfig) AsAntflyChunkerConfig() (AntflyChunkerConfig, error) {
	var body AntflyChunkerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAntflyChunkerConfig overwrites any union data inside the ChunkerConfig as the provided AntflyChunkerConfig
func (t *ChunkerConfig) FromAntflyChunkerConfig(v AntflyChunkerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAntflyChunkerConfig performs a merge with any union data inside the ChunkerConfig, using the provided AntflyChunkerConfig
func (t *ChunkerConfig) MergeAntflyChunkerConfig(v AntflyChunkerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t ChunkerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *ChunkerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsGoogleEmbedderConfig returns the union data inside the EmbedderConfig as a GoogleEmbedderConfig
func (t EmbedderConfig) AsGoogleEmbedderConfig() (GoogleEmbedderConfig, error) {
	var body GoogleEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided GoogleEmbedderConfig
func (t *EmbedderConfig) FromGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided GoogleEmbedderConfig
func (t *EmbedderConfig) MergeGoogleEmbedderConfig(v GoogleEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexEmbedderConfig returns the union data inside the EmbedderConfig as a VertexEmbedderConfig
func (t EmbedderConfig) AsVertexEmbedderConfig() (VertexEmbedderConfig, error) {
	var body VertexEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided VertexEmbedderConfig
func (t *EmbedderConfig) FromVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided VertexEmbedderConfig
func (t *EmbedderConfig) MergeVertexEmbedderConfig(v VertexEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaEmbedderConfig returns the union data inside the EmbedderConfig as a OllamaEmbedderConfig
func (t EmbedderConfig) AsOllamaEmbedderConfig() (OllamaEmbedderConfig, error) {
	var body OllamaEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OllamaEmbedderConfig
func (t *EmbedderConfig) FromOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OllamaEmbedderConfig
func (t *EmbedderConfig) MergeOllamaEmbedderConfig(v OllamaEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIEmbedderConfig returns the union data inside the EmbedderConfig as a OpenAIEmbedderConfig
func (t EmbedderConfig) AsOpenAIEmbedderConfig() (OpenAIEmbedderConfig, error) {
	var body OpenAIEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) FromOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided OpenAIEmbedderConfig
func (t *EmbedderConfig) MergeOpenAIEmbedderConfig(v OpenAIEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockEmbedderConfig returns the union data inside the EmbedderConfig as a BedrockEmbedderConfig
func (t EmbedderConfig) AsBedrockEmbedderConfig() (BedrockEmbedderConfig, error) {
	var body BedrockEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided BedrockEmbedderConfig
func (t *EmbedderConfig) FromBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided BedrockEmbedderConfig
func (t *EmbedderConfig) MergeBedrockEmbedderConfig(v BedrockEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereEmbedderConfig returns the union data inside the EmbedderConfig as a CohereEmbedderConfig
func (t EmbedderConfig) AsCohereEmbedderConfig() (CohereEmbedderConfig, error) {
	var body CohereEmbedderConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereEmbedderConfig overwrites any union data inside the EmbedderConfig as the provided CohereEmbedderConfig
func (t *EmbedderConfig) FromCohereEmbedderConfig(v CohereEmbedderConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereEmbedderConfig performs a merge with any union data inside the EmbedderConfig, using the provided CohereEmbedderConfig
func (t *EmbedderConfig) MergeCohereEmbedderConfig(v CohereEmbedderConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t EmbedderConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *EmbedderConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsFuzziness0 returns the union data inside the Fuzziness as a Fuzziness0
func (t Fuzziness) AsFuzziness0() (Fuzziness0, error) {
	var body Fuzziness0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness0 overwrites any union data inside the Fuzziness as the provided Fuzziness0
func (t *Fuzziness) FromFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness0 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness0
func (t *Fuzziness) MergeFuzziness0(v Fuzziness0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzziness1 returns the union data inside the Fuzziness as a Fuzziness1
func (t Fuzziness) AsFuzziness1() (Fuzziness1, error) {
	var body Fuzziness1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzziness1 overwrites any union data inside the Fuzziness as the provided Fuzziness1
func (t *Fuzziness) FromFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzziness1 performs a merge with any union data inside the Fuzziness, using the provided Fuzziness1
func (t *Fuzziness) MergeFuzziness1(v Fuzziness1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Fuzziness) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Fuzziness) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsGoogleGeneratorConfig returns the union data inside the GeneratorConfig as a GoogleGeneratorConfig
func (t GeneratorConfig) AsGoogleGeneratorConfig() (GoogleGeneratorConfig, error) {
	var body GoogleGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGoogleGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided GoogleGeneratorConfig
func (t *GeneratorConfig) FromGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGoogleGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided GoogleGeneratorConfig
func (t *GeneratorConfig) MergeGoogleGeneratorConfig(v GoogleGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVertexGeneratorConfig returns the union data inside the GeneratorConfig as a VertexGeneratorConfig
func (t GeneratorConfig) AsVertexGeneratorConfig() (VertexGeneratorConfig, error) {
	var body VertexGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVertexGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided VertexGeneratorConfig
func (t *GeneratorConfig) FromVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVertexGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided VertexGeneratorConfig
func (t *GeneratorConfig) MergeVertexGeneratorConfig(v VertexGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOllamaGeneratorConfig returns the union data inside the GeneratorConfig as a OllamaGeneratorConfig
func (t GeneratorConfig) AsOllamaGeneratorConfig() (OllamaGeneratorConfig, error) {
	var body OllamaGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OllamaGeneratorConfig
func (t *GeneratorConfig) FromOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OllamaGeneratorConfig
func (t *GeneratorConfig) MergeOllamaGeneratorConfig(v OllamaGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOpenAIGeneratorConfig returns the union data inside the GeneratorConfig as a OpenAIGeneratorConfig
func (t GeneratorConfig) AsOpenAIGeneratorConfig() (OpenAIGeneratorConfig, error) {
	var body OpenAIGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOpenAIGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) FromOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOpenAIGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided OpenAIGeneratorConfig
func (t *GeneratorConfig) MergeOpenAIGeneratorConfig(v OpenAIGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBedrockGeneratorConfig returns the union data inside the GeneratorConfig as a BedrockGeneratorConfig
func (t GeneratorConfig) AsBedrockGeneratorConfig() (BedrockGeneratorConfig, error) {
	var body BedrockGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBedrockGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided BedrockGeneratorConfig
func (t *GeneratorConfig) FromBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBedrockGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided BedrockGeneratorConfig
func (t *GeneratorConfig) MergeBedrockGeneratorConfig(v BedrockGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAnthropicGeneratorConfig returns the union data inside the GeneratorConfig as a AnthropicGeneratorConfig
func (t GeneratorConfig) AsAnthropicGeneratorConfig() (AnthropicGeneratorConfig, error) {
	var body AnthropicGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAnthropicGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) FromAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAnthropicGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided AnthropicGeneratorConfig
func (t *GeneratorConfig) MergeAnthropicGeneratorConfig(v AnthropicGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereGeneratorConfig returns the union data inside the GeneratorConfig as a CohereGeneratorConfig
func (t GeneratorConfig) AsCohereGeneratorConfig() (CohereGeneratorConfig, error) {
	var body CohereGeneratorConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereGeneratorConfig overwrites any union data inside the GeneratorConfig as the provided CohereGeneratorConfig
func (t *GeneratorConfig) FromCohereGeneratorConfig(v CohereGeneratorConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereGeneratorConfig performs a merge with any union data inside the GeneratorConfig, using the provided CohereGeneratorConfig
func (t *GeneratorConfig) MergeCohereGeneratorConfig(v CohereGeneratorConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t GeneratorConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *GeneratorConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Config returns the union data inside the IndexConfig as a BleveIndexV2Config
func (t IndexConfig) AsBleveIndexV2Config() (BleveIndexV2Config, error) {
	var body BleveIndexV2Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Config overwrites any union data inside the IndexConfig as the provided BleveIndexV2Config
func (t *IndexConfig) FromBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Config performs a merge with any union data inside the IndexConfig, using the provided BleveIndexV2Config
func (t *IndexConfig) MergeBleveIndexV2Config(v BleveIndexV2Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexConfig returns the union data inside the IndexConfig as a EmbeddingIndexConfig
func (t IndexConfig) AsEmbeddingIndexConfig() (EmbeddingIndexConfig, error) {
	var body EmbeddingIndexConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexConfig overwrites any union data inside the IndexConfig as the provided EmbeddingIndexConfig
func (t *IndexConfig) FromEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexConfig performs a merge with any union data inside the IndexConfig, using the provided EmbeddingIndexConfig
func (t *IndexConfig) MergeEmbeddingIndexConfig(v EmbeddingIndexConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Config returns the union data inside the IndexConfig as a GraphIndexV0Config
func (t IndexConfig) AsGraphIndexV0Config() (GraphIndexV0Config, error) {
	var body GraphIndexV0Config
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Config overwrites any union data inside the IndexConfig as the provided GraphIndexV0Config
func (t *IndexConfig) FromGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Config performs a merge with any union data inside the IndexConfig, using the provided GraphIndexV0Config
func (t *IndexConfig) MergeGraphIndexV0Config(v GraphIndexV0Config) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["description"], err = json.Marshal(t.Description)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'description': %w", err)
	}

	object["enrichments"], err = json.Marshal(t.Enrichments)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'enrichments': %w", err)
	}

	object["name"], err = json.Marshal(t.Name)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'name': %w", err)
	}

	object["type"], err = json.Marshal(t.Type)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'type': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *IndexConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["description"]; found {
		err = json.Unmarshal(raw, &t.Description)
		if err != nil {
			return fmt.Errorf("error reading 'description': %w", err)
		}
	}

	if raw, found := object["enrichments"]; found {
		err = json.Unmarshal(raw, &t.Enrichments)
		if err != nil {
			return fmt.Errorf("error reading 'enrichments': %w", err)
		}
	}

	if raw, found := object["name"]; found {
		err = json.Unmarshal(raw, &t.Name)
		if err != nil {
			return fmt.Errorf("error reading 'name': %w", err)
		}
	}

	if raw, found := object["type"]; found {
		err = json.Unmarshal(raw, &t.Type)
		if err != nil {
			return fmt.Errorf("error reading 'type': %w", err)
		}
	}

	return err
}

// AsBleveIndexV2Stats returns the union data inside the IndexStats as a BleveIndexV2Stats
func (t IndexStats) AsBleveIndexV2Stats() (BleveIndexV2Stats, error) {
	var body BleveIndexV2Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBleveIndexV2Stats overwrites any union data inside the IndexStats as the provided BleveIndexV2Stats
func (t *IndexStats) FromBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBleveIndexV2Stats performs a merge with any union data inside the IndexStats, using the provided BleveIndexV2Stats
func (t *IndexStats) MergeBleveIndexV2Stats(v BleveIndexV2Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsEmbeddingIndexStats returns the union data inside the IndexStats as a EmbeddingIndexStats
func (t IndexStats) AsEmbeddingIndexStats() (EmbeddingIndexStats, error) {
	var body EmbeddingIndexStats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromEmbeddingIndexStats overwrites any union data inside the IndexStats as the provided EmbeddingIndexStats
func (t *IndexStats) FromEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeEmbeddingIndexStats performs a merge with any union data inside the IndexStats, using the provided EmbeddingIndexStats
func (t *IndexStats) MergeEmbeddingIndexStats(v EmbeddingIndexStats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGraphIndexV0Stats returns the union data inside the IndexStats as a GraphIndexV0Stats
func (t IndexStats) AsGraphIndexV0Stats() (GraphIndexV0Stats, error) {
	var body GraphIndexV0Stats
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGraphIndexV0Stats overwrites any union data inside the IndexStats as the provided GraphIndexV0Stats
func (t *IndexStats) FromGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGraphIndexV0Stats performs a merge with any union data inside the IndexStats, using the provided GraphIndexV0Stats
func (t *IndexStats) MergeGraphIndexV0Stats(v GraphIndexV0Stats) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t IndexStats) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *IndexStats) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsTermQuery returns the union data inside the Query as a TermQuery
func (t Query) AsTermQuery() (TermQuery, error) {
	var body TermQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermQuery overwrites any union data inside the Query as the provided TermQuery
func (t *Query) FromTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermQuery performs a merge with any union data inside the Query, using the provided TermQuery
func (t *Query) MergeTermQuery(v TermQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchQuery returns the union data inside the Query as a MatchQuery
func (t Query) AsMatchQuery() (MatchQuery, error) {
	var body MatchQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchQuery overwrites any union data inside the Query as the provided MatchQuery
func (t *Query) FromMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchQuery performs a merge with any union data inside the Query, using the provided MatchQuery
func (t *Query) MergeMatchQuery(v MatchQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchPhraseQuery returns the union data inside the Query as a MatchPhraseQuery
func (t Query) AsMatchPhraseQuery() (MatchPhraseQuery, error) {
	var body MatchPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchPhraseQuery overwrites any union data inside the Query as the provided MatchPhraseQuery
func (t *Query) FromMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchPhraseQuery performs a merge with any union data inside the Query, using the provided MatchPhraseQuery
func (t *Query) MergeMatchPhraseQuery(v MatchPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPhraseQuery returns the union data inside the Query as a PhraseQuery
func (t Query) AsPhraseQuery() (PhraseQuery, error) {
	var body PhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPhraseQuery overwrites any union data inside the Query as the provided PhraseQuery
func (t *Query) FromPhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePhraseQuery performs a merge with any union data inside the Query, using the provided PhraseQuery
func (t *Query) MergePhraseQuery(v PhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMultiPhraseQuery returns the union data inside the Query as a MultiPhraseQuery
func (t Query) AsMultiPhraseQuery() (MultiPhraseQuery, error) {
	var body MultiPhraseQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMultiPhraseQuery overwrites any union data inside the Query as the provided MultiPhraseQuery
func (t *Query) FromMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMultiPhraseQuery performs a merge with any union data inside the Query, using the provided MultiPhraseQuery
func (t *Query) MergeMultiPhraseQuery(v MultiPhraseQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFuzzyQuery returns the union data inside the Query as a FuzzyQuery
func (t Query) AsFuzzyQuery() (FuzzyQuery, error) {
	var body FuzzyQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFuzzyQuery overwrites any union data inside the Query as the provided FuzzyQuery
func (t *Query) FromFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFuzzyQuery performs a merge with any union data inside the Query, using the provided FuzzyQuery
func (t *Query) MergeFuzzyQuery(v FuzzyQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPrefixQuery returns the union data inside the Query as a PrefixQuery
func (t Query) AsPrefixQuery() (PrefixQuery, error) {
	var body PrefixQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPrefixQuery overwrites any union data inside the Query as the provided PrefixQuery
func (t *Query) FromPrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePrefixQuery performs a merge with any union data inside the Query, using the provided PrefixQuery
func (t *Query) MergePrefixQuery(v PrefixQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsRegexpQuery returns the union data inside the Query as a RegexpQuery
func (t Query) AsRegexpQuery() (RegexpQuery, error) {
	var body RegexpQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromRegexpQuery overwrites any union data inside the Query as the provided RegexpQuery
func (t *Query) FromRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeRegexpQuery performs a merge with any union data inside the Query, using the provided RegexpQuery
func (t *Query) MergeRegexpQuery(v RegexpQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsWildcardQuery returns the union data inside the Query as a WildcardQuery
func (t Query) AsWildcardQuery() (WildcardQuery, error) {
	var body WildcardQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromWildcardQuery overwrites any union data inside the Query as the provided WildcardQuery
func (t *Query) FromWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeWildcardQuery performs a merge with any union data inside the Query, using the provided WildcardQuery
func (t *Query) MergeWildcardQuery(v WildcardQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsQueryStringQuery returns the union data inside the Query as a QueryStringQuery
func (t Query) AsQueryStringQuery() (QueryStringQuery, error) {
	var body QueryStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromQueryStringQuery overwrites any union data inside the Query as the provided QueryStringQuery
func (t *Query) FromQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeQueryStringQuery performs a merge with any union data inside the Query, using the provided QueryStringQuery
func (t *Query) MergeQueryStringQuery(v QueryStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsNumericRangeQuery returns the union data inside the Query as a NumericRangeQuery
func (t Query) AsNumericRangeQuery() (NumericRangeQuery, error) {
	var body NumericRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromNumericRangeQuery overwrites any union data inside the Query as the provided NumericRangeQuery
func (t *Query) FromNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeNumericRangeQuery performs a merge with any union data inside the Query, using the provided NumericRangeQuery
func (t *Query) MergeNumericRangeQuery(v NumericRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermRangeQuery returns the union data inside the Query as a TermRangeQuery
func (t Query) AsTermRangeQuery() (TermRangeQuery, error) {
	var body TermRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermRangeQuery overwrites any union data inside the Query as the provided TermRangeQuery
func (t *Query) FromTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermRangeQuery performs a merge with any union data inside the Query, using the provided TermRangeQuery
func (t *Query) MergeTermRangeQuery(v TermRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDateRangeStringQuery returns the union data inside the Query as a DateRangeStringQuery
func (t Query) AsDateRangeStringQuery() (DateRangeStringQuery, error) {
	var body DateRangeStringQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDateRangeStringQuery overwrites any union data inside the Query as the provided DateRangeStringQuery
func (t *Query) FromDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDateRangeStringQuery performs a merge with any union data inside the Query, using the provided DateRangeStringQuery
func (t *Query) MergeDateRangeStringQuery(v DateRangeStringQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBooleanQuery returns the union data inside the Query as a BooleanQuery
func (t Query) AsBooleanQuery() (BooleanQuery, error) {
	var body BooleanQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBooleanQuery overwrites any union data inside the Query as the provided BooleanQuery
func (t *Query) FromBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBooleanQuery performs a merge with any union data inside the Query, using the provided BooleanQuery
func (t *Query) MergeBooleanQuery(v BooleanQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsConjunctionQuery returns the union data inside the Query as a ConjunctionQuery
func (t Query) AsConjunctionQuery() (ConjunctionQuery, error) {
	var body ConjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromConjunctionQuery overwrites any union data inside the Query as the provided ConjunctionQuery
func (t *Query) FromConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeConjunctionQuery performs a merge with any union data inside the Query, using the provided ConjunctionQuery
func (t *Query) MergeConjunctionQuery(v ConjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDisjunctionQuery returns the union data inside the Query as a DisjunctionQuery
func (t Query) AsDisjunctionQuery() (DisjunctionQuery, error) {
	var body DisjunctionQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDisjunctionQuery overwrites any union data inside the Query as the provided DisjunctionQuery
func (t *Query) FromDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDisjunctionQuery performs a merge with any union data inside the Query, using the provided DisjunctionQuery
func (t *Query) MergeDisjunctionQuery(v DisjunctionQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchAllQuery returns the union data inside the Query as a MatchAllQuery
func (t Query) AsMatchAllQuery() (MatchAllQuery, error) {
	var body MatchAllQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchAllQuery overwrites any union data inside the Query as the provided MatchAllQuery
func (t *Query) FromMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchAllQuery performs a merge with any union data inside the Query, using the provided MatchAllQuery
func (t *Query) MergeMatchAllQuery(v MatchAllQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsMatchNoneQuery returns the union data inside the Query as a MatchNoneQuery
func (t Query) AsMatchNoneQuery() (MatchNoneQuery, error) {
	var body MatchNoneQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromMatchNoneQuery overwrites any union data inside the Query as the provided MatchNoneQuery
func (t *Query) FromMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeMatchNoneQuery performs a merge with any union data inside the Query, using the provided MatchNoneQuery
func (t *Query) MergeMatchNoneQuery(v MatchNoneQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDocIdQuery returns the union data inside the Query as a DocIdQuery
func (t Query) AsDocIdQuery() (DocIdQuery, error) {
	var body DocIdQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDocIdQuery overwrites any union data inside the Query as the provided DocIdQuery
func (t *Query) FromDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDocIdQuery performs a merge with any union data inside the Query, using the provided DocIdQuery
func (t *Query) MergeDocIdQuery(v DocIdQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBoolFieldQuery returns the union data inside the Query as a BoolFieldQuery
func (t Query) AsBoolFieldQuery() (BoolFieldQuery, error) {
	var body BoolFieldQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBoolFieldQuery overwrites any union data inside the Query as the provided BoolFieldQuery
func (t *Query) FromBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBoolFieldQuery performs a merge with any union data inside the Query, using the provided BoolFieldQuery
func (t *Query) MergeBoolFieldQuery(v BoolFieldQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsIPRangeQuery returns the union data inside the Query as a IPRangeQuery
func (t Query) AsIPRangeQuery() (IPRangeQuery, error) {
	var body IPRangeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromIPRangeQuery overwrites any union data inside the Query as the provided IPRangeQuery
func (t *Query) FromIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeIPRangeQuery performs a merge with any union data inside the Query, using the provided IPRangeQuery
func (t *Query) MergeIPRangeQuery(v IPRangeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingBoxQuery returns the union data inside the Query as a GeoBoundingBoxQuery
func (t Query) AsGeoBoundingBoxQuery() (GeoBoundingBoxQuery, error) {
	var body GeoBoundingBoxQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingBoxQuery overwrites any union data inside the Query as the provided GeoBoundingBoxQuery
func (t *Query) FromGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingBoxQuery performs a merge with any union data inside the Query, using the provided GeoBoundingBoxQuery
func (t *Query) MergeGeoBoundingBoxQuery(v GeoBoundingBoxQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoDistanceQuery returns the union data inside the Query as a GeoDistanceQuery
func (t Query) AsGeoDistanceQuery() (GeoDistanceQuery, error) {
	var body GeoDistanceQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoDistanceQuery overwrites any union data inside the Query as the provided GeoDistanceQuery
func (t *Query) FromGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoDistanceQuery performs a merge with any union data inside the Query, using the provided GeoDistanceQuery
func (t *Query) MergeGeoDistanceQuery(v GeoDistanceQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoBoundingPolygonQuery returns the union data inside the Query as a GeoBoundingPolygonQuery
func (t Query) AsGeoBoundingPolygonQuery() (GeoBoundingPolygonQuery, error) {
	var body GeoBoundingPolygonQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoBoundingPolygonQuery overwrites any union data inside the Query as the provided GeoBoundingPolygonQuery
func (t *Query) FromGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoBoundingPolygonQuery performs a merge with any union data inside the Query, using the provided GeoBoundingPolygonQuery
func (t *Query) MergeGeoBoundingPolygonQuery(v GeoBoundingPolygonQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGeoShapeQuery returns the union data inside the Query as a GeoShapeQuery
func (t Query) AsGeoShapeQuery() (GeoShapeQuery, error) {
	var body GeoShapeQuery
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGeoShapeQuery overwrites any union data inside the Query as the provided GeoShapeQuery
func (t *Query) FromGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGeoShapeQuery performs a merge with any union data inside the Query, using the provided GeoShapeQuery
func (t *Query) MergeGeoShapeQuery(v GeoShapeQuery) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Query) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Query) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsOllamaRerankerConfig returns the union data inside the RerankerConfig as a OllamaRerankerConfig
func (t RerankerConfig) AsOllamaRerankerConfig() (OllamaRerankerConfig, error) {
	var body OllamaRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOllamaRerankerConfig overwrites any union data inside the RerankerConfig as the provided OllamaRerankerConfig
func (t *RerankerConfig) FromOllamaRerankerConfig(v OllamaRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOllamaRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided OllamaRerankerConfig
func (t *RerankerConfig) MergeOllamaRerankerConfig(v OllamaRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTermiteRerankerConfig returns the union data inside the RerankerConfig as a TermiteRerankerConfig
func (t RerankerConfig) AsTermiteRerankerConfig() (TermiteRerankerConfig, error) {
	var body TermiteRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTermiteRerankerConfig overwrites any union data inside the RerankerConfig as the provided TermiteRerankerConfig
func (t *RerankerConfig) FromTermiteRerankerConfig(v TermiteRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTermiteRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided TermiteRerankerConfig
func (t *RerankerConfig) MergeTermiteRerankerConfig(v TermiteRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsCohereRerankerConfig returns the union data inside the RerankerConfig as a CohereRerankerConfig
func (t RerankerConfig) AsCohereRerankerConfig() (CohereRerankerConfig, error) {
	var body CohereRerankerConfig
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCohereRerankerConfig overwrites any union data inside the RerankerConfig as the provided CohereRerankerConfig
func (t *RerankerConfig) FromCohereRerankerConfig(v CohereRerankerConfig) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCohereRerankerConfig performs a merge with any union data inside the RerankerConfig, using the provided CohereRerankerConfig
func (t *RerankerConfig) MergeCohereRerankerConfig(v CohereRerankerConfig) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t RerankerConfig) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	if err != nil {
		return nil, err
	}
	object := make(map[string]json.RawMessage)
	if t.union != nil {
		err = json.Unmarshal(b, &object)
		if err != nil {
			return nil, err
		}
	}

	object["field"], err = json.Marshal(t.Field)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'field': %w", err)
	}

	object["provider"], err = json.Marshal(t.Provider)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'provider': %w", err)
	}

	object["template"], err = json.Marshal(t.Template)
	if err != nil {
		return nil, fmt.Errorf("error marshaling 'template': %w", err)
	}

	b, err = json.Marshal(object)
	return b, err
}

func (t *RerankerConfig) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	if err != nil {
		return err
	}
	object := make(map[string]json.RawMessage)
	err = json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["field"]; found {
		err = json.Unmarshal(raw, &t.Field)
		if err != nil {
			return fmt.Errorf("error reading 'field': %w", err)
		}
	}

	if raw, found := object["provider"]; found {
		err = json.Unmarshal(raw, &t.Provider)
		if err != nil {
			return fmt.Errorf("error reading 'provider': %w", err)
		}
	}

	if raw, found := object["template"]; found {
		err = json.Unmarshal(raw, &t.Template)
		if err != nil {
			return fmt.Errorf("error reading 'template': %w", err)
		}
	}

	return err
}

// RequestEditorFn  is the function signature for the RequestEditor callback function
type RequestEditorFn func(ctx context.Context, req *http.Request) error

// Doer performs HTTP requests.
//
// The standard http.Client implements this interface.
type HttpRequestDoer interface {
	Do(req *http.Request) (*http.Response, error)
}

// Client which conforms to the OpenAPI3 specification for this service.
type Client struct {
	// The endpoint of the server conforming to this interface, with scheme,
	// https://api.deepmap.com for example. This can contain a path relative
	// to the server, such as https://api.deepmap.com/dev-test, and all the
	// paths in the swagger spec will be appended to the server.
	Server string

	// Doer for performing requests, typically a *http.Client with any
	// customized settings, such as certificate chains.
	Client HttpRequestDoer

	// A list of callbacks for modifying requests which are generated before sending over
	// the network.
	RequestEditors []RequestEditorFn
}

// ClientOption allows setting custom parameters during construction
type ClientOption func(*Client) error

// Creates a new Client, with reasonable defaults
func NewClient(server string, opts ...ClientOption) (*Client, error) {
	// create a client with sane default values
	client := Client{
		Server: server,
	}
	// mutate client and add all optional params
	for _, o := range opts {
		if err := o(&client); err != nil {
			return nil, err
		}
	}
	// ensure the server URL always has a trailing slash
	if !strings.HasSuffix(client.Server, "/") {
		client.Server += "/"
	}
	// create httpClient, if not already present
	if client.Client == nil {
		client.Client = &http.Client{}
	}
	return &client, nil
}

// WithHTTPClient allows overriding the default Doer, which is
// automatically created using http.Client. This is useful for tests.
func WithHTTPClient(doer HttpRequestDoer) ClientOption {
	return func(c *Client) error {
		c.Client = doer
		return nil
	}
}

// WithRequestEditorFn allows setting up a callback function, which will be
// called right before sending the request. This can be used to mutate the request.
func WithRequestEditorFn(fn RequestEditorFn) ClientOption {
	return func(c *Client) error {
		c.RequestEditors = append(c.RequestEditors, fn)
		return nil
	}
}

// The interface specification for the client above.
type ClientInterface interface {
	// AnswerAgentWithBody request with any body
	AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// QueryBuilderAgentWithBody request with any body
	QueryBuilderAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	QueryBuilderAgent(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GlobalQueryWithBody request with any body
	GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RagQueryWithBody request with any body
	RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetStatus request
	GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListTables request
	ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropTable request
	DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetTable request
	GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateTableWithBody request with any body
	CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BackupTableWithBody request with any body
	BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// BatchWithBody request with any body
	BatchWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	Batch(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListIndexes request
	ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DropIndex request
	DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetIndex request
	GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateIndexWithBody request with any body
	CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LookupKey request
	LookupKey(ctx context.Context, tableName string, key string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// LinearMergeWithBody request with any body
	LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// QueryTableWithBody request with any body
	QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// TableRagQueryWithBody request with any body
	TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RestoreTableWithBody request with any body
	RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateSchemaWithBody request with any body
	UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListUsers request
	ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetCurrentUser request
	GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteUser request
	DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserByName request
	GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateUserWithBody request with any body
	CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateUserPasswordWithBody request with any body
	UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RemovePermissionFromUser request
	RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserPermissions request
	GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error)

	// AddPermissionToUserWithBody request with any body
	AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)
}

func (c *Client) AnswerAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AnswerAgent(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAnswerAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryBuilderAgentWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryBuilderAgentRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryBuilderAgent(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryBuilderAgentRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GlobalQuery(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGlobalQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQueryWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RagQuery(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRagQueryRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetStatus(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetStatusRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListTables(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListTablesRequest(c.Server, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetTable(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetTableRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateTable(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BackupTable(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBackupTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) BatchWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) Batch(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewBatchRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListIndexes(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListIndexesRequest(c.Server, tableName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DropIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDropIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetIndex(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetIndexRequest(c.Server, tableName, indexName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndexWithBody(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequestWithBody(c.Server, tableName, indexName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateIndex(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateIndexRequest(c.Server, tableName, indexName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LookupKey(ctx context.Context, tableName string, key string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLookupKeyRequest(c.Server, tableName, key)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMergeWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) LinearMerge(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewLinearMergeRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) QueryTable(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewQueryTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQueryWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) TableRagQuery(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewTableRagQueryRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTableWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RestoreTable(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRestoreTableRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchemaWithBody(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequestWithBody(c.Server, tableName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSchema(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSchemaRequest(c.Server, tableName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListUsers(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListUsersRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetCurrentUser(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetCurrentUserRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteUser(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteUserRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserByName(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserByNameRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateUser(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPasswordWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateUserPassword(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateUserPasswordRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RemovePermissionFromUser(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRemovePermissionFromUserRequest(c.Server, userName, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserPermissions(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserPermissionsRequest(c.Server, userName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUserWithBody(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequestWithBody(c.Server, userName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) AddPermissionToUser(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewAddPermissionToUserRequest(c.Server, userName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

// NewAnswerAgentRequest calls the generic AnswerAgent builder with application/json body
func NewAnswerAgentRequest(server string, body AnswerAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAnswerAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewAnswerAgentRequestWithBody generates requests for AnswerAgent with any type of body
func NewAnswerAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/answer")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewQueryBuilderAgentRequest calls the generic QueryBuilderAgent builder with application/json body
func NewQueryBuilderAgentRequest(server string, body QueryBuilderAgentJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewQueryBuilderAgentRequestWithBody(server, "application/json", bodyReader)
}

// NewQueryBuilderAgentRequestWithBody generates requests for QueryBuilderAgent with any type of body
func NewQueryBuilderAgentRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/agents/query-builder")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGlobalQueryRequest calls the generic GlobalQuery builder with application/json body
func NewGlobalQueryRequest(server string, body GlobalQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewGlobalQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewGlobalQueryRequestWithBody generates requests for GlobalQuery with any type of body
func NewGlobalQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/query")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRagQueryRequest calls the generic RagQuery builder with application/json body
func NewRagQueryRequest(server string, body RagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRagQueryRequestWithBody(server, "application/json", bodyReader)
}

// NewRagQueryRequestWithBody generates requests for RagQuery with any type of body
func NewRagQueryRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/rag")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetStatusRequest generates requests for GetStatus
func NewGetStatusRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/status")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListTablesRequest generates requests for ListTables
func NewListTablesRequest(server string, params *ListTablesParams) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "prefix", runtime.ParamLocationQuery, params.Prefix); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "pattern", runtime.ParamLocationQuery, params.Pattern); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropTableRequest generates requests for DropTable
func NewDropTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetTableRequest generates requests for GetTable
func NewGetTableRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateTableRequest calls the generic CreateTable builder with application/json body
func NewCreateTableRequest(server string, tableName string, body CreateTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewCreateTableRequestWithBody generates requests for CreateTable with any type of body
func NewCreateTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBackupTableRequest calls the generic BackupTable builder with application/json body
func NewBackupTableRequest(server string, tableName string, body BackupTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBackupTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBackupTableRequestWithBody generates requests for BackupTable with any type of body
func NewBackupTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/backup", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewBatchRequest calls the generic Batch builder with application/json body
func NewBatchRequest(server string, tableName string, body BatchJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewBatchRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewBatchRequestWithBody generates requests for Batch with any type of body
func NewBatchRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/batch", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListIndexesRequest generates requests for ListIndexes
func NewListIndexesRequest(server string, tableName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDropIndexRequest generates requests for DropIndex
func NewDropIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetIndexRequest generates requests for GetIndex
func NewGetIndexRequest(server string, tableName string, indexName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateIndexRequest calls the generic CreateIndex builder with application/json body
func NewCreateIndexRequest(server string, tableName string, indexName string, body CreateIndexJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateIndexRequestWithBody(server, tableName, indexName, "application/json", bodyReader)
}

// NewCreateIndexRequestWithBody generates requests for CreateIndex with any type of body
func NewCreateIndexRequestWithBody(server string, tableName string, indexName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "indexName", runtime.ParamLocationPath, indexName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/indexes/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewLookupKeyRequest generates requests for LookupKey
func NewLookupKeyRequest(server string, tableName string, key string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "key", runtime.ParamLocationPath, key)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/lookup/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewLinearMergeRequest calls the generic LinearMerge builder with application/json body
func NewLinearMergeRequest(server string, tableName string, body LinearMergeJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewLinearMergeRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewLinearMergeRequestWithBody generates requests for LinearMerge with any type of body
func NewLinearMergeRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/merge", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewQueryTableRequest calls the generic QueryTable builder with application/json body
func NewQueryTableRequest(server string, tableName string, body QueryTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewQueryTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewQueryTableRequestWithBody generates requests for QueryTable with any type of body
func NewQueryTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/query", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewTableRagQueryRequest calls the generic TableRagQuery builder with application/json body
func NewTableRagQueryRequest(server string, tableName string, body TableRagQueryJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewTableRagQueryRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewTableRagQueryRequestWithBody generates requests for TableRagQuery with any type of body
func NewTableRagQueryRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/rag", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRestoreTableRequest calls the generic RestoreTable builder with application/json body
func NewRestoreTableRequest(server string, tableName string, body RestoreTableJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRestoreTableRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewRestoreTableRequestWithBody generates requests for RestoreTable with any type of body
func NewRestoreTableRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/restore", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateSchemaRequest calls the generic UpdateSchema builder with application/json body
func NewUpdateSchemaRequest(server string, tableName string, body UpdateSchemaJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateSchemaRequestWithBody(server, tableName, "application/json", bodyReader)
}

// NewUpdateSchemaRequestWithBody generates requests for UpdateSchema with any type of body
func NewUpdateSchemaRequestWithBody(server string, tableName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "tableName", runtime.ParamLocationPath, tableName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/tables/%s/schema", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListUsersRequest generates requests for ListUsers
func NewListUsersRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetCurrentUserRequest generates requests for GetCurrentUser
func NewGetCurrentUserRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/me")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDeleteUserRequest generates requests for DeleteUser
func NewDeleteUserRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserByNameRequest generates requests for GetUserByName
func NewGetUserByNameRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateUserRequest calls the generic CreateUser builder with application/json body
func NewCreateUserRequest(server string, userName UserNamePathParameter, body CreateUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewCreateUserRequestWithBody generates requests for CreateUser with any type of body
func NewCreateUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUpdateUserPasswordRequest calls the generic UpdateUserPassword builder with application/json body
func NewUpdateUserPasswordRequest(server string, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateUserPasswordRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewUpdateUserPasswordRequestWithBody generates requests for UpdateUserPassword with any type of body
func NewUpdateUserPasswordRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/password", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewRemovePermissionFromUserRequest generates requests for RemovePermissionFromUser
func NewRemovePermissionFromUserRequest(server string, userName UserNamePathParameter, params *RemovePermissionFromUserParams) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resource", runtime.ParamLocationQuery, params.Resource); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "resourceType", runtime.ParamLocationQuery, params.ResourceType); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUserPermissionsRequest generates requests for GetUserPermissions
func NewGetUserPermissionsRequest(server string, userName UserNamePathParameter) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewAddPermissionToUserRequest calls the generic AddPermissionToUser builder with application/json body
func NewAddPermissionToUserRequest(server string, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewAddPermissionToUserRequestWithBody(server, userName, "application/json", bodyReader)
}

// NewAddPermissionToUserRequestWithBody generates requests for AddPermissionToUser with any type of body
func NewAddPermissionToUserRequestWithBody(server string, userName UserNamePathParameter, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "userName", runtime.ParamLocationPath, userName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/users/%s/permissions", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

func (c *Client) applyEditors(ctx context.Context, req *http.Request, additionalEditors []RequestEditorFn) error {
	for _, r := range c.RequestEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	for _, r := range additionalEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	return nil
}

// ClientWithResponses builds on ClientInterface to offer response payloads
type ClientWithResponses struct {
	ClientInterface
}

// NewClientWithResponses creates a new ClientWithResponses, which wraps
// Client with return type handling
func NewClientWithResponses(server string, opts ...ClientOption) (*ClientWithResponses, error) {
	client, err := NewClient(server, opts...)
	if err != nil {
		return nil, err
	}
	return &ClientWithResponses{client}, nil
}

// WithBaseURL overrides the baseURL.
func WithBaseURL(baseURL string) ClientOption {
	return func(c *Client) error {
		newBaseURL, err := url.Parse(baseURL)
		if err != nil {
			return err
		}
		c.Server = newBaseURL.String()
		return nil
	}
}

// ClientWithResponsesInterface is the interface specification for the client with responses above.
type ClientWithResponsesInterface interface {
	// AnswerAgentWithBodyWithResponse request with any body
	AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error)

	// QueryBuilderAgentWithBodyWithResponse request with any body
	QueryBuilderAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error)

	QueryBuilderAgentWithResponse(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error)

	// GlobalQueryWithBodyWithResponse request with any body
	GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error)

	// RagQueryWithBodyWithResponse request with any body
	RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error)

	// GetStatusWithResponse request
	GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error)

	// ListTablesWithResponse request
	ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error)

	// DropTableWithResponse request
	DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error)

	// GetTableWithResponse request
	GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error)

	// CreateTableWithBodyWithResponse request with any body
	CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error)

	// BackupTableWithBodyWithResponse request with any body
	BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error)

	// BatchWithBodyWithResponse request with any body
	BatchWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchResponse, error)

	BatchWithResponse(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchResponse, error)

	// ListIndexesWithResponse request
	ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error)

	// DropIndexWithResponse request
	DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error)

	// GetIndexWithResponse request
	GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error)

	// CreateIndexWithBodyWithResponse request with any body
	CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error)

	// LookupKeyWithResponse request
	LookupKeyWithResponse(ctx context.Context, tableName string, key string, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error)

	// LinearMergeWithBodyWithResponse request with any body
	LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error)

	// QueryTableWithBodyWithResponse request with any body
	QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error)

	// TableRagQueryWithBodyWithResponse request with any body
	TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error)

	// RestoreTableWithBodyWithResponse request with any body
	RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error)

	// UpdateSchemaWithBodyWithResponse request with any body
	UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error)

	// ListUsersWithResponse request
	ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error)

	// GetCurrentUserWithResponse request
	GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error)

	// DeleteUserWithResponse request
	DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error)

	// GetUserByNameWithResponse request
	GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error)

	// CreateUserWithBodyWithResponse request with any body
	CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error)

	// UpdateUserPasswordWithBodyWithResponse request with any body
	UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error)

	// RemovePermissionFromUserWithResponse request
	RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error)

	// GetUserPermissionsWithResponse request
	GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error)

	// AddPermissionToUserWithBodyWithResponse request with any body
	AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)

	AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error)
}

type AnswerAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *AnswerAgentResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AnswerAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AnswerAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type QueryBuilderAgentResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryBuilderResult
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r QueryBuilderAgentResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r QueryBuilderAgentResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GlobalQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GlobalQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GlobalQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetStatusResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ClusterStatus
	JSON401      *Error
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetStatusResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetStatusResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListTablesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]TableStatus
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListTablesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListTablesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *TableStatus
	JSON404      *NotFound
}

// Status returns HTTPResponse.Status
func (r GetTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
}

// Status returns HTTPResponse.Status
func (r CreateTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BackupTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *struct {
		Backup string `json:"backup,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON404 *NotFound
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BackupTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BackupTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type BatchResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *struct {
		// Deleted Number of documents successfully deleted
		Deleted int `json:"deleted,omitempty,omitzero"`

		// Failed List of failed operations with error details
		Failed []struct {
			// Error Error message for this failure
			Error string `json:"error,omitempty,omitzero"`

			// Id The document ID that failed
			Id string `json:"id,omitempty,omitzero"`
		} `json:"failed,omitempty,omitzero"`

		// Inserted Number of documents successfully inserted
		Inserted int `json:"inserted,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON404 *NotFound
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r BatchResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r BatchResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListIndexesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r ListIndexesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListIndexesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DropIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r DropIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DropIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IndexStatus
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r GetIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateIndexResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *BadRequest
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r CreateIndexResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateIndexResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LookupKeyResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *map[string]interface{}
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LookupKeyResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LookupKeyResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type LinearMergeResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *LinearMergeResult
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r LinearMergeResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r LinearMergeResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type QueryTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *QueryResponses
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r QueryTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r QueryTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type TableRagQueryResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *RAGResult
	JSON400      *Error
	JSON404      *NotFound
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r TableRagQueryResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r TableRagQueryResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RestoreTableResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON202      *struct {
		Restore string `json:"restore,omitempty,omitzero"`
	}
	JSON400 *BadRequest
	JSON500 *InternalServerError
}

// Status returns HTTPResponse.Status
func (r RestoreTableResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RestoreTableResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateSchemaResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Table
	JSON400      *BadRequest
	JSON404      *NotFound
	JSON500      *InternalServerError
}

// Status returns HTTPResponse.Status
func (r UpdateSchemaResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateSchemaResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListUsersResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]struct {
		Username string `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON403 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r ListUsersResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListUsersResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetCurrentUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *struct {
		Permissions []Permission `json:"permissions,omitempty,omitzero"`
		Username    string       `json:"username,omitempty,omitzero"`
	}
	JSON401 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r GetCurrentUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetCurrentUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserByNameResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *User
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserByNameResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserByNameResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *User
	JSON400      *Error
	JSON409      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateUserPasswordResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateUserPasswordResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateUserPasswordResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RemovePermissionFromUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RemovePermissionFromUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RemovePermissionFromUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserPermissionsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *[]Permission
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserPermissionsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserPermissionsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type AddPermissionToUserResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *SuccessMessage
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r AddPermissionToUserResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r AddPermissionToUserResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

// AnswerAgentWithBodyWithResponse request with arbitrary body returning *AnswerAgentResponse
func (c *ClientWithResponses) AnswerAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

func (c *ClientWithResponses) AnswerAgentWithResponse(ctx context.Context, body AnswerAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*AnswerAgentResponse, error) {
	rsp, err := c.AnswerAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAnswerAgentResponse(rsp)
}

// QueryBuilderAgentWithBodyWithResponse request with arbitrary body returning *QueryBuilderAgentResponse
func (c *ClientWithResponses) QueryBuilderAgentWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error) {
	rsp, err := c.QueryBuilderAgentWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryBuilderAgentResponse(rsp)
}

func (c *ClientWithResponses) QueryBuilderAgentWithResponse(ctx context.Context, body QueryBuilderAgentJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryBuilderAgentResponse, error) {
	rsp, err := c.QueryBuilderAgent(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryBuilderAgentResponse(rsp)
}

// GlobalQueryWithBodyWithResponse request with arbitrary body returning *GlobalQueryResponse
func (c *ClientWithResponses) GlobalQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

func (c *ClientWithResponses) GlobalQueryWithResponse(ctx context.Context, body GlobalQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*GlobalQueryResponse, error) {
	rsp, err := c.GlobalQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGlobalQueryResponse(rsp)
}

// RagQueryWithBodyWithResponse request with arbitrary body returning *RagQueryResponse
func (c *ClientWithResponses) RagQueryWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQueryWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

func (c *ClientWithResponses) RagQueryWithResponse(ctx context.Context, body RagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*RagQueryResponse, error) {
	rsp, err := c.RagQuery(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRagQueryResponse(rsp)
}

// GetStatusWithResponse request returning *GetStatusResponse
func (c *ClientWithResponses) GetStatusWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetStatusResponse, error) {
	rsp, err := c.GetStatus(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetStatusResponse(rsp)
}

// ListTablesWithResponse request returning *ListTablesResponse
func (c *ClientWithResponses) ListTablesWithResponse(ctx context.Context, params *ListTablesParams, reqEditors ...RequestEditorFn) (*ListTablesResponse, error) {
	rsp, err := c.ListTables(ctx, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListTablesResponse(rsp)
}

// DropTableWithResponse request returning *DropTableResponse
func (c *ClientWithResponses) DropTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*DropTableResponse, error) {
	rsp, err := c.DropTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropTableResponse(rsp)
}

// GetTableWithResponse request returning *GetTableResponse
func (c *ClientWithResponses) GetTableWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*GetTableResponse, error) {
	rsp, err := c.GetTable(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetTableResponse(rsp)
}

// CreateTableWithBodyWithResponse request with arbitrary body returning *CreateTableResponse
func (c *ClientWithResponses) CreateTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

func (c *ClientWithResponses) CreateTableWithResponse(ctx context.Context, tableName string, body CreateTableJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateTableResponse, error) {
	rsp, err := c.CreateTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateTableResponse(rsp)
}

// BackupTableWithBodyWithResponse request with arbitrary body returning *BackupTableResponse
func (c *ClientWithResponses) BackupTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

func (c *ClientWithResponses) BackupTableWithResponse(ctx context.Context, tableName string, body BackupTableJSONRequestBody, reqEditors ...RequestEditorFn) (*BackupTableResponse, error) {
	rsp, err := c.BackupTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBackupTableResponse(rsp)
}

// BatchWithBodyWithResponse request with arbitrary body returning *BatchResponse
func (c *ClientWithResponses) BatchWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*BatchResponse, error) {
	rsp, err := c.BatchWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchResponse(rsp)
}

func (c *ClientWithResponses) BatchWithResponse(ctx context.Context, tableName string, body BatchJSONRequestBody, reqEditors ...RequestEditorFn) (*BatchResponse, error) {
	rsp, err := c.Batch(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseBatchResponse(rsp)
}

// ListIndexesWithResponse request returning *ListIndexesResponse
func (c *ClientWithResponses) ListIndexesWithResponse(ctx context.Context, tableName string, reqEditors ...RequestEditorFn) (*ListIndexesResponse, error) {
	rsp, err := c.ListIndexes(ctx, tableName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListIndexesResponse(rsp)
}

// DropIndexWithResponse request returning *DropIndexResponse
func (c *ClientWithResponses) DropIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*DropIndexResponse, error) {
	rsp, err := c.DropIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDropIndexResponse(rsp)
}

// GetIndexWithResponse request returning *GetIndexResponse
func (c *ClientWithResponses) GetIndexWithResponse(ctx context.Context, tableName string, indexName string, reqEditors ...RequestEditorFn) (*GetIndexResponse, error) {
	rsp, err := c.GetIndex(ctx, tableName, indexName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetIndexResponse(rsp)
}

// CreateIndexWithBodyWithResponse request with arbitrary body returning *CreateIndexResponse
func (c *ClientWithResponses) CreateIndexWithBodyWithResponse(ctx context.Context, tableName string, indexName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndexWithBody(ctx, tableName, indexName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

func (c *ClientWithResponses) CreateIndexWithResponse(ctx context.Context, tableName string, indexName string, body CreateIndexJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateIndexResponse, error) {
	rsp, err := c.CreateIndex(ctx, tableName, indexName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateIndexResponse(rsp)
}

// LookupKeyWithResponse request returning *LookupKeyResponse
func (c *ClientWithResponses) LookupKeyWithResponse(ctx context.Context, tableName string, key string, reqEditors ...RequestEditorFn) (*LookupKeyResponse, error) {
	rsp, err := c.LookupKey(ctx, tableName, key, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLookupKeyResponse(rsp)
}

// LinearMergeWithBodyWithResponse request with arbitrary body returning *LinearMergeResponse
func (c *ClientWithResponses) LinearMergeWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMergeWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

func (c *ClientWithResponses) LinearMergeWithResponse(ctx context.Context, tableName string, body LinearMergeJSONRequestBody, reqEditors ...RequestEditorFn) (*LinearMergeResponse, error) {
	rsp, err := c.LinearMerge(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseLinearMergeResponse(rsp)
}

// QueryTableWithBodyWithResponse request with arbitrary body returning *QueryTableResponse
func (c *ClientWithResponses) QueryTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

func (c *ClientWithResponses) QueryTableWithResponse(ctx context.Context, tableName string, body QueryTableJSONRequestBody, reqEditors ...RequestEditorFn) (*QueryTableResponse, error) {
	rsp, err := c.QueryTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseQueryTableResponse(rsp)
}

// TableRagQueryWithBodyWithResponse request with arbitrary body returning *TableRagQueryResponse
func (c *ClientWithResponses) TableRagQueryWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQueryWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

func (c *ClientWithResponses) TableRagQueryWithResponse(ctx context.Context, tableName string, body TableRagQueryJSONRequestBody, reqEditors ...RequestEditorFn) (*TableRagQueryResponse, error) {
	rsp, err := c.TableRagQuery(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseTableRagQueryResponse(rsp)
}

// RestoreTableWithBodyWithResponse request with arbitrary body returning *RestoreTableResponse
func (c *ClientWithResponses) RestoreTableWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTableWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

func (c *ClientWithResponses) RestoreTableWithResponse(ctx context.Context, tableName string, body RestoreTableJSONRequestBody, reqEditors ...RequestEditorFn) (*RestoreTableResponse, error) {
	rsp, err := c.RestoreTable(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRestoreTableResponse(rsp)
}

// UpdateSchemaWithBodyWithResponse request with arbitrary body returning *UpdateSchemaResponse
func (c *ClientWithResponses) UpdateSchemaWithBodyWithResponse(ctx context.Context, tableName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchemaWithBody(ctx, tableName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

func (c *ClientWithResponses) UpdateSchemaWithResponse(ctx context.Context, tableName string, body UpdateSchemaJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSchemaResponse, error) {
	rsp, err := c.UpdateSchema(ctx, tableName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSchemaResponse(rsp)
}

// ListUsersWithResponse request returning *ListUsersResponse
func (c *ClientWithResponses) ListUsersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListUsersResponse, error) {
	rsp, err := c.ListUsers(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListUsersResponse(rsp)
}

// GetCurrentUserWithResponse request returning *GetCurrentUserResponse
func (c *ClientWithResponses) GetCurrentUserWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetCurrentUserResponse, error) {
	rsp, err := c.GetCurrentUser(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetCurrentUserResponse(rsp)
}

// DeleteUserWithResponse request returning *DeleteUserResponse
func (c *ClientWithResponses) DeleteUserWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*DeleteUserResponse, error) {
	rsp, err := c.DeleteUser(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteUserResponse(rsp)
}

// GetUserByNameWithResponse request returning *GetUserByNameResponse
func (c *ClientWithResponses) GetUserByNameWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserByNameResponse, error) {
	rsp, err := c.GetUserByName(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserByNameResponse(rsp)
}

// CreateUserWithBodyWithResponse request with arbitrary body returning *CreateUserResponse
func (c *ClientWithResponses) CreateUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

func (c *ClientWithResponses) CreateUserWithResponse(ctx context.Context, userName UserNamePathParameter, body CreateUserJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateUserResponse, error) {
	rsp, err := c.CreateUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateUserResponse(rsp)
}

// UpdateUserPasswordWithBodyWithResponse request with arbitrary body returning *UpdateUserPasswordResponse
func (c *ClientWithResponses) UpdateUserPasswordWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPasswordWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

func (c *ClientWithResponses) UpdateUserPasswordWithResponse(ctx context.Context, userName UserNamePathParameter, body UpdateUserPasswordJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateUserPasswordResponse, error) {
	rsp, err := c.UpdateUserPassword(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateUserPasswordResponse(rsp)
}

// RemovePermissionFromUserWithResponse request returning *RemovePermissionFromUserResponse
func (c *ClientWithResponses) RemovePermissionFromUserWithResponse(ctx context.Context, userName UserNamePathParameter, params *RemovePermissionFromUserParams, reqEditors ...RequestEditorFn) (*RemovePermissionFromUserResponse, error) {
	rsp, err := c.RemovePermissionFromUser(ctx, userName, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRemovePermissionFromUserResponse(rsp)
}

// GetUserPermissionsWithResponse request returning *GetUserPermissionsResponse
func (c *ClientWithResponses) GetUserPermissionsWithResponse(ctx context.Context, userName UserNamePathParameter, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error) {
	rsp, err := c.GetUserPermissions(ctx, userName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserPermissionsResponse(rsp)
}

// AddPermissionToUserWithBodyWithResponse request with arbitrary body returning *AddPermissionToUserResponse
func (c *ClientWithResponses) AddPermissionToUserWithBodyWithResponse(ctx context.Context, userName UserNamePathParameter, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUserWithBody(ctx, userName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

func (c *ClientWithResponses) AddPermissionToUserWithResponse(ctx context.Context, userName UserNamePathParameter, body AddPermissionToUserJSONRequestBody, reqEditors ...RequestEditorFn) (*AddPermissionToUserResponse, error) {
	rsp, err := c.AddPermissionToUser(ctx, userName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseAddPermissionToUserResponse(rsp)
}

// ParseAnswerAgentResponse parses an HTTP response from a AnswerAgentWithResponse call
func ParseAnswerAgentResponse(rsp *http.Response) (*AnswerAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AnswerAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest AnswerAgentResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseQueryBuilderAgentResponse parses an HTTP response from a QueryBuilderAgentWithResponse call
func ParseQueryBuilderAgentResponse(rsp *http.Response) (*QueryBuilderAgentResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &QueryBuilderAgentResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryBuilderResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGlobalQueryResponse parses an HTTP response from a GlobalQueryWithResponse call
func ParseGlobalQueryResponse(rsp *http.Response) (*GlobalQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GlobalQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRagQueryResponse parses an HTTP response from a RagQueryWithResponse call
func ParseRagQueryResponse(rsp *http.Response) (*RagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseGetStatusResponse parses an HTTP response from a GetStatusWithResponse call
func ParseGetStatusResponse(rsp *http.Response) (*GetStatusResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetStatusResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ClusterStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListTablesResponse parses an HTTP response from a ListTablesWithResponse call
func ParseListTablesResponse(rsp *http.Response) (*ListTablesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListTablesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropTableResponse parses an HTTP response from a DropTableWithResponse call
func ParseDropTableResponse(rsp *http.Response) (*DropTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetTableResponse parses an HTTP response from a GetTableWithResponse call
func ParseGetTableResponse(rsp *http.Response) (*GetTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest TableStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	}

	return response, nil
}

// ParseCreateTableResponse parses an HTTP response from a CreateTableWithResponse call
func ParseCreateTableResponse(rsp *http.Response) (*CreateTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	}

	return response, nil
}

// ParseBackupTableResponse parses an HTTP response from a BackupTableWithResponse call
func ParseBackupTableResponse(rsp *http.Response) (*BackupTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BackupTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest struct {
			Backup string `json:"backup,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseBatchResponse parses an HTTP response from a BatchWithResponse call
func ParseBatchResponse(rsp *http.Response) (*BatchResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &BatchResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest struct {
			// Deleted Number of documents successfully deleted
			Deleted int `json:"deleted,omitempty,omitzero"`

			// Failed List of failed operations with error details
			Failed []struct {
				// Error Error message for this failure
				Error string `json:"error,omitempty,omitzero"`

				// Id The document ID that failed
				Id string `json:"id,omitempty,omitzero"`
			} `json:"failed,omitempty,omitzero"`

			// Inserted Number of documents successfully inserted
			Inserted int `json:"inserted,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListIndexesResponse parses an HTTP response from a ListIndexesWithResponse call
func ParseListIndexesResponse(rsp *http.Response) (*ListIndexesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListIndexesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDropIndexResponse parses an HTTP response from a DropIndexWithResponse call
func ParseDropIndexResponse(rsp *http.Response) (*DropIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DropIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetIndexResponse parses an HTTP response from a GetIndexWithResponse call
func ParseGetIndexResponse(rsp *http.Response) (*GetIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IndexStatus
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateIndexResponse parses an HTTP response from a CreateIndexWithResponse call
func ParseCreateIndexResponse(rsp *http.Response) (*CreateIndexResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateIndexResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLookupKeyResponse parses an HTTP response from a LookupKeyWithResponse call
func ParseLookupKeyResponse(rsp *http.Response) (*LookupKeyResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LookupKeyResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest map[string]interface{}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseLinearMergeResponse parses an HTTP response from a LinearMergeWithResponse call
func ParseLinearMergeResponse(rsp *http.Response) (*LinearMergeResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &LinearMergeResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest LinearMergeResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseQueryTableResponse parses an HTTP response from a QueryTableWithResponse call
func ParseQueryTableResponse(rsp *http.Response) (*QueryTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &QueryTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest QueryResponses
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseTableRagQueryResponse parses an HTTP response from a TableRagQueryWithResponse call
func ParseTableRagQueryResponse(rsp *http.Response) (*TableRagQueryResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &TableRagQueryResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest RAGResult
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	case rsp.StatusCode == 200:
		// Content-type (text/event-stream) unsupported

	}

	return response, nil
}

// ParseRestoreTableResponse parses an HTTP response from a RestoreTableWithResponse call
func ParseRestoreTableResponse(rsp *http.Response) (*RestoreTableResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RestoreTableResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest struct {
			Restore string `json:"restore,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateSchemaResponse parses an HTTP response from a UpdateSchemaWithResponse call
func ParseUpdateSchemaResponse(rsp *http.Response) (*UpdateSchemaResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateSchemaResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Table
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalServerError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListUsersResponse parses an HTTP response from a ListUsersWithResponse call
func ParseListUsersResponse(rsp *http.Response) (*ListUsersResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListUsersResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []struct {
			Username string `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 403:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON403 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetCurrentUserResponse parses an HTTP response from a GetCurrentUserWithResponse call
func ParseGetCurrentUserResponse(rsp *http.Response) (*GetCurrentUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetCurrentUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest struct {
			Permissions []Permission `json:"permissions,omitempty,omitzero"`
			Username    string       `json:"username,omitempty,omitzero"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 401:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON401 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteUserResponse parses an HTTP response from a DeleteUserWithResponse call
func ParseDeleteUserResponse(rsp *http.Response) (*DeleteUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserByNameResponse parses an HTTP response from a GetUserByNameWithResponse call
func ParseGetUserByNameResponse(rsp *http.Response) (*GetUserByNameResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserByNameResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateUserResponse parses an HTTP response from a CreateUserWithResponse call
func ParseCreateUserResponse(rsp *http.Response) (*CreateUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest User
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 409:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON409 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateUserPasswordResponse parses an HTTP response from a UpdateUserPasswordWithResponse call
func ParseUpdateUserPasswordResponse(rsp *http.Response) (*UpdateUserPasswordResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateUserPasswordResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRemovePermissionFromUserResponse parses an HTTP response from a RemovePermissionFromUserWithResponse call
func ParseRemovePermissionFromUserResponse(rsp *http.Response) (*RemovePermissionFromUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RemovePermissionFromUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserPermissionsResponse parses an HTTP response from a GetUserPermissionsWithResponse call
func ParseGetUserPermissionsResponse(rsp *http.Response) (*GetUserPermissionsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserPermissionsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest []Permission
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseAddPermissionToUserResponse parses an HTTP response from a AddPermissionToUserWithResponse call
func ParseAddPermissionToUserResponse(rsp *http.Response) (*AddPermissionToUserResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &AddPermissionToUserResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest SuccessMessage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// Base64 encoded, gzipped, json marshaled Swagger object
var swaggerSpec = []string{

	"H4sIAAAAAAAC/+y96XIjObIu+CoYdl/TMiS1ZVZ1c6zstnKr1KlcdKSsrnusmUaBESCJUgQQBSAksWSa",
	"Z5gXmZeaJxmDO4BALBSpJft0263+UZ1iYHU4HA6H++e3vUTmhRRMGN0b3fYKqmjODFPw18+aqU80Z6fU",
	"LE79F/shZTpRvDBcit6o92XBSKmZEjRnw16/x+2PBTWLXr9nf+uNeqVrqdfvKfZbyRVLeyOjStbv6WTB",
	"cmpbZTc0LzJb/Fe5EKm0pc2ysD9oo7iY9+7u7mwDupBCMxjiK5qesd9Kpo39K5HCMAH/pEWR8YTaIe79",
	"qu04b6Ou/qzYrDfq/Wmvmv4eftV7b5WSCruqz/MVTYlynd31eyfC2Dln50xdMYW1vvkYfKdEQ6+EYcF+",
	"75M072Qp0m8/hDOmZakSRoQ0ZAZ92kKunm32WNBs6RaoULJgynD3VwL9ulWdSpkxKuzwjRas68tdYAE5",
	"/ZUlptfv3QzmcmB/HOhLXgwkjItmg0JyAfw5o5lmd/0wjDOmy8ysHAw3LIe/Z1Ll1PRGvVkmqamYT5T5",
	"lKm4Z1/muxe9aoBUKbqM5/LMDT+NFPqaqeM5EybaLnVyzJlgihrk4vs440df8LUUMz63I83pzQS47sZM",
	"jLxkQrfFxEd6w/MyJ0YamhEsRWiWyWuWkplURDGjOLtiKUllUuZMGOLaHI7FLwsmiGamHz5qQhUjhSoF",
	"S8m2bUabgaLi0jbHlTY7xEgy44Zcc7PggpgF12RapnNmG/xZs1mZQcdM6NLKF/Lhw0ffJcl4zl0fltHZ",
	"TcJYylKsqcmrt2dfcBL8d6awGW14DlttOBa9fiXPDvbt//q9nAtLgd7oICylXac5gx38W8mUW4o64Y7t",
	"+hM5I7bE0osgbWfHblhSGjYkVgbjZxj8Nc8yMmXEKCq0ZT9HYs1yKgxPiGZUJYuxoCIlhSzKjBqWEi6M",
	"JGbBQrkJliMzzrLUDoHRZIEdDeMZ/uO2x0XKbuzw/9Fj+ZSlKRfzCU9vel/7PaClpUO/Z+gURHyhZFom",
	"Rvfu+hvVfVlVVeyKs2vdu/var/bYfQz7n3a8Z5Xkzrk4wXoH7d0Lk2svgj0LtzQR1JSKZiSjYl7SeSC6",
	"tNROMqo1n3GWEktXnhdKXrE0JlTvlwU1wFSWzFOmDZnT3PJeRgsjC01KkTJF/ny4v7//P9sHIBx/VvTX",
	"ttmMgoB7AVzWOJxxnxlJXEXkg6U2LCeFknlh+oSCeCBOAnAp+jABaRZMEXnF1IJRy/nn5dQomlhWmSmZ",
	"k/a2tx2lVk3IuWCEXlGe2VULuypsvzc4aKhgx034rKs5ru2mb+ynF/XdtN+1m7RhxVrGiMTiOZS/6/es",
	"sJhooxgsS42+qLDU6ftWwPzOz9+SUMluFAWHjibbnikSR1i3zfu+hKf+DuFCG0Zhm/3H+edPxCs6FRfE",
	"x2KlR/3D8Ww/EuGVOPnaPDaax4E/HGmWfZ7BVl5PMlfL7t2GrEJOorZpN0MQv6RJhraw18h0bg6wh2xb",
	"w7EYCyve6i1MgmiDP4HBKBeaFIoNXOM0I4pRLYVdk20+IwwWKyVXnI4FcMiw3uoQVj9U2rGCleuoFa4J",
	"LY20nSY0y5akoFqzlBg5FnZHt3YSsd3AnrMj5KLkBmS5WchyvnCcXT+I753oOpZ+Xav8pVY3rBoyzMRx",
	"YFvYnTnmhU0OIt8dNCnxrPYQwet7XaPP3H2ts+a538L1wZ0yNQCiJqB+lI7OlsTRCiAHFrxgGRdsSN7a",
	"WWA1KsiCXrGxsOe7vBYkbBuybddpQbmwSxR+1jvAmbb2QBcsseQlqGzp4ViczAjFprkGXcEPjKV9wo29",
	"G2kYmpHFIGNXLIt6pJo4+dLFCjiZzcSYJVelkdWZ6GFc02jJ/itlImFrWwkl6y3MpNXyymJd/XeuXFz7",
	"bqX4el0bV51Hqm/E7k+tQZv0LNIUMSvIPknu6eHzFVM0y0hVhoCKGRhwe3+4bw+3g+H+zpC8lkLzlClN",
	"ptIsCJ3yzAoCI31x2GpWX+Aps9dMvGPpSCRm5FLI64ylc7hlty4VOerXoNR0nI3usoELCkesYhm7op2z",
	"O/OfUFSxrpE5VRG0KrsB4wk/YXyNo629FF0TWH3IVedbl4hDsreFNhxZ/joVr7FdDmTnQVmEuet7Nm69",
	"2x8brGeZJqfqMrVyyJGsqfRtcM+zmsld/9n59vHLuPmY/6W5cfNpeBk3qXiiNY/zcj5nGrTnThYKZ2pL",
	"6a+dnJsOqnMn3bNVIrHbLVBXnbUNbccpTXAielGLB+CMC5rZS2cl8jr0QFJqq2rZCpXiRXVkDLhHYNsS",
	"HcMvtZE5mZc8BT6yE3CjMFKwvr2zUJ4ROJ377rRfZqx2dXsF15iEaxQDhiULYbXAITkRSVam9nPKiKug",
	"yfWCKTsFYF4z7LrMga7RMdy2CgIMrpZ2s0qVMjUkH0tTggrKbpKs1PyKodjaCpW2hpsqatDhBy4uu+xZ",
	"TzEM4UVzghfNletSu47Gi1NxVoctuJORzSxbvl6U4pKph/FyJhOaEWyAJLYFy3ZO0vhbCNfhF6JKoauC",
	"KVcsMdmyMjYxoo1UdM6IsGxRKJkwrftjYUvI0hDcnMDcgrAbZ9j9Yu/OhoGBlydsSE6cBqm5ZSsy4zcs",
	"HWj+OxuLYH8aTKm9hYTRACMISRKaLOBCWt3hx2J392fN0Bp2vWBitLs7FgNyVgrYaHbvZWwAY05Zkckl",
	"bsptfU1VTnKZsh1b/r9kSVIptgwRjKUk2G32YBChZ5ooqTWQQPtq11QYAkIXDNmmtLq8ndwNN8tqhJ4S",
	"/l7cMdi8zAzHsdo9YKyChdvO969YWtrzIZHahAHAiD9/+vS/BjRJWOZO5EC9bTacD/skWUhxuZxIIW7s",
	"3Z4aNl/u1OZQMKW5NmCptJX3AhWgfzvjWILcop3UltS90cv9fs+uS0aLYMyxv3kGs1sQuLHX72lWULcF",
	"e5ZAdjdQNWcmqrl/15SKszLLJl4g0jTleEycRoW6TBrt/WEbGoD9Bix1zsSBE7ES6ZWVm95IWyimLUW2",
	"2RUTxN6688Isd/q+vLdN2t3BUmTVUTIzI6LL2YzfoO0MLIJpaHxLE0c4tEX6zujU9hXaLjUjo6TWElWM",
	"SJEt7Tc0gl6xxN68wlrZOxxsbZQjBC78YCtL3exNaRvBCx/J+CUjUym14WLed6bRnBYF/MlM0rBW3XYJ",
	"qpgRIgvTy5b9zlvNUSGJyG5kOFwtH4bjc0hOlaW80WCz1nAwBNaWM3LF1JJklnuqI9ceFPdbp5uceu+g",
	"P4XBVlZB1wCZMnPNGBhsNEtKE4anh+Q9ywpNcsrBlhOMhk6GoGCZylKkVHFWH3S3EbDaNtF4/Q5qKGe+",
	"LMEDBu2kRcaNiWTC1ngsxmOxBV9thbmixULvdJ7ujS1aI1nbUAuFo3V2pLNrCzMfEneu4Q6iPEezErID",
	"VZYuKNXt4bBuRVefnl/g59seE7bqP3r4BDCherKU5QQq9XuXbHktVWpnbeVLv7cwedbrW72ZKZ5Y6lLD",
	"DIcnX2+27Pcyq2JYjUKCqor/1AsKbYYNaatkchqpqhVNj4VZKFnwpKlsbHjMh/pBt7hi5PikOta3X2fU",
	"6nL2oMv0DpyYx6cn5JItyRWn5IIWfHLJlhf+UUSRi+NPX96ffT49eT05Pj2Z/PT2vy4IE1dcSQF2hyuq",
	"OJ1mzJ2+b1EykI/Qw2h3lyTQ5UBLIZgZvBi8HBzuH77c/+vhX8m24xkrP7GULEodyhwc7B+EL0eDl4MF",
	"5Zel/fTiYP/wEDt8IxPoZmFMoUd7e6lM9JB6QgwTme8xAb/u0akszQDb20MS7Nmde8XZdddh5nn7xf5f",
	"v+v3oEJv1Fs9n17zfMMxAB/lhV2PUrHeaH/4fes0c3Tv9j+oltWt1ZCczMAY5++KfTKjWabJlCaXVh61",
	"1qx7ybr2dTzx27XyuhKBQV47/dAb+KNOIuHliBkLrnvp2iaKPbaRj8nJG393riiFX4yEU9PLt9VdbFVf",
	"Wyy4tVN7Drx/oG05GS99xzY2SmaaKCpSmQumQeWI7pz2qj9AM9t7Pl8wRa5oVjJ7kFwyIktTlIbk0t7F",
	"oImnWc+MLCaXHUwoi8El0ZYAcG/w7jJD8tkqHxq3PFx5nSmY/BRUCng9BgN1OdXst9JyILBNN2fYIRTt",
	"IXwqk4yVumMQMYmOM7hogNyzd8qK9k+jS6my7q3589mHNu/ZXcpECqcA2fYGjD7edBzDW93R7mBncmfp",
	"Tm2EpeKdl8LY5oF7qMvk8Yoml2Wx0hliCp8nPO14CRb8t5IRnjJh7LCUO1s4ypayGJKf8UmIKDZjCmxs",
	"8NoLX52rA2i/RBaOia0O+nohpWaEkpxRe7uZlRkRNLeVqdW8wcagiT1Y967szUMKwkV43WmonW4KsPEG",
	"+weDg5eDq8Ou3Wcvvv6NoKESufurLxEOUT/P87IopDIa72GWwe0XJlI9svekD3ClnvGM4QV/RC7sH6O9",
	"vb2CmsWekXvY0oUtfZzT36Ug50cjcqGPRnt70zK5ZGZgSdAuj2+CjqSBNjTLCLgJWCrRvrtGuJfFnBlq",
	"fw7TCIyFdZoEhEHkSxzGHt7FBtij3is1U3oA9fYqEq9lyIqvIsJ386dJFhF7Nl3RTLKwF2OmTJ+kLGOG",
	"4STDa2HEW1ZeUnex9+4jThc5NjLnCTfL3V1Yst3dcyymF1Slu7sj8rlqxl6lKFTwVg4oFank2MRHzw3w",
	"WdtWwGcm5ZYqU3hHPBwUC6qZvfjn3JDtw9PXO2j5wQ5A5R9g+9eKG9u2HfB7eV1rB+ZLExzgtVSXMJGD",
	"IfnoV9t5ytEM6M00ef/hNbGaqTY0L9DWxzKWGE0SKVXKBd4CbNdjcTgkr6NfcShxr0SxRKq0b6Wt4Qkv",
	"qL16QTnCwQ9Pj8XRkBzPDI7C/0p0mSTMKiZxt0iPWg9j8WJITuPWnVOSczXRS5EslBSy1NnSeXrI7Crq",
	"/uWQnLFE4s1PygI9nph2jSRufdEIYxiBmzuFAcdjm1GelYrhQpwyBaJHJMzxDnKOW7Op5VCmR2Rc7u8f",
	"JeRlrklGDRPJ0pZ9HS1vvIQj8n8f7teLnsAscFKlLRTaPNonmiVSpLDy2gwSy1HbVktX8XR3cMQ/llRR",
	"YRjTbsDHWeYX1K2F1ebtEtmZkm3qN4e/gdpPyNNgB3rdpg0aD6BvEEPbgl2TjFEwGDJd5k2iQ0MnKcsL",
	"2Zgm2U5LdN5kjXWyy6/pjLl5vWKCzbjxszpzFi/BjN0PwfYHy0sVnkxcpPyKpyW4SKA/ma370R5KbDbj",
	"CbeDCdae7bJIYe/YrnFpUxj5sXeGuGdTLpiIhZEuqBMc2otxFGTYelngvweE3XCwsVh1Hr/ZqdgFM0z0",
	"iaVs+JIoRg1459XvKCgawbPMSuzR93+xGij8U2bphCaJLIWxEtiNwVaCzweHR3DrmLPe6Gjf3k4pz5xv",
	"8t9cD/bqVDk5/4dcCPIG3ZbpHPpMwL7tXphZzsu89/XO9f/i5Xehg8OXUQdUsBUdUMHIec7Bs7rVxVfw",
	"1a2rMWH6K30Kg6vlyRvnvGVrDMmbmpelYrm88l5fKMPgYIVT5JM0DA/8T1IMYNVsg2FtNM+YMNmS8LmQ",
	"iqW25BvbTWBmZxtnKZmymWVBzxDekG61IGA7W/cn33DBrPzBtmsj9Ib3ypLYsMSu54bNnuLuanzTbWJt",
	"kt5T1psbwQBK1ZQbRdUSrQr27mLQgL2UpXI6Db6zRHeCSl1oXkKLzrWt96ydV8wlW1qxZQldrtBtK1Mh",
	"rPgrpu3F2u7wxC39z3CWC10tvtVd4UHBjpppf8Mch+017tm/4FzLmN0O496OW1+SMTG3ZJnN4GCOF7So",
	"Dh4yIJeMFXaAuXsrpFN721pIZWqsoqWygiljNzyRYLND/60+0ZIkqHgXis34DTxVUkM06rb2zji3pKei",
	"Zc3/t5UTHQxklYgJPH+ue+U7X4rkAxS07Xh18z4Z06mTWsbiYlBkNKm4i/hzBp+AP0oxl29eDeAt1lWW",
	"CqXOl65GwZ3cbhnL7rlM+WwZvStXD280HeDXASpqino+bqq7RZGBkgWqADy3SieTQK2EQ9Oru9FAYot8",
	"rSGrNMMNP2GgM/kblDOcxm1s/5mLpE/+nJfZTp9QpGb8uSj1ok/+XJQZFLBXHInq2WuZ51KAYcfqRDi1",
	"E5Eo5tzqSwFvZdvgSd2HNw3dJ1dWksMe/BnWoVKTbXdJqRQT5g01+AL4kQrYk3ZgmmzTNN1DKUwsz/UJ",
	"yNC4NeGcH1DC+dXwh7p/87eiR1Us0RDctz2wAQaxYbdfv1eRBYrIojfqWerZ/UTNwv41RKfxfg+MQ73R",
	"wV3fF4wmFlfIqDZ/5+yapeCa6HsOm3JFt3ZV4mZgA4Zue1e8sM1t6rse2HwTB8p+7xVLlUwu34Ip/aFP",
	"4Me/nBPXQPU6Vn8Ch3ucLZcoBocEzbybaGQ9lYqcHH8kSmZOReg0essFU2wIHQ2YmGdcLwZXL/qEgiFg",
	"aLihYoCfDbsxg6vD0f59Bu1rPXRVE5nvTXEie/YmoQ3c1+clD1btgZPvLB26p4vYsu3t2N1DrBuxXUcQ",
	"2jZH8pZ6wKg2g4NeSyMDLWai+e+sZto96LLfQll4zUELYViSOAREFobntohZKFnOF0Vp1tqTmx35RQ+2",
	"4qZRuJsOW32ydd9itazCK8nZEeUw7zRJfXFsit8D5/oJOKeJMPCwEM2hVCvU0bn9VzER7HqSccHqL3cQ",
	"UdVcrF8WDEIljITHwwLuJlC3svhyUZQGo3OckhvWc7jew/8eQyZO/bHPYdGW734Qg/17in9oQhOrqLvT",
	"lfm9H+y6fTC79J0tr09ew4r3yUd7OaRZFFayWi5ED1MrXxEGVwej/T5Y9IZZRnN6NDgafL8/HXChjSoT",
	"4wo47hTyig4KJeHXbyVCOtzSnvpQ9OwbeWPaNvfLxhWffzMPv+mT0T/1Leh5XnOGz+ddfY9YsXeBE3t3",
	"/vthJVIa7M3yiRRZx5NsJBAt++Usl2o5ADccd5Vri7wHuLXeO9pzQ01H6HHK9eWk1HCNaj102PPTvVGB",
	"vcCyy3RpmK49OHFhvnvRXsPNnYSZDxJvxJDZn0nOtB0d4TOi7RSslp6l8AI2ZZWf7BPcwxWbljxLQ1hb",
	"54pVJNDEKcZgXglVH71wltUNzSbOt6uL5b0orO5szgIEdZ5zMTq5SMrsnb2c/KePAW3oblJm3eHr4A62",
	"TpV/BYXu+j24AHUYl5pvRba7ryvGyahYPcoHjSUz6yOMsCt79pTr234txa+lAOtvrd5EyLV133DdqqsX",
	"diM8vOaKJfbvaas072MCMpWLObKMP6FL96ibskQxqhkBA4b7N7pz+DAFnUjFtGVkWgVLB9ZNZTkF13JR",
	"ZhnGNKMbZut8ebU07IyK+Qo4ASuhVvinuPjmwzjY+bBtvAS/79dSoN2y7mwixQTlVYd/KJbHE1st/c1d",
	"WOW2Cm3jAmPpwPhAs2u61CNyDP8PruxQXLE5VWlmj2g5I7I0iczBMuK7H5EvvqwUhIolYl5UjlGusOE5",
	"k6WpFXfWGvyC9bQrbtWrCcSWd9QAJx34GCpZbcg5xOFU7PW/olA1APyjar7Ti63yt29bzfxDbcbFJb7c",
	"ViTF2MR6dJI9GZagWCdhIVshpfESrw0EqBjiid7/MLR19c5soSjcLxaBVeddcrDl51+FMEvBNghmdh7m",
	"9Xbu+uuiLdsxBmgfasCLBBPBOpJDS6e+eJMGoR0wGjWZpRT4CtwOhqUdUQx1M8ca73OD1OnBhRi8362+",
	"yW9QB2m7n1crchpNva3yt4bl1MRhtMdytKhUQ3Cu8N2bCds7D6Nc+eQSuvYzQuQM/xe62+S0gFvY50+f",
	"/pe7SWF0h1RYwr1poo3a8dDQyhUgzoicNyM1qn6nS7zmoQmWbFutygy46BPhOvRLD3ItCkEY3ROwgCPR",
	"TBhwNnL+GEtAYkAnhW3XrHb3dozSYMr+I3Sxt1OTc36poxLd9F8VPLyhDaIeqtwKIaOCZsvfXQQZnKb9",
	"sfAeG/Y3sIA5QYhR/34964gCuoI/qcfU684o/H+H0KyZVAmbBLQWu7Zrn29cYVCSPtoKVTvRBlqrDYbd",
	"9sQzAlzHJsVCUc0m+P4aqyFHq2MLaOTJiDAs0AoX85oRpXY5XovCUweAWG/686F/q2An2E2RUQ7/xDEC",
	"O2uuXZChEzzIz7U4t9UYWK091wnz0GJdWLbmbqv5jFHn0ASh0YnMpzhwmmVu8EwsrILrr2Z26rE0rabh",
	"3KrcdnM2arpKN1kdx18fbBS0/M+O7/VgPpMV+ECvM6rwJEZK4at+muLRDGbfzrhGsr0ocyoGitHU3gV2",
	"nnC/j7dS13tstF+qneLMHjhqeGa4KajA4GrPzujPBEabZ45RtqpOba/VkD6eaU+RbVDsfWAaHN6wzxtI",
	"KzWYF4cV85T1ULI0DCNm1unAtiQE3kDU0lPFeWhhBbN+dm9GabTsGBW310AIA+QK8OjAN/iUFUyk2l6S",
	"asMcERcRhA/7W4rBw/pWnyyWhTQLBng5AezCFok/bD2BylZJmExpcrlqtq+UBP87W2aOYVLVtP3m7GCR",
	"wEhck63Qy9bOk8b6yBNWl9P7kAXeMGhEs5TocjoIJddOK/UVYVrfFoAg2g4tedri2eY2iGhXg6TpvBdi",
	"KPB7RjOzWA2BsYDvYGwtgxx0YcSRGlyKSyGv7bmFFewASlH9O2VzRVOEeQNrQLeODM2eQ1/rwnEbcU+l",
	"WUycNGpP5kSkHN2ar50F15ZnlnB4vlSiLFK4/Rw7LLky5+Z3pmQFHrkIdLwfQigmuj2N0J7dLX3AcuEt",
	"3ngPhCh6gGHQBMLQYKy1RVrrXu+G2skU8BT5OMcIrLvKJ2JddODrz+/fnr19ZGhg47H8aLgfLF99crB/",
	"+IKkPNc7fVcQVICMi3lJMyh9z2une45PZL4XAlUwgr1uJoCX64knPEaDegN9rwr6a4+07ieB3fUeFtfn",
	"KB+C+l5TQWimAW5RMwM0r9N38zC+eF6x4bM9xcZrkQsbcaBeywLejvB933KMDKdrFGIeCZR2++4XL/ka",
	"2F32B9hbdtxdwqUjUrBzMdrkBXuHk3wtJo/jA+uvwZ2tt88MVQormuoje/vpTWso7+W17WdBRZo5TwlN",
	"Minm8CBF8QkopzfOdoLOoTFJP33+9LbX751/OT770utDH18fHxuGlHikR4Uj48roYpnn6Km3eXjxkwRI",
	"gh0O1KDISl2LJ/Zfqn/Swf4RvOc/VGwkC2oeEB9cG1OnmHhqQHBTcKyJBn6sDJkpdOZcTgomaGaWXXiF",
	"8AEZBPg3VHouP4T/voDk5kJuJGJWC5ZWey2CoyqbsIfQ29d5NrePP+KV/93jlR94FpwxABZ/3FGgoPI/",
	"V23EPrv1xp2+//xkbRHb6Xae7RjCv7hCWIHyTAqmrIK2iTh1ACw1j3/LAVZ/qX4B3abu63m/aO0m30by",
	"tWK41ZK2u/m2DieLibjPUyeX2gSMu8hvB8JQTalEOHpDtHXffcF4ynp4hnOd6KLSA7ZsBwztBls26QKN",
	"HZK3Vjpj8CNar34rKYC3UpGOhUegrLw/kCdLjOQH+ic041N8sgNQoUQCwJCh+vLf9+npQViLnaQltCiU",
	"pMmiA2VRM3WFMn+AXhlz++8Fny9qyKWzCAE0IPDRNFXgpBzhgXbxds2mct8bj8N4jzp2S9jxWPOUx7C7",
	"bmauuzU90d8rce3pmkvRRr5freiTeDtW7XZuSQjP/WLJuBJyo0bzlTaj+msJiUp5IYixkhD6aTQpSlVI",
	"zeoJP7zMiZ7AGM1JIrOMTqXqhNP4WTNlD3CAs8A9VV3vu5JroDLyAe6qDvGrwwThEl+sDh69b2nA47V6",
	"Su0MAkVnTsQRke6vmrPIkJzgKJydkKR8Bue7cWbyhBaIV81dINm7Ohwgw+m/+nj4MuQVGZC/I8peXKIi",
	"EM95RhWgPbr4uVymNKuV5jmdM71Hy5TLPaszSKud/JcsAcGdpmmFOuKrGRnCNpuTKKixeqRuRYhHCUfA",
	"xxRchXMmNFDx6C8vPDAZurN47YZm2cDql1leV2okhCPE2+VSiMnVPj7LgJkn9OMz/niYRijWJQREmU8w",
	"Yv6+oxhLWCJgNHzQQxHdhLyhhhKuEajC1mapBzZwVRFFVArQSyHw1YdpnPPf7ZH1Y8lTANTXDojzPIcz",
	"nBqqmdFkG5EZDvb3f7KbTO+MyMHgKET7D8hHlvIyjyrYooODj7700eBgPyr+AWEK682zqvjB/v8ZQQkA",
	"eoGbiuPlKbPLDjeLLGMZ1zmZlqby2wzAqMSh7wQSsJuCQaYTBBHhv6NMaXGTpQ5AURpJjtMUIRTOYRBA",
	"o7FwmLLah3ru7kphaejQUxRz0CRcit3dEBaZymtheM6G0GoeTQ1wUDGgM4A4+FlDliIcrVkophcySzXZ",
	"Dht+mmHsJvoCOJSNQA5N0hLEBMJD4vgQanZAPjGIz2/Rc+ZhUQYLRq+WAMKSSYpL8rPzjeU+b9nFXpgv",
	"u6ggoECP4fM5vl84SAnXv8dgHI3FxcXFlOrFWJx+Pv9C9ia+2b2rg6hdKBcAe5n4rWT2ek1rpPZBdBjt",
	"DQjACNPhwQh0A1mlX41kLCIC4auzYgEAAx4yLNP4pfRRaTBaVRbueAH8ndTqzVbQASuStxnVhicoKdwe",
	"O15FELItJMmpQBSPANZR8yD7jKwWIlWhjuctKAHOIwVVeIknUcY4TbYBxEGx3GqeGPvF4YjAfFkxPXfq",
	"gvWo4avfee3ZLBMdqA3nWLRbRwJxZw/olcoFF9xwmk0KmfGkE5YhaBgZ1wYPTqgCKBNc62D4MC7d4cZq",
	"9GloAGV5p9N30KsLqjVAa9YyIuqjRB2Z079pff0ZYDcDcUP5DvXCZ2XsTmcFOoGfkWDXOCt7XQv4+s4u",
	"WFCz6CPEGdon7Ak8ZUTm3BhEzclLbRC0ItSoRyxtkt2x4fjqZ9alUb6hkWt8A/ZYybz9iP2AbHmeZB23",
	"4Se025gddHLvzB6amqkiSdsZOTjWrblVBwCUjtQ8of1zmPmzXEc8SuykoEqjhtVxT0trYQ+2zsBBy7YN",
	"8itia6yu7S7EE9fgip0YXeWqKtpQZTarFIpuMuAucdaKZHkqjV17T77ygUW1PjMfynK/ebUaQSfDy+Qk",
	"fZaZ8rQ+xzXgPY1R2torxge3xfNwWjWdb2YQ6o2Q/6pMEC58Rmhl/nNeLw+48R533W1r7XXaMKsjdXPA",
	"92NyRTOeYtY5nCVJ7aR8YI/vdktXE/Sg6VyHyCguZkxVoGGqzFwCIzw07Fjd/atB465d8Dbt8h05hlbS",
	"PrlmfL4w6F0pnJufhxYPJsW2ZQ1hwibUdEZA4mnH0jkj11R7ULFa7NbKrfwAN02HTPiwRQr6CQwvtPGI",
	"pLDeFw3sZl3Ykpp992LARCKtCuDMm4HzLtkyJkhnDNoDIkIhjGTtILDYNxtEcAGpWf0sncG7IyBXJYBD",
	"CbBVzoQxMdLBWJVmIRVLJ9PluPcUF0FEQNqURe11wYEmPTuf4hZbQRj8uLeBR/aKM+KRToSOawPnuGbD",
	"aL8+fkPYeb0BI3I7FrJsuwGFopAXN52j/QnsA3A7h2DEz6WZS/BZhgLhPVXIFC7VXIzIiUhkXpVxmax8",
	"iak0ixF5Jc3CtoiNIa5dXKsWuIOj5QKg92vucA/mAUuTL8uCbf6KQklIkcj8Dmrna8oyeT3RLJtNMikL",
	"vTbNagQogBhfET0pJtixB5CxTT4lQj2nN5OY71cFCftnQJ+/mlV74hl5HxSurvG004TgU/c3H0/3bbIS",
	"lXCnDLBBVlxu9clWJSw7vKejDT6Jj8ZmDjgsEqE4I4xYAN+Oue2RGuDKO5mdoD7z+XhHK29XTR8LQ7Po",
	"pRh5Fh8/YyCHyCICRTbW00FH2ggXrO33+tBY2R+lnGdN/9l1sbJ/Z8qwmwdW+gwm9IdWKpg4PnlgpW60",
	"tHW1Oj2JnxIB7Jt6/hBgscpn2XepvSmnylmLb1uG5UWGifskQexI/jsjC3ldT8A/FokUVwzQNcE9pwvf",
	"inwJrZWakffg5zmlShO9FIbe4FO6f7q5oorLUhMfG0sWLCsqxCjfFjlHUHk0ku7unkNTu7ujuH03DTCW",
	"eneWRfj8qwZ/FgR12sFmXmPiMNtONWpAcKzlfYb8Xo5WsXWdfPnyIXjajMhLknNRelTF3d3X+Gpeb12x",
	"hIF7k8/ZUSFHhqyHDurZk+Q9ksS9MBwMye6uTlQ5fW/ybHeXDMgZIjEip+xh8I6hc7yPsRtI404Sezri",
	"msFJ+v7Lxw9jQQi5uLioqAS/3N6G9snC5BnmWhTm7s5XgP/3HWtygU9BOAB8t7mAzv0HOyT/ux2Zq3+c",
	"ppoIdo3waQhCPs0AkjBzgYfbRZ+k/KpPFgeDxXd9knHMu7UThoDuJRAlhtODdSpCWi98P4YcvJZ+h5Z+",
	"7Dcg3Fvv3oFw2VxX3iH+qqZX0uhPfEa22W8+pmTco4nhV2zc27m7O4Z/gpH19naPzxzlqkp/u2RLe7Ow",
	"6hPNoM45/hvPuriWe+A4sgPPWcopjP1HJn7i9ppkXCpF+OQ8I7jL/Z9Xz61uDVdOB6uXKvsBHmPfUEN/",
	"PjsJA68+2wN4CGUmpco6Cox7fvdFiLV7UGP4azEf9zrrQAYG/0bk8kG4SoVYVamZYqLdiWdWxycjz5Lx",
	"fwMNR9D2qFT4zDmC5vYKMf+/pnBH7Q+HQ2Tj+L+wOoRYseRB4iARyjmCIcO+BV69gEYvyIDglZf4Ky/o",
	"OD+fnQTg5Iuo+18LFvd/4Tn/wlJ5tLd3Qfbw3xr+GJBf2NT27xwXqic2xwGovAW4AN+aI6VtoJnLAyz8",
	"fs9ivg5b7PxoAPvGwDORh23eRgXUJ/ZoruglW17sBIJVz10+9PAUX+S4mFd02909Af8AK0nfyGuRSZqi",
	"a5mG0IttPoM0jywFT/foiAqEDS2dvnmnUSLfGC8b8VVjxpU2pLBzUEykTEG+BXRNCNWt1LTVz7xTiqm3",
	"47GMf+dZRl2pIHqQR1hSKitzvPOwn6efWYBJN/gmPV2GldO+rmbwKKjJtmaM1C9mZ95jc2fkxay7KCyk",
	"NuR6wQ3LuDbu46niV/aEPTlF0QvHZ+HTCp6fn70j1BiaXGrPeH6g+PQMwDc6OgYP9vc/vmqVdYg5ccGj",
	"/dAkrC8JvhjtRg/3X/yluOkDNw/cuns2OmdsFPxXETtkyCXmOKvpSX/y9BsMEgD6gWwbu7u4Db9IeJMf",
	"kLfwJ/IOF+TL58+fXLpusv1FXjIx+Kw4E3ZtPiOs+ydp/LvoCuladQEXmCFeaIJM6/7sgl8+UnXJ1A/w",
	"sgQWV2F+eLGuasqAhkz9MO6Nx6YuDx0r/gK5hjTM8H86LoTZck0onomJ6TfdsBwpUqb5XDg3x4Jq7cAB",
	"0GLsZJqR5MOHj1abI4SchJAMTXZ3j/YH3+3/D+e1D5lbnVNEnLoCrNTXC56xkCnSdgO+gR8+fIRmbXnF",
	"Fo5zaJKUiibLYZjlT2xJ3jHwIo9k8WucnVdKcd9ejC5gOpdsOQA/fVJQroK2AqjcDq0+h0Wx54nVZ/7x",
	"p6OvI0J5Hx/z+3nmVaQvdFpmVHmq2datDi9V7pxNPMV8L1W8ti374cNHUlClvSWotIJJGypScE2AGh8d",
	"ZTSuVFPhASL4vCGxUP0gr5kC72pImOtUybRMgPaXgHpDwf5MhSYZlLbjCTVCS++oNpj0BC7N2NQHBI/1",
	"8SfO1SLUAd+ZxKvIZEDecRcJUfcStlodRoKBTAgzQht5fLrGu+WCbE+lzHZG4FHzJ4f3DyYlWEW4xbv8",
	"rhd29S4iYWNUycIpixvugmxzYXZG4D/nnQl1QROfPdThnbtsC7HkCi2FLXlBttFIsTMigEFIQvJSNHE4",
	"nvFo66EtAfnL7bXqwu3qC19BV4eqjxDA6BJPIK8IGW4yZudhlHSbzpLFufCdO58+QghauUcEMgy8kXgG",
	"djM7fPLGGjx1CGGoQo/IofvBHq16RF683G9Jojc+C5wgZ8c/jnZ3gxyCJyn3NdpD4daERzXgOEBdMMpy",
	"58sGbYfzMOIVaN3FdqJLS3WCzLlZlFPQWY2UYoC9wr9d7R8lObEUDm6lnZVpVlwyfcnF3lxi5dqN1q2S",
	"v9YF2CpQ2iJaNk6TL7h8Vg3GIkNYUCvd31BT/5JSAx++0Lm2H/4EcTxVRTrXd3e3t/bYuLvrk9vbPVvA",
	"1hiL29vo0ueWyio/QRdxOo+dfWuQp8hatk9BcxxcZcgY1S6YkYVjYi+btvCp4gkbkT/f3hb2X9EQIv9R",
	"IBRoZ/cOIJCndcXpGFY0mKjT19V10PFg5aIW91rrzN70cAvd3b1a2sb9X+FuV10HE2rYXCp7JXQ5QeBK",
	"+P/9v/8POcW/vYIcVZ7KdBmNcnf3bRT88ncX/OKdNy9+fPvx5NNJFWI08HE1sJ/Q4keOT6Ds59O3n45X",
	"lkXzW1zw1fH528nPZx/81QauP1XR+JpwfHqiseqHD8cfjyfvP59/sdXQEOgTuNn67irkbjmQst8qsKOD",
	"gxdHL1w6rJPc3rfs7j9VDLqBnFRvg7O2213ek5hD+SrbVOTVvQ1WERxwBWYOhrVlsKftWG08YCGNBSSj",
	"CcEIXGAGn+oAQ7XCyrCLSdWXi/xywGfTZQFxErbYWFQ2vCiK0GGj+ex4Dr8lCoNw70jwHO+9eA0rcPoH",
	"Q4JecxHgL1520Pq3YBidUShuCwUtHGwlv0DOlEbgTjyZEbkl4x5epKHtTzT31+PeiPzDX5mTUAU/DofD",
	"r+TuohbUBsO9uLj4Vdveb624HfdgT9mmxr2Py5Cratzr42dv14ACQYparcL27EtFA7Ylb/FIGvfy5QSJ",
	"iZ7aMOL94UGf7A8P7X+O+sQO1Ba/G4t4s/2sGXkN+VZwg33kc4XGR3yoEgB97xPQW4Fr7/AumKDNf5hX",
	"qcGTPmYXLoHsxrnV4qUcalT8X8T838HFOJoQm17vGFNMFuHqHY9BzmbgVRqydc1DlE1HICDkgwi1B0cD",
	"ndMsa7jNF0xQDobvljW8Mw6wbdfuQJGcs5wL3uv34PZ/0+t79/y+77Afpe8IkecAPtkFtBBkSBx40X4N",
	"QmjFDXE/o/CNKuygOWOniVUl1sHYxSELmzw9VKMIDnT1EaBOamSwHcfBLwqyTz3eH2ZDGHkuBogkT54H",
	"Sb7f02WeU8V/Z49BLvRPJO1xtx8g0PTqxTdybV4YPSTnjJE1LxNotsWdVqX7rfnUvmdZJvuRMdlKXDKG",
	"XGOgNth/ULOg4vaWgTfq7e0nUMOc8vB/EHseUsXI7e2x1YPIktnxyywdPnptW26Ann2/rnyi9JvrDxT/",
	"J4Poe43gW0Ho+6EImXY51Ddfv6HYPxXP/61fqDoPhfWrts+xcKjiHrRqnW96E+mr6vQdTZj5HJw6G+xL",
	"DZtgYNXGj/yxW3cbAHalu7NLKPfQ3j5htZUd+sxVHX7k3aSovNifkRSu0QcRBGIwEGayfV4+A7VWj8kw",
	"lx9xs4xvTOUx5boatFtr81XgGUtDXsN79kPbZb6bkjJuK8DkQd5e8JLLmGHd+Evtwcksk9dl8bBI/egc",
	"nUEDg7IIod56iNnGqbegsSpgfiwSmmXkesGTBVz+MEw/WTBaMLU3Q5slKK7/ewTmt8lHZjIpPZLqEpzF",
	"Kjn5Dr5JuDRHtq4Kt0841zPIOtnl6vUghOeOxX08svNDw/07SFNdv/8Jkf/vyt9/54JpdJgUS+ejFU5M",
	"LszRYZcTWbUnaWlkx0b82oUjMvPd1RCBEcxiyggVxPVgb47g7yzHvaEf6PKZktGsEt6zmBj3tVVRDcGi",
	"ZvxmkrkY/E2IB8J6fW4eKNV1/Hegxj3O06594djE1e6htdDE9uBaYEt4aK0VmQo3yLeBqeceWrEbxu8p",
	"jnqhrW+QrOOe7Is/VsfKCm89dNDzl0pvYvQOZg3/u7HodMAj6/zv3IHhbd1QB94rcyp4UWY0imv+38BJ",
	"zyNHAwnAXJt6m2ukb/zhtfeNvPagToTpAlSxLHTNpuFByhkovZmHonPTP9Xh75l8/fx0rUZ5Ae3c3V0g",
	"iXVzuCSTc57ETg0KAvGWxFxLDzYIGH5u6n+4Ej7VlXDwjZ0Jq6XEJzPYGbhGWzpaJRTPfzgf/uF8+Ifz",
	"4R/Oh384H/7hfPiH8+Efzod/OB/+4Xz4UOdDO/TavQm1t2ieYRYtp7dXHkTPLJiO9k/fy1snzZ2UvPI3",
	"tOUI3QzRKTFUA6c83y/6Jg55enc3smWrCy78Hl1w7dfIe/HvgHESxn/yJvJ/jLqK2r+9/VMpIDXx3zKq",
	"jfOHxJ/g4dw3/mCfQHsNRFV2gor73Z0zlNgre/1DuAoCmp5C6D5bDgy0fqK2RSe87E/OhDGqqBl9HBDv",
	"4FkjUeio7VfpbheVe2XHoh9jnk4MxvY+mK2Ln7/UjYV/S7BTgTeHCVWMRv2fN85uUCw6CQp0OUVsVug0",
	"0kFKzdTEqU6gqRzWtRh8Pbb9nWYACUnjeTjA12Hk5PVa5rkUpOnrtbtrd8z2mc9XNzgu5zkqZT+GZ4Md",
	"q6q/Q6kRfAGannQJx02sncks3oS2/muw/9Qcb13eOwc95LYtcw0g1mM9lWI0Dief6k7GINMc2GM9HQ22",
	"WfGGbcknwWxDtloh6KySWBFASN+FzQHzwQtSl66m4luNM6YxbS9lNDE8CcT/ibEiClnWmIB3AEImYzdo",
	"ECFTlkl7R+EiRjkkiUPasCuaZIyqfuWAfMUceBHm/eWiiscdOBMmcQ/LHpBgrmjCZmWWLcm2qcU9j/0b",
	"9CVb/vA7U3Lcs5epOJH5F0CkDLVgTRRz+dvQOgy0cYatojoyS81Wp1+xt5Uq/cq8MIMXw4NOD7yOvCvx",
	"q8b9Tnkrkt481TGP+heAjZz0fmTylSxBH30lb57lXWoqjZH5RHXj4fwjk6JPMmq+xu+3azHSHpKnf/XD",
	"mJHFJGOz/45hNZ/E/Ega9Op+JQtrdCqz5fyZkO5Wk6nAXiZg+tncF+NHJk9tjbXIIY32V8z5Dbc3pYQ9",
	"F6wfNFb3ZDrYv8wfhovoAVz/+zkojCSa3ApK4qq0KJhRs+EQM7kxkmFX/+cLWnTC0/3IJNgItC3gbl/O",
	"qR+MGHA04StgLNfRn7OJKiNVyoU9CKKFq5yAHGrZmodqBMSJ2/p6z5R+ZDJnpos5FctaPj/ggKft/RKT",
	"csKlv4dJtLnolM7aE27NtkMCt9C/4Nd+NZj75vKNRco8ItUmkwmkbU4qNNQ5mS7YnQ3zD4UAHrL9Ixy4",
	"O49NYdkMFHpQLiI87KMIgP39gyiJ5dH+94eYxLI7+xDlwzlMZJiyqz3XGC042lMrN/S69hOSCPWWslS2",
	"/ABBA2Nw//3vDyOtqGOYdRXJaS0PS1jkF+G+hEV18m6esKgRMeAdqmBa7ZFU1mzn4VMxg4tI2f7+u7/0",
	"ycHLo+8gPgRWRrFE5jkTKUt3upMXrT5Aovm/zmSZkgC+7iHCSj1ImDCKZgdbO0MSUL4sC6NHCzk+6RPv",
	"9ItxabAMlqLdWZzauZRWLO39yZQ2SYS5ouGOrHXSbugJTzcgkitMTt6Q7RUT7weQ9zqldjopUqqsu9uf",
	"zz742UZsGkD5Q+9g4tPB7MUbCZ3q6fRKxXuPz73Z7fz0MIG3KvemE4LrBNXh8OVgllG9iDOmRd8KJcPf",
	"R8N9+/djJBdmAO3wMn2IOOla7ufbj6uSpD0l1+TGCdCaq7F2w0bLHu/YMLdmg1v13wolo1/cwiIRWhs+",
	"HtRzbfZOaj9HqsnDtQkvD585h+TzZIF8Wt7LRwq95xRlihYLCGb6+/4DfNttrcnVvgth6oRPZekcE+l3",
	"7MEPLn1FgMPUIaSXq7rnod7U37yBAtsFDE9vJoBd6TMnYmrrDSQEgmLWsidu75MfSCnwcSrded6goHhV",
	"QpBZI5DM3sggDUvHiqxZjFVpvNYGOrXyd72WpTB1CsUQp62J/UuEpQX80k2QUF0sGND3W8eCwbJ/kik7",
	"Zxkou6tx/BeYjVxDQQLpHPYcADnGsAWm8LbzFk9csmUHFd7eFBlPuAkpZgC3GMpuDFm7+YLA9tlkB+Kk",
	"qhkHkOrwxJcSBbFI+inBgrabyYxnZr2ftV2nd1gSpK3tewLl27DAbog4fqqShR+rP/6pxhkCKPe49+cq",
	"3ZorOO6RAZSchbx29ZZcRcjk5n4agiyYWPUjVHeXqMYogJoBEhsRBcRTImofC28OOyDYRJqsn2TU6U4V",
	"Zy8x3pslpWHOpzeQaK82244tgK8hXTHdPFn4t5KQJRbJFCduePb9gBAdbFJ10g5yZ8aOraylpa12e2sT",
	"PDzg3A9ihZz0D2kg6H1QVci2bdn4aZ17nm33DNwRJ4vchoxOU1Ydf7aHp2Q2AMVuvck9sOkploeakG6v",
	"I9c7fgAwFO0cv/AXx78NOPB703RhzXPDiidwGbLzhGYcIuBWsL/73OT/+uC3WV6YJfmB0Czb+RY7Ao62",
	"Knx77arUjs+QvOMpDSw3sAUHfrAa6Cr7dsTaX59DRJ4GXm0ynLucxHLBKHrFlKYZvMMX1CxmHN62OvIe",
	"zKXiZpGv2oChALBGWV3MCzqHjN32iury3Nj73tZTNmTobFJtzc0T0jRIETS5ag5PSE6TsrTEF3q2Cl/A",
	"xcqEck6P2Q6rsfMUWZnGiUDW3Y2qrCEOwn/V5QyVGkDuCdezb3nWgZ/86mMGsvRFmCLPRbzL+2ApYEyW",
	"ve0mIduXA72QyjBtBvBl5yk6pr2GpqzAYM9uvbfarFjwib15nWADPdtrhJ1Eflzvq1L0+M7/WWlJulKR",
	"fLMUJI+9R+BYJrnVotbrAotfoPhHW/p51O4KCaMpyJAvIGNcpH23Tg9Ir8n0ajXIFYCQl5oywZneeaAe",
	"9NG29QQRtFJq28mirN50REBCrPgJluPRg1ohD92gUDJ54vlD/DEEfArhjJQd8hOd+PAyBh7SmNsrDmhf",
	"YzLpjXqQT/pNGSAMHmTbWW/VeQYjwfNphDjmZ1EGv3Tmh7O/AuhH5305cnZz4t7+JKxMmUplaeSPPTik",
	"e/3e5aT2C9yo3b3nCQm8mnunw2UFrFBc1CZSLWUzZWXn4eodm5y1w94rGrfVh7NC7N/UuEP53I+hyHOe",
	"L7HxenNt+F0tb8s2n5GWvQFcjXeeoBSvMBq8xgyYLuuXJtvXCyZIzdIQun58WqkHaH9db5dv6qkbH29D",
	"6GK/n9gSrMmgz0YsCOH4XHtWfHY12/a3ypTz1pu4Nx3UuiPlSavSkJF2EZ4gGk9OAfHqWRysEp52g0+t",
	"8rxqZqy29bue3xoYnWvzForwvrMZTMurjF0xfEg63BCRpBM/dF2ljmfEu68PSiUcUsd2ZBRGix8klDSa",
	"FKUqpO5MrM2E4sliheE0PDqGQs5h3khwtYeTsTKpBtxYzBQ8JG+rxom3O0IGYpYSamCgBuIALM2z2pP8",
	"P3qa5VQYnkwAeBWOVowmsmzx7Hu+23z6KfJD8Gy0osf7VxsWulOvgY5dIyv5fbMXzSfxOnbxMFbfrE77",
	"afbu3omWuisVo9/wa6lcvWbrBVXpRIcmVz3irm3Sz7M96KrxTRtpZeaH0YaWGqNeSagVyuvCJeyMeTaO",
	"0Kheya72e/0evH3Bv/xzQKd3709siciRXUc0AXBFH3fLUnz/5Rp82Zg27SckJfMVQQ/d50KLAh+4YFR9",
	"ZGrOTumcVUzT3h6lu4BnUIXktg6CLwS4Q/eCqMsEAod7I3KcZeAgqVI46qcxZjZLiSsJwUBYt6DKAODL",
	"KAKWINrIokBRB4tKprIUKVXLPkkyDkALC3ivV8yoJfpzCLs2Sam0VNg0vP/bht9Rey1DPFOZJKVSLO0T",
	"IcNIVw0wWn73Ae4gMOJev4V5Wq1HROYzt5YdR0RE10BSEEd6KSBsWSNUiR8m6EwVwjkkftZDiPZDvjGS",
	"XDJWkGOAWLALYFtyKCOiqhqA1h3oumvL+QG+l9eEG3It1WXAxj9nIu0cDmD5N8YEcELnmKQAUTB1qGQW",
	"1KUWCJkAgEkAb8fVQcBM7acR8ZPdmZdh40BbAHI11ZYnqgG5Jl8MycnsPmYqNYv5xsWJ3xi/A5Egvxyf",
	"fTr5BEHPn6Qhms6YRxgCZhKmWj/nXCSvmMpoUdhVDAPWXRCaqVpOVCnWozCezCDsve8eyDS5ttO/hm0A",
	"2oElGmJ7ydKQnAJQSLLwPSOfAA4l7FsI/6WGIY9M2YJecYhxnGHcf55ziEi0ZV8vWHLpUEL9clzzLENf",
	"mVxesTQE61Xr4+gMcZdj4bMF+4uY9kOecEBUUXRJ4KLmKAJXNKRY0G0cYdpIkxnVZgJbKe10Mzx5Y4UZ",
	"JIfH8bv3RcWuANoNd6Fb9aGdyzsAm3G/jCAWEp8fcZeTcW/cs+XOy6m2hUQorLF0ja9qnXkUBlvd+9gg",
	"eANQzI40YvIImGEsIG4GgTu1FcZcVFIjo3YOdj9rZnSDcj0XGTna3z/qzjgNq/qwO/5HWjgzF+x7cvIG",
	"H3Ddn3jsjMjtuOd/m/B0cgDJJYbD4V2f1L8chi93yDFw2oMWPMKo1mWlDjtplLEbnkg4hB3I3XSJQgBP",
	"ClgjlCvAsY6Y4GUEEhKbAVDaEPQqhebauNu51dwBcwdfHmmWuYsr7HRtFV0Er9gJK+RwEOiVtLxdvcid",
	"vEHkOm+XRgm3pd1BCZlLAFZUzWjSZP7baA0P7J+oefc+0MLIAgQLT1hv9Ne//nX417+i360rfhgV/ygx",
	"MtaVPmwVPooK/8SWU0lVWpX/Hsp3anRLkUzgPrJOqztfiuQDFGwqdZ4Nv96vu6zE0EaJ0mXQRqHlpaRU",
	"bcm5zWc12bOzwicxCK0uMeNOuGumooa7emt2NiSfRebz5rS/Dx+QxL3fmwHE9cZRnU1E7I4WL9kSscDX",
	"tRU0XqykJzqhQnStSdNaDjvSlUaJ6RSAtASJi/LQvwR1uMw7qPq2RTcItPrbLu7ncW+lgjDu2c+pWoLn",
	"wcCqjO48JTlN2bjXmbw/EvybHERe6UcRsA1+dw01pLMbeysv7uN1V4BMWUJLzQI2woLqhZNAKdkuBU4p",
	"7Wb3za5p3deK6O3mKc8yd32HpX7fZLnAEnZnl0UK+YC298kGW7oZUelvk6HPsOd7FdHrq9wlreC58DjL",
	"nsUmCKs1oVmMce+7arrfh6IrR/VJCvaMwxJSsE3HBWVXDux0oaheNTQHQ9JtG/3vhdXGuRUw+vUG2lrp",
	"lbT4N6XCPfkRXI4Rd6GWCoAs0s7788Nxyrto3E1cK6TOjaKGzZf1ACulZq2YKihudX4o7659+RRR7mou",
	"zfZuGiyvzufZ6nqV4Qh/HI6FUrMROWMJt8oozcgZFZfkXQmhqAPXPrNnoVTMg1erqriyxS1FyoyOhdLQ",
	"WIbOyue2TtWWsHTL+O9Va9MlybnYy+mNB2+j5JqLVF7DaEPn1/5NEeuNhdUp7LUWbzfNWVlJ25mWz1bT",
	"NVMKkllp+1/faCcXAKbOvTLhv5fh22lMNtfQ7kcOgYa7uDdy4FnlS4def05navpjIi+F1Hr4tl0onnPL",
	"PV1O67bNCe7H+9z37D3JlXr8Y6br7Te/2JvfRMEeX/kczGJSbMMVzeO6ax+PEHf2+EfoJzhC1TILtVjb",
	"23pbAX8rn/F9GdCv1g4CTCnR880Km/K37b7rRaeT7SNSfWNRABcwza/YJKfA8aLMMjq1F3BkvLbxKaqC",
	"2XDWV3Ftt500VlSNoGS4eFTNuzVkra7UVXqOB+TFaj87ubQ2aw5qLNde8693/R7m4ngc1IdLlbsC3gPx",
	"s+OMjVJZMXhFkyUcgz6hZ6nZEAJkAQikVFkMAlLLzsvEFbmiamUsvZA5TxAYAUOqtr//7i8I89En+c2U",
	"OtSEAZrxtg/2D1/4zzTLBjkXPMvJ9tFfXtwHDoKwYQBviXLufyY/hHl2pyNtjqwBg+ZxyCB+uNedabgN",
	"ARLFr98Xou6WqTM8vTmurT7ZahGqGY/eMZnV8A9e8Vsxqf79wdJu7LVg6U40k4hPVkKZVDNYOZhnisLu",
	"znDzsG11T24WVyLgSMM8AJWYCx+aeN9uW7V/oNmj4dHo+/1pn/x2zcTh8OXo+8Npn6SMFZqxy4E6wK85",
	"twp7Nvp+2rf1rujo6MV07X7J+FRRtex4o/nmEA+P3SIxUez2iMhi/wyESWTK1OjoaNrcLnEDf8At/LPh",
	"FrokyHNv9DOIknrk8amgcu347D2jpLe9hS4ejdTzjakIqb0eqYRA3cdijH0+ffvpeD3GmEtpol1vccaP",
	"49MT3dRcVgrY7qzkES7Zwcuj77xG0irstJZ12GVFRo1dmCGimoLcBfAfyGa1CXqZvhwMh8Ne/1HZ1B+E",
	"LORW716gsvoaPQKorONE+Qyo8BE6mWenio+2AX7q49kHhFoPJUOWBoAOCzhlI3L48rs+eXlw2CdWr2xA",
	"mm2MQLSS1Gu2PhJyNWrYynY3U90AWqrgEU+tVd2qpa1UNwdxDyc3FtjSAKrmUz42Fv3V8fnbiW10M52u",
	"c5TPKqQeq9MhMe7R6TqxwRAzuQYJhj/BVaVP5FGfyBfwxwNlweOAwBrbtRPzFd7TRLKc2B4z09HSKX5A",
	"4kBWi1CJbFtVxnLHwzSawWE3Iuw/CTUsYFs/eJNWQGHYxlb1T1hW+7db4RYsWOi1y7av7S3gIWvg6zzr",
	"Evzr6Lb/ampph3R8Pll16iJW2qBRm8NQPzn8o9+r3paeBODTdX4rTE3WAjUi25gkbuCyyn0TDAuEnapi",
	"kZ8rDuwJhu6wWq1V99kV1hn7H9szupa1yfsAcgKkx5Na6ISl3rz+v9xSvuMijbyaGx5Y3xgmIgBHfVu8",
	"iMvaIXpQy6t+f2L1R2Mz+L72o85ePmdfz89ITdyD52u32riNwAT0LPUitUuiPn2nNw7HCunuubt8IACD",
	"3XgNEIaa5xLSLMzk63Ns824/ywAb8M+I/4fOJjNZivRJxzW+h0wMz9lks8wN/14HzdO56ansEjVXu4NY",
	"KbGQhW5dQo4DupPHmCAOZAL8vX29ETl3SABYZrokC1lgikCyPVWMpmYxwPSwLuUd4XMB/i5IFcxkXknB",
	"EbFjdime3HXLeUAHrFhXE1IBSjG3vScYWQ5JkhaUix0/yo5WHeqLLvN2i5m8xua0IUqWBhwTvX9MRK1I",
	"bNdk7RPwDxpILl3QKQs3UEhp2Vqh7gUCkBv+O2timjYJFMp10KW5RHAPtmVXrEzNqyimWkWoGgmfRjXD",
	"lLBKC+DhdUa3Q9yAUZQLgzm1AuSMtnX6z6Yq2TnBXBtKyjozgq1DtjGH9gH5IRirBi5lql3end43UTnW",
	"wjE5f5xnR2XagE5upzbpZCmEawTjfD7CPAwr6lsQZoWa/baCyDbSe42xCHdRLL/BnfVpB08FzdSB5KK5",
	"mENmYoAxVTKP9mQ3pNQUpdujo547oJk6Y6YA8NJS2Tvi19FhHkyJbhwQxNzwC1nFGqB77D8Ra+OJC9wt",
	"c49BrqKkRUfH+9cWaL4CqgCN4Q6FhGwrBkjJsEjg87tMsigl/1OUfpbO2YaQY+G4eTzK21NozxSkZ8QD",
	"qpn8atUN7cxH/yFoLlqQEavC/mL/DfepUjOFP0hFtna3ED40k1OaNWzJEJqnJ9BGd+iiiyDcBE7CDw8R",
	"JTaDoKgI0YlDEWjRHMo92BSNJldiaRWhXIxFYBXeXr8H4YK9fo+mOSYXq2jmSrRo9W/lTb3GiXpjp+lT",
	"8Ev+1gkVg4v0/YZxV657nKXocuxuP9sVqoQAhAa0+tSnmQafffJbSTNulsOxeM+yQnuvaFkaksnrgWIZ",
	"uwKQMl/fJegueMEyCAKAZKwg88R8LLDVOS00AAewK+5C3jH+QRa+oeEKHypoYDKnxaRgKunMh3GOzZhS",
	"1SIsIDAc+0+V1c4gD71ZUHegufbonI1FiMaIA67LDF54DeR+H/dYNpXXetyDCGBsltsFmwKY4HAs3klF",
	"3Hbqk6P94T7ACHQM5Gj/f7TDu21v9eDdo/3nVmzpVMusNAyp2qbke6rS6haaIL0U0wuZpUPiMTYxhtmF",
	"hrBMXiM9r2hWsrGgihF24yJSFZtTlUL6bzkj0ixYzIiAFdCMOt8f7h8897yRiWAzdKGqsIJIkS0rzgkT",
	"JHjx+YEEViS7pNFic+X3hy8BUkOH9mxhuBgbkjGqDVnQbOZfzqo9MByL46LIOEtDogDw0HDVW3R6+Zxk",
	"cvJmkpeZ4RNENlqLLwHhxwAfEvJFAL5GUTCq7D6B1orMYeMwTban0iyqDAhjQUVaT/qwMyQ/azYrMV0b",
	"F4liVKMjFEs4EGS6dKnbQMTQuWIQ8E8cpjdJ+QzcRkN+cJqRnJmFTB2zPRqUWZt0krKrSdgVK9gp5iQu",
	"yCeiDRWp3V2RCPR7h5GcUSchmsx0MNxvMFMXc9rqA3Kwq02asiuEd/EU1B62imZWjGcc0FKcUmrXCBsm",
	"HQAQB8/JYl3BBOF83QxB6wtTOVZZh4IVhUNuVDTWcdZVeEjZVjjaugpWvVluOI5IRVlX9ozN2U2xWdlf",
	"eJYmVKWblYZS56C3bFahHZezroZd9gcUf0MNg+IPGdUrFAWbFX4txa+lgA204ZC4fliFeiT4RqWrCO21",
	"o5HJSbo5Wd5Z/XWz4jVMy7VIdR055jeoU8///YBOaknSN6gX5T+G0CL456uSZylTK9+y596fbn1G47rj",
	"HcSEmU799hM1paIZyaiYlxSS2rQgKH1ELTYRX+vecZECAE1RTjOuF1a7UIYnGdOEThH2KVlwwaxughp0",
	"0IYBc2LJqOoEk4CZTFblKPJwljgyuMyjn3IAtQTInJSpIfl8xZSC0A+89WPThM+8T2HagKs03GTM5cvG",
	"CQcMhjDNCTUPAK+E57RptgaWEodnJJlaPnDBozOpADTMj9Vleq1NxZ7EOH0Y8o2p2yv8iqz1kXIL/HXV",
	"YRr4s/sRFgAQU9aJCA1+mluaVGVCcjnnQOgnDG5sB8P9nbo++pdObWFjNzN2U2RUrMi6+r7MqRgoRlOg",
	"alTWLg3AmtmR4vhSyRAz6XqxBFg6qok2qkxMqViKt5VrMEZWK3DucnDBSm01t8SWJYUHQ8F1PP70xicQ",
	"1gS5DxjDDo4mJluSrcCKW1375xEhyz+GhXD7HedrL6RVSvw35x8cmNRwLJwbcqkB6VsxGBgXxCVTQOyy",
	"VmA+MGsV6twClaIiBWXNmTaibegAHXpNAoLA9cXDXjVM5b1RtWVR0LY4+xrb6BAyx2JJuNYl030CufpQ",
	"tQYDIdW6zAtUtXOaMryHe29MMa8Ypi5b4LwjWwk1bC7VcgsSPIIrAd787X7uu6j4OktwoQ2j6UOkTmN7",
	"43BW7u73XckIw5NFjDpPFryNBXoPzB2mKkykSoer7NQO3uvkjR0O3hDxGvxABLhztBwAJqb9iaX2QocY",
	"yrBESNqzs3eOy4er3jjciKAqtgpDW2HcOAu2K7w9uVkvuOl0j+285bgesYfuQHYYQTB0P9hD0feALTT5",
	"w65gmOF9bNK1V4J3KTLKghvdDs1auLobPfMEpux65pG5baMwy2A8wN9+Z0pWWALBsLL6xbe2XN5cuPGS",
	"tZdnw0wclhKEXlGe+eCMjZKrNqfY+ZqyGW1iIb0C1kevf1489uXu+lWI/RqcUDCHoXXKEiXxaXRBvNvd",
	"WeGQe/BQZ2rxgpUmpqRRCsi6USKCobTndMp1kdFlZb3FHvWmUJ4+h8UEcGFWvpD7YpVREy0kDoHHHqI8",
	"o4qbpZc8dZunrz8WYNGsTMlg+iSx5dODp/oJ4+92goJRNQAVoQJ51HjiYqqclGs3kBr16rrWwUPYfx2e",
	"RyBfKdJO+rmN+Hz0mytGDVP3k5B8AIBTX0vbMwIxMRd8vmAq6q9JbtReLDX9y0Wk1TokzXvtqU+nqVu6",
	"iWKWqF1kDSkF3lORZmxKlSZWKmSAsIuQsRjualuId13QO9zri8uuNByLL77+gmpCAX86Thvgc8ZCgOft",
	"raX8EH/C/7N3nbu7CxfB5aLbdncBv0mTL58/fyLbX+QlE4PPijNhNdHPINXIJ4m6144HMp1BpODgu/3/",
	"4QJyQqDhaCwuLi4WYdJjcXuLnrFfpER2cIO6u4OiOJpjL4rJe5YVTOndXXAou6jqXpABOQNqaT9T0Nvz",
	"wm43GL4bHfBjSORuG8Wl1KOxIGRALtC96SNVl0xdkG0rbHZG5DhNyZ8caBHkZQAIYhRWIaxtBMJ0xzVk",
	"tRNhLsg2F2ZnRE7gTxR9uqCA2V1VPPS1UoaZ223fyAo7I4KaqWYFBcsBOiDQaWlFBYwE3OEudKLK6XuT",
	"Z0iOXF4xTd5/+fiBGDrHixG7MYomRhM0wg/IRc5STm2FXxQtNEJ8/3x2gvehH5n4iRu05ucypRnRGEGM",
	"9P/N1nvrng6R3Ipr9+6YSOFVIF0LDPTr94pqnsDijCxPruKECwCVjpbyntIkXr0fYEsSXIcf9l1LXxzd",
	"7ETvayksxA/j3nhsxj0/klIbmYf9OiIXX7jJ2IjUdxUYKu7uxmPxSqbL5tepTJd+PIoGxFHkURjVnyBp",
	"cY0Qt7d/u2TLuzvfGLR+e7tnS0JjYxFzOjpCMu23QZ98+PARBFfOf2epFZCFlZH8ko3cbjM4kxNh0IkS",
	"cqVJ8nd8psGb8ljQ0iykGpH/oIKRN5KNhWWvf/zp6OuIUN53TrV5Fm3hkGncrz0M9NzFZ2B+gBDrOedm",
	"UU4hxNNIKQY4H/i3rfqjJCeWjXK/nTpr0qy4ZPqSi725xJq1W/9qdutM3+LDjSd+2R8o1O1+iDZRFZwd",
	"rHh1LEB/+4ZME92S/cKO+sLhrNtjgXKhOxtzJwoctAHbHW0h9ta1lCW5pgJyK8HA4pH682ab53RuL9un",
	"b97pPmEmGe74ay+Rs7H4tdQGhMqQ1AYNGSoEBrnh/S6VplAyL5wsrmakWC5NBD2Lwn645hDAWh+tFCOl",
	"yn6At7GkVBk+klkJBZnJnWUIZqh9XzirPZCBUWunb95t1JYXpsEaoGQOFIra+sJuzCaNBaR7NzTAfXIN",
	"d4pPO0hcYRAY9ZGjfAABc2Ln2C5ZUSwq+5HfsHRELs4d7J3d5l7YkNvbP/EZwT9WtXJ7u8dnThj9YrlL",
	"SOPjsFjav48/uXb7gqWEalJklAvkqNbe7Zrrvfv2XhfNcONdowR2WI4b7vCKAaJGCenkKsCwCMGkUpm9",
	"2bHaRJFYWE0mJxQgRJSCmwaLEs/rPvASbPXqe9UuPrhXGR68ANi6YoRmitF0GRl9oylINAj7hCo8BWM4",
	"YNaDfidSK0GqjhKaZfU398pUAXq+5lJE4I0bwchVLzjxBf9XLcXwjF5/dJDesa7Oc6us+Cik3qgHUp+L",
	"+Z6t1bu7+3ofOCT1ThmaUPLp85dKpRmSN+EeHK7GIFJdzeg645yMvP2CeFcPlzyjcvIYi3PGyNQOYADN",
	"DADsoODDJc0zDydbZMy49EOQ5AvGU62o3bJ2J78N985U0ZnRI3IxdvbXEfwy7sGOBzURirFCsQTW3Ukd",
	"qFL9DMYrV+td7Zpl2ZNfsZTATop78l+gWt2U7HzpDoI9vOcNr6NoKJ/PSKMpMI2xm4KKdKJr0Lx117AI",
	"hDdnal4BnNb9KWpOcUC5UoBO4dN8Iy4oLCG4sERovbX2bFW4Cmr0sBjVMPpdM+ggA9JOQHO1sBTouYfv",
	"gb6ZTrDbGU2YebTb+TtbG9WVtgyDj87C3UzyN58rNkcTevAiXDoTOIqcurEH3srgMmsbZSkR9IrPK+sP",
	"XtZXiYl174tOTzcy0Ni9WoWddjJrHj80y3w9u0XR6gVGG9CJJN5VWci6QjT/neHxnBdKXjFSMAXHhGil",
	"3KgeJ0uVRXn0+r0EjB4Pf5fcDFA3WooKWNdliPBmvchqt5DaHR9RYhIQXeGA6ZZQQOlOKozFa5nnUsAp",
	"VyUNAh+YgWGCClMZZkA84I8jmuRs5ETKz5qpQYjYdrezca/UTI0ODo98sZAKFSRgvVX3mDry0iac59Ol",
	"6fQGb2EI/8sfQwKeH7vPIauBY/QKCCrwL7M6FLSCDnewzjjrVQcR7lxmLGs1l/kZzyeXNa6+gE7Uh2dB",
	"v+b2IoFZsaBYtZ9GqEsf7h8eDfYPBvsHrsZrd5Q02g8njGHJQshMzpdAT+9gMWLiYSdVo50lo6oa0j4c",
	"Vc031sfw2aPgLr4pT4Kt1TtzBqNvgJezcrYGs70sXF6xJ7KQvwMhD3H7b3unGePSjHsjMu45FVyNe3dO",
	"WWFZGkRLq/hUpstRs45zC2sVtiJmxhNOM1hwe1JnGZ8zkTBfFTyhWhUbrOELo4tgq/R4PO7hUwGmfrB/",
	"Y5V1rFmbDQqLNrMCY2IuSn8PeVIMm+fUZtpqlmTUwYRV+dE5OgG5VO/B49nx0l7NJxiYxj8lJFQQ5Q1J",
	"zXAGtC1AQJZmGV5zwLZF/lztwFrIQUvhcK7KqzUON7TounXP1W5IXEqyNH7cblzqhmPxsekpnTgAuUhr",
	"AcnNuIp0V8ynh1nsqofzbpVkYpliAmjH9aj6SYX2/CDFBCyjm2CRBe9w6VSRIXkXkWriA/DhXOLa+8Vf",
	"RghWY+FeIyACGeNMKqFCts2ycLncDvZ3GvM/3O/O/aTmrHZ3uNfHspYD5K7fk7OZ7sL++NQ1a33Ji8bD",
	"p1PNwgNzkKU1T5zqZQfSSKJgZfV3N182LUF3rbFn5BTTfO/qognEzU2my/vEQMfzawNvRRnMjeder5wa",
	"7qJYG06ArhmybY8x8gP4NjJ4CO0TNNz/QKj/yS4sUq2Al9O1ZCPnLUMLJP/MrqnVfJGW02Xt5dK54dcl",
	"bKS7uwPXOS3UEJsiKVKEwKz7fbihFHh5IObu+mDEGjYvYJTU2GAD/9Hq7PZSdvXDLdyPbI9Ip/ZT71hA",
	"Mv6gpYrUiy6XFwbzi7bXyEmr7pQ222dn73aGmBzxPlMhLY3MqXFbPxgOsW0wVbn7a2zHQsTCsfBolkHG",
	"euELISjkom3vv2ia8Kv92fLndPpBrBu4RI4Nd1vHzLBJOwG1H+CXii8GJLxCVBGyYai1gV7zS16wlNNO",
	"z9Nu9yKflVV3RvLiJ7SUhPAf5I0q423b70jFjW7ufOQcXbv86lYO3nnGtkZuDxdIX90Yrbtx4VtvJNft",
	"YlJ8/G3PJ/bOeYxC5b12qgk2PR/td17FBYGSc/r6GNWEwfmnt/be5o6ByoQ77DTFQlbqNhQApL92ORIJ",
	"n0XbHLNFdiOmPt0q1VrVaqiorrpJP11bXUXeszhNV7pKge0kpveg28RxTtfzJTZ8nr98OfWexYnVaGW8",
	"AoE9a55pq3KdrZQiv8DDoZMfi8BPJAGEAwWIwx15fmQHtr7PvlgfJxck51nGNUukSHVztA/O7NgM4bZD",
	"CTRc6RJ5vpmJ2GmUigpdJf20GyoEEsKNU7sbJyLsuFoI4QTGLrytETBPQyA+ecW0ceF4ivL5wsykuqYq",
	"JTPnKFcdJAPLb5Zl7IXwlWL00l2Gb8K9idszV5fTAbgGosezGyEqRIzaMzx06kZFFYxVe3VwAGAYkylN",
	"LkfE+5aTqZLUKm/257kCv2e357nSBt7uRIWp6A6c0FVonwjG0uAjfYMZshfLlEVdLZaFNAuGwYlUaHD3",
	"cpasvnuFhohSVCTdEkS90amGt9e9RIqEFZ6SOlZ4fTZ+WDO4+DjqAtu4+ff6PTu2TjN7K8TtiYAAwc54",
	"f6jHal/ws+Mfv0kAEr7H3+PTkKDTS6khjBse72u+DXbXf/jwMZjcq4gYSpyPk6/HNQQluHdM92P9am9b",
	"m8ksk9fot4DAU2jzub0Ntuy7uxE5rs5m3AVpw0OV8NS9NbAs1dhCQ6u07dix2Nlt6eY93oe+RDFJO2Px",
	"X7KEQdvLf6cXH2aQM9KRjv/OHMyAnW/fPVnY6WVSFtqlU6wcpix5KgBv0DbynA6cC1gEGBwc/E7eaIg/",
	"GhHvPBQRynkf8dT+808lurH+LaPa3N31ye3tHv4E7/foTtTQa195tAizYJpVTfc9UWChDSgHhDoVZWTV",
	"+I7RjMUbmZBoTA33KFsiGshY/J1mPLUzfKbJrYrK4V2qbZPFKpkdmbGG5C0NvAKWeBSUS0LdGevvR/53",
	"bjSR1wIv6ugM3fQcjWxfiEeVVV3b65mVfdQwAQxh5JwBzMK21agRhgOOAxzUlsaedlyguQsdgbGNyD9u",
	"x6gnoPmxoAVTGjNaNzYLFhgOh/gV2rS/HezffcWW4RhJqDatZtHbplHxZZ9gev/GENADbUVp11WO7irP",
	"MvrmAKZSXrpGmjdYW+AWBx0PzY5qU5ysmoc/glWcYL2DtrlNL7Vh+WStlMZyQUBLAolS8KYLj5H8d9Sl",
	"4p1tJRmYRsDhalZm5PiEUK3B+doMybmr2RTLDfur5UWuWdadTMFK4ok2itHc/tK+cAjYI+fnb0koFd+4",
	"IieZ/zj//Cm8z7YhHboOUw7xldUBufJoXXFDPP7RK8d4ooiUX/HUK2/L2r2wevWtH89QMr6+3HPtqHbt",
	"kLxesOQSf8HKWyHoEFzQ4KbmnrTBIkZ5Viq8oTz9Nh1esd3I1zUWmMU32HWTizEJvhnEkoJO1itbrlwn",
	"S7SyYVXvds3Mt6wLEeRdsHjiSQEaq7tZBiVlfV6rKjfRZhbCU1/e5a3o9lft0lrATG/PnkqtgPe9dWNs",
	"wVa5AXRQdVPIj86EZJsARnDDHljrtVww1ar0tf0AekxKgebCDueYFfnPIlNyR9CsS0uVMjFPqNz7z2sm",
	"jgZ+JIP94XevRu8OvutMsnn3gJiUFmd0ZvVoTyBOwORTsfsUnwZpDbH4ln6dN6gagt5K4DrntAMl+yRC",
	"AQSFVkFQr7Nlbm/tuvQxbjwe6c8W7PV7u3Vou5U4gGdMG2kXPdymNnuTf0WTy7IIB/dXaMqo5aosSvCx",
	"g13CYYSekm1oUZpcytls4gyp3K+ZA2U6bCGFhnIu6gwHzmlGXFP3ZoJ52QlXW/m9whs8zSZhWA2Y3P39",
	"/eaITrCK756kLKMto1ANJne/+7WO3kyogaDJeqdH/Q2eHy31Q+1aZoZ7AXpdvyume7TfMV/f+7r5duQ4",
	"bp88sjQr9szrzOpmPmiiCuq1bYyCCYRsBztNbGda7pDwtE622U2RSWBC96IaA4v7lnoeC79zf/tXNjjM",
	"uzHC7a/193EccJUdCe71igFC5Yh88Ta4YEaEs7OgImUpuWTLa6lS7e0+mlQBLfG7lpviB3bFMnLoC2Gg",
	"GtqjKgNUZJeinZYpsERdyzJLI4Qzh4hooqN8+/3yzVsyINjrUbPXGiinx+OM++sm8YKqtBIvDTGxNGyi",
	"fFL4ewXX0oEjtU7rqI0uLejcSEXn7DzYqpvA5PpyUoJ3UdsuzPUlKfENQRDbj94omho894uubF+/LPCO",
	"Wz19LagmiiUM/I9Tauiw+07QnlcJgSfeNaoj3VD4UJ0nn8PTkHdTsho/NGQvicvNHtOaWvK9b1K1m1tk",
	"/AeTldPOCdcu6sugn2BO1WUqr4W/sEDGZH/EVpY27zbzj4BFy1MEl0t4is5KX63E6Px+gAX64YdDX8OB",
	"kLQONX836tQ+qrADPylQPa0A9ZOJQzjvmRM8iNWGrJg+aE/E/tq3/z38ulal9UPv3CFLkcCWryeysHNH",
	"Y3Pj3WEpkoWSwi9pBtICvC7BebN6LAXBOPYNjXsj8gvlqI2f0RlYVAuprZxKrCyECO3tGdWGadP3dtcd",
	"bATkTa2JUza1G+invxP8BsWCqaNWtPL0w1fFX44/xJWYUDxZgAy01aIwGBJ98n6m9aFva0cOWeqodHQ8",
	"uAnQSyFqg6q5u8BokDOmTJsBm82kMqTWeJURdWZ1LjipIYrFlgLbJs+ZLE2faMy50Se51IakGChcl+DV",
	"6npJHkgHpcK0e30Yeqds/+Kf5hoyNeaXldaeDjAw084m+iX4yoDxHhKogXLzweW0exmpXdXIIl+4x7yz",
	"ntjq1ftCa8sg2MntKmyxdc3DpM6xqK1kj8hHjzU+YNtjbcgBGHjosaJTl1yIR9l+fUR4sMq/1d0i8VSr",
	"nhSLjEWXcZfCrMkusNEDpHnTCROfX8Bbzrsrepy3YHJGB93O7MO+iKPXY8nsHdWrZWternP0E4OBBjcx",
	"9HsMFPhVSw/FtMKjQcykB1XX9ygQkriSqN2lXW70UoTrqX/6aazFcCxOZuiu1o/aENJUYWFUOFdF77SJ",
	"0pqlZFoaKIpMlHZC1FqONNkk9c/gnWen/+qcaTEmuBqOXoDuym4Krli/Qv4GkWEyRPID6acNzQuy7S0J",
	"OxgYo8mPsurDncI+3+vhi8VWn2x9n9r/Hnz3l8XWTm0ikfOA76p7EhVKHuXCe3FVg7Lb48uXDzgLl1U1",
	"HmeckXncm4SK4x44sEQ0tNpS5fllF6EiAiR1MCsmcMWU7lyDv+OHEM0N/Am+ZHgryfk88n+q6b+dThv/",
	"P3vvut24jeyPvgqWk70ieST51p1kNCvrv922u+OJb9t2J7P3KH8LJmGJMQVwCNC20svz8TzAecTzJGeh",
	"qnAhRfnStySz50vSpkhcC4VCoer3u1+qTbwV/jR3BW4w973mDqPRqL8IESgPasjaEWDBNKqXtagJf7at",
	"F+UsjvBpASgkgKKWABYAi3vMkQtvOaCjVnXsQYQ/mdP5GS1d1sIIR/WTNRMun3V2Iy5mHPLKZJXnaIrU",
	"ckoiHRR9ksmnffJw2aE1Dxf40DmK3L0706rupn8KkTl9yxL7cc1pC7Gn9GumGWeJkKbkOfgYMDRLlDeZ",
	"2znoOx1KiuKBTCZKlkDc58TuFT6SW4fd3X9HEemZ0KyPesRFKMEVwowXSDd/dPQ3ot5GYEdV4ht6JDsO",
	"QMooNlW3DL3o7FaV1xQOgR/C612CVthxDTjzDRiurlqr+wrvVzHPBv/qQ0akb/PlnEB+HL9eleWmn8ke",
	"k9RSJ/lgxidTJa/nF0rKu2HcEQwaBSr3tQSn0/7Dv7wWumqL2ZZz4hSAkYGNlbx8tue54ml7ke/s+/e1",
	"0mAEcIao1wcbQ3YoZnZY7dSRNbbZn2XSHmnOzw/grc0hO7F6XwP0A52mrH1t91dMT5KTXFzlQMyVCgf6",
	"lQV8nKQqAa0+S4VEj1OJnmW9ALxZZBdAx70yNaYYrq3lKuH5VGkz/Hb92/Xa8WP4jtyX0G2NzLDqRpQ5",
	"LzyPvH0WXSoEb75HGVoZrowQNiWkSqxEc+LJQ6My1+/baPifwiPuVlxMJO5tjNY+f9UdsB0uGc81oK9q",
	"YQDeavvo/PXBf1+c750e7p/vXdg6hLzJSiXBbnPhRPVj0tJRfZDHvD7qz4DCXNRJjSM23X/jDLJMYjbd",
	"gEA1kOLejs+NkNa8AXdZt+fed5Ym3HFQGP4wuTJDpqurq+yOAEfA6vSFf6UZSQyaYq4yfqkhKo9+s+eH",
	"YVIriZcCgQMrXXfDRtHHI3k+zTRD5Y2oMFaN0vtXlalKD8WFHhzY7TAdBEyzGS8K+FOYpJmm0bY7xCsg",
	"8su8XH/83oC6aqIIrCK6FB2wk9KOvNFM3CVC230xqERIFCvnLLeLI0LyW3nsxqG5RB9sdMg2wtdtY6kA",
	"T4eRKKlFUhnfPD1gyO4z4xmY2S5Gk/GkVJr2MHapKplyF+fcgt0cNTpSF7HzizRH48zrAcwikDtd5Bnw",
	"wfjVPhrJ0Uh+RWlTJYfIa92lvCmQMUwssfuR3yRbD69PTfJyW2Cc59VQbrXZWJgOR/zcnBUrNjCoA0Zm",
	"Cu1WGZKkkqRxDLfFNPzsV/G4sDSISKhlgGXYjoEZ4SA2URzdrHh2kIWhtlt1H8+NkZUCyzTaEQYP3jE+",
	"DAO+cKigifh5ud23GJ/xHMOv/bq+cQeA9/NtW5eMknBCUWjNkCDDkiLq7zIyvLqtovq+m+Tg0V2qMbTY",
	"qdZxdVdvLUCxsl/kPIl9UfVYebxIOFRyonZf9bWZA7Ii3nHrQbjVozw8B2lg1AxTuEaSkNzpOMlyPhdl",
	"jwEKn3SgIzztz1SaXc376PAteSIcQtg+JLRzaYarq9EtYhnlsx0dn7Mbnmcp3DPwCc+kNtFlkju4w1ZF",
	"WBc6RkEYycvKAO2OZpn5SrNCaZ1RChamCrJMQhWR5oekMgSehM7LlAmp7YY3V1UZOfy9Xh5Jog+Aa6as",
	"BW3k3cq1mAcCgeHG5tZKbyUUBa4BVawMV77MZLLiSD9XvhzcZOJWr/RWALFlZbgBMTnwIpmjuxwMQf9B",
	"zrX5MRO3Dqa9vkagGQtORyclQIIPLrVLwTjp/R54vbh01gDokUxqURrdbVsbcbeWJWdHo2gUCBji41uD",
	"WgLh4pPC4bzgHBdt4XBVYVv5OEGWB1YmofDLJrtimQGiAvmVYeLOtr4DA0Brh2EV3cdDG+3I18bmwTV9",
	"XCw6FFTxjOFwLJjt7LF/PTs+Ajpwo8heIy04WvlyUGlRDqzqw3jaLweGTyC2VpUMIV7o1xqxRCSri644",
	"FN4FRxyACVtVH5L4OlbY3LjBb19WUgvTY7HAdwfsHAEnCiFTADxz6ot1aFuHbzOZrH05q/IeOHbhERQG",
	"kIgLc6QKt5IemZz2aI+6Pq0Kq7h8u6LbKNuEld4Kdsz+A9f8l0Wlp/j/PLf/52l6rs7wlQLaZrsC/8sk",
	"/I/bc11DE3xZCrj3aL3CQr5gni+7y/YsBRRCC+dyTKYz7tuWK42iTcgcBRAWgvhFyMG7zr6L/u6ufADl",
	"tluqzzvReY0HALqd7Aq8ECLtfgBPc6tqfcW1+PoFmRXRfQRqg4chjz6UIvqMlKnVtwAhFc0D3NV4TmSr",
	"5hCV68IWpb8DZORYCT8KzvRe9NHY8guRTtpuf+L2wysf0oHHWPg/oA8Avr+U9/0EUyNcJ4j6XTOeK7o1",
	"gdn7qAx+i/sOLtGf31+6g+ao8taUcvsYgyUf1RYeUP8CcPZq+3Pbav0x05nBqHqYbvBeKDQT3psjEp2K",
	"dEH0mHTs+peJ5nvZjSWhvKG4XjrUE8+yn+d4E/kJuPbJ6+9WwBOMHsLhs6+zTIbDgSeb1B8yvjN+dxFt",
	"DI+FgXp5YfAR7hGVRFTv9IO2CNuSWipHiINd1poFJJyP3Z5YW7jmLGtMpDYIIW3lYzPvtjRnfZlr4pM2",
	"5/6DNZRw4BYP3Fo+zCizIPyRIyeSo6ceUGoG15MQMN6C5XjCtb5VZbo0h1iK24uCXqoHPkpxe7aVlFvm",
	"5D+1vj0u03iG/CePuR5q5bcZxG81BrrXm+U+uZhyPV1mETFnEbm3mX17wPbuCqU9PC9c6GmRVIB5U2b6",
	"un4P8Nc3r+f/s/nn6nA2GAyeAiFpDy8umikU84uaylSJRwfEf91rdLJtcH4UpRF3ewh18wyv1xulrP29",
	"k6sqZVgI295vouJo1hFW+osy06I/KXkqug61USNWJF1euYiinVKkmGOgWWd7d6eLIUyVmeJtFnoSTx1V",
	"3v72IStVLtjY/lev8azIubEDDOdDxz1CCH8MWAn1cHWVTcQsk1nft7e/vr7hqTN6bGv9m02WZjPd7UUA",
	"PVG0H4G88yrN1NpNlgrVJZoTlUAFjj4gsSM0mMBwAYnADQxWn2drLhzxRti/UpXotXC5sTYRBu5uQhsX",
	"LvDSbCYkRo/YBvdWcpVQRM9Kpft0x7wRJQW1dRtNHysQQOm2Mpv3J0nRp2f1PCFs/MqCwyYJ03bRbua7",
	"c7y75+YJ3u5C6uW1AFRNMWDbVlNLREcxim3v7oAASCX7b3ZO4ku3JZFlYUhqyRXfLGS3QIyTe9s5Q5uo",
	"5qzzzdff9tjGy62vwbEAcoG5NosD+Re2sfltf+PF+rcNYCf/VuyljdR1mLb4uqM+gw3uxnj5lWLilmVY",
	"idsn+/7yIyrpqx77SlR27vq3QpuNZReeb46P3xzsXewcHL/dvTg43tk+3z8+GrA4IKpWbOtkRK5u16kl",
	"AviwL3ypfolzybyeXFJFWwqkF/p3D40vvcj2d58wVienx3/d2zlfej38vn50HIMmzsb7a+qgfD6tqt6X",
	"rLlwR7KDrTmtZI+9+WGvB1Q8lRFsT04yKbphX3WIbIjxCFfpLBU3PVZWciTHE1CvUGmMfNZ3+CC5mmRy",
	"/BE3jM3By/5VzvXUbxbdXvxbUSr/99Zg3f79MfYFgHdbw4lq7gLLlT6/8zeNL9b//PXCNuA78x5bAKYB",
	"23ZWJRCeffPpNoUzYbRbZdsnJwf7qI4udk73dveOzve3D87a19sHbyf/spo5Eo3HEVdDNIAPXQiw+HCK",
	"ad/Xluv/WPKeqvsf1fhxob9Pbd9YNC3K25Qq16zkMlUzKTSE6YS0FSTL3hysdwfse6QtJFqWGb8Wjn1r",
	"phBmM1Wzh2/PNx8h0TaquLhuO4kW/Wum7ejDVbeH1cUbfo2q0+cDGFWwH3wYjgMUY7q6xHs0g/LVLkK2",
	"CUUbLm6Si0q3NCLwiS+s/mjsP2JUwfIt+6csTxNepp848vaWqnk8SNi/+XNbSoo7wUIyBTYR2PS2K1Td",
	"0CTwstmnYbbsjrZyfw+uvStFxPCGJ9A3YiDeluYKMhlDvGGTWw3eSC/pH20YlfY5HrbTzPbwEjiRrsW8",
	"j3yfEJmGXEW1jF0BRgUwhximJONsdRVDaSFtDCKapK40cs4YAczuq6sYW0u4swgjfSnwXthE/HouOjOK",
	"hS2l1VcJL/hllmeGUJ1SkWc3omTT+WWZedJ1bphOeI5cCF98wX6acsMO+bU1urDHb2X2j0rgz1+w7/Fr",
	"x5vXZ6urrw43X7I/eUY9D6a7ujpkrxt4+tjIhVC6J+DnYl2H/lBjS4eULISowdJtTT3meN3gdEzsUfaI",
	"jEXseRveQUdoWxaGFffYcSHk9n6Pbf90xl6JtFTJdc8ZsW9A0ffsyExLVWQJlvg9L9NbXgq2nSQiJ11p",
	"yzzbP9ytZUxbS/XHv22ubf/4t/7LjU0rDXffft1jR3vHR/aP7dPDLrT37HCPdc4Sjmjah9yU2R3buzN4",
	"XERTd/v00M3KbiSQO06eohFDSdsVOptgwwhzLRK+SamqQhO3kOF45UfXnEleaSNKbJoLZukoiSGEkDhG",
	"8/O9KrNf7fLLGeSgZXJi69u1pdXhjWPKdIrUwwy0FjrTUnjTGquJ+wsXzhzuHWAityH+hiKVoEjMpNSe",
	"5l7ZdtlTDIV/bZ7suARcI6Shp7lKrjM5wQpfZ1L035QcIKB3bbPsygIRp12T0jXtgEL4dEIgmpCICfmw",
	"mnUow7KHL/cCjnQvzirtMX4tZddN7vZ+/wg3kdcCdg+a2dPtNzCXHlzKg7n1eTWZIaNttHlDc85EeSPK",
	"/pnd9/Zu8DhkC9tGWIDtiZAGl5ZDenaQoKWqjE8F8HO5gHxAE+SucF0UIkodoSWE9AAyvDsUBdZdlmhA",
	"jYTB3PMjZQt9FZA9w+k8oFa5jGQoNxc8FWUfbsasnhFa+7KDZgH+MCOseqA3QKx8j1N1K3PF015URo+0",
	"EDlhE2dJ2eVUp5m07wF/LRgob08PNOvY/WgNNqU1vbVmDx00EGdnp69ZgYG5Dr3VETNS0BcMOWkBK2V2",
	"i2d7d4UoM2DwgM7tIMfdQXZZQgys61A/ZKif7f5A/LiqB2EjZ7D5YYNP5mZqDxK2yaAgT/Yh3QxLh+MS",
	"JX96HQV1ELHs+K6P22p/dcy4lESvTMNDseE0DRQdcgbRISHEDmWSAvYwaESzzpeZTHoUrAKBId2Iwr0R",
	"WIflH2RS8JIBAwKuHm4EoCsieYzdXglKvxSJsvoI8cvuwJbLGeba06rxDNWnjtbaltkCQ4VdJchRH9/g",
	"ybCxNEByZh6PAfoc8404nESkt3J3JgiaZg+4RLpOTTs/cNw1dfGNkg1tmyKoDwgY7IOuQlWPF7QdvKuG",
	"eaJfncSFtgJiwubXDPcsUI7YjmMENYDdgJ25wOh6k0rBc3fUxYXkA6jtdIRtwU6sXX4mm9F8/lBdilIK",
	"O8LHFEMEu/kVIdaPSfBcgNE46C9r9zhlkWdXIpknuWAzLvkEiHixgpNSzYSZWmv/0OrXBKblFeUEsZmS",
	"mUGSKRe9inOtLq1yqw3F/4hS9Xep+extAV4uKO5U5dCUip65HbFhIOIe7Qb/dS7uIE5zv7aC0CiyKxiK",
	"Hgekx5v1MetYa63bY2O7xeATssZgXE75q8z8l/0dscnhhVLkOMnTrAhyRzs+amMyogLLgKDH4x4bO00s",
	"4odFVggrGf4Z6yBoQQTVHPQrVQZHGaeYFdVJmVBj1vFwPH6FeUGyXUIaC+gQhm05Ii37o+OswP6KG4jJ",
	"KkWfKMRa7c8fM7BP0TPwJ8fYUDJVMjr2tREka9ZBQ5LKPMmryQTsnO3aAWDI9rieQ+RnmjrdgdAQEB4B",
	"7oBSTKwtZO0pYzUUeOfyLBF0t+sOQHnOTjGk5pSSVBZOQ7hSBplay8WE53D8BfY/f/g5qS7zLGHbJ/sr",
	"Uebwys0Gz4sp36CwVsmLbGW4sjVYH2xRpCCc5tb4BM6WiEAEB1I6gdZPWuDxPTg4hPhjhIaa1/gKPR57",
	"L0RsM0LQAGvbquk64nHPczPVMt/rGnUqQnkipcMEkGJ6LCVJ+EkDMru0ayGZpz2yh7A2eECX4VgSoS9x",
	"DbigmHAziCNe91MYbvsW2GIreIQW2rxS6dydbl0oX3A5I8OZOybzxxkZfA0e+K1+XKd4gRqVxeb6+qdp",
	"QQDWFHdmDYalj6Cp9QKboW9NW5aQVnE+oRhcKsOFaaqH+vfYNDP6AoLm4N/0QMjUTiDXCrL3Q3J+j2ay",
	"R+ixF1VxEYDKotdSJUUPIU1bbl9avAwoH2B3BxSmXgQhS1laqmzAxt73Vl58xPkBvoy2Ju5TLgCPm1oG",
	"2N+Xn6cRzhwDGaABjt1IkCwQOZD+DuCXHq5pJT7wsP77n3cgZXSiPcj9RRy8bhvk1B5yAwJ/7KPaj0un",
	"AEFOwcSUTeYj8nngoRUx5SAboYL9I43JCgmZPlj72AviNoKcKIz0wwQDqwljNOfBAt8RAPQGolFC6yWO",
	"o0yHdFeExif2XAB/euUYdJ3yBfsakXzCSICBTdeNIPV0I+Y/CsgyX2lKcoE06gnc/kXA5plkp9tvmLM3",
	"8P6qrm+hr69wZj6l1o3r+Y3Ubr0JpHcXlhfaWeixrGHBfW4lQ7PgLqwwRJQkHkBINMZBAZgVtu7Fp28d",
	"AlBJZU2OSqa/rdZzY2MVRgJk0MBY0H2WNgSJgDCyiB8CFmZT7Tyu7zwlSLuC20NDTHtuKjrr2KZ7AEqY",
	"UEIfx+NfDeGH1BcOtnNdo9A6NlW89m76nwEOYTwe2wkZyXcjyVgNId9TiI1WevhjK1D+g2Sr9GEExD+S",
	"91ArtqlB4/dYkygbTvsWteL/LyVpi/jYfAmE8GW//Pso5tP0Z5TRys/Nbmw2uvF97R4BfPSPdSUiQHjq",
	"4Oa8MKpgE7B9wuC2jsE0m0zjzEb6irm5WTYA1Ky23seb3GLjijJLBDLgJpvr6+vEn3uhjUquQZWHFhNZ",
	"C9YY8sagCPxntExahn/jZX34f8J0cUcF/cjI2+01GvaYhB1fqLOXP3l6eGKPuY2uijsA1lFy2bgRJ3Yq",
	"AG20Zcm8bMja0S7YumivQ1+BlaPKr51B0GNayLRO0gecIprRx2DHjXdQZ/TPAVs41tF3fZna4RsPRhKI",
	"T8BvBXmetmT8fDSS4yE1LOLWQMVhx61FMkcr2/vwU5C6v49WxOwSZtl3+uV9o8hUJTBlbdMQjedoxVRG",
	"lRnPYSB9eRvrbgQX7J03ADyO98Kf0NIJJk5vpW2k68W1nI0+s1kUuCCXmkTBGPrsppDj5fijHbROUCEz",
	"HnN3zh83I0o+eY4RATeT6JLhHm43APFHhNp1llTvnCwRftiJGCDqQYEIP9zibOicne11iUiC533w6tLV",
	"xKJP55RPPuWCi2jUPvPSCSwzH9GBo64CRLKbTA8EFEMlO4TkpzhX7DHwH41lHHtWvNQ0XCt0I+24p0HW",
	"aiw5n10XIH3PH1UT2NZ3Tv1l9ba/rH4TAJKfqiUC2uNEtKKOm6qUGD3jkMmmgudmShoDWIfUFZw+IICn",
	"duggXwjFPyzuo8IQgOQnXF87WLlHqlyYGHrBdSawBi6e3Dc+vZi8lbwyU1UCtGC/EY/tMQsiqW2rxQ/m",
	"mpM6VBV7z5a5N8K46aMBimSKfrgId34kVXj8jKSqPu8HmTbn+EpvxYf+IT5Ja6YrHWcvCfYQDe+AJmEP",
	"IBdNpAh4CHDMK8MVtxroOgcLWImxpSP4682XL1sC/R9tGtBGuXuk0Lj/Cw0ZrF7c/H29/+ef//Rls6H/",
	"1x4uLgary9qKBS5rbBtWt53CD1pPT8s6jNBnFzMOW8CcHT8lSUdQ+g+L8Cueni7o6k8r9QAgA3nUTkqd",
	"yMODZQK/9g7+f8Rn4h51qT2gLcr/bqmKc6IhaszTi5Z4XfCWpaUqilal9PscQttH52F+ePx67UrijTBL",
	"xujj7Q01EV7mp0QOUx15Rx8euSNlXqNb85l61tSqe2TMHlSbR1EEvpsB0C2EAkGqxUvrStPgfY5m/Lm3",
	"5JCxAzhH9jwhxW2MYq88O2UT8b5HEJR03VsjyXJ+yrdasB2unYuSkGhNIDWQ0SVOyg1vde7IanaBVgp4",
	"h+r+kvPQ1quneEDrhW05JxveqoD7RjJmHzWR86MfWfBV1p62luR+sHOBPiGMBCfXU3ghxKwvfA2OvLTl",
	"cb1gnOdGwfiSD0uDS2LyzREd02jl5/oH971m5eA4/ej1I1OJ3Xmf3pJLlc4/UUOadcd/3jcmyxdDIBv9",
	"TPZ5nsd+ZuwZtjcq2hdL/3Alj2pMEDWH+GjFvnK/6NH1wooCf5Gldw0xDWXFwVFYIDXhfumCcsH9Ps79",
	"6QvrJTW25um1zXDwNwk3PFd059wIYQn+/2cvS3Jwf75l6Tzqv+nyRCf772B1Nqb7MyzS3uKEwDXDI5Vj",
	"itHTK5fVTJRZ8jGVRLgZqV+HvJ+q8IL/uKogr/1DyoJCJqPxoWsd/LnW4OgVFxa4sPxcViutNEhAqQ3+",
	"CLO7qPY8788ymeWzxjtVSW8sAH5vbLzYeuHUWhiwBf32xRfsldCGnZQ8MVmClkmf7VqzxiGIEr57KRwz",
	"s1E+IK+GJtpnZ4A9htaHuHUZIhizoWf2WGKtGi2MZp2N/haEQVqjaCa4zOTkqqJzCzHm1I7JgT/dXWnV",
	"rkihrB0lNVC9cswGuFQ1OyjK0CJRgJbV8qJaLk3QGgwm/cf34UY1/Ea+XOJWWXaSQODP+hmO4qPy3Bu7",
	"wuGwv98R+RmHDhyw2D5/n5Pu2iUQ4CIqz3MOJXYJ0LcfcDx54DhSF0Dk6f2UAthgAn6K7D3Po7hICIzj",
	"HpxJ0QXbE/hSFgUVu+AixxmS/JqP43d45un5MzkqqMeLrgqrZBcd5q3yb5Lpe4h/C7/jZ1oItr2fagmY",
	"ZPrZVgBFQLQlmDvwg4jyLNa67su2pHUMAFsOK42/x+jSGC8N0WTBfeOdqPU2473P4o0sfE0Ms4RMn2mo",
	"qypbYcayJaRpPnljfxfpiKg/T+JPaoJbIwT3ew2x//QpZGZtmqi2MtpDB/746sdd6qEiIMRzsLFQRDWm",
	"vL+3copYO5fexezTO5/j1gDqep9bg9jWDH7N3+28+iuEuN2L8wi//na+3YU942EpWnsH/3jSBQdM9Eq7",
	"um/ejKfi7g96wSEpowxifZ84vcuuO5aM2Mc7ntTWXluEAszDe193fMYr6azW1N/tcuo9VFtG091Sm19l",
	"H8fgw3NeEK+Pb/bVyJ2fbPW1iR9P0z+QEthO06ADIIHoCRpgiY7NlbquirV312J+v3y7hpd+EPMP1RMP",
	"0Rg8apudQmp/yN74l7HGcHgZB/S67GmG1+9KwfwgoqhNmCQgv1RLnSzXYv5RLISZKCfi+YfgT3TgbcRJ",
	"EuV/9iviS10LUTh4pkwixAwe4RxKBcD3EFQFchGdTVWRXc17I3mitJmUQvfY2RagynI5r2Ne0JcDtp1r",
	"xa6lupWM6yGV6huDqbMj6SCo4Kcey2RSgqrgOT0R/UTNZqJM8BW4CH+lzJTqodOCNkCKpSRz5ErUqMs5",
	"xuzasb8W8wGjM4cG1jfRv+VzBtMH+YX7dASR4rYO4YGVgbOZ8EOSKZeTgPSBPm88tNDougKQMDIuhxV8",
	"IugG32OIEAjGfipmhTKEUHOkcIa0fc0TGdrP9YCd8SuBAPqQfDySaIjJObwA1EpWJZRVYYBN3dbnAwgA",
	"wMQWTZ5xO3YeD6w27Nsn+5p1nAywn5TaoZ+6NIEs59eCiTtg8gWxuOWlmKpKCxcjZpQblisAQ73t5xyR",
	"jmq+c2rlT9unR/tHb3AEDNO2ow2OWJg08j4Q0WMBQEZ2WvRgJJFutp8gfA2M4vbJPlBbDFpc9AjuAtgu",
	"n8hOiGr4jVz0tRYsy9+En5FoTfxLOz9jzQhS3ArWE0l+rPy6lBDAIdWHlyiP7+OkCCmPz75AcNGSn95t",
	"CukHn/L64H9V0s8ff+1g57jLhUkWTMUlIfct8u9ydZ5/f+BzMj6LIRWlDYVkEPBP1gfh95ZOxOAhpjKE",
	"ZEafkbKYbYSXyP9OOfp3ytEnSjl6X5X2R8pRWqoe3k9HCsgvej8rgT4GlJfPYiycYoWf0lygKp6lQzY/",
	"4LI1moAQb2DKbDIR5dOuF9scSTgvLt7AF/eH8QC6HnC3KVsD2ke1PNsSjgb/N/WjVC0yjcd+BCr9RDKN",
	"CRn46u8ldouQWdGU+Bc+C+L0LqBCPR4SBpGED6WQQj6lhnMi3uXyPAfEKp8hqufaiFlE9MLTWSZZIUqA",
	"KFJy0OKs0OYt1Pyxrq3r6u75LG6PBFO0SJYXpSgC6LdINMVKtz59pa9VeZmlqZCs73JZF+f685s7uGTY",
	"B9zyVySJbqkAa2G0PNZQkB5ZIXSh6WMcyNGXz+M8YJFCbYO2dOod/ABq/8Bl0eBb9LPzdFrKk9qMLtDm",
	"f+j6+p2vpz+IBEOCN/mTF4XsIYl+Z//XEgrSIEGnC4HoDNAuvfhiu+S+aMV5LF0U32+DsfeKp+y0jq/n",
	"ZJpl2qfqfz5YPRiS3xBV771lEKee8SUi13uO2nxUzt4IUI+v5t4u/kQGJbT+WVrq30L7B1OchLrajELy",
	"cts4w7W1NLwCAmOF8oSb6Yl7vPLU/GpoiwfinmQ3QoapRYoDZBMesLd+xiUSsxsgLCpKkYhUyEQMlmTv",
	"eO38qZJ3bAU1h0aLsEAWDVzV+oH/uDHm77OoQ8t+R9tRRr7HTBaVCQt9zdNhzzI94yaZ0nL/86dv5Y6S",
	"V3mW1JQP43kpeDpn4i7TRnf/QEqglkH1dINpLWZU/2hKomqDw6YLEIDtd9P+pH0Sv7TVnQQu90+x8tuJ",
	"6Fum60jchj48ffF/PEGinfsQkzTamuh68Zi36LOrAhmPHcBARxv/v3f95zrJQG0VYV08ac3Xj9DLDkyn",
	"YqZu6gem8CUrK+djRms54DqXggKr/IZvz8stQIpQfjibvy7VjPb1B13OTWZXX59zVkStNEC5WkJN6WAJ",
	"sJUr4EHfdPAMqDIVpb7wF0iPRULa9tqXPnp7z23ND7X5kUubUEgbUFfLUfckmn5s4u9GrTgAebzqC/IT",
	"bI941H5HKoepkp2qGIXeywWazl46/zi6CVd2LNeeGiJSUZFX7glHa57nUYHPO2KfRArvc6SWPeRv/Pcx",
	"/F/9GF7UpG2JtH/aA/l2mrrTeH1zeXTFbKdpaOm5+oTn7HiRtNivodnOqYb8aZ/1kP0EOzu088GEod/L",
	"kfvfK/p5OVX15fPQDoYl26rajNZDnkkIecdXPGffGi+ytZsNWMtU7LuF2NUsuWaZNCE3AJriYhYplH/7",
	"ZN8BEzZZYu1jeougijQQYS2wxjqq/Zga1nOtDUfECfxGAV3jctJ1+l9/ouhfY6Iy9Wy0UMB/Nj7rGz1m",
	"HVnMHJ8ikNXCq/RCAU/GrHMyP9kH8tLtPMe28xKt7D7kJ2ByTWHqWTUwWif7zExLVU2mLFGpiBjAYPhe",
	"W7si0DfyHBIabjJx22NXSNsM8fi8zLSSBA9ZacESrgWbVFnKZSJ6TAukKPz7zM68QyaAen7uLDI1pirR",
	"XciEICN/IoDuEqnsIKrprp9musg53hfAhgOMWmf0xuLJ4xA5TaGJGCzB5qoqncQQavJXehFJO0gSIi5/",
	"Dy8gK5iH0XafeY4wL1wh7vURYO4hzjQWBCzcdkKlSuvw3X6P4jl+kArgV00hcUbZevDFSvIbniHZ+mUV",
	"EKOvKpnE31cyqnKnzIDM3GFcaMavrkQCg0vFReSvEIoIn2HZ/dssFf5TGrdDzyaLiwbHjyVTkVz78Rqy",
	"8Zu9c7aGTfkVFknEUjtDllr3Fv05tkdsIDh+sbm+bkt/q0HStIiIa42CdKMJkF0iFXfgt8UYFxxgnosS",
	"OprJq5J7vNJBLIot6NqL0ugk5TC81CKQKISUhpTJNnEcMETkRmHBNwKwBxKCAxty4IghUAAntGdEIjeS",
	"+C+NuK64Hn0XvWcCpBNyTlyDqH2oYmu02KurFNCLJK7UcuG5sgcj+dM0y4VHlu0RpixkpxAAm18mWtwI",
	"q2EuhRRXmdFew1pFCRllyEy/JzWIJTQyJqYnxi0/PMTUXJhsBrDtjlDYFvK6ynN2Lu4MPrU6S6NfIpOe",
	"PxOPVUVRqqLMrOwg9+AM87mo/FfC2Jk+gyQxW7Rtbp/f8lJ4EnAHKacdr1Tg4oUroDrQnCMEppZDU7Dj",
	"lLAGit1ZrhTO64MYadpj9vIzN8vR1gcd1obLlJdp7e14SsNcwmw0cUAfAOhsR81dAs75CDTng8CcywFr",
	"nwBA+Z5wmE3wxyVAte/fgKmZ5Y/Uae2jR+qEQ3ZLlXBsJ/6qxRbeP62JTxuZmTDcLtRHWtqKx/ooIitI",
	"GUT3LO/MQxCeEfpmTdrakvBtsVc816L25vtCA98vx+TdnUs+y5JIW7HOuK1F4y7YC+NH2jtmfXYsIaUa",
	"EFEQ5hL3AHsgYuMwxsASDtm10p7erPqLdFP3kers+XMMpLOAGJHnvjLsEs/zOetcOX53a5HoXN2KEgre",
	"v4Jjkc856rnPIi2qWZppqwRTIlAT2prrxyA9enV16DA3x23CRST5Ej+qdRswPOvw5LYoKh8LsDuL/Moa",
	"0VNRZoaNl0z+GE8OBS+JbX/bLkPYV6mg4WIbaamOHSHbkjXq1wkbDAb3DuWUVPqeV9aOS39cX7njkYS2",
	"2KbQN7Dl4WLRNPZzO9RTdYtmE0wlTuSAHTobAy0FvFgPlge85bdHv39jujN8A8eXhzF/rQS5EAq/PwHC",
	"KYLSBsJ635DHS62r8riKMZRqzbYx69iXu7Alh8cXF/QhHdt+QhBru433ue7PVdV/Ws96Abub64u5qgjR",
	"97nN2ZyUfOYAvO307ajZpcMYOK1y4RbC2H4/xu/thjKGY+GsMhWsROIzvBGsk0yV0oIpKRjXrCgzyN6y",
	"zeuiGR4eaNbBcntUaNfxLSfQDEGcgje8zDjk/43d+PXYeLH/Y9QqLT+wPzH/qdUm6pbKVpWptZF14PjO",
	"01RTn7uLCwAkeTySr5TKBQenAemSoF/Qiw5DPawZO237eF37p+LOa9wYgfiL5WrCGeR9a1TmjLuViasI",
	"QYJhCcJXPiTfrlGes/EFqhp4GQAIrPHbx78Jun3RYHvmftUGWO16B3uKHe0+3nW2CkePPTL7PTbOM3k9",
	"7jK0l6FVKfoRFNQwFX6ysXMdu02Mw7JkqrR/4rLwctcd1JXjOaxHmhMw/OmJXyd91qTVDej4Rl0LBw2C",
	"J0XJ87nONERtoeAQWnOvxvfdi4sKzL59tyIfqvT788MDZvgE9DPo1FAb/FYrzw9Hn+3d8cT0IYTI63YY",
	"NWj1ryLthoL2d3XPVqJ7LOFGTBTSjiKXqh4sXZx9tpdOBJN9O+yu4BJHojLKgTQMWjSbnyvaKbASEAPW",
	"Z29PD9bsv91sU798FW5iv2BHiNMO8+GWdZhUQnG3RSImpmYdQrrEg/NVrriVEz8Uiaqk0T0GqPJ25hJV",
	"ChqCSyzflnZeVmINFjq74XnlT9pfsF1uxNp5NhNRM1JuhMlmMGL2J234rHDE8qFqDFFbc/EpEB3UY5D+",
	"G8p/I5QuuLHLP1QwEQrcHLaCA24yU6ViLVdyAv9i8FuoKFfEmtxjiVJlavcN18eJUHrKcXJ3YP7u2ESo",
	"ScmLaZYw+C2UdKkquzeDtJRiQud9bOgZKanQSk9CbAv/EWHK/TOSTnRcgE0KB+1oahZoKWhWcnVpC3yV",
	"SasfwCMQFxWVkM34hATb/u8Sv2hwbcN2ui8pFdo+3L9aMKKsGdqwVFH3oQa7EqU1IcEGjI/VY1g3zmRf",
	"3FDG7P/7f/5fNo4MoYVXHZEBqryRA26Nvw3cBYufkwzHr/tHP3tbsjJqxk2WsNdI7RxcBtz9BOYDbLfo",
	"aQvQ+YCC74BuySlAXs3xhXHiP7bG0i4tjGgL81/6N7X7lgAIhIZv0eB3GmLGC49EGvZNl4OORpQtfns/",
	"cvH7Aqnf0Ft2hPnrO0raledM6Z+mQgYrN0x2JAHOa+dif/0RqWEUEwdKdXWV3Qk3NCfx/gbnPdyR7Cyj",
	"jQUnBs1UmU2yUCiwSkAJP5CSpN0PjNGlFuxZu/HaamIS7/yz7OsHDF0aHzJPrblBZm5Q7+GnaItf3AXi",
	"12g76YiWHan7ABMEnMJwqEHJLOzUkfkCbwi7sTLYWMGZ3Sfb2wmFfcefb8Exl8nJMFrUzXOIIJdeC5cD",
	"1uV4G/psO03bd+Lmlhu598lND/1EewPs5aYBAcvF2hhgCLC0KtEHjmYxcF/gyfChMy/o2EKVhsuaKXPl",
	"1cgXXziIM/B8Oj6L4LZsO7KQbpnyG8Gm2WQqymCvJ0obllYAJRCESGe6bhBREXbFXnFwy/uT7WVl6FTv",
	"3OiFteN4jpNMm1fbqIP6iwXOt0rdiHIqeNrc96BTuGNFLaorVTiTpW77gD7F09A4fxfW4AJNAOB0XNNZ",
	"hmkHqecbZTUqzcGu07Ln5wesY22S/rnqH2Q3ohspexoPHRrIxF2RlcEEhkhJ+0cNa5xf2QHmEXZMGoji",
	"dsNrC113MXSXc8YhU39SQvxXYjeoqmC/qEtWVhIuDxSehU75lWG54KkovekBN9hsJ2aosz+5BwJ6fWsV",
	"OiYswFUEYgTgDcfYmPzCtXnc6vZ2FExWzWFoi2exij/GVzZfBI6rB/3lVNan95cDsanjsHrUATxaCf7b",
	"lmrvH6AwavFufq9uWWbYrSqvNVCL9VkQChAwQSJUByByY+pv5bMyWAmk4zSLbQxaGZdzRgRK6CaoGTAi",
	"ZdwQunumJGwqrxZFr6yktrZ4OWdb60yLRMlUtwih/XwP+pDGKwLIhexxyq1ruzNkQrNsNhNpxo3I56xz",
	"Ka5UKVydXY/aiEA5pUAoepGyzsb6+npcvrESnM0Euoomyt/oQ9MSJbWQuvKH3x282rHr4NSh/qD54+5P",
	"ubv+MfUDix0pI3hqV3w81I8sEjzFPLBEvklrP0bkU3QuuuDmaWsIqvr0Kyhu1pJFZHd6vEgkGi1uBAQB",
	"LK4vaLSn93rsGqN+VeECmMgaixv2lMsGAnYAQaLlGIkHma4EW1qUAtBCM1kz8zVuTPhOJtnp652tra0/",
	"M+y8C8Aab65vvuyvb/TXN843Nofr68P19f9B319Y/865Z5cV1n2b5RiIwCB+y6tzOG07lfAah1mOpG20",
	"Ey0NcShvVKQ64D20PbfWtT04huUMT1/O7MOXbJbJytDmv/liah9uvmBTVZX47Btws3zDUj7XrGMov4xr",
	"tvH1t1M0Te2/7Esb7FaIa9fmJkkqqvwoTKCVbnFxxWxMl62YnGtzwSHqzkpFmG6qy2vZDegPKdtx7bPx",
	"gLBkEcjGKwElmeDJlOF71oqC++EUdTWWTzCp58LagvZQs8PBWH5ix2C3DI22HwsmpAF9SS13U0Ft9+qb",
	"qj5QE3aqMLjoibVurdeG6kBN2iwUl9aO1W6tw/R7w6Nm2k65PWmIMtMmS2iyQyDCmVElnwhacFZow4EX",
	"Az1SpkXBS9oaxkMzpjMjuxZzjcfZ485GlzCkQSqPFPobUqFFmfHcuSulECnuoGAz056mEy7hs39urK/3",
	"7ZZy563jKZfwO9ha9lQSTuaXKs1wYRxmMptxjGLiE+HNXtb559Y6u5wbMlDdp10cBQxtQJZ2JxZ9RldE",
	"12JOPbLCRfFBwers/HOWJaWiFdulTmezwp6UlKRQCELvhWITTgi/syzPQfpjYxVbtEMj8kpM+U2mSmrS",
	"aeum3/Hcx5c5Xo4cwNbfB2d1oMXpFCVueyytMJhTgNEDn7zsY3FsUvIEMgMylTJBcS23ZWbIwYCMPaWg",
	"ElK0T9AMSL1x4A0C3WVULczG7VTkM4/lCGFOTljrEVlWAiPaJFtzriYTd5XjRMaFYNEq2T96fcww3s5W",
	"YguJbfV4lX23+cIXcwHIzzc8/25rXbtSYA5EyqqCFnlsQIFf9rsXmywq7uXMTqvh+QW9/93G1tY3tYuX",
	"Q5XSZaZt2sKJYHV1G3kUYf0pzHKF0bJTS0JAalBHkTH180G4lNwuijyDaD9TKp6Y7Mau3YZPTNc3vJBh",
	"i32G+zleXtPdu7cP/WS7XXumbqjpbgEJ02yZ7dOsMHO6AoA25nm8ngjeDaLgjEItclKKm0xVOp+3zEQp",
	"ZjyjRuxMuZzYT12Ny4dMittG4/By/TbszZxGLzaJ28ZuL7S+FAnPkyonVBTblDCHkQMRpeEgmznYSXcv",
	"vZOr5LoJ/O5DwldX8Zr+6PwE/CNzmbDEfqFdoJkLp4QATVckLgDSQRC1tTCKbh+xY5NJ9s+aeqEC3CKh",
	"4F8IAqSLwhr7OgScnR/48WuOmbs2BKGmsoJRDwaRLcLZb854U6X75xGXKg5/XAAbWwx+RFbNB0MfHR4l",
	"eOwj1YNeJWA3jYm31oh0q1eDtEYY/pFEWD+HRNlzjo/sJksrnkebio+JRBKz41rM3N7VVZZkCOuE1TLl",
	"oGyC87c2sJxp3LcoIwSxcaHlI+njgK21VBjy8TkmMee0vhbzPtwisYJnpe7WKMY6/k4Ydn3X+t3MrujL",
	"ysrQecml5onvxUJgu1GzLKHLYQgLxv2FmehDDxjur4RUibe6I7nZL6Zcw+3+LDOss3myY3cZZVSi8gED",
	"1zhv8iUyXXCpw6hhPLLzko9k0+lF8MWZsTY0Z2nUwaidgyUuhI0BO6QwM4eQynO46BKafX+wE1mwEDAr",
	"cojmiTqLDRzJzQHbiZ7SThw1gZgTeugmTLICQhxwRDPwpeqR3BqwbfSCAc+YCRx8Iu3VqsVBrdUwki8G",
	"7CQu3W4KUhn0g3CnrlBFI4aqym+i6l8O2KlIFFguuVKFNyywELr/8zD6cMlINm3cNorhxjF/jbH+7oy4",
	"uuqviRwVBN34bZ/sew3K+uwXq1cqDMkmIXHrgsoB+XSh7s70Qf0KMfIYyU7Sp0rGL1VpmFETYabocbH7",
	"IXTXqh0IRV/sBY7ilMs0Fym7yThMpB8i0t5eBdhS/rm5PtNOkUcRFriITGPdra5G9n/NqKUP0Hujh0Cm",
	"sZWwl6FwOHUvKbvRDmQCAZ89zHsFG68rM9pIblWpTR+yMDoL3SVT/E3FSy6N8NMaTQGJK4y4O4J3UJlk",
	"Zk581AvDjEmSfjJYx+786BsDhOdZUwox8s/zikSdYp1gONcFF27e+JXoNmhDYvsD6DYEmgae7ASliiQq",
	"BjopSnWV5YL9yZrPDge76x3ufUNhQqi6gbwTnCJukGJpfFXl13QR4hJGQbfmeV+Vfanslj9hjpjd3Ysg",
	"/QVDgovOrtVkZ3OZQBf/N9DkUHc+gCEnW+TH6Xmc+QYjTs/vsMuJcB7YbPAI22DjwCko+MRF4nVCJ66F",
	"XTGbA3Ym7P6Dz4EIx6i6RROUo91EaFCATmbIqgJ76PxwC515gNwHWX1e2J2hENyAOpPizmAr+kzWyHy8",
	"Aq+x+rQtN7q/JplaO5yf/dcBXCaf7R3s7ZyzVfb69PjQEflodny6u3fKXv03y1J2sH+4f87g7Hr8+vXZ",
	"3jlbH48kY/0F8p/dVw2Sngapvf3mtJJ0kHaBxlNVlfl8LeVZPu/iFSf3K8bHpuLCsPsWtBuSiwD5FHIR",
	"N9c3X/TXN9ZcBwa/aCX/D2BefJelyIuU25PFd5sva62PhD7hhudq4vIqSq3KSE7wG+rbpUjUzGeJgNah",
	"mvEmz7d6i4GOOODXApO+QKTA/QMBLqwztutybX19fQPaPO4x/2TTPRkMBl2sHw1iVFsoMbDaA1cSMSjh",
	"2ycEC45VZZLBgPSYtuJNd8oaRety7hmlbMNtqy/LLLnWLVKSitxwRBIJgmKt9yAptTFuNLFJ54RvYtJM",
	"jdaJcnDsLhV9jjHfVsRfuQQkZ+x4JiwydnASgb4CfFSUZtZ3dFesxnaFZdTJswI/Vr+sZIMPq8UYOUMy",
	"h5Bq2bNLtuQytRWhOxb9fJ+LpYrOUUjSLlNGgOtw14ph4Xgsgwm54WWmKu19hfYnISnhcWzFaLi2tlZw",
	"M10zag0/hHg2BYmIVszIfdVnY701XFu7rJJrYeAT++L2jP+qJDvbsvU77PfoXFmKyyrLUycjERo805IX",
	"eqp8mB37wUqcc6uO5G5WisREBzU6SxKlCSByULiEO3GGQyLuYFnJKpn9o8JdLD5NNwHoFw/TsM7DSbXl",
	"LE3sL/5WkeycWtreVSPItMduMAZvIbCuN5JBwULuG7d2K0V3w8nc7t0gNqciyYoS5uiUy2v2uoLbjM7p",
	"6Wt/WMXNshZ9CxGvEIJ7RgocLm8xuY5oRebS8DtMQFG3oryqchY1P5MTEB24taynwmV2qxxfqnQ+tKul",
	"MqIEb5MLEMXBVqV9a/to1+rF41P736Pjc3jx1Mp/VNRc8HIIBrbYXN9cx7zUaWktnvDSaAXDdQr4YbTi",
	"nZBnZOj5rh5xzKPOuZxUPNREE7UwLUP07tmPw9yGe3EfX+LSPqELxKnjrEzYD6nIujvtzEV5+KN6KHCm",
	"UpH7SfseJQJbglM8khT9pBuhS65ep2mxa+3S0hKkbgu7sIVd0AaPt6IgGS6SMZped6E6WnH1Rt9hGqLV",
	"pBzP4nmeTSC4092fuXGLQuAvbPkX0h52aiHvFChIVxfQ1T1MokDP7Ckm1joiJbQInfhe+SsPvw7gCTsp",
	"xVV2RwH1SIcUaZDbqdKgNyAbpjRYaoRcgt7dRr4CVnZRYNEwDvakM4SbZOiLkxG4t4Di4aBA721sbuEV",
	"Nvz14uXXo5VGq2Fdj+R2UeRzxmuLl2vGJds+2rXbDcZBtjfPz2h9dikOfT40IplKlavJHEprrMTRyr3r",
	"TPCowwkCI99BT9nzA2AOUNNkShOBD/ztnZ9H17E9jMSKZsKF/TV62zk6Pg8d7TZ6Kly5j3Y2FUUpEOL7",
	"+JSQAoag7G5EGvW14Wuw+7tw/hOK2se7S/AIWxse4kp0orzQllxeZ3LSo7TkCCkslOv09+n2G9Yh4Cme",
	"97eriR0NkbI3Himii4GijV1Ipg5MQoRgW1IFBweHuPcv6p/SVeVKgteIs8ytrAeYxmL91yC+ykSd8yoJ",
	"FwI+kDPUATZCCPqF3dSnlOhbUbLtCST4jeS+1yvG0VmpCnwQuFh9BB3+GDA2YAx2cq611eY6DJ5mICQa",
	"r6itoelCau1C7LvBFxpS6+EaFlVtqxEQj0mIgObQC806dpd1lekuiwOx93fpd007UDeejoRajp6ZHqOI",
	"S91zzUBfPI0oDd6+lznaS05dLnyb/9qBAoAqsCYU5kRhOn3IprcVsH9UEPHq9evGoLlruWjdYIH8ye/Q",
	"XYx9Aq0xbm5BFL3Z2GDG3vNjD9YkmqVA05rupKymXW4lAcQhz2EhuxDnoGdqW6m3CLzO2rS10loOmhi9",
	"lEImKhUlbuJ00oB8Fi/fHqEShLLvp9xDEwxs023xTqPMgFApSaoSQ0O4XLAWoqTeHtPKuX5nzKpDuu3s",
	"+2A41xTyxRlVsJcQi4DWY9MuaN3eJxixn/MCbjDdrg6HcvvGxvo6PSqpM7WAMRK0kiLB8pzPuI8EG61A",
	"ryiAS8hJwtXaf90KudV3I9NfH3z9avh64+vooygap5Y8txB/ZSdxy4kOOykrCTNJO6yqDBxbSazDxM1Z",
	"KgwhsuCcTngBp1FNIDizTGazagZuMj1VedoO39A6oDOI1xEsF7yUAbLADlUlG6M3y+QFtOAC9Jn9bX3w",
	"Mowev6OfJ7y4KESZUHTe1vpgfWE0+mzcKG88ZD8IUaCN4rrvNzKIutSG/e0/POWWKug1LK2t+rE9TKsC",
	"Q4Axw4ulpSpQukGo//Yf3vEFwZNJZbIbUVdjX7AXA3LXnhm7HiawVe1gIu1U3S4zictIT7iMWTwGl+XV",
	"mHUoWLU7XHa66juFkfbQLcluBdwzsZnSBoCXMEit1FdjW0rOoflnICm+EGn3+Tz7lbbqW5FNpjS6dkSy",
	"K/CDm3yOR3Se5epGlGO8Ew99y64iHRA2NrgQ8EP10vlMve2MunYc24Fjl+gcWa4QxFCUglRGw5aJ7JeR",
	"BL0d2S+08ziYlUsKMIeTUknPTWTdCV6SX2N1tZYrgjdKlOURdiG7Kbq9l+Z0CN7hs2Cl19yUrBNG7U9e",
	"HtAvjLrbWW9GMcnLUt2CUKcKYy62MJfNaTEIP/byrsG5i8XgOkWdD8ijqjJ5JkodOx4WCB4XPQ8OhOYB",
	"14PDWQ+IWnSawkyYpzsdsAhrbM1UyvNmXh4iSngnQjNFwdwqnyOMCRCQH+ENgWg7v1n3ObeRBwIrGMlX",
	"h5svKZ252XiyXMHyH4QsOThaI5YOBrw04YPq6V8kYDuNEI6WGEUfAhy33eviOAMBclOy9M7/OBOzC6sy",
	"fUJ6Peb3GDOTHUiAe3vMOg6mqTtk+1cA59FzIGU4rFbJiJkC+tB8zjqVFnC0VSUzAiJvuvX7YqrEjqs7",
	"dTCeT1SZmelsuQeHdTC1K7hwuq0+HNZZ9OF0F5w4rLPgxOkuenFYZ9GL0/WZBTi7X+nFbNAwyS7ljOxt",
	"2ymjH0mZWsza90LLr6UkeaWE2bOwbkhgt4uiVHfZzK7C674UvLSqS1plfgnjs/3D0VHXQb+AhbBgT9YF",
	"/KaZmztYPHI2Zvd7Xqa3vBR9niQip9NFmmkDL7sgrSjQ5Gz/cBdyCcoq8Qewu2+/Xts+3B2y7R//tomX",
	"gj/+rf9yYxPVLF04omahRsagV322fXo4ZEd7x0fw8dnhHuucJTynYCRTZncBIaXLfFvBd2Ml5lVm/sue",
	"IaRxoWDo4U2rRKRO7q+UMkUJYT0ydQGzIUnvSLE3J2/jCAjlo35taTsnb0m/pKLI1TwKQ21JXHpEM5CA",
	"tCgFP3s1vZBmM+w9mGDfvqDH+PJ728U8z/vW3sxn0e9VSb9OjSmGa2u5NWOmSpvhxsaLrRcttrDPRUgp",
	"8djpJ9e88ZDt0T/rIXAwsM708BKsY2XH80ahfijGQ7e4/CPWqSdxuwZYW6eW992l2wuRp+MhJRBD0OWl",
	"D0j869nx0Qk3U+fQdtkQjZPBGB45rKwB7X7u+ZcDQCe+tAY2waUYMStybsR4yL6HoJZLbg0HeoqaBfM4",
	"ilLNChOZZniH4vnc7QBktttr0faLp0bwvocQUcygX+NVmqk1Kxyqvn+AYe1A7xpbBe3jfgJPSLxat/MW",
	"X7QTRw2xO9YsCnJRlwa/6R+DzLIO3iEdwvG0u7icHhD0h8X8SULu5PtEFVXO6Tiuh2wcirNzDK7mPvSo",
	"7/BTZneXPKNnOS8nwh8ZAY92/9GuFELyrK0rANrix7a/1dczwIChN3mRXVwLck/q6/5gMIi7cui60F7M",
	"mHU2Xm59nXZ7LW9gP1hna/2bzbY3eMr76+ubvgwPfKHUJBfsjbBD9ljHJ/jW4x1fX38RHW7VLyIxlBY5",
	"WpnN+/QouBQIOsO50/v2OFnyfKNdwX7z9bdR8k1NtnGRxfAXdCrAJRYQTrZ/OmOvRFqq5PqxXl/Sa22i",
	"C5ejA5MZLiMh69+EliOAh++ZPVf3N1pnfXlhVmiX/rppf03UVJRigM+FnOSZnvZvthZ+gkHKMzmpeG5/",
	"dzCyYez2fVL0SJL+diePhPvAdg/6AToLDxmguJyt0674Qk4PYH2deV3JOue3qn9m+ER0XaYklhH8bN7n",
	"DVNahwIyU0EuMzzZRT+2+meWb/WffiuHDdrdq/kReM+C85zf8NZNP46vsiftH+Ph7Izhw3HXj6peGFaA",
	"MvH7SidWrF0Px4EmAeXc4VIUqasLRZssg9VV3DcgPAVr79E/+sU0A1m95NeNX+CTrbEDnLXqGUHBC9N/",
	"oex78K++qcrL8KeChtJXqNvwK/hnf3Ow3r/KuZ72xV0BH+HzjcFLq5saT+BNKmtbmmmpCoyrHSc5t6eO",
	"rf7LvlZSCtPfXN98sbG+iWvS/aqKSsMv65ubfx47bFtQKg50HAsdLC+wf7M5XPf71BE6nqJl26GYEreE",
	"AKyaPMcOgCHFeItWRfkhq2RjffMZy6S2iTx1G3lsI1mQf5z0r/SiH91qMRwJvA3BhEvnTUS95vNluc8W",
	"rKkjjwDtJf5QpBmnfNmAbIPKMBpwUqW9OAeLS+ZjYxnk6ICJ50y1Wz4P/pb9GcYLgghxLb5+wfA+ImUd",
	"CNp6e7rfBaGyfw2hN2u/FGLyl0t4u4fxzPgHntpd/Bq9XMinv3srLosHXsZmvj09wJA0suUQwQ5x6QG6",
	"bov+QcFKXsi37dbCMBKQ/eis4vcskNB2wv0bXlfabrSdBB3u8WjlhKIET6bKqBDaYD/06edtA539+Or4",
	"9Hb9hzcTtb29vX109na693ay3TD5EBuLDhf9V3B+PYFzBQgRZoxnv6Lfuw58kCh5I0D2HEYL+XCDxKP4",
	"tRxjPtKmuOw6xuVPU221gRyyd+9geO/vRyO54+7o2bt37r4eftgN5dnfouLv730FH3tTrm+gblrYGUTI",
	"hZhFOHBaCVwcWTvennVh6n/+RQN9xaTKUrFGiWeUvQ1pZm5aWlKjEw45qRjiGmXIIsYM3WkMQ2a9K90e",
	"dO9MvfRSJMLuG4ACUEs+5hodw3cmdplgT6nj43fvPI7V/f14yPYxlQs9bBDAR699kRHU5v39YDB4924t",
	"u4IPdlwoB89ZriZZ4t7H1Pey5HP3hX2ClRi0+eBX7T6oZG61to8NcZ/hc2rdjSghu8pXSl//Jyjh+3ur",
	"It69+89rMff/vspKbfxfOYc/huxAqQIBwFyowurqqyrLTT+T7HuRF6J0QdsbA7a6qpOyuvzezPLVVdZn",
	"xFKGArymzRyCHiaasKhMyRODKbwExluqGYBIgciOx+MgR/Dk3TtfPpuaWX5BTo37e/cB/N9VrNkYdTM2",
	"gHQzXgnRD7ZJ7jmAn+P3wO4kxW0O0RuYx3QJmZ0iR2AL1il6LM1uemy60Z9+3WN51mPCJBj8zEJsRJHz",
	"jLqHsVulgHyylJWCp573Aq5sVlfFP2Dg9tz9bAjOdaG2bkr10jGyQtgR/3DEIKMVTBwerXTv77fhnySY",
	"jfetPFjDHLOu4HWHuQgyHX9FqmLLthk2bmj2GyF/yAxLlSEPEe7paHPY5Wf7sHgjs7Qn+HlV5t/BLrPL",
	"DX97uu8bHn4200wP4J2LqsxbXkB/ilVNxDIJWgm+GPxSTDAUauEb2E9d+oQLD8aPCrnso2bk8WIlTk5J",
	"RIZOGuP/+jEcQtnDqsQUnEVbxe6rIMHxf2F2GGPx0eTt6QHiRlKeBYgpGjWAd1k3qpxN5SMpltlVg8Fg",
	"7ITeGyZsLbJMWJ/9JC5t/boZvOTB4uaFcBEImL/AQhB3W9Q2kJm75UqGD+uzs60+LBkDaHkuNLxDKC30",
	"YnNGr8Uc0Z1hwAJY5Q417sT7K8O4ra6iQQqok+pW5ooDxnApNDjmO9kVBc93e3WDxQ+sL+lk97XG7erO",
	"OLWIaXKglTHpoRQyhQAXTi4I/7lVmPbzU9AnOXkJQjloCx2qX7M85/SW1zooI0TXBT0uVe7lw/UMt+ei",
	"VHaCMP/IzZyj+nJxItbAQh1K6NpTpQ27nWZG5Jk29ONJmd3YzW3/BPUqWA8e3uLs7PQ148bw5Fo70XJN",
	"QRw6CMXRkRWwsb5++GrhXZPNhKpqL26t+yJhBiMf/UKhm+svvi3uesjkRTPrBOVMiCFrZ5laqzmPv3Aj",
	"1O8ndIXwAlQ9LLRzpSSqfPjTs+ScHx8febijc3UtZP+4zDBKkpBKjwiPprtUf4YqGGhIhAj0Wqv9Z5YL",
	"OTHTQ15ei/I7xCS2doM037147NNUwBiK8rvRymhk6hqPhA169ppQAkJQ3urq1nr/6/X/QFhsvCLD+yra",
	"BHH1/PXs+MhJ2I5ClBa6ByGovSFegjaS4J1QQvI79hBRMSBo3279f/9i6+ch41mPwgdmubMmzvklONpp",
	"OmzplcwC1oAneXC1HNfu5w4ODlnBS02uRcbYsffPofqKR3zMOpdK5d0hgHN+wTBoBTAYoO0IKB0JqSkr",
	"4fUvTtQYUKm7Q3BpEiUa0wVPYJkF8faf+Xkbsw7Gfnfd5RN5ARTCcBsaCjRK4bKejWmux+4N7daIO3qq",
	"yhSVGdY2P7yLZ/sN0j13K+2z8BiSsQzZX7kUbFeh3mufsAVZ81h00Y4H8ndWo93z6zgi3DNKyT7OOPyb",
	"vn6j2L7tk6eaa/2Y58W10NeZXJso/Hgkf/KOFXc67OGlE1724TmCZQAxlno/DaTTGsSrysroFJ9p5iCZ",
	"RDqoAQ7voeq3IwrbrbswdORyrkZPfxquyZp3iwhQi8XJCWGTo51OlCcBmdmvgmcesaOztL+tbDtU18+8",
	"y067yw+6jUOu7ypJqb/H9U4QgFdXBUGkeFCeMWYw0N0p84wuhBwNm0VRikLIVLPxl4Oxu+SlJFtHefPl",
	"oOVyFpD2izxLMhPNG70P/C1/X/95gLfyY6/Qsujqws5w2PxRqlwONKfMjoGDKaYbXzpcIDw7QAX4gCPM",
	"SPSJWnVelsBiWLs8dyPqE5YyUANg3+w5H817iogfqk/uCTlSRgzja3275tQsMxjoTkCCl018dljT0Y2B",
	"u3fY+vZFuISL/NewRB1AovMbva+H6puvv211QXnP0we5lN7bgb14ifnMi6CHam5eWCwJij4J+wzeprAz",
	"Yari/X3/L7e+XhRP4jh5umzGN+rPuVNfuFX/8t3xyd7R9v7F9sn+xQ97/33fOg6tmOWrqxRjHGzh20yL",
	"HLCmvkeAbP+T9pkSGLafzCFA36NF06FrjcLsAFCb/PbAo+l9ci38WHFcbEPTsEwaxWaCWzV0VeUUhKIj",
	"7iZcTxpDp+cOa8vcqr42cAwMosb+5ENwuhHCOhyLeoTARF8RVQTqZGIoxdPojWY7uaoA1YsiQ4BxwG4X",
	"qrCb4lphzznJvMcS+2IUckJxMCSRazrhDkqLzK7YQIFsbYeWTpv3rb/3TYn6EmGjrlzIEL9RWcpupyoX",
	"IRGjhuIYkmfQnrHlbMeg72c+ePAc8mPwtRow/Noia1UdK36Iu+3GgO1iJmMM4rYIgg6egFaEzQcxemko",
	"Pz1Kr4uH+wS0kK30Bsu4BZ+Aw7vpeHLi0HprKLQOb5SyGqGHhzjg2sAuiyRe3pgtF65vt0diVyBWrLbW",
	"tKfrUrOiTEcZqCWGOS9aVB4YvG1g+yBtnltDLuLuB5OOqDXoLsLzQnVHEnF7EIbJw/wDITzjYMmXSK06",
	"sCdeRr7HHkDqFqMV/yX8bVSBgpDzwm4B6E92KZPCw+7vEqjET7buKS8KITWqg7mqwOmEcfrwwf9xMCDo",
	"HNDuOUJ4IqQ34H8xIcssmdoV1muCqRHSQZQR7iAAA6b+gH0vSvGVbQk3iH1ZiMRgw0KliO3DOgTp75SX",
	"FLcU4wf4F4QCWfOjdP1V8Lb76kjcUhi/UWzP4TSeIyyhjwFs6Xm9e8vGIaguexS33a0tn0tra8iT47Nz",
	"toY5kWvv4P9wT7RGI7X2Dv4Bz55gYtRMhsFgsLim93z7/OTXukOXVn446nen2DskRKpPoIPPjKBiw8sB",
	"QbMJTxsFcy6Bp4V8VIDdJSIJvJewuzmxpxelmpRCa68qDhs/1Icc8HSeOuI0dAdKXTNu2Bigui6wDUTA",
	"EgbU1Qcgw/BmSOYuS1Xivaej9dsGeQnz4YMfWrOX6jVBLlOvuTiB+VwjhC/g9A5dGLMp500w4dc8y0Ua",
	"FdrOgGHKzGkucVcoaTd6nsPEq6urB6YzQPw1JtTBPmPZCKEaemYPaJn06UxmKmJ2cQAGzK6YVjOkdMcO",
	"Buxg6FYEC9giOZ3xogQ0Z/9+jHYdjCg5zdrZ32FUtGhOTlUKBtFh0VA3QWtjTKWbjDf3WbgEcDqMPMer",
	"qztqNlPSdZOdJULyMlO1a1R/SAZ0nLeBct97saIBp2loTDzmIoryJkuEw8/T3j/e6Ifb7zou+ieER3Vb",
	"066oIPAi2FVwAT6SYSyMxH8UoCWjZdEB8XcYl3G6H/zQ9fehp1bmAGYXAgacF9df0ZAUU2KeKefeNYw8",
	"QOQUhihqZ6N72xiu19Hp7xy3ZTjH2JH/R6UMmaqLceP+AhSC/VBBAB8g0AqgFdCLryu6vgMHERJ2lBeP",
	"AM3yRmiTTXh0E3ZKU6yNKug6esbvGDf2NGWa00qzipu0p36Eaa3pqtXV1zzP7RC6fNM5CeFryCLKQJZg",
	"ycMlUM+jbobcTYeaS9/bwb3iOaoX+GNBcG6XakiY+1bn4ePoLZRvZEQ5ewS7pfamz24rJ+LCdYIsW+pi",
	"PWjpfJpprxk9MEJ+y+fa4ay4bFyn6qKYbKufq7Ca/ebica/RmlnAFT9XBDdIiqWZnWBPV6Uq0FHsNn40",
	"Vth4d+9g73zvUX0JK+5UEP+yx9jGqoZs3GLotBWyNYhMD7jM0gtbUt8ZFsS4rYw98kWspc7K7NSzLLvO",
	"hqtBeitHu+RoVOPaRtLBdFFyNhw+cTAJgYCnYsAaAd8dnynXpUXTRMldNIADWxRggL3CmLRD/osqI/Pd",
	"LS9IW4AR0sLonkMOo0i2YKsOn2Jr4sd+ueCfPlwUy+xTmX1iTVmSgwA35LM5XY0T3prHKlyI4HtT8oJS",
	"XSnrGyhcz88PIBYVfg2DCrSfblRBMwGgaqaknmYFekodSoUpud2yAmjLgB1k1xF4To9BcXBw0yPpYn1b",
	"ucWciV+IEomVkVogXkaBETV0iR3f2B1U3C52BuHg8JrGWmG2ET7FP2oj9NOh4WSEnUpAYzIlGFfbEikI",
	"OBuB/nwZQOeBY+Ed8P2pKlwERD9Cj4pHE4Hi7EEjimubhD6005j4g4mbqrb0YJVkPL+AN5oC8YWf/4f4",
	"0qI5sm/H9AGijBv5dP60J7W8FImQBtkiHNDywxRSjzKN7cHEP5NlzOurGt3Yh7KE8QQXA5sC4nlAKL8W",
	"dcKXrl1cGHQBWtF2iTvq/TRmHEOxXmQbW1iczSPiQzRjVOgzKca8XN3oGt0gzkz8ZHWVdUwgN+giIpK3",
	"w8FUb/BaeEuJXIYR98aj7AeLLHEhU3LsmZRIglwvbBtRHT+njfHKQOUVtxS5zRWNLzSTmwDqFn3smw3i",
	"siiNrEOMQZlkIDeINtxnuw7DIy6NEqSATtODfLAab9YD/Fp+XgHxwGMzL5JsMa6DsXx+fvA5SLceZNiC",
	"DUG/vx7FuMyLJ/A9btT07LldvAy/RrBxV8RfaO5r6ohIuYDNGD5yeE8Acm8Hc5uestdCpO/fnw/RrgGT",
	"x0pAzrUBjjPbauhhXOhfmMrt2Y70SBuf1gJj2KkA7GSJdG8fMGmmFLBtX0Rb9mNMnc2pc2X4ILqorL+w",
	"UlyVQk8ZgEzbTTwnBCaVp7X5dZMYn5E/QBqL7MKO4XPl0J6T4TvYu+1kPSSF4BPIsxSB7GSqbqNjOPL2",
	"P4n6zGsNt1PWtUdASHBwsy3ao0GgRuRktK8DciYQmqGSrO2mur6dEkqDL77JluYJFW25nY0ujBSUSmwW",
	"pYAYy7o58CQSNSglwEw/nwmtbn/FJGwO2jpwoS3s+sv50Mgofz4XGkyfYypqTtpycrTlFGgIuIH+S3px",
	"Gd0Ziq2dHDBYuu3MZl702unNIpI9BD2vC10bzZloCvMv6tJtrRf2JH5hTP7d1nPZzrA7yHS2sflNoDr7",
	"9s8LTGcvX2xtekP3kDyjYCWKtGmUw8Z7bj+vLfSU6cyuVuLmuBSJnUpKPrDzZpW666HXKyhB0jb9Rtea",
	"7r22Teq1+IS5lHGtedLpsx0EKQcPBKxHBGkrPIKp8OzN/q4nWPjEmBPlb6DpjO4IKgqX+EnOJeNJAlQm",
	"E6IXiKgHFmBaWrjXwJ0Ttcp5fpwnb5H6bDvP/Sk0UTOQ/xmX3te3jFvtoZqWsKx5B49oH5oH+NFO/AF8",
	"gXIMzi+xhWuPMZnRTN1KmF6KMCco+3TiyMsCMRvFfLTZtaxjm+gXY/iG0saOFDgHhLfPh9GIAi9X3DQ9",
	"5aUI201s6xI0P7zmRKpBAbfDpW3MDCQaVYlsldwHOOUw4p/k+Oj8BCn7HZBmTKveSixHrqqFYCBr3VLa",
	"bwy7VjPr9ZMDCLwIXtQ8E0ujCYJ5QpEEPtSJbEtnvz6hhF708xLjs1kFz61YXDhu6Q+rYmO6PB7CHih8",
	"fFP9JFW/yA/jHvtIVJ4l2cLMIH+/uqp7gQa1Czavf3M1cR6MnwDZGihQssk0Vr0R1xB9B4omBZsllnmW",
	"XfmSHd8IZ5fKmFxIkVzT4RavZPRUlUAM1qAlxP7YGejbk3/mjjcOfhINeu2zfYNGpY78KEq7npoupUuy",
	"O3y0BUYmBJAvKNS1JoZ7BBVYCorbReSB2s7UZ3twFdDiDyF0yeZeXGJYdwybCDP/MPshapMH2Q+PY2IK",
	"JKkyCiNQQlVvtShbiofHTy3SrukMj5uh4BP/sKX46Mf7n+3Phk/elKoq9Mrw7+9cEXQVflJd5hmwgqz0",
	"Vgyf2HdWJqj5LwCtXqQrvRVSZ/Vha+GRXCTDaEGpXJiBn+1gRGMWDX2jZTSiURd/vv/5/v8PAAD//7Jb",
	"mz8c4AIA",
}

// GetSwagger returns the content of the embedded swagger specification file
// or error if failed to decode
func decodeSpec() ([]byte, error) {
	zipped, err := base64.StdEncoding.DecodeString(strings.Join(swaggerSpec, ""))
	if err != nil {
		return nil, fmt.Errorf("error base64 decoding spec: %w", err)
	}
	zr, err := gzip.NewReader(bytes.NewReader(zipped))
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}
	var buf bytes.Buffer
	_, err = buf.ReadFrom(zr)
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}

	return buf.Bytes(), nil
}

var rawSpec = decodeSpecCached()

// a naive cached of a decoded swagger spec
func decodeSpecCached() func() ([]byte, error) {
	data, err := decodeSpec()
	return func() ([]byte, error) {
		return data, err
	}
}

// Constructs a synthetic filesystem for resolving external references when loading openapi specifications.
func PathToRawSpec(pathToFile string) map[string]func() ([]byte, error) {
	res := make(map[string]func() ([]byte, error))
	if len(pathToFile) > 0 {
		res[pathToFile] = rawSpec
	}

	return res
}

// GetSwagger returns the Swagger specification corresponding to the generated code
// in this file. The external references of Swagger specification are resolved.
// The logic of resolving external references is tightly connected to "import-mapping" feature.
// Externally referenced files must be embedded in the corresponding golang packages.
// Urls can be supported but this task was out of the scope.
func GetSwagger() (swagger *openapi3.T, err error) {
	resolvePath := PathToRawSpec("")

	loader := openapi3.NewLoader()
	loader.IsExternalRefsAllowed = true
	loader.ReadFromURIFunc = func(loader *openapi3.Loader, url *url.URL) ([]byte, error) {
		pathToFile := url.String()
		pathToFile = path.Clean(pathToFile)
		getSpec, ok := resolvePath[pathToFile]
		if !ok {
			err1 := fmt.Errorf("path not found: %s", pathToFile)
			return nil, err1
		}
		return getSpec()
	}
	var specData []byte
	specData, err = rawSpec()
	if err != nil {
		return
	}
	swagger, err = loader.LoadFromData(specData)
	if err != nil {
		return
	}
	return
}
